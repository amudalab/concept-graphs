
Alphabeta pruning
 /firstHeading 
 bodyContent 

 tagline 
From Wikipedia, the free encyclopedia
 /tagline 
 subtitle 
(Redirected from Alpha-beta pruning)
 /subtitle 
 jumpto 

					Jump to:					navigation, 					search

 /jumpto 
 bodycontent 
For other uses, see Alphabeta (disambiguation).


Graph and tree
search algorithms





A*
B*
Beam
BellmanFord
Best-first
Bidirectional
Borvka
Branch & bound
BFS
British Museum
D*
DFS
Depth-limited
Dijkstra
Edmonds
FloydWarshall
Hill climbing
Iterative deepening
Kruskal
Johnson
Lexicographic BFS
Prim
Uniform-cost




Listings




Graph algorithms
Search algorithms
List of graph algorithms




Related topics




Dynamic programming
Graph traversal
Tree traversal
Search games







v
t
e





Alphabeta pruning is a search algorithm that seeks to decrease the number of nodes that are evaluated by the minimax algorithm in its search tree. It is an adversarial search algorithm used commonly for machine playing of two-player games (Tic-tac-toe, Chess, Go, etc.). It stops completely evaluating a move when at least one possibility has been found that proves the move to be worse than a previously examined move. Such moves need not be evaluated further. When applied to a standard minimax tree, it returns the same move as minimax would, but prunes away branches that cannot possibly influence the final decision.[1]




Contents


1 History
2 Improvements over naive minimax
3 Pseudocode
4 Heuristic improvements
5 Other algorithms
6 See also
7 References
8 External links




[edit] History
Allen Newell and Herbert A. Simon who used what John McCarthy calls an "approximation"[2] in 1958 wrote that alphabeta "appears to have been reinvented a number of times".[3] Arthur Samuel had an early version and Richards, Hart, Levine and/or Edwards found alphabeta independently in the United States.[4] McCarthy proposed similar ideas during the Dartmouth Conference in 1956 and suggested it to a group of his students including Alan Kotok at MIT in 1961.[5] Alexander Brudno independently discovered the alphabeta algorithm, publishing his results in 1963.[6] Donald Knuth and Ronald W. Moore refined the algorithm in 1975[7][8] and Judea Pearl proved its optimality in 1982.[9]
[edit] Improvements over naive minimax




An illustration of alphabeta pruning. The grayed-out subtrees need not be explored (when moves are evaluated from left to right), since we know the group of subtrees as a whole yields the value of an equivalent subtree or worse, and as such cannot influence the final result. The max and min levels represent the turn of the player and the adversary, respectively.


The benefit of alphabeta pruning lies in the fact that branches of the search tree can be eliminated. This way, the search time can be limited to the 'more promising' subtree, and a deeper search can be performed in the same time. Like its predecessor, it belongs to the branch and bound class of algorithms. The optimization reduces the effective depth to slightly more than half that of simple minimax if the nodes are evaluated in an optimal or near optimal order (best choice for side on move ordered first at each node).
With an (average or constant) branching factor of b, and a search depth of d plies, the maximum number of leaf node positions evaluated (when the move ordering is pessimal) is O(b*b*...*b) = O(bd)  the same as a simple minimax search. If the move ordering for the search is optimal (meaning the best moves are always searched first), the number of leaf node positions evaluated is about O(b*1*b*1*...*b) for odd depth and O(b*1*b*1*...*1) for even depth, or . In the latter case, where the ply of a search is even, the effective branching factor is reduced to its square root, or, equivalently, the search can go twice as deep with the same amount of computation.[10] The explanation of b*1*b*1*... is that all the first player's moves must be studied to find the best one, but for each, only the best second player's move is needed to refute all but the first (and best) first player move  alphabeta ensures no other second player moves need be considered. When nodes are ordered at random, the average number of nodes evaluated is roughly .[2]




An animated pedagogical example that attempts to be human-friendly by substituting initial infinite (or arbitrarily large) values for emptiness and by avoiding using the negamax coding simplifications.


Normally during alphabeta, the subtrees are temporarily dominated by either a first player advantage (when many first player moves are good, and at each search depth the first move checked by the first player is adequate, but all second player responses are required to try to find a refutation), or vice versa. This advantage can switch sides many times during the search if the move ordering is incorrect, each time leading to inefficiency. As the number of positions searched decreases exponentially each move nearer the current position, it is worth spending considerable effort on sorting early moves. An improved sort at any depth will exponentially reduce the total number of positions searched, but sorting all positions at depths near the root node is relatively cheap as there are so few of them. In practice, the move ordering is often determined by the results of earlier, smaller searches, such as through iterative deepening.
The algorithm maintains two values, alpha and beta, which represent the maximum score that the maximizing player is assured of and the minimum score that the minimizing player is assured of respectively. Initially alpha is negative infinity and beta is positive infinity. As the recursion progresses the "window" becomes smaller. When beta becomes less than alpha, it means that the current position cannot be the result of best play by both players and hence need not be explored further.
Additionally, this algorithm can be trivially modified to return an entire principal variation in addition to the score. Some more aggressive algorithms such as MTD(f) do not easily permit such a modification.
[edit] Pseudocode

function alphabeta(node, depth, , , Player)         
    if  depth = 0 or node is a terminal node
        return the heuristic value of node
    if  Player = MaxPlayer
        for each child of node
             := max(, alphabeta(child, depth-1, , , not(Player) ))     
            if   
                break                             (* Beta cut-off *)
        return 
    else
        for each child of node
             := min(, alphabeta(child, depth-1, , , not(Player) ))     
            if   
                break                             (* Alpha cut-off *)
        return 
(* Initial call *)
alphabeta(origin, depth, -infinity, +infinity, MaxPlayer)

[edit] Heuristic improvements
Further improvement can be achieved without sacrificing accuracy, by using ordering heuristics to search parts of the tree that are likely to force alphabeta cutoffs early. For example, in chess, moves that take pieces may be examined before moves that do not, or moves that have scored highly in earlier passes through the game-tree analysis may be evaluated before others. Another common, and very cheap, heuristic is the killer heuristic, where the last move that caused a beta-cutoff at the same level in the tree search is always examined first. This idea can be generalized into a set of refutation tables.
Alphabeta search can be made even faster by considering only a narrow search window (generally determined by guesswork based on experience). This is known as aspiration search. In the extreme case, the search is performed with alpha and beta equal; a technique known as zero-window search, null-window search, or scout search. This is particularly useful for win/loss searches near the end of a game where the extra depth gained from the narrow window and a simple win/loss evaluation function may lead to a conclusive result. If an aspiration search fails, it is straightforward to detect whether it failed high (high edge of window was too low) or low (lower edge of window was too high). This gives information about what window values might be useful in a re-search of the position.
[edit] Other algorithms
More advanced algorithms that are even faster while still being able to compute the exact minimax value are known, such as SCOUT,[11] Negascout and MTD-f.
Since the minimax algorithm and its variants are inherently depth-first, a strategy such as iterative deepening is usually used in conjunction with alphabeta so that a reasonably good move can be returned even if the algorithm is interrupted before it has finished execution. Another advantage of using iterative deepening is that searches at shallower depths give move-ordering hints that can help produce cutoffs for higher depth searches much earlier than would otherwise be possible.
Algorithms like SSS*, on the other hand, use the best-first strategy. This can potentially make them more time-efficient, but typically at a heavy cost in space-efficiency.[citation needed]
[edit] See also

Pruning (algorithm)
Branch and bound
Minimax
Combinatorial optimization
Negamax
Transposition table

[edit] References

George T. Heineman, Gary Pollice, and Stanley Selkow (2008). "Chapter 7: Path Finding in AI". Algorithms in a Nutshell. Oreilly Media. pp.217223. ISBN978-0-596-51624-6.
Judea Pearl, Heuristics, Addison-Wesley, 1984


^ Russell, Stuart J.; Norvig, Peter (2010). Artificial Intelligence: A Modern Approach (3rd ed.). Upper Saddle River, New Jersey: Pearson Education, Inc.. p.167. ISBN0-13-604259-7. http://aima.cs.berkeley.edu/
^ a b McCarthy, John (LaTeX2HTML 27 November 2006). "Human Level AI Is Harder Than It Seemed in 1955". http://www-formal.stanford.edu/jmc/slides/wrong/wrong-sli/wrong-sli.html. Retrieved 2006-12-20.
^ Newell, Allen and Herbert A. Simon (March 1976). "Computer Science as Empirical Inquiry: Symbols and Search" (PDF). Communications of the ACM 19 (3). http://archive.computerhistory.org/projects/chess/related_materials/text/2-3.Computer_science_as_empirical_inquiry/2-3.Computer_science_as_empirical_inquiry.newell_simon.1975.ACM.062303007.pdf. Retrieved 2006-12-21.
^ Edwards, D.J. and Hart, T.P. (4 December 1961 to 28 October 1963). "The Alphabeta Heuristic (AIM-030)". Massachusetts Institute of Technology. http://hdl.handle.net/1721.1/6098. Retrieved 2006-12-21.
^ Kotok, Alan (XHTML 3 December 2004). "MIT Artificial Intelligence Memo 41". http://www.kotok.org/AI_Memo_41.html. Retrieved 2006-07-01.
^ Marsland, T.A. (May 1987). "Computer Chess Methods (PDF) from Encyclopedia of Artificial Intelligence. S. Shapiro (editor)" (PDF). J. Wiley & Sons. pp.159171. http://www.cs.ualberta.ca/~tony/OldPapers/encyc.mac.pdf. Retrieved 2006-12-21.
^ * Knuth, D. E., and Moore, R. W. (1975). "An Analysis of AlphaBeta Pruning". Artificial Intelligence 6 (4): 293326. doi:10.1016/0004-3702(75)90019-3. http://www.fileserve.com/file/ZgR5t3j/An_Analysis_of_Alpha-Beta_Pruning.pdf.



Reprinted as Chapter 9 in Knuth, Donald E. (2000). Selected Papers on Analysis of Algorithms. Stanford, California: Center for the Study of Language and Information - CSLI Lecture Notes, no. 102. ISBN1-57586-212-3. OCLC222512366. http://www-cs-faculty.stanford.edu/~knuth/aa.html.




^ Abramson, Bruce (June 1989). "Control Strategies for Two-Player Games". ACM Computing Surveys 21 (2): 137. doi:10.1145/66443.66444. http://www.theinformationist.com/pdf/constrat.pdf/. Retrieved 2008-08-20.[dead link]
^ Pearl, Judea (August 1982). "The Solution for the Branching Factor of the Alphabeta Pruning Algorithm and its Optimality". Communications of the ACM 25 (8): 559564.
^ Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN0-13-790395-2, http://aima.cs.berkeley.edu/
^ Pearl, J., "SCOUT: A Simple Game-Searching Algorithm With Proven Optimal Properties," Proceedings of the First Annual National Conference on Artificial Intelligence, Stanford University, August 1821, 1980, pp. 143-145.

[edit] External links

http://www.emunix.emich.edu/~evett/AI/AlphaBeta_movie/sld001.htm
http://sern.ucalgary.ca/courses/CPSC/533/W99/presentations/L1_5B_McCullough_Melnyk/
http://sern.ucalgary.ca/courses/CPSC/533/W99/presentations/L2_5B_Lima_Neitz/search.html
http://www.maths.nott.ac.uk/personal/anw/G13GAM/alphabet.html
http://chess.verhelst.org/search.html
http://www.frayn.net/beowulf/index.html
http://hal.inria.fr/docs/00/12/15/16/PDF/RR-6062.pdf
Minimax (with or without alphabeta pruning) algorithm visualization - game tree solving (Java Applet), for balance or off-balance trees
Demonstration/animation of minimax game search algorithm with alphabeta pruning (using html5, canvas, javascript, css)









v
t
e


Topics in game theory






Definitions



Normal-form game
Extensive-form game
Cooperative game
Succinct game
Information set
Hierarchy of beliefs
Preference








Equilibrium concepts



Nash equilibrium
Subgame perfection
Mertens-stable equilibrium
Bayesian-Nash
Perfect Bayesian
Trembling hand
Proper equilibrium
Epsilon-equilibrium
Correlated equilibrium
Sequential equilibrium
Quasi-perfect equilibrium
Evolutionarily stable strategy
Risk dominance
Core
Shapley value
Pareto efficiency
Quantal response equilibrium
Self-confirming equilibrium
Strong Nash equilibrium
Markov perfect equilibrium








Strategies



Dominant strategies
Pure strategy
Mixed strategy
Tit for tat
Grim trigger
Collusion
Backward induction
Forward induction
Markov strategy








Classes of games



Symmetric game
Perfect information
Simultaneous game
Sequential game
Repeated game
Signaling game
Cheap talk
Zerosum game
Mechanism design
Bargaining problem
Stochastic game
Large poisson game
Nontransitive game
Global games








Games



Prisoner's dilemma
Traveler's dilemma
Coordination game
Chicken
Centipede game
Volunteer's dilemma
Dollar auction
Battle of the sexes
Stag hunt
Matching pennies
Ultimatum game
Rock-paper-scissors
Pirate game
Dictator game
Public goods game
Blotto games
War of attrition
El Farol Bar problem
Cake cutting
Cournot game
Deadlock
Diner's dilemma
Guess 2/3 of the average
Kuhn poker
Nash bargaining game
Screening game
Prisoners and hats puzzle
Trust game
Princess and monster game
Monty Hall problem








Theorems



Minimax theorem
Nash's theorem
Purification theorem
Folk theorem
Revelation principle
Arrow's impossibility theorem








Key Figures



Kenneth Arrow
Robert Aumann
Kenneth Binmore
Samuel Bowles
Melvin Dresher
Merrill M. Flood
Drew Fudenberg
Donald B. Gillies
John Harsanyi
Leonid Hurwicz
David K. Levine
Daniel Kahneman
Harold W. Kuhn
Eric Maskin
Jean-Franois Mertens
Paul Milgrom
Oskar Morgenstern
Roger Myerson
John Nash
John von Neumann
Ariel Rubinstein
Thomas Schelling
Reinhard Selten
Herbert Simon
Lloyd Shapley
John Maynard Smith
Jean Tirole
Albert W. Tucker
William Vickrey
Robert B. Wilson
Peyton Young








See also



Tragedy of the commons
Tyranny of small decisions
All-pay auction
List of games in game theory
Confrontation Analysis
List of game theorists









 
NewPP limit report
Preprocessor visited node count: 8413/1000000
Preprocessor generated node count: 40913/1500000
Post-expand include size: 74493/2048000 bytes
Template argument size: 28824/2048000 bytes
Highest expansion depth: 21/40
Expensive parser function count: 2/500

 Saved in parser cache with key enwiki:pcache:idhash:159501-0!0!0!!en!4!* and timestamp 20121225221725 
  /bodycontent 
 printfooter 

				Retrieved from "http://en.wikipedia.org/w/index.php?title=Alphabeta_pruning&oldid=528929489"				
 /printfooter 
 catlinks 
Categories: Game artificial intelligenceGraph algorithmsOptimization algorithms and methodsSearch algorithmsHidden categories: Articles with inconsistent citation formatsAll articles with dead external linksArticles with dead external links from September 2010All articles with unsourced statementsArticles with unsourced statements from February 2007Articles with example pseudocode  /catlinks 

 debughtml 
 /debughtml 

 /bodyContent 

 