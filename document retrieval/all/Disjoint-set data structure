
Disjoint-set data structure
 /firstHeading 
 bodyContent 

 tagline 
From Wikipedia, the free encyclopedia
 /tagline 
 subtitle 

 /subtitle 
 jumpto 

					Jump to:					navigation, 					search

 /jumpto 
 bodycontent 
In computing, a disjoint-set data structure is a data structure that keeps track of a set of elements partitioned into a number of disjoint (nonoverlapping) subsets. A union-find algorithm is an algorithm that performs two useful operations on such a data structure:

Find: Determine which subset a particular element is in. This can be used for determining if two elements are in the same subset.
Union: Join two subsets into a single subset.

Because it supports these two operations, a disjoint-set data structure is sometimes called a union-find data structure or merge-find set. The other important operation, MakeSet, which makes a set containing only a given element (a singleton), is generally trivial. With these three operations, many practical partitioning problems can be solved (see the Applications section).
In order to define these operations more precisely, some way of representing the sets is needed. One common approach is to select a fixed element of each set, called its representative, to represent the set as a whole. Then, Find(x) returns the representative of the set that x belongs to, and Union takes two set representatives as its arguments.




Contents


1 Disjoint-set linked lists

1.1 Analysis of the naive approach


2 Disjoint-set forests
3 Applications
4 History
5 See also
6 References
7 External links




[edit] Disjoint-set linked lists
A simple approach to creating a disjoint-set data structure is to create a linked list for each set. The element at the head of each list is chosen as its representative.
MakeSet creates a list of one element. Union appends the two lists, a constant-time operation. The drawback of this implementation is that Find requires (n) or linear time to traverse the list backwards from a given element to the head of the list.
This can be avoided by including in each linked list node a pointer to the head of the list; then Find takes constant time, since this pointer refers directly to the set representative. However, Union now has to update each element of the list being appended to make it point to the head of the new combined list, requiring (n) time.
When the length of each list is tracked, the required time can be improved by always appending the smaller list to the longer. Using this weighted-union heuristic, a sequence of m MakeSet, Union, and Find operations on n elements requires O(m+nlogn) time.[1] For asymptotically faster operations, a different data structure is needed.
[edit] Analysis of the naive approach
We now explain the bound  above.
Suppose you have a collection of lists, each node of a list contains an object, the name of the list to which it belongs, and the number of elements in that list. Also assume that the sum of the number of elements in all lists is  (i.e. there are  elements overall). We wish to be able to merge any two of these lists, and update all of their nodes so that they still contain the name of the list to which they belong. The rule for merging the lists  and  is that if  is larger than  then merge the elements of  into  and update the elements that used to belong to , and vice versa.
Choose an arbitrary element of list , say . We wish to count how many times in the worst case will  need to have the name of the list to which it belongs updated. The element  will only have its name updated when the list it belongs to is merged with another list of the same size or of greater size. Each time that happens, the size of the list to which  belongs at least doubles. So finally, the question is "how many times can a number double before it is the size of ?" (then the list containing  will contain all  elements). The answer is exactly . So for any given element of any given list in the structure described, it will need to be updated  times in the worst case. Therefore updating a list of  elements stored in this way takes  time in the worst case. A find operation can be done in  for this structure because each node contains the name of the list to which it belongs.
A similar argument holds for merging the trees in the data structures discussed below, additionally it helps explain the time analysis of some operations in the binomial heap and Fibonacci heap data structures.
[edit] Disjoint-set forests
Disjoint-set forests are data structures where each set is represented by a tree data structure, in which each node holds a reference to its parent node (see spaghetti stack). They were first described by Bernard A. Galler and Michael J. Fischer in 1964,[2] although their precise analysis took years.
In a disjoint-set forest, the representative of each set is the root of that set's tree. Find follows parent nodes until it reaches the root. Union combines two trees into one by attaching the root of one to the root of the other. One way of implementing these might be:

 function MakeSet(x)
     x.parent := x


 function Find(x)
     if x.parent == x
        return x
     else
        return Find(x.parent)


 function Union(x, y)
     xRoot := Find(x)
     yRoot := Find(y)
     xRoot.parent := yRoot

In this naive form, this approach is no better than the linked-list approach, because the tree it creates can be highly unbalanced; however, it can be enhanced in two ways.
The first way, called union by rank, is to always attach the smaller tree to the root of the larger tree, rather than vice versa. Since it is the depth of the tree that affects the running time, the tree with smaller depth gets added under the root of the deeper tree, which only increases the depth if the depths were equal. In the context of this algorithm, the term rank is used instead of depth since it stops being equal to the depth if path compression (described below) is also used. One-element trees are defined to have a rank of zero, and whenever two trees of the same rank r are united, the rank of the result is r+1. Just applying this technique alone yields a worst-case running-time of  per MakeSet, Union, or Find operation. Pseudocode for the improved MakeSet and Union:

 function MakeSet(x)
     x.parent := x
     x.rank   := 0


 function Union(x, y)
     xRoot := Find(x)
     yRoot := Find(y)
     if xRoot == yRoot
         return

     // x and y are not already in same set. Merge them.
     if xRoot.rank < yRoot.rank
         xRoot.parent := yRoot
     else if xRoot.rank > yRoot.rank
         yRoot.parent := xRoot
     else
         yRoot.parent := xRoot
         xRoot.rank := xRoot.rank + 1

The second improvement, called path compression, is a way of flattening the structure of the tree whenever Find is used on it. The idea is that each node visited on the way to a root node may as well be attached directly to the root node; they all share the same representative. To effect this, as Find recursively traverses up the tree, it changes each node's parent reference to point to the root that it found. The resulting tree is much flatter, speeding up future operations not only on these elements but on those referencing them, directly or indirectly. Here is the improved Find:

 function Find(x)
     if x.parent != x
        x.parent := Find(x.parent)
     return x.parent

These two techniques complement each other; applied together, the amortized time per operation is only , where  is the inverse of the function , and  is the extremely fast-growing Ackermann function. Since  is the inverse of this function,  is less than 5 for all remotely practical values of . Thus, the amortized running time per operation is effectively a small constant.
In fact, this is asymptotically optimal: Fredman and Saks showed in 1989 that  words must be accessed by any disjoint-set data structure per operation on average.[3]
[edit] Applications
Disjoint-set data structures model the partitioning of a set, for example to keep track of the connected components of an undirected graph. This model can then be used to determine whether two vertices belong to the same component, or whether adding an edge between them would result in a cycle. The Union-Find algorithm is used in high-performance implementations of Unification.[4]
This data structure is used by the Boost Graph Library to implement its Incremental Connected Components functionality. It is also used for implementing Kruskal's algorithm to find the minimum spanning tree of a graph.
Note that the implementation as disjoint-set forests doesn't allow deletion of edgeseven without path compression or the rank heuristic.
[edit] History
While the ideas used in disjoint-set forests have long been familiar, Robert Tarjan was the first to prove the upper bound (and a restricted version of the lower bound) in terms of the inverse Ackermann function, in 1975.[5] Until this time the best bound on the time per operation, proven by Hopcroft and Ullman,[6] was O(log* n), the iterated logarithm of n, another slowly growing function (but not quite as slow as the inverse Ackermann function).
Tarjan and Van Leeuwen also developed one-pass Find algorithms that are more efficient in practice while retaining the same worst-case complexity.[7]
In 2007, Sylvain Conchon and Jean-Christophe Fillitre developed a persistent version of the disjoint-set forest data structure, allowing previous versions of the structure to be efficiently retained, and formalized its correctness using the proof assistant Coq.[8]
[edit] See also

Partition refinement, a different data structure for maintaining disjoint sets, with updates that split sets apart rather than merging them together

[edit] References

^ Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. Introduction to Algorithms, Second Edition. MIT Press and McGrawHill, 2001. ISBN 0-262-03293-7. Chapter 21: Data structures for Disjoint Sets, pp. 498524.
^ Bernard A. Galler and Michael J. Fischer. An improved equivalence algorithm. Communications of the ACM, Volume 7, Issue 5 (May 1964), pp. 301303. The paper originating disjoint-set forests. ACM Digital Library
^ M. Fredman and M. Saks. The cell probe complexity of dynamic data structures. Proceedings of the Twenty-First Annual ACM Symposium on Theory of Computing, pp. 345354. May 1989. "Theorem 5: Any CPROBE(log n) implementation of the set union problem requires (m (m, n)) time to execute m Find's and n1 Union's, beginning with n singleton sets."
^ Knight, Kevin (1989). "Unification: A multidisciplinary survey". ACM Computing Surveys 21: 93124. doi:10.1145/62029.62030. http://portal.acm.org/citation.cfm?id=62030.
^ Tarjan, Robert Endre (1975). "Efficiency of a Good But Not Linear Set Union Algorithm". Journal of the ACM 22 (2): 215225. doi:10.1145/321879.321884. http://portal.acm.org/citation.cfm?id=321884.
^ Hopcroft, J. E.; Ullman, J. D. (1973). "Set Merging Algorithms". SIAM Journal on Computing 2 (4): 294303. doi:10.1137/0202024.
^ Robert E. Tarjan and Jan van Leeuwen. Worst-case analysis of set union algorithms. Journal of the ACM, 31(2):245281, 1984.
^ Sylvain Conchon and Jean-Christophe Fillitre. A Persistent Union-Find Data Structure. In ACM SIGPLAN Workshop on ML, Freiburg, Germany, October 2007.

[edit] External links

C++ implementation, part of the Boost C++ libraries
A Java implementation with an application to color image segmentation, Statistical Region Merging (SRM), IEEE Trans. Pattern Anal. Mach. Intell. 26(11): 14521458 (2004)
Java applet: A Graphical Union-Find Implementation, by Rory L. P. McGuire
Wait-free Parallel Algorithms for the Union-Find Problem, a 1994 paper by Richard J. Anderson and Heather Woll describing a parallelized version of Union-Find that never needs to block
Python implementation
graphical online implementation, , by F. Schwarzentruber

 
NewPP limit report
Preprocessor visited node count: 2242/1000000
Preprocessor generated node count: 13814/1500000
Post-expand include size: 9843/2048000 bytes
Template argument size: 3105/2048000 bytes
Highest expansion depth: 14/40
Expensive parser function count: 0/500

 Saved in parser cache with key enwiki:pcache:idhash:1037551-0!0!0!!en!*!* and timestamp 20130123213915 
  /bodycontent 
 printfooter 

				Retrieved from "http://en.wikipedia.org/w/index.php?title=Disjoint-set_data_structure&oldid=534554346"				
 /printfooter 
 catlinks 
Categories: Data structuresSearch algorithms  /catlinks 

 debughtml 
 /debughtml 

 /bodyContent 

 