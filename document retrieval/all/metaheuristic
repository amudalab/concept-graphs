
Metaheuristic
 /firstHeading 
 bodyContent 

 tagline 
From Wikipedia, the free encyclopedia
 /tagline 
 subtitle 

 /subtitle 
 jumpto 

					Jump to:					navigation, 					search

 /jumpto 
 bodycontent 
In computer science, metaheuristic designates a computational method that optimizes a problem by iteratively trying to improve a candidate solution with regard to a given measure of quality. Metaheuristics make few or no assumptions about the problem being optimized and can search very large spaces of candidate solutions. However, metaheuristics do not guarantee an optimal solution is ever found. Many metaheuristics implement some form of stochastic optimization.
Other terms having a similar meaning as metaheuristic, are: derivative-free, direct search, black-box, or indeed just heuristic optimizer. Several books and survey papers have been published on the subject.[1][2][3][4][5][6][7]




Contents


1 Applications
2 Main contributions
3 Criticism
4 See also
5 References
6 External links




[edit] Applications




Different classifications of metaheuristics.


Metaheuristics are used for combinatorial optimization in which an optimal solution is sought over a discrete search-space. An example problem is the travelling salesman problem where the search-space of candidate solutions grows more than exponentially as the size of the problem increases, which makes an exhaustive search for the optimal solution infeasible. Additionally, multidimensional combinatorial problems, including most design problems in engineering such as form-finding and behavior-finding, suffer from the curse of dimensionality, which also makes them infeasible for exhaustive search or analytical methods. Popular metaheuristics for combinatorial problems include simulated annealing by Kirkpatrick et al.,[8] genetic algorithms by Holland et al.,[9] ant colony optimization by Dorigo,[10] scatter search[11] and tabu search[12] by Glover.
Metaheuristics are also used for problems over real-valued search-spaces, where the classic way of optimization is to derive the gradient of the function to be optimized and then employ gradient descent or a quasi-Newton method. Metaheuristics do not use the gradient or Hessian matrix so their advantage is that the function to be optimized need not be continuous or even differentiable. Popular metaheuristic optimizers for real-valued search-spaces include particle swarm optimization by Eberhart and Kennedy,[13] differential evolution by Storn and Price[14] and evolution strategies by Rechenberg[15] and Schwefel.[16]
Metaheuristics have been designed primarily to address problems that cannot be tackled through traditional optimization algorithms. Although still there is no guarantee, metaheuristic methods usually turn out to achieve better results and better performances in contrast to their classic counterparts. This better performance goes back to their nature of design; they have been designed and created to jump out of local optima to reach the global one. They are supposed not to get stuck in local optima. In other words, because heuristic algorithms perform a wide random search, the chance of being trapped in local optima is deeply decreased.[17]
Metaheuristics based on decomposition techniques have also been proposed for tackling hard combinatorial problems of large size.[18]
[edit] Main contributions





Timeline of main contributions.


Many different metaheuristics are in existence and new variants are continually being proposed. Some of the most significant contributions to the field are:

1952: Robbins and Monro work on stochastic optimization methods.[19]
1952: Fermi and Metropolis develop an early form of pattern search as described belatedly by Davidon.[20]
1954: Barricelli carry out the first simulations of the evolution process and use them on general optimization problems.[21]
1963: Rastrigin proposes random search.[22]
1965: Matyas proposes random optimization.[23]
1965: Rechenberg proposes evolution strategy.[24]|
1965: Nelder and Mead propose a simplex heuristic, which was shown by Powell to converge to non-stationary points on some problems.[25]
1966: Fogel et al. propose evolutionary programming.[26]
1970: Hastings proposes the Metropolis-Hastings algorithm.[27]
1970: Cavicchio proposes adaptation of control parameters for an optimizer.[28]
1970: Kernighan and Lin propose a graph partitioning method, related to variable-depth search and prohibition-based (tabu) search.[29]
1975: Holland proposes the genetic algorithm.[9]
1977: Glover proposes Scatter Search.[11]
1978: Mercer and Sampson propose a metaplan for tuning an optimizer's parameters by using another optimizer.[30]
1980: Smith describes genetic programming.[31]
1983: Kirkpatrick et al. propose simulated annealing.[8]
1986: Glover proposes tabu search, first mention of the term metaheuristic.[12]
1986: Farmer et al. work on the artificial immune system.[32]
1986: Grefenstette proposes another early form of metaplan for tuning an optimizer's parameters by using another optimizer.[33]
1988: First conference on genetic algorithms is organized at the University of Illinois at Urbana-Champaign.
1988: Koza registers his first patent on genetic programming.[34][35]
1989: Goldberg publishes a well known book on genetic algorithms.[1]
1989: Evolver, the first optimization software using the genetic algorithm.
1989: Moscato proposes the memetic algorithm.[36]
1991: Interactive evolutionary computation.
1992: Dorigo proposes the ant colony algorithm.[10]
1993: The journal, Evolutionary Computation, begins publication by the Massachusetts Institute of Technology.
1993: Fonseca and Fleming propose MOGA for multiobjective optimization.[37]
1994: Battiti and Tecchiolli propose Reactive Search Optimization(RSO) principles for the online self-tuning of heuristics.[38][39]
1994: Srinivas and Deb propose NSGA for multiobjective optimization.[40]
1995: Kennedy and Eberhart propose particle swarm optimization.[13]
1995: Wolpert and Macready prove the no free lunch theorems.[41][42]
1996: Mhlenbein and Paa work on the estimation of distribution algorithm.[43]
1996: Hansen and Ostermeier propose CMA-ES.[44]
1997: Storn and Price propose differential evolution.[14]
1997: Rubinstein proposes the cross entropy method.[45]
1999: Taillard and Voss propose POPMUSIC.[18]
2001: Geem et al. propose harmony search.[46]
2001: Hanseth and Aanestad introduce the Bootstrap Algorithm.[47]
2002: Deb et al. propose NSGA-II for multiobjective optimization.[48]
2004: Nakrani and Tovey propose bees optimization.[49]
2005: Krishnanand and Ghose propose Glowworm swarm optimization.[50][51][52]
2005: Karaboga proposes Artificial Bee Colony Algorithm (ABC).[53]
2005: Duc-Truong Pham et al. proposed Bees Algorithms (BA)
2006: Haddad et al. introduces honey-bee mating optimization.[54]
2007: Hamed Shah-Hosseini introduces Intelligent Water Drops.
2007: Atashpaz-Gargari introduces Imperialist competitive algorithm.
2008: Wierstra et al. propose natural evolution strategies based on the natural gradient.[55]
2008: Yang introduces firefly algorithm.[56]
2008: Mucherino and Seref propose the Monkey Search
2009: Ali Husseinzadeh Kashan introduced the League Championship Algorithm (LCA).[57][58][59]
2009: Yang and Deb introduce cuckoo search.[60]
2009: Rashedi proposes Gravitational Search Algorithm
2009: Josue Cuevas et al. propose Virus Optimization Algorithm
2010: Yang develops bat algorithm.[61]
2011: Hamed Shah-Hosseini proposes the Galaxy-based Search Algorithm.[62]
2011: Tamura and Yasuda propose spiral optimization.[63][64]
2012: Civicioglu proposes Differential Search Algorithm. Matlab code-link has been provided in ivicioglu, P.,(2012).[65]

[edit] Criticism
Mathematical analyses of metaheuristics have been presented in the literature, see e.g. Holland's schema theorem[9] for the genetic algorithm, Rechenberg's work[15] on evolution strategies, the work by Trelea,[66] amongst others, for analysis of particle swarm optimization, and Zaharie[67] for analysis of differential evolution. These analyses make a number of assumptions in regard to the optimizer variants and the simplicity of the optimization problems which limit their validity in real-world optimization scenarios. Performance and convergence aspects of metaheuristic optimizers are therefore often demonstrated empirically in the research literature. This has been criticized in the no free lunch set of theorems by Wolpert and Macready,[42] which, among other things, prove that all optimizers perform equally well when averaged over all problems. The practical relevance of the no free lunch theorems however is minor, because they will generally not hold on the collection of problems a practitioner is facing.
For the practitioner, the most relevant issue is that metaheuristics are not guaranteed to find the optimum or even a satisfactory near-optimal solution. All metaheuristics will eventually encounter problems on which they perform poorly and the practitioner must gain experience in which optimizers work well on different classes of problems. Sometimes, an algorithm will converge well in theory, but in practice, it may take a significant number of iterations/generations before optimal or near-optimal solutions can be reached.
[edit] See also
Metaheuristic methods are, generally speaking, sub-fields of:

Optimization algorithms
Heuristic
Stochastic search

Sub-fields of metaheuristics include:

Local search
Evolutionary computing which includes, amongst others:

Evolutionary algorithms
Swarm Intelligence



Other fields of interest:

Reactive Search Optimization
Meta-optimization
Matheuristics
Hyper-heuristics

[edit] References


^ a b Goldberg, D.E. (1989). Genetic Algorithms in Search, Optimization and Machine Learning. Kluwer Academic Publishers. ISBN0-201-15767-5.
^ Luke, S. (2009). Essentials of metaheuristics. http://cs.gmu.edu/~sean/book/metaheuristics/.
^ Talbi, E-G. (2009). Metaheuristics: from design to implementation. Wiley. ISBN0-470-27858-7.
^ Glover, F.; Kochenberger, G.A. (2003). Handbook of metaheuristics. 57. Springer, International Series in Operations Research & Management Science. ISBN978-1-4020-7263-5.
^ Mucherino, A.; Seref, O. (2009). "Modeling and Solving Real Life Global Optimization Problems with Meta-Heuristic Methods". Advances in Modeling Agricultural Systems 25: 117. doi:10.1007/978-0-387-75181-8_19.
^ Blum, C.; Roli, A. (2003). Metaheuristics in combinatorial optimization: Overview and conceptual comparison. 35. ACM Computing Surveys. pp.268308.
^ Battiti, Roberto; Mauro Brunato; Franco Mascia (2008). Reactive Search and Intelligent Optimization. Springer Verlag. ISBN978-0-387-09623-0.
^ a b Kirkpatrick, S.; Gelatt Jr., C.D.; Vecchi, M.P. (1983). "Optimization by Simulated Annealing". Science 220 (4598): 671680. doi:10.1126/science.220.4598.671. PMID17813860.
^ a b c Holland, J.H. (1975). Adaptation in Natural and Artificial Systems. University of Michigan Press. ISBN0-262-08213-6.
^ a b Dorigo, M. (1992). Optimization, Learning and Natural Algorithms (Phd Thesis). Politecnico di Milano, Italie.
^ a b Glover, Fred (1977). "Heuristics for Integer programming Using Surrogate Constraints". Decision Sciences 8 (1): 156166.
^ a b Glover, F. (1986). "Future Paths for Integer Programming and Links to Artificial Intelligence". Computers and Operations Research 13 (5): 533549. doi:10.1016/0305-0548(86)90048-1.
^ a b Kennedy, J.; Eberhart, R. (1995). "Particle Swarm Optimization". Proceedings of IEEE International Conference on Neural Networks. IV. pp.19421948.
^ a b Storn, R.; Price, K. (1997). "Differential evolution - a simple and efficient heuristic for global optimization over continuous spaces". Journal of Global Optimization 11 (4): 341359. doi:10.1023/A:1008202821328.
^ a b Rechenberg, I. (1971). Evolutionsstrategie  Optimierung technischer Systeme nach Prinzipien der biologischen Evolution (PhD Thesis). ISBN3-7728-0373-3.
^ Schwefel, H-P. (1974). Numerische Optimierung von Computer-Modellen (PhD Thesis).
^ Talebi, Arash; Molaei, Sheikh (17). "M.A., M.J.". Proceeding of 2010 2nd Ieee International Conference on Information and Financial Engineering: 430-437. doi:10.1109/icife.2010.5609394.
^ a b Taillard, Eric; Voss, Stephan (1999). "POPMUSIC: Partial Optimization Metaheuristic Under Special Intensification Conditions". Technical Report (Institute for Computer Sciences, heig-vd, Yverdon). http://mistic.heig-vd.ch/taillard/articles.dir/popmusic.pdf.
^ Robbins, H.; Monro, S. (1951). "A Stochastic Approximation Method". Annals of Mathematical Statistics 22 (3): 400407. doi:10.1214/aoms/1177729586.
^ Davidon, W.C. (1991). "Variable metric method for minimization". SIAM Journal on Optimization 1 (1): 117. doi:10.1137/0801001.
^ Barricelli, N.A. (1954). "Esempi numerici di processi di evoluzione". Methodos: 4568.
^ Rastrigin, L.A. (1963). "The convergence of the random search method in the extremal control of a many parameter system". Automation and Remote Control 24 (10): 13371342.
^ Matyas, J. (1965). "Random optimization". Automation and Remote Control 26 (2): 246253.
^ Rechenberg, I. (1965). Cybernetic Solution Path of an Experimental Problem. Royal Aircraft Establishment Library Translation.
^ Nelder, J.A.; Mead, R. (1965). "A simplex method for function minimization". Computer Journal 7: 308313. doi:10.1093/comjnl/7.4.308.
^ Fogel, L.; Owens, A.J.; Walsh, M.J. (1966). Artificial Intelligence through Simulated Evolution. Wiley. ISBN0-471-26516-0.
^ Hastings, W.K. (1970). "Monte Carlo Sampling Methods Using Markov Chains and Their Applications". Biometrika 57 (1): 97109. doi:10.1093/biomet/57.1.97.
^ Cavicchio, D.J. (1970). "Adaptive search using simulated evolution". Technical Report (University of Michigan, Computer and Communication Sciences Department). hdl:2027.42/4042.
^ Kernighan, B.W.;Lin, S. (1970). "An efficient heuristic procedure for partitioning graphs". Bell System Technical Journal 49 (2): 291307.
^ Mercer, R.E.; Sampson, J.R. (1978). "Adaptive search using a reproductive metaplan". Kybernetes (The International Journal of Systems and Cybernetics) 7 (3): 215228. doi:10.1108/eb005486.
^ Smith, S.F. (1980). A Learning System Based on Genetic Adaptive Algorithms (PhD Thesis). University of Pittsburgh.
^ Farmer, J.D.; Packard, N.; Perelson, A. (1986). "The immune system, adaptation and machine learning". Physica D 22 (1-3): 187204. doi:10.1016/0167-2789(86)90240-X.
^ Grefenstette, J.J. (1986). "Optimization of control parameters for genetic algorithms". IEEE Transactions Systems, Man, and Cybernetics 16 (1): 122128. doi:10.1109/TSMC.1986.289288.
^ US 4935877
^ Koza, J.R. (1992). Genetic Programming: on the programming of computers by means of natural selection. MIT Press. ISBN0-262-11170-5.
^ Moscato, P. (1989). "On Evolution, Search, Optimization, Genetic Algorithms and Martial Arts: Towards Memetic Algorithms". Technical Report C3P 826 (Caltech Concurrent Computation Program).
^ Fonseca, C.M.; Fleming, P.J. (1993). "Genetic Algorithms for Multiobjective Optimization: formulation, discussion and generalization". Proceedings of the 5th International Conference on Genetic Algorithms (Urbana-Champaign, IL, USA): 416423.
^ Battiti, Roberto; Gianpietro Tecchiolli (1994). "The reactive tabu search." (PDF). ORSA Journal on Computing 6 (2): 126140. http://rtm.science.unitn.it/~battiti/archive/TheReactiveTabuSearch.PDF.
^ Battiti, Roberto; Gianpietro Tecchiolli (1995). "Training neural nets with the reactive tabu search." (PDF). IEEE Transactions on Neural Networks 6 (5): 11851200. doi:10.1109/72.410361. PMID18263407. http://rtm.science.unitn.it/~battiti/archive/rts-nn.pdf.
^ Srinivas, N.; Deb, K. (1994). "Multiobjective Optimization Using Nondominated Sorting in Genetic Algorithms". Evolutionary Computation 2 (3): 221248. doi:10.1162/evco.1994.2.3.221.
^ Wolpert, D.H.; Macready, W.G. (1995). "No free lunch theorems for search". Technical Report SFI-TR-95-02-010 (Santa Fe Institute).
^ a b Wolpert, D.H.; Macready, W.G. (1997). "No free lunch theorems for optimization". IEEE Transactions on Evolutionary Computation 1 (1): 6782. doi:10.1109/4235.585893.
^ Mlhenbein, H.; Paa, G. (1996). "From recombination of genes to the estimation of distribution I. Binary parameters". Lectures Notes in Computer Science: Parallel Problem Solving from Nature (PPSN IV) 1411: 178187.
^ Hansen; Ostermeier (1996). "Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation.". Proceedings of the IEEE International Conference on Evolutionary Computation: 312317.
^ Rubinstein, R.Y. (1997). "Optimization of Computer simulation Models with Rare Events". European Journal of Operations Research 99 (1): 89112. doi:10.1016/S0377-2217(96)00385-2.
^ Geem, Z.W.; Kim, J.H.; Loganathan, G.V. (2001). "A new heuristic optimization algorithm: harmony search". Simulation 76 (2): 6068. doi:10.1177/003754970107600201.
^ Hanseth, O.; Aanestad, M. (2001). "Bootstrapping networks, communities and infrastructures. On the evolution of ICT solutions in heath care". First International Conference on Information Technology in Health Care (ITHC, September 67, 2001). Erasmus University, Rotterdam, The Netherlands.
^ Deb, K.; Pratap, A.; Agarwal, S.; Meyarivan, T. (2002). "A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II". IEEE Transactions on Evolutionary Computation 6 (2): 182197. doi:10.1109/4235.996017.
^ Nakrani, S.; Tovey, S. (2004). "On honey bees and dynamic server allocation in Internet hosting centers". Adaptive Behavior 12.
^ Krishnanand, K.; Ghose, D. (2009). "Glowworm swarm optimization for simultaneous capture of multiple local optima of multimodal functions". Swarm Intelligence 3 (2): 87124. doi:10.1007/s11721-008-0021-5.
^ Krishnanand, K.; Ghose, D. (2006). "Glowworm swarm based optimization algorithm for multimodal functions with collective robotics applications". Multiagent and Grid Systems 2: 209222.
^ Krishnanand, K.; Ghose, D. (2005). "Detection of multiple source locations using a glowworm metaphor with applications to collective robotics". Proceedings of IEEE Swarm Intelligence Symposium. pp.8491.
^ Karaboga, D. (2005). "An Idea Based On Honey Bee Swarm For Numerical Numerical Optimization". Technical Report-TR06 (Erciyes University, Engineering Faculty, Computer Engineering Department).
^ Haddad, O. B. et al.; Afshar, Abbas; Mario, Miguel A. (2006). "Honey-bees mating optimization (HBMO) algorithm: a new heuristic approach for water resources optimization". Water Resources Management 20 (5): 661680. doi:10.1007/s11269-005-9001-3.
^ Wierstra, D.; Schaul, T.; Peters, J.; Schmidhuber, J. (2008). "Natural Evolution Strategies". Proceedings of the IEEE Congress on Evolutionary Computation (CEC). Hong Kong, China. pp.3381-3387. http://www.idsia.ch/~tom/publications/nes.pdf.
^ Yang, X.-S. (2008). Nature-Inspired Metaheuristic Algorithms. Luniver Press. ISBN1-905986-28-9.
^ Husseinzadeh Kashan, A. (2009). "League Championship Algorithm: a new algorithm for numerical function optimization". Proceedings of IEEE International Conference of Soft Computing and Pattern Recognition (SoCPaR 2009). pp.43-48.
^ Husseinzadeh Kashan, A. (2010). "A new algorithm for constrained optimization inspired by the sport league championships". Proceedings of IEEE World Congress on Computational Intelligence (WCCI 2010). pp.487-494.
^ Husseinzadeh Kashan, A. (2011). "An Efficient Algorithm for Constrained Global Optimization and Application to Mechanical Engineering Design: League Championship Algorithm (LCA)". Computer Aided Design 43 (12): 17691792. doi:10.1016/j.cad.2011.07.003.
^ Yang, X.-S.; Deb, S. (2009). Cuckoo search via Levy flights, in: World Congress on Nature & Biologically Inspired Computing (NaBIC 2009).. IEEE Publication, USA. pp.210214.
^ Yang, X.-S. (2010). A New Metaheuristic Bat-Inspired Algorithm http://arxiv.org/abs/1004.4170, in: Nature Inspired Cooperative Strategies for Optimization (NISCO 2010) (Eds. J. R. Gonzalez et al.), Studies in Computational Intelligence,. Springer, Berlin. pp.65-74.
^ Shah-Hosseini, Hamed (2011). "Principal components analysis by the galaxy-based search algorithm: a novel metaheuristic for continuous optimisation.". International Journal of Computational Science and Engineering 6 (1/2): 132140. doi:10.1504/IJCSE.2011.041221.
^ Tamura, K.; Yasuda, K. (2011). "Primary Study of Spiral Dynamics Inspired Optimization". IEEJ Transactions on Electrical and Electronic Engineering 6 (S1): S98S100. doi:10.1002/tee.20628. http://onlinelibrary.wiley.com/doi/10.1002/tee.20628/abstract.
^ Tamura, K.; Yasuda, K. (2011). "Spiral Dynamics Inspired Optimization". Journal of Advanced Computational Intelligence and Intelligent Informatics 15 (8): 11161122. http://www.fujipress.jp/finder/xslt.php?mode=present&inputfile=JACII001500080020.xml.
^ Civicioglu, P. (2012). "Transforming geocentric cartesian coordinates to geodetic coordinates by using differential search algorithm". Computers & Geosciences 46: 229247. doi:10.1016/j.cageo.2011.12.011.
^ Trelea, I.C. (2003). "The Particle Swarm Optimization Algorithm: convergence analysis and parameter selection". Information Processing Letters 85 (6): 317325. doi:10.1016/S0020-0190(02)00447-7.
^ Zaharie, D. (2002). "Critical values for the control parameters of differential evolution algorithms". Proceedings of the 8th International Conference on Soft Computing (MENDEL). Brno, Czech Republic. pp.6267.


[edit] External links

EU/ME forum for researchers in the field.
MetaHeur - Excel application to metaheuristic methods









v
t
e


Metaheuristics for combinatorial problems









Genetic algorithm
Simulated annealing
Ant colony optimization
Local search
Genetic programming
















v
t
e


Metaheuristics for real-valued problems









Genetic algorithm
Evolutionary programming
Particle swarm optimization
Differential evolution
CMA-ES
Local search
















v
t
e


Major subfields of optimization









Convex programming
Integer programming
Quadratic programming
Nonlinear programming
Stochastic programming
Robust optimization
Combinatorial optimization
Infinite-dimensional optimization
Metaheuristics
Constraint satisfaction
Multiobjective optimization








 
NewPP limit report
Preprocessor visited node count: 39560/1000000
Preprocessor generated node count: 45183/1500000
Post-expand include size: 182248/2048000 bytes
Template argument size: 70361/2048000 bytes
Highest expansion depth: 15/40
Expensive parser function count: 0/500

 Saved in parser cache with key enwiki:pcache:idhash:774458-0!*!0!!en!4!* and timestamp 20130106110834 
  /bodycontent 
 printfooter 

				Retrieved from "http://en.wikipedia.org/w/index.php?title=Metaheuristic&oldid=531601640"				
 /printfooter 
 catlinks 
Categories: Applied mathematicsOperations researchMathematical optimizationHeuristics  /catlinks 

 debughtml 
 /debughtml 

 /bodyContent 

 