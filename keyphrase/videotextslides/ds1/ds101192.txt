Row 1::Height 2::asymptotic analysis of running time
Row 2::Height 1::use o notation to express number of primitive
Row 3::Height 1::operations executed as function of input size
Row 4::Height 1::comparing asymptotic running times
Row 5::Height 3::an algorithm that runs in o(n) time is better
Row 6::Height 1::than one that runs in o(n 2) time
Row 7::Height 1::similarly o log n is better than o n
Row 8::Height 1::hierarchy of functions log
Row 9::Height 1::caution beware of very large constant factors
Row 10::Height 3::an algorithm running in time is still
Row 11::Height 1::but might be less efficient than one running
Row 12::Height 1::in time 2n which is
