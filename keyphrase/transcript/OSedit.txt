However, the cost of this compaction is time and it can be particularly severe for
large hard disks that use contiguous allocation, where compacting all the space
11.4 473
may take hours and may be necessary on a weekly basis. Some systems require
that this function be done with the file system unmounted. During
this normal system operation generally cannot be permitted, so
such compaction is avoided at all costs on production machines. Most modern
systems that need defragmentation can perform it during normal
system operations, but the performance penalty can be substantial.
Another problem with contiguous allocation is determining how much
space is needed for a file. When the file is created, the total amount of space
it will need must be found and allocated. How does the creator (program or
person) know the size of the file to be created  In some cases, this detennination
may be fairly simple (copying an existing file, for example); in general, however,
the size of an output file may be difficult to estimate.
If we allocate too little space to a file, we may find that the file cannot
be extended. Especially with a best-fit allocation strategy, the space on both
sides of the file may be in use. Hence, we cannot make the file larger in place.
Two possibilities then exist. First, the user program can be terminated, with
an appropriate error message. The user must then allocate more space and
run the program again. These repeated runs may be costly. To prevent them,
the user will normally overestimate the amount of space needed, resulting in
considerable wasted space. The other possibility is to find a larger hole, copy
the contents of the file to the new space, and release the previous space. This
series of actions can be repeated as long as space exists, although it can be time
consuming. However, the user need never be informed explicitly about what
is happening; the system continues despite the problem, although more and
more slowly.
Even if the total amount of space needed for a file is known in advance,
preallocation may be inefficient. A file that will grow slowly over a long period
(months or years) must be allocated enough space for its final size, even though
much of that space will be unused for a long time. The file therefore has a large
amount of internal fragmentation.
To minimize these drawbacks, some operating systems use a modified
contiguous-allocation scheme. Here, a contiguous chunk of space is allocated
initially; then, if that amount proves not to be large enough, another chunk of
contiguous space, known as an is added. The location of a file's blocks
is then recorded as a location and a block count, plus a link to the first block
of the next extent. On some systems, the owner of the file can set the extent
size, but this setting results in inefficiencies if the owner is incorrect. Internal
fragm.entation can still be a problem if the extents are too large, and external
fragmentation can become a problem as extents of varying sizes are allocated
and deallocated. The commercial Veritas file system uses extents to optimize
performance. It is a high-performance replacement for the standard UNIX UFS.
11.4.2 Linked Allocation
solves all problems of contiguous allocation. With linked
allocation, each file is a linked list of disk blocks; the disk blocks may be
scattered anywhere on the disk. The directory contains a pointer to the first
and last blocks of the file. For example, a file of five blocks might start at block
9 and continue at block 16, then block 1, then block 10, and finally block 25
(Figure 11.6). Each block contains a pointer to the next block. These pointers
474 Chapter 11
directory
12
16 170180190
20021~_20_.~23_0-4------------~
2402Sc.51:260270
280290300310
Figure i 1.6 Linked allocation of disk space.
are not made available to the user. Thus, if each block is 512 bytes in size, and
a disk address (the poileter) requires 4 bytes, then the user sees blocks of 508
bytes.
To create a new file, we simply create a new entry ile the directory. With
linked allocation, each directory entry has a pointer to the first disk block of the
file. This pointer is initialized to nil (the end-of-list pointer value) to signify an
empty file. The size field is also set to 0. A write to the file causes the free-space
management system to filed a free block, and this new block is written to
and is linked to the end of the file. To read a file, we simply read blocks by
following the pointers from block to block. There is no external fragmentation
with linked allocation, and any free block on the free-space list can be used to
satisfy a request. The size of a file need not be declared when that file is created.
A file can continue to grow as long as free blocks are available. Consequently,
it is never necessary to compact disk space.
Linked allocation does have disadvantages, however. The major problem
is that it can be used effectively only for sequential-access files. To filed the
ith block of a file, we must start at the begirueing of that file and follow the
pointers rnetil we get to the ith block. Each access to a pointer requires a disk
read, and some require a disk seek. Consequently, it is inefficient to support a
direct-access capability for linked-allocation files.
Another disadvantage is the space required for the pointers. If a pointer
requires 4 bytes out of a 512-byte block, then 0.78 percent of the disk is being
used for pointers, rather than for information. Each file requires slightly more
space than it would otherwise.
The usual solution to this problem is to collect blocks into multiples, called
and to allocate clusters rather than blocks. For instance, the file system
may define a cluster as four blocks and operate on the disk only in cluster
units. Pointers then use a much smaller percentage of the file's disk space.
This method allows the logical-to-physical block mapping to remain simple
11.4 475
but improves disk throughput (because fewer disk-head seeks are required)
and decreases the space needed for block allocation and free-list management.
The cost of this approach is an increase in internal fragmentation, because
more space is wasted when a cluster is partially full than when a block is
partially full. Clusters can be used to improve the disk-access time for many
other algorithms as welt so they are used in most file systems.
Yet another problem of linked allocation is reliability. Recall that the files
are linked together by pointers scattered all over the disk, and consider what
would happen if a pointer were lost or damaged. A bug in the operating-system
software or a disk hardware failure might result in picking up the wrong
pointer. This error could in turn result in linking into the free-space list or into
another file. One partial solution is to use doubly linked lists, and another is
to store the file name and relative block number in each block; however, these
schemes require even more overhead for each file.
An important variation on linked allocation is the use of a
(FAT!. This simple but efficient method of disk-space allocation is used
by the MS-DOS and OS/2 operating systems. A section of disk at the beginning
of each volume is set aside to contain the table. The table has one entry for
each disk block and is indexed by block number. The FAT is used in much the
same way as a linked list. The directory entry contains the block number of the
first block of the file. The table entry indexed by that block number contains
the block number of the next block in the file. This chain continues until it
reaches the last block, which has a special end-of-file value as the table entry.
An unused block is indicated by a table value of 0. Allocating a new block to
a file is a simple matter of finding the first 0-valued table entry and replacing
the previous end-of-file value with the address of the new block. The 0 is then
replaced with the end-of-file value. An illustrative example is the FAT structure
shown in Figure 11.7 for a file consisting of disk blocks 217, 618, and 339.
directory entry
name start block
0
217 618
339 -
618 339
number of disk blocks -1
FAT
Figure 11.7 File-allocation table.
476 Chapter 11
The FAT allocation scheme can result in a significant number of disk head
seeks, unless the FAT is cached. The disk head must move to the start of the
volume to read the FAT and find the location of the block in question, then
move to the location of the block itself. In the worst case, both moves occur for
each of the blocks. A benefit is that random-access time is improved, because
the disk head can find the location of any block by reading the information in
the FAT.
11.4.3 Indexed Allocation
Linked allocation solves the external-fragmentation and size-declaration problems
of contiguous allocation. However, in the absence of a FAT, linked
allocation cannot support efficient direct access, since the pointers to the blocks
are scattered with the blocks themselves all over the disk and must be retrieved
in order. solves this problem by bringil1.g all the pointers
together into one location: the blo;ct:.
Each file has its own index block, which is an array of disk-block addresses.
The i th entry in the index block points to the i 111 block of the file. The directory
contains the address of the index block (Figure 11.8). To find and read the i 1Jz
block, we use the pointer in the i 1lz index-block entry. This scheme is similar to
the paging scheme described il1. Section 8.4.
When the file is created, all pointers in the index block are set to nil. When
the ith block is first written, a block is obtained from the free-space manage1~
and its address is put in the ith index-block entry.
Indexed allocation supports direct access, without suffering from external
fragmentation, because any free block on the disk can satisfy a request for more
space. Indexed allocation does suffer from wasted space, however. The pointer
overhead of the index block is generally greater than the pointer overhead of
linked allocation. Consider a common case in which we have a file of only one
or two blocks. With linked allocation, we lose the space of only one pointer per
directory
file
jeep
16
Figure 11.8 Indexed allocation of disk space.
11.4 Allocation Methods 477
block. With indexed allocation, an entire index block must be allocated, even
if only one or two pointers will be non-nil.
This point raises the question of how large the index block should be. Every
file must have an index block, so we want the index block to be as small as
possible. If the index block is too small, however, it will not be able to hold
enough pointers for a large file, and a mechanism will have to be available to
deal with this issue. Mechanisms for this purpose include the following:
c Linked scheme. An index block is normally one disk block. Thus, it can
be read and written directly by itself. To allow for large files, we can link
together several index blocks. For example, an index block might contain a
small header giving the name of the file and a set of the first 100 disk-block
addresses. The next address (the last word in the index block) is nil (for a
small file) or is a pointer to another index block (for a large file).
  Multilevel index. A variant of linked representation uses a first-level index
block to point to a set of second-level index blocks, which in tum point to
the file blocks. To access a block, the operating system uses the first-level
index to find a second-level index block and then uses that block to find the
desired data block. This approach could be continued to a third or fourth
level, depending on the desired maximum file size. With 4,096-byte blocks,
we could store 1,024 four-byte pointers in an index block. Two levels of
indexes allow 1,048,576 data blocks and a file size of up to 4GB.
  Combined scheme. Another alternative, used in the UFS, is to keep the
first, say, 15 pointers of the index block in the file's inode. The first 12
of these pointers point to direct blocks; that is, they contain addresses of
blocks that contain data of the file. Thus, the data for small files (of no more
than 12 blocks) do not need a separate index block. If the block size is 4 KB,
then up to 48 KB of data can be accessed directly. The next three pointers
point to indirect blocks. The first points to a single indirect block, which
is an index block containing not data but the addresses of blocks that do
contain data. The second points to a double indirect block, which contains
the address of a block that contains the addresses of blocks that contain
pointers to the actual data blocks. The last pointer contains the address of a
triple indirect block. Under this method, the number of blocks that can be
allocated to a file exceeds the amount of space addressable by the four-byte
file pointers used by many operating systems. A 32-bit file pointer reaches
only 232 bytes, or 4GB. Many UNIX implementations, including Solaris and
IBM's AIX, now support up to 64-bit file pointers. Pointers of this size allow
files and file systems to be terabytes in size. A UNIX inode is shown in
Figure 11.9.
Indexed-allocation schemes suffer from some of the same performance
problems as does linked allocation. Specifically, the index blocks can be cached
in memory, but the data blocks may be spread all over a volume.
11.4.4 Performance
The allocation methods that we have discussed vary in their storage efficiency
and data-block access times. Both are important criteria in selecting the proper
method or methods for an operating system to implement.
478 Chapter 11 Implementing File Systems
Figure 11.9 The UNIX inode.
Before selecting an allocation method, we need to determine how the
systems will be used. A system with mostly sequential access should not use
the same method as a system with mostly random access.
For any type of access, contiguous allocation requires only one access to get
a disk block. Since we can easily keep the initial address of the file in memory,
we can calculate immediately the disk address of the ith block (or the next
block) and read it directly.
For linked allocation, we can also keep the address of the next block in
memory and read it directly. This method is fine for sequential access; for
direct access, however, an access to the ith block might require i disk reads. This
problem indicates why linked allocation should not be used for an application
requiring direct access.
As a result, some systems support direct-access files by using contiguous
allocation and sequential-access files by using linked allocation. For these
systems, the type of access to be made must be declared when the file is
created. A file created for sequential access will be linked and cannot be used
for direct access. A file created for direct access will be contiguous and can
support both direct access and sequential access, but its maximum length must
be declared when it is created. In this case, the operating system must have
appropriate data structures and algorithms to support both allocation methods.
Files can be converted from one type to another by the creation of a new file of
the desired type, into which the contents of the old file are copied. The old file
may then be deleted and the new file renamed.
Indexed allocation is more complex. If the index block is already in memory,
then the access can be made directly. However, keeping the index block in
memory requires considerable space. If this memory space is not available,
then we may have to read first the index block and then the desired data
block. For a two-level index, two index-block reads might be necessary. For an
11.5
11.5 479
extremely large file, accessing a block near the end of the file would require
reading in all the index blocks before the needed data block finally could
be read. Thus, the performance of indexed allocation depends on the index
structure, on the size of the file, and on the position of the block desired.
Some systems combine contiguous allocation with indexed allocation by
using contiguous allocation for small files (up to three or four blocks) and
automatically switching to an indexed allocation if the file grows large. Since
most files are small, and contiguous allocation is efficient for small files, average
performance can be quite good.
For instance, the version of the UNIX operating system from Sun Microsystems
was changed in 1991 to improve performance in the file-system allocation
algorithm. The performance measurements indicated that the maximum disk
throughput on a typical workstation (a 12-MIPS SPARCstation1) took 50 percent
of the CPU and produced a disk bandwidth of only 1.5 ME per second. To
improve performance, Sun made changes to allocate space in clusters of 56 KB
whenever possible (56 KB was the maximum size of a DMA transfer on Sun
systems at that time). This allocation reduced external fragmentation, and thus
seek and latency times. In addition, the disk-reading routines were optimized
to read in these large clusters. The inode structure was left unchanged. As a
result of these changes, plus the use of read-ahead and free-behind (discussed
in Section 11.6.2), 25 percent less CPU was used, and throughput substantially
improved.
Many other optimizations are in use. Given the disparity between CPU
speed and disk speed, it is not unreasonable to add thousands of extra
instructions to the operating system to save just a few disk-head movements.
Furthermore, this disparity is increasing over time, to the point where hundreds
of thousands of instructions reasonably could be used to optimize head
movements.
Since disk space is limited, we need to reuse the space from deleted files for new
files, if possible. (Write-once optical disks only allow one write to any given
sector, and thus such reuse is not physically possible.) To keep track of free disk
space, the system maintains a The free-space list records all free
disk blocks-those not allocated to some file or directory. To create a file, we
search the free-space list for the required amount of space and allocate that
space to the new file. This space is then removed from the free-space list. When
a file is deleted, its disk space is added to the free-space list. The free-space list,
despite its name, might not be implemented as a list, as we discuss next.
11.5.1 Bit Vector
Frequently, the free-space list is implemented as a or Each
block is represented by 1 bit. If the block is free, the bit is 1; if the block is
allocated, the bit is 0.
For example, consider a disk where blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17,
18, 25, 26, and 27 are free and the rest of the blocks are allocated. The free-space
bit map would be
480 Chapter 11
001111001111110001100000011100000 ...
The main advantage of this approach is its relative simplicity and its
efficiency in finding the first free block or n consecutive free blocks on the
disk. Indeed, many computers supply bit-manipulation instructions that can
be used effectively for that purpose. For example, the Intel family starting with
the 80386 and the Motorola family starting with the 68020 have instructions
that return the offset in a word of the first bit with the value 1 (these processors
have powered PCs and Macintosh systems, respectively). One technique for
finding the first free block on a system that uses a bit-vector to allocate disk
space is to sequentially check each word in the bit map to see whether that
value is not 0, since a 0-valued word contains only 0 bits and represents a set
of allocated blocks. The first non-0 word is scanned for the first 1 bit, which is
the location of the first free block. The calculation of the block number is
(number of bits per word) x (number of 0-value words) +offset of first 1 bit.
Again, we see hardware features driving software functionality. Unfortunately,
bit vectors are inefficient unless the entire vector is kept in main
memory (and is written to disk occasionally for recovery needs). Keeping it in
main memory is possible for smaller disks but not necessarily for larger ones.
A 1.3-GB disk with 512-byte blocks would need a bit map of over 332 KB to
track its free blocks, although clustering the blocks in groups of four reduces
this number to around 83 KB per disk. A 1-TB disk with 4-KB blocks requires 32
MB to store its bit map. Given that disk size constantly increases, the problem
with bit vectors will continue to escalate. A 1-PB file system would take a 32-GB
bitmap just to manage its free space.
11.5.2 Linked List
Another approach to free-space management is to link together all the free
disk blocks, keeping a pointer to the first free block in a special location on the
disk and caching it in memory. This first block contains a pointer to the next
free disk block, and so on. Recall our earlier example (Section 11.5.1), in which
blocks 2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 17, 18, 25, 26, and 27 were free and the
rest of the blocks were allocated. In this situation, we would keep a pointer to
block 2 as the first free block. Block 2 would contain a pointer to block 3, which
would point to block 4, which would point to block 5, which would point to
block 8, and so on (Figure 11.10). This scheme is not efficient; to traverse the
list, we must read each block, which requires substantial I/0 time. Fortunately,
however, traversing the free list is not a frequent action. Usually, the operating
system simply needs a free block so that it can allocate that block to a file, so
the first block in the free list is used. The FAT method incorporates free-block
accounting into the allocation data structure. No separate method is needed.
11.5.3 Grouping
A modification of the free-list approach stores the addresses of n free blocks
in the first free block. The first n-1 of these blocks are actually free. The last
block contains the addresses of another n free blocks, and so on. The addresses
11.5 481
Figure 11.10 Linked free-space list on disk.
of a large number of free blocks can now be found quickly, unlike the situation
when the standard linked-list approach is used.
11.5.4 Counting
Another approach takes advantage of the fact that, generally, several contiguous
blocks may be allocated or freed simultaneously, particularly when space is
allocated with the contiguous-allocation algorithm or through clustering. Thus,
rather than keeping a list of n free disk addresses, we can keep the address of
the first free block and the number (n) of free contiguous blocks that follow the
first block. Each entry in the free-space list then consists of a disk address and
a count. Although each entry requires more space than would a simple disk
address, the overall list is shorter, as long as the count is generally greater than
1. Note that this method of tracking free space is similar to the extent method
of allocating blocks. These entries can be stored in a B-tree, rather than a linked
list for efficient lookup, insertion, and deletion.
11.5.5 Space Maps
Sun's ZFS file system was designed to encompass huge numbers of files,
directories, and even file systems (in ZFS, we can create file-system hierarchies).
The resulting data structures could have been large and inefficient if they had
not been designed and implemented properly. On these scales, metadata I/0
can have a large performance impact. Conside1~ for example, that if the freespace
list is implemented as a bit map, bit maps must be modified both when
blocks are allocated and when they are freed. Freeing 1GB of data on a 1-TB
disk could cause thousands of blocks of bit maps to be updated, because those
data blocks could be scattered over the entire disk.
482 Chapter 11
11.6
ZFS uses a combination of techniques in its free-space managem.ent
algorithm to control the size of data structures and minimize the I/0 needed
to manage those structures. First, ZFS creates to divide the space
on the device into chucks of manageable size. A given volume may contain
hundreds of metaslabs. Each metaslab has an associated space map. ZFS uses
the counting algorithm to store information about free blocks. Rather than
write count structures to disk, it uses log-structured file- system techniques
to record them. The space map is a log of all block activity (allocatil  g and
freemg), in time order, in countil  g format. When ZFS decides to allocate or
free space from a metaslab, it loads the associated space map into memory
in a balanced-tree structure (for very efficient operation), indexed by offset,
and replays the log into that structure. The in-memory space map is then an
accurate representation of the allocated and free space in the metaslab. ZFS also
condenses the map as much as possible by combining contiguous free blocks
into a sil  gle entry. Finally, the free-space list is updated on disk as part of
the transaction-oriented operations of ZFS. During the collection and sortmg
phase, block requests can still occur, and ZFS satisfies these requests from the
log. In essence, the log plus the balanced tree is the free list.
Now that we have discussed various block-allocation and directorymanagement
options, we can further consider their effect on performance
and efficient disk use. Disks tend to represent a major bottleneck in system
performance, since they are the slowest main computer component. In this
section, we discuss a variety of techniques used to improve the efficiency and
performance of secondary storage.
11.6.1 Efficiency
The efficient use of disk space depends heavily on the disk allocation and
directory algorithms in use. For instance, UNIX inodes are preallocated on a
volume. Even an   empty   disk has a percentage of its space lost to inodes.
However, by preallocating the inodes and spreading them across the volume,
we improve the file system's performance. This improved performance results
from the UNIX allocation and free-space algorithms, which try to keep a file's
data blocks near that file's inode block to reduce seek time.
As another example, let's reconsider the clustermg scheme discussed in
Section 11.4, which aids in file-seek and file-transfer performance at the cost
of internal fragmentation. To reduce this fragmentation, BSD UNIX varies the
cluster size as a file grows. Large clusters are used where they can be filled, and
small clusters are used for small files and the last cluster of a file. This system
is described in Appendix A.
The types of data normally kept in a file's directory (or inode) entry also
require consideration. Commonly, a   last write date   is recorded to supply
information to the user and to determine whether the file needs to be backed
up. Some systems also keep a   last access date,   so that a user can determine
when the file was last read. The result of keeping this information is that,
whenever the file is read, a field in the directory structure must be written
11.6 483
to. That means the block must be read into memory, a section changed, and
the block written back out to disk, because operations on disks occur only in
block (or cluster) chunks. So any time a file is opened for reading, its directory
entry must be read and written as well. This requirement can be inefficient for
frequently accessed files, so we must weigh its benefit against its performance
cost when designing a file system. Generally, every data item associated with a
file needs to be considered for its effect on efficiency and performance.
As an example, consider how efficiency is affected by the size of the pointers
used to access data. Most systems use either 16- or 32-bit pointers throughout
the operating system. These pointer sizes limit the length of a file to either
216 (64 KB) or 232 bytes (4 GB). Some systems implement 64-bit pointers to
increase this limit to 264 bytes, which is a very large number indeed. However,
64-bit pointers take more space to store and in turn make the allocation and
free-space-management methods (linked lists, indexes, and so on) use more
disk space.
One of the difficulties in choosing a pointer size, or indeed any fixed
allocation size within an operating system, is planning for the effects of
changing technology. Consider that the IBM PC XT had a 10-MB hard drive
and an MS-DOS file system that could support only 32 MB. (Each FAT entry
was 12 bits, pointing to an 8-KB cluster.) As disk capacities increased, larger
disks had to be split into 32-MB partitions, because the file system could not
track blocks beyond 32MB. As hard disks with capacities of over 100MB became
common, the disk data structures and algorithms in MS-DOS had to be modified
to allow larger file systems. (Each FAT entry was expanded to 16 bits and later
to 32 bits.) The initial file-system decisions were made for efficiency reasons;
however, with the advent of MS-DOS Version 4, millions of computer users were
inconvenienced when they had to switch to the new, larger file system. Sun's
ZFS file system uses 128-bit pointers, which theoretically should never need
to be extended. (The minimum mass of a device capable of storing 2128 bytes
using atomic-level storage would be about 272 trillion kilograms.)
As another example, consider the evolution of Sun's Solaris operating
system. Originally, many data structures were of fixed length, allocated at
system startup. These structures included the process table and the open-file
table. When the process table became full, no more processes could be created.
When the file table became full, no more files could be opened. The system
would fail to provide services to users. Table sizes could be increased only by
recompiling the kernel and rebooting the system. Since the release of Solaris
2, almost all kernel structures have been allocated dynamically, eliminating
these artificial limits on system performance. Of course, the algorithms that
manipulate these tables are more complicated, and the operating system is a
little slower because it must dynamically allocate and deallocate table entries;
but that price is the usual one for more general functionality.
11.6.2 Performance
Even after the basic file-system algorithms have been selected, we can still
improve performance in several ways. As will be discussed in Chapter 13,
most disk controllers include local memory to form an on-board cache that is
large enough to store entire tracks at a time. Once a seek is performed, the
track is read into the disk cache starting at the sector under the disk head
484 Chapter 11
1/0 using
read( ) and write( )
tile system
Figure 11.11 1/0 without a unified buffer cache.
(reducing latency time). The disk controller then transfers any sector requests
to the operating system. Once blocks make it from the disk controller into main
memory, the operating system may cache the blocks there.
Some systems maintain a separate section of main memory for a
where blocks are kept under the assumption that will be used
again shortly. Other systems cache file data using a The page
cache uses virtual memory techniques to cache file data as pages rather than
as file-system-oriented blocks. Cachii  lg file data using virtual addresses is far
more efficient than caching through physical disk blocks, as accesses interface
with virtual memory rather than the file system. Several systems-including
Solaris, Linux, and Windows NT, 2000, and XP-use caching to cache
both process pages and file data. This is known as
Some versions of UNIX and Linux provide a To
illustrate the benefits of the unified buffer cache, consider the two alternatives
for opening and accessing a file. One approach is to use memory mapping
(Section 9.7); the second is to use the standard system calls read() and
write(). Without a unified buffer cache, we have a situation similar to Figure
11.11. Here, the read() and write() system calls go through the buffer cache.
The memory-mapping call, however, requires using two caches-the page
cache and the buffer cache. A memory mapping proceeds by reading in disk
blocks from the file system and storing them in the buffer cache. Because the
virtual memory system does not interface with the buffer cache, the contents
of the file in the buffer cache must be copied into the page cache. This situation
is known as and requires caching file-system data twice. Not
only does it waste memory but it also wastes significant CPU and I/O cycles due
to the extra data movement within system memory. In addition, inconsistencies
between the two caches can result in corrupt files. In contrast, when a unified
buffer cache is provided, both memory mapping and the read() and write()
system calls use the same page cache. This has the benefit of a voiding double
11.6 485
memory-mapped 1/0
buffer cache
file system
Figure 11.12 1/0 using a unified buffer cache.
caching, and it allows the virtual memory system to manage file-system data.
The unified buffer cache is shown in Figure 11.12.
Regardless of whether we are caching disk blocks or pages (or both), LRU
(Section 9.4.4) seems a reasonable general-purpose algorithm for block or page
replacement. However, the evolution of the Solaris page-caching algorithms
reveals the difficulty in choosil1.g an algorithm. Solaris allows processes and the
page cache to share unused memory. Versions earlier than Solaris 2.5.1 made
no distmction between allocatmg pages to a process and allocating them to
the page cache. As a result, a system performing many I/0 operations used
most of the available memory for caching pages. Because of the high rates
of I/0, the page scanner (Section 9.10.2) reclaimed pages from processesrather
than from the page cache-when free memory ran low. Solaris 2.6 and
Solaris 7 optionally implemented priority paging, in which the page scanner
gives priority to process pages over the page cache. Solaris 8 applied a fixed
limit to process pages and the file-system page cache, preventing either from
forcing the other out of memory. Solaris 9 and 10 again changed the algorithms
to maximize memory use and mmimize thrashing.
Another issue that can affect the performance of I/0 is whether writes to
the file system occur synchronously or asynchronously.
occur in the order in which the disk subsystem receives and the writes
are not buffered. Thus, the calling routine must wait for the data to reach the
disk drive before it can proceed. In an the data are stored
in the cache, and control returns to the caller. Asynchronous writes are done
the majority of the time. However, metadata writes, among others, can be
synchronous. Operating systems frequently include a flag in the open system
call to allow a process to request that writes be performed synchxonously. For
example, databases use this feature for atomic transactions, to assure that data
reach stable storage in the required order.
Some systems optimize their page cache by using different replacement
algorithms, depending on the access type of the file. A file being read or
written sequentially should not have its pages replaced in LRU order, because
the most recently used page will be used last, or perhaps never again. Instead,
sequential access can be optimized by techniques known as free-behind and
read-ahead. removes a page from the buffer as soon as the next
486 Chapter 11
11.7
page is requested. The previous are not likely to be used again and
waste buffer space. With a requested page and several subsequent
pages are read and cached. These pages are likely to be requested after the
current page is processed. Retrieving these data from the disk in one transfer
and caching them saves a considerable ancount of time. One might think that
a track cache on the controller would elincinate the need for read-ahead on a
multiprogrammed system. However, because of the high latency and overhead
involved in making many small transfers from the track cache to main memory,
performing a read-ahead remains beneficial.
The page cache, the file system, and the disk drivers have some interesting
interactions. When data are written to a disk file, the pages are buffered in the
cache, and the disk driver sorts its output queue according to disk address.
These two actions allow the disk driver to minimize disk-head seeks and to
write data at times optimized for disk rotation. Unless synchronous writes are
required, a process writing to disk simply writes into the cache, and the system
asynchronously writes the data to disk when convenient. The user process sees
very fast writes. When data are read from a disk file, the block I/0 system does
some read-ahead; however, writes are much more nearly asynchronous than
are reads. Thus, output to the disk through the file system is often faster than
is input for large transfers, counter to intuition.
Files and directories are kept both in main memory and on disk, and care must
be taken to ensure that a system failure does not result in loss of data or in data
inconsistency. We deal with these issues in this section as well as how a system
can recover from such a failure.
A system crash can cause inconsistencies among on-disk file-system data
structures, such as directory structures, free-block pointers, and free FCB
pointers. Many file systems apply changes to these structures in place. A
typical operation, such as creating a file, can involve many structural changes
within the file system on the disk Directory structures are modified, FCBs are
allocated, data blocks are allocated, and the free counts for all of these blocks
are decreased. These changes can be interrupted by a crash, and inconsistencies
among the structures can result. For example, the free FCB count might indicate
that an FCB had been allocated, but the directory structure might not point to
the FCB. Compounding this problem is the caching that operating systems do
to optimize I/0 performance. Some changes may go directly to disk, while
others may be cached. If the cached changes do not reach disk before a crash
occurs, more corruption is possible.
In addition to crashes, bugs in file-system implementation, disk controllers,
and even user applications can corrupt a file system. File systems have varying
methods to deal with corruption, depending on the file-system data structures
and algorithms. We deal with these issues next.
11.7.1 Consistency Checking
Whatever the cause of corruption, a file system must first detect the problems
and then correct them. For detection, a scan of all the metadata on each file
11.7 487
system can confirm or deny the consistency of the systenL Unfortunately, this
scan can take minutes or hours and should occur every time the system boots.
Alternatively, a file system can record its state within the file-system metadata.
At the start of any metadata change, a status bit is set to indicate that the
metadata is in flux. If all updates to the metadata complete successfully, the file
system can clear that bit. It however, the status bit remains set, a consistency
checker is run.
The systems program such as f s ck in UNIX or
chkdsk in Windows-compares the data in the directory structure with the
data blocks on disk and tries to fix any inconsistencies it finds. The allocation
and free-space-management algorithms dictate what types of problems the
checker can find and how successful it will be in fixing them. For instance, if
linked allocation is used and there is a link from any block to its next block,
then the entire file can be reconstructed from the data blocks, and the directory
structure can be recreated. In contrast the loss of a directory entry on an
indexed allocation system can be disastrous, because the data blocks have no
knowledge of one another. For this reason, UNIX caches directory entries for
reads; but any write that results in space allocation, or other metadata changes,
is done synchronously, before the corresponding data blocks are written. Of
course, problems can still occur if a synchronous write is interrupted by a crash.
11.7.2 Log-Structured File Systems
Computer scientists often fin.d that algorithms and technologies origil1.ally used
in one area are equally useful in other areas. Such is the case with the database
log-based recovery algorithms described in Section 6.9.2. These logging algorithms
have been applied successfully to the of consistency '-.il'C'--  .ll
The resulting implementations are known as
(or file systems.
Note that with the consistency-checking approach discussed in the preceding
section, we essentially allow structures to break and repair them on
recovery. However, there are several problems with this approach. One is that
the inconsistency may be irreparable. The consistency check may not be able to
recover the structures, resulting in loss of files and even entire directories.
Consistency checking can require human intervention to resolve conflicts,
and that is inconvenient if no human is available. The system can remain
unavailable until the human tells it how to proceed. Consistency checking also
takes system and clock time. To check terabytes of data, hours of clock time
may be required.
The solution to this problem is to apply log-based recovery techniques to
file-system metadata updates. Both NTFS and the Veritas file system use this
method, and it is included in recent versions of UFS on Solaris. In fact it is
becoming common on many operating systems.
Fundamentally, all metadata changes are written
Each set of operations for performing a specific task is a
the changes are written to this log, they are considered to be committed,
and the system call can return to the user process, allowing it to continue
execution. Meanwhile, these log entries are replayed across the actual filesystem
structures. As the changes are made, a pointer is updated to indicate
488 Chapter 11
which actions have completed and which are still incomplete. When an entire
committed transaction is completed, it is removed from the log file, which is
actually a circular buffer. A cb:uL;n  writes to the end of its space and
then continues at the beginning, overwriting older values as it goes. We would
not want the buffer to write over data that had not yet been saved, so that
scenario is avoided. The log may be in a separate section of the file system or
even on a separate disk spindle. It is more efficient, but more complex, to have
it under separate read and write heads, thereby decreasing head contention
and seek times.
If the system crashes, the log file will contain zero or more transactions.
Any transactions it contains were not completed to the file system, even though
they were committed by the operating system, so they must now be completed.
The transactions can be executed from the pointer until the work is complete
so that the file-system structures remain consistent The only problem occurs
when a transaction was aborted -that is, was not committed before the system
crashed. Any changes from such a transaction that were applied to the file
system must be undone, again preserving the consistency of the file system.
This recovery is all that is needed after a crash, elimil  ating any problems with
consistency checking.
A side benefit of using logging on disk metadata updates is that those
updates proceed much faster than when they are applied directly to the on-disk
data structures. The reason for this improvement is found in the performance
advantage of sequential I/0 over random I/0. The costly synchronous random
meta data writes are turned into much less costly synchronous sequential writes
to the log-structured file system's loggil  g area. Those changes in turn are
replayed asynchronously via random writes to the appropriate structures.
The overall result is a significant gain in performance of metadata-oriented
operations, such as file creation and deletion.
11.7.3 Other Solutions
Another alternative to consistency checking is employed by Network Appliance's
WAFL file system and Sun's ZFS file system. These systems never
overwrite blocks with new data. Rather, a transaction writes all data and metadata
changes to new blocks. When the transaction is complete, the metadata
structures that pointed to the old versions of these blocks are updated to point
to the new blocks. The file system can then remove the old pointers and the old
blocks and make them available for reuse. If the old pointers and blocks are
kept, a is created; the snapshot is a view of the file system before the
last update took place. This solution should require no consistency checking if
the pointer update is done atomically. WAFL does have a consistency checke1~
however, so some failure scenarios can still cause metadata corruption. (See
11.9 for details of the WAFL file system.)
Sun's ZFS takes an even more im  ovative approach to disk consistency.
It never overwrites blocks, just as is the case with WAFL. However, ZFS goes
further and provides check-summing of all metadata and data blocks. This
solution (when combined with RAID) assures that data are always correct. ZFS
therefore has no consistency checker. (More details on ZFS are found in Section
12.7.6.)
11.7 489
11.7.4 Backup and Restore
Magnetic disks sometimes fail, and care must be taken to ensure that the data
lost in such a failure are not lost forever. To this end, system programs can be
used to data from disk to another storage device, such as a floppy
disk, magnetic tape, optical disk, or other hard disk. Recovery from the loss of
an individual file, or of an entire disk, may then be a matter of the
data from backup.
To minimize the copying needed, we can use information from each file's
directory entry. For instance, if the backup program knows when the last
backup of a file was done, and the file's last write date in the directory indicates
that the file has not changed since that date, then the file does not need to be
copied again. A typical backup schedule may then be as follows:
1. Copy to a backup medium all files from the disk. This is called a
to another medium all files changed since day 1. This is an
Day 3. Copy to another medium all files changed since day 2.
Day N. Copy to another medium all files changed since day N-1. Then
go back to Day 1.
The new cycle can have its backup written over the previous set or onto
a new set of backup media. In this manner, we can restore an entire disk
by starting restores with the full backup and continuing through each of the
incremental backups. Of course, the larger the value of N, the greater the
number of media that must be read for a complete restore. An added advantage
of this backup cycle is that we can restore any file accidentally deleted during
the cycle by retrieving the deleted file from the backup of the previous day. The
length of the cycle is a compromise between the amount of backup medium
needed and the number of days back from which a restore can be done. To
decrease the number of tapes that must be read to do a restore, an option is to
perform a full backup and then each day back up all files that have changed
since the full backup. In this way, a restore can be done via the most recent
incremental backup and the full backup, with no other incremental backups
needed. The trade-off is that more files will be modified each day, so each
successive incremental backup involves more files and more backup media.
A user ncay notice that a particular file is missing or corrupted long after
the damage was done. For this reason, we usually plan to take a full backup
from time to time that will be saved   forever.   It is a good idea to store these
permanent backups far away from the regular backups to protect against
hazard, such as a fire that destroys the computer and all the backups too.
And if the backup cycle reuses media, we must take care not to reuse the
490 Chapter 11
11.8
media too many times-if the media wear out, it might not be possible to
restore any data from the backups.
Network file systems are commonplace. They are typically integrated with
the overall directory structure and interface of the client system. NFS is a
good example of a widely used, well-implemented client-server network file
system. Here, we use it as an example to explore the implementation details of
network file systems.
NFS is both an implementation and a specification of a software system for
accessing remote files across LANs (or even WANs). NFS is part of ONC+, which
most UNIX vendors and some PC operating systems support. The implementation
described here is part of the Solaris operating system, which is a modified
version of UNIX SVR4 running on Sun workstations and other hardware. It uses
either the TCP or UDP /IP protocol (depending on the interconnecting network).
The specification and the implementation are intertwined in our description of
NFS. Whenever detail is needed, we refer to the Sun implementation; whenever
the description is general, it applies to the specification also.
There are multiple versions of NFS, with the latest being Version 4. Here,
we describe Version 3, as that is the one most commonly deployed.
11.8.1 Overview
NFS views a set of interconnected workstations as a set of independent machines
with independent file systems. The goal is to allow some degree of sharing
among these file systems (on explicit request) in a transparent manner. Sharing
is based on a client-server relationship. A machine may be, and often is, both a
client and a server. Sharing is allowed between any pair of machines. To ensure
machine independence, sharing of a remote file system affects only the client
machine and no other machine.
So that a remote directory will be accessible in a transparent manner
from a particular machine-say, from Ml-a client of that machine must
first carry out a mount operation. The semantics of the operation involve
mounting a remote directory over a directory of a local file system. Once the
mount operation is completed, the mounted directory looks like an integral
subtree of the local file system, replacing the subtree descending from the
local directory. The local directory becomes the name of the root of the newly
mounted directory. Specification of the remote directory as an argument for the
mount operation is not done transparently; the location (or host name) of the
remote directory has to be provided. However, fron  l then on, users on machine
Ml can access files in the remote directory in a totally transparent manner.
To illustrate file mounting, consider the file system depicted in Figure 11.13,
where the triangles represent subtrees of directories that are of interest. The
figure shows three independent file systems of machines named U, 51, and
52. At this point, on each machine, only the local files can be accessed. Figure
11.14(a) shows the effects of mounting 81: /usr/shared over U: /usr/local.
This figure depicts the view users on U have of their file system. Notice that
after the mount is complete, they can access any file within the dirl directory
11.8 491
U: S1: S2:
usr usr usr
Figure 11.13 Three independent file systems.
using the prefix /usr /local/ dir1. The original directory /usr /local on that
machine is no longer visible.
Subject to access-rights accreditation, any file system, or any directory
within a file system, can be mounted remotely on top of any local directory.
Diskless workstations can even mount their own roots from servers. Cascading
mounts are also permitted in some NFS implementations. That is, a file system
can be mounted over another file system that is remotely mounted, not local. A
machine is affected by only those mounts that it has itself invoked. Mounting a
remote file system does not give the client access to other file systems that were,
by chance, mounted over the former file system. Thus, the mount mechanism
does not exhibit a transitivity property.
In Figure 11.14(b), we illustrate cascading mounts. The figure shows the
result of mounting S2: /usr /dir2 over U: /usr/local/dir1, which is already
remotely mounted from 51. Users can access files within dir2 on U using the
U: U:
(a) (b)
Figure 11.14 Mounting in NFS. (a) Mounts. (b) Cascading mounts.
492 Chapter 11
prefix /usr/local/dir1. If a shared file system is mounted over a user's home
directories on all machines in a network, the user can log into any workstation
and get his honce environment. This property permits
One of the design goals of NFS was to operate in a heterogeneous environment
of different machines, operating systems, and network architectures.
The NFS specification is independent of these media and thus encourages
other implementations. This independence is achieved through the use of
RPC primitives built on top of an external data representation (XDR) protocol
used between two implementation-independent interfaces. Hence, if the
system consists of heterogeneous machines and file systems that are properly
interfaced to NFS, file systems of different types can be mounted both locally
and remotely.
The NFS specification distinguishes between the services provided by a
mount mechanism and the actual remote-file-access services. Accordingly, two
separate protocols are specified for these services: a mount protocol and a
protocol for remote file accesses, the The protocols are specified as
sets of RPCs. These RPCs are the building blocks used to implement transparent
remote file access.
11.8.2 The Mount Protocol
The establishes the initial logical connection between a server
and a client. In Sun's implementation, each machine has a server process,
outside the kernel, performing the protocol functions.
A mount operation includes the name of the remote directory to be
mounted and the name of the server machine storing it. The mount request
is mapped to the corresponding RPC and is forwarded to the mount server
running on the specific server machine. The server maintains an
that specifies local file systems that it exports for mounting, along with names
of machines that are permitted to mount them. (In Solaris, this list is the
I etc/dfs/dfstab, which can be edited only by a superuser.) The specification
can also include access rights, such as read only. To simplify the maintenance
of export lists and mount tables, a distributed naming scheme can be used to
hold this information and make it available to appropriate clients.
Recall that any directory within an exported file system can be mounted
remotely by an accredited machine. A component unit is such a directory. When
the server receives a mount request that conforms to its export list, it returns to
the client a file handle that serves as the key for further accesses to files within
the mounted file system. The file handle contains all the information that the
server needs to distinguish an individual file it stores. In UNIX terms, the file
handle consists of a file-system identifier and an inode number to identify the
exact mounted directory within the exported file system.
The server also maintains a list of the client machines and the corresponding
currently mounted directories. This list is used mainly for administrative
purposes-for instance, for notifying all clients that the server is going down.
Only through addition and deletion of entries in this list can the server state
be affected by the mount protocol.
Usually, a system has a static mounting preconfiguration that is established
at boot time (I etc/vfstab in Solaris); however, this layout can be modified. In
11.8 493
addition to the actual mount procedure, the mount protocol includes several
other procedures, such as unmount and return export list.
11.8.3 The NFS Protocol
The NFS protocol provides a set of RPCs for remote file operations. The
procedures support the following operations:
Searching for a file within a directory
Reading a set of directory entries
Manipulating links and directories
Accessing file attributes
Reading and writing files
These procedures can be invoked only after a file handle for the remotely
mounted directory has been established.
The omission of open() and close() operations is intentional. A prominent
feature of NFS servers is that they are stateless. Servers do not maintain
information about their clients from one access to another. No parallels to
UNIX's open-files table or file structures exist on the server side. Consequently,
each request has to provide a full set of arguments, including a unique file
identifier and an absolute offset inside the file for the appropriate operations.
The resulting design is robust; no special measures need be taken to recover
a server after a crash. File operations must be idempotent for this purpose.
Every NFS request has a sequence number, allowing the server to determine if
a request is duplicated or if any are missing.
Maintaining the list of clients that we mentioned seems to violate the
statelessness of the server. Howeve1~ this list is not essential for the correct
operation of the client or the server, and hence it does not need to be restored
after a server crash. Consequently, it might include inconsistent data and is
treated as only a hint.
A further implication of the stateless-server philosophy and a result of the
synchrony of an RPC is that modified data (including indirection and status
blocks) must be committed to the server's disk before results are returned to
the client. That is, a client can cache write blocks, but when it flushes them
to the server, it assumes that they have reached the server's disks. The server
must write all NFS data synchronously. Thus, a server crash and recovery
will be invisible to a client; all blocks that the server is managing for the
client will be intact. The consequent performance penalty can be large, because
the advantages of caching are lost. Performance can be increased using
storage with its own nonvolatile cache (usually battery-backed-up memory).
The disk controller ackiwwledges the disk write when the write is stored in
the nonvolatile cache. In essence, the host sees a very fast synchronous write.
These blocks remain intact even after system crash and are written from this
stable storage to disk periodically.
A single NFS write procedure call is guaranteed to be atomic and is not
intermixed with other write calls to the same file. The NFS protocol, however,
does not provide concurrency-control mechanisms. A write () system call may
494 Chapter 11
client server
Figure 11.15 Schematic view of the NFS architecture.
be broken down into several RPC writes, because each NFS write or read call
can contain up to 8 KB of data and UDP packets are limited to 1,500 bytes. As a
result, two users writing to the same remote file may get their data intermixed.
The claim is that, because lock management is inherently stateful, a service
outside the NFS should provide locking (and Solaris does). Users are advised
to coordinate access to shared files using mechanisms outside the scope of NFS.
NFS is integrated into the operating system via a VFS. As an illustration
of the architecture, let's trace how an operation on an already open remote
file is handled (follow the example in Figure 11.15). The client initiates the
operation with a regular system call. The operating-system layer maps this
call to a VFS operation on the appropriate vnode. The VFS layer identifies the
file as a remote one and invokes the appropriate NFS procedure. An RPC call
is made to the NFS service layer at the remote server. This call is reinjected to
the VFS layer on the remote system, which finds that it is local and invokes
the appropriate file-system operation. This path is retraced to return the result.
An advantage of this architecture is that the client and the server are identical;
thus, a machine may be a client, or a server, or both. The actual service on each
server is performed by kernel threads.
11.8.4 Path-Name Translation
in NFS involves the parsing of a path name such as
/usr/local/dir1/file. txt into separate directory entries, or components:
(1) usr, (2) local, and (3) dir1. Path-name translation is done by breaking the
path into component names and perform.ing a separate NFS lookup call for
every pair of component name and directory vnode. Once a n10unt point is
crossed, every component lookup causes a separate RPC to the server. This
11.8 495
expensive path-name-traversal scheme is needed, since the layout of each
client's logical name space is unique, dictated by the mounts the client has
performed. It would be ITluch more efficient to hand a server a path name
and receive a target vnode once a mount point is encountered. At any point,
however, there might be another mount point for the particular client of whicb
the stateless server is unaware.
So that lookup is fast, a directory-name-lookup cache on the client side
holds the vnodes for remote directory names. This cache speeds up references
to files with the same initial path name. The directory cache is discarded when
attributes returned from the server do not match the attributes of the cached
vnode.
Recall that mounting a remote file system on top of another already
mounted remote file system (a cascading mount) is allowed in some implementations
of NFS. However, a server cannot act as an intermediary between a
client and another server. Instead, a client must establish a direct client-server
com1ection with the second server by directly mounting the desired directory.
When a client has a cascading mount, more than one server can be involved in a
path-name traversaL However, each component lookup is performed between
the original client and some server. Therefore, when a client does a lookup on
a directory on which the server has mounted a file system, the client sees the
underlying directory instead of the mounted directory.
11.8.5 Remote Operations
With the exception of opening and closing files, there is almost a one-to-one
correspondence between the regular UNIX system calls for file operations and
the NFS protocol RPCs. Thus, a remote file operation can be translated directly
to the corresponding RPC. Conceptually, NFS adheres to the remote-service
paradigm; but in practice, buffering and caching techniques are employed for
the sake of performance. No direct correspondence exists between a remote
operation and an RPC. Instead, file blocks and file attributes are fetched by the
RPCs and are cached locally. Future remote operations use the cached data,
subject to consistency constraints.
There are two caches: the file-attribute (inode-infonnation) cache and the
file-blocks cache. When a file is opened, the kernel checks with the remote
server to determine whether to fetch or revalidate the cached attributes. The
cached file blocks are used only if the corresponding cached attributes are up
to date. The attribute cache is updated whenever new attributes arrive from
the server. Cached attributes are, by default, discarded after 60 seconds. Both
read-ahead and delayed-write techniques are used between the server and the
client. Clients do not free delayed-write blocks until the server confirms that
the data have been written to disk Delayed-write is retained even when a file
is opened concurrently, in conflicting modes. Hence, UNIX semantics (Section
10.5.3.1) are not preserved.
Tuning the system for performance makes it difficult to characterize the
consistency semantics of NFS. New files created on a machine may not be
visible elsewhere for 30 seconds. Furthermore, writes to a file at one site may
or may not be visible at other sites that have this file open for reading. New
opens of a file observe only the changes that have already been flushed to the
server. Thus, NFS provides neither strict emulation of UNIX semantics nor the
496 Chapter 11
11.9
session sen  antics of Andrew (Section 10.5.3.2).ln spite of these drawbacks, the
utility and good performance of the mechanism make it the most widely used
multi-vendor-distributed system in operation.
Disk I/O has a huge impact on system performance. As a result, file-system
design and implementation command quite a lot of attention from system
designers. Some file systems are general purpose, in that they can provide
reasonable performance and functionality for a wide variety of file sizes, file
types, and I/0 loads. Others are optimized for specific tasks in an attempt to
provide better performance in those areas than general-purpose file systems.
The WAFL file system from Network Appliance is an example of this sort of
optimization. WAFL, the write-anywhere file layout, is a powerful, elegant file
system optimized for random writes.
WAFL is used exclusively on network file servers produced by Network
Appliance and so is meant for use as a distributed file system. It can provide
files to clients via the NFS, CIFS, ftp, and http protocols, although it was
designed just for NFS and CIFS. When many clients use these protocols to talk
to a file server, the server may see a very large demand for random reads and
an even larger demand for random writes. The NFS and CIFS protocols cache
data from read operations, so writes are of the greatest concern to file-server
creators.
WAFL is used on file servers that include an NVRAM cache for writes.
The WAFL designers took advantage of running on a specific architecture to
optimize the file system for random I/0, with a stable-storage cache in front.
Ease of use is one of the guiding principles of WAFL, because it is designed
to be used in an appliance. Its creators also designed it to include a new
snapshot functionality that creates multiple read-only copies of the file system
at different points in time, as we shall see.
The file system is similar to the Berkeley Fast File System, with many
modifications. It is block-based and uses inodes to describe files. Each inode
contains 16 pointers to blocks (or indirect blocks) belonging to the file described
by the inode. Each file system has a root inode. All of the metadata lives in
files: all inodes are in one file, the free-block map in another, and the free-inode
root inode
1  free blotk map I
Figure 11.16 The WAFL file layout
11.9 497
map in a third, as shown in Figure 11.16. Because these are standard files, the
data blocks are not limited in location and can be placed anywhere. If a file
system is expanded by addition of disks, the lengths of the metadata files are
automatically expanded by the file systen  .
Thus, a WAFL file system is a tree of blocks with the root inode as its
base. To take a snapshot, WAFL creates a copy of the root inode. Any file or
metadata updates after that go to new blocks rather than overwriting their
existing blocks. The new root inode points to metadata and data changed as a
result of these writes. Meanwhile, the snapshot (the old root inode) still points
to the old blocks, which have not been updated. It therefore provides access to
the file system just as it was at the instant the snapshot was made-and takes
very little disk space to do so! In essence, the extra disk space occupied by a
snapshot consists of just the blocks that have been modified since the snapshot
was taken.
An important change from more standard file systems is that the free-block
map has more than one bit per block. It is a bitmap with a bit set for each
snapshot that is using the block. When all snapshots that have been using the
block are deleted, the bit map for that block is all zeros, and the block is free to
be reused. Used blocks are never overwritten, so writes are very fast, because
a write can occur at the free block nearest the current head location. There are
many other performance optimizations in WAFL as well.
Many snapshots can exist simultaneously, so one can be taken each hour
of the day and each day of the month. A user with access to these snapshots
can access files as they were at any of the times the snapshots were taken.
The snapshot facility is also useful for backups, testing, versioning, and so on.
WAFL's snapshot facility is very efficient in that it does not even require that
copy-on-write copies of each data block be taken before the block is modified.
Other file systems provide snapshots, but frequently with less efficiency. WAFL
snapshots are depicted in Figure 11.17.
Newer versions of WAFL actually allow read-write snapshots, known as
,.HJ'  '-  '    Clones are also efficient, using the same techniques as shapshots. In
this case, a read-only snapshot captures the state of the file system, and a clone
refers back to that read-only snapshot. Any writes to the clone are stored in
new blocks, and the clone's pointers are updated to refer to the new blocks.
The original snapshot is unmodified, still giving a view into the file system as
it was before the clone was updated. Clones can also be promoted to replace
the original file system; this involves throwing out all of the old pointers and
any associated old blocks. Clones are useful for testing and upgrades, as the
original version is left untouched and the clone deleted when the test is done
or if the upgrade fails.
Another feature that naturally falls from the WAFL file system implementation
is the duplication and synchronization of a set of data over a
network to another system. First, a snapshot of a WAFL file system is duplicated
to another system. When another snapshot is taken on the source system, it
is relatively easy to update the remote system just by sending over all blocks
contained in the new snapshot. These blocks are the ones that have changed
between the times the two snapshots were taken. The remote system adds these
blocks to the file system and updates its pointers, and the new system then is a
duplicate of the source system as of the time of the second snapshot. Repeating
this process maintains the remote system as a nearly up-to-date copy of the first
498 Chapter 11
11.10
(a) Before a snapshot.
(b) After a snapshot, before any blocks change.
(c) After block D has changed to o .
Figure 11.17 Snapshots in WAFL.
system. Such replication is used for disaster recovery. Should the first system
be destroyed, most of its data are available for use on the remote system.
Finally, we should note that Sun's ZFS file system supports similarly
efficient snapshots, clones, and replication.
The file system resides permanently on secondary storage, which is designed to
hold a large amount of data permanently. The most common secondary-storage
medium is the disk.
Physical disks may be segmented into partitions to control media use
and to allow multiple, possibly varying, file systems on a single spindle.
These file systems are mounted onto a logical file system architecture to make
then   available for use. File systems are often implemented in a layered or
modular structure. The lower levels deal with the physical properties of storage
devices. Upper levels deal with symbolic file names and logical properties of
files. Intermediate levels map the logical file concepts into physical device
properties.
Any file-system type can have different structures and algorithms. A VFS
layer allows the upper layers to deal with each file-system type uniformly. Even
499
remote file systems can be integrated into the system's directory structure and
acted on by standard system calls via the VFS interface.
The various files can be allocated space on the disk in three ways:
through contiguous, linked, or indexed allocation. Contiguous allocation can
suffer from external fragmentation. Direct access is very inefficient with
linked allocation. Indexed allocation may require substantial overhead for its
index block. These algorithms can be optimized in many ways. Contiguous
space can be enlarged through extents to increase flexibility and to decrease
external fragmentation. Indexed allocation can be done in clusters of multiple
blocks to increase throughput and to reduce the number of index entries
needed. Indexing in large clusters is similar to contiguous allocation with
extents.
Free-space allocation methods also influence the efficiency of disk-space
use, the performance of the file system, and the reliability of secondary storage.
The methods used include bit vectors and linked lists. Optimizations include
grouping, countilcg, and the FAT, which places the linked list in one contiguous
area.
Directory-management routines must consider efficiency, performance,
and reliability. A hash table is a commonly used method, as it is fast and
efficient. Unfortunately, damage to the table or a system crash can result
in inconsistency between the directory information and the disk's contents.
A consistency checker can be used to repair the damage. Operating-system
backup tools allow disk data to be copied to tape, enabling the user to recover
from data or even disk loss due to hardware failure, operating system bug, or
user error.
Network file systems, such as NFS, use client-server methodology to
allow users to access files and directories from remote machines as if they
were on local file systems. System calls on the client are translated into
network protocols and retranslated into file-system operations on the server.
Networking and multiple-client access create challenges in the areas of data
consistency and performance.
Due to the fundamental role that file systems play in system operation,
their performance and reliability are crucial. Techniques such as log structures
and cachirtg help improve performance, while log structures and RAID improve
reliability. The WAFL file system is an example of optimization of performance
to match a specific I/O load.
11.1 In what situations would using memory as a RAM disk be more useful
than using it as a disk cache 
11.2 Consider a file systenc that uses a modifed contiguous-allocation
scheme with support for extents. A file is a collection of extents,
with each extent corresponding to a contiguous set of blocks. A key
issue in such systems is the degree of variability in the size of the
500 Chapter 11
extents. What are the advantages and disadvantages of the following
schemes 
a. All extents are of the same size, and the size is predetermined.
b. Extents can be of any size and are allocated dynamically.
c. Extents can be of a few fixed sizes, and these sizes are predetermined.
11.3 Some file systems allow disk storage to be allocated at different levels
of granularity. For instance, a file system could allocate 4 KB of disk
space as a single 4-KB block or as eight 512-byte blocks. How could
we take advantage of this flexibility to improve performance  What
modifications would have to be made to the free-space management
scheme in order to support this feature 
11.4 What are the advantages of the variant of linked allocation that uses a
FAT to chain together the blocks of a file 
11.5 Consider a file currently consisting of 100 blocks. Assume that the filecontrol
block (and the index block, in the case of indexed allocation)
is already in memory. Calculate how many disk I/0 operations are
required for contiguous, linked, and indexed (single-level) allocation
strategies, if, for one block, the following conditions hold. In the
contiguous-allocation case, assume that there is no room to grow at
the beginning but there is room to grow at the end. Also assume that
the block information to be added is stored in memory.
a. The block is added at the beginning.
b. The block is added in the middle.
c. The block is added at the end.
d. The block is removed from the beginning.
e. The block is removed from the middle.
f. The block is removed from the end.
11.6 Consider a file system that uses inodes to represent files. Disk blocks
are 8 KB in size, and a pointer to a disk block requires 4 bytes. This file
system has 12 direct disk blocks, as well as single, double, and triple
indirect disk blocks. What is the maximum size of a file that can be
stored in this file system 
11.7 Assume that in a particular augmentation of a reinote-file-access
protocol, each client maintains a name cache that caches translations
from file names to corresponding file handles. What issues should we
take into account in implementing the name cache 
11.8 Consider the following backup scheme:
Day 1. Copy to a backup medium all files from the disk.
Day 2. Copy to another m.edium all files changed since day 1.
Day 3. Copy to another medium all files changed since day 1.
501
This differs from the schedule given in Section 11.7.4 by having all
subsequent backups copy all files modified since the first full backup.
What are the benefits of this system over the one in Section 11.7.4 
What are the drawbacks  Are restore operations made easier or more
difficult  Explain your answer.
11.9 Why must the bit map for file allocation be kept on mass storage, rather
than in main memory 
11.10 Consider a file system on a disk that has both logical and physical
block sizes of 512 bytes. Assume that the information about each
file is already in memory. For each of the three allocation strategies
(contiguous, linked, and indexed), answer these questions:
a. How is the logical-to-physical address mapping accomplished
in this system  (For the indexed allocation, assume that a file is
always less than 512 blocks long.)
b. If we are currently at logical block 10 (the last block accessed was
block 10) and want to access logical block 4, how many physical
blocks must be read from the disk 
11.11 Why is it advantageous to the user for an operating system to dynamically
allocate its internal tables  What are the penalties to the operating
system for doing so 
11.12 Explain why logging metadata updates ensures recovery of a file
system after a file-system crash.
11.13 Fragmentation on a storage device can be eliminated by recompaction
of the information. Typical disk devices do not have relocation or base
registers (such as those used when memory is to be compacted), so
how can we relocate files  Give three reasons why recompacting and
relocation of files are often avoided.
11.14 Consider a system where free space is kept in a free-space list.
a. Suppose that the pointer to the free-space list is lost. Can the
system reconstruct the free-space list  Explain your answer.
b. Consider a file system similar to the one used by UNIX with
indexed allocation. How many disk I/0 operations might be
502 Chapter 11
required to read the contents of a small local file at /a/b/c  Assume
that none of the disk blocks is currently being cached.
c. Suggest a scheme to ensure that the pointer is never lost as a result
of memory failure.
11.15 One problem with contiguous allocation is that the user must preallocate
enough space for each file. If the file grows to be larger than the
space allocated for it, special actions must be taken. One solution to this
problem is to define a file structure consisting of an initial contiguous
area (of a specified size). If this area is filled, the operating system
automatically defines an overflow area that is linked to the initial
contiguous area. If the overflow area is filled, another overflow area
is allocated. Compare this implementation of a file with the standard
contiguous and linked implementations.
11.16 Discuss how performance optimizations for file systems might result
in difficulties in maintaining the consistency of the systems in the event
of com.puter crashes.
The MS-DOS FAT system is explained in Norton and Wilton [1988], and the OS/2
description can be found in Iacobucci [1988]. These operating systems use
the Intel 8086 CPUs(Intel [1985b ], Intel [1985a], Intel [1986], and Intel [1990]).
IBM allocation methods are described in Deitel [1990]. The internals of the
BSD UNL'   system are covered in full in McKusick et al. [1996]. McVoy and
Kleiman [1991] discusses optimizations of these methods made in Solaris. The
Coogle file system is described in Ghemawat et al. [2003]. FUSE can be found
at http:/ /fuse.sourceforge.net/.
Disk file allocation based on the buddy system is covered in Koch
[1987]. A file-organization scheme that guarantees retrieval in one access
is described by Larson and Kajla [1984]. Log-structured file organizations
for enhancing both performance and consistency are discussed in
Rosenblum and Ousterhout [1991], Seltzer et al. [1993], and Seltzer et aL
[1995]. Algorithms such as balanced trees (and much more) are covered
by Knuth [1998] and Carmen et aL [2001]. The ZFS source code for space
maps can be found at http://src.opensolaris.org/source/xref/onnv/onnvgate/
usr I src/uts/ common/ fs/ zfs/ space_map.c.
Disk caching is discussed by McKeon [1985] and Smith [1985]. Caching in
the experimental Sprite operating system is described in Nelson et aL [1988].
General discussions concerning mass-storage technology are offered by Chi
[1982] and Hoagland [1985]. Folk and Zoellick [1987] covers the gamut of file
structures. Silvers [2000] discusses implementing the page cache in the NetBSD
operating system.
The network file system (NFS) is discussed in Sandberg et aL [1985],
Sandberg [1987], Sun [1990], and Callaghan [2000]. NFS Version 4 is a standard
described at http:/ /www.ietf.org/rfc/rfc3530.txt. The characteristics of
503
workloads in distributed file systems are examined in Baker et al. [1991].
Ousterhout [1991] discusses the role of distributed state in networked file
systems. Log-structured designs for networked file systems are proposed in
Hartman and Ousterhout [1995] and Thekkath et al. [1997]. NFS and the UNIX
file system (UFS) are described in Vahalia [1996] and Mauro and McDougall
[2007]. The Windows NT file system, NTFS, is explained in Solomon [1998]. The
Ext2 file system used in Linux is described in Bovet and Cesati [2002] and
the WAFL file system in Hitz et al. [1995]. ZFS documentation can be found at
http:/ /www.opensolaris.org/ os/ community /ZFS/ docs.

12.1
The file system can be viewed logically as consisting of three parts. In Chapter
10, we examined the user and programmer interface to the file system. In
Chapter 11, we described the internal data structures and algorithms used
by the operating system to implement this interface. In this chapter, we
discuss the lowest level of the file system: the secondary and tertiary storage
structures. We first describe the physical structure of magenetic disks and
magnetic tapes. We then describe disk-scheduling algorithms, which schedule
the order of disk I/ Os to improve performance. Next, we discuss disk formatting
and management of boot blocks, damaged blocks, and swap space. We then
examine secondary storage structure, covering disk reliability and stablestorage
implementation. We conclude with a brief description of tertiary
storage devices and the problems that arise when an operating system uses
tertiary storage.
To describe the physical structure of secondary and tertiary storage
devices and its effects on the uses of the devices.
To explain the performance characteristics of mass-storage devices.
To discuss operating-system services provided for mass storage, including
RAID and HSM.
In this section, we present a general overview of the physical structure of
secondary and tertiary storage devices.
12.1.1 Magnetic Disks
provide the bulk of secondary storage for modern computer
systems. Conceptually, disks are relatively simple (Figure 12.1). Each disk
platter has a flat circular shape, like a CD. Common platter diameters range
505
506 Chapter 12
arm assembly
rotation
Figure 12.1 Moving-head disk mechanism.
from 1.8 to 5.25 inches. The two surfaces of a platter are covered with a magnetic
material. We store information by recording it magnetically on the platters.
A read -write head   flies   just above each surface of every platter. The
heads are attached to a that moves all the heads as a unit. The surface
of a platter is logically divided into circular which are subdivided into
The set of tracks that are at one arm position makes up a
There may be thousands of concentric cylinders in a disk drive, and each track
may contain hundreds of sectors. The storage capacity of common disk drives
is measured iil gigabytes.
When the disk is in use, a drive motor spins it at high speed. Most drives
rotate 60 to 200 times per second. Disk speed has two parts. The
is the rate at which data flow between the drive and the computer. The
sometimes called the consists of the
time necessary to move the disk arm to the desired cylinder, called the
and the time necessary for the desired sector to rotate to the disk head,
called the Typical disks can transfer several megabytes of
data per second, and they seek times and rotational latencies of several
milliseconds.
Because the disk head flies on an extremely thin cushion of air (measured
in microns), there is a danger that the head will make contact with the disk
surface. Although the disk platters are coated with a thin protective laye1~ the
head will sometimes damage the magnetic surface. This accident is called a
A head crash normally cannot be repaired; the entire disk must be
replaced.
A disk can be allowing different disks to be mounted as needed.
Removable magnetic disks generally consist of one platter, held in a plastic case
to prevent damage while not in the disk drive. are inexpensive
removable magnetic disks that have a soft plastic case containing a flexible
platter. The head of a floppy-disk drive generally sits directly on the disk
12.1 507
DISK TRANSFER RATES
As with many aspects of computingf published performance numbers for
disks are not the same as real-world performance numbers. Stated transfer
rates are always lower than for example. The transfer
rate may be the rate at which bits can be read from the magnetic media by
the disk head, but that is different from the rate at which blocks are delivered
to the operating system.
surface, so the drive is designed to rotate more slowly than a hard-disk drive
to reduce the wear on the disk surface. The storage capacity of a floppy disk
is typically only 1.44MB or so. Removable disks are available that work much
like normal hard disks and have capacities measured in gigabytes.
A disk drive is attached to a computer by a set of wires called an
Several kinds of buses are available, including
buses. The data transfers on a bus are carried out by special
electronic processors called The is the controller at
the computer end of the bus. A is built into each disk drive. To
perform a disk I/0 operation, the computer places a command into the host
controller, typically using memory-mapped I/0 portsf as described in Section
9.7.3. The host controller then sends the command via messages to the disk
controller, and the disk controller operates the disk-drive hardware to carry
out the command. Disk controllers usually have a built-in cache. Data transfer
at the disk drive happens between the cache and the disk surface, and data
transfer to the host, at fast electronic speeds, occurs between the cache and the
host controller.
12.1.2 Magnetic Tapes
was used as an early secondary-storage medium. Although it
is relatively permanent and can hold large quantities of dataf its access time
is slow compared with that of main memory and magnetic disk. In addition,
random access to magnetic tape is about a thousand times slower than random
access to magnetic disk, so tapes are not very useful for secondary storage.
Tapes are used mainly for backup, for storage of infrequently used information,
and as a medium for transferring information from one system to another.
A tape is kept in a spool and is wound or rewound past a read-write head.
Moving to the correct spot on a tape can take minutes, but once positioned,
tape drives can write data at speeds comparable to disk drives. Tape capacities
vary greatly, depending on the particular kind of tape drive. Typically, they
store from 20GB to 200GB. Some have built-in compression that can more than
double the effective storage. Tapes and their drivers are usually categorized
by width, includil1.g 4, 8f and 19 millimeters and 1/4 and 1/2 inch. Some are
named according to technology, such as LT0-2 and SDLT. Tape storage is further
described in Section 12.9.
508 Chapter 12
12.2
FIRE WIRE
refers to an interface designed for connecting peripheral devices
such as hard drives, DVD drives, and digital video cameras to a computer
system. Fire Wire was first developed by Apple Computer and became
the IEEE 1394 standard in 1995. The originaLFireWire standard provided
bandwidth up to 400 megabits per second. Recently, a new standardFireWire
2-has emerged and is identified by the IEEE 1394b standard.
FireWire 2 provides double the data rate of the original FireWire-800
megabits per second.
Modern disk drives are addressed as large one-dimensional arrays of
where the logical block is the smallest unit of transfer. The size of
a logical block is usually 512 bytes, although some disks can be
to have a different logical block size, such as 1,024 bytes. This option
is described in Section 12.5.1. The one-dimensional array of logical blocks is
mapped onto the sectors of the disk sequentially. Sector 0 is the first sector
of the first track on the outermost cylinder. The mapping proceeds in order
through that track, then through the rest of the tracks in that cylinder, and then
through the rest of the cylinders from outermost to innermost.
By using this mapping, we can -at least in theory-convert a logical block
number into an old-style disk address that consists of a cylinder number, a track
number within that cylinder, and a sector number within that track. In practice,
it is difficult to perform this translation, for two reasons. First, most disks have
some defective sectors, but the mapping hides this by substituting spare sectors
from elsewhere on the disk. Second, the number of sectors per track is not a
constant on smne drives.
Let's look more closely at the second reason. On media that use
the density of bits per track is uniform. The farther a track
is from the center of the disk, the greater its length, so the more sectors it can
hold. As we move from outer zones to inner zones, the number of sectors per
track decreases. Tracks in the outermost zone typically hold 40 percent more
sectors than do tracks in the innermost zone. The drive increases its rotation
speed as the head moves from the outer to the inner tracks to keep the same rate
of data moving under the head. This method is used in CD-ROM and DVD-ROM
drives. Alternatively, the disk rotation speed can stay constant; in this case, the
density of bits decreases from inner tracks to outer tracks to keep the data rate
constant. This method is used in hard disks and is known as
The number of sectors per track has been increasing as disk technology
improves, and the outer zone of a disk usually has several hundred sectors per
track. Similarly, the number of cylinders per disk has been increasing; large
disks have tens of thousands of cylinders.
12.3
12.3 509
Computers access disk storage in two ways. One way is via I/O ports (or
this is common on small systems. The other way is via
a remote host in a distributed file system; this is referred to as
12.3.1 Host-Attached Storage
Host-attached storage is storage accessed through local I/0 ports. These ports
use several technologies. The typical desktop PC uses an I/0 bus architecture
called IDE or ATA. This architecture supports a maximum of two drives per I/0
bus. A newer, similar protocol that has simplified cabling is SATA. High-end
workstations and servers generally use more sophisticated I/0 architectures,
such as SCSI and fiber charmel (FC).
SCSI is a bus architecture. Its physical medium is usually a ribbon cable with
a large number of conductors (typically 50 or 68). The SCSI protocol supports a
maximum of 16 devices per bus. Generally, the devices include one controller
card in the host (the and up to 15 storage devices (the
to.rgr:::ts). A SCSI disk is a common SCSI target, but the protocol provides the
ability to address up to 8 in each SCSI target. A typical use of
logical unit addressing is to commands to components of a RAID array
or components of a removable media library (such as a CD jukebox sendil  g
commands to the media-changer mechanism or to one of the drives).
FC is a high-speed serial architecture that can operate over optical fiber or
over a four-conductor copper cable. It has two variants. One is a large switched
fabric having a 24-bit address space. This variant is expected to dominate
in the future and is the basis of (SJld',;s), discussed in
Section 12.3.3. Because of the large space and the switched nature of
the communication, multiple hosts and storage devices can attach to the fabric,
allowing great flexibility in I/0 communication. The other FC variant is an
that can address 126 devices (drives and controllers).
A wide variety of storage devices are suitable for use as host-attached
storage. Among these are hard disk drives, RAID arrays, and CD, DVD, and
tape drives. The I/0 commands that initiate data transfers to a host-attached
storage device are reads and writes of logical data blocks directed to specifically
identified storage units (such as bus ID, SCSI ID, and target logical unit).
12.3.2 Network-Attached Storage
A network-attached storage (NAS) device is a special-purpose storage system
that is accessed remotely over a data network (Figure 12.2). Clients access
network-attached storage via a remote-procedure-call interface such as NFS
for UNIX systems or CIFS for Windows machines. The remote procedure calls
(RPCs) are carried via TCP or UDP over an IP network-usually the same
local-area network (LAN) that carries all data traffic to the clients. The networkattached
storage unit is usually implemented as a RAID array with software that
implements the RPC interface. It is easiest to thil  k of NAS as simply another
storage-access protocol. For example, rather than using a SCSI device driver
and SCSI protocols to access storage, a system using NAS would use RPC over
TCP /IP.
510 Chapter 12
12.4
LAN/WAN
Figure 12.2 Network-attached storage.
Network-attached storage provides a convenient way for all the computers
on a LAN to share a pool of storage with the same ease of naming and access
enjoyed with local host-attached storage. However, it tends to be less efficient
and have lower performance than some direct-attached storage options.
is the latest network-attached storage protocol. In essence, it uses the
IP network protocol to carry the SCSI protocol. Thus, networks-rather than
SCSI cables-can be used as the interconnects between hosts and their storage.
As a result, hosts can treat their storage as if it were directly attached, even if
the storage is distant from the host.
12.3.3 Storage-Area Network
One drawback of network-attached storage systems is that the storage I/O
operations consume bandwidth on the data network, thereby increasing the
latency of network communication. This problem can be particularly acute
in large client-server installations-the communication between servers and
clients competes for bandwidth with the communication among servers and
storage devices.
A storage-area network (SAN) is a private network (using storage protocols
rather than networking protocols) connecting servers and storage units, as
shown in Figure 12.3. The power of a SAN lies in its flexibility. Multiple hosts
and multiple storage arrays can attach to the same SAN, and storage can
be dynamically allocated to hosts. A SAN switch allows or prohibits access
between the hosts and the storage. As one example, if a host is running low
on disk space, the SAN can be configured to allocate more storage to that host.
SANs make it possible for clusters of servers to share the same storage and for
storage arrays to include multiple direct host com1.ections. SANs typically have
more ports, and less expensive ports, than storage arrays.
FC is the most common SAN interconnect, although the simplicity of iSCSI is
increasing its use. An emerging alternative is a special-purpose bus architecture
named InfiniBand, which provides hardware and software support for highspeed
interconnection networks for servers and storage units.
One of the responsibilities of the operating system is to use the hardware
efficiently. For the disk drives, meeting this responsibility entails having
12.4 511
Figure 12.3 Storage-area network.
fast access time and large disk bandwidth. The access time has two major
components (also see Section 12.1.1). The is the time for the disk arm
to move the heads to the cylinder containing the desired sector. The
is the additional time for the disk to rotate the desired sector to the disk
head. The disk is the total number of bytes transferred, divided
by the total time between the first request for service and the completion of
the last transfer. We can improve both the access time and the bandwidth by
managing the order in which disk I/O requests are serviced.
Whenever a process needs I/0 to or from the disk, it issues a system call to
the operating system. The request specifies several pieces of information:
Whether this operation is input or output
What the disk address for the transfer is
What the memory address for the transfer is
What the number of sectors to be transferred is
If the desired disk drive and controller are available, the request can be
serviced immediately. If the drive or controller is busy, any new requests
for service will be placed in the queue of pending requests for that drive.
For a multiprogramming system with many processes, the disk queue may
often have several pending requests. Thus, when one request is completed, the
operating system chooses which pending request to service next. How does
the operating system make this choice  Any one of several disk-scheduling
algorithms can be used, and we discuss them next.
12.4.1 FCFS Scheduling
The simplest form of disk scheduling is, of course, the first-come, first-served
(FCFS) algorithm. This algorithm is intrinsically fair, but it generally does not
provide the fastest service. Consider, for example, a disk queue with requests
for I/0 to blocks on cylinders
98, 183, 37, 122, 14, 124, 65, 67,
512 Chapter 12
queue= 98, 183,37,122, 14,124,65,67
head starts at 53
0 14 37 536567 98 122124
Figure 12.4 FCFS disk scheduling.
183199
in that order. If the disk head is initially at cylinder 53, it will first move from
53 to 98, then to 183, 37, 122, 14, 124, 65, and finally to 67, for a total head
movement of 640 cylinders. This schedule is diagrammed in Figure 12.4.
The wild swing from 122 to 14 and then back to 124 illustrates the problem
with this schedule. If the requests for cylinders 37 and 14 could be serviced
together, before or after the requests for 122 and 124, the total head movement
could be decreased substantially, and performance could be thereby improved.
12.4.2 SSTF Scheduling
It seems reasonable to service all the requests close to the current head position
before moving the head far to service other This assumption is
the basis for the The SSTF algorithm
selects the request with the least seek time from the current head position.
Since seek time increases with the number of cylinders traversed by the head,
SSTF chooses the pending request closest to the current head position.
For our example request queue, the closest request to the initial head
position (53) is at cylinder 65. Once we are at cylinder 65, the next closest
request is at cylinder 67. From there, the request at cylinder 37 is closer than the
one at 98, so 37 is served next. Continuing, we service the request at cylinder 14,
then 98, 122, 124, and finally 183 (Figure 12.5). This scheduling method results
in a total head movement of only 236 cylinders-little more than one-third
of the distance needed for FCFS scheduling of this request queue. Clearly, this
algorithm gives a substantial improvement in performance.
SSTF scheduling is essentially a form of shortest-job-first (SJF) scheduling;
and like SJF scheduling, it may cause starvation of some requests. Remember
that requests may arrive at any time. Suppose that we have two requests in
the queue, for cylinders 14 and 186, and while the request from 14 is being
serviced, a new request near 14 arrives. This new request will be serviced
next, making the request at 186 wait. While this request is being serviced,
another request close to 14 could arrive. In theory, a continual stream of requests
near one another could cause the request for cylinder 186 to wait indefinitely.
12.4
queue= 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 14 37 536567 98 122124
Figure 12.5 SSTF disk scheduling.
513
183199
This scenario becomes increasingly likely as the pending-request queue grows
longer.
Although the SSTF algorithm is a substantial improvement over the FCFS
algorithm, it is not optimal. In the example, we can do better by moving the
head from 53 to 37, even though the latter is not closest, and then to 14, before
turning around to service 65, 67, 98, 122, 124, and 183. This strategy reduces
the total head movement to 208 cylinders.
12.4.3 SCAN Scheduling
In the
toward the end, servicing requests as it reaches each cylinder, until it gets
to the other end of the disk. At the other end, the direction of head movement
is reversed, and servicing continues. The head continuously scans back and
forth across the disk. The SCAN algorithm is sometimes called the
since the disk arm behaves just like an elevator in a building, first
servicing all the requests going up and then reversing to service requests the
other way.
Let's return to our example to illustrate. Before applying SCAN to schedule
the requests on cylinders 98, 183,37, 122, 14, 124, 65, and 67, we need to know
the direction of head movement in addition to the head's current position.
Assuming that the disk arm is moving toward 0 and that the initial head
position is again 53, the head will next service 37 and then 14. At cylinder 0,
the arm will reverse and will move toward the other end of the disk, servicil  lg
the requests at 65, 67, 98, 122, 124, and 183 (Figure 12.6). If a request arrives
in the queue just in front of the head, it will be serviced almost immediately; a
request arriving just behind the head will have to wait until the arm moves to
the end of the disk, reverses direction, and comes back.
Assuming a uniform distribution of requests for cylinders, consider the
density of requests when the head reaches one end and reverses direction. At
this point, relatively few requests are immediately in front of the head, since
these cylinders have recently been serviced. The heaviest density of requests
514 Chapter 12
queue= 98, 183,37,122, 14,124,65,67
head starts at 53
0 14 37 536567 98 122124
Figure 12.6 SCAN disk scheduling.
183199
is at the other end of the disk These requests have also waited the longest so
why not go there first  That is the idea of the next algorithm.
12.4.4 C-SCAN Scheduling
is a variant of SCAN designed to provide
a more uniform wait time. Like SCAN, C-SCAN moves the head from one end
of the disk to the other, servicing requests along the way. When the head
reaches the other end, however, it immediately returns to the beginning of
the disk without servicing any requests on the return trip (Figure 12.7). The
C-SCAN scheduling algorithm essentially treats the cylinders as a circular list
that wraps around from the final cylinder to the first one.
queue= 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 1 4 37 53 65 67 98 1 22 1 24
Figure 12.7 C-SCAN disk scheduling.
183199
12.4
queue = 98, 183, 37, 122, 14, 124, 65, 67
head starts at 53
0 14 37 536567 98 122124
Figure 12.8 C-LOOK disk scheduling.
12.4.5 LOOK Scheduling
515
183199
As we described themf both SCAN and C-SCAN move the disk arm across the
full width of the disk In practicef neither algorithm is often implemented this
way. More commonlyf the arm goes only as far as the final request in each
direction. Then, it reverses direction immediatelyf without going all the way to
the end of the disk Versions of SCAN and C-SCAN that follow this pattern are
called and because they look for a request before
continuing to move in a given direction (Figure 12.8).
12.4.6 Selection of a Disk-Scheduling Algorithm
Given so many disk-scheduling algorithmsf how do we choose the best one 
SSTF is common and has a natural appeal because it increases performance over
FCFS. SCAN and C-SCAN perform better for systems that place a heavy load on
the diskf because they are less likely to cause a starvation problem. For any
particular list of requestsf we can define an optimal order of retrievat but the
computation needed to find an optimal schedule may not justify the savings
over SSTF or SCAN. With any scheduling algoritlunf howeverf performance
depends heavily on the number and types of requests. For instance, suppose
that the queue usually has just one outstanding request. Thenf all scheduling
algorithms behave the samef because they have only one choice of where to
move the disk head: they all behave like FCFS scheduling.
Requests for disk service can be greatly influenced by the file-allocation
method. A program reading a contiguously allocated file will generate several
requests that are close together on the disk, resulting in limited head movement.
A linked or indexed fik in contrastf may include blocks that are widely
scattered on the diskf resulting in greater head movement.
The location of directories and index blocks is also important. Since every
file must be opened to be usedf and opening a file requires searching the
directory structuref the directories will be accessed frequently. Suppose that a
directory entry is on the first cylinder and a filef s data are on the final cylinder. In
this casef the disk head has to move the entire width of the disk If the directory
516 Chapter 12
12.5
entry were on the middle cylinder, the head would have to move only one-half
the width. Caching the directories and index blocks in main memory can also
help to reduce disk-arm movement particularly for read requests.
Because of these complexities, the disk-scheduling algorithm should be
written as a separate module of the operating system, so that it can be replaced
with a different algorithm if necessary. Either SSTF or LOOK is a reasonable
choice for the default algorithm.
The scheduling algorithms described here consider only the seek distances.
For modern disks, the rotational latency can be nearly as large as the
average seek time. It is difficult for the operating system to schedule for
improved rotational latency, though, because modern disks do not disclose the
physical location of logical blocks. Disk manufacturers have been alleviating
this problem by implementing disk-scheduling algorithms in the controller
hardware built into the disk drive. If the operating system sends a batch of
requests to the controller, the controller can queue them and then schedule
them to improve both the seek time and the rotational latency.
If I/O performance were the only consideration, the operating system
would gladly turn over the responsibility of disk scheduling to the disk hardware.
In practice, however, the operating system may have other constraints on
the service order for requests. For instance, demand paging may take priority
over application I/0, and writes are more urgent than reads if the cache is
running out of free pages. Also, it may be desirable to guarantee the order of a
set of disk writes to make the file system robust in the face of system crashes.
Consider what could happen if the operating system allocated a disk page to a
file and the application wrote data into that page before the operating system
had a chance to flush the modified inode and free-space list back to disk. To
accommodate such requirements, an operating system may choose to do its
own disk scheduling and to spoon-feed the requests to the disk controller, one
by one, for some types of I/0.
The operating system is responsible for several other aspects of disk management,
too. Here we discuss disk initialization, booting from disk, and bad-block
recovery.
12.5.1 Disk Formatting
A new magnetic disk is a blank slate: it is just a platter of a magnetic recording
material. Before a disk can store data, it must be divided into sectors that the
disk controller can read and write. This process is called
or Low-level formatting fills the disk with a special data
structure for each sector. The data structure for a sector typically consists of a
header, a data area (usually 512 bytes in size), and a trailer. The header and
trailer contain information used by the disk controller, such as a sector number
and an . When the controller writes a sector of data
during normal I/0, the ECC is updated with a value calculated from all the bytes
in the data area. When the sector is read, the ECC is recalculated and compared
with the stored value. If the stored and calculated numbers are different, this
12.5 517
mismatch indicates that the data area of the sector has become corrupted and
that the disk sector may be bad (Section 12.5.3). The ECC is an error-correcting
code because it contains enough information, if only a few bits of data have
been corrupted, to enable the controller to identify which bits have changed
and calculate what their correct values should be. It then reports a recoverable
. The controller automatically does the ECC processing whenever a
sector is read or written.
Most hard disks are low-level-formatted at the factory as a part of the
manufacturing process. This formatting enables the manufacturer to test the
disk and to initialize the mapping from logical block numbers to defect-free
sectors on the disk. For many hard disks, when the disk controller is instructed
to low-level-format the disk, it can also be told how many bytes of data space
to leave between the header and trailer of all sectors. It is usually possible to
choose among a few sizes, such as 256,512, and 1,024 bytes. Formatting a disk
with a larger sector size means that fewer sectors can fit on each track; but it
also means that fewer headers and trailers are written on each track and more
space is available for user data. Some operating systems can handle only a
sector size of 512 bytes.
Before it can use a disk to hold files, the operating system still needs to
record its own data structures on the disk. It does so in two steps. The first step
is to the disk into one or more groups of cylinders. The operatiltg
system can treat each partition as though it were a separate disk. For instance,
one partition can hold a copy of the operating system's executable code, while
another holds user files. The second step is icgicz;i or creation of a
file system. In this step, the operating system stores the iltitial file-system data
structures onto the disk. These data structures may include maps of free and
allocated space (a FAT or inodes) and an initial empty directory.
To increase efficiency, most file systems group blocks together into larger
chunks, frequently called Disk I/0 is done via blocks, but file system
II 0 is done via clusters, effectively assuring that II 0 has more sequential-access
and fewer random-access characteristics.
Some operating systems give special programs the ability to use a disk
partition as a large sequential array of logical blocks, without any file-system
data structures. This array is sometimes called the raw disk, and II 0 to this array
is termed raw l/0. For example, some database systems prefer raw IIO because
it enables them to control the exact disk location where each database record is
stored. Raw l/0 bypasses all the file-system services, such as the buffer cache,
file locking, prefetching, space allocation, file names, and directories. We can
make certain applications more efficient by allowing them to implement their
own special-purpose storage services on a raw partition, but most applications
perform better when they use the regular file-system services.
12.5.2 Boot Block
For a computer to start running-for instance, when it is powered up
or rebooted -it must have an initial program to run. This initial bootstrap
program tends to be simple. It initializes all aspects of the system, from CPU
registers to device controllers and the contents of main memory, and then
starts the operating system. To do its job, the bootstrap program finds the
518 Chapter 12
operating-system kernel on disk, loads that kernel into memory, and jumps to
an initial address to begin the operating-system execution.
For most computers, the bootstrap is stored in
This location is convenient, because ROM needs no initialization and is at a fixed
location that the processor can start executing when powered up or reset. And,
since ROM is read only, it cannot be infected by a computer virus. The problem is
that changing this bootstrap code requires changing the ROM hardware chips.
For this reason, most systems store a tiny bootstrap loader program in the boot
ROM whose only job is to bring in a full bootstrap program from disk. The full
bootstrap program can be changed easily: a new version is simply written onto
the disk. The full bootstrap program is stored in the   boot blocks   at a fixed
location on the disk. A disk that has a boot partition is called a or
The code in the boot ROM instructs the disk controller to read the boot
blocks into memory (no device drivers are loaded at this point) and then starts
executing that code. The full bootstrap program is more sophisticated than the
bootstrap loader in the boot ROM; it is able to load the entire operating system
from a non-fixed location on disk and to start the operating system ruru1ing.
Even so, the full bootstrap code may be small.
Let's consider as an example the boot process in Windows 2000. The
Windows 2000 system places its boot code in the first sector on the hard disk
(which it terms the or Furthermore, Windows 2000
allows a hard disk to be divided into one or more partitions; one partition,
identified as the contains the operating system and device
drivers. Bootil1g begins in a Windows 2000 system by running code that is
resident in the system's ROM memory. This code directs the system to read
the boot code from the MBR. In addition to containing boot code, the MBR
contains a table listing the partitions for the hard disk and a flag indicating
which partition the system is to be booted from, as illustrated in Figure 12.9.
Once the system identifies the boot partition, it reads the first sector from that
partition (which is called the and contilmes with the remainder of
the boot process, which includes loading the various subsystems and system
services.
MBR
partition 1
partition 2
partition 3
partition 4
boot
code
partition
table
boot partition
Figure 12.9 Booting from disk in Windows 2000.
12.5 519
12.5.3 Bad Blocks
Because disks have moving parts and small tolerances (recall that the disk
head flies just above the disk surface), they are prone to failure. Sometimes the
failure is complete; in this case, the disk needs to be replaced and its contents
restored from backup media to the new disk. More frequently, one or more
sectors become defective. Most disks even con'le from the factory with
Depending on the disk and controller in use, these blocks are handled
in a variety of ways.
On simple disks, such as some disks with IDE controllers, bad blocks are
handled manually. For instance, the MS-DOS format command performs logical
formatting and, as a part of the process, scans the disk to find bad blocks. If
format finds a bad block, it writes a special value into the corresponding FAT
entry to tell the allocation routines not to use that block. If blocks go bad during
normal operation, a special program (such as chkdsk) must be run manually
to search for the bad blocks and to lock them away. Data that resided on the
bad blocks usually are lost.
More sophisticated disks, such as the SCSI disks used in high-end PCs
and most workstations and servers, are smarter about bad-block recovery. The
controller maintains a list of bad blocks on the disk. The list is initialized during
the low-level formatting at the factory and is updated over the life of the disk.
Low-level formatting also sets aside spare sectors not visible to the operating
system. The controller can be told to replace each bad sector logically with one
of the spare sectors. This scheme is known as or
A typical bad-sector transaction might be as follows:
The operating system tries to read logical block 87.
The controller calculates the ECC and finds that the sector is bad. It reports
this finding to the operating system.
The next time the system is rebooted, a special command is run to tell the
SCSI controller to replace the bad sector with a spare.
After that, whenever the system requests logical block 87, the request is
translated into the replacement sector's address by the controller.
Note that such a redirection by the controller could invalidate any optimization
by the operating system's disk-scheduling algorithm! For this reason,
most disks are formatted to provide a few spare sectors in each cylinder and
a spare cylinder as well. When a bad block is remapped, the controller uses a
spare sector from the same cylinder, if possible.
As an alternative to sector some controllers can be instructed to
replace a bad block by Here is an example: Suppose that
logical block 17 becomes defective and the first available spare follows sector
202. Then, sector slipping remaps all the sectors front 17 to 202, moving them
all down one spot. That is, sector 202 is copied into the spare, then sector 201
into 202, then 200 into 201, and so on, until sector 18 is copied into sector 19.
Slipping the sectors in this way frees up the space of sector 18, so sector 17 can
be mapped to it.
The replacement of a bad block generally is not totally automatic because
the data in the bad block are usually lost. Soft errors may trigger a process in
520 Chapter 12
12.6
which a copy of the block data is made and the block is spared or slipped.
An unrecoverable howeverf results in lost data. Whatever file was
using th.at block must be repaired (for instancef by restoration from a backup
tape)f and that requires manual intervention.
Swapping was first presented in Section 8.2f where we discussed moving
entire processes between disk and main memory. Swapping in that setting
occurs when the amount of physical memory reaches a critically low point and
processes are moved from memory to swap space to free available memory.
In practicef very few modern operating systems implement swapping in
this fashion. Rathel~ systems now combine swapping with virtual memory
techniques (Chapter 9) and swap pagesf not necessarily entire processes. In
fact some systems now use the terms swapping and paging interchangeablyf
reflecting the merging of these two concepts.
is another low-level task of the operating
system. Virtual memory uses disk space as an extension of main memory.
Since disk access is much slower than memory accessf using swap space
significantly decreases system performance. The main goal for the design and
implementation of swap space is to provide the best throughput for the virtual
memory system. In this sectionf we discuss how swap space is usedf where
swap space is located on diskf and how swap space is managed.
12.6.1 Swap-Space Use
Swap space is used in various ways by different operating systemsf depending
on the memory-management algorithms in use. For instancef systems that
implement swapping may use swap space to hold an entire process imagef
including the code and data segments. Paging systems may simply store pages
that have been pushed out of main memory. The amount of swap space needed
on a system can therefore vary from a few megabytes of disk space to gigabytesf
depending on the amow1.t of physical memoryf the amount of virtual memory
it is backingf and the way in which the virtual memory is used.
Note that it may be safer to overestimate than to underestimate the amount
of swap space requiredf because if a system runs out of swap space it may be
forced to abort processes or may crash entirely. Overestimation wastes disk
space that could otherwise be used for filesf but it does no other harm. Some
systems recommend the amount to be set aside for swap space. Solarisf for
examplef suggests setting swap space equal to the amount by which virtual
memory exceeds pageable physical memory. In the past Linux has suggested
setting swap space to double the amount of physical memoryf although most
Linux systems now use considerably less swap space. In factf there is currently
much debate in the Linux community about whether to set aside swap space
at all!
Some operating systems-including Linux-allow the use of multiple
swap spaces. These swap spaces are usually put on separate disks so that the
load placed on the I/0 system. by paging and swapping can be spread over the
systemfs I/O devices.
12.6 521
12.6.2 Swap-Space Location
A swap space can reside in one of two places: it can be carved out of the
normal file system, or it can be in a separate disk partition. If the swap space
is simply a large file within the file system, normal file-system routines can be
used to create it, name it and allocate its space. This approach, though easy
to implement is inefficient. Navigating the directory structure and the diskallocation
data structures takes time and (possibly) extra disk accesses. External
fragmentation can greatly increase swapping times by forcing multiple seeks
during reading or writing of a process image. We can improve performance
by caching the block location information in physical memory and by using
special tools to allocate physically contiguous blocks for the swap file, but the
cost of traversing the file-system data structures remains.
Alternatively, swap space can be created in a separate partition. No
file system or directory structure is placed in this space. Rather, a separate
swap-space storage manager is used to allocate and deallocate the blocks
from the raw partition. This manager uses algorithms optimized for speed
rather than for storage efficiency, because swap space is accessed much more
frequently than file systems (when it is used). Internal fragmentation may
increase, but this trade-off is acceptable because the life of data in the swap
space generally is much shorter than that of files in the file system. Since
swap space is reinitialized at boot time, any fragmentation is short-lived. The
raw-partition approach creates a fixed amount of swap space during disk
partitioning. Adding more swap space requires either repartitioning the disk
(which involves moving the other file-system partitions or destroying them
and restoring them from backup) or adding another swap space elsewhere.
Some operating systems are flexible and can swap both in raw partitions
and in file-system space. Linux is an example: the policy and implementation
are separate, allowing the machine's administrator to decide which type of
swapping to use. The trade-off is between the convenience of allocation and
management in the file system and the performance of swapping in raw
partitions.
12.6.3 Swap-Space Management: An Example
We can illustrate how swap space is used by following the evolution of
swapping and paging in various UNIX systems. The traditional UNIX kernel
started with an implementation of swapping that copied entire processes
between contiguous disk regions and memory. UNIX later evolved to a
combination of swapping and paging as pagiltg hardware became available.
In Solaris 1 (SunOS), the designers changed standard UNIX methods to
improve efficiency and reflect technological developments. When a process
executes, text-segment pages containing code are brought in from the file
system, accessed in main memory, and thrown away if selected for pageout. It
is more efficient to reread a page from the file system than to write it to swap
space and then reread it from there. Swap space is only used as a backing store
for pages of memory, which includes memory allocated for the
stack, heap, and uninitialized data of a process.
More changes were made in later versions of Solaris. The biggest change
is that Solaris now allocates swap space only when a page is forced out of
physical memory, rather than when the virtual memory page is first created.
522 Chapter 12
12.7
swap partition
or swap file
swap map
1---------swap area--------1
page
I- slot -1
L---~---~---_L __ _L _ ~
Figure 12.10 The data structures for swapping on Linux systems.
This scheme gives better performance on modern computers, which have more
physical memory than older systems and tend to page less.
Linux is similar to Solaris in that swap space is only used for anonymous
memory or for regions of memory shared by several processes. Linux allows
one or more swap areas to be established. A swap area may be in either a swap
file on a regular file system or a raw-swap-space partition. Each swap area
consists of a series of 4-KB which are used to hold swapped pages.
Associated with each swap area is a .u1.2.p-an array of integer counters,
each corresponding to a page slot in the swap area. If the value of a counter is 0,
the corresponding page slot is available. Values greater than 0 indicate that the
page slot is occupied by a swapped page. The value of the counter iJ.l.dicates the
number of mappings to the swapped page; for example, a value of 3 indicates
that the swapped page is mapped to three different processes (which can occur
if the swapped page is storing a region of memory shared by three processes).
The data structures for swapping on Linux systems are shown in Figure 12.10.
Disk drives have continued to get smaller and cheaper, so it is now economically
feasible to attach many disks to a computer system. Having a large number
of disks in a system presents opportunities for improving the rate at which data
can be read or written, if the disks are operated in parallel. Furthermore, this
setup offers the potential for improving the reliability of data storage, because
redundant information can be stored on multiple disks. Thus, failure of one disk
does not lead to loss of data. A of disk-organization techniques, collectively
called disks (RAIDs), are commonly
used to address the performance and reliability issues.
In the past, RAIDs composed of small, cheap disks were viewed as a
cost-effective alternative to large, expensive disks; today, RAIDs are used for
their higher reliability and higher data-transfer rate, rather than for economic
reasons. Hence, the I in RAID, which once stood for   inexpensive/' now stands
for   iJ.l.dependent.  
12.7.1 Improvement of Reliability via Redundancy
Let us first consider the reliability of RAIDs. The chance that some disk out of
a set of N disks will fail is much higher than the chance that a specific single
12.7 523
STRUCTURING RAID
RAID storage can be structured in a variety of ways. For example, a system
can have disks directly attached to its buses. In this case, the operating
system or system software can implement RAID flmctionality. Alternatively,
an intelligent host controller can control multiple attached disks and can
implement RAID on those disks in hardware. Finally, a , or
can be used. A RAID array is a standalone unit with its own controller,
cache (usually), and disks. It is attached to the host via one or more standard
ATA SCSI or FC controllers. This common setup allows any operating system
and software without RAID functionality to have RAID-protected disks. It
is even used on systems that do have RAID software layers because of its
simplicity and flexibility.
disk will fail. Suppose that the of a single disk is 100,000
hours. Then the mean time to failure of some disk in an array of 100 disks
will be 100,000/100 = 1,000 hours, or 41.66 days, which is not long at all! If we
store only one copy of the data, then each disk failure will result in loss of a
significant amount of data -and such a high rate of data loss is unacceptable.
The solution to the problem of reliability is to introduce , we
store extra information that is not normally needed but that can be used in the
event of failure of a disk to rebuild the lost information. Thus, even if a disk
fails, data are not lost.
The simplest (but most expensive) approach to introducing redundancy
is to duplicate every disk. This technique is called With mirroring,
a logical disk consists of two physical disks, and every write is carried out
on both disks. The result is called a mirrored volume. If one of the disks in the
volume fails, the data can be read from the other. Data will be lost only if the
second disk fails before the first failed disk is replaced.
The mean time to failure of a mirrored volume-where failure is the loss
of data- depends on two factors. One is the mean time to failure of the
individual disks. The other is the which is the time it
takes (on average) to replace a failed disk and to restore the data on it. Suppose
that the failures of the two disks are that is, the failure of one disk
is not connected to the failure of the other. Then, if the mean time to failure of a
single disk is 100,000 hours and the mean time to repair is 10 hours, the
of a mirrored disk system is 100, 0002 /(2    10) = 500    106
hours, or 57,000 years!
You should be aware that the assumption of independence of disk failures
is not valid. Power failures and natural disasters, such as earthquakes, fires,
and floods, may result in damage to both disks at the same time. Also,
manufacturing defects in a batch of disks can cause correlated failures. As
disks age, the probability of failure grows, increasing the chance that a second
disk will fail while the first is being repaired. In spite of all these considerations,
however, n1.irrored-disk systems offer much higher reliability than do singledisk
systems.
Power failures are a particular source of concern, since they occur far more
frequently than do natural disasters. Even with mirroring of disks, if writes are
524 Chapter 12
in progress to the same block in both disks, and power fails before both blocks
are fully written, the two blocks can be in an inconsistent state. One solution
to this is to write one copy first then the next. Another is to add a
cache to the RAID array. This write-back cache is
protected from data loss during power failures, so the write can be considered
complete at that point, assuming the NVRAM has some kind of error protection
and correction, such as ECC or mirroring.
12.7.2 Improvement in Performance via Parallelism
Now let's consider how parallel access to multiple disks improves performance.
With disk mirroring, the rate at which read requests can be handled is
doubled, since read requests can be sent to either disk (as long as both disks
in a pair are functionat as is almost always the case). The transfer rate of each
read is the same as in a single-disk system, but the number of reads per unit
time has doubled.
With multiple disks, we can improve the transfer rate as well (or instead)
by striping data across the disks. In its simplest form, consists
of the bits of each byte across multiple disks; such striping is called
For example, if we have an array of eight disks, we write bit
i of each byte to disk i. The array of eight disks can be treated as a single disk
with sectors that are eight times the normal size and, more important that have
eight times the access rate. In such an organization, every disk participates in
every access (read or write); so the number of accesses that can be processed
per second is about the same as on a single disk, but each access can read eight
times as many data in the same time as on a single disk.
Bit-level striping can be generalized to include a number of disks that either
is a multiple of 8 or divides 8. For example, if we use an array of four disks,
bits i and 4 + i of each go to disk i. Further, striping need not occur at
the bit level. In for instance, blocks of a file are striped
across multiple disks; with n disks, block i of a file goes to disk (i mod n) + 1.
Other levels of striping, such as bytes of a sector or sectors of a block, also are
possible. Block-level striping is the most common.
Parallelism in a disk system, as achieved through striping, has two main
goals:
Increase the throughput of multiple small accesses (that is, page accesses)
by load balancing.
Reduce the response time of large accesses.
12.7.3 RAID Levels
Mirroring provides high reliability, but it is expensive. Striping provides high
data-transfer rates, but it does not improve reliability. Numerous schemes
to provide redundancy at lower cost by using disk striping combined with
  parity   bits (which we describe next) l1.ave been proposed. These schemes
have different cost-performance trade-offs and are classified according to
levels called We describe the various levels here; Figure 12.11
shows them pictorially (in the figure, P indicates error-correcting bits, and C
12.7 RAID Structure 525
(a) RAID 0: non-redundant striping.
(b) RAID 1: mirrored disks.
(c) RAID 2: memory-style error-correcting codes.
{d) RAID 3: bit-interleaved parity.
(e) RAID 4: block-interleaved parity.
{f) RAID 5: block-interleaved distributed parity.
(g) RAID 6: P + Q redundancy.
Figure 12.11 RAID levels.
indicates a second copy. of the data). In all cases depicted in the figure, four
disks' worth of data are stored, and the extra disks are used to store redundant
information for failure recovery.
  RAID level 0. RAID level 0 refers to disk arrays with striping at the level of
blocks but without any redundancy (such as mirroring or parity bits), as
shown in Figure 12.1l(a).
  RAID Ievell. RAID level1 refers to disk mirroring. Figure 12.1l(b) shows
a mirrored organization.
  ' RAID level2. RAID level2 is also known as memory-style error-correctingcode
(ECC) organization. Memory systems have long detected certain
errors by using parity bits. Each byte in a memory system may have a
parity bit associated with it that records whether the number of bits in the
byte set to 1 is even (parity= 0) or odd (parity= 1). If one of the bits in the
526 Chapter 12
byte is damaged (either a 1 becomes a 0, or a 0 becomes an the parity of
the byte changes and thus does not match the stored parity. Similarly, if the
stored parity bit is damaged, it does not match the computed parity. Thus,
all single-bit errors are detected by the menwry system .. Error-correcting
schemes store two or more extra bits and can reconstruct the data if a
single bit is damaged. The idea of ECC can be  used directly in disk arrays
via striping of bytes across disks. For example, the first bit of each byte can
be stored in disk 1, the second bit in disk 2, and so on until the eighth bit
is stored in disk 8; the error-correction bits are stored in further disks. This
scheme is shown pictorially in Figure 12.1l(c), where the disks labeled P
store the error-correction bits. If one of the disks fails, the remaining bits
of the byte and the associated error-correction bits can be read from other
disks and used to reconstruct the damaged data. Note that RAID level 2
requires only three disks' overhead for four disks of data, unlike RAID level
1, which requires four disks' overhead.
RAID level 3. RAID level 3, or
improves on level 2 by taking into account the fact that, unlike memory
systems, disk controllers can detect whether a sector has been read
correctly, so a single parity bit can be used for error correction as well as
for detection. The idea is as follows: If one of the sectors is damaged, we
know exactly which sector it is, and we can figure out whether any bit in
the sector is a 1 or a 0 by computing the parity of the corresponding bits
from sectors in the other disks. If the parity of the remaining bits is equal
to the stored parity, the missing bit is 0; otherwise, it is 1. RAID level3 is as
good as level 2 but is less expensive in the number of extra disks required
(it has only a one-disk overhead), so level 2 is not used in practice. This
scheme is shown pictorially in Figure 12.1l(d).
RAID level 3 has two advantages over level 1. First, the storage overhead
is reduced because only one parity disk is needed for several regular
disks, whereas one mirror disk is needed for every disk in level1. Second,
since reads and writes of a byte are spread out over multiple disks with
N-way striping of data, the transfer rate for reading or writing a single
block is N times as fast as with RAID level 1. On the negative side, RAID
level3 supports fewer l/Os per second, since every disk has to participate
in every I/0 request.
A further performance problem with RAID 3-and with all paritybased
RAID levels-is the expense of computing and writing the parity.
This overhead results in significantly slower writes than with non-parity
RAID arrays. To moderate this performance penalty, many RAID storage
arrays include a hardware controller with dedicated parity hardware. This
controller offloads the parity computation from the CPU to the array. The
array has an NVRAM cache as well, to store the blocks while the parity is
computed and to buffer the writes from the controller to the spindles. This
combination can make parity RAID almost as fast as non-parity. In fact, a
caching array doing parity RAID can outperform a non-caching non-parity
RAID.
RAID level 4. RAID level4, or uses
block-level striping, as in RAID 0, and in addition keeps a parity block on a
separate disk for corresponding blocks from N other disks. This scheme is
12.7 527
diagramed in Figure 12.1l(e). If one of the disks fails, the parity block can
be used with the corresponding blocks from the other disks to restore the
blocks of the failed disk.
A block read accesses only one disk, allowing other requests to be
processed by the other disks. Thus, the data-transfer rate for each access
is slowe1~ but multiple read accesses can proceed in parallel, leading to a
higher overall I/0 rate. The transfer rates for large reads are high, since all
the disks can be read in parallel; large writes also have high transfer rates,
since the data and parity can be written in parallel.
Small independent writes cannot be performed in parallel. An operatingsystem
write of data smaller than a block requires that the block be read,
modified with the new data, and written back The parity block has to be
updated as well. This is known as the   sYTi:.e . Thus, a
single write requires four disk accesses: two to read the two old blocks and
two to write the two new blocks.
WAFL (Chapter 11) uses RAID level4 because this RAID level allows disks
to be added to a RAID set seamlessly. If the added disks are initialized with
blocks containing all zeros, then the parity value does not change, and the
RAID set is still correct.
RAID levelS. RAID levelS, or , differs
from level 4 by spreading data and parity among all N + 1 disks, rather
than storing data in N disks and parity in one disk. For each block, one of
the disks stores the parity, and the others store data. For example, with an
array of five disks, the parity for the nth block is stored in disk (n mod 5)+ 1;
the nth blocks of the other four disks store actual data for that block This
setup is shown in Figure 12.11(f), where the Ps are distributed across all
the disks. A parity block cannot store parity for blocks in the same disk,
because a disk failure would result in loss of data as well as of parity, and
hence the loss would not be recoverable. By spreading the parity across
all the disks in the set, RAID 5 avoids potential overuse of a single parity
disk, which can occur with RAID 4. RAID 5 is the most common parity RAID
system.
RAID level 6. RAID level 6, also called the is
much like RAID level 5 but stores extra redundant information to guard
against disk failures. Instead of parity, error-correcting codes such
as the are used. In the scheme shown in Figure
12.11(g), 2 bits of redundant data are stored for every 4 bits of datacompared
with 1 parity bit in level 5-and the system can tolerate two
disk failures.
RAID levels 0 + 1 and 1 + 0. RAID level 0 + 1 refers to a combination of RAID
levels 0 and 1. RAID 0 provides the performance, while RAID 1 provides
the reliability. Generally, this level provides better performance than RAID
5. It is common in enviromnents where both performance and reliability
are important. Unfortunately, like RAID 1, it doubles the number of disks
needed for storage, so it is also relatively expensive. In RAID 0 + 1, a set
of disks are striped, and then the stripe is mirrored to another, equivalent
stripe.
528 Chapter 12
stripe
a) RAID 0 + 1 with a single disk failure.
uA
mirror
b) RAID 1 + 0 with a single disk failure.
Figure 12.12 RAID 0 + 1 and 1 + 0.
Another RAID option that is becoming available commercially is RAID
level 1 + 0, in which disks are mirrored in pairs and then the resulti.J.l.g
mirrored pairs are striped. This scheme has some theoretical advantages
over RAID 0 + 1. For example, if a single disk fails in RAID 0 + 1, an entire
stripe is inaccessible, leaving only the other stripe available. With a failure
in RAID 1 + 0, a single disk is unavailable, but the disk that mirrors it is still
available, as are all the rest of the disks (Figure 12.12).
Numerous variations have been proposed to the basic RAID schemes described
here. As a result, some confusion may exist about the exact definitions of the
different RAID levels.
The implementation of RAID is another area of variation. Consider the
following layers at which RAID can be implemented.
Volume-management software can implement RAID within the kernel or
at the system software layer. In this case, the storage hardware can provide
a minimum of features and still be part of a full RAID solution. Parity RAID
is fairly slow when implemented in software, so typically RAID 0, 1, or 0 +
1 is used.
RAID can be implemented in the host bus-adapter (HBA) hardware. Only
the disks directly connected to the HBA can be part of a given RAID set.
This solution is low in cost but not very flexible.
12.7 529
RAID can be implemented in the hardware of the storage array. The storage
array can create RAID sets of various levels and can even slice these sets
into smaller volumes, which are then presented to the operating system.
The operating system need only implement the file system on each of the
volumes. Arrays can have multiple connections available or can be part of
a SAN, allowing multiple hosts to take advantage of the array's features.
RAID can be implemented in the SAN interconnect layer by disk virtualization
devices. In this case, a device sits between the hosts and the storage.
It accepts commands from the servers and manages access to the storage.
It could provide mirroring, for example, by writing each block to two
separate storage devices.
Other features, such as and replication, can be implemented at
each of these levels as well. involves the automatic duplication of
writes between separate sites for redundancy and disaster recovery. Replication
can be synchronous or asynchronous. In synchronous replication, each block
must be written locally and remotely before the write is considered complete,
whereas in asynchronous replication, the writes are grouped together and
written periodically. Asynchronous replication can result in data loss if the
primary site fails, but it is faster and has no distance limitations.
The implementation of these features differs depending on the layer at
which RAID is implemented. For example, if RAID is implemented in software,
then each host may need to carry out and manage its own replication. If
replication is implemented in the storage array or in the SAN intercom1ect,
however, then whatever the host operating system or its features, the host's
data can be replicated.
One other aspect of most RAID implementations is a hot spare disk or disks.
A is not used for data but is configured to be used as a replacement in
case disk failure. For instance, a hot spare can be used to rebuild a mirrored
pair should one of the disks in the pair fail. In this way, the RAID level can be
reestablished automatically, without waiting for the failed disk to be replaced.
Allocating more than one hot spare allows more than one failure to be repaired
without human intervention.
12.7.4 Selecting a RAID Level
Given the many choices they have, how do system designers choose a RAID
level  One consideration is rebuild performance. If a disk fails, the time needed
to rebuild its data can be significant. This may be an important factor if a
continuous supply of data is required, as it is in high-performance or interactive
database systems. Furthermore, rebuild performance influences the mean time
to failure.
Rebuild performance varies with the RAID level used. Rebuilding is easiest
 or RAID level1, since data can be copied from another disk; for the other levels,
we need to access all the other disks in the array to rebuild data in a failed disk.
Rebuild times can be hours for RAID 5 rebuilds of large disk sets.
RAID level 0 is used in high-performance applications where data loss is
not critical. RAID level1 is popular for applications that require high reliability
with fast recovery. RAID 0 + 1 and 1 + 0 are used where both performance and
reliability are important-for example, for small databases. Due to RAID 1's
530 Chapter 12
THE InServ STORAGE ARRAY
Im1ovation, in an effort to provide better, faster, and less expensive solutions,
frequently blurs the lines that separated previous technologies. Consider the
InServ storage array from 3Par. Unlike most other storage arrays, InServ
does not require that a set of disks be configured at a specific RAID level.
Rather, each disk is broken into 256-MB   chunklets.   RAm is then applied at
the chunklet level. A disk can thus participate in multiple and various RAID
levels as its chunklets are used for multiple volumes.
InServ also provides snapshots similar to those created by the WAFL file
system. The format of InServ snapshots can be read-write as well as readonly,
allowing multiple hosts to mount copies of a given file system without
needing their own copies of the entire file system. Any changes a host makes
in its own copy are copy-on-write and so are not reflected in the other copies.
A further innovation is . Some file systems do not expand
or shrink On these systems, the original size is the only size, and any change
requires copying data. An administrator can configure InServ to provide a
host with a large amount of logical storage that initially occupies only a small
amount of physical storage. As the host starts using the storage, unused disks
are allocated to the host, up to the original logical level. The host thus can
believe that it has a large fixed storage space, create its file systems there, and
so on. Disks can be added or removed from the file system by InServ without
the file systems noticing the change. This feature can reduce the number of
drives needed by hosts, or at least delay the purchase of disks until they are
really needed.
high space overhead, RAID levelS is often preferred for storing large volumes
of data. Level6 is not supported currently by many RAID implementations, but
it should offer better reliability than levelS.
RAID system designers and administrators of storage have to make several
other decisions as well. For example, how many disks should be in a given
RAID set  How many bits should be protected by each parity bit  If more disks
are in an array, data-transfer rates are higher, but the system is more expensive.
If more bits are protected by a parity bit, the space overhead due to parity bits
is lower, but the chance that a second disk will fail before the first failed disk is
repaired is greater, and that will result in data loss.
12.7.5 Extensions
The concepts of RAID have been generalized to other storage devices, including
arrays of tapes, and even to the broadcast of data over wireless systems. When
applied to arrays of tapes, RAID structures are able to recover data even if one
of the tapes in an array is damaged. When applied to broadcast of data, a
block of data is split into short units and is broadcast along with a parity unit;
if one of the units is not received for any reason, it can be reconstructed from the
other units. Comrnonly, tape-drive robots containing multiple tape drives will
stripe data across all the drives to increase throughput and decrease backup
time.
12.7 531
12.7.6 Problems with RAID
Unfortunately, RAID does not always assure that data are available for the
operating system and its users. A pointer to a file could be wrong, for example,
or pointers within the file structure could be wrong. Incomplete writes, if not
properly recovered, could result in corrupt data. Some other process could
accidentally write over a file system's structures, too. RAID protects against
physical media errors, but not other hardware and software errors. As large as
is the landscape of software and hardware bugs, that is how numerous are the
potential perils for data on a system.
The Solaris ZFS file system takes an innovative approach to solving these
problems through the use of - a technique which is used to verify
the integrity of data. ZFS maintains internal checksums of all blocks, including
data and metadata. These checksums are not kept with the block that is being
checksummed. Rathel~ they are stored with the pointer to that block. (See
figure 12.13.) Consider an inode with pointers to its data. Within the inode is
the checksum of each block of data. If there is a problem with the data, the
checksum will be incorrect and the file system will know about it. If the data
are mirrored, and there is a block with a correct checksum and one with an
incorrect checksum, ZFS will automatically update the bad block with the good
one. Similarly, the directory entry that points to the inode has a checksum for the
inode. Any problem in the inode is detected when the directory is accessed.
This checksumming takes places throughout all ZFS structures, providing a
much higher level of consistency, error detection, and error correction than is
found in RAID disk sets or standard file systems. The extra overhead that is
created by the checksum calculation and extra block read-modify-write cycles
is not noticeable because the overall performance of ZFS is very fast.
Another issue with most RAID implementations is lack of flexibility.
Consider a storage array with twenty disks divided into four sets of five disks.
Each set of five disks is a RAID level 5 set. As a result, there are four separate
data 1
Figure 12.13 ZFS checksums all metadata and data.
532 Chapter 12
volumes, each holding a file system. But what if one file system is too large
to fit on a five-disk RAID level 5 set   And what if another file system needs
very little space  If such factors are known ahead of time, then the disks and
volumes can be properly allocated. Very frequently, however, disk use and
requirements change over time.
Even if the storage array allowed the entire set of twenty disks to be
created as one large RAID set other issues could arise. Several volumes of
various sizes could be built on the set. But some volume managers do not
allow us to change a volume's size. In that case, we would be left with the same
issue described above-mismatched file-system sizes. Some volume n  lanagers
allow size changes, but some file systems do not allow for file-system growth
or shrinkage. The volumes could change sizes, but the file systems would need
to be recreated to take advantage of those changes.
ZFS combines file-system management and volume management into a
unit providing greater functionality than the traditional separation of those
functions allows. Disks, or partitions of disks, are gathered together via RAID
sets into of storage. A pool can hold one or more ZFS file systems. The
entire pool's free space is available to all file systems within that pool. ZFS uses
the memory model of   malloc   and   free   to allocate and release storage for
each file system as blocks are used and freed within the file system. As a result
there are no artificial limits on storage use and no need to relocate file systems
between volumes or resize volumes. ZFS provides quotas to limit the size of a
file system and reservations to assure that a file system can grow by a specified
amount, but those variables may be changed by the file system owner at any
time. Figure 12.14(a) depicts traditional volumes and file systems, and Figure
12.14(b) shows the ZFS model.
I FS I
~ (a) Traditional volumes and file systems.
(b) ZFS and pooled storage.
Figure 12.14 (a) Traditional volumes and file systems. (b) A ZFS pool and file systems.
12.8
12.8 533
In Chapter 6, we introduced the write-ahead log, which requires the availability
of stable storage. By definition, information residing in stable storage is never
lost. To implement such storage, we need to replicate the required information
on multiple storage devices (usually disks) with independent failure modes.
We also need to coordinate the writing of updates in a way that guarantees
that a failure during an update will not leave all the copies in a damaged state
and that, when we are recovering from a failure, we can force all copies to a
consistent and correct value, even if another failure occurs during the recovery.
In this section, we discuss how to meet these needs.
A disk write results in one of three outcomes:
Successful completion. The data were written correctly on disk.
Partial failure. A failure occurred in the midst of transfer, so only some of
the sectors were written with the new data, and the sector being written
during the failure may have been corrupted.
Total failure. The failure occurred before the disk write started, so the
previous data values on the disk remain intact.
Whenever a failure occurs during writing of a block, the system needs to
detect it and invoke a recovery procedure to restore the block to a consistent
state. To do that, the system must maintain two physical blocks for each logical
block. An output operation is executed as follows:
Write the information onto the first physical block.
When the first write completes successfully, write the same inJormation
onto the second physical block.
Declare the operation complete only after the second write completes
successfully.
During recovery from a failure, each pair of physical blocks is examined.
If both are the same and no detectable error exists, then no further action is
necessary. If one block contains a detectable error, then we replace its contents
with the value of the other block. If neither block contains a detectable error,
but the blocks differ in content, then we replace the content of the first block
with that of the second. This recovery procedure ensures that a write to stable
storage either succeeds completely or results in no change.
We can extend this procedure easily to allow the use of an arbitrarily large
number of copies of each block of stable storage. Although having a large
number of copies further reduces the probability of a failure, it is usually
reasonable to simulate stable storage with only two copies. The data in stable
storage are guaranteed to be safe unless a failure destroys all the copies.
Because waiting for disk writes to complete (synchronous I/O) is time
consuming, many storage arrays add NVRAM as a cache. Since the memory is
nonvolatile (it usually has battery power to back up the unit's power), it can
be trusted to store the data en route to the disks. It is thus considered part of
534 Chapter 12
12.9
the stable storage. Writes to it are much faster than to disk, so performance is
greatly improved.
Would you buy a DVD or CD player that had one disk sealed inside  Of course
not. You expect to use a DVD or CD player with many relatively inexpensive
disks. On a computer as well, using many inexpensive cartridges with one
drive lowers the overall cost. Low cost is the defining characteristic of tertiary
storage, which we discuss in this section.
12.9.1 Tertiary-Storage Devices
Because cost is so important, in practice, tertiary storage is built with
The most common examples are floppy disks, tapes, and read-only,
write-once, and rewritable CDs and DVDs. Many any other kinds of tertiarystorage
devices are available as well, including removable devices that store
data in flash memory and interact with the computer system via a USB interface.
12.9.1.1 Removable Disks
Removable disks are one kind of tertiary storage. Floppy disks are an example
of removable magnetic disks. They are made from a thin, flexible disk coated
with magnetic material and enclosed in a protective plastic case. Although
common floppy disks can hold only about 1 MB, similar technology is used
for removable magnetic disks that hold more than 1 GB. Removable magnetic
disks can be nearly as fast as hard disks, although the recording stuface is at
greater risk of from scratches.
A is another kind of removable disk. It records data
on a rigid platter coated with magnetic material, but the recording technology
is quite different from that for a magnetic disk. The magneto-optic head flies
much farther from the disk surface than a magnetic disk head does, and the
magnetic material is covered with a thick protective layer of plastic or glass.
This arrangement makes the disk much more resistant to head crashes.
The magneto-optic disk drive has a coil that produces a magnetic field; at
room temperature, the field is too large and too weak to magnetize a bit on the
disk. To write a bit, the disk head flashes a laser beam at the disk surface. The
laser is aimed at a tiny spot where a bit is to be written. The laser heats this
spot, which makes the spot susceptible to the magnetic field. Now the large,
weak magnetic field can record a tiny bit.
The magneto-optic head is too far from the disk surface to read the data by
detecting the tiny magnetic fields in the way that the head of a hard disk does.
Instead, the drive reads a bit using a property of laser light called the
When a laser beam is bounced off of a magnetic spot, the polarization
of the laser beam is rotated clockwise or counterclockwise, dependin~g on the
orientation of the magnetic field. This rotation is what the head detects to read
a bit.
Another category of removable disk is the Optical disks do not
use magnetism at all. Instead, they use special materials that can be altered by
laser light to have relatively dark or bright spots. One exarnple of optical-disk
12.9 535
technology is the which is coated with a material that can
freeze into either a crystalline or an amorphous state. The crystalline state is
more transparent, and hence a laser beam is brighter when it passes through
the lTlaterial and bounces off the reflective layer. The phase-change drive uses
laser light at three different powers: low power to read data, medium power
to erase the disk by melting and refreezing the recording medium into the
crystalline state, and high power to melt the medium into the amorphous state
to write to the disk. The most common examples of this technology are the
re-recordable CD-RW and DVD-RW.
The kinds of disks just described can be used over and over. They are called
In contrast, can
be written only once. An old way to make a WORM disk is to manufacture a thin
aluminum film sandwiched between two glass or plastic platters. To write a
bit, the drive uses a laser light to burn a small hole through the aluminum. This
burning cannot be reversed. Although it is possible to destroy the information
on a WORM disk by burning holes everywhere, it is virtually impossible to alter
data on the disk, because holes can only be added, and the ECC code associated
with each sector is likely to detect such additions. WORM disks are considered
durable and reliable because the metal layer is safely encapsulated between
the protective glass or plastic platters and magnetic fields cannot damage the
recording. A newer write-once technology records on an organic polymer dye
instead of an aluminum layer; the dye absorbs laser light to form marks. This
technology is used in the recordable CD-R and DVD-R.
Read-oniv such as CD-ROM and DVD-ROM, come from the factory
with the data prerecorded. They use technology similar to that of WORM disks
(although the bits are pressed, not burned), and they are very durable.
Most removable disks are slower than their nonremovable counterparts.
The writing process is slower, as are rotation and sometimes seek time.
12.9.1.2 Tapes
Magnetic tape is another type of removable medium. As a general rule, a tape
holds more data than an optical or magnetic disk cartridge. Tape drives and
disk drives have similar transfer rates. But random access to tape is much
slower than a disk seek, because it requires a fast-forward or rewind operation
that takes tens of seconds or even minutes.
Although a typical tape drive is more expensive than a typical disk drive,
the price of a tape cartridge is lower than the price of the equivalent capacity
of magnetic disks. So tape is an economical medium for purposes that do not
require fast random access. Tapes are commonly used to hold backup copies
of disk data. They are also used in large supercomputer centers to hold the
enornwus volumes of data used in scientific research and by large commercial
enterprises.
Large tape installations typically use robotic tape changers that move tapes
between tape drives and storage slots in a tape library. These mechanisms give
the computer automated access to many tape cartridges.
A robotic tape library can lower the overall cost of data storage. A diskresident
file that will not be needed for a while can be to tape, where
the cost per gigabyte is lower; if the file is needed in the future, the computer
can it back into disk storage for active use. A robotic tape library is
536 Chapter 12
sometimes called storage, since it is between the high performance
of on-line magnetic disks and the low cost of off-line tapes sitting on shelves
in a storage room.
12.9.1.3 Future Technology
In the future, other storage technologies may become important. Sometimes old
technologies are used in new ways, as economics change or the technologies
evolve. For example, solid-state disks, or are growing in importance and
becoming more common. Simply described, an SSD is a disk that is used like
a hard drive. Depending on the memory technology used, it can be volatile
or nonvolatile. The memory technology also affects performance. Nonvolatile
SSDs have the same characteristics as traditional hard disks but can be more
reliable because they have no moving parts and faster because they have no
seek time or latency. In addition, they use less energy. However, they are more
expensive per megabyte than traditional hard disks, have lower capacity than
the larger hard disks, and may have shorter life-spans than hard disks; so their
uses are limited. In one example, SSDs are being used in storage arrays to hold
metadata which requires high-performance such as the journal of a journaling
file system. SSDs are also being added to notebook computers to make them
smaller, faster, and more energy efficient.
Another promising storage technology, bologt;;:phk uses laser
light to record holographic photographs on special media. We can think of a
hologram as a three-dimensional array of pixels. Each pixel represents one bit:
0 for black or 1 for white. And all the pixels in a hologram are transferred in one
flash of laser light, so the data transfer rate is extremely high. With continued
development, holographic storage may become commercially viable.
Another technology under active research is based on
(IV!E\1S). The idea is to apply the fabrication
technologies that produce electronic chips to the manufacture of small datastorage
machines. One proposal calls for the fabrication of an array of 10,000
tiny disk heads, with a square centimeter of magnetic storage material suspended
above the array. When the storage material is moved lengthwise over
the heads, each head accesses its own linear track of data on the material. The
storage material can be shifted sideways slightly to enable all the heads to
access their next track. Although it remains to be seen whether this technology
can be successful, it may provide a nonvolatile data-storage technology that is
faster than magnetic disk and cheaper than semiconductor DRAM.
Whether the storage medium is a removable magnetic disk, a DVD, or a
magnetic tape, the operating system needs to provide several capabilities to use
removable media for data storage. These capabilities are discussed in Section
12.9.2.
12.9.2 Operating-System Support
Two major jobs of an operating system are to manage physical devices and
to present a virtual machine abstraction to applications. In this chapter, we
have seen that, for hard disks, the operating system provides two abstractions.
One is the raw device, which is just an array of data blocks. The other is a file
system. For a file system on a magnetic disk, the operating system queues and
12.9 537
schedules the interleaved requests from several applications. Now, we shall see
how the operating system does its job when the storage media are removable.
12.9.2.1 Application Interface
Most operating systems can handle removable disks almost exactly as they do
fixed disks. When a blank cartridge is inserted into the drive (or mounted), the
cartridge must be formatted, and then an empty file system is generated on the
disk. This file system is used just like a file system on a hard disk
Tapes are often handled differently. The operating system usually presents
a tape as a raw storage medium. An application does not open a file on the
tape; it opens the whole tape drive as a raw device. Usually, the tape drive
is then reserved for the exclusive use of that application until the application
exits or closes the tape device. This exclusivity makes sense, because random
access on a tape can take tens of seconds, or even a few minutes, so interleaving
random accesses to tapes from more than one application would be likely to
cause thrashing.
When the tape drive is presented as a raw device, the operating system
does not provide file-system services. The application must decide how to use
the array of blocks. For instance, a program that backs up a hard disk to tape
might store a list of file names and sizes at the beginning of the tape and then
copy the data of the files to the tape in that order.
It is easy to see the problems that can arise from this way of using tape.
Since every application makes up its own rules for how to organize a tape,
a tape full of data can generally be used only by the program that created it.
For instance, even if we know that a backup tape contains a list of file names
and file sizes followed by the file data, we will still find it difficult to use the
tape. How exactly are the file names stored  Are the file sizes in binary or ASCII
form  Are the files written one per block, or are they all concatenated in one
tremendously long string of bytes  We do not even know the block size on the
tape, because this variable is generally one that can be chosen separately for
each block written.
For a disk drive, the basic operations are read(), write(), and seek().
Tape drives have a different set of basic operations. Instead of seek(), a tape
drive uses the locate() operation. The tape locate() operation is more
precise than the disk seek() operation, because it positions the tape to a
specific logical block, rather than an entire track. Locating to block 0 is the
same as rewinding the tape.
For most kinds of tape drives, it is possible to locate to any block that has
been written on a tape. In a partly filled tape, however, it is not possible to
locate into the empty space beyond the written area, because most tape drives
do not manage their physical space in the same way disk drives do. For a disk
drive, the sectors have a fixed size, and the formatting process must be used to
place empty sectors in their final positions before any data can be written. Most
tape drives have a variable block size, and the size of each block is detern  ined
on the fly, when that block is written. If an area of defective tape is encountered
during writing, the bad area is skipped and the block is written again. This
operation explains why it is not possible to locate into the empty space beyond
the written area -the positions and numbers of the logical blocks have not yet
been detennined.
538 Chapter 12
Most tape drives have a read_position() operation that returns the
logical block number where the tape head is currently located. Many tape
drives also support a space() operation for relative motion. So, for example,
the operation space ( -2) would locate backward over two logical blocks.
For most kinds of tape drives, writing a block has the side effect of logically
erasing everything beyond the position of the write. In practice, this side effect
means that most tape drives are append-only devices, because updating a
block in the middle of the tape also effectively erases everything beyond that
block. The tape drive implements this appending by placing an end-of-tape
(EOT) mark after a block that is written. The drive refuses to locate past the EOT
mark, but it is possible to locate to the EOT and then start writing. Doing so
overwrites the old EOT mark and places a new one at the end of the new blocks
just written.
In principle, a file system can be implemented on a tape. But many of the
file-system data structures and algorithms would be different from those used
for disks, because of the append-only property of tape.
12.9.2.2 File Naming
Another question that the operating system needs to handle is how to name
files on removable media. For a fixed disk, naming is not difficult. On a PC, the
file name consists of a drive letter followed by a path name. In UNIX, the file
name does not contain a drive letter, but the moLmt table enables the operating
system to discover on what drive the file is located. If the disk is removable,
however, knowing what drive contained the cartridge at some time in the past
does not mean knowing how to find the file. If every removable cartridge in
the world had a different serial number, the name of a file on a removable
device could be prefixed with the serial number, but to ensure that no two
serial numbers are the same would require each one to be about 12 digits in
length. Who could remember the names of her files if she had to memorize a
12-digit serial number for each one 
The problem becomes even more difficult when we want to write data
on a removable cartridge on one computer and then use the cartridge in
another computer. If both machines are of the same type and have the same
kind of removable drive, the only difficulty is knowing the contents and data
layout on the cartridge. But if the machines or drives are different, many
additional problems can arise. Even if the drives are compatible, different
computers may store bytes in different orders and may use different encodings
for binary numbers and even for letters (such as ASCII on PCs versus EBCDIC
on mainframes).
Today's operating systems generally leave the name-space problem
unsolved for removable media and depend on applications and users to figure
out how to access and interpret the data. Fortunately, a few kinds of removable
media are so well standardized that all computers use them the same way. One
example is the CD. Music CDs use a universal format that is understood by any
CD drive. Data CDs are available in only a few different formats, so it is usual
for a CD drive and the operating-system device driver to be programmed to
handle all the comn1on formats. DVD fonnats are also well standardized.
12.9 539
12.9.2.3 Hierarchical Storage Management
A JU enables the computer to change the removable cartridge in a
tape or disk drive without human assistance. Two major uses of this technology
are for backups and hierarchical storage systems. The use of a jukebox for
backups is simple: When one cartridge becomes full, the computer instructs
the jukebox to switch to the next cartridge. Some jukeboxes hold tens of drives
and thousands of cartridges, with robotic arms managing the movement of
tapes to the drives.
A hierarchical storage system extends the storage hierarchy beyond
primary memory and secondary storage (that is, magnetic disk) to incorporate
tertiary storage. Tertiary storage is usually implemented as a jukebox of tapes
or removable disks. This level of the storage hierarchy is larger, cheaper, and
slower.
Although the virtual memory system can be extended in a straightforward
manner to tertiary storage, this extension is rarely carried out in practice. The
reason is that a retrieval from a jukebox can take tens of seconds or even
minutes, and such a long delay is intolerable for demand paging and for other
forms of virtual memory use.
The usual way to incorporate tertiary storage is to extend the file system.
Small and frequently used files remain on magnetic disk, while large and old
files that are not actively used are archived to the jukebox. In some file-archiving
systems, the directory entry for the file continues to exist, but the contents of
the file no longer occupy space in secondary storage. If an application tries to
open the file, the open () system call is suspended until the file contents can
be staged in from tertiary storage. When the contents are again available from
magnetic disk, the open () operation returns control to the application, which
proceeds to use the disk-resident copy of the data.
Today, is usually found in installations
that have large volumes of data that are used seldom, sporadically,
Current work in HSM includes extending it to provide full
Here, data move from disk to tape
and back to disk, as needed, but are deleted on a schedule or according to
policy. For example, some sites save e-mail for seven years but want to be sure
that at the end of seven years it is destroyed. At that point, the data might be
on disk, HSM tape, and backup tape. ILM centralizes knowledge of where the
data are so that policies can be applied across all these locations.
12.9.3 Performance Issues
As with any component of the operating system, the three most important
aspects of tertiary-storage performance are speed, reliability, and cost.
12.9.3.1 Speed
The speed of tertiary storage has two aspects: bandwidth and latency. We
measure the bandwidth in bytes per second. The  ~'L' is
the average data rate during a transfer-that is, the number of bytes
divided by the transfer time. The calculates the average
over the entire l/0 time, including the time for seek() or locate() and any
540 Chapter 12
cartridge-switching time in a jukebox. In essence, the sustained bandwidth is
the rate at which the data stream actually flows, and the effective bandwidth is
the overall data rate provided by the drive. The bandwidth of a drive is generally
understood to mean the sustained bandwidth.
For removable disks, tlce bandwidth ranges from a few megabytes per
second for the slowest to over 40 MB per second for the fastest. Tapes have a
similar range of bandwidths, from a few megabytes per second to over 30MB
per second.
The second aspect of speed is the . By this performance
measure, disks are much faster than tapes. Disk storage is essentially twodimensional-
all the bits are out in the open. A disk access simply moves the
ann to the selected cylinder and waits for the rotational latency, which may
take less than 5 milliseconds. By contrast, tape storage is three-dimensional.
At any time, a small portion of the tape is accessible to the head, whereas most
of the bits are buried below hundreds or thousands of layers of tape wound
on the reel. A random access on tape requires winding the tape reels until
the selected block reaches the tape head, which can take tens or hundreds of
seconds. So we can generally say that random access within a tape cartridge is
more than a thousand times slower than random access on disk.
If a jukebox is involved, the access latency can be significantly higher. For
a removable disk to be changed, the drive must stop spinning, then the robotic
arm must switch the disk cartridges, and then the drive must spin up the new
cartridge. This operation takes several seconds-about a hundred times longer
than the random-access time within one disk. So switching disks in a jukebox
incurs a relatively high performance penalty.
For tapes, the robotic-ann time is about the same as for disks. But for tapes
to be switched, the old tape generally must rewind before it can be ejected, and
that operation can take as long as 4 minutes. And, after a new tape is loaded
into the drive, many seconds can be required for the drive to calibrate itself
to the tape and to prepare for I/0. Although a slow tape jukebox can have a
tape-switch time of 1 or 2 minutes, this time is not enormously greater than the
random-access time within one tape.
To generalize, we can say that random access in a disk jukebox has a
latency of tens of seconds, whereas random access in a tape jukebox has a
latency of hundreds of seconds; switching tapes is expensive, but switching
disks is not. We must be careful not to overgeneralize, though. Some expensive
tape jukeboxes can rewind, eject, load a new tape, and fast-forward to a random
item of data all in less than 30 seconds.
If we pay attention to only the performance of the drives in a jukebox,
the bandwidth and latency seem reasonable. But if we focus our attention
on the cartridges instead, we find a terrible bottleneck. Consider first the
bandwidth. The bandwidth-to-storage-capacity ratio of a robotic library is
much less favorable than that of a fixed disk. To read all the data stored on
a large hard disk could take about an hour. To read all the data stored in a
large tape library could take years. The situation with respect to access latency
is nearly as bad. To illustrate, if 100 requests are queued for a disk drive,
the average waiting time will be about a second. If 100 requests are queued
for a tape library, the average waiting time could be over an hour. The low
cost of tertiary storage results from having many cheap cartridges share a few
expensive drives. But a removable library is best devoted to the storage of
12.9 541
infrequently used data, because the library can satisfy only a relatively small
number of I/0 requests per hour.
12.9.3.2 Reliability
Although we often think good pe1jormance means high speed, another important
aspect of performance is reliability. If we try to read some data and are unable
to do so because of a drive or media failure, for all practical purposes the access
time is infinitely long and the bandwidth is infinitely small. So it is important
to understand the reliability of removable media.
Removable n1.ag:netic disks are somewhat less reliable than are fixed hard
disks, because they are more likely to be exposed to harmful environmental
conditions such as dust, large changes in temperature and humidity, and
mechanical forces such as shock and bending. Optical disks are considered
very reliable, because the layer that stores the bits is protected by a transparent
plastic or glass layer. The reliability of magnetic tape varies widely, depending
on the kind of drive. Some inexpensive drives wear out tapes after a few dozen
uses; other drives are gentle enough to allow millions of reuses. By comparison
with a magnetic-disk head, the head in a magnetic-tape drive is a weak spot.
A disk head flies above the media, but a tape head is in close contact with
the tape. The scrubbing action of the tape can wear out the head after a few
thousands or tens of thousands of hours.
In summary, we can say that a fixed-disk drive is likely to be more reliable
than a removable-disk or tape drive, and an optical disk is likely to be more
reliable than a magnetic disk or tape. But a fixed magnetic disk has one
weakness. A head crash in a hard disk generally destroys the data, whereas
the failure of a tape drive or optical-disk drive often leaves the data cartridge
unharmed.
12.9.3.3 Cost
Storage cost is another important factor. Here is a concrete example of how
removable media may lower the overall storage cost. Suppose that a hard disk
that holds X GB has a price of $200; of this amom1.t, $190 is for the housing,
motor, and controller, and $10 is for the magnetic platters. The storage cost
for this disk is $200/ X per gigabyte. Now, suppose that we can manufacture
the platters in a removable cartridge. For one drive and 10 cartridges, the total
price is $190 + $100, and the capacity is lOX GB, so the storage cost is $291 X per
gigabyte. Even if it is a little more expensive to make a removable cartridge,
the cost per gigabyte of removable storage may well be lower than the cost per
gigabyte of a hard disk, because the expense of one drive is averaged with the
low price of many removable cartridges.
Figures 12.15, 12.16, and 12.17 show cost trends per megabyte for DRAM
memory, magnetic hard disks, and tape drives. The prices in the graphs are
the lowest prices found in advertisements in various computer magazines and
on the World Wide Web at the end of each year. These prices reflect the smallcomputer
marketplace of the readership of these magazines, where prices are
low by comparison with the mainframe and minicomputer markets. In the case
of tape, the price is for a drive with one tape. The overall cost of tape storage
becomes much lower as more tapes are purchased for use with the drive,
542 Chapter 12
co
::;;;
&:5-
160
80
40
20
10
1.2
0.8
0.4
64
KB
32
128MB
512MB
2GB
0  02 --'-c-19=':,8.,.-2 -1-  98-cc4--:-19=':c8-=-6 -1~9'::-:88---,19=':c9-=-o -1c-:'91'::-:92--:1 c:':99-4 -c:c19L96---,19c:':9-=-8 -2.,-,o'::-:oo--:2c:':oo-=-2 -2::-::0L.04:--::2c:':oo-=-6 - :'2oos
Year
Figure 12.  15 Price per megabyte of DRAM, from 1981 to 2008.
because the price of a tape is a small fraction of the price of the drive. However,
in a huge tape library containing thousands of cartridges, the storage cost is
dominated by the cost of the tape cartridges. As of 2004, the cost per GB of tape
cartridges was around $.40.
As Figure 12.15 shows, the cost of DRAM fluctuates widely. In the period
from 1981 to 2004, we can see three price crashes (around 1981, 1989, and
1996) as excess production caused a glut in the marketplace. We can also
see two periods (around 1987 and 1993) where shortages in the marketplace
caused sigrtificant price increases. In the case of hard disks (Figure 12.16), the
price decline has been steadier. Tape-drive prices also fell steadily up to 1997
(Figure 12.17). Since 1997, the price per gigabyte of inexpensive tape drives
has ceased its dramatic fall, although the price of mid-range tape technology
(such as DAT /DDS) has continued to fall and is now approaching that of the
co
::;;;
  '
100
50
20
5
2
0.5
0.2
0.05
0.02-
0.004
0.001
0.0005
0.0002
10
20
1982 1984 1986
120
1.2
2
1988 1990 1992
19
GB
GB
GB
1994 1996 1998 2000 2002 2004 2006 2008
Year
Figure 12.16 Price per megabyte of magnetic hard disk, from 1981 to 2008.
12.10
OJ
~
12.10
40
20
8- 60
120
1.2
0.5-
0.1
72GB
0.025
320GB
0.01 320GB
0.0051~9c-c84-1-:L98-:-6 -19:':-88c---cc19~90c---:c19~92:--c-c19L94-c-c19L96,---.,-c19'cc98-2,-JOOc-c0--c2,-J.00,-,-2--:~--:.,J=~2008
Year
Figure 12.17 Price per megabyte of a tape drive, from 1984 to 2008.
543
in.expensive drives. Tape-drive prices are not shown for years prior to 1984,
because, as mentioned, the magazines used in tracking prices are targeted to
the small-computer marketplace, and tape drives were not widely used with
small computers prior to 1984.
We can see from these graphs that the cost of storage has fallen dramatically.
By comparing the graphs, we can also see that the price of disk storage has
plummeted relative to the price of DRAM and tape.
The price per megabyte of magnetic disk storage improved by more than
four orders of magnitude from 1981 to 2004, whereas the corresponding
improvement for main memory was only three orders of magnitude. Main
memory today is more expensive than disk storage by a factor of 100.
The price per megabyte dropped much more rapidly for disk drives than
for tape drives as well. In. fact, the price per megabyte of a magnetic disk drive
is approaching that of a tape cartridge without the tape drive. Consequently,
small- and medium-sized tape libraries have a higher storage cost than disk
systems with equivalent capacity.
The dramatic fall in disk prices has largely rendered tertiary storage
obsolete. We no longer have any tertiary storage technology that is orders
of magnitude less expensive than magnetic disk. It appears that the revival
of tertiary storage must await a revolutionary technology breakthrough.
Meanwhile, tape storage will find its use mostly limited to purposes such
as backups of disk drives and archival storage in enormous tape libraries that
greatly exceed the practical storage capacity of large disk farms.
Disk drives are the major secondary-storage I/0 devices on most computers.
Most secondary storage devices are either magnetic disks or n1.agnetic tapes.
Modern disk drives are structured as large one-dimensional arrays of logical
disk blocks. Generally, these logical blocks are 512 bytes in size. Disks may be
attached to a computer system in one of two ways: (1) through the local I/0
ports on the host computer or (2) through a network cmmection.
544 Chapter 12
Requests for disk I/0 are generated by the file system and by the virtual
memory system. Each request specifies the address on the disk to be referenced,
in the form of a logical block number. Disk-schedLiling algorithms can improve
the effective bandwidth, the average response time, and the variance in
response time. Algorithms such as SSTF, SCAN, C-SCAN, LOOK, and C-LOOK
are designed to make such improvements through strategies for disk-queue
ordering.
Performance can be harmed by external fragmentation. Some systems
have utilities that scan the file system to identify fragmented files; they then
move blocks around to decrease the fragmentation. Defragmenting a badly
fragmented file system can significantly improve performance, but the systenc
may have reduced performance while the defragmentation is in progress.
Sophisticated file systems, such as the UNIX Fast File System, incorporate
many strategies to control fragmentation during space allocation so that disk
reorganization is not needed.
The operating system manages the disk blocks. First, a disk must be lowlevel-
formatted to create the sectors on the raw hardware-new disks usually
come preformatted. Then, the disk is partitioned, file systems are created, and
boot blocks are allocated to store the system's bootstrap program. Finally, when
a block is corrupted, the system must have a way to lock out that block or to
replace it logically with a spare.
Because an efficient swap space is a key to good performance, systems
usually bypass the file system and use raw disk access for paging I/0. Some
systems dedicate a raw disk partition to swap space, and others use a file
within the file system instead. Still other systems allow the user or system
administrator to make the decision by providing both options.
Because of the amount of storage required on large systems, disks are
frequently made redundant via RAID algorithms. These algorithms allow more
than one disk to be used for a given operation and allow continued operation
and even automatic recovery in the face of a disk failure. RAID algorithms
are organized into different levels; each level provides some combination of
reliability and high transfer rates.
The write-ahead log scheme requires the availability of stable storage.
To implement such storage, we need to replicate the needed information on
multiple nonvolatile storage devices (usually disks) with independent failure
modes. We also need to update the information in a controlled manner to
ensure that we can recover the stable data after any failure during data transfer
or recovery.
Tertiary storage is built from disk and tape drives that use removable
media. Many different technologies are available, including magnetic tape,
removable magnetic and magneto-optic disks, and optical disks.
For removable disks, the operating system generally provides the full
services of a file-system interface, including space management and requestqueue
scheduling. For many operating systems, the name of a file on a
removable cartridge is a combination of a drive name and a file name within
that drive. This convention is simpler but potentially more confusing than is
using a name that identifies a specific cartridge.
For tapes, the operating system generally provides only a raw interface.
Many operating systems have no built-in support for jukeboxes. Jukebox
545
support can be provided by a device driver or by a privileged application
designed for backups or for HSM.
Three important aspects of performance are bandwidth, latency, and
reliability. Many bandwidths are available for both disks and tapes, but the
random-access latency for a tape is generally much greater than that for a disk.
Switching cartridges in a jukebox is also relatively slow. Because a jukebox
has a low ratio of drives to cartridges, reading a large fraction of the data in a
jukebox can take a long time. Optical media, which protect the sensitive layer
with a transparent coating, are generally more robust than magnetic media,
which are more likely to expose the magnetic material to physical damage.
Lastly, the cost of storage has decreased greatly in the past two decades, most
notably for disk storage.
12.1 What would be the effects on cost and performance if tape storage had
the same areal density as disk storage  (Areal density is the number of
gigabits per square inch.)
12.2 It is sometimes said that tape is a sequential-access medium, whereas
a magnetic disk is a random-access medium. In fact the suitability
of a storage device for random access depends on the transfer size.
The term streaming transfer rate denotes the rate for a data transfer
that is underway, excluding the effect of access latency. By contrast, the
effective transfer rate is the ratio of total bytes per total seconds, including
overhead time such as access latency.
Suppose that, in a computer, the level-2 cache has an access latency
of 8 nanoseconds and a streaming transfer rate of 800 megabytes per
second, the main memory has an access latency of 60 nanoseconds and
a streaming transfer rate of 80 megabytes per second, the magnetic disk
has an access latency of 15 milliseconds and a streaming transfer rate
of 5 megabytes per second, and a tape drive has an access latency of 60
seconds and a streaming transfer rate of 2 megabytes per seconds.
a. Random access causes the effective transfer rate of a device to
decrease, because no data are transferred during the access time.
For the disk described, what is the effective transfer rate if an
average access is followed by a streaming transfer of (1) 512 bytes,
(2) 8 kilobytes, (3) 1 megabyte, and (4) 16 megabytes 
b. The utilization of a device is the ratio of effective transfer rate to
streaming transfer rate. Calculate the utilization of the disk drive
for each of the four transfer sizes given in part a.
c. Suppose that a utilization of 25 percent (or higher) is considered
acceptable. Using the performance figures given, compute the
smallest transfer size for disk that gives acceptable utilization.
546 Chapter 12
d. Complete the following sentence: A disk is a random-access
device for transfers larger than ______ bytes and is a sequentialaccess
device for s1naller transfers.
e. Compute the minimum transfer sizes that give acceptable utilization
for cache, memory, and tape.
f. When is a tape a random-access device, and when is it a
sequential-access device 
12.3 The reliability of a hard-disk drive is typically described in terms of a
quantity called mean time between failures (MTBF). Although this quantity
is called a   time,   the MTBF actually is measured in drive-hours per
failure.
a. If a system contains 1,000 disk drives, each of which has a 750,000-
hour MTBF, which of the following best describes how often a
drive failure will occur in that disk farm: once per thousand
years, once per century, once per decade, once per year, once per
month, once per week, once per day, once per hour, once per
minute, or once per second 
b. Mortality statistics indicate that, on the average, a U.S. resident
has about 1 chance in 1,000 of dying between the ages of 20 and 21.
Deduce the MTBF hours for 20-year-olds. Convert this figure from
hours to years. What does this MTBF tell you about the expected
lifetime of a 20-year-old 
c. The manufacturer guarantees a 1-million-hour MTBF for a certain
model of disk drive. What can you conclude about the number of
years for which one of these drives is under warranty 
12.4 Discuss how an operating system could maintain a free-space list
for a tape-resident file system. Assume that the tape technology is
append-only and that it uses EOT marks and locate, space, and read
position commands as described in Section 12.9.2.1.
12.5 Imagine that a holographic storage drive has been invented. The drive
costs $10,000 and has an average access time of 40 milliseconds. It uses
a $100 cartridge the size of a CD. This cartridge holds 40,000 images,
and each image is a square black-and-white picture with a resolution
of 6, 000 x 6, 000 pixels (each pixel stores 1 bit). The drive can read or
write one picture in 1 millisecond. Answer the following questions.
a. What would be some good uses for this device 
b. How would this device affect the l/0 performance of a computing
system 
c. What kinds of storage devices, if any, would become obsolete as
a result of the invention of this device 
547
12.6 The term   Fast Wide SCSI-II   denotes a SCSI bus that operates at a
data rate of 20 megabytes per second when it moves a packet of bytes
between the host and a device. Suppose that a Fast Wide SCSI-II disk
drive spins at 7,200 RPM, has a sector size of 512 bytes, and holds 160
sectors per track
a. Estimate the sustained transfer rate of this drive in megabytes per
second.
b. Suppose that the drive has 7,000 cylinders, 20 tracks per cylinde1~
a head-switch time (from one platter to another) of 0.5 millisecond,
and an adjacent-cylinder seek time of 2 milliseconds. Use
this additional information to give an accurate estimate of the
sustained transfer rate for a huge transfer.
c. Suppose that the average seek time for the drive is 8 milliseconds.
Estimate the I/0 operations per second and the effective transfer
rate for a random-access workload that reads individual sectors
that are scattered across the disk
d. Calculate the random-access I/0 operations per second and
transfer rate for I/0 sizes of 4 kilobytes, 8 kilobytes, and 64
kilobytes.
e. If multiple requests are in the queue, a scheduling algorithm such
as SCAN should be able to reduce the average seek distance. Suppose
that a random-access workload is reading 8-kilobyte pages,
the average queue length is 10, and the scheduling algorithm
reduces the average seek time to 3 milliseconds. Now calculate
the I/0 operations per second and the effective transfer rate of the
drive.
12.7 Compare the performance of write operations achieved by a RAID level
5 organization with that achieved by a RAID level1 organization.
12.8 Suppose that a disk drive has 5,000 cylinders, numbered 0 to 4999. The
drive is currently serving a request at cylinder 143, and the previous
request was at cylinder 125. The queue of pending requests, in FIFO
order, is:
86,1470,913,1774,948,1509,1022,1750,130
Starting from the current head position, what is the total distance (in
cylinders) that the disk arm moves to satisfy all the pending requests
for each of the following disk-scheduling algorithms 
a. FCFS
b. SSTF
548 Chapter 12
c. SCAN
d. LOOK
e. C-SCAN
f. C-LOOK
12.9 Elementary physics states that when an object is subjected to a constant
acceleration a, the relationship between distance d and time t is given
by d = ~at2 . Suppose that, during a seek, the disk in Exercise 12.8
accelerates the disk arm at a constant rate for the first half of the seek,
then decelerates the disk arm at the same rate for the second half of the
seek. Assume that the disk can perform a seek to an adjacent cylinder
in 1 n  lillisecond and a full-stroke seek over all 5,000 cylinders in 18
milliseconds.
a. The distance of a seek is the number of cylinders that the head
moves. Explain why the seek time is proportional to the square
root of the seek distance.
b. Write an equation for the seek time as a function of the seek
distance. This equation should be of the form t = x + y~,
where t is the time in milliseconds and L is the seek distance in
cylinders.
c. Calculate the total seek time for each of the schedules in Exercise
12.8. Determine which schedule is the fastest (has the smallest
total seek time).
d. The percentage speedup is the time saved divided by the original
time. What is the percentage speedup of the fastest schedule over
FCFS 
12.10 The accelerating seek described in Exercise 12.9 is typical of hard-disk
drives. By contrast, floppy disks (and many hard disks manufactured
before the mid-1980s) typically seek at a fixed rate. Suppose that the
disk in Exercise 12.9 has a constant-rate seek rather than a constantacceleration
seek, so the seek time is of the form t = x + yL, where t
is the time in milliseconds and L is the seek distance. Suppose that the
time to seek to an adjacent cylinder is 1 millisecond, as before, and the
time to seek to each additional cylinder is 0.5 milliseconds.
a. Write an equation for this seek time as a function of the seek
distance.
b. Using this seek-time function, calculate the total seek time  or
each of the schedules in Exercise 12.8. Is your answer the same as
the one  or Exercise 12.9(c) 
549
c. What is the percentage speedup of the fastest scb.edule over FCFS
in this case 
12.11 Suppose that the disk in Exercise 12.9 rotates at 7,200 RPM.
a. What is the average rotational latency of this disk drive 
b. What seek distance can be covered in the tim.e that you found  or
part a 
12.12 Suppose that a one-sided 5.25-inch optical-disk cartridge has an areal
density of 1 gigabit per square inch. Further suppose that a magnetic
tape has an areal density of 20 megabits per square inch and is 1/2
inch wide and 1,800 feet long. Calculate an estimate of the storage
capacities of these two kinds of storage media. Suppose that an optical
tape exists that has the same physical size as the magnetic tape but the
same storage density as the optical disk. What volume of data could
the optical tape hold  What would be a marketable price for the optical
tape if the magnetic tape cost $25 
12.13 Write a program that simulates the disk-scheduling algorithms discussed
in Section 12.4.
12.14 Why is rotational latency usually not considered in disk scheduling 
How would you modify SSTF, SCAN, and C-SCAN to include latency
optimization 
12.15 Remapping bad blocks by sector sparing or sector slipping can influence
perfonnance. Suppose that the drive in Exercise 12.6 has a total
of 100 bad sectors at random locations and that each bad sector is
mapped to a spare that is located on a different track within the same
cylinder. Estimate the number of I/0 operations per second and the
effective transfer rate for a random-access workload consisting of 8-
kilobyte reads, assuming a queue length of 1 (that is, the choice of
scheduling algorithm is not a factor). What is the effect of a bad sector
on performance 
12.16 Discuss the relative advantages and disadvantages of sector sparing
and sector slipping.
12.17 Compare the performance of C-SCAN and SCAN scheduling, assuming
a uniform distribution of requests. Consider the average response time
(the time between the arrival of a request and the completion of that
request's service), the variation in response time, and the effective
550 Chapter 12
bandwidth. How does performance depend on the relative sizes of
seek time and rotational latency 
12.18 None of the disk-scheduling disciplines, except FCFS, is truly fair
(starvation may occur).
a. Explain why this assertion is true.
b. Describe a way to modify algorithms such as SCAN to ensure
fairness.
c. Explain why fairness is an important goal in a time-sharing
system.
d. Give three or more examples of circumstances in which it is
important that the operating system be unfair in serving I/O
requests.
12.19 Consider a RAID level 5 organization comprising five disks, with the
parity for sets of four blocks on four disks stored on the fifth disk. How
many blocks are accessed in order to perform the following 
a. A write of one block of data
b. A write of seven continuous blocks of data
12.20 The operating system generally treats removable disks as shared file
systems but assigns a tape drive to only one application at a time. Give
three reasons that could explain this difference in treatment of disks and
tapes. Describe the additional features that an operating system would
need to support shared file-system access to a tape jukebox. Would the
applications sharing the tape jukebox need any special properties, or
could they use the files as though the files were disk-resident  Explain
your answer.
12.21 How would use of a RAM disk affect your selection of a disk-scheduling
algorithm  What factors would you need to consider  Do the same
considerations apply to hard-disk scheduling, given that the file system
stores recently used blocks in a buffer cache in main memory 
12.22 You can use simple estimates to compare the cost and performance
of a terabyte storage system made entirely from disks with one that
incorporates tertiary storage. Suppose that each magnetic disk holds
10GB, costs $1,000, transfers 5MB per second, and has an average access
latency of 15 milliseconds. Also suppose that a tape library costs $10
per gigabyte, transfers 10 MB per second, and has an average access
latency of 20 seconds. Compute the total cost, the maximum total data
rate, and the average waiting time for a pure disk system. If you make
551
any assumptions about the workload, describe and justify them. Now,
suppose that 5 percent of the data are frequently used, so they must
reside on disk, but the other 95 percent are archived in the tape library.
Further suppose that the disk system handles 95 percent of the requests
and the library handles the other 5 percent. What are the total cost,
the maximum. total data rate, and the average waiting time for this
hierarchical storage system 
12.23 Assume that you have a mixed configuration comprising disks organized
as RAID levell and RAID levelS disks. Assume that the system
has flexibility in deciding which disk organization to use for storing a
particular file. Which files should be stored in the RAID level 1 disks
and which in the RAID levelS disks in order to optimize performance 
12.24 What are the tradeoffs involved in rereading code pages from the file
system versus using swap space to store them 
12.25 Requests are not usually uniformly distributed. For example, we can
expect a cylinder containing the file-system FAT or inodes to be accessed
more frequently than a cylinder containing only files. Suppose you
know that 50 percent of the requests are for a small, fixed number of
cylinders.
a. Would any of the scheduling algorithms discussed in this chapter
be particularly good for this case  Explain your answer.
b. Propose a disk-scheduling algorithm that gives even better performance
by taking advantage of this   hot spot   on the disk.
c. File systems typically fil1.d data blocks via an indirection table,
such as a FAT in DOS or inodes in UNIX. Describe one or more ways
to take advantage of this indirection to improve disk performance.
12.26 Discuss the reasons why the operating system might require accurate
information on how blocks are stored on a disk. How could the operating
system improve file system performance with this knowledge 
12.27 In a disk jukebox, what would be the effect of having more open files
than the number of drives in the jukebox 
12.28 Compare the throughput achieved by a RAID levelS organization with
that achieved by a RAID levell organization for the following:
a. Read operations on single blocks
b. Read operations on multiple contiguous blocks
552 Chapter 12
12.29 Could a RAID level 1 organization achieve better performance for read
requests than a RAID level 0 organization (with nonredundant striping
of data)  If so, how 
Discussions of redundant arrays of independent disks (RAIDs) are presented
by Patterson et al. [1988] and in the detailed survey of Chen et al. [1994].
Disk-system architectures for high-performance computing are discussed by
Katz et al. [1989]. Enhancements to RAID systems are discussed in. Wilkes
et al. [1996] and Yu et al. [2000]. Teorey and Pinkerton [1972] present an early
comparative analysis of disk-scheduling algorithms. They use simulations that
model a disk for which seek time is linear in the number of cylinders crossed.
For this disk LOOK is a good choice for queue lengths below 140, and C-LOOK
is good for queue lengths above 100. King [1990] describes ways to improve the
seek time by moving the disk ann when the disk is otherwise idle. Seltzer et al.
[1990] and Jacobson and Wilkes [1991] describe disk-scheduling algorithms that
consider rotational latency in addition to seek time. Scheduling optimizations
that exploit disk idle times are discussed in Lumb et al. [2000]. Worthington
et al. [1994] discuss disk performance and show the negligible performance
impact of defect management. The placement of hot data to improve seek
times has been considered by Ruemmler and Wilkes [1991] and Akyurek and
Salen'l [1993]. Ruemmler and Wilkes [1994] describe an accurate performance
model for a modern disk drive. Worthington et al. [1995] tell how to determine
low-level disk properties such as the zone structure, and this work is further
advanced by Schindler and Gregory [1999]. Disk power management issues
are discussed in Douglis et al. [1994L Douglis et al. [1995L Greenawalt [1994L
and Golding et al. [1995].
The I/0 size and randomness of the workload has a considerable influence
on disk performance. Ousterhout et al. [1985] and Ruemmler and Wilkes
[1993] report numerous interesting workload characteristics, including that
most files are smalt most newly created files are deleted soon thereafter, most
files that are opened for reading are read sequentially in their entirety, and most
seeks are short. McKusick et al. [1984] describe the Berkeley Fast File System
(FFS), which uses many sophisticated techniques to obtain good performance
for a wide variety of workloads. McVoy and Kleiman [1991] discuss further
improvements to the basic FFS. Quinlan [1991] describes how to implement
a file system on WORM storage with a magnetic disk cache; Richards [1990]
discusses a file-system approach to tertiary storage. Maher et al. [1994] give an
overview of the integration of distributed file systems and tertiary storage.
The concept of a storage hierarchy has been studied for more than
thirty years. For instance, a 1970 paper by Mattson et al. [1970] describes a
mathematical approach to predicting the performance of a storage hierarchy.
Alt [1993] describes the accommodation of removable storage in a commercial
operating system, and Miller and Katz [1993] describe the characteristics of
tertiary-storage access in a supercomputing environment. Benjamin [1990]
gives an overview of the massive storage requirements for the EOSDIS project
at NASA. Management and use of network-attached disks and programmable
553
disks are discussed in Gibson et al. [1997b t Gibson et al. [1997at Riedel et al.
[1998t and Lee and Thekkath [1996].
Holographic storage technology is the subject of an article by Psaltis and
Mok [1995]; a collection of papers on this topic dating from 1963 has been
assembled by Sincerbox [1994]. Asthana and Finkelstein [1995] describe several
emerging storage technologies, including holographic storage, optical tape,
and electron trapping. Toigo [2000] gives an in-depth description of modern
disk technology and several potential future storage technologies.

13.1
R
The two main jobs of a computer are I/0 and processing. In many cases, the
main job is I/0, and the processing is merely incidental. For instance, when
we browse a Web page or edit a file, our immediate interest is to read or enter
some information, not to compute an answer.
The role of the operating system in computer I/0 is to manage and
control I/0 operations and I/0 devices. Although related topics appear in
other chapters, here we bring together the pieces to paint a complete picture
of I/0. First, we describe the basics of I/O hardware, because the nature of the
hardware interface places constraints on the internal facilities of the operating
system. Next, we discuss the I/0 services provided by the operating system
and the embodiment of these services in the application I/0 interface. Then,
we explain how the operating system bridges the gap between the hardware
interface and the application interface. We also discuss the UNIX System V
STREAMS mechanism, which enables an application to assemble pipelines of
driver code dynamically. Finally, we discuss the performance aspects of I/O
and the principles of operating-system design that improve I/0 performance.
To explore the structure of an operating system's 1/0 subsystem.
To discuss the principles and complexities of 110 hardware.
To explain the performance aspects of 110 hardware and software.
The control of devices connected to the computer is a major concern of
operating-system designers. Because I/O devices vary so widely in their
function and speed (consider a mouse, a hard disk, and a CD-ROM jukebox),
varied methods are needed to control them. These methods form the I/0
subsystem of the kernet which separates the rest of the kernel from the
complexities of managing I/0 devices.
555
556 Chapter 13
13.2
I/O-device technology exhibits two conflicting trends. On the one hand, we
see increasing standardization of software and hardware interfaces. This trend
helps 11s to incorporate improved device generations into existing computers
and operating systems. On the other hand, we see an increasingly broad variety
of 1/0 devices. Some new devices are so unlike previous devices that it is a
challenge to incorporate them into our computers and operating systems. This
challenge is met by a combination of hardware and software techniques. The
basic I/0 hardware elements, such as ports, buses, and device controllers,
accommodate a wide variety of I/0 devices. To encapsulate the details and
oddities of different devices, the kernel of an operating system is structured
to use device-driver modules. The present a uniform deviceaccess
interface to the I/0 subsystem, much as system calls provide a standard
interface between the application and the operating system.
Computers operate a great many kinds of devices. Most fit into the general
categories of storage devices (disks, tapes), transmission devices (network
cards, modems), and human-interface devices (screen, keyboard, mouse).
Other devices are more specialized, s11ch as those involved in the steering
of a military fighter jet or a space shuttle. In these aircraft, a human gives input
to the flight computer via a joystick and foot pedals, and the computer sends
output commands that cause motors to move rudders, flaps, and thrusters.
Despite the incredible variety of I/0 devices, though, we need only a few
concepts to understand how the devices are attached and how the software
can control the hardware.
A device communicates with a computer system by sending signals over a
cable or even through the air. The device communicates with the machine via a
connection point, or example, a serial port. If devices use a common
set of wires, the connection is called a bus. A is a set of wires and a rigidly
defined protocol that specifies a set of messages that can be sent on the wires.
In terms of the electronics, the messages are conveyed by patterns of electrical
voltages applied to the wires with defined timings. When device A has a cable
that plugs into device B, and device B has a cable that plugs into device C, and
device C plugs into a port on the computer, this arrangement is called a
A daisy chain usually operates as a bus.
Buses are used widely in computer architecture and vary in their signaling
methods, speed, throughput, and connection methods. A typical PC bus
structure appears in Figure 13.1. This figure shows a (the common
PC system bus) that connects the processor-memory subsystem to the fast
devices and an that connects relatively slow devices, such as
the keyboard and serial and USB ports. In the upper-right portion of the figure,
four disks are c01mected together on a SCSI bus plugged into a SCSI controller.
Other common buses used to interconnect main parts of a computer include
with up to 4.3 GB; (PCie), with throughput up
with throughput up to 20 GB.
is a collection of electronics that can operate a port, a bus,
or a device. A serial-port controller is a simple device controller. It is a single
chip (or portion of a chip) in the computer that controls the signals on the
13.2 557
Figure 13.1 A typical PC bus structure.
wires of a serial port. By contrast, a SCSI bus controller is not simple. Because
the SCSI protocol is complex, the SCSI bus controller is often implemented as
a separate circuit board (or a that plugs into the computer. It
typically contains a processor, microcode, and some private memory to enable
it to process the SCSI protocol messages. Some devices have their own built-in
controllers. If you look at a disk drive, you will see a circuit board attached
to one side. This board is the disk controller. It implements the disk side of
the protocol for some kind of com1ection-SCSI or ATA, for instance. It has
microcode and a processor to do many tasks, such as bad-sector mapping,
prefetching, buffering, and caching.
How can the processor give commands and data to a controller to
accomplish an I/0 transfer  The short answer is that the controller has one
or more registers for data and control signals. The processor communicates
with the controller by reading and writing bit patterns in these registers. One
way in which this communication can occur is through the use of special
I/0 instructions that specify the transfer of a byte or word to an I/0 port
address. The I/0 instruction triggers bus lines to select the proper device and
to move bits into or out of a device register. Alternatively, the device controller
can support In this case, the device-control registers
are mapped into the address space of the processor. The CPU executes I/0
requests using the standard data-transfer instructions to read and write the
device-control registers.
Some systems use both techniques. For instance, PCs use I/0 instructions
to control some devices and memory-mapped I/0 to control others. Figure
13.2 shows the usual I/O port addresses for PCs. The graphics controller has
I/O ports for basic control operations, but the controller has a large memory558
Chapter 13
000-00F DMA controller
020-021 interrupt controller
040-043 timer
200-20F game controller
2F8-2FF serial port (secondary)
320-32F hard-disk controller
378-37F parallel port
3D0-3DF graphics controller
3F0-3F7 diskette-drive controller
3F8-3FF serial port (primary)
Figure 13.2 Device 1/0 port locations on PCs (partial).
mapped region to hold screen contents. The process sends output to the screen
by writing data into the memory-mapped region. The controller generates
the screen image based on the contents of this memory. This technique is
simple to use. Moreover, writing millions of bytes to the graphics memory
is faster than issuing millions of I/0 instructions. But the ease of writing
to a memory-mapped I/0 controller is offset by a disadvantage. Because a
common type of software fault is a write through an incorrect pointer to an
unintended region of memory, a memory-mapped device register is vulnerable
to accidental modification. Of course, protected memory helps to reduce this
risk.
An I/0 port typically consists of four registers, called the (1) status, (2)
control, (3) data-in, and (4) data-out registers.
The
The
is read by the host to get input.
is written by the host to send output.
The contains bits that can be read by the host. These bits
indicate states, such as whether the current command has completed,
whether a byte is available to be read from the data-in register, and whether
a device error has occurred.
The can be written by the host to start a command or to
change the nlOde of a device. For instance, a certain bit in the control
register of a serial port chooses between full-duplex and half-duplex
communication, another bit enables parity checking, a third bit sets the
word length to 7 or 8 bits, and other bits select one of the speeds supported
by the serial port.
The data registers are typically 1 to 4 bytes in size. Some controllers have
FIFO chips that can hold several bytes of input or output data to expand the
capacity of the controller beyond the size of the data register. A FIFO chip can
hold a small burst of data until the device or host is able to receive those data.
13.2 559
13.2.1 Polling
The complete protocol for interaction between the host and a controller
can be intricate, but the basic handshaking notion is simple. We explain
handshaking with an example. Assume that 2 bits are used to coordinate
the producer-consumer relationship between the controller and the host. The
controller indicates its state through the busy bit in the status register. (Recall
that to set a bit means to write a 1 into the bit and to clear a bit means to write
a 0 into it.) The controller sets the busy bit when it is busy working and clears
the busy bit when it is ready to accept the next comm.and. The host signals
its wishes via the command-ready bit in the command register. The host sets the
command-ready bit when a command is available for the controller to execute.
For this example, the host writes output through a port, coordinating with the
controller by handshaking as follows.
The host repeatedly reads the busy bit until that bit becomes clear.
The host sets the write bit in the command register and writes a byte into
the data-out register.
The host sets the command-ready bit.
When the controller notices that the command-ready bit is set, it sets the
busy bit.
The controller reads the command register and sees the write command.
It reads the data-out register to get the byte and does the I/O to the device.
The controller clears the command-ready bit, clears the error bit in the status
register to indicate that the device I/O succeeded, and clears the busy bit
to indicate that it is finished.
This loop is repeated for each byte.
In step 1, the host is or it is in a loop, reading the
status register over and over until the busy bit becomes clear. If the controller
and device are fast, this method is a reasonable one. But if the wait may be
long, the host should probably switch to another task. How, then, does the
host know when the controller has become idle  For some devices, the host
must service the device quickly, or data will be lost. For instance, when data
are streaming in on a serial port or from a keyboard, the small buffer on the
controller will overflow and data will be lost if the host waits too long before
returning to read the bytes.
In many computer architectures, three CPU-instruction cycles are sufficient
to poll a device: read a device register, logical-and to extract a status bit, and
branch if not zero. Clearly, the basic polling operation is efficient. But polling
becomes inefficient when it is attempted repeatedly yet rarely finds a device
to be ready for service, while other useful CPU processing remains undone. In
such instances, it may be more efficient to arrange for the hardware controller to
notify the CPU when the device becomes ready for service, rather than to require
the CPU to poll repeatedly for an I/0 completion. The hardware mechanism
that enables a device to notify the CPU is called an
560 Chapter 13
7
CPU
device driver initiates 1/0
CPU executing checks for
interrupts between instructions
CPU resumes
processing of
interrupted task
1/0 controller
4
Figure 13.3 Interrupt-driven 1/0 cycle.
13.2.2 Interrupts
The basic interrupt mechanism works as follows. The CPU hardware has a wire
called the that the CPU senses after executing every
instruction. When the CPU detects that a controller has asserted a signal on
the line, the CPU performs a state save and jumps to the
at a fixed address in memory. The interrupt handler
determines the cause of the interrupt, performs the necessary processing,
performs a state restore, and executes a return from interrupt instruction
to return the CPU to the execution state prior to the interrupt. We say that
the device controller raises an interrupt by asserting a signal on the interrupt
request line, the CPU catches the interrupt and dispatches it to the interrupt
handler, and the handler clears the interrupt by servicing the device. Figure
13.3 summarizes the interrupt-driven I/0 cycle.
This basic interrupt mechanism enables the CPU to respond to an asynchronous
event, as when a device controller becomes ready for service. In a
modern operating system, however, we need nlOre sophisticated interrupthandling
features.
We need the ability to defer interrupt handling during critical processing.
13.2 561
We need an efficient way to dispatch to the proper interrupt handler for
a device without first polling all the devices to see which one raised the
interrupt.
We need multilevel interrupts, so that the operating system can distinguish
between high- and low-priority interrupts and can respond with
the appropriate degree of urgency.
In modern computer hardware, these three features are provided by the CPU
and by the
Most CPUs have two interrupt request lines. One is the
'    ''        '. which is reserved for events such as unrecoverable memory errors.
The second interrupt line is it can be turned off by the CPU before
the execution of critical instruction sequences that must not be interrupted.
The maskable interrupt is used by device controllers to request service.
The interrupt mechanism accepts an number that selects a
specific interrupt-handling routine from a small set. In most architectures, this
address is an offset in a table called the . This vector contains
the memory addresses of specialized interrupt handlers. The purpose of a
vectored interrupt mechanism is to reduce the need for a single interrupt
handler to search all possible sources of interrupts to determine which one
needs service. In practice, however, computers have more devices (and, hence,
interrupt handlers) than they have address elements in the interrupt vector.
A common way to solve this problem is to use the technique of interrupt
chaining, in which each element in the interrupt vector points to the head of
a list of interrupt handlers. When an il1.terrupt is raised, the handlers on the
corresponding list are called one by one, until one is found that can service
the request. This structure is a compromise between the overhead of a huge
interrupt table and the inefficiency of dispatching to a single interrupt handler.
Figure 13.4 illustrates the design of theinterruptvector for the Intel Pentium
processor. The events from 0 to 31, which are nonmaskable, are used to signal
various error conditions. The events from 32 to 255, which are maskable, are
used for purposes such as device-generated interrupts.
The interrupt mechanism also implements a system of
This mechanism enables the CPU to defer the handling of low-priority
interrupts without maskii1.g off all interrupts and makes it possible for a
high-priority interrupt to preempt the execution of a low-priority interrupt.
A modern operating system interacts with the interrupt mechanism in
several ways. At boot time, the operating system probes the hardware buses
to determine what devices are present and installs the corresponding interrupt
handlers into the interrupt vector. During I/0, the various device controllers
raise interrupts when they are ready for service. These interrupts signify that
output has cornpleted, or that input data are available, or that a failure has
been detected. The interrupt mechanism is also used to handle a wide variety
of such as dividing by zero, accessing a protected or nonexistent
memory address, or attempting to execute a privileged instruction from user
mode. The events that trigger interrupts have a common property: they are
occurrences that induce the CPU to execute an urgent self-contained routine.
An operating system has other good uses for an efficient hardware and
software mechanism that saves a small amount of processor state and then
562 Chapter 13
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
i 
18
19-31
32-255
breakpoint
INTO-detected overflow
bound range exception
invalid opcode
device not available
double fault
coprocessor segment overrun (reserved)
invalid task state segment
segment not present
stack fault
general protection
page fault
(Intel reserved, do not use)
floating-point error
alignment check
machine check
(Intel reserved, do not use)
maskable interrupts
Figure i3.4 Intel Pentium processor event-vector table.
calls a privileged routine in the kernel. For example, many operating systems
use the interrupt mechanism for virtual memory paging. A page fault is an
exception that raises an interrupt. The interrupt suspends the current process
and jumps to the page-fault handler in the kernel. This handler saves the state
of the process, moves the process to the wait queue, performs page-cache
management, schedules an I/0 operation to fetch the page, schedules another
process to resume execution, and then returns from the interrupt.
Another example is found in the implementation of system calls. Usually,
a program uses library calls to issue system calls. The library routines check
the arguments given by the application, build a data structure to convey the
arguments to the kernel, and then execute a special instruction called a
or . This instruction has an operand that identifies the desired
kernel service. When a process executes the trap instruction, the interrupt
hardware saves the state of the user code, switches to supervisor mode, and
dispatches to the kernel routine that implements the requested service. The
trap is given a relatively low interrupt priority compared with those assigned
to device interrupts-executilcg a system call on behalf of an application is less
urgent than servicing a device controller before its FIFO queue overflows and
loses data.
Interrupts can also be used to manage the flow of control within the kernel.
For example, consider the processing required to complete a disk read. One
step is to copy data from kernel space to the user buffer. This copying is time
consuming but not urgent-it should not block other high-priority interrupt
13.2 563
handling. Another step is to start the next pending l/0 for that disk drive. This
step has higher priority. If the disks are to be used efficiently, we need to start
the next I/O as soon as the previous one completes. Consequently, a pair of
interrupt handlers implen  ents the kernel code that completes a disk read. The
high-priority handler records the l/0 status, clears the device interrupt, starts
the next pending I/0, and raises a low-priority interrupt to complete the work.
Later, when the CPU is not occupied with high-priority work, the low-priority
interrupt will be dispatched. The corresponding handler completes the userlevel
I/0 by copying data from kernel buffers to the application space and then
calling the scheduler to place the application on the ready queue.
A threaded kernel architecture is well suited to implement multiple
interrupt priorities and to enforce the precedence of interrupt handling over
background processing in kernel and application routines. We illustrate this
point with the Solaris kernel. In Solaris, interrupt handlers are executed
as kernel threads. A range of high priorities is reserved for these threads.
These priorities give interrupt handlers precedence over application code and
kernel housekeeping and implement the priority relationships among interrupt
handlers. The priorities cause the Solaris thread scheduler to preempt lowpriority
interrupt handlers in favor of higher-priority ones, and the threaded
implementation enables multiprocessor hardware to run several interrupt
handlers concurrently. We describe the interrupt architecture of Windows XP
and UNIX in Chapter 22 and Appendix A, respectively.
In summa:r:y, interrupts are used throughout modern operating systems to
handle asynchronous events and to trap to supervisor-mode routines in the
kernel. To enable the most urgent work to be done first, modern computers
use a system of interrupt priorities. Device controllers, hardware faults, and
system calls all raise interrupts to trigger kernel routines. Because interrupts
are used so heavily for time-sensitive processing, efficient interrupt handling
is required for good system performance.
13.2.3 Direct Memory Access
For a device that does large transfers, such as a disk drive, it seems wasteful
to use an expensive general-purpose processor to watch status bits and to
feed data into a controller register one byte at a time-a process termed
Many computers avoid burdening the main CPU with
PIO by offloading some of this work to a special-purpose processor called a
To initiate a DMA transfer, the host
writes a DMA command block into memory. This block contains a pointer to
the source of a transfer, a pointer to the destination of the transfer, and a count
of the number of bytes to be transferred. The CPU writes the address of this
command block to the DMA controller, then goes on with other work. The DMA
controller proceeds to operate the memory bus directly, placing addresses on
the bus to perform transfers without the help of the main CPU. A simple DMA
controller is a standard component in PCs, and for
the PC usually contain their own high-speed DMA hardware.
Handshaking between the DMA controller and the device controller is
performed via a pair of wires called DMA-request and DMA-acknowledge.
The device controller places a signal on the DMA-request wire when a word
of data is available for transfer. This signal causes the DMA controller to seize
564 Chapter 13
the memory bus, place the desired address on the memory-address wires,
and place a signal on the Dl\IIA -acknowledge wire. When the device controller
receives the DMA-acknowledge signat it transfers the word of data to memory
and removes the DMA-request signal.
When the entire transfer is finished, the DMA controller interrupts the CPU.
This process is depicted in Figure 13.5. When the DMA controller seizes the
memory bus, the CPU is momentarily prevented from accessing main memory
although it can still access data items in its primary and secondary caches.
Although this can slow down the CPU computation, offloading
the data-transfer work to a DMA controller generally improves the total system
performance. Some computer architectures use physical memory addresses for
DMA, but others perform mercwry using virtual
addresses that undergo translation to physical addresses. DVMA can perform
a transfer between two memory-mapped devices without the intervention of
the CPU or the use of main memory.
On protected-mode kernels, the operating system generally prevents
processes from issuing device commands directly. This discipline protects data
from access-control violations and also protects the system from erroneous use
of device controllers that could cause a system crash. Instead, the operating
system exports functions that a sufficiently privileged process can use to
access low-level operations on the underlying hardware. On kernels without
memory protection, processes can access device controllers directly. This direct
access can be used to achieve high performance/ since it can avoid kernel
communication, context switches, and layers of kernelsoftware. Unfortunately,
it interferes with system security and stability. The trend in general-purpose
operating systems is to protect memory and devices so that the system can try
to guard against erroneous or malicious applications.
5. DMA controller
transfers bytes to
buffer X, increasing
memory address
and decreasing C
until C = 0
1. device driver is told
to transfer disk data
to buffer at address X
2. device driver tells L  -'  '-  -~i-  '-'~--'--'
disk controller to
transfer C bytes
from disk to buffer
at address X
6. when C = 0, DMA
interrupts CPU to signal
transfer completion 1:2.'.c~li.ip:2i:.2-J
rc-c~.,.,---J'-=  ,._--~ 3. disk controller initiates
DMA transfer
c'G!,Or:tt_ront;r  '    I 4. disk controller sends
each byte to DMA
controller
Figure 13.5 Steps in a DMA transfer.
13.3
13.3 565
13.2.4 1/0 Hardware Summary
Although the hardware aspects of I/0 are complex when considered at the
level of detail of electronics-hardware design, the concepts that we have
just described are sufficient to enable us to understand many I/0 features
of operating systen  s. Let's review the main concepts:
A bus
A controller
An I/0 port and its registers
The handshaking relationship between the host and a device controller
The execution of this handshaking in a polling loop or via interrupts
The offloading of this work to a DMA controller for large transfers
We gave a basic example of the handshaking that takes place between a
device controller and the host earlier in this section. In reality, the wide variety
of available devices poses a problem for operating-system implementers. Each
kind of device has its own set of capabilities, control-bit definitions, and
protocols for interacting with the host-and they are all different. How can
the operating system be designed so that we can attach new devices to the
computer without rewriting the operating system  And when the devices
vary so widely, how can the operating system give a convenient, uniform I/0
interface to applications  We address those questions next.
In this section, we discuss structuring techniques and interfaces for the
operating system that enable I/0 devices to be treated in a standard, uniform
way. We explain, for instance, how an application can open a file on a disk
without knowing what kind of disk it is and how new disks and other devices
can be added to a cmnputer without disruption of the operating system.
Like other complex software-engineering problems, the approach here
involves abstraction, encapsulation, and software layering. Specifically, we
can abstract away the detailed differences in I/0 devices by identifying a few
general kinds. Each kind is accessed through a standardized set of
functions-an The differences are encapsulated in kernel modules
called device drivers that internally are custom-tailored to specific devices
but that export one of the standard interfaces. Figure 13.6 illustrates how the
I/O-related portions of the kernel are structured in software layers.
The purpose of the device-driver layer is to hide the differences among
device controllers from the I/O subsystem of the kernel, much as the I/0
system calls encapsulate the behavior of devices in a few generic classes
that hide hardware differences from applications. Making the I/0 subsystem
independent of the hardware simplifies the job of the operating-system
developer. It also benefits the hardware manufacturers. They either design
new devices to be compatible with an existing host controller interface (such as
SCSI-2), or they write device drivers to interface the new hardware to popular
566 Chapter 13
Figure 13.6 A kernel I/O structure.
operating systems. Thus, we can attach new peripherals to a computer without
waiting for the operating-system vendor to develop support code.
Unfortm1ately for device-hardware manufacturers, each type of operating
system has its own standards for the device-driver interface. A given device
may ship with multiple device drivers-for instance, drivers for MS-DOS,
Windows 95/98, Windows NT/2000, and Solaris. Devices vary on many
dimensions, as illustrated in Figure 13.7.
Character-stream or block. A character-stream device transfers bytes one
by one, whereas a block device transfers a block of bytes as a unit.
Sequential or random access. A sequential device transfers data in a fixed
order determined by the device, whereas the user of a random-access
device can instruct the device to seek to any of the available data storage
locations.
Synchronous or asynchronous. A synchronous device performs data
transfers with predictable response times. An asynchronous device
exhibits irregular or unpredictable response times.
Sharable or dedicated. A sharable device can be used concurrently by
several processes or threads; a dedicated device cannot.
Speed of operation. Device speeds range from a few bytes per second to
a few gigabytes per second.
Read -write, read only, or write only. Some devices perform both input
and output, but others support only one data transfer direction.
access method
transfer schedule
I/O direction
13.3
synchronous
asynchronous
dedicated
sharable
latency
seek time
transfer rate
delay between operations
read only
write only
read-write
tape
keyboard
tape
keyboard
CD-ROM
Figure i 3. 7 Characteristics of 1/0 devices.
567
For the purpose of application access, many of these differences are hidden
by the operating system, and the devices are grouped into a few conventional
types. The resulting styles of device access have been found to be useful
and broadly applicable. Although the exact system calls may differ across
operating systems, the device categories are fairly standard. The major access
conventions include block I/0, character-stream I/0, memory-mapped file
access, and network sockets. Operating systems also provide special system
calls to access a few additional devices, such as a time-of-day clock and a timer.
Some operating systems provide a set of system calls for graphical display,
video, and audio devices.
Most operating systems also have an (or that transparently
passes arbitrary conunands from an application to a device driver. In
UNIX, this system call is ioctl () (for   I/0 control  ). The ioctl () system call
enables an application to access any functionality that can be implernented by
any device driver, without the need to invent a new system call. The ioctl ()
system call has three arguments. The first is a file descriptor that connects the
application to the driver by referring to a hardware device managed by that
driver. The second is an integer that selects one of the commands implemented
in the driver. The third is a pointer to an arbitrary data structure in memory
that enables the application and driver to communicate any necessary control
information or data.
13.3.1 Block and Character Devices
The captures all the aspects necessary for accessing disk
drives and other block-oriented devices. The device is expected to understand
commands such as read() and write() ;if it is a random-access device, it is also
expected to have a seek() command to specify which block to transfer next.
568 Chapter 13
Applications normally access such a device through a file-system interface.
We can see that read(), write(), and seek 0 capture the essen.tial behaviors
of block-storage devices, so that applications are insulated from the low-level
differences among those devices.
The operating system itself, as well as special applications such as databasemanagement
systems, may prefer to access a block device as a simple linear
array of blocks. This mode of access is sometimes called If the
application performs its own buffering, then using a file systen1. would cause
extra, unneeded buffering. Likewise, if an application provides its own locking
of file blocks or regions, then any operating-system locking services would be
redundant at the least and contradictory at the worst. To avoid these conflicts,
raw-device access passes control of the device directly to the application, letting
the operating system step out of the way. Unfortunately, no operating-system
services are then performed on this device. A compromise that is becoming
common is for the operating system to allow a mode of operation on a file that
disables buffering and locking. In the UNIX world, this is called
Memory-mapped file access can be layered on top of block-device drivers.
Rather than offering read and write operations, a memory-mapped interface
provides access to disk storage via an array of bytes in main memory. The
system call that maps a file into memory returns the virtual memory address
that contains a copy of the file. The actual data transfers are performed only
when needed to satisfy access to the memory image. Because the transfers
are handled by the same mechanism as that used for demand-paged virtual
memory access, memory-mapped I/O is efficient. Memory mapping is also
convenient for programmers-access to a memory-mapped file is as simple
as reading from and writing to memory. Operating systems that offer virtual
memory commonly use the mapping interface for kernel services. For instance,
to execute a program, the operating system maps the executable into memory
and then transfers control to the entry address of the executable. The mapping
interface is also commonly used for kernel access to swap space on disk.
A keyboard is an example of a device that is accessed through a
The basic system calls in this interface enable an application
to get() or put() one character. On top of this interface, libraries can be
built that offer line-at-a-time access, with buffering and editing services (for
example, when a user types a backspace, the preceding character is removed
from the input stream). This style of access is convenient for input devices such
as keyboards, mice, and modems that produce data for input   spontaneously  
-that is, at times that cam1.ot necessarily be predicted by the application. This
access style is also good for output devices such as printers and audio boards,
which naturally fit the concept of a linear stream of bytes.
13.3.2 Network Devices
Because the performance and addressing characteristics of network I/0 differ
significantly from those of disk I/0, most operating systems provide a network
I/O interface that is different from the read() -write() -seek() interface used
for disks. One interface available in many operating systerns, including UNIX
and Windows NT, is the network interface.
Think of a wall socket for electricity: any electrical appliance can be plugged
in. By analogy, the system calls in the socket interface enable an application
13.3 569
to create a socket, to connect a local socket to a remote address (which plugs
this application into a socket created by another application), to listen for
any remote application to plug into the local socket, and to send and receive
packets over the connection. To support the implementation of servers, the
socket interface also provides a function called select() that manages a set
of sockets. A call to select () returns information about which sockets have a
packet waiting to be received and which sockets have room to accept a packet
to be sent. The use of select() eliminates the polling and busy waiting that
would otherwise be necessary for network I/0. These functions encapsulate the
essential behaviors of networks, greatly facilitating the creation of distributed
applications that can use any underlying network hardware and protocol stack
Many other approaches to interprocess communication and network
communication have been implemented. For instance, Windows NT provides
one interface to the network interface card and a second interface to the
network protocols (Appendix C.6). In UNIX, which has a long history as a
proving ground for network technology, we find half-duplex pipes, full-duplex
FIFOs, full-duplex STREAMS, message queues, and sockets. Information on UNIX
networking is given in Appendix A.9.
13.3.3 Clocks and Timers
Most computers have hardware clocks and timers that provide three basic
functions:
Give the current time.
Give the elapsed time.
Set a timer to trigger operation X at time T.
These functions are used heavily by the operating system, as well as by timesensitive
applications. Unfortunately, the system calls that implement these
functions are not standardized across operating systems.
The hardware to measure elapsed time and to trigger operations is called
a . It can be set to wait a certain amount of time
generate an interrupt, and it can be set to do this once or to repeat the
process to generate periodic interrupts. The scheduler uses this mechanism to
generate an interrupt that will preempt a process at the end of its time slice.
The disk I/O subsystem uses it to invoke the periodic flushing of dirty cache
buffers to disk, and the network subsystem uses it to cancel operations that are
proceeding too slowly because of network congestion or failures. The operating
system may also provide an interface for user processes to use timers. The
operating system can support more timer requests than the number of timer
hardware chan11els by simulating virtual clocks. To do so, the kernel (or the
timer device driver) maintains a list of interrupts wanted by its own routines
and by user requests, sorted in earliest-time-first order. It sets the timer for the
earliest tince. When the timer interrupts, the kernel signals the requester and
reloads the timer with the next earliest time.
On many computers, the interrupt rate generated by the hardware clock is
between 18 and 60 ticks per second. This resolution is coarse, since a modern
computer can execute hundreds of millions of instructions per second. The
570 Chapter 13
precision of triggers is limited by the coarse resolution of the timer, together
with the overhead of maintaining virtual clocks. Furthermore, if the timer
ticks are used to maintain the system time-of-day clock, the system clock
can drift. In most computers, the hardware clock is constructed from a highfrequency
counter. In some computers, the value of this counter can be read
from a device register, in which case the counter can be considered a highresolution
clock. Although this clock does not generate interrupts, it offers
accurate measurements of time intervals.
13.3.4 Blocking and Nonblocking 1/0
Another aspect of the system-call interface relates to the choice between
blocking I/0 and nonblocking I/0. When an application issues a
system call, the execution of the application is suspended. The application
is moved from the operating system's run queue to a wait queue. After the
system call completes, the application is moved back to the run queue, where
it is eligible to resume execution. When it resumes execution, it will receive
the values returned by the system call. The physical actions performed by
I/0 devices are generally asynchronous-they take a varying or unpredictable
amount of time. Nevertheless, most operating systems use blocking system
calls for the application interface, because blocking application code is easier
to understand than nonblocking application code.
Some user-level processes need I/0. One example is a user
interface that receives keyboard and mouse input while processing and
displaying data on the screen. Another example is a video application that
reads frames from a file on disk while simultaneously decompressing and
displaying the output on the display.
One way an application writer can overlap execution with I/0 is to write
a multithreaded application. Some threads can perform blocking system calls,
while others continue executing. The Solaris developers used this technique to
implement a user-level library for asynchronous I/0, freeing the application
writer from that task. Some operating systems provide nonblocking I/0 system
calls. A nonblocking call does not halt the execution of the application for an
extended time. h1.stead, it returns quickly, with a return value that indicates
how many bytes were transferred.
An alternative to a nonblocking system call is an asynchronous system
call. An asynchronous call returns immediately, without waiting for the I/0 to
complete. The application continues to execute its code. The completion of the
I/0 at some future time is communicated to the application, either through the
setting of some variable in the address space of the application or through the
triggering of a signal or software interrupt or a call-back routine that is executed
outside the linear control flow of the application. The difference between
nonblocking and asynchronous system calls is that a nonblocking read()
returns immediately with whatever data are available-the full number of
bytes requested, fewer, or none at all. An asynchronous read () call requests a
transfer that will be performed in its entirety but will complete at some future
time. These two I/0 methods are shown in Figure 13.8.
A good example of nonblocking behavior is the select () system call for
network sockets. This system call takes an argument that specifies a maximum
waiting time. By setting it to 0, an application can poll for network activity
13.4
13.4 571
kernel user user
kernel
(a) (b)
Figure 13.8 Two 1/0 methods: (a) synchronous and (b) asynchronous.
without blocking. But using select() introduces extra overhead, because
the select() call only checks whether I/0 is possible. For a data transfer,
select() must be followed by some kind of read() or write() command.
A variation on this approach, fotmd in Mach, is a blocking multiple-read call.
It specifies desired reads for several devices in one system call and returns as
soon as any one of them completes.
Kernels provide many services related to I/0. Several services-scheduling,
buffering, caching, spooling, device reservation, and error handlil1.g-are
provided by the kernel's I/0 subsystem and build on the hardware and devicedriver
infrastructure. The I/O subsystem is also responsible for protectil1.g itself
from errant processes and malicious users.
13.4.1 1/0 Scheduling
To schedule a set of I/O requests means to determine a good order in which to
execute them. The order in which applications issue system calls rarely is the
best choice. Scheduling can improve overall system performance, can share
device access fairly among processes, and can reduce the average waiting time
for I/0 to complete. Here is a simple example to illustrate. Suppose that a disk
arm is near the begilming of a disk and that three applications issue blocking
read calls to that disk Application 1 requests a block near the end of the disk,
application 2 requests one near the beginning, and application 3 requests one
in the middle of the disk The operating system can reduce the distance that the
disk ann travels by serving the applications in the order 2, 3, 1. Rearrangil1.g
the order of service in this way is the essence of I/0 scheduling.
Operating-system developers implement scheduling by maintaining a wait
queue of requests for each device. When an application issues a blocking I/0
system call, the request is placed on the queue for that device. The I/0 scheduler
rearranges the order of the queue to improve the overall system efficiency
and the average response time experienced by applications. The operating
572 Chapter 13
Figure 13.9 Device-status table.
system may also try to be fair, so that no one application receives especially
poor service, or it may give priority service for delay-sensitive requests. For
instance, requests from the virtual memory subsystem may take priority over
application requests. Several scheduling algorithms for disk I/0 are detailed
in Section 12.4.
When a kernel supports asynchronous I/0, it must be able to keep track
of many I/0 requests at the same time. For this purpose, the operating system
might attach the wait queue to a :able. The kernel manages this
table, which contains an entry for each I/0 device, as shown in Figure 13.9.
Each table entry indicates the device's type, address, and state (not functioning,
idle, or busy). If the device is busy with a request, the type of request and other
parameters will be stored in the table entry for that device.
One way in which the I/0 subsystem improves the efficiency of the
computer is by scheduling I/0 operations. Another way is by using storage
space in main memory or on disk via teclul.iques called buffering, caching, and
spooling.
13.4.2 Buffering
A is a memory area that stores data being transferred between two
devices or between a device and an application. Buffering is done for three
reasons. One reason is to cope with a speed mismatch between the producer and
consumer of a data stream. Suppose, for example, that a file is being received
via modem for storage on the hard disk The modem is about a thousand
times slower than the hard disk So a buffer is created in main mernory to
accumulate the bytes received from the modem. When an entire buffer of data
has arrived, the buffer can be written to disk in a single operation. Since the
disk write is not instantaneous and the modem still needs a place to store
additional incoming data, two buffers are used. After the modem fills the first
buffer, the disk write is requested. The modem then starts to fill the second
buffer while the first buffer is written to disk By the time the modem has filled
13.4 573
the second buffer, the disk write from the first one should have completed,
so the modem can switch back to the first buffer while the disk writes the
second one. This decouples the producer of data from the
consun1.er, thus relaxing timing requirements between them. The need for this
decoupling is illustrated in Figure 13.10, which lists the enormous differences
in device speeds for typical computer hardware.
A second use of buffering is to provide adaptations for devices that
have different data-transfer sizes. Such disparities are especially common in
computer networking, where buffers are used widely for fragmentation and
reassembly of messages. At the sending side, a large message is fragmented
into small network packets. The packets are sent over the network, and the
receiving side places them in a reassembly buffer to form an image of the
source data.
A third use of buffering is to support copy semantics for application I/0.
An example will clarify the meaning of   copy semantics.   Suppose that an
application has a buffer of data that it wishes to write to disk It calls the
write() systemcalt providing a pointer to the buffer and an integer specifying
the number of bytes to write. After the system call returns, what happens if
the application changes the contents of the buffer  With the
version of the data written to disk is guaranteed to be version at the
time of the application system calt independent of any subsequent changes
in the application's buffer. A simple way in which the operating system can
guarantee copy semantics is for the write () system call to copy the application
I System Bus
Hype(~ransport (32,pair) ~~~Iii~~~~~~~~
I
PCI ~xpress 2.0 (    32)
i
lnfi!l.i band (QDR ;.1 2X)

0.00001 0.001 0.1 10 1000 100000 1 EFigure
13.10 Sun Enterprise 6000 device-transfer rates (logarithmic).
574 Chapter 13
data into a kernel buffer before returning control to the application. The disk
write is performed from the kernel buffer, so that subsequent changes to the
application buffer have no effect. Copying of data between kernel buffers and
application data space is common in operating systems, despite the overhead
that this operation introduces, because of the clean semantics. The same effect
can be obtained more efficiently by clever use of virtual memory mapping and
copy-on-write page protection.
13.4.3 Caching
A is a region of fast memory that holds copies of data. Access to the cached
copy is more efficient than access to the original. For instance, the instructions
of the currently running process are stored on disk, cached ilc physical memory,
and copied again ill the CPU's secondary and primary caches. The difference
between a buffer and a cache is that a buffer may hold the only existing copy
of a data item, whereas a cache, by definition, holds a copy on faster storage of
an item that resides elsewhere.
Caching and buffering are distinct functions, but sometinces a region
of memory can be used for both purposes. For illstance, to preserve copy
semantics and to enable efficient scheduling of disk I/0, the operating system
uses buffers in maill memory to hold disk data. These buffers are also used as
a cache, to improve the I/O efficiency for files that are shared by applications
or that are being written and reread rapidly. When the kernel receives a file
I/0 request, the kernel first accesses the buffer cache to see whether that region
of the file is already available in main memory. If it is, a physical disk I/O
can be avoided or deferred. Also, disk writes are accumulated ill the buffer
cache for several seconds, so that large transfers are gathered to allow efficient
write schedules. This strategy of delayilcg writes to improve I/O efficiency is
discussed, in the context of remote file access, ill Section 17.3.
13.4.4 Spooling and Device Reservation
A is a buffer that holds output for a device, such as a printer, that cannot
accept ilcterleaved data streams. Although a prillter can serve only one job
at a time, several applications may wish to print their output concurrently,
without having their output mixed together. The operating system solves this
problem by intercepting all output to the printer. Each application's output
is spooled to a separate disk file. When an application finishes printing, the
spooling system queues the correspondilcg spool file for output to the printer.
The spooling system copies the queued spool files to the printer one at a time. In
some operating systems, spooling is managed by a system daemon process. In
others, it is handled by an in-kernel thread. In either case, the operating system
provides a control interface that enables users and system administrators to
display the queue, remove unwanted jobs before those jobs print, suspend
printing while the printer is serviced, and so on.
Some devices, such as tape drives and printers, cannot usefully multiplex
the I/0 requests of multiple concurrent applications. Spooling is one way
operating systems can coordinate concurrent output. Another way to deal with
concurrent device access is to provide explicit facilities for coordination. Some
operating systems (including VMS) provide support for exclusive device access
by enabling a process to allocate an idle device and to deallocate that device
13.4 575
when it is no longer needed. Other operating systems enforce a limit of one
open file handle to such a device. Many operating systems provide functions
that enable processes to coordinate exclusive access among then'lselves. For
instance, Windows NT provides system calls to wait until a device object
becomes available. It also has a parameter to the open () system call that
declares the types of access to be permitted to other concurrent threads. On
these systems, it is up to the applications to avoid deadlock.
13.4.5 Error Handling
An operating system that uses protected memory can guard against many
kinds of hardware and application errors, so that a complete system failure is
not the usual result of each minor mechanical glitch. Devices and I/0 transfers
can fail in many ways, either for transient reasons, as when a network becomes
overloaded, or for   permanent   reasons, as when a disk controller becomes
defective. Operating systems can often compensate effectively for transient
failures. For instance, a disk read() failure results in a read() retry, and
a network send() error results in a res end(), if the protocol so specifies.
Unfortunately, if an important component experiences a permanent failure,
the operating system is unlikely to recover.
As a general rule, an I/0 system call will return one bit of information
about the status of the call, signifying either success or failure. In the UNIX
operating system, an additional integer variable named errno is used to
return an error code-one of about a hundred values-indicating the general
nature of the failure (for example, argument out of range, bad pointer, or
file not open). By contrast, some hardware can provide highly detailed error
information, although many current operating systems are not designed to
convey this information to the application. For instance, a failure of a SCSI
device is reported by the SCSI protocol in three levels of detail: a key that
identifies the general nature of the failure, such as a hardware error or an illegal
request; an that states the category of failure, such as a
bad command parameter or a self-test failure; and an
'X     ' l  '.l that gives even more detail, such as which command parameter was
in error or which hardware subsystem failed its self-test. Further, many SCSI
devices maintain internal pages of error-log information that can be requested
by the host-but seldom are.
13.4.6 1/0 Protection
Errors are closely related to the issue of protection. A user process may
accidentally or purposely attempt to disrupt the normal operation of a systern
by attempting to issue illegal I/0 instructions. We can use various mechanisms
to ensure that such disruptions cam'lot take place in the system.
To prevent users from performing illegal I/0, we define all I/0 instructions
to be privileged instructions. Thus, users cannot issue I/O instructions directly;
they must do it through the operating system. To do I/0, a user program
executes a system call to request that the operating system perform I/0 on its
behalf (Figure 13.11). The operating system, executing in monitor mode, checks
that the request is valid and, if it is, does the I/0 requested. The operating
system then returns to the user.
576 Chapter 13
CD
trap to
monitor
kernel
 
perform 1/0
 
return
to user
user
program
Figure 13.1  1 Use of a system call to perform 1/0.
In addition, any memory-mapped and I/O port memory locations must
be protected from user access by the memory-protection system. Note that a
kernel cannot simply deny all user access. Most graphics games and video
editing and playback software need direct access to memory-mapped graphics
controller memory to speed the performance of the graphics, for example. The
kernel might in this case provide a locking mechanism to allow a section of
graphics memory (representing a window on screen) to be allocated to one
process at a time.
13.4.7 Kernel Data Structures
The kernel needs to keep state information about the use of I/0 components.
It does so through a variety of in-kernel data structures, such as the open-file
table structure from Section 11.1. The kernel uses many similar structures to
track network connections, character-device communications, and other I/0
activities.
UNIX provides file-system access to a variety of entities, such as user files,
raw devices, and the address spaces of processes. Although each of these
entities supports a read () operation, the semantics differ. For instance, to
read a user file, the kernel needs to probe the buffer cache before deciding
whether to perform a disk I/0. To read a raw disk, the kernel needs to ensure
that the request size is a multiple of the disk sector size and is aligned on
a sector boundary. To read a process image, it is merely necessary to copy
data from memory. UNIX encapsulates these differences within a uniform
structure by using an object-oriented teclucique. The open-file record, shown in
13.4 577
system-wide open-file table
1;.;:.::, .;,.';t;.,' 
file-system record 1:~. s  :  1~iF ~. ..  
inode pointer +.,; :, : . :.'  
pointer to read and write functions I  .  . . :: i
,;.l,
pointer to select function
;;:;:,:;.~Ti~~~~~ple pointer to ioctl function
file descriptor
.,_ ..: ;: \ '':'' pointer to close function
n .:.r ..  :...   :  . .
.. :      :  .  . . . r;i~~~}~~~kl :f   
user-process memory networking (socket) record I :'~1~t~6~!V'.'.
pointer to network info +f:.;.   ......
pointer to read and write.functions
:, ,  .
~   ..  .
pointer to select function
pointer to ioctl function
pointer to close f..un ction .
kernel memory
Figure 13.  12 UNIX 1/0 kernel structure.
Figure 13.12, contains a dispatch table that holds pointers to the appropriate
routines, depending on the type of file.
Some operating systems use object-oriented methods even more extensively.
For instance, Windows NT uses a message-passing implementation for
I/0. An I/0 request is converted into a message that is sent through the kernel
to the II 0 manager and then to the device driver, each of which may change the
message contents. For output, the message contains the data to be written. For
input, the message contains a buffer to receive the data. The message-passing
approach can add overhead, by comparison with procedural techniques that
use shared data structures, but it simplifies the structure and design of the I/0
system and adds flexibility.
13.4.8 Kernel I/O Subsystem Summary
In summary, the I/0 subsystem coordinates an extensive collection of services
that are available to applications and to other parts of the kernel. The I/0
subsystenc supervises these procedures:
Management of the name space for files and devices
Access control to files and devices
Operation control (for example, a modem cannot seek ())
File-system space allocation
Device allocation
578 Chapter 13
13.5
Buffering, caching, and spooling
I/0 scheduling
Device-status monitoring, error handling, and failure recovery
Device-driver configuration and initialization
The upper levels of the I/O subsystem access devices via the uniform
interface provided by the device drivers.
Earlier, we described the handshaking between a device driver and a device
controller, but we did not explain how the operating system connects an
application request to a set of network wires or to a specific disk sector.
Consider, for example, reading a file from disk. The application refers to the
data by a file name. Within a disk, the file system maps from the file name
through the file-system directories to obtain the space allocation of the file. For
instance, in MS-DOS, the name maps to a number that indicates an entry in the
file-access table, and that table entry tells which disk blocks are allocated to
the file. In UNIX, the name maps to an inode number, and the corresponding
inode contains the space-allocation information. But how is the connection
made from the file name to the disk controller (the hardware port address or
the memory-mapped controller registers) 
One method is that used by MS-DOS, a relatively simple operating system.
The first part of an MS-DOS file name, preceding the colon, is a string that
identifies a specific hardware device. For example, c: is the first part of every
file name on the primary hard disk. The fact that c: represents the primary hard
disk is built into the operating system; c: is mapped to a specific port address
through a device table. Because of the colon separator, the device name space
is separate from the file-system name space. This separation makes it easy
for the operating system to associate extra functionality with each device. For
instance, it is easy to invoke spooling on any files written to the printer.
If, instead, the device name space is incorporated in the regular file-system
name space, as it is in UNIX, the normal file-system name services are provided
automatically. If the file system provides ownership and access control to all
file names, then devices have owners and access control. Since files are stored
on devices, such an interface provides access to the I/O system at two levels.
Names can be used to access the devices themselves or to access the files stored
on the devices.
UNIX represents device names in the regular file-system name space. Unlike
an MS-DOS file name, which has a colon separator, a UNIX path name has no
clear separation of the device portion. In fact, no part of the path name is the
name of a device. UNIX has a that associates prefixes of path names
with specific device names. To resolve a path name, UNIX looks up the name in
the mount table to find the longest ncatchilcg prefix; the corresponding entry
in the mount table gives the device name. This device name also has the form
of a name in the file-system name space. When UNIX looks up this name in
the file-system directory structures, it finds not an inode number but a   major,
13.5 579
minor   device number. The m.ajor device number identifies a device driver
that should be called to handle l/0 to this device. The minor device number
is passed to the device driver to index into a device table. The corresponding
device-table entry gives the port address or the memory-mapped address of
the device controller.
Modern operating systems obtain significant flexibility from the multiple
stages of lookup tables in the path between a request and a physical device
controller. The mechanisms that pass requests between applications and
drivers are general. Thus, we can introduce new devices and drivers into a
computer without recompiling the kernel. In fact, some operating systems
have the ability to load device drivers on demand. At boot time, the system
first probes the hardware buses to determine what devices are present; it then
loads in the necessary drivers, either immediately or when first required by an
I/0 request.
We next describe the typical life cycle of a blocking read request, as depicted
in Figure 13.13. The figure suggests that an I/0 operation requires a great many
steps that together consume a tremendous number of CPU cycles.
A process issues a blocking read () system call to a file descriptor of a file
that has been opened previously.
The system-call code in the kernel checks the parameters for correctness.
In the case of input, if the data are already available irl the buffer cache,
the data are returned to the process, and the I/O request is completed.
Otherwise, a physical I/0 must be performed. The process is removed
from the run queue and is placed on the wait queue for the device, and
the I/0 request is scheduled. Eventually, the I/0 subsystem sends the
request to the device driver. Depending on the operating system, the
request is sent via a subroutine call or an in-kernel message.
The device driver allocates kernel buffer space to receive the data and
schedules the I/0. Eventually, the driver sends commands to the device
controller by writing into the device-control registers.
The device controller operates the device hardware to perform the data
transfer.
The driver may poll for status and data, or it may have set up a DMA
transfer into kernel memory. We assume that the transfer is managed
by a DMA controller, which generates an interrupt when the transfer
completes.
The correct interrupt handler receives the interrupt via the interruptvector
table, stores any necessary data, signals the device driver, and
returns from the interrupt.
The device driver receives the signal, determines which I/0 request has
completed, determines the request's status, and signals the kernel I/0

subsystem that the request has been completed.  
The kernel transfers data or return codes to the address space of the
requesting process and moves the process from the wait queue back to
the ready queue.
580 Chapter 13
13.6
system call
device-controller commands
user
process
kernel
1/0 subsystem
kernel
1/0 subsystem
device
driver
interrupt
handler
device
controller
return from system call
interrupt
~-------tim_e~--~-)
Figure 13.13 The life cycle of an 1/0 request.
Moving the process to the ready queue unblocks the process. When the
scheduler assigns the process to the CPU, the process resumes execution
at the completion of the system call.
UNIX System V has an interesting mechanism, called that enables
an application to assemble pipelines of driver code dynamically. A stream is
a full-duplex connection between a device driver and a user-level process. It
consists of a that interfaces with the user process, a  :id
that controls the device, and zero or more between the stream
user process
13.6
I
STREAMS
modules
_j
Figure 13.14 The STREAMS structure.
581
head and the driver end. Each of these components contains a pair of queues
-a read queue and a write queue. Message passing is used to transfer data
between queues. The STREAMS structure is shown in Figure 13.14.
Modules provide the functionality of STREAMS processing; they are pushed
onto a stream by use of the ioctl () system call. For examplef a process can
open a serial-port device via a stream and can push on a module to handle
input editing. Because messages are exchanged between queues in adjacent
modules, a queue in one module may overflow an adjacent queue. To prevent
this from occurring, a queue may support Without flow control,
a queue accepts all messages and immediately sends them on to the queue
in the adjacent module without buffering them. A queue supporting flow
control buffers messages and does not accept messages without sufficient
buffer space; this process involves exchanges of control messages between
queues in adjacent modules.
A user process writes data to a device using either the write() orputmsg()
system call. The write() system call writes raw data to the stream, whereas
putmsg () allows the user process to specify a message. Regardless of the
system call used by the user process, the stream head copies the data into a
message and delivers it to the queue for the next module in line. This copying of
messages continues until the message is copied to the driver end and hence the
device. Similarly, the user process reads data from the stream head using either
the read() or getmsg () system call. If read() is used, the stream head gets
a message from its adjacent queue and returns ordinary data (an unstructured
byte stream) to the process. If getmsg () is used, a message is returned to the
process.
582 Chapter 13
13.7
STREAMS I/0 is asynchronous (or nonblocking) except when the user
process communicates with the stream~ head. When writing to the stream,
the user process will block, assuming the next queue uses flow controt until
there is room to copy the message. Likewise, the user process will block when
reading from the stream~ until data are available.
As mentioned, the driver end-like the stream head and modules-has
a read and write queue. However, the driver end must respond to interrupts,
such as one triggered when a frame is ready to be read from a network Unlike
the stream head, which may block if it is unable to copy a message to the
next queue in line, the driver end must handle all incoming data. Drivers
must support flow control as well. However, if a device's buffer is fult the
device typically resorts to dropping incoming messages. Consider a network
card whose input buffer is full. The network card must simply drop further
messages until there is ample buffer space to store incoming messages.
The benefit of using STREAMS is that it provides a framework for a
modular and incremental approach to writing device drivers and network
protocols. Modules may be used by different streams and hence by different
devices. For example, a networking module may be used by both an Ethernet
network card and a 802.11 wireless network card. Furthermore, rather than
treating character-device I/O as an unstructured byte stream, STREAMS allows
support for message boundaries and control information when communicating
between modules. Most UNIX variants support STREAMS, and it is the preferred
method for writing protocols and device drivers. For example, System V UNIX
and Solaris implement the socket mechanism using STREAMS.
I/ 0 is a major factor in system performance. It places heavy demands on the CPU
to execute device-driver code and to schedule processes fairly and efficiently
as they block and unblock The resulting context switches stress the CPU and its
hardware caches. I/O also exposes any inefficiencies in the interrupt-handling
mechanisms in the kernel. In addition, I/O loads down the memory bus during
data copies between controllers and physical memory and again durilcg copies
between kernel buffers and application data space. Coping gracefully with all
these demands is one of the major concerns of a computer architect.
Although modern computers can handle many thousands of interrupts per
second, interrupt handling is a relatively expensive task Each interrupt causes
the system to perform a state change, to execute the interrupt handler, and then
to restore state. Programmed I/0 can be more efficient than internJpt-driven
I/0, if the number of cycles spent in busy waiting is not excessive. An I/0
completion typically unblocks a process, leading to the full overhead of a
context switch.
Network traffic can also cause a high context-switch rate. Consider, for
instance, a remote login from one machine to another. Each character typed
on the local machine must be transported to the remote machine. On the local
machine, the character is typed; a keyboard interrupt is generated; and the
character is passed through the interrupt handler to the device driver, to the
kernet and then to the user process. The user process issues a network I/O
system call to send the character to the remote machine. The character then
13.7 583
flows into the local kernel, through the network layers that construct a network
packet, and into the network device driver. The network device driver transfers
the packet to the network controller, which sends the character and generates
an interrupt. The interrupt is passed back up through the kernel to cause the
network l/0 system call to complete.
Now, the remote system's network hardware receives the packet, and an
interrupt is generated. The character is unpacked from the network protocols
and is given to the appropriate network daemon. The network daemon
identifies which remote login session is involved and passes the packet to
the appropriate subdaemon for that session. Throughout this flow, there are
context switches and state switches (Figure 13.15). Usually, the receiver echoes
the character back to the sender; that approach doubles the work.
To eliminate the context switches involved in moving each character
between daemons and the kernel, the Solaris developers reimplemented the
daemon using in-kernel threads. Sun estimates that this improvement
sending system receiving system
Figure 13.15 lntercomputer communications.
584 Chapter 13
increased the maximum number of network logins from a few hundred to a
few thousand on a large server.
Other systems use separate for terminal I/0 to reduce
the interrupt burden on the main CPU. For instance, a
can multiplex the traffic from hundreds of remote terminals into one port on a
large computer. An is a dedicated, special-purpose CPU found in
mainframes and in other high-end systems. The job o  a channel is to offload
I/0 work from the main CPU. The idea is that the cham1.els keep the data flowing
smoothly, while the main CPU remains free to process the data. Like the device
controllers and DMA controllers found in smaller computers, a channel can
process more general and sophisticated programs, so channels can be tuned
for particular workloads.
We can employ several principles to improve the efficiency of I/0:
Reduce the number of context switches.
Reduce the number of times that data must be copied in memory while
passing between device and application.
Reduce the frequency of interrupts by using large transfers, smart controllers,
and polling (if busy waiting can be minimized).
Increase concurrency by using DMA-knowledgeable controllers or channels
to offload simple data copying from the CPU.
Move processing primitives into hardware, to allow their operation in
device controllers to be concurrent with CPU and bus operation.
Balance CPU, memory subsystem, bus, and I/O performance, because an
overload in any one area will cause idleness in others.
I/0 devices vary greatly in complexity. For instance, a mouse is simple. The
mouse movements and button clicks are converted into numeric values that are
passed from hardware, through the mouse device driver, to the application. By
contrast, the functionality provided by the Windows NT disk device driver is
complex. It not only manages individual disks but also implements RAID arrays
(Section 12.7). To do so, it converts an application's read or write request into a
coordinated set of disk I/0 operations. Moreover, it implements sophisticated
error-handling and data-recovery algorithms and takes many steps to optimize
disk performance.
Where should the I/0 functionality be implemented -in the device hardware,
in the device driver, or in application software  Sometimes we observe
the progression depicted in Figure 13.16.
Initially, we implement experimental I/0 algorithms at the application
level, because application code is f1exible and application bugs are unlikely
to cause system crashes. Furthermore, by developing code at the application
level, we avoid the need to reboot or reload device drivers after every
change to the code. An application-level implementation can be inefficient,
however, because of the overhead o  context switches and because the
application cannot take advantage of internal kernel data structures and
13.8
13.8 585
device code (hardware)
Figure 13.16 Device functionality progression.
kernel functionality (such as efficient in-kernel messaging, threading, and
locking).
When an application-level algorithm has demonstrated its worth, we may
reimplement it in the kernel. This can improve performance, but the development
effort is more challenging, because an operating-system kernel is
a large, complex software system. Moreover, an in-kernel implementation
must be thoroughly debugged to avoid data corruption and system
crashes.
The highest performance may be obtained through a specialized implementation
in hardware, either in the device or in the controller. The
disadvantages of a hardware implementation include the difficulty and
expense of making further improvements or of fixing bugs, the increased
development time (months rather than days), and the decreased flexibility.
For instance, a hardware RAID controller may not provide any means for
the kernel to influence the order or location of individual block reads and
writes, even if the kernel has special information about the workload that
would enable it to improve the I/0 performance.
The basic hardware elements involved in I/0 are buses, device controllers, and
the devices themselves. The work of moving data between devices and main
memory is perform.ed by the CPU as programmed I/0 or is offloaded to a DMA
controller. The kernel module that controls a device is a device driver. The
system-call interface provided to applications is designed to handle several
basic categories of hardware, including block devices, character devices,
memory-mapped files, network sockets, and programmed interval timers. The
system calls usually block the processes that issue them, but nonblocking and
586 Chapter 13
asynchronous calls are used by the kernel itself and by applications that must
not sleep while waiting for an I/0 operation to complete.
The kernel's I/O subsystem provides num.erous services. Among these
are I/0 scheduling, buffering, caching, spooling, device reservation, and error
handling. Another service, name translation, makes the connections between
hardware devices and the symbolic file names used by applications. It involves
several levels of mapping that translate from character-string names, to specific
device drivers and device addresses, and then to physical addresses of II 0 ports
or bus controllers. This mapping may occur within the file-system name space,
as it does in UNIX, or in a separate device name space, as it does in MS-DOS.
STREAMS is an implementation and methodology that provides a framework
for a modular and incremental approach to writing device drivers and
network protocols. Through streams, drivers can be stacked, with data passing
through them sequentially and bidirectionally for processing.
I/O system calls are costly in terms of CPU consumption because of the
many layers of software between a physical device and an application. These
layers imply overhead from several sources: context switching to cross the
kernel's protection boundary, signal and interrupt handling to service the I/0
devices, and the load on the CPU and memory system to copy data between
kernel buffers and application space.
13.1 Write (in pseudocode) an implementation of virtual clocks, including
the queueing and management of timer requests for the kernel and
applications. Assume that the hardware provides three timer channels.
13.2 What are the advantages and disadvantages of supporting memorymapped
I/0 to device control registers 
13.3 Typically, at the completion of a device I/0, a single interrupt is raised
and appropriately handled by the host processor. In certain settings,
however, the code that is to be executed at the completion of the
I/0 can be broken into two separate pieces. The first piece executes
immediately after the I/0 completes and schedules a second interrupt
for the remaining piece of code to be executed at a later time. What is
the purpose of using this strategy in the design of interrupt handlers 
13.4 Why might a system use interrupt-driven I/0 to manage a single serial
port and polling I/0 to manage a front-end processor, such as a termii1.al
concentrator 
13.5 What are the various kinds of performance overhead associated with
servicing an interrupt 
13.6 UNIX coordinates the activities of the kernel I/0 components by
manipulating shared in-kernel data structures, whereas Windows NT
uses object-oriented message passing between kernel I/O components.
Discuss three pros and three cons of each approach.
587
13.7 In most multiprogrammed systems, user programs access memory
through virtual addresses, while the operating system uses raw physical
addresses to access men10ry. What are the implications of this
design for the initiation of I/0 operations by the user program and
their execution by the operating system 
13.8 Polling for an I/0 completion can waste a large number of CPU cycles
if the processor iterates a busy-waiting loop many times before the I/0
completes. But if the I/0 device is ready for service, polling can be much
more efficient than is catching and dispatching an interrupt. Describe
a hybrid strategy that combines polling, sleeping, and interrupts for
I/0 device service. For each of these three strategies (pure polling, pure
interrupts, hybrid), describe a computing environment in which that
strategy is more efficient than is either of the others.
13.9 Consider the following I/0 scenarios on a single-user PC:
a. A mouse used with a graphical user interface
b. A tape drive on a multitasking operating system (with no device
preallocation available)
c. A disk drive containing user files
d. A graphics card with direct bus connection, accessible through
memory-mapped I/0
For each of these scenarios, would you design the operating system
to use buffering, spooling, caching, or a combin_ation  Would you use
polled I/O or interrupt-driven I/0  Give reasons for your choices.
13.10 The example of handshaking in Section 13.2 used 2 bits: a busy bit and a
command-ready bit. Is it possible to implement this handshaking with
only 1 bit  If it is, describe the protocol. If it is not, explain why 1 bit is
insufficient.
13.11 Discuss the advantages and disadvantages of guaranteeing reliable
transfer of data between modules in the STREAMS abstraction.
13.12 Some DMA controllers support direct virtual memory access, where
the targets of I/0 operations are specified as virtual addresses and
a translation from virtual to physical address is performed during
the DMA. How does this design complicate the design of the DMA
controller  What are the advantages of providing such functionality 
13.13 Why is it important to scale up system-bus and device speeds as CPU
speed increases 
13.14 When multiple interrupts from different devices appear at about the
same time, a priority scheme could be used to determine the order in
which the interrupts would be serviced. Discuss what issues need to
be considered in assigning priorities to different interrupts.
588 Chapter 13
13.15 Describe three circumstances under which blocking II 0 should be used.
Describe three circumstances under which nonblocking I/0 should be
used. Why not just implement nonblocking I/0 and have processes
busy-wait until their devices are ready 
Vahalia [1996] provides a good overview of I/O and networking in UNIX.
Leffler et al. [1989] detail the I/O structures and methods employed in
BSD UNIX. Milenkovic [1987] discusses the complexity of I/0 methods and
implementation. The use and programming of the various interprocesscommunication
and network protocols in UNIX are explored in Stevens
[1992]. Brain [1996] documents the Windows NT application interface. The
I/O implementation in the sample MINIX operating system is described in
Tanenbaum and Woodhull [1997]. Custer [1994] includes detailed information
on the NT message-passing implementation of I/0.
For details of hardware-level II 0 handling and memory-mapping functionality,
processor reference manuals (Motorola [1993] and Intel [1993]) are among
the best sources. Hennessy and Patterson [2002] describe multiprocessor systems
and cache-consistency issues. Tanenbaum [1990] describes hardware I/0
design at a low level, and Sargent and Shoemaker [1995] provide a programmer's
guide to low-level PC hardware and software. The IBM PC device I/O
address map is given in IBM [1983]. The March 1994 issue of IEEE Computer is
devoted to I/0 hardware and software. Raga [1993] provides a good discussion
of STREAMS.
Part Six
Protection mechanisms control access to a system by limiting the types
of file access permitted to users. In addition, protection must ensure
that only processes that have gained proper authorization from the
operating system can operate on memory segments, the CPU, and other
resources.
Protection is provided by a mechanism that controls the access of
programs, processes, or users to the resources defined by a computer
system. This mechanism must provide a means for specifying the controls
to be imposed, together with a means of enforcing them.
Security ensures the authentication of system users to protect the
integrity of the information stored in the system (both data and code),
as well as the physical resources of the computer system. The security
system prevents unauthorized access, malicious destruction 01- alteration
of data, and accidental introduction of inconsistency.

14.1
CHAPTER
The processes in an operating system must be protected from one another's
activities. To provide such protection, we can use various mechanisms to ensure
that only processes that have gained proper authorization from the operating
system can operate on the files, memory segments, CPU, and other resources
of a system.
Protection refers to a mechanism for controlling the access of programs,
processes, or users to the resources defined by a computer system. This
mechanism must provide a means for specifying the controls to be imposed,
together with a means of enforcement. We distinguish between protection and
security, which is a measure of confidence that the integrity of a system and
its data will be preserved. In this chapter, we focus on protection. Security
assurance is a much broader topic, and we address it in Chapter 15.
To discuss the goals and principles of protection in a modern computer
system.
   To explain how protection domains, combined with an access matrix, are
used to specify the resources a process may access.
To examine capability- and language-based protection systems.
As computer systems have become more sophisticated and pervasive in their
applications, the need to protect their integrity has also grown. Protection was
originally conceived as an adjunct to multiprogramming operating systems,
so that untrustworthy users might safely share a common logical name space,
such as a directory of files, or share a common physical name space, such as
memory. Modern protection concepts have evolved to increase the reliability
of any complex system that makes use of shared resources.
We need to provide protection for several reasons. The most obvious is the
need to prevent the mischievous, intentional violation of an access restriction
591
592 Chapter 14
14.2
by a user. Of more general importance, however, is the need to ensure that
each program component active in a system uses system resources only in
ways consistent with stated policies. This requirement is an absolute one for a
reliable system.
Protection can improve reliability by detecting latent errors at the interfaces
between component subsystems. Early detection of interface errors can often
prevent contamination of a healthy subsystem by a malfunctioning subsystem.
Also, an unprotected resource cannot defend against use (or misuse) by an
unauthorized or incompetent user. A protection-oriented system provides
means to distinguish between authorized and unauthorized usage.
The role of protection in a computer system is to provide a mechanism for
the enforcement of the policies governing resource use. These policies can be
established in a variety of ways. Some are fixed in the design of the system,
while others are formulated by the management of a system. Still others are
defined by the individual users to protect their own files and programs. A
protection system must have the flexibility to enforce a variety of policies.
Policies for resource use may vary by application, and they may change
over time. For these reasons, protection is no longer the concern solely of
the designer of an operating system. The application programmer needs to
use protection mechanisms as well, to guard resources created and supported
by an application subsystem against misuse. In this chapter, we describe the
protection mechanisms the operating system should provide, but application
designers can use them as well in designing their own protection software.
Note that mechanisms are distinct from policies. Mechanisms determine how
something will be done; policies decide what will be done. The separation
of policy and mechanism is important for flexibility. Policies are likely to
change from place to place or time to time. In the worst case, every change
in policy would require a change in the underlying mechanism. Using general
mechanisms enables us to avoid such a situation.
Frequently, a guiding principle can be used throughout a project, such as
the design of an operating system. Following this principle simplifies design
decisions and keeps the system consistent and easy to understand. A key,
time-tested guiding principle for protection is the It
dictates that programs, users, and even systems be given just enough privileges
to perform their tasks.
Consider the analogy of a security guard with a passkey. If this key allows
the guard into just the public areas that she guards, then misuse of the key
will result in minimal damage. If, however, the passkey allows access to all
areas, then damage from its being lost, stolen, misused, copied, or otherwise
compromised will be much greater.
An operating system following the principle of least privilege implements
its features, programs, system calls, and data structures so that failure or
compromise of a component does the minimum damage and allows the
n1inimum damage to be done. The overflow of a buffer in a system daemon
might cause the daemon process to fail, for example, but should not allow the
execution of code from the daemon process's stack that would enable a remote
14.3
14.3 593
user to gain maximum privileges and access to the entire system (as happens
too often today).
Such an operating system also provides system calls and services that
allow applications to be written with fine-grained access controls. It provides
mechanisms to enable privileges when they are needed and to disable them
when they are not needed. Also beneficial is the creation of audit trails for
all privileged function access. The audit trail allows the prograrnmer, systems
administrator, or law-enforcement officer to trace all protection and security
activities on the system.
Managing users with the principle of least privilege entails creating a
separate account for each user, with just the privileges that the user needs. An
operator who needs to mount tapes and back up files on the system has access
to just those commands and files needed to accomplish the job. Some systems
implement role-based access control (RBAC) to provide this functionality.
Computers implemented in a computing facility under the principle of least
privilege can be limited to running specific services, accessing specific remote
hosts via specific services, and doing so during specific times. Typically, these
restrictions are implemented through enabling or disabling each service and
through using access control lists, as described in Sections 10.6.2 and 14.6.
The principle of least privilege can help produce a more secure computing
environment. Unfortunately, it frequently does not. For example, Windows
2000 has a complex protection scheme at its core and yet has many security
holes. By comparison, Solaris is considered relatively secure, even though it
is a variant of UNIX, which historically was designed with little protection
in mind. One reason for the difference may be that Windows 2000 has more
lines of code and more services than Solaris and thus has more to secure and
protect. Another reason could be that the protection scheme in Windows 2000
is irtcomplete or protects the wrong aspects of the operating system, leaving
other areas vulnerable.
A computer system is a collection of processes and objects. By objects, we mean
both (such as the CPU, memory segments, printers, disks, and
tape drives) and (such as files, programs, and semaphores).
Each object has a unique name that differentiates it from all other objects in the
system, and each can be accessed only through well-defined and meaningful
operations. Objects are essentially abstract data types.
The operations that are possible may depend on the object. For example,
on a CPU, we can only execute. Memory segments can be read and written,
whereas a CD-ROM or DVD-ROM can only be read. Tape drives can be read,
written, and rewound. Data files can be created, opened, read, written, closed,
and deleted; program files can be read, written, executed, and deleted.
A process should be allowed to access only those resources for which it
has authorization. Furthermore, at any time, a process should be able to access
only those reso1Jrces that it currently reqLlires to complete its task. This second
requirement, conunonly referred to as the need-to-know principle, is useful in
limiting the amount of damage a faulty process can cause in the system. For
example, when process p invokes procedure A(), the procedure should be
594 Chapter14
allowed to access only its own variables and the formal parameters passed
to it; it should not be able to access all the variables of process p. Similarly,
consider the case in which process p invokes a compiler to compile a particular
file. The compiler should not be able to access files arbitrarily but should have
access only to a well-defined subset of files (such as the source file, listing file,
and so on) related to the file to be compiled. Conversely, the compiler may have
private files used for accounting or optimization purposes that process p should
not be able to access. The need-to-know principle is similar to the principle of
least privilege discussed in Section 14.2 in that the goals of protection are to
minimize the risks of possible security violations.
14.3.1 Domain Structure
To facilitate the scheme just described, a process operates within a
which specifies the resources that the process may access. Each
domain defines a set of objects and the types of operations that may be invoked
on each object. The ability to execute an operation on an object is an
A domain is a collection of access rights, each of which is an ordered pair
  object-name, rights-set  . For example, if domain D has the access right   file F,
{read, write}  , then a process executing in domain D can both read and write
file F; it cannot, however, perform any other operation on that object.
Domains do not need to be disjoint; they may share access rights. For
example, in Figure 14.1, we have three domains: D1, D2, and D3 . The access
right    0 4, {print}   is shared by D2 and D3, implying that a process executing
in either of these two domains can print object 0 4 . Note that a process must be
executing in domain D1 to read and write object 0 1, while only processes in
domain D3 may execute object 0 1.
The association between a process and a domain may be either if
the set of resources available to the process is fixed throughout the process's
lifetime, or As might be expected, establishing dynamic protection
domains is more complicated than establishing static protection domains.
If the association between processes and domains is fixed, and we want to
adhere to the need-to-know principle, then a mechanism must be available to
change the content of a domain. The reason stems from the fact that a process
may execute in two different phases and may, for example, need read access
in one phase and write access in another. If a domain is static, we must define
the domain to include both read and write access. However, this arrangement
provides more rights than are needed in each of the two phases, since we have
read access in the phase where we need only write access, and vice versa.
Thus, the need-to-know principle is violated. We must allow the contents of
   0 3 , {read, write}   
   0 1,.{read, write}  
   0 2 , {execute}   
   0 2, {write}  
   01, {execute}  
   0 3 , {read}  
Figure 14.1 System with three protection domains.
14.3 595
a domain to be modified so that the domain always reflects the n1inimum
necessary access rights.
If the association is dynamic, a mechanism is available to allow
enabling the process to switch from one domain to another. We may
also want to allow the content of a domain to be changed. If we cannot change
the content of a domain, we can provide the same effect by creating a new
domain with the changed content and switching to that new domain when we
want to change the domain content.
A domain can be realized in a variety of ways:
Each user may be a domain. In this case, the set of objects that can be
accessed depends on the identity of the user. Domain switching occurs
when the user is changed -generally when one user logs out and another
user logs in.
Each process may be a domain. In this case, the set of objects that can be
accessed depends on the identity of the process. Domain switching occurs
when one process sends a message to another process and then waits for
a response.
Each procedure may be a domain. In this case, the set of objects that can be
accessed corresponds to the local variables defined within the procedure.
Domain switching occurs when a procedure call is made.
We discuss domain switching in greater detail in Section 14.4.
Consider the standard dual-mode (monitor-user mode) model of
operating-system execution. When a process executes in monitor mode, it
can execute privileged instructions and thus gain complete control of the
computer system. In contrast, when a process executes in user mode, it can
invoke only nonprivileged instructions. Consequently, it can execute only
within its predefined memory space. These two modes protect the operating
system (executing in monitor domain) from the user processes (executing
in user domain). In a multiprogrammed operating system, two protection
domains are insufficient, since users also want to be protected from one
another. Therefore, a more elaborate scheme is needed. We illustrate such a
scheme by examining two influential operating systems-UNIX and MULTICS
-to see how they implement these concepts.
14.3.2 An Example: UNIX
In the UNIX operating system, a domain is associated with the user. Switching
the domain corresponds to changing the user identification temporarily.
This change is accomplished tbough the file system as follows. An owner
identification and a domain bit (known as the setuid bit) are associated with
each file. When the setuid bit is on, and a user executes that file, the user ID is
set to that of the owner of the file; when the bit is off, however, the user ID does
not change. For example, when a user A (that is, a user with useriD =A) starts
executing a file owned by B, whose associated domain bit is off, the useriD of
the process is set to A. When the setuid bit is on, the useriD is set to that of
the owner of the file: B. When the process exits, this temporary useriD change
ends.
596 Chapter 14
Other methods are used to change domains in operating systems in which
user IDs are used for domain definition, because almost all systems need
to provide such a mechanism. This mechanism is used when an otherwise
privileged facility needs to be made available to the general user population.
For instance, it might be desirable to allow users to access a network without
letting them write their own networking programs. In such a case, on a UNIX
system, the setuid bit on a networking program. would be set, causing the user
lD to change when the program was run. The user lD would change to that
of a user with network access privilege (such as root, the most powerful user
ID). One problem with this method is that if a user manages to create a file
with user ID root and with its setuid bit on, that user can become root and do
anything and everything on the system. The setuid mechanism is discussed
further in Appendix A.
An alternative to this method used in other operating systems is to place
privileged programs in a special directory. The operating system would be
designed to change the user lD of any program run from this directory, either
to the equivalent of root or to the user lD of the owner of the directory. This
eliminates one security problem with setuid programs in which crackers create
and hide such programs for later use (using obscure file or directory names).
This method is less flexible than that used in UNIX, however.
Even more restrictive, and thus more protective, are systems that simply
do not allow a change of user ID. In these instances, special techniques must
be used to allow users access to privileged facilities. For instance, a
may be started at boot time and run as a special user ID. Users then
run a separate program, which sends requests to this process whenever they
need to use the facility. This method is used by the TOPS-20 operating system.
In any of these systems, great care must be taken in writing privileged
programs. Any oversight can result in a total lack of protection on the system.
Generally, these programs are the first to be attacked by people trying to
break into a system; unfortunately, the attackers are frequently successful.
For example, security has been breached on many UNIX systems because of the
setuid feature. We discuss security in Chapter 15.
14.3.3 An Example: MUL TICS
In the MULTICS system, the protection domains are organized hierarchically
into a ring structure. Each ring corresponds to a single domain (Figure 14.2).
The rings are numbered from 0 to 7. Let D; and Dj be any two domain rings.
If j    i, then D; is a subset of Dj- That is, a process executing in domain Dj
has more privileges than does a process executing in domain D;. A process
executing in domain Do has the most privileges. If only two rings exist, this
scheme is equivalent to the monitor-user n1ode of execution, where monitor
mode corresponds to Do and user mode corresponds to D1.
MULTICS has a segmented address space; each segment is a file, and each
segment is associated with one of the rings. A segm.ent description includes an
entry that identifies the ring number. In addition, it includes three access bits
to control reading, writing, and execution. The association between segments
and rings is a policy decision with which we are not concerned here.
A current-ring-number counter is associated with each process, identifying
the ring in which the process is executing currently. When a process is executing
14.3 597
Figure 14.2 MULTICS ring structure.
in ring i, it cmmot access a segment associated with ring j (j    i). It can access a
segment associated with ring k (k::: i). The type of access, however, is restricted
according to the access bits associated with that segment.
Domain switching in MULTICS occurs when a process crosses from one ring
to another by calling a procedure in a different ring. Obviously, this switch must
be done in a controlled mmmer; otherwise, a process could start executing in
ring 0, and no protection would be provided. To allow controlled domain
switching, we modify the ring field of the segment descriptor to include the
following:
Access bracket. A pair of integers, bl and b2, such that bl ::=: b2.
Limit. An integer b3 such that b3    b2.
List of gates. Identifies the entry points (or
may be called.
at which the segments
If a process executing in ring i calls a procedure (or segncent) with access bracket
(bl,b2), then the call is allowed if bl ::=: i ::=: b2, and the current ring number of
the process remains i. Otherwise, a trap to the operating system occurs, and
the situation is handled as follows:
If i    bl, then the call is allowed to occur, because we have a transfer to a
ring (or domain) with fewer privileges. However, if parameters are passed
that refer to segments in a lower ring (that is, segments not accessible to
the called procedure), then these segments must be copied into an area
that can be accessed by the called procedure.
If i    b2, then the call is allowed to occur only if b3 is greater than or equal
to i and the call has been directed to one of the designated entry points in
the list of gates. This scheme allows processes with limited access rights to
call procedures in lower rings that have more access rights, but only in a
carefully controlled mmmer.
598 Chapter 14
14.4
The main disadvantage of the ring (or hierarchical) structure is that it does
not allow us to enforce the need-to-know principle. In particular, if an object
must be accessible in domain 0 J but not accessible in domain Oi, then we must
have j    i. But this requirement means that every segment accessible in Oi is
also accessible in 0 1.
The MULTICS protection system is generally more complex and less efficient
than are those used in current operating systems. If protection interferes with
the ease of use of the system or significantly decreases system performance,
then its use must be weighed carefully against the purpose of the system. For
instance, we would want to have a complex protection system on a computer
used by a university to process students' grades and also used by students for
classwork. A similar protection system would not be suited to a computer being
used for number crunching, in which performance is of utmost importance. We
would prefer to separate the mechanism from the protection policy, allowing
the same system to have complex or simple protection depending on the needs
of its users. To separate mechanism from policy, we require a more general
model of protection.
Our model of protection can be viewed abstractly as a matrix, called an
The rows of the access matrix represent domains, and the columns
represent objects. Each entry in the matrix consists of a set of access rights.
Because the column defines objects explicitly, we can omit the object name
from the access right. The entry access(i,j) defines the set of operations that a
process executing in domain Oi can invoke on object OJ.
To illustrate these concepts, we consider the access matrix shown in Figure
14.3. There are four domains and four objects-three files (F1, F2, F3) and one
laser printer. A process executing in domain 0 1 can read files F1 and F3 . A
process executing in domain 0 4 has the same privileges as one executing in
domain 0 1; but in addition, it can also write onto files F1 and F3 . Note that the
laser printer can be accessed only by a process executing in domain 0 2.
The access-matrix scheme provides us with the mechanism for specifying
a variety of policies. The mechanism consists of implementing the access
01 read read
02 print
03 read execute
04
read read
write write
Figure 14.3 Access matrix.
14.4 599
matrix and ensuring that the semantic properties we have outlined hold.
More specifically, we must ensure that a process executing in domain n can
access only those objects specified in row ( and then only as allowed by the
access-matrix entries.
The access matrix can implement policy decisions concerning protection.
The policy decisions involve which rights should be included in the (i,j)th
entry. We must also decide the domain in which each process executes. This
last policy is usually decided by the operating system.
The users normally decide the contents of the access-matrix entries. When
a user creates a new object Oi, the column Oi is added to the access matrix
with the appropriate initialization entries, as dictated by the creator. The user
may decide to enter some rights in some entries in cohum1 j and other rights
in other entries, as needed.
The access matrix provides an appropriate mechanism for defining and
implementing strict control for both the static and dynamic association between
processes and domains. When we switch a process from one domain to another,
we are executing an operation (switch) on an object (the domain). We can
control domain switching by including domains among the objects of the
access matrix. Similarly, when we change the content of the access matrix,
we are performing an operation on an object: the access matrix. Again, we
can control these changes by including the access matrix itself as an object.
Actually, since each entry in the access matrix may be modified individually,
we must consider each entry in the access matrix as an object to be protected.
Now, we need to consider only the operations possible on these new objects
(domains and the access matrix) and decide how we want processes to be able
to execute these operations.
Processes should be able to switch from one domain to another. Switching
from domain D; to domain Di is allowed if and only if the access right switch
E access(i,j). Thus, in Figure 14.4, a process executing in domain D2 can switch
to domain D3 or to domain D4 . A process in domain D4 can switch to D1, and
one in domain D1 can switch to D2-
Allowing controlled change in the contents of the access-matrix entries
requires three additional operations: copy, owner, and control. We examine
these operations next.
01 read read switch
02 print switch switch
03 read execute
04 read read switch
write write
Figure 14.4 Access matrix of Figure 14.3 with domains as objects.
600 Chapter 14
(a)
execute read   execute
execute read
(b)
Figure 14.5 Access matrix with copy rights.
The ability to copy an access right from one domain (or row) of the access
matrix to another is denoted by an asterisk (  ) appended to the access right.
The copy right allows the access right to be copied only within the colurrm.
(that is, for the object) for which the right is defined. For example, in Figure
14.5(a), a process executing in domain D2 can copy the read operation into any
entry associated with file F2 . Hence, the access matrix of Figure 14.5(a) can be
modified to the access matrix shown in Figure 14.5(b ).
This scheme has two variants:
A right is copied from access(i, j) to access(Jc, j); it is then removed from
access(i, j). This action is a transfer of a right, rather than a copy.
Propagation of the copy right may be limited. That is, when the right
R   is copied from access(i,j) to access(lc,j), only the right R (not R  )
is created. A process executing in domain D~r cannot further copy the
right R.
A system may select only one of these three copy rights, or it may provide all
three by identifying them as separate rights: copy, transfer, and limited copy.
We also need a mechanism to allow addition of new rights and removal of
some rights. The owner right controls these operations. If access(i, j) includes
the owner right, then a process executing in domain Di can add and remove
any right in any entry in column j. For example, in Figure 14.6(a), domain D1
is the owner of F1 and thus can add and delete any valid right in column F1.
Similarly, domain D2 is the owner of F2 and F3 and thus can add and remove
any valid right within these two columns. Thus, the access matrix of Figure
14.6(a) can be modified to the access matrix shown in Figure 14.6(b).
14.4 601
01 owner
write
execute
read  
read  
02 owner
owner
write
03 execute
(a)
01 owner
write
execute
owner read  
02 read   owner
write   write
03 write write
(b)
Figure 14.6 Access matrix with owner rights.
The copy and owner rights allow a process to change the entries in a column.
A mechanism is also needed to change the entries in a row. The control right
is applicable only to domain objects. If access(i, j) includes the control right,
then a process executing in domain Di can remove any access right from
row j. For example, suppose that, in Figure 14.4, we include the control right in
access(D2, D4). Then, a process executil1.g in domain D2 could modify domai11
D4, as shown in Figure 14.7.
read read switch
print switch switch
control
read execute
write write switch
Figure 14.7 Modified access matrix of Figure 14.4.
602 Chapter 14
14.5
The copy and owner rights provide us with a mechanism to limit the
propagation of access rights. However, they do not give us the appropriate tools
for preventing the propagation (or disclosure) of information. The problem. of
guaranteeing that no information initially held in an object can migrate outside
of its execution environment is called the . This problem
is in general unsolvable (see the bibliographical notes at the end of the chapter).
These operations on the domains and the access matrix are not in themselves
important, but they illustrate the ability of the access-matrix model to
allow the implementation and control of dynamic protection requirements.
New objects and new domains can be created dynamically and included in the
access-matrix model. However, we have shown only that the basic mechanism
exists; system designers and users must make the policy decisions concerning
which domains are to have access to which objects in which ways.
How can the access matrix be implemented effectively  In general, the matrix
will be sparse; that is, most of the entries will be empty. Although datastructure
techniques are available for representing sparse matrices, they are
not particularly useful for this application, because of the way in which
the protection facility is used. Here, we first describe several methods of
implementing the access matrix and then compare the methods.
14.5.1 Global Table
The simplest implementation of the access matrix is a global table consisting
of a set of ordered triples   domain, object, rights-set  . Whenever an operation
M is executed on an object Oj within domain D;, the global table is searched
for a triple   D;, 0 1, R~c  , with ME R~c. If this triple is found, the operation is
allowed to continue; otherwise, an exception (or error) condition is raised.
This implementation suffers from several drawbacks. The table is usually
large and thus cannot be kept in main memory, so additional I/0 is needed.
Virtual memory techniques are often used for managing this table. In addition,
it is difficult to take advantage of special groupings of objects or domains.
For example, if everyone can read a particular object, this object must have a
separate entry in every domain.
14.5.2 Access Lists for Objects
Each column in the access matrix can be implemented as an access list for
one object, as described in Section 10.6.2. Obviously, the empty entries can be
discarded. The resulting list for each object consists of ordered pairs   domain,
rights-set  , which define all domains with a nonempty set of access rights for
that object.
This approach can be extended easily to define a list plus a default set of
access rights. When an operation M on an object Oi is attempted in domain
D;, we search the access list for object 0 i, looking for an entry    D;, R1c    with
ME RJc. If the entry is found, we allow the operation; if it is not, we check the
default set. If M is in the default set, we allow the access. Otherwise, access is
14.5 603
denied, and an exception condition occurs. For efficiency, we may check the
default set first and then search the access list.
14.5.3 Capability Lists for Domains
Rather than associating the columns of the access matrix with the objects as
access lists, we can associate each row with its domain. A ltst for
a domain is a list of objects together with the operations allowed on tbose
objects. An object is often represented by its physical name or address, called
a To execute operation M on object 0 1, the process executes the
operation M, specifying the capability (or pointer) for object 0 j as a parameter.
Simple of the capability means that access is allowed.
The capability list is associated with a domain, but it is never directly
accessible to a process executing in that domain. Rather, the capability list
is itself a protected object, maintained by the operating system and accessed
by the user only indirectly. Capability-based protection relies on the fact that
the capabilities are never allowed to migrate into any address space directly
accessible by a user process (where they could be modified). If all capabilities
are secure, the object they protect is also secure against unauthorized access.
Capabilities were originally proposed as a kind of secure pointer, to
meet the need for resource protection that was foreseen as multiprogrammed
computer systems came of age. The idea of an inherently protected pointer
provides a fom1dation for protection that can be extended up to the applications
level.
To provide inherent protection, we must distinguish capabilities from other
kinds of objects, and they must be interpreted by an abstract machine on which
higher-level programs run. Capabilities are usually distinguished from other
data in one of two ways:
Each object has a to denote whether it is a capability or accessible
data. The tags themselves must not be directly accessible by an application
program. Hardware or firmware support may be used to enforce this
restriction. Although only one bit is necessary to distinguish between
capabilities and other objects, more bits are often used. This extension
allows all objects to be tagged with their types by the hardware. Thus,
the hardware can distinguish integers, floating-point numbers, pointers,
Booleans, characters, instructions, capabilities, and uninitialized values by
their tags.
Alternatively, the address space associated with a program can be split into
two parts. One part is accessible to the program and contains the program's
normal data and instructions. The other part, containing the capability list,
is accessible only by the operating system. A segmented memory space
(Section 8.6) is useful to support this approach.
Several capability-based protection systems have been developed; we describe
them briefly in Section 14.8. The Mach operating system also uses a version of
capability-based protection; it is described in Appendix B.
604 Chapter 14
14.5.4 A Lock-Key Mechanism
The t   ' is a compromise between access lists and capability
lists. Each object has a list of unique bit patterns, called Similarly, each
domain has a list of unique bit patterns, called A process executing in a
domain can access an object only if that domain has a key that matches one of
the locks of the object.
As with capability lists, the list of keys for a domain must be managed
by the operating system on behalf of the domain. Users are not allowed to
examine or modify the list of keys (or locks) directly.
14.5.5 Comparison
As you might expect choosing a technique for implementing an access matrix
involves various trade-offs. Using a global table is simple; however, the table
can be quite large and often cannot take advantage of special groupings of
objects or domains. Access lists correspond directly to the needs of users.
When a user creates an object he can specify which domains can access the
object as well as what operations are allowed. However, because access-rights
information for a particular domain is not localized, determining the set of
access rights for each domain is difficult. In addition, every access to the object
must be checked, requiring a search of the access list. In a large system with
long access lists, this search can be time consuming.
Capability lists do not correspond directly to the needs of users; they
are usefut however, for localizing information for a given process. The
process attempting access must present a capability for that access. Then, the
protection system needs only to verify that the capability is valid. Revocation
of capabilities, however, may be inefficient (Section 14.7).
The lock-key mechanism, as mentioned, is a compromise between access
lists and capability lists. The mechanism can be both effective and flexible,
depending on the length of the keys. The keys can be passed freely from
domain to domain. In addition, access privileges can be effectively revoked by
the simple technique of changing some of the locks associated with the object
(Section 14.7).
Most systems use a combination of access lists and capabilities. When a
process first tries to access an object, the access list is searched. If access is
denied, an exception condition occurs. Otherwise, a capability is created and
attached to the process. Additional references use the capability to demonstrate
swiftly that access is allowed. After the last access, the capability is destroyed.
This strategy is used in the MULTICS system and in the CAL system.
As an example of how such a strategy works, consider a file system in
which each file has an associated access list. When a process opens a file, the
directory structure is searched to find the file, access permission is checked, and
buffers are allocated. All this information is recorded in. a new entry in a file
table associated with the process. The operation returns an index into this table
for the newly opened file. All operations on the file are made by specification
of the index into the file table. The entry in the file table then points to the file
and its buffers. When the file is closed, the file-table entry is deleted. Since the
file table is maintained by the operating system, the user carmot accidentally
corrupt it. Thus, the user can access only those files that have been opened.
14.6
14.6 605
Since access is checked when the file is opened, protection is ensured. This
strategy is used in the UNIX system.
The right to access must still be checked or1 each access, and the file-table
entry has a capability only for the allowed operations. If a file is opened for
reading, then a capability for read access is placed in the file-table entry. If
an attempt is made to write onto the file, the system identifies this protection
violation by com.paring the requested operation with the capability in the
file-table entry.
In Section 10.6.2, we described how access controls can be used on files within a
file system. Each file and directory are assigned an owner, a group, or possibly
a list of users, and for each of those entities, access-control information is
assigned. A similar function can be added to other aspects of a computer
system. A good example of this is found in Solaris 10.
Solaris 10 advances the protection available in the Sun Microsystems
operating system by explicitly adding the principle of least privilege via
This facility revolves around privileges.
A privilege is the right to execute a system call or to use an option within
that system call (such as opening a file with write access). Privileges can be
assigned to processes,limiting them to exactly the access they need to perform
their work. Privileges and programs can also be assigned to Users are
assigned roles or can take roles based on passwords to the roles. In this way a
user can take a role that enables a privilege, allowing the user to run a program
to accomplish a specific task, as depicted in Figure 14.8. This implementation
of privileges decreases the security risk associated with superusers and setuid
programs.
user1
executes with role 1 privileges
~
Figure 14.8 Role-based access control in Solaris 10.
606 Chapter 14
14.7
Notice that this facility is similar to the access matrix described in Section
14.4. This relationship is further explored in the exercises at the end of the
chapter.
In a dynamic protection system, we may sometimes need to revoke access
rights to objects shared by different users. Various questions about revocation
may arise:
Immediate versus delayed. Does revocation occur immediately, or is it
delayed  If revocation is delayed, can we find out when it will take place 
Selective versus general. When an access right to an object is revoked,
does it affect all the users who have an access right to that object, or can
we specify a select group of users whose access rights should be revoked 
Partial versus total. Can a subset of the rights associated with an object be
revoked, or must we revoke all access rights for this object 
Temporary versus permanent. Can access be revoked permanently (that
is, the revoked access right will never again be available), or can access be
revoked and later be obtained again 
With an access-list scheme, revocation is easy. The access list is searched for
any access rights to be revoked, and they are deleted from the list. Revocation
is immediate and can be general or selective, total or partial, and permanent
or temporary.
Capabilities, howeve1~ present a much more difficult revocation problem,
as mentioned earlier. Since the capabilities are distributed throughout the
system, we must find them before we can revoke them. Schemes that implement
revocation for capabilities include the following:
Reacquisition. Periodically, capabilities are deleted from each domain. If
a process wants to use a capability, it may find that that capability has been
deleted. The process may then try to reacquire the capability. If access has
been revoked, the process will not be able to reacquire the capability.
Back-pointers. A list of pointers is maintained with each object, pointing
to all capabilities associated with that object. When revocation is required,
we can follow these pointers, changing the capabilities as necessary. This
scheme was adopted in the MULTICS system. It is quite general, but its
implementation is costly.
Indirection. The capabilities point indirectly, not directly, to the objects.
Each capability points to a unique entry in a global table, which in turn
points to the object. We implement revocation by searching the global table
for the desired entry and deleting it. Then, when an access is attempted,
the capability is found to point to an illegal table entry. Table entries can
be reused for other capabilities without difficulty, since both the capability
and the table entry contain the unique name of the object. The object for a
14.8
14.8 607
capability and its table entry must match. This scheme was adopted in the
CAL system. It does not allow selective revocation.
Keys. A key is a unique bit pattern that can be associated with a capability.
This key is defined when the capability is created, and it can be neither
modified nor inspected by the process that owns the capability. A
is associated with each object; it can be defined or replaced with
the set-key operation. When a capability is created, the current value
of the master key is associated with the capability. When the capability
is exercised, its key is compared with the master key. If the keys match,
the operation is allowed to continue; otherwise, an exception condition
is raised. Revocation replaces the master key with a new value via the
set-key operation, invalidating all previous capabilities for this object.
This scheme does not allow selective revocation, since only one master
key is associated with each object. If we associate a list of keys with each
object, then selective revocation can be implemented. Finally, we can group
all keys into one global table of keys. A capability is valid only if its
key matches some key in the global table. We implement revocation by
removing the matching key from the table. With this scheme, a key can be
associated with several objects, and several keys can be associated with
each object, providing maximum flexibility.
In key-based schemes, the operations of defining keys, inserting them
into lists, and deleting them from lists should not be available to all users.
In particular, it would be reasonable to allow only the owner of an object
to set the keys for that object. This choice, however, is a policy decision
that the protection system can implement but should not define.
In this section, we survey two capability-based protection systems. These
systems differ in their complexity and in the types of policies that can be
implemented on them. Neither system is widely used, but both provide
interesting proving grounds for protection theories.
14.8.1 An Example: Hydra
Hydra is a capability-based protection system that provides considerable
flexibility. The system implements a fixed set of possible access rights, including
such basic forms of access as the right to read, write, or execute a memory
segment. In addition, a user (of the protection system) can declare other rights.
The interpretation of user-defined rights is performed solely by the user's
program, but the system provides access protection for the use of these rights,
as well as for the use of system-defined rights. These facilities constitute a
significant development in protection technology.
Operations on objects are defined procedurally. The procedures that
implement such operations are themselves a form of object, and they are
accessed indirectly by capabilities. The names of user-defined procedures must
be identified to the protection system if it is to deal with objects of the userdefined
type. When the definition of an object is made krtOwn to Hydra, the
names of operations on the type become Auxiliary rights
608 Chapter 14
can be described in a capability for an instance of the type. For a process to
perform an operation on a typed object, the capability it holds for that object
must contain the name of the operation being invoked among its auxiliary
rights. This restriction enables discrin  lination of access rights to be made on an
instance-by-instance and process-by-process basis.
Hydra also provides ::'!fnrWk.;:J1o:L This scheme allows a procedure
to be certified as to act on a formal parameter of a specified type
on behalf of any process that holds a right to execute the procedure. The rights
held by a trustworthy procedure are independent oC and may exceed, the
rights held by the calling process. However, such a procedure must not be
regarded as universally trustworthy (the procedure is not allowed to act on
other types, for instance), and the trustworthiness must not be extended to any
other procedures or program segments that might be executed by a process.
Amplification allows implementation procedures access to the representation
variables of an abstract data type. If a process holds a capability to a typed
object A, for instance, this capability may include an auxiliary right to invoke
some operation P but does not include any of the so-called kernel rights, such
as read, write, or execute, on the segment that represents A. Such a capability
gives a process a means of indirect access (through the operation P) to the
representation of A, but only for specific purposes.
When a process invokes the operation P on an object A, howeve1~ the
capability for access to A may be amplified as control passes to the code body
of P. This amplification may be necessary to allow P the right to access the
storage segment representing A so as to implement the operation that P defines
on the abstract data type. The code body of P may be allowed to read or to
write to the segment of A directly, even though the calling process cmmot.
On return from P the capability for A is restored to its originat unamplified
state. This case is a typical one in which the rights held by a process for access
to a protected segment must change dynamically, depending on the task to
be performed. The dynamic adjustment of rights is performed to guarantee
consistency of a programmer-defined abstraction. Amplification of rights can
be stated explicitly in the declaration of an abstract type to the Hydra operating
system.
When a user passes an object as an argument to a procedure, we may need
to ensure that the procedure cannot modify the object. We can implement this
restriction readily by passing an access right that does not have the modification
(write) right. Howeve1~ if amplification may occur, the right to modify may
be reinstated. Thus, the user-protection requirement can be circumvented.
In generat of course, a user may trust that a procedure performs its task
correctly. This assumption is not always correct however, because of hardware
or software errors. Hydra solves this problem by restricting amplifications.
The procedure-call mechanism of Hydra was designed as a direct solution
to the problem of mutually suspicious subsystems. This problem is defined as
follows. Suppose that a program is provided that can be invoked as a service
by a number of different users (for example, a sort routine, a compile1~ a
game). When users invoke this service program, they take the risk that the
program will malfunction and will either damage the given data or retain
some access right to the data to be used (without authority) later. Similarly,
the service program may have som.e private files (for accounting purposes,
14.8 609
for example) that should not be accessed directly by the calling user program.
Hydra provides mechanisms for directly dealing with this problem.
A Hydra subsystem is built on top of its protection kernel and may require
protection of its own components. A subsystem interacts with the kernel
through calls on a set of kernel-defined primitives that define access rights to
resources defined by the subsystenl.. The subsystem designer can define policies
for use of these resources by user processes, but the policies are enforceable by
use of the standard access protection afforded by the capability system.
Programmers can make direct use of the protection system after acquainting
themselves with its features in the appropriate reference rnanual. Hydra
provides a large library of system-defined procedures that can be called by
user programs. Programmers can explicitly incorporate calls on these system
procedures into their program code or can use a program translator that has
been interfaced to Hydra.
14.8.2 An Example: Cambridge CAP System
A different approach to capability-based protection has been taken in the
design of the Cambridge CAP system. CAP's capability system is simpler and
superficially less powerful than that of Hydra. However, closer examination
shows that it, too, can be used to provide secure protection of user-defined
objects. CAP has two kinds of capabilities. The ordinary kind is called a
. It can be used to provide access to objects, but the only
rights provided are the standard read, write, and execute of the individual
storage segments associated with the object. Data capabilities are interpreted
by microcode in the CAP machine.
The second kind of capability is the so-called which
is protected, but not interpreted, by the CAP microcode. It is interpreted by a
protected (that is, privileged) procedure, which may be written by an application
programmer as part of a subsystem. A particular kind of rights amplification
is associated with a protected procedure. When executing the code body of
such a procedure, a process temporarily acquires the right to read or write the
contents of a software capability itself. This specific kind of rights amplification
corresponds to an implementation of the seal and unseal primitives on
capabilities. Of course, this privilege is still subject to type verification to ensure
that only software capabilities for a specified abstract type are passed to any
such procedure. Universal trust is not placed in any code other than the CAP
machine's microcode. (See Bibliographical Notes for references.)
The interpretation of a software capability is left completely to the subsystem,
through the protected procedures it contains. This scheme allows a
variety of protection policies to be implemented. Although programmers can
define their own protected procedures (any of which might be incorrect), the
security of the overall system cannot be compromised. The basic protection
system will not allow an unverified, user-defined, protected procedure access
to any storage segments (or capabilities) that do not belong to the protection
environment in which it resides. The most serious consequence of an insecure
protected procedure is a protection breakdown of the subsystem for which that
procedure has responsibility.
610 Chapter 14
14.9
The designers of the CAP system have noted that the use of software
capabilities allowed them to realize considerable economies in formulating
and implementing protection policies commensurate with the requirements of
abstract resources. However, subsystem designers who want to make use of
this facility cannot simply study a reference manual, as is the case with Hydra.
Instead, they must learn the principles and techniques of protection, since the
system provides them with no library of procedures.
To the degree that protection is provided in existing computer systems, it is
usually achieved through an operating-system kernel, which acts as a security
agent to inspect and validate each attempt to access a protected resource. Since
comprehensive access validation may be a source of considerable overhead,
either we must give it hardware support to reduce the cost of each validation
or we must allow the system designer to compromise the goals of protection.
Satisfying all these goals is difficult if the flexibility to implement protection
policies is restricted by the support mechanisms provided or if protection
environments are made larger than necessary to secure greater operational
efficiency.
As operating systems have become more complex, and particularly as they
have attempted to provide higher-level user interfaces, the goals of protection
have become much more refined. The designers of protection systems have
drawn heavily on ideas that originated in programming languages and
especially on the concepts of abstract data types and objects. Protection systems
are now concerned not only with the identity of a resource to which access is
attempted but also with the functional nature of that access. In the newest
protection systems, concern for the function to be invoked extends beyond
a set of system-defined functions, such as standard file-access methods, to
include functions that may be user-defined as well.
Policies for resource use may also vary, depending on the application,
and they may be subject to change over time. For these reasons, protection
can no longer be considered a matter of concern only to the designer of an
operating system. It should also be available as a tool for use by the application
designe1~ so that resources of an applications subsystem can be guarded against
tampering or the influence of an error.
14.9.1 Compiler-Based Enforcement
At this point, programming languages enter the picture. Specifying the desired
control of access to a shared resource in a system is making a declarative
statement about the resource. This kind of statement can be integrated into a
language by an extension of its typing facility. When protection is declared
along with data typing, the designer of each subsystem can specify its
requirements for protection, as well as its need for use of other resources in a
system. Such a specification should be given directly as a program is composed,
and in the language in which the program itself is stated. This approach has
several significant advantages:
14.9 611
Protection needs are simply declared, rather than programmed as a
sequence of calls on procedures of an operating system.
Protection requirements can be stated independently of the facilities
provided by a particular operating system.
The means for enforcement need not be provided by the designer of a
subsystem.
A declarative notation is natural because access privileges are closely
related to the linguistic concept of data type.
A variety of techniques can be provided by a programming-language
implementation to enforce protection, but any of these must depend on some
degree of support from an underlying machine and its operating system. For
example, suppose a language is used to generate code to run on the Cambridge
CAP system. On this system, every storage reference made on the underlying
hardware occurs indirectly through a capability. This restriction prevents any
process from accessing a resource outside of its protection environment at
any time. However, a program may impose arbitrary restrictions on how
a resource can be used during execution of a particular code segment.
We can implement such restrictions most readily by usin.g the software
capabilities provided by CAP. A language implementation might provide
standard protected procedures to interpret software capabilities that would
realize the protection policies that could be specified in the language. This
scheme puts policy specification at the disposal of the programmers, while
freeing them from implementing its enforcement.
Even if a system does not provide a protection kernel as powerful as those
of Hydra or CAP, mechanisms are still available for implementing protection
specifications given in a programming language. The principal distinction is
that the security of this protection will not be as great as that supported by
a protection kernel, because the mechanism must rely on more assumptions
about the operational state of the system. A compiler can separate references
for which it can certify that no protection violation could occur from those
for which a violation might be possible, and it can treat them differently. The
security provided by this form of protection rests on the assumption that the
code generated by the compiler will not be modified prior to or during its
execution.
What, then, are the relative merits of enforcement based solely on a kernel,
as opposed to enforcement provided largely by a compiler 
Security. Enforcement by a kernel provides a greater degree of security
of the protection system itself than does the generation of protectionchecking
code by a compiler. In a compiler-supported scheme, security
rests on correctness of the translator, on some underlying mechanism of
storage management that protects the segments from which compiled
code is executed, and, ultimately, on the security of files from which a
program is loaded. Some of these considerations also apply to a softwaresupported
protection kernel, but to a lesser degree, since the kernel may
reside in fixed physical storage segments and may be loaded only from
a designated file. With a tagged-capability system, in which all address
612 Chapter 14
computation is performed either by hardware or by a fixed microprogram,
even greater security is possible. Hardware-supported protection is also
relatively immune to protection violations that might occur as a result of
either hardware or system software malfunction.
Flexibility. There are limits to the flexibility of a protection kernel in
implementing a user-defined policy, although it may supply adequate
facilities for the system to provide enforcement of its own policies.
With a programming language, protection policy can be declared and
enforcem.ent provided as needed by an implementation. If a language
does not provide sufficient flexibility, it can be extended or replaced with
less disturbance of a system in service than would be caused by the
modification of an operating-system kerneL
Efficiency. The greatest efficiency is obtained when enforcement of protection
is supported directly by hardware (or microcode). Insofar as software
support is required, language-based enforcement has the advantage that
static access enforcement can be verified off-line at compile time. Also,
since an intelligent compiler can tailor the enforcement mechanism to
meet the specified need, the fixed overhead of kernel calls can often be
avoided.
In summary, the specification of protection in a programming language
allows the high-level description of policies for the allocation and use of
resources. A language implementation can provide software for protection
enforcement when automatic hardware-supported checking is unavailable. In
addition, it can interpret protection specifications to generate calls on whatever
protection system is provided by the hardware and the operating system.
One way of making protection available to the application program is
through the use of a software capability that could be used as an object
of computation. Inherent in this concept is the idea that certain program
components might have the privilege of creating or examining these software
capabilities. A capability-creating program would be able to execute a primitive
operation that would seal a data structure, rendering the latter's contents
inaccessible to any program components that did not hold either the seal or
the unseal privilege. Such components might copy the data structure or pass
its address to other program components, but they could not gain access to
its contents. The reason for introducing such software capabilities is to bring a
protection mechanism into the programming language. The only problem with
the concept as proposed is that the use of the seal and unseal operations takes
a procedural approach to specifying protection. A nonprocedural or declarative
notation seems a preferable way to make protection available to the application
programmer.
What is needed is a safe, dynamic access-control mechanism for distributing
capabilities to system resources among user processes. To contribute to the
overall reliability of a system, the access-control mechanism should be safe
to use. To be useful in practice, it should also be reasonably efficient. This
requirement has led to the development of a number of language constructs
that allow the programmer to declare various restrictions on the use of a specific
managed resource. (See the Bibliographical Notes for appropriate references.)
These constructs provide mechanisms for three functions:
14.9 613
Distributing capabilities safely and efficiently among customer processes.
In particular, mechanisms ensure that a user process will use the managed
resource only if it was granted a capability to that resource.
Specifying the type of operations that a particular process may invoke on
an allocated resource (for example, a reader of a file should be allowed
only to read the file, whereas a writer should be able both to read and
to write). It should not be necessary to grant the same set of rights to
every user process, and it should be impossible for a process to enlarge
its set of access rights, except with the authorization of the access-control
mechanism.
Specifying the order in which a particular process may invoke the various
operations of a resource (for example, a file must be opened before it can
be read). It should be possible to give two processes different restrictions
on the order in which they can invoke the operations of the allocated
resource.
The incorporation of protection concepts into programming languages, as
a practical tool for system design, is in its infancy. Protection will likely become
a matter of greater concern to the designers of new systems with distributed
architectures and increasingly stringent requirements on data security. Then
the importance of suitable language notations in which to express protection
requirements will be recognized more widely.
14.9.2 Protection in Java
Because Java was designed to run in a distributed environment, the Java
virtual machine-or JVM-has many built-in protection mechanisms. Java
programs are composed of each of which is a collection of data fields
and functions (called that operate on those fields. The JVM loads a
class in response to a request to create instances (or objects) of that class. One of
the most novel and useful features ofJ ava is its support for dynamically loading
untrusted classes over a network and for executing mutually distrusting classes
within the same JVM.
Because of these capabilities of Java, protection is a paramount concern.
Classes running in the same JVM may be from different sources and may not
be equally trusted. As a result, enforcing protection at the granularity of the
JVM process is insufficient. Intuitively, whether a request to open a file should
be allowed will generally depend on which class has requested the open. The
operating system lacks this knowledge.
Thus, such protection decisions are handled within the JVM. When the
JVM loads a class, it assigns the class to a protection domain that gives
the permissions of that class. The protection domain to which the class is
assigned depends on the URL from which the class was loaded and any digital
signatures on the class file. (Digital signatures are covered in Section 15.4.1.3.)
A configurable policy file determines the permissions granted to the domain
(and its classes). For example, classes loaded from a trusted server might be
placed in a protection domain that allows them to access files in the user's
home directory, whereas classes loaded from an untrusted server might have
no file access permissions at all.
614 Chapter 14
It can be complicated for the JVM to determine what class is responsible for a
request to access a protected resource. Accesses are often performed indirectly,
through system libraries or other classes. For example, consider a class that
is not allowed to open network connections. It could call a system library to
request the load of the contents of a URL. The JVM must decide whether or not
to open a network connection for this request. But which class should be used
to determine if the connection should be allowed, the application or the system
library 
The philosophy adopted in Java is to require the library class to explicitly
permit a network corucection. More generally, in order to access a protected
resource, some method in the calling sequence that resulted in the request must
explicitly assert the privilege to access the resource. By doing so, this method
takes responsibility for the request; presumably, it will also perform whatever
checks are necessary to ensure the safety of the request. Of course, not every
method is allowed to assert a privilege; a method can assert a privilege only if
its class is in a protection domain that is itself allowed to exercise the privilege.
This implementation approach is called Every thread
in the JVM has an associated stack of its ongoing invocations. When
a caller may not be trusted, a method executes an access request within a
doPri vileged block to perform the access to a protected resource directly or
indirectly. doPri vileged () is a static method in the AccessController class
that is passed a class with a run () method to invoke. When the doPri vileged
block is entered, the stack frame for this method is annotated to indicate this
fact. Then, the contents of the block are executed. When an access to a protected
resource is subsequently requested, either by this method or a method it
calls, a call to checkPermissions () is used to invoke stack inspection to
determine if the request should be allowed. The inspection examines stack
frames on the calling thread's stack, starting from the most recently added
frame and working toward the oldest. If a stack frame is first found that has the
doPri vileged () annotation, then checkPermissions () returns immediately
and silently, allowing the access. If a stack frame is first found for which
access is disallowed based on the protection domain of the method's class,
then checkPermissions () throws an AccessControlException. If the stack
inspection exhausts the stack without finding either type of frame, then
whether access is allowed depends on the implementation (for example, some
implementations of the JVM may allow access, while other implementations
may disallow it).
Stack inspection is illustrated in Figure 14.9. Here, the gui () method of
a class in the untrusted applet protection domain performs two operations,
first a get () and then an open () . The former is an invocation of the
get () method of a class in the URL loader protection domain, which is
permitted to open() sessions to sites in the lucent. com domain, in particular
a proxy server proxy .lucent. com for retrieving URLs. For this reason, the
untrusted applet's get() invocation will succeed: the checkPermissions ()
call in the networking library encounters the stack frame of the get()
method, which performed its open() in a doPri vileged block. However,
the untrusted applet's open() invocation will result in an exception, because
the checkPermissions () call finds no doPri vileged annotation before
encountering the stack frame of the gui () method.
14.10
protection
domain:
socket
permission:
class:
none
gui:
get( uri);
open(addr);
14.10
  .lucent.com:80, connect
get(URL u):
doPrivileged {
open('proxy.lucent.com:80');
}
  request u from proxy  
Figure 14.9 Stack inspection.
615
any
open(Addr a):
checkPermission
(a, connect);
connect (a);
Of course, for stack inspection to work, a program must be unable to
modify the annotations on its own stack frame or to do other manipulations
of stack inspection. This is one of the most important differences between
Java and many other languages (including C++). A Java program cannot
directly access memory; it can manipulate only an object for which it has
a reference. References cannot be forged, and the manipulations are made
only through well-defined interfaces. Compliance is enforced through a
sophisticated collection of load-time and run-time checks. As a result, an object
cannot manipulate its run-time stack, because it camlOt get a reference to the
stack or other components of the protection system.
More generally, Java's load-time and run-time checks enforce of
Java classes. Type safety ensures that classes cannot treat integers as pointers,
write past the end of an array, or otherwise access memory in arbitrary ways.
Rather, a program can access an object only via the methods defined on that
object by its class. This is the f01mdation of Java protection, since it enables a
class to effectively - and protect its data and methods from other
classes loaded in the same JVM. For example, a variable can be defined as
private so that only the class that contains it can access it or protected so
that it can be accessed only by the class that contains it, subclasses of that class,
or classes in the same package. Type safety ensures that these restrictions can
be enforced.
Computer systems contain many objects, and they need to be protected from
misuse. Objects may be hardware (such as memory, CPU time, and I/0 devices)
or software (such as files, programs, and semaphores). An access right is
permission to perform an operation on an object. A domain is a set of access
rights. Processes execute in domains and may use any of the access rights in
the domain to access and manipulate objects. During its lifetime, a process may
be either bound to a protection domain or allowed to switch from one domain
to another.
616 Chapter 14
The access matrix is a general model of protection that provides a
mechanisnc for protection without imposing a particular protection policy on
the system or its users. The separation of policy and mechanism is an important
design property.
The access matrix is sparse. It is normally implemented either as access lists
associated with each object or as capability lists associated with each domain.
We can include dynamic protection in the access-matrix model by considering
domains and the access matrix itself as objects. Revocation of access rights in a
dynamic protection model is typically easier to implement with an access-list
scheme than with a capability list.
Real systems are much more limited than the general model and tend to
provide protection only for files. UNIX is representative, providing read, write,
and execution protection separately for the owner, group, and general public
for each file. MULTICS uses a ring structure in addition to file access. Hydra, the
Cambridge CAP system, and Mach are capability systems that extend protection
to user-defined software objects. Solaris 10 implements the principle of least
privilege via role-based access controt a form of the access matrix.
Language-based protection provides finer-grained arbitration of requests
and privileges than the operating system is able to provide. For example, a
single Java JVM can run several threads, each in a different protection class. It
enforces the resource requests through sophisticated stack inspection and via
the type safety of the language.
14.1 Consider a computer system in which   computer games   can be played
by students only between 10 P.M. and 6 A.M., by faculty members
between 5 P.M. and 8 A.M., and by the computer center staff at all
times. Suggest a scheme for implementing this policy efficiently.
14.2 The RC 4000 system, among others, has defined a tree of processes (called
a process tree) such that all the descendants of a process can be given
resources (objects) and access rights by their ancestors only. Thus, a
descendant can never have the ability to do anything that its ancestors
cannot do. The root of the tree is the operating system, which has the
ability to do anything. Assume the set of access rights is represented
by an access matrix, A. A(x,y) defines the access rights of process x to
object y. If xis a descendant of z, what is the relationship between A(x,y)
and A(z,y) for an arbitrary object y 
14.3 How are the access-matrix facility and the role-based access-control
facility similar  How do they differ 
14.4 Discuss the need for rights amplification in Hydra. How does this
practice compare with the cross-ring calls in a ring-protection scheme 
617
14.5 Explain why a capability-based system such as Hydra provides greater
flexibility than the ring-protection scheme in enforcing protection
policies.
14.6 Consider the ring-protection scheme in MULTICS. If we were to implement
the system calls of a typical operating system and store them in a
segment associated with ring 0, what should be the values stored in the
ring field of the segment descriptor  What happens during a system
call when a process executing in a higher-numbered ring invokes a
procedure in ring 0 
14.7 Discuss the strengths and weaknesses of implementing an access matrix
using capabilities that are associated with domains.
14.8 Discuss the strengths and weaknesses of implementing an access matrix
using access lists that are associated with objects.
14.9 The access-control matrix can be used to determine whether a process
can switch from, say, domain A to domain B and enjoy the access
privileges of domain B. Is this approach equivalent to including the
access privileges of domain B in those of domain A 
14.10 How can systems that implement the principle of least privilege still
have protection failures that lead to security violations 
14.11 How does the principle of least privilege aid in the creation of protection
systems 
14.12 What protection problems may arise if a shared stack is used for
parameter passing 
14.13 If all the access rights to an object are deleted, the object can no longer
be accessed. At this point the object should also be deleted, and the
space it occupies should be returned to the system. Suggest an efficient
implementation of this scheme.
14.14 Discuss which of the following systems allow module designers to
enforce the need-to-know principle.
a. The MULTICS ring-protection scheme
b. Hydra's capabilities
c. JVM's stack-inspection scheme
618 Chapter 14
14.15 Consider a computing environment where a unique number is associated
with each process and each object in the system. Suppose that we
allow a process with number n to access an object with number m only
if n    m. What type of protection structure do we have 
14.16 What is the need-to-know principle  Why is it important for a protection
system to adhere to this principle 
14.17 What hardware features does a computer system need for efficient
capability manipulation  Can these features be used for memory
protection 
14.18 Describe how the Java protection model would be compromised if a
Java program were allowed to directly alter the annotations of its stack
frame.
14.19 A Burroughs B7000/B6000 MCP file can be tagged as sensitive data.
When such a file is deleted, its storage area is overwritten by some
random bits. For what purpose would such a scheme be useful 
The access-matrix model of protection between domains and objects was
developed by Lampson [1969] and Lampson [1971]. Popek [1974] and Saltzer
and Schroeder [1975] provided excellent surveys on the subject of protection.
Harrison et al. [1976] used a formal version of this model to enable them to
prove properties of a protection system mathematically.
The concept of a capability evolved from Iliffe's and Jodeit's codewords,
which were implemented in the Rice University computer (Iliffe and Jodeit
[1962]). The term capability was introduced by Dennis and Horn [1966].
The Hydra system was described by Wulf et al. [1981]. The CAP system
was described by Needham and Walker [1977]. Organick [1972] discussed the
MULTICS ring-protection system.
Revocation was discussed by Redell and Fabry [1974], Cohen and Jefferson
[1975], and Ekanadham and Bernstein [1979]. The principle of separation of
policy and mechanism was advocated by the designer of Hydra (Levin et al.
[1975]). The confinement problem was first discussed by Lampson [1973] and
was further examined by Lipner [1975].
The use of higher-level languages for specifying access control was
suggested first by Morris [1973], who proposed the use of the seal and unseal
operations discussed in Section 14.9. Kieburtz and Silberschatz [1978], Kieburtz
and Silberschatz [1983], and McGraw and Andrews [1979] proposed various
language constructs for dealing with general dynamic-resource-management
schemes. Jones and Liskov [1978] considered how a static access-control scheme
can be incorporated in a programming language that supports abstract data
types. The use of minimal operating-system support to enforce protection was
advocated by the Exokernel Project (Ganger et al. [2002], Kaashoek et al. [1997]).
15.1
Protection, as we discussed in Chapter 14, is strictly an internal problem: How
do we provide controlled access to programs and data stored in a computer
system  on the other hand, requires not only an adequate protection

system but also consideration of the external environment within which the
system operates. A protection system is ineffective if user authentication is
compromised or a program is run by an unauthorized user.
Computer resources must be guarded against unauthorized access, malicious
destruction or alteration, and accidental introduction of inconsistency.
These resources include information stored in the system (both data and code),
as well as the CPU, memory, disks, tapes, and networking that are the computer.
In this chapter, we start by examining ways in which resources may
be accidentally or purposely misused. We then explore a key security enabler
-cryptography. Finally, we look at mechanisms to guard against or detect
attacks.
To discuss security threats and attacks.
To explain the fundamentals of encryption, authentication, and hashing.
To examine the uses of cryptography in computing.
To describe various countermeasures to security attacks.
In many applications, ensuring the security of the computer system is worth
considerable effort. Large commercial systems containing payroll or other
financial data are inviting targets to thieves. Systems that contain data pertaining
to corporate operations may be of interest to unscrupulous competitors.
Furthermore, loss of such data, whether by accident or fraud, can seriously
impair the ability of the corporation to function.
In Chapter 14, we discussed mechanisms that the operating system can
provide (with appropriate aid from the hardware) that allow users to protect
621
622 Chapter 15
their resources, including programs and data. These mechanisms work well
only as long as the users conform to the intended use of and access to these
resources. We say that a system is if its resources are used and accessed
as intended under all circumstances. Unfortunately total security cannot be
achieved. Nonetheless, we must have mechanisms to make security breaches
a rare occurrence, rather than the norm.
Security violations (or misuse) of the system. can be categorized as intentional
(malicious) or accidental. It is easier to protect against accidental misuse
than against malicious misuse. For the most part protection mechanisms are
the core of protection from accidents. The following list includes several forms
of accidental and malicious security violations. We should note that in our
discussion of security, we use the terms intruder and cracker for those attempting
to breach security. In addition, a is the potential for a security violation,
such as the discovery of a vulnerability, whereas an is the attempt to
break security.
Breach of confidentiality. This type of violation involves 1mauthorized
reading of data (or theft of information). Typically, a breach of confidentiality
is the goal of an intruder. Capturing secret data from a system or
a data stream, such as credit-card information or identity information for
identity theft, can result directly in money for the intruder.
Breach of integrity. This violation involves unauthorized modification
of data. Such attacks can, for example, result in passing of liability to
an innocent party or modification of the source code of an important
commercial application.
Breach of availability. This violation involves unauthorized destruction of
data. Some crackers would rather wreak havoc and gain status or bragging
rights than gain financially. Web-site defacement is a common example of
this type of security breach.
Theft of service. This violation involves unauthorized use of resources.
For example, an intruder (or intrusion program) may install a daemon on
a system that acts as a file server.
Denial of service. This violation involves preventing legitimate use of the
system. or attacks are sometimes accidental. The
original Internet worm turned into a DOS attack when a bug failed to delay
its rapid spread. We discuss DOS attacks further in Section 15.3.3.
Attackers use several standard methods in their attempts to breach
security. The most common is in which one participant in
a communication pretends to be someone (another host or another
person). By masquerading, attackers breach the correctness
of identification; they can then gain access that they would not normally be
allowed or escalate their privileges-obtain privileges to which they would not
normally be entitled. Another common attack is to replay a captured exchange
of data. A consists of the malicious or fraudulent repeat of a
valid data transmission. Sometimes the replay comprises the entire attackfor
example, in a repeat of a to transfer money. But frequently it is
done along with again to escalate privileges. Consider
15.1 623
Normal
attacker
Masquerading
attacker
Man-in-the-middle
attacker
Figure 15.1 Standard security attacks.
the damage that could be done if a request for authentication had a legitimate
user's information with an unauthorized user's. Yet another kind of
attack is the in which an attacker sits in the data
flow of a communication, masquerading as the sender to the receiver, and
vice versa. In a network communication, a man-in-the-middle attack may be
preceded by a in which an active communication session is
intercepted. Several attack methods are depicted in Figure 15.1.
As we have already suggested, absolute protection of the system from
malicious abuse is not possible, but the cost to the perpetrator can be made
sufficiently high to deter most intruders. In some cases, such as a denial-ofservice
attack, it is preferable to prevent the attack but sufficient to detect the
attack so that cmmtermeasures can be taken.
To protect a system, we must take security measures at four levels:
Physical. The site or sites containing the computer systems must be
physically secured against armed or surreptitious entry by intruders.
Both the machine rooms and the terminals or workstations that have
access to the machines must be secured.
624 Chapter 15
must be done carefully to assure that only
access to the system. Even authorized users/
to let others use their access (in exchange
They may also be tricked into allowing
One type of social-engineering attack
Here, a legitimate-looking e-mail or Web page misleads
a user into entering confidential information. Another teclucique is
Human. Authorization
appropriate users have
however, may be
for a bribe, for
access via
is
a general term for attempting to gather information in
order to gain unauthorized access to the computer (by looking through
trash, finding phone books, or finding notes containing passwords, for
example). These security problems are management and personnel issues,
not problems pertaining to operating systems.
Operating system. The system must protect itself from accidental or
purposeful security breaches. A runaway process could constitute an
accidental denial-of-service attack. A query to a service could reveal passwords.
A stack overflow could the launching of an unauthorized
process. list of possible breaches is almost endless.
Network. Much computer data in modern systems travels over private
leased lines, shared lines like the Internet, wireless connections, or dial-up
lines. Intercepting these data could be just as harmful as breaking into a
computer; and interruption communications could constitute a remote
denial-of-service attack, diminishing users' use of and trust in the system.
at the first two levels must be Inaintained if operating-system
is to be ensured. A weakness at a high security (physical or
allows circumvention of strict low-level (operating-system) security
measures. the old adage that a chaL.'l is as weak as its weakest link is
true of system security. All these aspects must be addressed for
to be maintained.
to allow the
more
is As intruders
countermeasures are created and deployed.
This causes intruders to become more in their attacks. For
incidents include the use of to
Section
tools needed to block the
In the remainder of this
15
15.2 625
ways, ranging from passwords for authentication through guarding against
viruses to detecting intrusions. We start with an exploration of security threats.
Processes, along with the kernel, are the only means of accomplishing work
on a computer. Therefore, writing a program that creates a breach of security,
or causing a normal process to change its behavior and create a breach, is a
common goal of crackers. In fact even most nonprogram security events have
as their goal causing a program threat. For example, while it is useful to log in
to a without authorization, it is quite a lot more useful to leave behind
a daemon that provides information or allows easy access even if
the original exploit is blocked. In this section, we describe common methods
which programs cause security breaches. Note that there is considerable
variation in the naming conventions of security holes and that we use the most
common or descriptive terms.
15.2.1 Horse
systems have mechanisms for allowing programs written by users to
be executed by other users. If these programs are executed in a domain that
provides the access rights of the executing user, the other users may misuse
these rights. A text-editor program, for example, may include code to search
the file to be edited for certairl keywords. If any are found, the entire file
may be to a special area accessible to the creator of the text editor.
A code segment that misuses its environment is called a Long
search paths, as are common on UNIX systems, exacerbate the Trojanhorse
The search path lists the set of directories to search when an
program name is given. The is searched for a file of that
name, and the file is executed. All the directories in such a search path must
be secure, or a horse could be slipped into the user's and executed
consider the use of the  .   character in a search path. The  .  
to include the current directory in the search. if a user has
  .  in her search has set her current to a friend's directory, and
enters the name of a normal system commanct be executed
from the friend's instead. The program would run the user's
to do anything that the user is allowed to
the user's instance.
horse is a that emulates a
What
626 Chapter 15
such as the control-alt-delete conlbination used by all modern Windows
operating systems.
Another variation on the Trojan horse is Spyware sometimes
accompanies a program that the user has chosen to install. Most frequently, it
comes along with freeware or shareware programs, but sometimes it is included
with commercial software. The goal of spyware is to download ads to display
on the user's system, create when certain sites are
visited, or capture information from the user's system and return it to a central
site. This latter is an example of a general category of attacks known as
in which surreptitious communication occurs. For example,
the installation of an innocuous-seeming program on a Windows system could
result in the loading of a spyware daemon. The spyware could contact a central
site, be given a message and a list of recipient addresses, and deliver the spam
message to those users from the Windows machine. This process continues
until the user discovers the spyware. Frequently, the spyware is not discovered.
In 2004, it was estimated that 80 percent of spam was being delivered by this
method. This theft of service is not even considered a crime in most countries!
Spyware is a micro example of a macro problem: violation of the principle
of least privilege. Under most circumstances, a user of an operating system
does not need to install network daemons. Such daemons are installed via
two mistakes. First, a user may run with more privileges than necessary (for
example, as the administrator), allowing programs that she runs to have more
access to the system than is necessary. This is a case of human error-a common
security weakness. Second, an operating system may allow by default more
privileges than a normal user needs. This is a case of poor operating-system
design decisions. An operating system (and, indeed, software in general)
should allow fine-grained control of access and security, but it must also be easy
to manage and understand. Inconvenient or inadequate security measures are
bound to be circumvented, causing an overall weakening of the security they
were designed to implement.
15.2.2 Trap Door
The designer of a program or system might leave a hole in the software that only
he is capable of using. This type of security breach (or was shown in
the movie War Games. For instance, the code Inight check a specific user ID or
password, and it might circumvent normal security procedures. Programmers
have been arrested for embezzling from banks by including rounding errors
in their code and having the occasional half-cent credited to their accounts.
This account credititrg can add up to a large amount of money, considering the
number of transactions that a large bank executes.
A clever trap door could be included in a compiler. The compiler could
generate standard object code as well as a trap door, regardless of the source
code being compiled. This activity is particularly nefarious, since a search of
the source code of the program will not reveal any problems. Only the source
code of the compiler would contain the information.
Trap doors pose a difficult problem because, to detect them, we have to
analyze all the source code for all components of a system. Given that software
systems may consist of millions of lines of code, this analysis is not done
frequently, and frequently it is not done at all!
15.2 627
15.2.3 Logic Bomb
Consider a program that initiates a security incident only under certain
circLtmstances. It would be hard to detect because under normal operations,
there would be no security hole. However, when a predefined set of parameters
were met, the security hole would be created. This scenario is known as a
A programmer, for example, might write code to detect whether
was still employed; if that check failed, a daemon could be spawned to allow
remote access, or code could be launched to cause damage to the site.
15.2.4 Stack and Buffer Overflow
The stack- or buffer-overflow attack is the most common way for an attacker
outside the system, on a network or dial-up connection, to gain unauthorized
access to the target system. An authorized user of the system may also use this
exploit for privilege escalation.
Essentially, the attack exploits a bug in a program. The bug can be a simple
case of poor programming, in which the programmer neglected to code bounds
checking on an input field. In this case, the attacker sends more data than the
program was expecting. By using trial and error, or by examining the source
code of the attacked program if it is available, the attacker determines the
vulnerability and writes a program to do the following:
Overflow an input field, command-line argument, or input buffer-for
example, on a network daemon-wl.til it writes into the stack.
Overwrite the current return address on the stack with the address of the
exploit code loaded in step 3.
Write a simple set of code for the next space in the stack that includes
the commands that the attacker wishes to execute-for instance, spawn
a shell.
The result of this attack program's execution will be a root shell or other
privileged command execution.
For instance, if a Web-page form expects a user name to be entered into a
field, the attacker could send the user name, plus extra characters to overflow
the buffer and reach the stack, plus a new return address to load onto the stack,
plus the code the attacker wants to run. When the buffer-reading subroutine
returns from execution, the return address is the exploit code, and the code
is run.
Let's look at a buffer-overflow exploit in more detail. Consider the simple
C program in Fig1-1re 15.2. This program creates a character array
size BUFFER_SIZE and copies the contents of the parameter provided on the
command line-argv [1]. As long as the size of this parameter is less than
BUFFER_SIZE (we need one byte to store the null terminator), this program
works properly. But consider what happens if the parameter provided on the
command line is longer than BUFFER_SIZE. In this scenario, the strcpy ()
function will begin copying from argv [1] until it encounters a null terminator
(\0) or until the program crashes. Thus, this program suffers from a potential
problem in which copied data overflow the buffer array.
628 Chapter 15
#include   stdio.h  
#define BUFFER_SIZE 256
int main(int argc, char   argv[])
{
}
char buffer[BUFFER_SIZE];
if (argc    2)
return -1;
else {
strcpy(buffer,argv[1]);
return 0;
}
Figure   15.2 C program with buffer-overflow condition.
Note that a careful programmer could have performed bounds checking
on the size of argv [1] by using the strncpy () function rather than strcpy (),
replacing the line   strcpy(buffer, argv [1]);   with   strncpy(buffer,
argv[1], sizeof(buffer)-1) ;  .Unfortunately, good bounds checking is
the exception rather than the norm.
Furthermore, lack of bounds checking is not the only possible cause of the
behavior of the program in Figure 15.2. The program could instead have been
carefully designed to compromise the integrity of the system. We now consider
the possible security vulnerabilities of a buffer overflow.
When a function is invoked in a typical computer architecture, the variables
defined locally to the function (sometimes known as automatic variables), the
parameters passed to the function, and the address to which control returns
once the function exits are stored in a stack frame. The layout for a typical stack
frame is shown in Figure 15.3. Examining the stack frame from top to bottom,
we first see the parameters passed to the function, followed by any automatic
variables declared in the function. We next see the frame pointer, which is
the address of the beginning of the stack frame. Finally, we have the return
bottom ~ frame pointer
grows
top
Figure 15.3 The layout for a typical stack frame.
15.2 629
address, which specifies where to return control once the function exits. The
frame pointer must be saved on the stack, as the value of the stack pointer can
vary during the function call; the saved frame pointer allows relative access to
parameters and automatic variables.
Given this standard memory layout, a cracker could execute a bufferoverflow
attack. I-:Ter goal is to replace the return address in the stack frame so
that it now points to the code segment containing the attacking program.
The programmer first writes a short code segment such as the following:
#include   stdio.h  
int main(int argc, char   argv[])
{
execvp(' '\bin\sh'', ''\bin \sh'', NULL);
return 0;
Using the execvp () system call, this code segment creates a shell process.
If the program being attacked runs with system-wide permissions, this newly
created shell will gain complete access to the system. Of course, the code
segment could do anything allowed by the privileges of the attacked process.
This code segment is then compiled so that the assembly language instructions
can be modified. The primary modification is to remove unnecessary features
in the code, thereby reducing the code size so that it can fit into a stack frame.
This assembled code fragment is now a binary sequence that will be at the
heart of the attack.
Refer again to the program shown in Figure 15.2. Let's assume that when
the main () function is called in that program, the stack frame appears as
shown in Figure 15.4(a). Using a debugger, the programmer then finds the
copied
(a) (b)
Figure 15.4 Hypothetical stack frame for Figure 15.2, (a) before and (b) after.
630 Chapter 15
address of buffer [0] in the stack. That address is the location of the code the
attacker wants executed. The binary sequence is appended with the necessary
amount of NO-OP instructions (for NO-OPeration) to fill the stack frame up
to the location of the return address; and the location. of buffer [0], the new
return address, is added. The attack is complete when the attacker gives this
constructed binary sequence as input to the process. The process then copies
the binary sequence from argv [1] to position buffer [0] in the stack frame.
Now, when control returns from main (), instead of returning to the location
specified by the old value of the return address, we return to the modified shell
code, which runs with the access rights of the attacked process! Figure 15.4(b)
contains the modified shell code.
There are many ways to exploit potential buffer-overflow problems. In
this example, we considered the possibility that the program being attackedthe
code shown in Figure 15.2-ran with system-wide permissions. However,
the code segment that runs once the value of the return address has been
modified might perform any type of malicious act, such as deleting files,
opening network ports for further exploitation, and so on.
This example buffer-overflow attack reveals that considerable knowledge
and programming skill are needed to recognize exploitable code and then
to exploit it. Unfortunately, it does not take great programmers to launch
security attacks. Rather, one cracker can determine the bug and then write an
exploit. Anyone with rudimentary computer skills and access to the exploita
so-called then try to launch the attack at target systems.
The buffer-overflow attack is especially pernicious because it can be run
between systems and can travel over allowed communication channels. Such
attacks can occur within protocols that are expected to be used to communicate
with the target machine, and they can therefore be hard to detect and prevent.
They can even bypass the security added by firewalls (Section 15.7).
One solution to this problem is for the CPU to have a feature that disallows
execution of code in a stack section of memory. Recent versions of Sun's SPARC
chip include this setting, and recent versions of Solaris enable it. The return
address of the overflowed routine can still be modified; but when the return
address is within the stack and the code there attempts to execute, an exception
is generated, and the program is halted with an error.
Recent versions of AMD and Intel x86 chips include the NX feature to prevent
this type of attack The use of the feature is supported in several x86 operating
systems, including Linux and Windows XP SP2. The hardware implementation
involves the use of a new bit in the page tables of the CPUs. This bit marks
the associated page as nonexecutable, so that instructions cannot be read from
it and executed. As this feature becomes prevalent, buffer-overflow attacks
should greatly diminish.
15.2.5 Viruses
Another form of program threat is a A virus is a fragment of code embedded
in a legitimate program. Viruses are self-replicating and are designed to
  infect   other programs. They can wreak havoc in a system by modifying or
destroying files and causing system crashes and program malfunctions. As
with most penetration attacks, viruses are very specific to architectures, operating
systems, and applications. Viruses are a particular problem for users of
15.2 631
PCs. UNIX and other multiuser operating systems generally are not susceptible
to viruses because the executable programs are protected from writing by the
operating system. Even if a virus does infect such a progran:1, its powers usually
are limited because other aspects of the system are protected.
Viruses are usually borne via e-mail, with spam the most comrnon vector.
They can also spread when users download viral programs Internet
file-sharing services or exchange infected disks.
Another common form of virus transmission uses Microsoft Office files,
such as Microsoft Word documents. These documents can contain macros
Visual Basic programs) that programs in the Office suite PowerPoint,
and Excel) will execute automatically. Because these programs run under the
user's own account, the macros can run largely unconstrained (for example,
deleting user files at will). Commonly, the virus will also e-mail itself to others
in the user's contact list. Here is a code sample that shows the simplicity of
writing a Visual Basic macro that a virus could use to format the hard drive of
a Windows computer as soon as the file containing the macro was opened:
Sub AutoOpen ()
Dim oFS
Set oFS = CreateObject(' 'Scripting.FileSystemObject'')
vs =Shell(' 'c: command.com /k format c:' ',vbHide)
End Sub
How do viruses work  Once a virus reaches a target machine, a program
known as a inserts the virus into the system. The virus dropper
is usually a Trojan horse, executed for other reasons but installing the virus
as its core activity. Once installed, the virus may do any one of a number of
things. There are literally thousands of viruses, but they fall into several main
categories. Note that many viruses belong to more than one category.
File. A standard file virus infects a system by appending itself to a file.
It changes the start of the program so that execution jumps to its code.
After it executes, it returns control to the program so that its execution is
not noticed. File viruses are sometimes known as parasitic viruses, as they
leave no full files behind and leave the host program still functional.
Boot. A boot virus infects the boot sector of the system, executing every
time the system is booted and before the operating system is loaded. It
watches for other boatable media (that is, floppy disks) and infects them.
These viruses are also known as memory viruses, because they do not
appear in the file system. Figure 15.5 shows how a boot virus works.
Macro. Most viruses are written in a low-levellanguage, such as assembly
or C. Macro viruses are written in a high-level language, such as Visual
Basic. These viruses are triggered when a program capable of executing
the macro is run. For example, a macro virus could be contained in a
spreadsheet file.
Source code. A source code virus looks for source code and modifies it to
include the virus and to help spread the virus.
632 Chapter 15
Figure i 5.5 A boot-sector computer virus.
Polymorphic. A polymorphic virus changes each time it is installed to
avoid detection by antivirus software. The changes do not affect the virus's
functionality but rather change the virus's signature. A
a pattern that Cili'i be used to identify a virus, typically a series
make up the virus code.
Encrypted. An encrypted virus includes decryption code along with the
encrypted virus, again to avoid detection. The virus first decrypts and then
executes.
Stealth. This tricky virus attempts to avoid detection by modifying parts
of the system that could be used to detect it. For example, it could modify
the read system call so that if the file it has modified is read, the original
form of the code is returned rather than the infected code.
Tunneling. This virus attempts to bypass detection by an anti virus scanner
by installing itself in the interrupt-handler chain. Similar viruses install
themselves in device drivers.
15.3
15.3 633
Multipartite. A virus of this type is able to infect nmltiple parts of a system,
including boot sectors, memory, and files. This makes it difficult to detect
and contain.
Armored. An armored virus is coded to ncake it hard for antivirus
researchers to unravel and understand. It can also be compressed to avoid
detection and disinfection. In addition, virus droppers and other full files
that are part of a virus infestation are frequently hidden via file attributes
or unviewable file names.
This vast variety of viruses is likely to continue to grow. In fact, in 2004
a new and widespread virus was detected. It exploited three separate bugs
for its operation. This virus started by infecting hundreds of Windows servers
(including many trusted sites) running Microsoft Internet Information Server
(IIS). Any vulnerable Microsoft Explorer Web browser visiting those sites
received a browser virus with any download. The browser virus installed
several back-door programs, including a which records
all things entered on the keyboard (including and credit-card
numbers). It also installed a daemon to allow unlimited remote access by
an intruder and another that allowed an intruder to route spam through the
infected desktop computer.
Generally, viruses are the most disruptive security attacks; and because
they are effective, they will continue to be written and to spread. the
active debates within the computing community is whether a JtH'-YHcn;_
in which many systems run the same hardware, operating system, and/ or
application software, is increasing the threat of and damage caused by security
intrusions. This monoculture supposedly consists of Microsoft products, and
part of the debate concerns whether such a monoculture even exists today.
Program threats typically use a breakdown in the protection mechanisms of a
system to attack programs. In contrast, system and network threats involve the
abuse of services and network comcections. System and network threats create
a situation in which operating-system resources and user files are Inisused.
Sometimes a system and network attack is used to launch a program attack,
and vice versa.
The more an operating system is-the more services it has enabled
and the more functions it allows-the more likely it is that a is available
to exploit. Increasingly, operating systems strive to be
For example, Solaris 10 moved from a model in which many services (FTP,
telnet, and others) were enabled by default when the system was installed
to a model in which almost all services are disabled at installation time and
must specifically be enabled system administrators. Such changes reduce
the system's set of ways in which an attacker can to
break into the system.
In the remainder of this section, we discuss some examples of system
and network threats, including worms, port scamcing, and denial-of-service
attacks. It is important to note that masquerading and replay attacks are also
634 Chapter 15
commonly launched over netvvorks between systems. In fact, these attacks
are more effective and harder to counter when multiple systems are involved.
For example, within a computer, the operating system usually can determine
the sender and receiver of a message. Even if the sender changes to the ID of
someone else, there may be a record of that ID change. When multiple systems
are involved, especially systems controlled by attackers, then such tracing is
much more difficult.
In general, we can say that sharing secrets (to prove identity and as keys to
encryption) is required for authentication and encryption, and sharing secrets
is easier in environments (such as a single operating system) in which secure
sharing methods exist. These methods include shared memory and interprocess
comnmnications. Creating secure communication and authentication is
discussed in Sections 15.4 and 15.5.
15.3.1 Worms
A is a process that uses the mechanism to ravage system
performance. The worm spawns copies of itself, using up system resources
and perhaps locking out all other processes. On computer networks, worms
are particularly potent, since they may reproduce themselves among systems
and thus shut down an entire network. Such an event occurred in 1988 to UNIX
systems on the Internet, causing the loss of system and system-administrator
time worth millions of dollars.
At the close of the workday on November 2, 1988, Robert Tappan Morris,
Jr., a first-year Cornell graduate student, unleashed a worm program on one
or more hosts corm.ected to the Internet. Targeting Sun Microsystems' Sun 3
workstations and VAX computers running variants of Version 4 BSD UNIX, the
worm quickly spread over great distances; within a few hours of its release,
it had consumed system resources to the point of bringing down the infected
machines.
Although Robert Morris designed the self-replicating program for rapid
reproduction and distribution, some of the features of the UNIX networking
environment provided the means to propagate the worm throughout the system.
It is likely that Morris chose for in.itial infection an Internet host left open
for and accessible to outside users. From there, the worm program exploited
flaws in the UNIX operating system's security routines and took advantage
of UNIX utilities that simplify resource sharing in local-area networks to gain
unauthorized access to thousands of other connected sites. Morris's methods
of attack are outlined next.
The worm was made up of two programs, a (also called a
or program and the main program. ll.c, the grappling
hook consisted of 99 lines of C code compiled and run on each machine it
accessed. Once established on the computer system under attack, the grappling
hook connected to the machine where it originated and uploaded a copy of the
main worm onto the hooked system (Figure 15.6). The main program proceeded
to search for other machines to which the newly infected system could connect
easily. In these actions, Morris exploited the UNIX networking utility rsh for
easy remote task execution. By setting up special files that list host-login
name pairs, users can omit entering a password each time they access a remote
account on the paired list. The worm searched these special files for site names
15.3 635
rsh attack
finger attack
sendmail attack
worm sent
target system infected system
Figure 15.6 The Morris Internet worm.
that would allow remote execution without a password. Where remote shells
were established, the worm program was uploaded and began executing anew.
The attack via remote access was one of three infection methods built into
the worm. The other two methods involved operating-system bugs in the UNIX
finger and sendmail programs.
The finger utility functions as an electronic telephone directory; the
command
finger user-name hostname
returns a person's real and login names along with other information that
the user may have provided, such as office and home address and telephone
number, research plan, or clever quotation. Finger runs as a background
process (or daemon) at each BSD site and responds to queries throughout the
Internet. The worm executed a buffer-overflow attack on finger. The program
queried finger with a 536-byte string crafted to exceed the buffer allocated
for input and to overwrite the stack frame. Instead of returning to the main
routine where it resided before Morris's calt the finger daemon was routed
to a procedure within the invading 536-byte string now residing on the stack
The new procedure executed /bin/ sh, which, if successful, gave the worm a
remote shell on the machine under attack.
The bug exploited in sendmail also involved using a daemon process
for malicious entry. sendmail sends, receives, and routes electronic mail.
Debugging code in the utility permits testers to verify and display the state of
the ncail system. The debugging option was useful to system administrators
and was often left on. Morris included in his attack arsenal a call to debug that
-instead of specifying a user address, as would be normal in testing-issued
a set of cornmands that mailed and executed a copy of the grappling-hook
program.
Once in place, the main worm systematically attempted to discover user
passwords. It began by trying simple cases of no password or passwords
constructed of account-user-name combinations, then used comparisons with
an internal dictionary of 432 favorite password choices, and then went to the
636 Chapter 15
final stage of trying each word in the standard UNIX on-line dictionary as a
possible password. This elaborate and efficient three-stage password-cracking
algorithm enabled the worm to gain access to other user accounts on the
infected system. The wonTt then searched for rsh data files in these newly
broken accounts and used them as described previously to gain access to user
accounts on remote systems.
With each new access, the worm program searched for already active
copies of itself. If it found one, the new copy exited, except in every seventh
instance. Had the worm exited on all duplicate sightings, it might have
remained undetected. Allowing every seventh duplicate to proceed (possibly
to confound efforts to stop its spread baiting with fake worms) created a
wholesale infestation of Sun and VAX systems on the Internet.
The very features of the UNIX network environment that assisted il  l the
worm's propagation also helped to stop its advance. Ease of electronic communication,
mechanisms to copy source and binary files to remote machines, and
access to both source code and human expertise allowed cooperative efforts to
develop solutions quickly. By the evening of the next day, November 3, methods
of halting the invading program were circulated to system administrators via
the Internet. Within days, specific software patches for the exploited security
flaws were available.
Why did Morris unleash the worm  The action has been characterized
as both a harmless prank gone awry and a serious criminal offense. Based
on the complexity of the attack, it is unlikely that the worm's release or the
scope of its spread was unintentional. The worm program took elaborate steps
to cover its tracks and to repel efforts to stop its spread. Yet the program
contained no code aimed at damaging or destroying the systems on which it
ran. The author clearly had the expertise to include such commands; in fact,
data structures were present in the bootstrap code that could have been used to
transfer Trojan-horse or virus programs. The behavior of the program may lead
to interesting observations, but it does not provide a sound basis for inferring
motive. What is not open to speculation, however, is the legal outcome: A
federal court convicted Morris and handed down a sentence of three years'
probation, 400 hours of community service; and a $10,000 fine. Morris's legal
costs probably exceeded $100,000.
Security experts continue to evaluate methods to decrease or eliminate
worms. A more recent event; though, shows that worms are still a fact of
life on the Internet. It also shows that as the Internet grows, the damage
that even   harmless   worms can do also grows and can be significant. This
example occurred during August 2003. The fifth version of the   Sobig   worm,
more properly known as   W32.Sobig.F@mm,   was released by persons at this
time unknown. It was the fastest-spreading worm released to date, at its peak
mfecting hundreds of thousands of computers and one in seventeen e-mail
messages on the Internet. It clogged e-mail inboxes, slowed networks, and
took a huge number of hours to clean up.
Sobig.F was launched by being uploaded to a pornography newsgroup via
an account created with a stolen credit card. It was disguised as a photo. The
virus targeted Microsoft Windows systems and used its own SMTP engine to
e-mail itself to all the addresses found on an infected system. It used a variety
of subject lines to help avoid detection, including   Thank You!     Your details,''
and   Re: Approved.   It also used a random address on the host as the   From:  
15.3 637
address, making it difficult to determine from the message which machine was
the infected source. Sobig.F included an attachment for the target e-mail reader
to click on, again with a variety of names. If this payload was executed, it stored
a program called WINPPR32.EXE in the default Windows directory, along with
a text file. It also modified the Windows registry.
The code included in the attachment was also programmed to periodically
attempt to connect to one of twenty servers and download and execute a
program from them. Fortunately, the servers were disabled before the code
could be downloaded. The content of the program from these servers has not
yet been determined. If the code was malevolent, untold damage to a vast
number of machines could have resulted.
15.3.2 Port Scanning
Port scanning is not an attack but rather a means for a cracker to detect
a system's vulnerabilities to attack. Port scanning typically is automated,
involving a tool that attempts to create a TCP liP connection to a specific port
or a range of ports. For example, suppose there is a known vulnerability (or
bug) in sendmail. A cracker could launch a port scanner to try to connect, say,
to port 25 of a particular system or to a range of systems. If the connection
was successful, the cracker (or tool) could attempt to communicate with the
answering service to determine if the service was indeed sendmail and, if so,
if it was the version with the bug.
Now imagine a tool in which each bug of every service of every operath  g
system was encoded. The tool could attempt to connect to every port of one
or nwre systems. For every service that answered, it could try to use each
known bug. Frequently, the bugs are buffer overflows, allowing the creation of
a privileged command shell on the system. From there, of course, the cracker
could install Trojan horses, back-door programs, and so on.
There is no such tool, but there are tools that perform subsets of that
functionality. For example, nmap (from http:/ /www.insecure.org/mrtap/) is
a very versatile open-source utility for network exploration and security
auditing. When pointed at a target, it will determine what services are n.1n..Tling,
including application names and versions. It can identify the host operating
system. It can also provide information about defenses, such as what firewalls
are defending the target. It does not exploit any known bugs.
Nessus (from http:/ /www.nessus.org/) performs a similar function, but
it has a database of bugs and their exploits. It can scan a range of systems,
determine the services running on those systems, and attempt to attack all
appropriate bugs. It generates reports about the results. It does not perform
the final step of exploiting the found bugs, but a knowledgeable cracker or a
script kiddie could.
Because port scans are detectable (Section 15.6.3), they frequently are
launched from Such systems are previously compromised,
independent systems that are serving their owners while being used for nefarious
purposes, including denial-of-service attacks and spam relay. Zombies
make crackers particularly difficult to prosecute because determining the
source of the attack and the person that launched it is challenging. This is
one of many reasons for securing   inconsequential   systems, not just systems
containing   valuable   information or services.
638 Chapter 15
15.3.3 Denial of Service
As mentioned earlier, denial-of-service attacks are aimed not at gaming
information or stealing resources but rather at disrupting legitimate use of
a system or facility. Most such attacks involve systems that the attacker has
not penetrated. Indeed, launching an attack that prevents legitimate use is
frequently easier than breaking into a machine or facility.
Denial-of-service attacks are generally network based. They fall into two
categories. Attacks in the first category use so many facility resources that,
in essence, no useful work can be done. For example, a Web-site click could
download a Java applet that proceeds to use all available CPU time or to pop up
windows infinitely. The second category involves disrupting the network of
the facility. There have been several successful denial-of-service attacks of this
kind against major Web sites. These attacks result from abuse of some of the
fundamental functionality of TCP liP. For instance, if the attacker sends the part
of the protocol that says   I want to start a TCP connection,   but never follows
with the standard   The connection is now complete,   the result can be partially
started TCP sessions. If enough of these sessions are launched, they can eat up
all the network resources of the system, disabling any further legitimate TCP
connections. Such attacks, which can last hours or days, have caused partial or
full failure of attempts to use the target facility. The attacks are usually stopped
at the network level until the operating systems can be updated to reduce their
vulnerability.
Generally, it is impossible to prevent denial-of-service attacks. The attacks
use the same mechanisms as normal Even more difficult to prevent
and resolve are These attacks
are launched from multiple sites at once, toward a common target, typically
by zombies. DDOS attacks have become more comncon and are sometimes
associated with blackmail attempts. A site comes under attack, and the
attackers offer to halt the attack in exchange for money.
Sometimes a site does not even know it is under attack. It can be difficult
to determine whether a system slowdown is an attack or just a surge in system
use. Consider that a successful advertising campaign that greatly increases
traffic to a site could be considered a DDOS.
There are other interesting aspects of DOS attacks. For example, if an
authentication algorithm locks an account for a period of time after several
incorrect attempts to access the account, then an attacker could cause all
authentication to be blocked by purposely making incorrect attempts to access
all accounts. Similarly, a firewall that automatically blocks certain kinds of
traffic could be induced to block that traffic when it should not. These examples
suggest that programmers and systems managers need to fully understand the
algorithms and technologies they are deploying. Finally, computer science
classes are notorious sources of accidental system DOS attacks. Consider the
first programming exercises in which students learn to create subprocesses
or threads. A common bug involves spawning subprocesses infinitely. The
system's free memory and CPU resources don't stand a chance.
There are many defenses against computer attacks, running the gamut from
methodology to technology. The broadest tool available to system designers
15.4 639
and users is cryptography. In this section, we discuss the details of cryptography
and its use in computer security.
In an isolated computer, the operating system can reliably determine the
sender and recipient of ali interprocess communication, since it controls all
communication channels in the computer. In a network of computers, the
situation is quite different. A networked computer receives bits from the
wire with no immediate and reliable way of determining what machine or
application sent those bits. Similarly, the computer sends bits onto the network
with no of knowing who might eventually receive them.
Commonly, network addresses are used to infer the potential senders
and receivers of network messages. Network packets arrive with a source
address, such as an IP address. And when a computer sends a message, it
names the intended receiver by specifying a destination address. However, for
applications where security matters, we are asking for trouble if we assume
that the source or destination address of a packet reliably determines who sent
or received that packet. A rogue computer can send a message with a falsified
source address, and numerous computers other than the .. one specified by the
destination address can (and typically do) receive a packet. For example, all of
the routers on the way to the destination will receive the packet, too. How, then,
is an operating system to decide whether to grant a request when it cannot trust
the named source of the request  And how is it supposed to provide protection
for a request or data when it cannot determine who will receive the response
or message contents it sends over the network 
It is generally considered infeasible to build a network of any scale in
which the source and destination addresses of packets can be trusted in this
sense. Therefore, the only alternative is somehow to eliminate the need to
trust the network. This is the job of cryptography. Abstractly, ~  ''  ~.,-ro.rnron~
used to constrain the potential senders and/ or receivers of a message.
cryptography is based on secrets called that are selectively distributed to
computers in a network and used to process messages. Cryptography enables a
recipient of a message to verify that the message was created by some computer
possessing a certain key-the key is the source of the message. Similarly: a
sender can encode its message so that only a computer with a certain key can
decode the message, so that the key becomes the destination. Unlike network
addresses, however, keys are designed so that it is not computationally feasible
to derive them from the messages they were used to generate or from any
other public information. Thus, they provide a much more trustworthy means
of constraining senders and receivers of messages. Note that cryptography is
a field of study unto itself, with large and small complexities and subtleties.
Here, we explore the most important aspects of the parts of cryptography that
pertain to operating systems.
15.4.1 Encryption
Because it solves a wide variety of communication security problems,
is used frequently in many aspects of modern computing. Encryption
a means for constraining the possible receivers of a message. An encryption
algorithm enables the sender of a message to ensure that only a computer
possessing a certain key can read the message. Encryption of messages is an
ancient practice, of course, and there have been many encryption algorithms,
640 Chapter 15
dating back to ancient times. In this section, we describe important modern
encryption principles and algorithms.
Figure 15.7 shows an example of two users communicating securely over
an insecure channel. We refer to this figure throughout the section. Note that the
key exchange can take place directly between the two parties or via a trusted
third party (that is, a certificate authority), as discussed in Section 15.4.1.4.
An encryption algorithm consists of the following components:
A set K of keys.
A set M of messages.
A set C of ciphertexts.
A function E : K --+ ( M --+ C). Thatis, for each k E K, E (k) is a function for
generating ciphertexts from messages. Both E and E (lc) for any k should
be efficiently computable functions.
A function D: I   --+ (C --+ M). Thatis, for eachlc E I  , D(k) is a function for
generating messages from ciphertexts. Both D and D(lc) for any k should
be efficiently computable functions.
An encryption algorithm must provide this essential property: given a ciphertext
c E C a computer can compute m such that E (lc)(m) = c only if it possesses
write ----1 rnessage rn 1
I
II 12.
0 ~-
z~ -x
~-
read 1 message ml
Figure i5.7 A secure communication over an insecure medium.
15.4 641
D(lc). Thus, a computer holding D(lc) can decrypt ciphertexts to the plaintexts
used to produce them, but a computer not holding D(lc) cannot decrypt ciphertexts.
Since ciphertexts are generally exposed (for example, sent on a network),
it is important that it be infeasible to derive D(lc) from the ciphertexts.
There are two main types of encryption algorithms: symmetric and
asymmetric. We discuss both types in the following sections.
15.4.1.1 Symmetric Encryption
In a the same key is used to encrypt and to
decrypt. That is, E can be from D(lc), and vice versa. Therefore, the
secrecy of E (lc) must be protected to the same extent as that of D(lc).
For the past several decades, the most commonly used symmetric encryption
algorithm in the United States for civilian applications has been the
adopted by the National Institute of StanTechxwlogy
(NIST). DES works by taking a 64-bit value and a 56-bit
key and performing a series of transformations. These transformations are
based on substitution and permutation operations, as is generally the case
for symmetric encryption transformations. Some of the transformations are
in that their algorithms are hidden. In fact, these
so-called   S-boxes   are classified by the United States government. Messages
longer than 64 bits are broken into 64-bit chunks. Because DES works on a
chunk of bits at a time, is known as a cipher. If the same key is used
for encrypting an extended anwunt of data, it becomes vulnerable to attack.
Consider, for example, that the same source block would result in the same
ciphertext if the same key and encryption algorithm were used. Therefore,
the chunks are not just encrypted but also exclusive-or'ed (XORed) with the
ciphertext block before encryption. This is known as
DES is now considered insecure for many applications because its keys can
be exhaustively searched with moderate computing resources. Rather than
giving up on DES, though, NIST created a modification called in
which the DES algorithm is repeated three times (two encryptions and one
decryption) on the same plaintext usli'lg two or three keys-for example,
c = E (k3 )(D(lc2)(E (K1)(m))). When three keys are used, the effective key length
is 168 bits. Triple DES is in widespread use today.
In 2001, NIST a new encryption algorithm, called the
to replace DES. AES is another symmetric block
cipher. It can use key lengths of 128, 192, and 256 bits and works on 128-bit
blocks. It works by performing 10 to 14 rounds of transformations on a matrix
formed from a block Generally, the algorithm is compact and efficient.
Several other symmetric block encryption algorithms in use today bear
mentioning. The algorithm is fast compact, and easy to implement. It
can use a variable key length of up to 256 bits and works on 128-bit blocks.
can vary in key length, number of transformations, and block size. Because it
uses only basic computational operations, it can run on a wide variety of crus.
is perhaps the most common stream cipher. A is
designed to encrypt and decrypt a stream of bytes or bits rather than a block.
This is useful when the length of a communication would make a block cipher
too slow. The key is input into a pseudo-random-bit generator, which is an
642 Chapter 15
algorithm that attempts to produce random bits. The output of the generator
when fed a key is a keystream. A is an infinite set of keys that can be
used for the input plaintext stream. RC4 is used in encrypting steams of data,
such as in WEP, the wireless LAN protocol. lt is also used in communications
between Web browsers and Web servers, as we discuss below. Unfortunately,
RC4 as used in WEP (IEEE standard 802.11) has been found to be breakable in a
reasonable amount of con1.puter time. In fact RC4 itself has vulnerabilities.
15.4.1.2 Asymmetric Encryption
In an there are different encryption and
decryption keys. Here, we one such algorithm, known as RSA after
the names of its inventors (Rivest, Shamir, and Adleman). The RSA cipher is a
block-cipher public-key algorithm and is the most widely used asymmetrical
algorithm. Asymmetrical algorithms based on elliptical curves are gaining
ground, however, because the key length of such an algorithm can be shorter
for the same amount of cryptographic strength.
It is computationally infeasible to derive D(kd, N) from E (lee, N), and so
E (ke, N) need not be kept secret and can be widely disseminated; thus, E (lee, N)
(or just Ice) is the and D(kd, N) (or just led) is the N is the
write 'I messlge 69/
    0
isl l
m
~
encryption_...,. 695 mod 91
key k5.91
~-----+
' Gl-
~ Gl
:J c
uc
m m
(f).r:::
-~ 0
' 1------)  .
(])
N
read~
Figure 15.8 Encryption and decryption using RSA asymmetric cryptography.
15.4 643
product of two large, randomly chosen prime numbers p and q (for example, p
andq are512bitseach). Theencryptionalgorithmis E(kc, N)(rn) = mk, mod N,
where Icc satisfies leekd mod (p -1)(q -1) = 1. The decryption algorithm is then
D(kd, N)(c) = ckd mod N
An example using small values is shown in Figure 15.8. In this example, we
make p = 7 and q = 13. We then calculate N = 7  13 = 91 and (p-1)(q -1) = 72.
We next select kc relatively prime to 72 and    72, yielding 5. Finally, we calculate
kd such that kekrt mod 72 = 1, yielding 29. We now have our keys: the public
key, lee, N = 5, 91, and the private key, led, N = 29, 91. Encrypting the message
69 with the public key results in the message 62, which is then decoded by the
receiver via the private key.
The use of asymmetric encryption begins with the publication of the public
key of the destination. For bidirectional communication, the source also must
publish its public key.   Publication   can be as simple as handing over an
electronic copy of the key, or it can be more complex. The private key (or   secret
key  ) must be jealously guarded, as anyone holding that key can decrypt any
message created by the matching public key.
We should note that the seemingly small difference in key use between
asymmetric and symmetric cryptography is quite large in practice. Asymmetric
cryptography is based on mathematical functions rather than transformations,
Inaking it much more computationally expensive to execute. It is much
faster for a computer to encode and decode ciphertext by using the usual
symmetric algorithms than by using asymmetric algorithms. Why, then, use
an asymmetric algorithm  In truth, these algorithms are not used for generalpurpose
encryption of large amounts of data. However, they are used not
only for encryption of small amounts of data but also for authentication,
confidentiality, and key distribution, as we show in the following sections.
15.4.1.3 Authentication
We have seen that encryption offers a way of constraining the set of possible
receivers of a message. Constraining the set of potential senders of a message is
called Authentication is thus complementary to encryption. In
fact, sometimes their functions overlap. Consider that an encrypted message
can also prove the identity of the sender. For example, if D(kd, N)(E (ke. N)(m))
produces a valid message, then we know that the creator of the message must
hold ke. Authentication is also useful for proving that a message has not been
modified. In this section, we discuss authentication as a constraint on possible
receivers of a message. Note that this sort of authentication is similar to but
distinct from user authentication, which we discuss in Section 15.5.
An authentication algorithm consists of the following components:
A set K of keys.
A set M of messages.
A set A of authenticators.
A functionS: K -  - (M-+ A). That is, for each k E K, S(k) is a function for
generating authenticators from messages. Both Sand S(k) for any k should
be efficiently computable functions.
644 Chapter 15
A function V : [( -+ (M x A-+ {true, false}). That is, for each lc E K,
V(lc) is a function for verifying authenticators on messages. Both V and
V(lc) for any lc should be efficiently computable functions.
The critical property that an authentication algorithm must possess is this: for a
message m, a computer can generate an authenticator a E A such that V (lc )(m, a)
= true only if it possesses S(lc). Thus, a computer holding S(lc) can generate
authenticators on messages so that any computer possessing V(lc) can verify
them. However, a computer not holding S(lc) cannot generate authenticators
on messages that can be verified using V(lc). Since authenticators are generally
exposed (for example, sent on a network with the messages themselves), it
must not be feasible to derive S(lc) from the authenticators.
Just as there are two types of encryption algorithms, there are two main
varieties of authentication algorithms. The first in understanding these
algorithms is to explore hash functions. A H(m) creates a small,
fixed-sized block of data, known as a or from
a message m. Hash functions work by taking a message in n-bit blocks and
processing the blocks to produce an n-bit hash. H must be collision resistant
on m-that is, it must be infeasible to find an 1111 # m such that H(m) = H(n/).
Now, if H(m) = H(m1), we know that m m1 -that is, we know that the
message has not been modified. Common message-digest functions include
which produces a 128-bit hash, and which outputs a 160-bit hash.
Message digests are useful for detecting changed messages but are not useful as
authenticators. For example, H(m) can be sent along with a message; but if His
known, then someone could modify m and recompute H(m), and the message
modification would not be detected. Therefore, an authentication algorithm
takes the message digest and encrypts it.
The first main type of authentication algorithm uses symmetric encryption.
In a a cryptographic checksum is generated
from message using a secret key. Knowledge of V(lc) and knowledge
of S(lc) are equivalent: one can be derived from the other, so lc must be kept
secret. A simple example of a MAC defines S(lc)(m) = f(k, H(m)), where f is
a function that is one-way on its first argument (that is, k cam10t be derived
from f(k, H(m))). Because of the collision resistance in the hash function, we
are reasonably assured that no other message could create the same MAC. A
suitable verification algorithm. is then V(lc)(m, a) = (j(lc, m) =a). Note that k
is needed to compute both S(lc) and V(lc), so anyone able to compute one can
compute the other.
The second main type of authentication algorithm is a
and the authenticators thus produced are called
In a digital-signature algorithm, it is computationally to derive S(ks)
from V(lcv); in particular, Vis a one-way function. Thus, kv is the public key
and lc5 is the private key.
Consider as an example the RSA digital-signature algorithm. It is similar
to the RSA encryption algorithm, but the key use is reversed. The digital
signature of a message is derived by computing S(lcs)(m) = H(m)  s mod N.
The key /c5 again is a pair (d, N), where N is the product of two large, randomly
chosen prime numbers p and q. The verification algorithm is then V(kv)(m, a) =
(ak   mod N = H(m)), where kv satisfies lc,)c5 mod (p - 1)(q - 1) = 1.
15.4 645
lf encryption can prove the identity of the sender of a m~essage, then why do
we need separate authentication algorithms  There are three primary reasons.
Authentication algorithms generally require fewer computations (with
the notable exception of H.SA digital signatures). Over large amounts of
plaintext, this efficiency can make a huge difference in resource use and
the time needed to authenticate a message.
The authenticator of a message is almost always shorter than the message
and its ciphertext. This improves space use and transmission time
efficiency.
Sometimes, we want authentication but not confidentiality. For example,
a company could provide a software patch and could   sign   that patch to
prove that it came from the company and that it hasn't been modified.
Authentication is a component of many aspects of security. For example, it
is the core of which supplies proof that an entity performed an
action. A typical example of nonrepudiation involves the filling out of electronic
forms as an alternative to the signing of paper contracts. Nonrepudiation
assures that a person filling out an electronic form cannot deny that he did
so.
15.4.1.4 Key Distribution
Certainly, a good part of the battle between cryptographers (those inventing
ciphers) and cryptanalysts (those trying to break them) involves keys. With
symmetric algorithms, both parties need the key, and no one else should
have it. The delivery of the symmetric key is a huge challenge. Sometimes
it is performed cut-or-band -say, via a paper document or a conversation.
These methods do not scale well, however. Also consider the key-management
challenge. Suppose a user wanted to communicate with N other users privately.
That user would need N keys and, for more security, would need to change
those keys frequently.
These are the very reasons for efforts to create asymmetric key algorithms.
Not only can the keys be exchanged in public, but a given user needs only
one private key, no matter how many other people she wants to communicate
with. There is still the matter of managing a public key for each party to be
communicated with, but since public keys need not be secured, simple storage
can be used for that
Unfortunately, even the distribution of public keys requires some care.
Consider the man-in-the-middle attack shown in Figure 15.9. Here, the person
who wants to receive an encrypted message sends out his public key, but an
attacker also sends her   bad   public key (which matches her private key). The
person who wants to send the encrypted message knows no better and so uses
the bad key to encrypt the message. The attacker then happily decrypts it.
The problem is one of authentication-what we need is proof of who (or
what) owns a public One to solve that problem involves the use
of digital certificates. A is a public key digitally signed by a
trusted party. The trusted party receives proof of identification from some entity
646 Chapter 15
encryption __,.
key kbad
attacker
decryption
key kd __,.
  co' -.u
'  c
;AQ    
CD 0
_ decryption ...,.
key kbad
.,......_read -+message m I
Figure 15.9 A man-in-the-middle attack on asymmetric cryptography.
and certifies that the public key
we can trust the certifier  These have their public keys
i.J.l.cluded within Web browsers (and other consumers of certificates) before they
are distributed. The certificate authorities can then vouch for other authorities
(digitally signing the public keys of these other authorities), and so on, creating
a web of trust. The certificates can be distributed in a standard X.509 digital
certificate format that can be parsed by computer. This scheme is used for
secure Web communication, as we discuss in Section 15.4.3.
15.4.2 Implementation of Cryptography
Network protocols are typically organized in each layer acting as a client
of the one below it. That is, when one protocol generates a message to send
to its protocol peer on another machine, it hands its message to the protocol
below it in the network-protocol stack for delivery to its peer on that machine.
For example, in an IP network, TCP (a transport-layer protocol) acts as a client
of IP (a network-layer protocol): TCP packets are passed down to IP for delivery
to the TCP peer at the other end of the TCP connection. IP encapsulates the TCP
15.4 647
packet in an IP packet, which it similarly passes down to the data-link layer to be
transmitted across the network to its IP peer on the destination computer. This
IP peer then delivers the TCP up to the TCP peer on that machine. All in
all, the which has been almost universally adopted as a
model for data networking, defines seven such protocol layers. (You will read
more about the ISO model of networking in Chapter 16; Figure 16.6 shows a
diagram of the model.)
Cryptography can be inserted at almost any layer in the ISO model. SSL
(Section 15.4.3), for example, provides security at the transport layer. Networklayer
security generally has been standardized on which defines IP
packet formats that allow the insertion of authenticators and the encryption
of packet contents. It uses symmetric encryption and uses the protocol
for key IPSec is becoming widely used as the basis for
in which all traffic between two IPSec endpoints
is encrypted to make a private network out of one that may otherwise be
public. Numerous protocols also have been developed for use by applications,
but then the applications themselves must be coded to implement security.
Where is cryptographic protection best placed in a protocol stack  In
general, there is no definitive answer. On the one hand, more protocols benefit
from protections placed lower in the stack. For example, since IP packets
encapsulate TCP packets, encryption of IP packets (using IPSec, for example) also
hides the contents of the encapsulated TCP packets. Similarly, authenticators
on IP packets detect the modification of contaii1.ed TCP header information.
On the other hand, protection at lower layers in the protocol stack may give
insufficient protection to higher-layer protocols. For example, an application
server that runs over IPSec might be able to authenticate the client computers
from which requests are received. However, to authenticate a user at a client
computer, the server may need to use an application-level protocol-for
example, the user may be required to type a password. Also consider the
problem of e-mail. E-mail delivered via the industry standard SMTP protocol is
stored and forwarded, frequently multiple times, before it is delivered. Each of
these transmissions could go over a secure or an insecure network. For e-mail
to be secure, the e-mail message needs to be encrypted so that its security is
independent of the transports that carry it.
15.4.3 An Example: SSL
SSL 3.0 is a cryptographic protocol that enables two computers to corrumJJ1icate
securely-that is, so that each can limit the sender and receiver of
to the other. It is perhaps the most commonly used cryptographic
on the Internet today, since it is the standard protocol by which Web
communicate securely with Web servers. For completeness, we should note that
SSL was designed by Netscape and that it evolved into the industry standard
TLS protocol. In this discussion, we use SSL to mean both SSL and TLS.
SSL is a complex protocol with many options. Here, we present only a
single variation of it, and even then in a very simplified and abstract form,
so as to maintain focus on its use of cryptographic primitives. What we are
about to see is a complex dance in which asymmetric cryptography is used so
that a client and a server can establish a secure )-cey that can be used
for symmetric encryption of the session between the two-all of this while
648 Chapter 15
avoiding man-in-the-middle and replay attacks. For added cryptographic
strength, the session keys are forgotten once a session is completed. Another
communication between the two will generation of new session keys.
The SSL protocol is initiated by a c to communicate securely with a
Prior to the protocol's use, the server s is assumed to have obtained
a certificate, denoted cert, from certification authority CA. This certificate is a
structure containing the following:
Various attributes attrs of the server, such as its unique distinguished name
and its common (DNS) name
The identity of a public encryption algorithm E () for the server
The public key kc of this server
A validity interval interval durirtg which the certificate should be considered
valid
A digital signature a on the above information made by theCA-that is,
a= S(kcA)(( attrs, E(ke), interval))
In addition, prior to the protocol's use, the client is presumed to have obtained
the public verification algorithm V(kcA) for CA. In the case of the Web, the user's
browser is shipped from its vendor containing the verification algorithms and
public keys of certain certification authorities. The user can add or delete these
for certification authorities as she chooses.
When c connects to s 1 it sends a 28-byte random value nc to the server, which
responds with a random value n5 of its own, plus its certificate cert5   The client
verifies that V(kcA)( ( attrs, E (lee), interval), a) =true and that the current time
is in the validity interval interval. If both of these tests are satisfied, the server
has proved its identity. Then the client generates a random 46-byte
and sends cpms = E (ks) (pms) to the server. The server recovers
pms = D(kd)(cpms). Now both the client and the server are in possession of
nc, n5 , and pms, and each can cmnpute a shared 48-byte L  '  '''    c  
f(nc, 715 , pms), where f is a one-way and collision-resistant function.
server and client can compute ms, since only they know pms.
dependence of ms on nc and n5 ensures that ms is a fresh value-that is, a
session key that has not been used in a previous communication. At this point,
the client and the server both compute the keys the ms:
A symmetric encryption key k~[YPt for encrypting messages from
to the server
client
A symmetric encryption
to the client
lc~rypt for encrypting messages from the server
A MAC generation Jc~ac generating authenticators on
from the client to the server
A MAC generation k~~ac for generating authenticators on
from the server to the
To send a message m to the server, the client sends
15.5
15.5 649
Upon receiving c, the server recovers
(m. a)= D(Jc~ pt)(c)
and accepts m if V(lc~ac)(m, a) =true. Similarly, to send a message m to the
client, the server sends
and the client recovers
and accepts m if V(k~ac)(m, a)= true.
This protocol enables the server to limit the recipients of its messages to the
client that generated pms and to limit the senders of the messages it accepts
to that same client. Similarly, the client can limit the recipients of the messages
it sends and the senders of the messages it accepts to the party that knows
S(kd) (that is, the party that can decrypt cpms). In many applications, such
as Web transactions, the client needs to verify the identity of the party that
knows S(lcd). This is one purpose of the certificate cert5 ; in particular, the attrs
field contains information that the client can use to determine the identityfor
example, the domain name-of the server with which it is communicating.
For applications in which the server also needs information about the client,
SSL supports an option by which a client can send a certificate to the server.
In addition to its use on the Internet, SSL is being used for a wide variety
of tasks. For example, IPSec VPNs now have a competitor in SSL VPNs. IPSec
is good for point-to-point encryption of traffic-say, between two company
offices. SSL VPNs are more flexible but not as efficient, so they might be used
between an individual employee working remotely and the corporate office.
Our earlier discussion of authentication involves messages and sessions. But
what about users  If a system cannot authenticate a user, then authenticating
that a message can'le from that user is Thus, a major security problem
for operating systems is The protection system depends
on the ability to identify the programs and processes currently executing,
which in turn depends on the ability to identify each user the system. Users
identify themselves. How do we determine a user's
is authentic  Generally, user authentication is based on one or more
things: the user's possession of something (a or card), the user's
of something user identifier and password), an attribute
retina or signature).
15.5.1 Passwords
The most comm.on
When the user
a user is the use of
user ID or account name, she
650 Chapter 15
is asked for a password. I  the user-supplied password matches the password
stored in the system, the system assumes that the account is being accessed by
the owner of that account.
Passwords are often used to protect objects in the computer system, in
the absence of more complete protection schemes. They can be considered a
special case of either keys or capabilities. For instance, a password may be
associated with each resource (such as a file). Whenever a request is made to
use the resource, the password nmst be given. If the password is correct, access
is granted. Different passwords may be associated with different access rights.
For example, different passwords may be used for reading files, appending
files, and updating files.
In practice, most systems require only one password for a user to gain
full rights. Although more passwords theoretically would be more secure,
such systems tend not to be implemented due to the classic trade-off between
security and convenience. If security makes something inconvenient then the
security is frequently bypassed or otherwise circumvented.
15.5.2 Password Vulnerabilities
Passwords are extremely common because they are easy to understand and use.
Unfortunately, passwords can often be guessed, accidentally exposed, sniffed,
or illegally transferred from an authorized user to an unauthorized one, as we
show next.
There are two common ways to guess a password. One way is for the
intruder (either human or program) to know the user or to have information
about the user. All too frequently, people use obvious information (such as the
names of their cats or spouses) as their passwords. The other way is to use brute
force, trying enumeration-or all possible combinations of valid password
characters (letters, numbers, and punctuation on some systems)-until the
password is found. Short passwords are especially vulnerable to this method.
For example, a four-character password provides only 10,000 variations. On
average, guessing 5,000 times would produce a correct hit. A program that
could try a password every millisecond would take only about 5 seconds to
guess a four-character password. Enumeration is less successful where systems
allow longer passwords that include both uppercase and lowercase letters,
along with numbers and all punctuation characters. Of course, users must take
advantage of the large password space and must not, for example, use only
lowercase letters.
In addition to being guessed, passwords can be exposed as a result of
visual or electronic monitoring. An intruder can look over the shoulder of a
user when the user is logging iil and can learn the password
easily by watching the keyboard. Alternatively, anyone with access to the
network on which a computer resides can seamlessly add a network monitor,
allowing him to watch all data being transferred on the network
including user IDs and passwords. Encrypting the data stream containing the
password solves this problem. Even such a system could have passwords
stolen, however. For example, if a file is used to contain the passwords, it
could be copied for off-system analysis. Or consider a Trojan-horse program
installed on the system that captures every keystroke before sending it on to
the application.
15.5 651
Exposure is a particularly severe problem if the password is written down
where it can be read or lost. As we shall see, some systems force users to select
hard-to-remember or long passwords, which may cause a user to record the
password or to reuse it. As a result, such systems provide much less security
than systems that allow users to select easy passwords!
The final type of password compromise, illegal transfer, is the result of
human nature. Most computer installations have a rule that forbids users to
share accounts. This rule is sometimes implemented for accounting reasons but
is often aimed at improving security. For instance, suppose one user ID is shared
by several users, and a security breach occurs from that user ID. It is impossible
to know who was using the ID at the time the break occurred or even whether
the user was an authorized one. With one user per user ID, any user can be
questioned directly about use of the account; in addition, the user might notice
something different about the account and detect the break-in. Sometimes,
users break account-sharing rules to help friends or to circumvent accounting,
and this behavior can result in a system's being accessed by unauthorized users
-possibly harmful ones.
Passwords can be either generated by the system or selected by a user.
System-generated passwords may be difficult to remember, and thus users may
write them down. As mentioned, however, user-selected passwords are often
easy to guess (the user's name or favorite car, for example). Some systems will
check a proposed password for ease of guessing or cracking before accepting it.
At some sites, administrators occasionally check user passwords and notify a
user if his password is easy to guess. Some systems also age passwords, forcing
users to change their passwords at regular intervals (every three months, for
instance). This method is not foolproof either, because users can easily toggle
between two passwords. The solution, as implemented on some systems, is to
record a password history for each user. For instance, the system could record
the last N passwords and not allow their reuse.
Several variants on these simple password schemes can be used. For
example, the password can be changed more frequently. In the extren:1e, the
password is changed from session to session. A new password is selected
(either by the system or by the user) at the end of each session, and that password
must be used for the next session. In such a case, even if a password is misused,
it can be used only once. When the legitimate user tries to use a now-invalid
password at the next session, he discovers the security violation. Steps can then
be taken to repair the breached security.
15.5.3 Encrypted Passwords
One problem with all these approaches is the difficulty of keeping the password
secret within the computer. How can the system store a password securely yet
allow its use for authentication when the user presents her password  The
UNIX system uses encryption to avoid the necessity of keeping its password
list secret. Each user has a password. The system contains a function that is
extremely difficult-the designers hope impossible-to invert but is simple
to compute. That is, given a value x, it is easy to compute the function value
f(x). Given a function value j(x), however, it is impossible to compute x. This
function is used to encode all passwords. Only encoded passwords are stored.
When a user presents a password, it is encoded and compared against the
652 Chapter 15
stored encoded password. Even if the stored encoded password is seen, it
cam1ot be decoded, so the password cannot be determined. Thus, the password
file does not need to be kept secret. The functionf(x) is typically an encryption
algorithm that has been designed and tested rigorously.
The flaw in this method is that the system no longer has control over
the passwords. Although the passwords are encrypted, anyone with a copy
of the password file can run fast encryption routines against it-encrypting
each word in a dictionary, for instance, and comparing the results against
the passwords. If the user has selected a password that is also a word in the
dictionary, the password is cracked. On sufficiently fast computers, or even
on clusters of slow computers, such a comparison may take only a few hours.
Furthermore, because UNIX systems use a well-known encryption algorithm,
a cracker might keep a cache of passwords that have been cracked previously.
For these reasons, new versions of UNIX store the encrypted password entries in
a file readable only by the The programs that compare a presented
password to the stored password run setuid to root; so they can read this file,
but other users cannot. They also include a   salt,   or recorded random number,
in the encryption algorithm. The salt is added to the password to ensure that
if two plaintext passwords are the same, they result in different ciphertexts.
Another weakness in the UNIX password methods is that many UNIX
systems treat only the first eight characters as significant. It is therefore
extremely important for users to take advantage of the available password
space. To avoid the dictionary encryption method, some systems disallow the
use of dictionary words as passwords. A good technique is to generate your
password by using the first letter of each word of an easily remembered phrase
using both upper and lower characters with a number or punctuation mark
thrown in for good measure. For example, the phrase   My mother's name is
Katherine   might yield the password   Mmn.isK!  . The password is hard to
crack but easy for the user to remember.
15.5.4 One-Time Passwords
To avoid the problems of password sniffing and shoulder surfing, a system
could use a set of paired When a session begins, the system
randomly selects and presents one part of a password pair; the user must
supply the other part. In this system, the user is challenged and must
with the correct answer to that challenge.
This approach can be generalized to the use of an algorithm as a password.
The algorithm might be an integer function, for example. The system selects
a random integer and presents it to the user. The user applies a function and
replies with the correct result. The system also applies the function. If the two
results match, access is allowed.
Such algorithmic passwords are not susceptible to reuse; that is, a user can
type in a password, and no entity intercepting that password will be able to
reuse it. In this scheme, the system and the user share a secret. The secret is
never transmitted over a medium that allows exposure. Rather, the secret is
used as input to the function, along with a shared seed. A is a random
number or alphanumeric sequence. The seed is the authentication challenge
from the computer. The secret and the seed are used as input to the function
f(secret, seed). The result of this function is transmitted as the password to the
15.5 653
computer. BecaLlSe the computer also knows the secret and the seed, it can
perform the same computation. If the results match, the user is authenticated.
The next time the user needs to be authenticated, another seed is generated,
and the same ensue. This time, the password is different.
In this system, the password is different in each
instance. Anyone capturing the password from one session and trying to reuse
it in another session will faiL One-time passwords are among the only ways to
prevent improper authentication clue to password exposure.
One-time password systems are implemented in various ways. Commercial
implementations, such as SecuriD, use hardware calculators. Most of these
calculators are shaped like a credit card, a key-chain dangle, or a USB device;
they include a display and may or may not also have a keypad. Some use
the current time as the random seed. Others the user to enter the
shared secret, also known as a or on the
keypad. The display then shows the one-time password. The use of both a
one-time password generator and a PIN is one form of n!Jn-  .  ' '-  ''  
Two different types of components are needed in this case. Two-factor
authentication offers far better authentication protection than single-factor
authentication.
Another variation on one-time passwords uses a or
which is a list of single-use passwords. Each password on the list is used
once and then is crossed out or erased. The commonly used S/Key system
uses either a software calculator or a code book based on these calculations
as a source of one-time passwords. Of course, the user must protect his code
book.
15.5.5 Biometrics
Yet another variation on the use of passwords for authentication involves
the use of biometric measures. Palm- or hand-readers are commonly used to
secure physical access-for example, access to a data center. These readers
match stored parameters against what is being read from hand-reader pads.
The parameters can include a temperature map, as well as finger length, finger
width, and line patterns. These devices are currently too large and expensive
to be used for normal computer authentication.
Fingerprint readers have become accurate and cost-effective and should
become more common in the future. These devices read finger ridge patterns
and convert them into a sequence of numbers. Over time, they can store a set of
sequences to adjust for the location of the finger on the reading pad and other
factors. Software can then scan a finger on the pad and compare its features
with these stored sequences to determine if they match. Of course, multiple
users can have profiles stored, and the scanner can differentiate among them.
A very accurate two-factor authentication scheme can result from requiring
a password as well as a user name and fingerprint scan. If this information
is encrypted in transit, the system can be very resistant to spoofing or replay
attack.
is better still. Consider how strong authentication
can be with a USB device that must be plugged into the system, a PIN, and
a fingerprint scan. Except for the user's having to place her finger on a pad and
plug the USB into the system, this authentication method is no less convenient
654 Chapter 15
15.6
that using normal passwords. Recall, though, that strong authentication by
itself is not sufficient to guarantee the ID of the user. An authenticated session
can still be hijacked if it is not encrypted.
Just as there are myriad threats to system and network security, there are many
security solutions. The solutions run the gamut from improved user education,
through technology, to bug-free software. Most security professionals
subscribe to the theory of which states that more layers
of defense are better than fewer layers. Of course, this theory applies to any
kind of security. Consider the security of a house without a door lock, with
a door lock, and with a lock and an alarm. In this section, we look at the
major methods, tools, and techniques that can be used to improve resistance
to threats.
15.6.1 Security Policy
toward improving the security of any aspect of computing is to
have a . Policies vary widely but generally include a statement
of what is being secured. For example, a policy might state that all outsideaccessible
applications must have a code review before being deployed, or that
users should not share their passwords, or that all connection points between a
company and the outside must have port scans nm every six months. Without
a policy in place, it is impossible for users and administrators to know what
is permissible, what is required, and what is not allowed. The policy is a road
map to security, and if a site is trying to move from less secure to more secure,
it needs a map to know how to get there.
Once the security policy is in place, the people it affects should know it
well. It should be their guide. The policy should also be a
that is reviewed and updated periodically to ensure that it is still pertinent and
still followed.
15.6.2 Vulnerability Assessment
How can we determine whether a security policy has been correctly implemented 
The best way is to execute a vulnerability assessment. Such assessments
can cover broad ground, from social engineering through risk assessment
to port scans. Rlsl   for example, endeavors to value the
assets of the entity in question (a program, a management team, a system, or
a facility) and determine the odds that a security incident will affect the entity
and decrease its value. When the odds of suffering a loss and the amount of the
potential loss are known, a value can be placed on trying to secure the entity.
The core activity of most vulnerability assessments is a           '.,-  ~'''--in
which the entity is scanned for known vulnerabilities. Because this book
is concerned with operating systems and the software that runs on them, we
concentrate on those aspects of vulnerability assessment.
Vulnerability scans typically are done at times when computer use is
relatively low, to minimize their impact. When appropriate, they are done on
15.6 655
test systems rather than production systems, because they can induce unhappy
behavior from the target systems or network devices.
A scan within an individual system can check a variety of aspects of the
system:
Short or easy-to-guess passwords
Unauthorized privileged programs, such as setuid programs
Unauthorized programs in system directories
Unexpectedly long-running processes
Improper directory protections on user and system directories
Improper protections on system data files, such as the password file, device
drivers, or the operating-system kernel itself
Dangerous entries in the program search path (for example, the Trojan
horse discussed in Section 15.2.1)
Changes to system programs detected with checksum values
Unexpected or hidden network daemons
Any problems found by a security scan can be either fixed automatically or
reported to the managers of the system.
Networked computers are much more susceptible to security attacks than
are standalone systems. Rather than attacks from a known set of access
points, such as directly connected terminals, we face attacks from an unknown
and large set of access points-a potentially severe security problem. To a
lesser extent, systems connected to telephone lines via modems are also more
exposed.
In fact, the U.S. government considers a system to be only as secure as its
most far-reaching connection. For instance, a top-secret system may be accessed
only from within a building also considered top-secret. The system loses its topsecret
rating if any form of communication Call. occur outside that environment.
Some government facilities take extreme security precautions. The connectors
that plug a terminal into the secure computer are locked in a safe in the office
when the terminal is not in use. A person must have proper ID to gain access to
the building and her office, must know a physical lock combination, and must
know authentication information for the computer itself to gain access to the
computer-an example of multifactor authentication.
Unfortunately for systems administrators and computer-security professionals,
it is frequently impossible to lock a machine in a room and disallow all
remote access. For instance, the Internet network currently connects millions of
computers. It is becoming a mission-critical, indispensable resource for many
companies and individuals. If you consider the Internet a club, then, as in any
club with millions of members, there are many good members and some bad
members. The bad members have many tools they can use to attempt to gain
access to the interconnected computers, just as Morris did with his worm.
Vulnerability scans can be applied to networks to address some of the
problems with network security. The scans search a network for ports that
respond to a request. If services are enabled that should not be, access to them
can be blocked, or they can be disabled. The scans then determine the details of
656 Chapter 15
the application listening on that port and try to determine if it has any known
vulnerabilities. Testing those vulnerabilities can determine if the system is
ncisconfigured or lacks needed patches.
Finally though, consider the use of port scanners in the hands of a cracker
rather than someone trying to improve security. These tools could help crackers
find vulnerabilities to attack. (Fortunately, it is possible to detect port scans
through anomaly detection, as we discuss next.) It is a general challenge to
security that the same tools can be used for good and for harm. In fact, some
people advocate stating that no tools should be
written to test security, because such tools can be used to find (and exploit)
security holes. Others believe that this approach to security is not a valid one,
pointing out, for example, that crackers could write their own tools. It seems
reasonable that security through obscurity be considered one of the layers
of security only so long as it is not the only layer. For example, a company
could publish its entire network configuration; but keeping that information
secret makes it harder for intruders to know what to attack or to determine
what might be detected. Even here, though, a company assuming that such
information will remain a secret has a false sense of security.
15.6.3 Intrusion Detection
and facilities is intimately linked to intrusion detection.
as its name suggests, strives to detect attempted or successful
intrusions into computer systems and to initiate appropriate responses to the
intrusions. Intrusion detection encompasses a wide array of techniques that
vary on a number of axes, including the following:
The time at which detection occurs. Detection can occur in real time (while
the intrusion is occurring) or after the fact.
The types of inputs examined to detect intrusive activity. These may
include user-shell commands, process system calls, and network packet
headers or contents. Some forms of intrusion might be detected only by
correlating information from several such sources.
The range of response capabilities. Simple forms of response include
alerting an administrator to the potential intrusion or somehow halting
the potentially intrusive activity-for example, killing a process engaged
in such activity. In a sophisticated fonn of response; a system might
transparently divert an intruder's activity to a false resource
exposed to the attacker. The resource appears real to the attacker and
enables the system to monitor and gain information about the attack
These degrees of freedom in the design space for detecting intrusions have
a wide range of solutions, known as
and IDS systems raise an alarm
when an intrusion is detected, while IDP systems act as routers, passing traffic
unless an intrusion is detected (at which point that traffic is blocked).
But just what constitutes an intrusion  Defining a suitable specification of
intrusion turns out to be quite difficult, and thus automatic IDSs and IDPs today
settle for one of two less ambitious approaches. In the first, called
system input or network traffic is examined for
15.6 657
specific behavior patterns (or known to indicate attacks. A simple
example of signature-based detection is scanning network packets for the string
/etc/passwd/ targeted for a UNIX systenL Another example is virus-detection
software, which scans binaries or network packets for lmown viruses.
The second approach, typically called attempts
through various techniques to detect anomalous behavior within computer
systen  s. Of course, not all anomalous system activity indicates an intrusion,
but the presumption is that intrusions often induce anomalous behavior. An
example of anomaly detection is monitoring system calls of a daemon process
to detect whether the system-call behavior deviates from normal patterns,
possibly indicating that a buffer overflow has been exploited in the daemon
to corrupt its behavior. Another example is monitoring shell commands to
detect anomalous commands for a given user or detecting an anomalous login
time for a user, either of which may indicate that an attacker has succeeded in
gaining access to that user's account.
Signature-based detection and anomaly detection can be viewed as two
sides of the same coin: Signature-based detection attempts to characterize
dangerous behaviors and to detect when one of these behaviors occurs,
whereas anomaly detection attempts to characterize normal (or non dangerous)
behaviors and to detect when something other than these behaviors occurs.
These different approaches yield IDSs and IDPs with very different properties,
however. In particular, anomaly detection can find previously unknown
methods of intrusion (so-called Signature-based detection,
in contrast, will identify only known attacks that can be codified in a recognizable
pattern. Thus, new attacks that were not contemplated when the
signatures were generated will evade signature-based detection. This problem
is well known to vendors of virus-detection software, who must release new
signatures with great frequency as new viruses are detected manually.
Anomaly detection is not necessarily superior to signature-based detection,
however. Indeed, a significant challenge for systems that attempt anomaly
detection is to benchmark   normal   system behavior accurately. If the system
has already been penetrated when it is benchmarked, then the intrusive activity
may be included in the   normal   benchmark. Even if the system is benchInarked
cleanly, without influence from intrusive behaviorf the benchmark
must give a fairly complete picture of normal behavior. Otherwise, the number
of (false alarms) orf worse, (missed intrusions)
will be excessive.
To illustrate the impact of even a marginally high rate of false alarms,
consider an installation consisting of a hundred UNIX workstations from which
security-relevant events are recorded for purposes of intrusion detection. A
small installation such as this could easily generate a million audit records per
day. Only one or two might be worthy of an administrator's investigation. If we
suppose, optimistically, that each actual attack is reflected in ten audit recordsf
we can roughly compute the rate of occurrence of audit records reflecting truly
intrusive activity as follows:
2 intrusions . 10 . recor s
mtrus10n
0.00002.
658 Chapter 15
Interpreting this as a   probability of occurrence of intrusive records/' we
denote it as P(I); that is, event I is the occurrence of a record reflecting truly
intrusive behavior. Since P(I) = 0.00002, we also know that P( ~I) = 1-P(I) =
0.99998. Now we let A denote the raising of an alarm by an IDS. An accurate IDS
should maximize both P(I lA) and P(~I I~A)-that is, the probabilities that an
alarm indicates an intrusion and that no alarm indicates no intrusion. Focusil  g
on P (I I A) for the moment, we can compute it using
P(IIA)
P(I)   P(AII)
P(I)   P(AII) + P(~I)   P(AI~I)
0.00002   P(AII)
0.00002   P(AII) + 0.99998   P(AI~I)
Now consider the impact ofthe false-alarm rate P(AI~I) on P(IIA). Even
with a very good true-alarm rate of P(Ail) = 0.8, a seemingly good falsealarm
rate of P(AI~I) = 0.0001 yields P(IIA) ~ 0.14. That is, fewer than one
ill every seven alarms indicates a real intrusion! In systems where a security
administrator ilwestigates each alarm, a high rate of false alarms-called a
  Christmas tree effect  -is exceedingly wasteful and will quickly teach the
admilcistrator to ignore alarms.
This example illustrates a general principle for IDSs and IDPs: For usability,
they must offer an extremely low false-alarm rate. Achieving a sufficiently
low false-alarm rate is an especially serious challenge for anomaly-detection
systems, as mentioned, because of the difficulties of adequately benchmarking
normal system behavior. However, research contil  ues to improve anomalydetection
techniques. Intrusion detection software is evolving to implement
signatures, anomaly algorithms, and other algorithms and to combine the
results to arrive at a more accurate anomaly-detection rate.
15.6.4 Virus Protection
As we have seen, viruses can and do wreak havoc on systems. Protection from
viruses thus is an important security concern. Antivirus programs are often
used to provide this protection. Some of these programs are effective against
only particular known viruses. They work by searching all the programs on
a system for the specific pattern of instructions known to make up the virus.
When they find a known pattern, they remove the instructions,
the program. Antivirus programs may have catalogs of thousands of viruses
for which they search.
Both viruses and antivirus software continue to become more sophisticated.
Some viruses modify themselves as they infect other software to avoid the basic
pattern-match approach of antivirus programs. Antivirus programs ill turn
now look for families of patterns rather than a single pattern to identify a virus.
In fact, some antivirus programs implement a variety of detection algorithms.
They can decompress compressed viruses before checking for a signature.
Some also look for process anomalies. A process opening an executable file
for writing is suspicious, for example, unless it is a compiler. Another popular
teducique is to run a program in a which is a controlled or emulated
15.6 659
THE TRIPWIRE FILE SYSTEM
An example of an anomaly-detection tool is the
checking tool for UNIX, developed at Purdue University. Tripwire operates on
the premise that many intrusions result in modification of system directories
and files. For example, an attacker might modify the system programs,
perhaps inserting copies with Trojan horses, or might insert new programs
into directories commonly found in user-shell search paths. Or an intruder
might remove system log files to cover his tracks. Tripwire is a tool to
monitor file systems for added, deleted, or changed files and to alert system
administrators to these modifications.
The operation of Tripwire is controlled by a configurationfile tw.config
that enumerates the directories and files to be monitored for changes,
deletions, or additions. Each entry in this configuration file includes a
selection mask to specify the file attributes (inode attributes) that will be
monitored for changes. For example, the selection mask might specify that a
file's permissions be monitored but its access time be ignored. In addition, the
selection mask can instruct thatthe file be monitored for changes. Monitoring
the hash of a file for changes is as good as monitoring the file itselt but storing
hashes of files requires far less room than copying the files themselves.
When run initially, Tripwire takes as input the tw.config file and
computes a sign.ature for each file or directory consisting of its monitored
attributes (inode attributes and hash values). These signatures are stored in a
database. When run subsequently, Tripwire inputs both tw.config and the
previously stored database, recomputes the signature for each file or directory
named in tw.conf ig, and compares this signature with the signature (if any)
in the previously compl.J-ted database. Events reported to an administrator
include any monitored file or directory whose signature differs from that in
the database (a changed file), any file or directory in a monitored directory
for which a signature does not exist in the database (an added file), and any
signature in the database for which the corresponding file or directory no
longer exists (a deleted file),
Although effective for a wide class of attacks, Tripwire does have limitations.
Perhaps the most obvious is the need to protect the Tripwire program
and its associated files, especially the database file, from unauthorized modification.
For this reason, Tripwire and its associated files should be stored
on some tamper-proof medium, such as a write-protected disk or a secure
server where logins can be tightly controlled. Unforhm.ately, this makes it
less convenient to update the database after authorized updates to monitored
directories and files. A second limitation is that some security-relevant
files-for example, system log files-are supposed to change over time, and
Tripwire does not provide a way to distinguish between an authorized and
an unauthorized change. So, for example, an attack that modifies (without
deleting) a system log that would normally change anyway would escape
Tripwire's detection capabilities. The best Tripwire can do in this case is to
detectcertain obvious inconsistencies (for example, a shrinking log file). Free
and commercial versions of Tripwire are available from http:/ /tripwire.org
and.http:/ /tripwire.com.
660 Chapter 15
section of the system. The antivirus software analyzes the behavior of the code
in the sandbox before letting it run unmonitored. Some antivirus programs also
put up a complete shield rather than just scanning files within a file system.
They search boot sectors, menlOry, inbound and outbound e-mail, files as they
are downloaded, files on removable devices or media, and so on.
The best protection against computer viruses is prevention, or the practice
of Purchasing unopened software from vendors and avoiding
free or pirated copies from public sources or disk exchange offer the safest
route to preventing infection. However, even new copies of legitimate software
applications are not immune to virus infection: in a few cases, disgruntled
employees of a software company have infected the master copies of software
programs to do economic harm to the company. For macro viruses, one defense
is to exchange Microsoft Word documents in an alternative file format called
Unlike the native Word format RTF does not include the
capability to attach macros.
Another defense is to avoid opening any e-mail attachments from unknown
users. Unfortunately, history has shown that e-mail vulnerabilities appear as
fast as they are fixed. For example, in 2000, the love bug virus became very
widespread by traveling in e-mail messages that pretended to be love notes
sent by friends of the receivers. Once a receiver opened the attached Visual
Basic script, the virus propagated by sending itself to the first addresses in the
receiver's e-mail contact list. Fortunately, except for clogging e-mail systems
and users' inboxes, it was relatively harmless. It did, however, effectively
negate the defensive strategy of opening attachments only from people known
to the receiver. A more effective defense method is to avoid opening any e-mail
attachment that contains executable code. Some companies now enforce this
as policy by removing all incoming attachments to e-mail messages.
Another safeguard, although it does not prevent infection, does permit
early detection. A user must begin by completely reformatting the hard disk,
especially the boot sector, which is often targeted for viral attack Only secure
software is uploaded, and a signature of each program is taken via a secure
message-digest computation. The resulting filename and associated messagedigest
list must then be kept free from unauthorized access. Periodically, or
each time a program is run, the operating system recomputes the signature and
compares it with the signature on the original list; any differences serve as a
warning of possible infection. This technique can be combined with others. For
example, a high-overhead antivirus scan, such as a sandbox, can be used; and
if a program passes the test, a signature can be created for it. If the signatures
match the next time the program is run, it does not need to be virus-scanned
again.
15.6.5 Auditing, Accounting, and Logging
Auditing, accounting, and logging can decrease system performance, but they
are useful in several areas, including security. Logging can be general or
specific. All system-call executions can be logged for analysis of program
behavior (or misbehavior). More typically, suspicious events are logged.
Authentication failures and authorization failures can tell us quite a lot about
break-in attempts.
15
15.7 661
Accounting is another potential tool in a security administrator's kit. It
can be used to find performance changes, which in tum can reveal security
problems. One of the early UNIX computer break-ins was detected by Cliff
Stoll when he was exam5ning accounting logs and spotted an anomaly.
We turn next to the question of how a trusted computer can be connected
safely to an untrustworthy network One solution is the use of a firewall to
separate trusted and unh usted systems. A is a computer, appliance,
or router that sits between the trusted and the untrusted. A network firewall
limits network access between the two and monitors and
logs all connections. It can also limit coru1.ections based on source or destination
address, source or destination port, or direction of the connection. For instance,
Web servers use HTTP to communicate with Web browsers. A firewall therefore
may allow only HTTP to pass from all hosts outside the firewall to the Web
server within the firewalL The Morris Internet worm used the finger protocol
to break into computers, so finger would not be allowed to pass, for example.
In fact, a network firewall can separate a network into multiple domains.
A common implementation has the Internet as the untrusted domain; a
semitrusted and semisecure network, called the
as another domain; and a company's computers as a third domain (Figure
15.10). Coru1.ections are allowed from the Internet to the DMZ computers and
from the company computers to the Internet but are not allowed from the
Internet or DMZ computers to the company computers. Optionally, controlled
commurucations may be allowed between the DMZ and one company computer
or more. For instance, a Web server on the DMZ may need to query a database
server on the corporate network With a firewall, however, access is contained,
and any DMZ systems that are broken into still are unable to access the company
computers.
Internet
Internet access from company's
computers
r---------i company computers
access between DMZ and
company's computers
Figure 15.10 Domain separation via firewall.
662 Chapter 15
15.8
Of course, a firewall itself must be secure and attack-proof; otherwise,
its ability to secure connections can be compromised. Furthermore, firewalls
do not prevent attacks that or travel within protocols or com1ections
that the firewall allows. A buffer-overflow attack to a Web server will not be
stopped by the firewall, for example, because the HTTP connection is allowed;
it is the contents of the HTTP connection that house the attack. Likewise, denialof-
service attacks can affect firewalls as much as any other machines. Another
vulnerability of firewalls is in which an unauthorized host pretends
to be an authorized host by meeting some authorization criterion. For example,
if a firewall rule allows a connection from a host and identifies that host by its
IP address, then another host could send packets using that same address and
be allowed through the firewall.
In addition to the most common network firewalls, there are other, newer
kinds of firewalls, each with its pros and cons. A is a
software layer either included with the operating system or added as an
application. Rather than limiting communication between security domains, it
limits communication to (and possibly from) a given host. A user could add
a personal firewall to her PC so that a Trojan horse would be denied access to
the network to which the PC is connected, for example. An prex-y
understands the protocols that applications speak across the network.
For example, SMTP is used for mail transfer. An application proxy accepts a
com1ection just as an SMTP server would and then initiates a connection to
the original destination SMTP server. It can monitor the traffic as it forwards
the message, watching for and disabling illegal commands, attempts to exploit
bugs, and so on. Some firewalls are designed for one specific protocol. An
for example, has the specific purpose of analyzing XML traffic
and blocking disallowed or malformed XML. sit between
applications and the kernel, monitoring system-call execution. For example,
in Solaris 10, the   least privilege   feature implements a list of more than fifty
system calls that processes may or may not be allowed to make. A process that
does not need to spawn other processes can have that ability taken away, for
instance.
The U.S. Department of Defense Trusted Computer System Evaluation Criteria
specify four security classifications in systems: A, B, C, and D. This specification
is widely used to determine the security of a facility and to model security
solutions, so we explore it here. The lowest-level classification is division D, or
minimal protection. Division D includes only one class and is used for systems
that have failed to meet the requirements of any of the other security classes.
For instance, MS-DOS and Windows 3.1 are in division D.
Division C, the next level of security, provides discretionary protection and
accountability of users and their actions through the use of audit capabilities.
Division C has two levels: C1 and C2. A C1-class system incorporates some
form of controls that allow users to protect private information and to
keep other users from accidentally reading or destroying their data. A C1
environment is one in which cooperating users access data at the same levels
of sensitivity. Most versions of UNIX are C1 class.
15.8 663
The total of all protection systems within a computer system (hardware,
software, firmware) that correctly enforce a security policy is known as a
The TCB of a Cl system controls access between
users and files by allowing the user to specify and control sharing of objects
by named individuals or defined groups. In addition, the TCB requires that the
users identify themselves before they start any activities that the TCB is expected
to mediate. This identification is accomplished via a protected mechanism or
password; the TCB protects the authentication data so that they are inaccessible
to unauthorized users.
A C2-class system adds an individual-level access control to the requirements
of a Cl system. For example, access rights of a file can be specified
to the level of a single individual. In addition, the system adrninistrator can
selectively audit the actions of any one or more users based on individual
identity. The TCB also protects itself from modification of its code or data
structures. In addition, no information produced by a prior user is available
to another user who accesses a storage object that has been released back to
the system. Some speciat secure versions of UNIX have been certified at the C2
level.
Division-B mandatory-protection systems have all the properties of a classC2
system; in addition, they attach a sensitivity label to each object. The Bl-class
TCB maintains the security label of each object in the system; the label is used
for decisions pertaining to mandatory access control. For example, a user
at the confidential level could not access a file at the more sensitive secret
level. The TCB also denotes the sensitivity level at the top and bottom of each
page of any human-readable output. In addition to the normal user-namepassword
authentication information, the TCB also maintains the clearance
and authorizations of individual users and will support at least two levels of
security. These levels are hierarchicat so that a user may access any objects
that carry sensitivity labels equal to or lower than his security clearance. For
example, a secret-level user could access a file at the confidential level in the
absence of other access controls. Processes are also isolated through the use of
distinct address spaces.
A B2-class system extends the sensitivity labels to each system resource,
such as storage objects. Physical devices are assigned minimum and maximum
security levels that the system uses to enforce constraints imposed by the
physical environments in which the devices are located. In addition, a B2
system supports covert channels and the auditing of events that could lead to
the exploitation of a covert channel.
A B3-class system allows the creation of access-control lists that denote
users or groups not granted access to a given named object. The TCB also
contains a mechanism to monitor events that may indicate a violation of
security policy. The mechanism notifies the security administrator and, if
necessary, terminates the event in the least disruptive manner.
The highest-level classification is division A. Architecturally, a class-Al
system is functionally equivalent to a B3 system, but it uses formal design
specifications and verification techniques, granting a high degree of assurance
that the TCB has been implemented correctly. A system beyond class Al might
be designed and developed in a trusted facility by trusted personnel.
The use of a TCB merely ensures that the system can enforce aspects of a
security policy; the TCB does not specify what the policy should be. Typically,
664 Chapter 15
15.9
a given computing environment develops a security policy for
and has the plan by a security agency, such as the National
Computer Security Center. Certain computing environments may require other
certification, such as that supplied by TEMPEST, which guards against electronic
eavesdropping. For example, a TEMPEST-certified system has terminals that
are shielded to prevent electromagnetic fields from escaping. This shielding
ensures that equipment outside the room or building where the terminal is
housed camwt detect what information is being displayed by the terminal.
Microsoft Windows XP is a general-purpose operating system designed to
support a variety of security features and methods. In this section, we examine
features that Windows XP uses to perform security functions. For more
information and background on Wilcdows XP, see Chapter 22.
The Windows XP security model is based on the notion of
Windows XP allows the creation of any number of user accounts, which can
be grouped in any manner. Access to system objects can then be permitted or
denied as desired. Users are identified to the system by a unique security ID.
When a user logs on, Windows XP creates a that includes
the security ID for the user, security IDs for any groups of which the user is
a member, and a list of any special privileges that the user has. Examples
of special privileges include backing up files and directories, shutting down
the compute1~ logging on interactively, and changing the system clock. Every
process that Windows XP runs on behalf of a user will receive a copy of the
access token. The system uses the security IDs in the access token to permit or
deny access to system objects whenever the use1~ or a process on behalf of the
user, attempts to access the object. Authentication of a user account is typically
accomplished via a user name and password, although the modular design of
Windows XP allows the development of custom authentication packages. For
example, a retinal (or eye) scanner might be used to verify that the user is who
she says she is.
Windows XP uses the idea of a subject to ensure that programs run by a
user do not get greater access to the system than the user is authorized to have.
A is used to track and manage permissions for each program that a
user runs; it is composed of the user's access token and the program acting
on behalf of the user. Since Windows XP operates with a client-server model,
two classes of subjects are used to control access: simple subjects and server
subjects. An example of a is the typical application program
that a user executes after she logs on. simple subject is assigned a
based on the security access token of the user. A is a
process implemented as a protected server that uses the security context of the
client when acting on the client's behalf.
As mentioned in Section 15.7, auditing is a useful security technique.
Windows XP has bL1ilt-in auditing that allows many common security threats
to be monitored. Examples include failure auditing for login and logoff events
to detect random password break-ins, success auditing for login and logoff
events to detect login activity at strange hours, success and failure write-access
auditing for executable files to track a virus outbreak, and success and failure
auditing for file access to detect access to sensitive files.
15.10
15.10 665
Security attributes of an object in Windows XP are described by a
The security descriptor contains the security ID of the owner
(who can change the access permissions), a group security ID used
the POSIX subsystem, a discretionary access-control list that identifies
users or groups are allowed (and which are not allowed) access, and
a system access-control list that controls which auditing messages the system
will generate. For example, the security descriptor of the file foo.bar might have
owner avi and this discretionary access-control list:
a vi -all access
group cs-read-write access
user cliff-no access
In addition, it might have a system access-control list of audit writes by
everyone.
An access-control list is composed of access-control entries that contain
the security ID of the individual and an access mask that defines all possible
actions on the object, with a value of AccessAllowed or AccessDenied for
each action. Files in Windows XP may have the following access types: ReadData,
WriteData,AppendData, Execute,ReadExtendedAttribute, WriteExtendedAttribute,
ReadAttributes, and Wri teAttributes. We can see
how this allows a fine degree of control over access to objects.
Windows XP classifies objects as either container objects or noncontainer
objects. such as directories, can logically contain other
objects. By default, an object is created within a container object, the new
object inherits permissions from the parent object. Similarly, if the user copies a
file from one directory to a new directory, the file will inherit the permissions of
the destination directory. inherit no other permissions.
Furthermore, if a permission is changed on a directory, the new permissions
do not automatically apply to existing files and subdirectories; the user may
explicitly apply them if she so desires.
The system administrator can prohibit printilig to a printer on the system
for all or part of a day and can use the Windows XP Performance Monitor to
help her spot approaching problems. In general, Windows XP does a good job
of providing features to help ensure a secure computing environment. Many of
these features are not enabled by default, however, which may be one reason
for the myriad security breaches on Windows XP systems. Another reason is
the vast number of services Windows XP starts at system boot tiine and the
number of applications that typically are installed on a Windows XP system.
For a real multiuser environment, the system administrator should formulate
a security plan and implement it, using the features that Windows XP provides
and other security tools.
Protection is an internal problem. Security, in contrast, must consider both
the computer system and the environment-people, buildings, businesses,
valuable objects, and threats-within which the system is used.
666 Chapter 15
The data stored in the computer system must be protected from unauthorized
access, malicious destruction or alteration, and accidental introduction of
inconsistency. It is easier to protect against accidental loss of data consistency
than to protect against malicious access to the data. Absolute protection of the
information stored in a computer system from malicious abuse is not possible;
but the cost to the perpetrator can be made sufficiently high to deter most, if
not all, attempts to access that information without proper authority.
Several types of attacks can be launched against programs and agaiTlSt
individual computers or the masses. Stack- and buffer-overflow techniques
allow successful attackers to change their level of system access. Viruses and
worms are self-perpetuating, sometimes infecting thousands of computers.
Denial-of-service attacks prevent legitimate use of target systems.
Encryption limits the domain of receivers of data, while authentication
limits the domain of senders. Encryption is used to provide confidentiality
of data being stored or transferred. Symmetric encryption requires a shared
key, while asymn'letric encryption provides a public key and a private key.
Authentication, when combined with hashing, can prove that data have not
been changed.
User authentication methods are used to identify legitimate users of a
system. In addition to standard user-name and password protection, several
authentication methods are used. One-time passwords, for example, change
from session to session to avoid replay attacks. Two-factor authentication
requires two forms of authentication, such as a hardware calculator with an
activation PIN. Multifactor authentication uses three or more forms. These
methods greatly decrease the chance of authentication forgery.
Methods of preventing or detecting security incidents include intrusiondetection
systems, antivirus software, auditing and logging of system events,
monitoring of system software changes, system-call monitoring, and firewalls.
15.1 Argue for or against the judicial sentence handed down against Robert
Morris, Jr., for his creation and execution of the Internet worm discussed
in Section 15.3.1.
15.2 Discuss a means by which managers of systems connected to the
Internet could design their systems to limit or eliminate the damage
done by worms. What are the drawbacks of making the change that
you suggest 
15.3 What commonly used computer programs are prone to man-in-themiddle
attacks  Discuss solutions for preventing this form of attack.
15.4 The UNIX program COPS scans a given system for possible security
holes and alerts the user to possible problems. What are two potential
hazards of using such a system for security  How can these problems
be limited or eliminated 
667
15.5 Make a list of six security concerns for a bank's computer system. For
each item on your list, state whether this concern relates to physicat
human, or operating-system~ security.
15.6 An experimental addition to UNIX allows a user to connect a
program to a file. The watchdog is invoked whenever a program
requests access to the file. The watchdog then either grants or denies
access to the file. Discuss two pros and two cons of using watchdogs
for security.
15.7 Discuss how the asymmetric encryption algorithm can be used to
achieve the following goals.
a. Authentication: the receiver knows that only the sender could
have generated the message.
b. Secrecy: only the receiver can decrypt the message.
c. Authentication and secrecy: only the receiver can decrypt the
message, and the receiver knows that only the sender could have
generated the message.
15.8 Why doesn't D(lce, N)(E(/cd, N)(m)) provide authentication of the
sender  To what uses can such an encryption be put 
15.9 Consider a system that generates 10 million audit records per day. Also
assume that there are on average 10 attacks per day on this system and
that each such attack is reflected in 20 records. If the intrusion-detection
system has a true-alarm rate of 0.6 and a false-alarm rate of 0.0005,
what percentage of alarms generated by the system correspond to real
intrusions 
15.10 What is the purpose of using a   salt   along with the user-provided
password  Where should the   salt   be stored, and how should it be
used 
General discussions concerning security are given by Hsiao et al. [1979L
Landwehr [1981], Deru:1ing [1982], Pfleeger and Pfleeger [2003], Tanenbaum
2003, and Russell and Gangemi [1991]. Also of general interest is the text by
Lobel [1986]. Computer networking is discussed in Kurose and Ross [2005].
Issues concernin~g the design and verification of secure systems are discussed
by Rushby [1981] and by Silverman [1983]. A security kernel for a
multiprocessor microcomputer is described by Schell [1983]. A distributed
secure system is described by Rushby and Randell [1983].
Morris and Thompson [1979] discuss password security. Morshedian
[1986] presents methods to fight password pirates. Password authentication
668 Chapter 15
with insecure communications is considered by Lamport [1981]. The issue
of password cracking is examined by Seely [1989]. Cmnputer break-ins are
discussed by Lehmann [1987] and by Reid [1987]. Issues related to trusting
computer programs are discussed in Thompson (1984].
Discussions concerning UNIX security are offered by Grampp and Morris
[1984 L Wood and Kochan [1985], Farrow [1986b], Farrow [1986a ], Filipski and
Hanko [1986], Hecht et al. [1988], Kramer [1988], and Garfinkel et al. [2003].
Bershad and Pinkerton [1988] present the watchdog extension to BSD UNIX. The
COPS security-scanning package for UNIX was written by Farmer at Purdue
University. It is available to users on the Internet via the FTP program from
host ftp.uu.net in directory /pub I security I cops.
Spafford [1989] presents a detailed technical discussion of the Internet
worm. The Spafford article appears with three others in a special section on
the Morris Internet worm in Communications of the ACM (Volume 32, Number
6, June 1989).
Security problems associated with the TCP /IP protocol suite are described
in Bellovin [1989]. The mechanisms commonly used to prevent such attacks are
discussed in Cheswick et al. [2003]. Another approach to protecting networks
from insider attacks is to secure topology or route discovery. Kent et al. [2000],
Hu et al. [2002], Zapata and Asokan [2002], and Hu and Perrig [2004] present
solutions for secure routing. Savage et al. [2000] examine the distributed denialof-
service attack and propose IP trace-back solutions to address the problem.
Perlman [1988] proposes an approach to diagnose faults when the network
contains malicious routers.
Information about viruses and worms can be found at
http:/ /www.viruslist.com, as well as in Ludwig [1998] and Ludwig
[2002]. Other Web sites containing up-to-date security information
include http:/ /www.trusecure.com and httpd:/ /www.eeye.com. A
paper on the dangers of a computer monoculture can be found at
http:/ /www.ccianet.org/papers/cyberinsecurity.pdf.
Diffie and Hellman [1976] and Diffie and Hellman [1979] were the first
researchers to propose the use of the public-key encryption scheme. The algorithm
presented in Section 15.4.1 is based on the public-key encryption scheme;
it was developed by Rivest et al. [1978]. Lempel [1979], Simmons [1979],
Denning and Demting [1979], Gifford [1982], Denning [1982], Ahituv et al.
[1987], Schneier [1996], and Stallings [2003] explore the use of cryptography in
computer systems. Discussions concerning protection of digital signatures are
offered by Akl [1983], Davies [1983], Denning [1983], and Denning [1984].
The U.S. government is, of course, concerned about security. The Department
of Defense Trusted Computer System Evaluation Criteria (DoD [1985]), known
also as the Orange Book, describes a set of security levels and the features that
an operating system must have to qualify for each security rating. Reading
it is a good starting point for understanding security concerns. The Microsoft
Windows NT Workstation Resource Kit (Microsoft [1996]) describes the security
Inodel of NT and how to use that model.
The RSA algorithm is presented in Rivest et al. [1978]. Information about
NIST's AES activities can be found at http:/ /www.nist.gov/aes/; information
about other cryptographic standards for the United States can also
be found at that site. More complete coverage of SSL 3.0 can be found at
669
http:/ /home.netscape.com/eng/ssl3/. In 1999, SSL 3.0 was modified slightly
and presented in an IETF Request for Comments (RFC) under the name TLS.
The example in Section 15.6.3 illustrating the impact of false-alarm rate
on the effectiveness of IDSs is based on Axelsson [1999]. The description of
Tripwire in Section 15.6.5 is based on Kim and Spafford [1993]. Research into
system-call-based anomaly detection is described in Forrest et al. [1996].

Part Seven
A distributed system is a collection of processors that do not share memory
or a clock. Instead, each processor has its own local memory, and the
processors communicate with one another through communication lines
such as local-area or wide-area networks. The processors in a distributed
system vary in size and function. Such systems may include small handheld
or real-time devices, personal computers, workstations, and large
mainframe computer systems.
A distributed file system is a file-service system whose users, servers,
and storage devices are dispersed among the sites of a distributed
system. Accordingly, service activity has to be carried out across the
network; instead of a single centralized data repository, there are multiple
independent storage devices.
The benefits of a distributed system include giving users access to
the resources maintained by the system and thereby speeding up computation
and improving data availability and reliability. Because a system is
distributed, however, it must provide mechanisms for process synchronization
and communication, for dealing with the deadlock problem, and
for handling failures that are not encountered in a centralized system.

16.1
A distributed system is a collection of processors that do not share memory
or a clock. Instead, each processor has its own local memory. The processors
communicate with one another through various communication networks,
such as high-speed buses or telephone lines. In this chapter, we discuss the
general structure of distributed systems and the networks that interconnect
them. We contrast the main differences in operating-system design between
these systems and centralized systems. In Chapter 17, we go on to discuss
distributed file systems. Then, i11 Chapter 18, we describe the methods
necessary for distributed operating systems to coordinate their actions.
To provide a high-level overview of distributed systems and the networks
that interconnect them.
To discuss the general structure of distributed operating systems.
A is a collection of loosely coupled processors interconnected
by a communication network. From the point of view of a specific
processor in a distributed system, the rest of the processors and their respective
resources are remote, whereas its own resources are local.
The processors in a distributed system may vary in size and function.
They may include small microprocessors, workstations, minicomputers, and
large general-purpose cornputer systems. These processors are referred to by a
number of names, such as sites, nodes, computers, machines, and hosts, depending
on the context in which they are mentioned. We mainly use site to indicate the
location of a machine and host to refer to a specific system at a site. Generally,
one host at one site, the server, has a resource that another host at another
site, the client (or user), would like to use. A general structure of a distributed
system is shown in Figure 16.1.
673
674 Chapter 16
site A site C
network
communication
site B
Figure 16.1 A distributed system.
D D
D D
l resources l
There are four major reasons for building distributed systems: resource
sharing, computation speedup, reliability, and communication. In this section, we
briefly discuss each of them.
16.1.1 Resource Sharing
If a number of different sites (with different capabilities) are connected to one
another, then a user at one site may be able to use the resources available at
another. For example, a user at site A may be using a laser printer located at
site B. Meanwhile, a user at B may access a file that resides at A. In general,
in a distributed system provides mechanisms for sharing
files at remote sites, processing information in a distributed database, printing
files at remote sites, using remote specialized hardware devices (such as a
high-speed array processor), and performing other operations.
16.1.2 Computation Speedup
If a particular computation can be partitioned into subcomputations that
can run concurrently, then a distributed system allows us to distribute
the subcomputations among the various sites; the subcomputations can be
run concurrently and thus provide In addition, if
a particular site is currently overloaded with jobs, some of them can be
moved to other, lightly loaded sites. This movement of jobs is called
Automated load sharing, in which the distributed operating system
automatically moves jobs, is not yet comnlOn in commercial systems.
16.1.3 Reliability
If one site fails in a distributed system, the remammg sites can continue
operating, giving the system better reliability. If the system is composed of
multiple large autonomous installations (that is, general-purpose computers),
the failure of one of them should not affect the rest. If, however, the system
16.2
16.2 675
is composed of sncall machines, each of which is responsible for some crucial
system function (such as tenninal character I/0 or the file system), then a single
failure may halt the operation of the whole system. In general, with enough
redundancy (in both hardware and data), the system can continue operation,
even if some of its sites have failed.
The failure of a site must be detected by the system, and appropriate action
may be needed to recover from the failure. The system must no longer use the
services of that site. In addition, if the function of the failed site can be taken
over by another site, the system must ensure that the transfer of function occurs
correctly. Finally, when the failed site recovers or is repaired, mechanisms must
be available to integrate it back into the system smoothly. As we shall see in
Chapters 17 and 18, these actions present difficult problems that have many
possible solutions.
16.1.4 Communication
When several sites are connected to one another by a communication network,
users at the various sites have the opportunity to exchange information. At
a low level, are passed between systems, much as messages are
passed between processes in the single-computer message system discussed
in Section 3.4. Given message passing, all the higher-level fLmctionality found
in standalone systems can be expanded to encompass the distributed system.
Such functions include file transfer, login, mail, and remote procedure calls
(RPCs).
The advantage of a distributed system is that these functions can be
carried out over great distances. Two people at geographically distant sites can
collaborate on a project, for example. By transferring the files of the project,
logging in to each other's remote systems to run programs, and exchanging
mail to coordinate the work, users minimize the limitations inherent in longdistance
work We wrote this book by collaborating in such a manner.
The advantages of distributed systems have resulted in an industry-wide
trend toward dovmslzing. Many companies are replacing their mainframes
with networks of workstations or personal computers. Companies get a bigger
bang for the buck (that is, better functionality for the cost), more flexibility in
locating resources and expanding facilities, better user interfaces, and easier
maintenance.
In this section, we describe the two general categories of network-oriented
operating systems: network operating systems and distributed operating
systems. Network operating systems are simpler to implement but generally
more difficult for users to access and utilize than are distributed operating
systems, which provide more features.
16.2.1 Network Operating Systems
A operating provides an environment in which users, who are
aware of the multiplicity of machines, can access remote resources by either
676 Chapter 16
logging in to the appropriate remote machine or transferring data from the
remote machine to their own machines.
16.2.1.1 Remote Login
An important function of a network operating system is to allow users to log in
remotely. The Internet provides the telnet facility for this p1.npose. To illustrate
this facility, lets suppose that a user at Westminster College wishes to compute
on   cs.yale.edu,   a computer that is located at Yale University. To do so, the
user must have a valid account on that machine. To log in remotely, the user
issues the command
telnet cs.yale.edu
This command results in the formation of a socket connection between the
local machine at Westminster College and the   cs.yale.edu   computer. After this
connection has been established, the networking software creates a transparent,
bidirectional link so that all characters entered by the user are sent to a process
on   cs.yale.edu   and all the output from that process is sent back to the user. The
process on the remote machine asks the user for a login name and a password.
Once the correct information has been received, the process acts as a proxy for
the use1~ who can compute on the remote machine just as any local user can.
16.2.1.2 Remote File Transfer
Another major function of a network operating system is to provide a
mechanism for remote file transfer from one machine to another. In such
an enviromnent, each computer maintains its own local file system. If a user at
one site (say,   cs.uvm.edu  ) wants to access a file located on another computer
(say,   cs.yale.edu  ), then the file must be copied explicitly from the computer
at Yale to the computer at the University of Vermont.
The Internet provides a mechanism for such a transfer with the file transfer
protocol (FTP) program. Suppose that a user on   cs.uvm.edu   wants to copy a
Java program Server. java that resides on   cs.yale.edu.   The user must first
invoke the FTP program by executing
ftp cs.yale.edu
The program then asks the user for a login name and a password. Once
the correct information has been received, the user must connect to the
subdirectory where the file Server. java resides and then copy the file by
executing
get Server. java
In this scheme, the file location is not transparent to the user; users must know
exactly where each file is. Moreover, there is no real file sharing, because a user
can only copy a file from one site to another. Thus, several copies of the same
file may exist, resulting in a waste of space. Tn addition, if these copies are
modified, the vario-us copies will be inconsistent.
16.2 677
Notice that, in our example, the user at the University of Vermont must
have login permission on   cs.yale.edu.   PTP also provides a way to allow a user
who does not have an account on the Yale computer to copy files remotely. This
remote copying is accomplished through the   anonymous FT'P   method, which
works as follows. The file to be copied (that is, Server. java) must be placed
in a special subdirectory (say, jtp) with the protection set to allow the public
to read the file. A user who wishes to copy the file uses the ftp command as
before. When the user is asked for the login nan'le, the user supplies the name
  anonymous   and an arbitrary password.
Once anonymous login is accomplished, care must be taken by the system
to ensure that this partially authorized user does not access inappropriate
files. Generally, the user is allowed to access only those files that are in the
directory tree of user   anonymous.   Any files placed here are accessible to
any anonymous users, subject to the usual file-protection scheme used on
that machine. Anonymous users, however, cam'lot access files outside of this
directory tree.
Implementation of the FTP mechanism is similar to telnet implementation.
A daemon on the remote site watches for requests to coru'lect to the system's PTP
port. Login authentication is accomplished, and the user is allowed to execute
commands remotely. Unlike the telnet daemon, which executes any command
for the user, the PTP daemon responds only to a predefined set of file-related
commands. These include the following:
get-Transfer a file from the remote machine to the local machine.
put-Transfer from the local machine to the remote machine.
ls or dir-List files in the current directory on the remote machine.
cd -Change the current directory on the remote machine.
There are also various commands to change transfer modes (for binary or ASCII
files) and to determine connection status.
An important point about telnet and PTP is that they require the user to
change paradigms. PTP requires the user to know a command set entirely
different from the normal operating-system commands. Telnet requires a
smaller shift: the user must know appropriate commands on the remote system.
For instance, a user on a Windows machine who teh'lets to a UNIX machine
must switch to UNIX commands for the duration of the telnet session. Facilities
are more convenient for users if they do not require the use of a different
set of commands. Distributed operating systems are designed to address this
problem.
16.2.2 Distributed Operating Systems
In a distributed operating system, users access remote resources in the same
way they access local resources. Data and process migration from one site to
another is under the control of the distributed operating system.
16.2.2.1 Data Migration
Suppose a user on site A wants to access data (such as a file) that reside at site
B. The system can transfer the data by one of two basic methods. One approach
678 Chapter 16
to is to transfer the entire file to site A. From that point on, all
access to the file is local. When the user no longer needs access to the file, a
copy of the file (if it has been modified) is sent back to site B. Even if only a
modest change has been made to a large file, all the data must be transferred.
This mechanism can be thought of as an automated FTP system. This approach
was used in the Andrew file system., as we discuss in Chapter 17, but it was
found to be too inefficient.
The other approach is to transfer to site A only those portions of the file
that are actually necessary for the immediate task. If another portion is required
later, another transfer will take place. When the user no longer wants to access
the file, any part of it that has been modified must be sent back to site B. (Note
the similarity to demand paging.) The Sun Microsystems network file system
(NFS) protocol uses this method (Chapter 17), as do newer versions of Andrew.
The Microsoft SMB protocol (running on top of either TCP /IP or the Microsoft
NetBEUI protocol) also allows file sharing over a network. SMB is described in
Appendix C.6.1.
Clearly, if only a small part of a large file is being accessed, the latter
approach is preferable. If significant portions of the file are being accessed,
however, it is more efficient to copy the entire file. In both methods, data
migration includes more than the mere transfer of data from one site to another.
The system must also perform various data translations if the two sites involved
are not directly compatible (for instance, if they use different character-code
representations or represent integers with a different number or order of bits).
16.2.2.2 Computation Migration
In some circumstances, we may want to transfer the computation, rather than
the data, across the system; this approach is called For
example, consider a job that needs to access various large files that reside at
different sites, to obtain a summary of those files. It would be more efficient to
access the files at the sites where they reside and return the desired results to
the site that il  itiated the computation. Generally, if the time to transfer the data
is longer than the time to execute the remote cmmnand, the remote command
should be used.
Such a computation can be carried out in different ways. Suppose that
process P wants to access a file at site A. Access to the file is carried out at
site A and could be il  itiated by an RPC. An RPC uses a
(UDP on the Internet) to execute a routine on a remote system (Section 3.6.2).
Process P invokes a predefilced procedure at site A. The procedure executes
appropriately and then returns the results to P.
Alternatively process P can send a message to site A. The operatil  g system
at site A then creates a new process Q whose function is to carry out the
designated task. When process Q completes its execution, it sends the needed
result back to P via the message system. In this scheme, process P may execute
concurrently with process Q; in fact, it may have several processes running
concurrently on several sites.
Either method could be used to access several files residing at various sites.
One RPC might result in the ilwocation of another RPC or even in the transfer
of messages to another site. Similarly, process Q could, duril  g the course of its
16.3
16.3 679
execution, send a message to another site, which in turn would create another
process. This process might either send a message back to Q or repeat the cycle.
16.2.2.3 Process Migration
A logical extension of computation migration is na  ,  '  '~c  
process is submitted for execution, it is not always executed at
it is initiated. The entire process, or parts of it, may be executed at different
sites. This scheme may be used for several reasons:
Load balancing. The processes (or subprocesses) may be distributed across
the network to even the workload.
Computation speedup. If a single process can be divided into a number
of subprocesses that can run concurrently on different sites, then the total
process turnaround time can be reduced.
Hardware preference. The process may have characteristics that make it
more suitable for execution on some specialized processor (such as matrix
inversion on an array processor) rather than on a microprocessor.
Software preference. The process may require software that is available
at only a particular site, and either the software cannot be moved, or it is
less expensive to move the process.
Data access. Just as in computation migration, if the data being used in the
computation are numerous, it may be more efficient to have a process run
remotely than to transfer all the data.
We use two complementary techniques to move processes in a computer
network. In the first, the system can attempt to hide the fact that the process has
migrated from the client. This scheme has the advantage that the user does not
need to code her program explicitly to accomplish the migration. This method
is usually employed for achieving load balancing and computation speedup
among homogeneous systems, as they do not need user input to help them
execute programs remotely.
The other approach is to allow (or require) the user to specify explicitly
how the process should migrate. This method is usually employed when the
process must be moved to satisfy a hardware or software preference.
You have probably realized that the Web has many aspects of a distributedcomputing
environment. Certainly it provides data migration (between a Web
server and a Web client). It also provides computation migration. For instance,
a Web client could trigger a database operation on a Web server. Finally, with
Java, it provides a form of process migration: Java applets are sent from the
server to the client, where they are executed. A network operating system
provides most of these features, but a distributed operating system makes
them seamless and easily accessible. The result is a powerful and easy-to-use
facility-one of the reasons for the huge growth of the World Wide Web.
There are basically two types of networks: and
The main difference between the two is the way in
680 Chapter 16
which they are geographically distributed. Local-area networks are composed
of processors distributed over small areas (such as a single building or a number
of adjacent buildings), whereas wide-area networks are composed of a number
of autonomous processors distributed over a large area (such as the United
States). These differences imply major variations in the speed and reliability
of the communications networks, and they are reflected in the distributed
operating-system design.
16.3.1 Local-Area Networks
Local-area networks emerged in the early 1970s as a substitute for large
mainframe computer systems. For many enterprises, it is more economical
to have a number of small computers, each with its own self-contained
applications, than to have a single large system. Because each small computer
is likely to need a full complement of peripheral devices (such as disks
and printers), and because some form of data sharing is likely to occur in
a single enterprise, it was a natural step to connect these small systems into a
network.
LANs, as mentioned, are usually designed to cover a small geographical
area (such as a single building or a few adjacent buildings) and are generally
used in an office environment. All the sites in such systems are close to one
another, so the communication links tend to have a higher speed and lower
error rate than do their cou.rJerparts in wide-area networks. High-quality
(expensive) cables are needed to attain this higher speed and reliability. It is
also possible to use the cable exclusively for data network traffic. Over longer
distances, the cost of using high-quality cable is enormous, and the exclusive
use of the cable tends to be prohibitively expensive.
The most conunon links in. a local-area network are twisted-pair and fiberoptic
cabling. The most common configurations are multiaccess bus, ring,
and star networks. Communication speeds range from 1 megabit per second,
for networks such as AppleTalk, infrared, and the new Bluetooth local radio
network, to 1 gigabit per second for Ethernet. Ten megabits per second
is the speed of requires a higher-quality
cable but runs at 100 m~egabits per second and is common. Also growing is the
use of optical-fiber-based FDDI networking. The FDDI network is token-based
and runs at over 100 megabits per second.
A typical LAN may consist of a number of different computers (from
mainframes to laptops or PDAs), various shared peripheral devices (such
as laser printers and magnetic-tape drives), and one or more gateways
(specialized processors) that provide access to other networks (Figure 16.2). An
Ethernet scheme is commonly used to construct LANs. An Ethernet network
has no central controller, because it is a multiaccess bus, so new hosts can be
added easily to the network The Ethernet protocol is defined by the IEEE 802.3
standard.
There has been significant growth in using the wireless spectrum for
designing local-area networks. Wireless (or WiFi) networks allow constructing
a network using only a wireless router for transmitting signals between hosts.
Each host has a wireless adapter networking card which allows it to join and
use the wireless network However, where Ethernet systems often run at 100
megabits per second, WiFi networks typically run at slower speeds. There are
16.3 681
workstation workstation workstation
printer laptop file server
Figure 16.2 Local-area network.
several IEEE standards for wireless networks: 802.11g can theoretically run at 54
megabits per second, although ilc practice data rates are often less than half that
amount. The recent 802.11n standard provides theoretically much higher data
rates than 802.11g, although in actual practice 802.11n networks have typical
data rates of around 75 megabits per second. Data rates of wireless networks
are heavily influenced by the distance between the wireless router and the
host as well as interference in the wireless spectrum. Wireless networks often
have a physical advantage over wired Ethernet networks as no cabling needs
to be run to connect communicatilcg hosts. As a result, wireless networks are
popular in homes as well as public areas such as libraries and Internet cafes.
16.3.2 Wide-Area Networks
Wide-area networks emerged in the late 1960s, mainly as an academic research
project to provide efficient communication among sites, allowing hardware and
software to be shared conveniently and economically by a wide community
of users. The first WAN to be designed and developed was the Arpanet. Begun
in 1968, the Arpanet has grown from a four-site experimental network to a
worldwide network of networks, the Internet, comprising millions of computer
systems.
Because the sites in a WAN are physically distributed over a large geographical
area, the communication links are, by default, relatively slow and unreliable.
Typical links are telephone lines, leased (dedicated data) lines, microwave links,
and satellite channels. These communication links are controlled by special
(Figure 16.3), which are responsible for defilcing
the interface through which the sites communicate over the network, as well
as for transferring information among the various sites.
682 Chapter 16
communication
subsystem
H
H
netwot k host
communication
processor
Figure 16.3 Communication processors in a wide-area network.
For example, the Internet WAN enables hosts at geographically separated
sites to communicate with one another. The host computers typically differ
from one another in type, speed, word length, operatil1.g system, and so
on. Hosts are generally on LANs, which are, in turn, connected to the
Internet via regional networks. The regional networks, such as NSFnet il1.
the northeast United States, are interlinked with (Section 16.5.2) to
form the worldwide network. Connections between networks frequently use a
telephone-system service called T1, which provides a transfer rate of 1.544
megabits per second over a leased line. For sites requiring faster Internet
access, Tls are collected into multiple-T1 units that work in parallel to provide
more throughput. For instance, a T3 is composed of 28 T1 connections and
has a transfer rate of 45 megabits per second. The routers control the path
each message takes through the net. This routing may be either dynamic, to
increase commmlication efficiency, or static, to reduce security risks or to allow
communication charges to be computed.
Other WANs use standard telephone lines as their primary means of communication.
are devices that accept digital data from the computer
side and convert it to the analog signals that the telephone system uses. A
modem at the destination site converts the analog signal back to digital form,
and the destination receives the data. The UNIX news network, UUCP, allows
systems to communicate with each other at predetermined times, via modems,
to exchange messages. The messages are then routed to other nearby systems
and in this way either are propagated to all hosts on the network (public
messages) or are transferred to specific destinations (private messages). WANs
are generally slower than LANs; their transmission rates range from 1,200 bits
16.4
16.4 683
per second to over 1 megabit per second. UUCP has been superseded by PPP,
the point-to-point protocol. PPP functions over modem coru1ections, allowing
home computers to be fully connected to the Internet.
The sites in a distributed system can be connected physically in a variety of
ways. Each configuration has advantages and disadvantages. We can compare
the configurations by using the following criteria:
Installation cost. The cost of physically linking the sites in the system
Communication cost. The cost in time and money to send a message from
site A to site B
Availability. The extent to which data can be accessed despite the failure
of some links or sites
The various topologies are depicted in Figure 16.4 as graphs whose nodes
correspond to sites. An edge from node A to node B corresponds to a direct
communication link between the two sites. In a fully connected network, each
site is directly connected to every other site. However, the number of links
grows as the square of the number of sites, resulting in a huge installation cost.
Therefore, fully connected networks are impractical in any large system.
In a pc:ntially direct links exist between some-but
not all-pairs of sites. Hence, the installation cost of such a configuration is
lower than that of the fully connected network. However, if two sites A and
B are not directly connected, messages from one to the other must be
through a sequence of communication links. This requirement results in a
higher communication cost.
If a communication link fails, messages that would have been transmitted
across the link must be rerouted. In some cases, another route through the
network may be found, so that the messages are able to reach their destination.
In other cases, a failure may mean that no connection exists between some
pair (or pairs) of sites. When a system is split into two (or more) unconnected
subsystems, it is partitioned. Under this definition, a subsystem (or partition)
may consist of a single node.
The various partially connected network types include tree-structured
networks, ring networks, and star networks, as shown in Figure 16.4. These
types have different failure characteristics and installation and communication
costs. Installation and communication costs are relatively low for a treestructured
network. However, the failure of a single link in such a network
can result in the network's becoming partitioned. In a ring network, at least
two links must fail for partition to occur. Thus, the ring network has a higher
degree of availability than does a tree-structured network. However, the
communication cost is high, since a message may have to cross a large number
of links. In a star network, the failure of a single link results in a network
partition, but one of the partitions has only a single site. Such a partition can be
treated as a single-site failure. The star network also has a low communication
cost, since each site is at most two links away from every other site. Howeve1~
684 Chapter 16
16.5
fully connected network partially connected network
B
D
F
tree-structured network star network
F
ring network
Figure 16.4 Network topology.
if the central site fails, all the sites in the system become disconnected from one
another.
Now that we have discussed the physical aspects of networking, we turn to
the internal workings. The designer of a communication network must address
five basic issues:
Naming and name resolution. How do two processes locate each other to
communicate 
Routing strategies. How are messages sent through the network 
Packet strategies. Are packets sent individually or as a sequence 
Connection strategies. How do two processes send a sequence of messages 
16.5 685
Contention. How do we resolve conflicting demands for the network's
LISe, given that it is a shared resource 
In the following sections, we elaborate on each of these issues.
16.5.1 Naming and Name Resolution
The first component of network communication is the naming o  the systems
in the network. For a process at site A to exchange information with a process
at site B, each must be able to specify the other. Within a computer system,
each process has a process identifier, and messages may be addressed with the
process identifier. Beca use networked systems share no memory, however, a
host within the system initially has no knowledge about the processes on other
hosts.
To solve this problem, processes on remote systems are generally identified
by the pair   host name, identifier  , where host name is a name unique within
the network and identifier may be a process identifier or other unique number
within. that host. A host name is usually an alphanumeric identifier, rather than
a number, to make it easier for users to specify. For instance, site A might have
hosts named homer, marge, bart, and lisa. Bart is certainly easier to remember
than is 12814831100.
Names are convenient for humans to use, but computers prefer numbers for
speed and simplicity. For this reason, there must be a mechanism to !-': the
host name into a that describes the destination system to the networking
hardware. This mechanism is similar to the name-to-address binding that
occurs during program compilation, linking, loading, and execution (Chapter
8). In the case of host names, two possibilities exist. First, every host may have a
data file containing the names and addresses of all the other hosts reachable on
the network (similar to binding at compile time). The problem with this model
is that adding or removing a host from the network requires updati.n.g the data
files on all the hosts. The alternative is to distribute the information among
systems on the network. The network must then use a protocol to distribute
and retrieve the information. This scheme is like execution-time binding. The
first method was the one originally used on the Internet; as the Internet
rnArr-,,or it became untenable, so the second method, the domain-name  '~'      '    
is now in use.
DNS specifies the naming structure of the hosts, as well as name-to-address
resolution. Hosts on the Internet are logically addressed with multipart names
known as IP addresses. The parts of an IP address progress frorn the most
specific to the most general part, with periods separating the fields. For
instance, bob.cs.brown.edu refers to host bob in the DepaTtment of
Science at Brown University within the top-level domain edu.
domains include com for commercial sites and for organizations, as well as
connected to the for systems
the resolves
in reverse order. Each
a a process on a
a name and returns the address of the name server
As the final the name server for the host in
host-id is returned. For a made
communicate with bob.cs.brown.edu would result in
686 Chapter 16
The kernel of system A issues a request to the name server for the edu
domain, asking for the address of the name server for brown.edu. The
name server for the edu domain must be at a known address, so that it
can be queried.
The edu nance server returns the address of the host on which the brown.edu
name server resides.
The kernel on system A then queries the name server at this address and
asks about cs.brown.edu.
An address is returned; and a request to that address for bob.cs.brown.edu
now, finally, returns an host-id for that host (for example,
128.148.31.100).
This protocol may seem inefficient, but local caches are usually kept by each
name server to speed the process. For example, the edu name server would
have brown.edu in its cache and would inform system A that it could resolve
two portions of the name, returning a pointer to the cs.brown.edu name server.
Of course, the contents of these caches must be refreshed over time in case
the name server is moved or its address changes. In fact, this service is so
important that many optimizations have occurred in the protocol, as well as
many safeguards. Consider what would happen if the primary edu name server
crashed. It is possible that no edu hosts would be able to have their addresses
resolved, making them all Lmreachable! The solution is to use secondary,
back-up name servers that duplicate the contents of the primary servers.
Before the domain-name service was introduced, all hosts on the Internet
needed to have copies of a file that contained the names and addresses of each
host on the network. All changes to this file had to be registered at one site (host
SRI-NIC), and periodically all hosts had to copy the updated file from SRI-NIC
to be able to contact new systems or find hosts whose addresses had changed.
Under the domain-name service, each name-server site is responsible for
updating the host information for that domain. For instance, any host changes
at Brown University are the responsibility of the name server for brown.edu
and need not be reported anywhere else. DNS lookups will automatically
retrieve the updated information because they will contact brown.edu directly.
Within domains, there can be autonomous subdomains to further distribute
the responsibility for host-name and host-id changes.
Java provides the necessary API to design a program that maps IP names to
IP addresses. The program shown in Figure 16.5 is passed an IP name (such as
bob.cs.brown.edu) on the command line and either outputs the IP address of the
host or returns a message indicating that the host name could not be resolved.
An InetAddress is a Java class representing an IP name or address. The static
method getByName () belonging to the InetAddress class is passed a string
representation of an IP name, and it returns the corresponding InetAddress.
The program then invokes the getHostAddress () method, which internally
uses DNS to look up the IP address of the designated host.
Generally, the operating system is responsible for accepting from its
processes a message destined for   host name, identifier   and for transferring
that message to the appropriate host. The kernel on the destination host is then
responsible for transferring the message to the process named by the identifier.
This exchange is by no means trivial; it is described in Section 16.5.4.
16.5
I    
   Usage: java DNSLookUp   IP name  
   i.e. java DNSLookUp www.wiley.com
  I
public class DNSLookUp {
}
public static void main(String[] args) {
InetAddress hostAddress;
try {
}
hostAddress = InetAddress.getByName(args[O]);
System.out.println(hostAddress.getHostAddress());
catch (UnknownHostException uhe) {
}
}
System. err. println (  Unknown host:    + args [0]) ;
Figure 16.5 Java program illustrating a DNS lookup.
16.5.2 Routing Strategies
687
When a process at site A wants to communicate with a process at site B, how
is the message sent  If there is only one physical path from A to B (such as
in a star or tree-structured network), the message must be sent through that
path. However, if there are multiple physical paths from A to B, then several
routing options exist. Each site has a indicating the alternative
paths that can be used to send a message to other sites. The table may include
information about the speed and cost of the various communication paths,
and it may be updated as necessary, either manually or via programs that
exchange routing information. The three most common routing schemes are
td~.-i:Ja] and
Fixed routing. A path from A to B is specified in advance and does not
change unless a hardware failure disables it. Usually, the shortest path is
chosen, so that communication costs are minimized.
Virtual routing. A path from A to B is fixed for the duration of one
Different sessions involving messages from A to B may use different paths.
A session could be as short as a file transfer or as long as a remote-login
period.
Dynamic routing. The path used to send a message from site A to site
B is chosen only when the message is sent. Because the decision is made
dynamically, separate messages may be assigned different paths. Site A
will make a decision to send the message to site C; C, in turn, will decide
to send it to siteD, and so on. Eventually, a site will deliver the message
to B. Usually, a site sends a message to another site on whatever link is the
least used at that particular time.
There are tradeoffs among these three schem.es. Fixed routing cannot adapt
to link failures or load changes. In other words, if a path has been established
688 Chapter 16
between A and B, the messages must be sent along this path, even if the path
is down or is used more heavily than another possible path. We can partially
remedy this problem by using virtual routing and can avoid it completely by
using dynamic routing. Fixed routing and virtual routing ensure that ncessages
from A to B will be delivered in the order in which they were sent. In dynamic
routing, messages may arrive out of order. We can remedy this problem by
appending a sequence number to each message.
Dynamic routing is the most complicated to set up and run; however, it is
the best way to manage routing in complicated environments. UNIX provides
both fixed routing for use on hosts within simple networks and dynamic
routing for complicated network environments. It is also possible to mix the
two. Within a site, the hosts may just need to know how to reach the system that
connects the local network to other networks (such as company-wide networks
or the Internet). Such a node is known as a Each individual host has
a static route to the gateway, although the gateway itself uses dynamic routing
to reach any host on the rest of the network.
A router is the entity within the computer network responsible for routing
messages. A router can be a host computer with routing software or a
special-purpose device. Either way, a router must have at least two network
cmmections, or else it would have nowhere to route messages. A router decides
whether any given message needs to be passed from the network on which
it is received to any other network connected to the router. It makes this
determination by examining the destination Internet address of the message.
The router checks its tables to determine the location of the destination host, or
at least of the network to which it will send the message toward the destination
host. In the case of static routing, this table is changed only by manual update
(a new file is loaded onto the router). With dynamic routing, a
is used between routers to inform them of network changes and to allow them
to update their routing tables automatically. Gateways and routers typically
are dedicated hardware devices that run code out of firmware.
16.5.3 Packet Strategies
Messages generally vary in length. To simplify the system design., we commonly
implement communication with fixed-length messages called
or A communication incplemented in one packet can be
sent to its destination in a A connectionless message
can be in which case the sender has no guarantee that, and cannot
tell whether, the packet reached its destination. Alternatively, the packet can
be usually, in this case, a packet is returned from the destination
indicating that the packet arrived. (Of course, the return packet could be lost
along the way.) If a message is too long to fit within one packet, or if the packets
need to How back and forth between the two communicators, a connection is
established to allow the reliable exchange of multiple packets.
16.5.4 Connection Strategies
c~uuc'''~u are able to reach their destinations, processes can institute
to exchange information. Pairs of processes that
want to communicate over the network can be connected in a number of ways.
16.5 689
The three most common schemes are
and
Circuit switching. If two processes want to con1municate, a permanent
physical link is established between them. Tl1is link is allocated for the
duration of the communication session, and no other process can use
that link during this period (even if the two processes are not actively
communicating for a while). This scheme is similar to that used in the
telephone system. Once a communication line has been opened between
two parties (that is, party A calls party B), no one else can use this circuit
until the communication is terminated explicitly (for example, when the
parties hang up).
Message switching. If two processes want to communicate, a temporary
link is established for the duration of one message transfer. Physical
links are allocated dynamically among correspondents as needed and
are allocated for only short periods. Each message is a block of data
with system information-such as the source, the destination, and errorcorrection
codes (ECC)-that allows the communication network to deliver
the message to the destination correctly. This scheme is similar to the
post-office mailing system. Each letter is a message that contains both the
destination address and source (return) address. Many messages (from
different users) can be shipped over the same link.
Packet switching. One logical message may have to be divided into a
number of packets. Each packet may be sent to its destination separately,
and each therefore must include a source and a destination address with its
data. Furthermore, the various packets may take different paths through
the network. The packets must be reassembled into messages as they
arrive. Note that it is not harmful for data to be broken into packets,
possibly routed separately, and reassembled at the destination. Breaking
up an audio signal (say, a telephone communication), in contrast, could
cause great confusion if it was not done carefully.
There are obvious tradeoffs among these schemes. Circuit switching requires
substantial set-up time and may waste network bandwidth, but it incurs
less overhead for shipping each message. Conversely, message and packet
switching require less set-up time but incur more overhead per message. Also,
in packet switching, each message must be divided into packets and later
reassembled. Packet switching is the method most commonly used on data
networks because it makes the best use of network bandwidth.
16.5.5 Contention
Depending on the network topology, a link may cmmect more than two sites
in the computer network, and several of these sites may want to transmit
information over a link simultaneously. This situation occurs mainly in a ring or
multiaccess bus network. In this case, the transmitted information may become
scrambled. If it does, it must be discarded; and the sites must be notified about
the problem so that they can retransmit the information. If no special provisions
are made, this situation may be repeated, resulting in degraded performance.
690 Chapter 16
16.6
Several techniques have been developed to avoid repeated collisions, including
collision detection and token passing.
CSMA/CD. Before transmitting a message over a link, a site must listen
to determine whether another message is currently being transmitted
over that link; this technique is called -uvith
. If the link is free, the site can start transmitting. Otherwise, it must
wait (and continue to listen) until the link is free. If two or more sites begin
transmitting at exactly the same time (each thinking that no other site is
using the link), then they will register a and will
stop transmitting. Each site will try again after some random time interval.
The main problem with this approach is that, when the system is very
busy, many collisions may occur, and thus performance may be degraded.
Nevertheless, CSMA/CD has been used successfully in the Ethernet system,
the most common local area network system. One strategy for limiting the
number of collisions is to limit the number of hosts per Ethernet network.
Adding more hosts to a congested network could result in poor network
throughput. As systems get faster, they are able to send more packets per
time segment. As a result, the number of systems per Ethernet network
generally is decreasing so that networking performance is kept reasonable.
Token passing. A unique message type, known as a continuously
circulates in the system (usually a ring structure). A site that wants to
transmit information must wait until the token arrives. It then removes
the token from the ring and begins to transmit its messages. When the
site completes its round of message passing, it retransmits the token. This
action, in turn, allows another site to receive and remove the token and
to start its message transmission. If the token gets lost, the system must
detect the loss and generate a new token. It usually does that by declaring
an to choose a unique site where a new token will be generated.
Later, in Section 18.6, we present one election algorithm. A token-passing
scheme has been adopted by the IBM and HP I Apollo systems. The benefit
of a token-passing network is that performance is constant. Adding new
sites to a network may lengthen the waiting time for a token, but it will not
cause a large performance decrease, as may happen on Ethernet. On lightly
loaded networks, however, Ethernet is more efficient, because systems can
send messages at any time.
When we are designing a communication network, we must deal with the
inherent complexity of coordinating asynchronous operations communicating
in a potentially slow and error-prone environment. In addition, the systems on
the network must agree on a protocol or a set of protocols for determining
host names, locating hosts on the network, establishing connections, and
so on. We can simplify the design problem (and related implementation)
by partitioning the problem into multiple layers. Each layer on one system
communicates with the equivalent layer on other systems. Typically, each layer
has its own protocols, and communication takes place between peer layers
16.6 691
network environment
ISO environment
real systems environment
Figure 16.6 Two computers communicating via the ISO network model.
using a specific protocol. The protocols may be implemented in hardware or
software. For instance, Figure 16.6 shows the logical communications between
two computers, with the three lowest-level layers implemented in hardware.
Following the International Standards Organization (ISO), we refer to the layers
as follows:
Physical layer. The physical layer is responsible for handling both the
mechanical and the electrical details of the physical transmission of a bit
stream. At the physical layer, the communicating systems must agree on
the electrical representation of a binary 0 and 1, so that when data are
sent as a stream of electrical signals, the receiver is able to interpret the
data properly as binary data. This layer is implemented in the hardware
of the networking device.
Data-link layer. The data-link layer is responsible for handlingfi'ames, or
fixed-length parts of packets, including any error detection and recovery
that occurs in the physical layer.
Network layer. The network layer is responsible for providing connecti01cS
and for routing packets in the communication network, including
handling the addresses of outgoing packets, decoding the addresses
of incoming packets, and maintaining routing information for proper
response to changing load levels. Routers work at this layer.
Transport layer. The transport layer is responsible for low-level access
to the network and for transfer of messages between clients, including
partitioning messages into packets, maintaining packet order, controlling
flow, and generating physical addresses.
Session layer. The session layer is responsible for implementing sessions,
or process-to-process communication protocols. Typically, these protocols
are the actual communications for remote logins and for file and mail
transfers.
692 Chapter 16
Presentation layer. The presentation layer is responsible for resolving the
differences in formats among the various sites in the network, including
character conversions and half duplex-full duplex modes (character
echoing).
Application layer. The application layer is responsible for interacting
directly with users. This layer deals with file transfe1~ remote-login
protocols, and electronic mail, as well as with schemas for distributed
databases.
Figure 16.7 summarizes the set of cooperating
protocols-showing the physical flow of data. As mentioned, logically each
layer of a protocol stack communicates with the equivalent layer on other
systems. But physically, a message starts at or above the application layer and
end-user application process
distributed information
transfer-syntax negotiation
data-representation transformations
dialog and synchronization
control for application entities
network-independent
message-interchange service J
end-to~end message transfer
(connection management, error control,
fragmentation, flow control)
network routing, addressing,
call set-up and clearing
application layer
presentation layer
session layer
transport layer
network layer
data-link control
(framing, data transparency, error control) link layer
mechanical and electrical
networkcinterface connections
physical connection to
network termination equipment
physical layer
16.7 The ISO protocol stack.
16.6
data-link -layer header
network-layer header
transport-layer header
f-------1
session-layer header
f-------1
presentation layer
f-------1
application layer
message
L_ _ _____j data-link -layer trailer
Figure 16.8 An ISO network message.
693
is passed through each lower level in turn. Each layer may modify the message
and il1.clude message-header data for the equivalent layer on the receiving
side. Ultimately, the message reaches the data-network layer and is transferred
as one or more packets (Figure 16.8). The data-lil1.k layer of the target system
receives these data, and the message is moved up through the protocol stack;
it is analyzed, modified, and stripped of headers as it progresses. It fu1.ally
reaches the application layer for use by the receiving process.
The ISO model formalizes some of the earlier work done in network
protocols but was developed in the late 1970s and is currently not in widespread
use. Perhaps the most widely adopted protocol stack is the TCP /IP model, which
has been adopted by virtually all Internet sites. The TCP /IP protocol stack
has fewer layers than does the ISO model. Theoretically, because it combilles
several functions ill each layer, it is more difficult to implement but more
efficient than ISO networking. The relationship between the ISO and TCP /IP
models is shown in Figure 16.9. The TCP /IP application layer identifies several
protocols ill widespread use ill the Internet, illcluding HTTP, FTP, Telnet, DNS,
and SMTP. The transport layer identifies the unreliable, connectionless user
datagram protocol (UDP) and the reliable, connection-oriented transmission
control protocol (TCP). The Internet protocol (IP) is responsible for routing IP
datagrams through the Internet. The TCP /IP model does not formally identify
a link or physical laye1~ allowing TCP /IP traffic to run across any physical
network. In Section 16.9, we consider the TCP /IP model running over an
Ethernet network.
Security should be a concern in the design and implementation of any
modern communication protocol. Both strong authentication and encryption
are needed for secure communication. Strong authentication ensures that
the sender and receiver of a communication are who or what they are
supposed to be. Encryption protects the contents of the communication
from eavesdropping. Weak authentication and clear-text communication are
still very common, however, for a variety of reasons. When most of the
694 Chapter 16
16.7
ISO
presentation
session
physical
TCP/IP
HTTP, DNS, Telnet
SMTP, FTP
not defined
not defined
TCP-UDP
not defined
not defined
Figure 16.9 The ISO and TCP/IP protocol stacks.
common protocols were designed, security was frequently less important than
performance, simplicity, and efficiency.
Strong authentication requires a multistep handshake protocol or authentication
devices, adding complexity to a protocol. Modern CPUs can efficiently
perform encryption, and systems frequently offload encryption to separate
cryptography processors, so system performance is not compromised. Longdistance
communication can be made secure by authenticating the endpoints
and encrypting the stream of packets in a virtual private network, as discussed
in 15.4.2. LAN communication remains unencrypted at most sites, but protocols
such as NFS Version 4, which includes strong native authentication and
encryption, should help improve even LAN security.
A distributed system may suffer from various types of hardware failure. The
failure of a link, the failure of a site, and the loss of a message are the most
common types. To ensure that the system is robust, we must detect any of these
failures, reconfigure the system so that computation can continue, and recover
when a site or a link is repaired.
16.7.1 Failure Detection
In an environment with no shared memory, we are generally unable to
differentiate among link failure, site failure, and message loss. We can usually
detect only that one of these failures has occurred. Once a failure has been
16.7 695
detected, appropriate action must be taken. What action is appropriate depends
on the particular application.
To detect link and site failure, we use a procedure. Suppose
that sites A and B have a direct physical link between them .. At fixed intervals,
the sites send each other an J-am-up m.essage. If site A does not receive this
message within a predetermined time period, it can assume that site B has
failed, that the link between A and B has failed, or that the message from B
has been lost. At this point, site A has two choices. It can wait for another time
period to receive an J-am-up message from B, or it can send an Are-you-up 
message to B.
If time goes by and site A still has not received an J-am-up message, or if site
A has sent an Are-you-up  message and has not received a reply, the procedure
can be repeated. Again, the only conclusion that site A can draw safely is that
some type of failure has occurred.
Site A can try to differentiate between link failure and site failure by sending
an Are-you-up  message to B by another route (if one exists). If and when B
receives this message, it immediately replies positively. This positive reply tells
A that B is up and that the failure is in the direct link between them. Since we
do not know in advance how long it will take the message to travel from A to B
and back, we must use a At the time A sends the Are-you-up 
message, it specifies a time interval during which it is willing to wait for the
reply from B. If A receives the reply message within that time interval, then it
can safely conclude that B is up. If not, however (that is, if a time-out occurs),
then A may conclude only that one or more of the following sih1ations has
occurred:
Site B is down.
The direct link (if one exists) from A to B is down.
The alternative path from A to B is down.
The message has been lost.
Site A cannot, however, determine which of these events has occurred.
16.7.2 Reconfiguration
Suppose that site A has discovered, through the mechanism described in the
previous section, that a failure has occurred. It must then initiate a procedure
that will allow the system to reconfigure and to continue its normal mode of
operation.
If a direct link from A to B has failed, this information must be broadcast to
every site in the system, so that the various routing tables can be updated
accordingly.
If the system believes that a site has failed (because that site can be reached
no longer), then all sites in the system must be so notified, so that they
will no longer attempt to use the services of the failed site. The failure of a
site that serves as a central coordinator for some activity (such as deadlock
detection) requires the election of a new coordinator. Similarly, if the failed
696 Chapter 16
site is part of a logical ring, then a new logical ring must be constructed.
Note that, if the site has not failed (that is, if it is up but camwt be reached),
then we may have the undesirable situation in which two sites serve as the
coordinator. When the network is partitioned, the two coordinators (each
for its own partition) may initiate conflicting actions. For example, if the
coordinators are responsible for implementing mutual exclusion, we may
have a situation in which two processes are executing simultaneously in
their critical sections.
16.7.3 Recovery from Failure
When a failed link or site is repaired, it must be integrated into the system
gracefully and smoothly.
Suppose that a link between A and B has failed. Wlcen it is repaired,
both A and B must be notified. We can accomplish this notification by
continuously repeating the handshaking procedure described in Section
16.7.1.
Suppose that site B has failed. Wlcen it recovers, it must notify all other sites
that it is up again. Site B then may have to receive information from the
other sites to update its local tables; for example, it may need routing-table
information, a list of sites that are down, or mcdelivered messages and
mail. If the site has not failed but simply could not be reached, then this
information is still required.
16.7.4 Fault Tolerance
A distributed system must tolerate a certain level of failure and continue to
function normally when faced with various types of failures. Making a facility
fault tolerant starts at the protocol level, as described above, but continues
through all aspects of the system. We use the term fault tolerance in a broad
sense. Communication faults, machine failures (of type fail-stop where the
machine stops before performing an erroneous operation that is visible to other
processors), storage-device crashes, and decays of storage media should all be
tolerated to some extent. A should continue to function,
perhaps in a degraded form, when faced with such failures. The degradation
can be in performance, in functionality, or in both. It should be proportional,
however, to the failures that caused it. A system that grinds to a halt when only
one of its components fails is certainly not fault tolerant.
Unfortunately, fault tolerance can be difficult and expensive to implement.
At the network layer, multiple redundant communication paths and network
devices such as switches and routers are needed to avoid a cmnmunication
failure. A storage failure can cause loss of the operating system, applications,
or data. Storage units can include redundant hardware components that
automatically take over from each other in case of failure. In addition, RAID
systems can ensure continued access to the data even in the event of one or
more disk failures (Section 12.7).
A system failure without redundancy can cause an application or an entire
facility to stop operation. The Inost simple system failure involves a system
running only stateless applications. These applications can be restarted without
16.8
16.8 697
compromising the operation; so as long as the applications can run on more
than one computer (node), operation can continue. Such a facility is commonly
known as a because it is computation-centric.
In contrast, systems involve running applications that access
and modify shared data. As a result, data-centric computing facilities are more
difficult to make fault tolerant. They failure-monitoring software and
special infrastructure. For instance, such as Veritas
Cluster and Sun Cluster include two or more computers and a set of shared
disks. Any given application can be stored on the computers or on the shared
disk, but the data must be stored on the shared disk. The running application's
node has exclusive access to the application's data on disk. The application is
monitored by the cluster software, and if it fails it is automatically restarted.
If it camwt be restarted, or if the entire computer fails, the node's exclusive
access to the application's data is terminated and is granted to another node
in the cluster. The application is restarted on that new node. The application
loses whatever state information was in the failed system's memory but can
continue based on whatever state it last wrote to the shared disk. From a user's
point of view, a service was interrupted and then restarted, possibly with some
data missing.
Specific applications may improve on this functionality by implementing
lock management along with clustering. With lock management (Section
18.4.1), the application can run on multiple nodes and can use the same data
on shared disks concurrently. Clustered databases frequently implement this
functionality. If anode fails, transactions can continue on other nodes, and users
notice no interruption of service, as long as the client is able to automatically
locate the other nodes in the cluster. Any noncommitted transactions on the
failed node are lost, but again, client applications can be designed to retry
noncommitted transactions if they detect a failure of their database node.
Making the multiplicity of processors and storage devices to the
users has been a key challenge to many designers. Ideally, a distributed system
should look to its users like a conventional, centralized system. The user
interface of a transparent distributed system should not distinguish between
local and remote resources. That is, users should be able to access remote
resources as though these resources were local, and the distributed system
should be responsible for locating the resources and for arranging for the
appropriate interaction.
Another aspect of transparency is user mobility. It would be convenient
to allow users to log into any machine in the system rather than forcing
them to use a specific machine. A transparent distributed system facilitates
user mobility by bringiicg over the user's environment (for example, home
directory) to wherever he logs in. Both the Andrew file system from CMU and
Project Athena from MIT provide this functionality on a large scale; NFS can
provide it on a smaller scale.
Still another issue is L;. -the capability of a system to adapt to
increased service load. Systems have bounded resources and can become
completely saturated under increased load. For example, with respect to a file
698 Chapter 16
system, saturation occurs either when a server's CPU runs at a high utilization
rate or when disks are almost full. Scalability is a relative property, but it can be
measured accurately. A scalable system reacts more gracefully to increased load
than does a nonscalable one. First, its performance degrades more moderately;
and second, its resources reach a saturated state later. Even perfect design
cannot accommodate an ever-growing load. Adding new resources might solve
the problem, but it might generate additional indirect load on other resources
(for example, adding machines to a distributed system can clog the network
and increase service loads). Even worse, expanding the system can call for
expensive design modifications. A scalable system should have the potential
to grow without these problems. In a distributed system, the ability to scale
up gracefully is of special importance, since expanding the network by adding
new machines or interconnecting two networks is commonplace. In short, a
scalable design should withstand high service load, accommodate growth of
the user community, and enable simple integration of added resources.
Scalability is related to fault tolerance, discussed earlier. A heavily loaded
component can become paralyzed and behave like a faulty component. Also,
shifting the load from a faulty component to that component's backup can
saturate the latter. Generally, having spare resources is essential for ensuring
reliability as well as for handling peak loads gracefully. An inherent advantage
of a distributed system is a potential for fault tolerance and scalability because
of the multiplicity of resources. However, inappropriate design can obscure
this potential. Fault-tolerance and scalability considerations call for a design
demonstrating distribution of control and data.
Very large-scale distributed systems, to a great extent, are still only
theoretical. No magic guidelines ensure the scalability of a system. It is easier
to point out why current designs are not scalable. We next discuss several
designs that pose problems and propose possible solutions, all in the context
of scalability.
One principle for designing very large-scale systems is that the service
demand from any component of the system should be bounded by a constant
that is independent of the number of nodes in the system. Any service
mechanism whose load demand is proportional to the size of the system is
destined to become clogged once the system grows beyond a certain size.
Adding more resources will not alleviate such a problem. The capacity of this
mechanism simply limits the growth of the system.
Another principle concerns centralization. Central control schemes and
central resources should not be used to build scalable (and fault-tolerant)
systems. Examples of centralized entities are central authentication servers,
central naming servers, and central file servers. Centralization is a form of
functional asyrrunetry among machines constituting the system. The ideal
alternative is a functionally symmetric configuration; that is, all the component
machines have an equal role in the operation of the system, and hence each
machine has some degree of autonomy. Practically, it is virtually impossible to
comply with such a principle. For instance, incorporating diskless machines
violates functional symmetry, since the workstations depend on a central disk
However, autonomy and symmetry are important goals to which we should
aspire.
Deciding on the process structure of the server is a major problem in
the design of any service. Servers are supposed to operate efficiently in peak
16.9
16.9 699
periods, when hundreds of active clients need to be served simultaneously. A
single-process server is certainly not a good choice, since whenever a request
necessitates disk I/0, the whole service will be blocked. Assigning a process for
each client is a better choice; however, the expense of frequent context switches
between the processes must be considered. A related problem occurs because
all the server processes need to share information.
One of the best solutions for the server architecture is the use of lightweight
processes, or threads, which we discuss in Chapter 4. We can think of a group
of lightweight processes as multiple threads of control associated with some
shared resources. Usually, a lightweight process is not bound to a particular
client. Instead, it serves single requests of different clients. Scheduling of
threads can be preemptive or nonpreemptive. If threads are allowed to run
to completion (nonpreemptive), then their shared data do not need to be
protected explicitly. Otherwise, some explicit locking mechanism must be used.
Clearly, some form of lightweight-process scheme is essential if servers are to
be scalable.
We now return to the name-resolution issue raised in Section 16.5.1 and
examine its operation with respect to the TCF /IF protocol stack on the Internet.
We consider the processing needed to transfer a packet between hosts on
different Ethernet networks.
In a TCF /IF network, every host has a name and an associated IF address
(or host-id). Both of these strings must be unique; and so that the name space
can be managed, they are segmented. The name is hierarchical (as explained
in Section 16.5.1), describing the host name and then the organization with
which the host is associated. The host-id is split into a network number and a
host number. The proportion of the split varies, depending on the size of the
network. Once the Internet adrninistrators assign a network number, the site
with that number is free to assign host-ids.
The sending system checks its routing tables to locate a router to send the
frame on its way. The routers use the network part of the host-id to transfer
the packet from its source network to the destination network. The destination
system then receives the packet. The packet may be a complete message, or it
may just be a component of a message, with more packets needed before the
message can be reassembled and passed to the TCF /UDF layer for transmission
to the destination process.
Now we know how a packet moves from its source network to its
destination. Within a network, how does a packet move from sender (host
or router) to receiver  Ethernet device has a unique byte number, called
the assigned to it for addressing. Two
devices on a LAN communicate with each other only with this number. If
a system needs to send data to another system, the networking software
generates an containing the IF
address of the destination system. This packet is to all other systems
on that Ethernet network.
A broadcast uses a special network address (usually, the maximum
address) to signal that all hosts should receive and process the packet. The
700 Chapter 16
broadcast is not re-sent by gateways, so only systems on the local network
receive it. Only the system whose IP address matches the IP address of the ARP
request responds and sends back its MAC address to the system that initiated
the query. For efficiency, the host caches the IP-MAC address pair in an internal
table. The cache entries are so that an entry is eventually removed from
the cache if an access to that system is not required within a given time. In
this way, hosts that are removed from a network are eventually forgotten. For
added performance, ARP entries for heavily used hosts may be hardwired in
the ARP cache.
Once an Ethernet device has announced its host-id and address, communication
can begin. A process may specify the name of a host with which to
communicate. Networking software takes that name and determines the IP
address of the target, using a DNS lookup. The message is passed from the
application laye1~ through the software layers, and to the hardware layer. At
the hardware layer, the packet (or packets) has the Ethernet address at its start;
a trailer indicates the end of the packet and contains a for detection
of packet damage (Figure 16.10). The packet is placed on the network by the
Ethernet device. The data section of the packet may contain some or all of the
data of the original message, but it may also contain some of the upper-level
headers that compose the message. In other words, all parts of the original
message must be sent from source to destination, and all headers above the
802.3layer (data-link layer) are included as data in the Ethernet packets.
If the destination is on the same local network as the source, the system
can look in its ARP cache, find the Ethernet address of the host, and place the
packet on the wire. The destination Ethernet device then sees its address in the
packet and reads in the packet passing it up the protocol stack.
If the destination system is on a network different from that of the source,
the source system finds an appropriate router on its network and sends the
packet there. Routers then pass the packet along the WAN 1-mtil it reaches its
bytes
7
2 or 6
2 or 6
2
0-1500
0-46
4
Pt.e~~n1bh:l.~s.tartfc1Ft:r  =ccll  et( 1 each byte pattern 1010101 o
data
pattern 10101011
Ethernet address or broadcast
Ethernet address
length in bytes
message data
message must be   63 bytes long
for error detection
Figure i 6.10 An Ethernet packet.
16.10
701
destination network. The router that connects the destination network checks
its ARP cache, finds the Ethernet number of the destination, and sends the
packet to that host. Through all of these transfers, the data-link-layer header
may change as the Ethernet address of the next router in the chain is used, but
the other headers of the packet remain the same until the packet is received
and processed by the protocol stack and finally passed to the receiving process
by the kernel.
A distributed system is a collection of processors that do not share memory or
a clock. Instead, each processor has its own local memory, and the processors
communicate with one another through various communication lines, such
as high-speed buses and telephone lines. The processors in a distributed
system vary in size and function. They may include small microprocessors,
workstations, minicomputers, and large general-purpose computer systems.
The processors in the system are connected through a communication
network, which can be configured in a number of ways. The network may
be fully or partially connected. It may be a tree, a star, a ring, or a multiaccess
bus. The communication-network design must include routing and com1ection
strategies, and it must solve the problems of contention and security.
A distributed system provides the user with access to the resources
the system provides. Access to a shared resource can be provided by data
migration, computation migration, or process migration.
Protocol stacks, as specified by network layering models,   massage   the
message, adding information to it to ensure that it reaches its destination. A
naming system (such as DNS) must be used to translate from a host name
to a network address, and another protocol (such as ARP) may be needed
to translate the network number to a network device address (an Ethernet
address, for instance). If systems are located on separate networks, routers are
needed to pass packets from source network to destination network.
A distributed system may suffer from various types of hardware failure.
For a distributed system to be fault tolerant, it must detect hardware failures
and reconfigure the system. When the failure is repaired, the system must be
reconfigured again.
16.1 What are the advantages of using dedicated hardware devices for
routers and gateways  What are the disadvantages of using these
devices compared with using general-purpose computers 
16.2 Why would it be a bad idea for gateways to pass broadcast packets
between networks  What would be the advantages of doing so 
16.3 Consider a network layer that senses collisions and retransmits immediately
on detection of a collision. What problems could arise with this
strategy  How could they be rectified 
702 Chapter 16
16.4 Even though the ISO model of networking specifies seven layers of
functionality, most computer systems use fewer layers to implement a
network. Why do they use fewer layers  What problems could the use
of fewer layers cause 
16.5 The lower layers of the ISO network model provide datagram service,
with no delivery guarantees for messages. A transport-layer protocol
such as TCP is used to provide reliability. Discuss the advantages and
disadvantages of supporting reliable message delivery at the lowest
possible layer.
16.6 What are the advantages and the disadvantages of making the computer
network transparent to the user 
16.7 Under what circumstances is a token-passing network more effective
than an Ethernet network 
16.8 Process migration within a heterogeneous network is usually impossible,
given the differences in architectures and operating systems.
Describe a method for process migration across different architectures
running:
a. The same operating system
b. Different operating systems
16.9 Contrast the various network topologies in terms of the following
attributes:
a. Reliability
b. Available bandwidth for concurrent communications
c. Installation cost
d. Load balance in routing responsibilities
16.10 How does using a dynamic routing strategy affect application behavior 
For what type of applications is it beneficial to use virtual routing
instead of dynamic routing 
16.11 The original HTTP protocol used TCP /IP as the underlying network
protocol. For each page, graphic, or applet, a separate TCP session was
constructed, used, and torn down. Because of the overhead of building
and destroying TCP liP connections, performance problems resulted
from this implementation method. Would using UDP rather than TCP
be a good alternative  What other changes could you make to improve
HTTP performance 
16.12 What are the advantages and disadvantages of using circuit switching 
For what kinds of applications is circuit switching a viable strategy 
16.13 In what ways is using a name server better than using static host tables 
What problems or complications are associated with name servers 
What methods could you use to decrease the amount of traffic name
servers generate to satisfy translation requests 
703
16.14 Of what use is an address-resolution protocol  Why is it better to use
such a protocol than to make each host read each packet to determine
that packet's destination  Does a token-passing network need such a
protocol  Explain your answer.
16.15 What is the difference between computation migration and process
migration  Which is easier to implement, and why 
16.16 Run the program shown in Figure 16.5 and determine the IP addresses
of the following host names:
www.wiley.com
www.cs.yale.edu
www.apple.com
www.westminstercollege.edu
www.ietf.org
16.17 To build a robust distributed system, you must know what kinds of
failures can occur.
a. List three possible types of failure in a distributed system.
b. Specify which of the entries in your list also are applicable to a
centralized system.
16.18 Explain why doubling the speed of the systems on an Ethernet segment
may result in decreased network performance. What changes could
help solve this problem 
16.19 Name servers are organized in a hierarchical manner. What is the
purpose of using a hierarchical organization 
16.20 Consider a distributed system with two sites, A and B. Consider
whether site A can distinguish among the following:
a. B goes down.
b. The link between A and B goes down.
c. B is extremely overloaded, and its response time is 100 times
longer than normal.
What implications does your answer have for recovery in distributed
systems 
Tanenbaum [2003], Stallings [2000a], and Kurose and Ross [2005] provide
general overviews of computer networks. Williams [2001] covers computer
networking from a computer-architecture viewpoint.
The Internet and its protocols are described in Comer [1999] and Comer
[2000]. Coverage of TCP /IP can be found in Stevens [1994] and Stevens [1995].
704 Chapter 16
UNIX network programming is described thoroughly in Stevens [1997] and
Stevens [1998].
Discussions concerning distributed operating-system structures have been
offered by Coulouris et al. [2001] and Tanenbaum and van Steen [2002].
Load balancing and load sharing are discussed by I-Iarchol-Balter and
Downey [1997] and Vee and I-Isu [2000]. I-Iarish and Owens [1999] describes
load-balancing DNS servers. Process migration is discussed by Jul et al. [1988],
Douglis and Ousterhout [1991], Han and Ghosh [1998], and Milojicic et al.
[2000]. Issues relating to a distributed virtual machine for distributed systems
are examined in Sirer et al. [1999].
17.1
In the previous chapter, we discussed network construction and the low-level
protocols needed to transfer between systems. Now we examine
one use of this infrastructure. A is a distributed
implementation of the classical time-sharing of a file system, where
multiple users share files and storage resources (Chapter 11). The purpose of
a DFS is to support the same kind of sharing when the files are physically
dispersed among the sites of a distributed system.
In this chapter, we describe how a DFS can be designed and implemented.
First, we discuss common concepts on which DFSs are based. Then, we illustrate
our concepts by examining one influential DFS-the Andrew file system (AFS).
To explain the naming mechanism that provides location transparency and
independence.
To describe the various methods for accessing distributed files.
To contrast stateful and stateless distributed file servers.
To show how replication of files on different machines in a distributed file
system is a useful redundancy for improving availability.
To introduce the Andrew file system (AFS) as an example of a distributed
file system.
As we noted in the preceding chapter, a distributed system is a collection
of loosely coupled computers interconnected by a communication network.
These computers can share physically dispersed files by using a distributed
file system (DFS). In this chapter, we use the term DFS to mean distributed file
systems in general, not the commercial Transarc DFS product; we refer to the
latter as Transarc DFS. Also, NFS refers to NFS Version 3, unless otherwise noted.
705
706 Chapter 17
To explain the structure of a DFS, we need to define the terms service, server,
and client. A is a software entity running on one or more machines
and providing a particular type of function to clients. A is the service
software running on a single machine. A is a process that can invoke
a service using a set of operations that form its Sometimes a
lower-level interface is defined for the actual cross-machine interaction; it is
the
Using this terminology, we say that a file system provides file services to
clients. A client interface for a file service is formed by a set of primitive file
operations, such as create a file, delete a file, read from a file, and write to a file.
The primary hardware concponent that a file server controls is a set of local
secondary-storage devices (usually, magnetic disks) on which files are stored
and from which they are retrieved according to the clients' requests.
A DFS is a file system whose clients, servers, and storage devices are
dispersed among the machines of a distributed system. Accordingly, service
activity has to be carried out across the network. Instead of a single centralized
data repository, the system frequently has multiple and independent storage
devices. As you will see, the concrete configuration and implementation of a
DFS may vary from system to system. In some configurations, servers run on
dedicated machines; in others, a machine can be both a server and a client. A DFS
can be implemented as part of a distributed operating system or, alternatively,
by a software layer whose task is to manage the communication between
conventional operating systems and file systems. The distinctive features of a
DFS are the multiplicity and autonomy of clients and servers in the system.
Ideally, a DFS should appear to its clients to be a conventional, centralized
file system. The multiplicity and dispersion of its servers and storage devices
should be made invisible. That is, the client interface of a DFS should not
distinguish between local and remote files. It is up to the DFS to locate the
files and to arrange for the transport of the data. A DFS facilitates
user mobility by bringing a user's environment (that is, home directory) to
wherever the user logs in.
The most important performance measure of a DFS is the amount of time
needed to satisfy service requests. In conventional systems, this time consists of
disk-access time and a small amount of CPU-processing time. In a DFS, however,
a remote access has the additional overhead attributed to the distributed
structure. This overhead includes the time to deliver the request to a server, as
well as the time to get the response across the network back to the client. For
each direction, in addition to the transfer of the information, there is the CPU
overhead of running the communication protocol software. The performance
of a DFS can be viewed as another dimension of the DFS's transparency. That is,
the performance of an ideal DFS would be comparable to that of a conventional
file system.
The fact that a DFS manages a set of dispersed storage devices is the DFS' s
key distinguishing feature. The overall storage space managed by a DFS is
composed of different and remotely located smaller storage spaces. Usually,
these constituent storage spaces correspond to sets of files. A cmnpm1.c:nt
is the smallest set of files that can be stored on a single machine, independently
from other units. All files belonging to the same component unit must reside
in the same location.
17.2
17.2 707
is a mapping between logical and physical objects. For instance,
users deal with logical data objects represented by file nances, whereas the
system manipulates physical blocks of data stored on disk tracks. Usually, a
user refers to a file by a textual name. The latter is mapped to a lower-level
numerical identifier that in turn is mapped to disk blocks. This multilevel
mapping provides users with an abstraction of a file that hides the details of
how and where on the disk the file is stored.
In a transparent DFS, a new dimension is added to the abstraction: that of
hiding where in the network the file is located. In a conventional file system, the
range of the naming mapping is an address within a disk. In a DFS, this range
is expanded to include the specific machine on whose disk the file is stored.
Going one step further with the concept of treating files as abstractions leads
to the possibility of Given a file name, the mapping returns a
set of the locations of this file's replicas. In this abstraction, both the existence
of multiple copies and their locations are hidden.
17.2.1 Naming Structures
We need to differentiate two related notions regarding name mappings in a
DFS:
. The name of a file does not reveal any hint of the
file's physical storage location.
'J'  ~'  '''.  ,  ' '-'  '  The name of a file does not need to be changed
when the file's physical storage location changes.
Both definitions relate to the level of naming discussed previously,
since files have different names at different levels (that is, user-level textual
names and system-level numerical identifiers). A location-independent naming
scheme is a dynamic mapping, since it can map the same file name to
different locations at two different times. Therefore, location independence is
a stronger property than is location transparency.
In practice, most of the current DFSs provide a static, location-transparent
mapping for user-level names. These systems, however, do not support
  that is, changing the location of a file automatically is impossible.
Hence, the notion of location independence is irrelevant for these systems.
Files are associated permanently with a specific set of disk blocks. Files and
disks can be moved between machines manually, but file migration implies an
automatic, operating-system-initiated action. Only AFS and a few experimental
file systems support location independence and file mobility. AFS supports file
mobility mainly for administrative purposes. A protocol provides migration
of AFS component units to satisfy high-level user requests, without changing
either the user-level names or the low-level names of the corresponding files.
A few aspects can further differentiate location independence and static
location transparency:
Divorce of data from location, as exhibited by location independence,
provides a better abstraction for files. A file name should denote the file's
708 Chapter 17
most significant attributes, which are its contents ratber than its location.
Location-independent files can be viewed as logical data containers that
are not attached to a specific storage location. If only static location
transparency is supported, the file name still denotes a specific, although
hidden, set of physical disk blocks.
Static location transparency provides users with a convenient way to share
data. Users can share remote files by simply naming the files in a locationtransparent
manner, as though the files were local. Nevertheless, sharing
the storage space is cumbersome, because logical names are still statically
attached to physical storage devices. Location independence promotes
sharing the storage space itself, as well as the data objects. When files can
be mobilized, the overall, system-wide storage space looks like a single
virtual resource. A possible benefit of such a view is the ability to balance
the utilization of disks across the system.
Location independence separates the naming hierarchy from the storagedevices
hierarchy and from the intercomputer structure. By contrast, if
static location transparency is used (although names are transparent),
we can easily expose the correspondence between component units and
machines. The machines are configured in a pattern similar to the naming
structure. This configuration may restrict the architecture of the system
um1.ecessarily and conflict with other considerations. A server in charge of
a root directory is an example of a structure that is dictated by the naming
hierarchy and contradicts decentralization guidelines.
Once the separation of name and location has been completed, clients
can access files residing on remote server systems. In fact, these clients may
be and rely on servers to provide all files, including the operatingsystem
kernel. Special protocols are needed for the boot sequence, however.
Consider the problem of getting the kernel to a diskless workstation. The
diskless workstation has no kernel, so it cam1.ot use the DFS code to retrieve
the kernel. Instead, a special boot protocol, stored in read-only memory (ROM)
on the client, is invoked. It enables networking and retrieves only one special
file (the kernel or boot code) from a fixed location. Once the kernel is copied
over the network and loaded, its DFS makes all the other operating-system files
available. The advantages of diskless clients are many, including lower cost
(because the client machines require no disks) and greater convenience (when
an operating-system upgrade occurs, only the server needs to be modified).
The disadvantages are the added complexity of the boot protocols and the
performance loss resulting from the use of a network rather than a local disk.
The current trend is for clients to use both local disks and remote file servers.
Operating systems and networking software are stored locally; file systems
containing user data-and possibly applications-are stored on remote file
systems. Some client systems may store commonly used applications, such as
word processors and Web browsers, on the local file system as well. Other, less
commonly used applications may be from the remote file server to the
client on demand. The main reason for providing clients with local file systems
rather than pure diskless systems is that disk drives are rapidly increasing in
capacity and decreasing in cost, with new generations appearing every year
or so. The same cannot be said for networks, which evolve every few years.
17.2 709
Overall, systems are growing more quickly than are networks, so extra work
is needed to limit network access to improve system throughput.
17.2.2 Naming Schemes
There are three main approaches to naming schemes in a DFS. In the simplest
approach, a file is identified by some combination of its host name and local
name, which guarantees a unique system-wide name. In Ibis, for instance,
a file is identified uniquely by the name host: local-name, where Local-name is a
UNIX-like path. This naming scheme is neither location transparent nor location
independent. Nevertheless, the same file operations can be used for both local
and remote files. The DFS is structured as a collection of isolated component
units, each of which is an entire conventional file system. In this first approach,
component 1-mits remain isolated, although means are provided to refer to a
remote file. We do not consider this scheme any further in this text.
The second approach was popularized by Sun's network file system, NFS.
NFS is the file-system component of ONC+, a networking package supported
by many UNIX vendors. NFS provides a means to attach remote directories
to local directories, thus giving the appearance of a coherent directory tree.
Early NFS versions allowed only previously mmmted remote directories to
be accessed transparently. With the advent of the feature, mounts
are done on demand, based on a table of mount points and file-structure
names. Components are integrated to support transparent sharing, although
this integration is limited and is not uniform, because each machine may attach
different remote directories to its tree. The resulting structure is versatile.
We can achieve total integration of the component file systems by using the
third approach. Here, a single global name structure spans all the files in the
system. Ideally, the composed file-system structure is the same as the structure
of a conventional file system. In practice, however, the many special files (for
example, UNIX device files and machine-specific binary directories) make this
goal difficult to attain.
To evaluate naming structures, we look at their
The most complex and most difficult-to-maintain structure is the NFS structure.
Because any rem.ote directory can be attached anywhere onto the local directory
tree, the resulting hierarchy can be highly m1structured. If a server becomes
unavailable, some arbitrary set of directories on different machines becomes
unavailable. In addition, a separate accreditation mechanism controls which
machine is allowed to attach which directory to its tree. Thus, a user might
be able to access a remote directory tree on one client but be denied access on
another client.
17.2.3 Implementation Techniques
Implementation of transparent naming requires a provision for the mapping
of a file naine to the associated location. To keep this mapping manageable,
we must aggregate sets of files into component units and provide the mapping
on a component-unit basis rather than on a single-file basis. This aggregation
serves administrative purposes as well. UNIX-like systems use the hierarchical
directory tree to provide name-to-location mapping and to aggregate files
recursively into directories.
710 Chapter 17
17.3
To enhance the availability of the crucial mapping information, we can use
replication, local caching, or both. As we noted, location independence means
that the mapping changes over time; hence, replicating the mapping makes
a simple yet consistent update of this information impossible. A teclllcique
to overcome this obstacle is to introduce low-level me
Textual file names are mapped to lower-level file identifiers that
indicate to which component unit the file belongs. These identifiers are still
location independent. They can be replicated and cached freely without being
invalidated by migration of component units. The inevitable price is the need
for a second level of mapping, which maps component units to locations and
needs a simple yet consistent update mechanism. Implementing UNIX-like
directory trees using these low-levet location-independent identifiers makes
the whole hierarchy invariant under component-unit migration. The only
aspect that does change is the component-unit location mapping.
A common way to implement low-level identifiers is to use structured
names. These names are bit strings that usually have two parts. The first
part identifies the component unit to which the file belongs; the second part
identifies the particular file within the unit. Variants with more parts are
possible. The invariant of structured names, however, is that individual parts
of the name are unique at all times only within the context of the rest of the
parts. We can obtain uniqueness at all times by taking care not to reuse a name
that is still in use, by adding sufficiently more bits (this method is used in AFS),
or by using a timestamp as one part of the name (as done in Apollo Domain).
Another way to view this process is that we are taking a location-transparent
system, such as Ibis, and adding another level of abstraction to produce a
location-independent naming scheme.
Aggregating files into component units and using lower-level locationindependent
file identifiers are techniques exemplified in AFS.
Consider a user who requests access to a remote file. The server storing the file
has been located by the nanling scheme, and now the actual data transfer must
take place.
One way to achieve this transfer is through a
whereby requests for accesses are delivered to the server, the server machine
performs the accesses, and their results are forwarded back to the user. One
of the most common ways of implementing remote service is the remote
procedure call (RPC) paradigm, which we discussed in Chapter 3. A direct
analogy exists between disk-access methods in conventional file systems and
the remote-service method in a DFS: using the remote-service method is
analogous to performing a disk access for each access request.
To ensure reasonable performance of a remote-service mechanism, we can
use a form of caching. In conventional file systems, the rationale for caching is
to reduce disk I/0 (thereby increasing performance), whereas in DFSs, the goal
is to reduce both network traffic and disk I/0. In the following discussion, we
describe the implementation of caching in a DFS and contrast it with the basic
remote-service paradigm.
17.3 711
17.3.1 Basic Caching Scheme
The concept of caching is simple. If the data needed to satisfy the access request
are not already cached, then a copy of those data is brought from the server to
the client system. Accesses are performed on the cached copy. The idea is to
retain recently accessed disk blocks in the cache, so that repeated accesses to the
same information can be handled locally, without additional network traffic.
A replacement policy (for example, the least-recently-used algorithm) keeps

the cache size bounded. No direct correspondence exists between accesses and
traffic to the server. Files are still identified with one master copy residing at the
server machine, but copies (or parts) of the file are scattered in different caches.
When a cached copy is modified, the changes need to be reflected on the master
copy to preserve the relevant consistency semantics. The problem of keeping
the cached copies consistent with the master file is the
which we discuss in Section 17.3.4. DFS caching could just as easily
be called , it acts sincilarly to demand-paged virtual
memory, except that the backing store usually is not a local disk but rather a
remote server. NFS allows the swap space to be mounted remotely, so it actually
can implement virtual memory over a network, notwithstanding the resulting
performance penalty.
The granularity of the cached data in a DFS can vary from blocks of a file to
an entire file. Usually, more data are cached than are needed to satisfy a single
access, so that many accesses can be served by the cached data. This procedure
is much like diskread-ahead (Section 11.6.2). AFS caches files in large chunks (64
KB). The other systems discussed in this chapter support caching of individual
blocks driven by client demand. Increasing the caching unit increases the hit
ratio, but it also increases the miss penalty, because each miss requires more
data to be transferred. It increases the potential for consistency problems as
well. Selecting the unit of caching involves considering parameters such as the
network transfer unit and the RPC protocol service unit (if an RPC protocol is
used). The network transfer unit (for Ethernet, a packet) is about 1.5 KB, so larger
units of cached data need to be disassembled for delivery and reassembled on
reception.
Block size and total cache size are obviously of importance for blockcaching
schemes. In UNIX-like systems, common block sizes are 4 KB and 8
KB. For large caches (over 1MB), large block sizes (over 8 KB) are beneficial. For
smaller caches, large block sizes are less beneficial because they result in fewer
blocks in the cache and a lower hit ratio.
17.3.2 Cache Location
Where should the cached data be stored-on disk or in main memory  Disk
caches have one clear advantage over main-memory caches: they are reliable.
Modifications to cached data are lost in a crash if the cache is kept in volatile
memory. Moreove1~ if the cached data are kept on disk, they are still there during
recovery, and there is no need to fetch them again. Main-memory caches have
several advantages of their own, however:
Main-memory caches permit workstations to be diskless.
Data can be accessed more quickly from a cache in main memory than
from one on a disk.
712 Chapter 17
Technology is moving toward larger and less expensive memory. The
resulting performance speedup is predicted to outweigh the advantages
of disk caches.
The server caches (used to speed up disk I/0) will be in main memory
regardless of where user caches are located; if we use main-memory caches
on the user machine, too, we can build a single caching nl.echanism for use
by both servers and users.
Many remote-access implementations can be thought of as hybrids of
caching and remote service. In NFS, for instance, the implementation is based on
remote service but is augmented with client- and server-side memory caching
for performance. Similarly Sprite's implementation is based on caching; but
under certain circumstances, a remote-service method is adopted. Thus, to
evaluate the two methods, we must evaluate the degree to which either method
is emphasized.
The NFS protocol and most implementations do not provide disk caching.
Recent Solaris implementations ofNFS (Solaris 2.6 and beyond) include a clientside
disk-caching option, the - file system. Once the NFS client reads
blocks of a file from the serve1~ it caches them in memory as well as on disk.
If the memory copy is flushed, or even if the system reboots, the disk cache
is referenced. If a needed block is neither in memory nor in the cachefs disk
cache, an RPC is sent to the server to retrieve the block, and the block is written
into the disk cache as well as stored in the memory cache for client use.
17.3.3 Cache-Update Policy
The policy used to write modified data blocks back to the server's master copy
has a critical effect on the performance and reliability. The simplest
policy is to write data to disk as soon as they are placed in any cache.
The advantage of a is reliability: little information is
lost when a client system crashes. However, this policy requires each write
access to wait until the information is sent to the server, so it causes poor write
performance. Caching with write-through is equivalent to using remote service
for write accesses and exploiting caching for read accesses.
An alternative is the also known as
where we delay updates to the master copy. Modifications are written
to the cache and then are written through to the server at a later time. This
policy has two advantages over write-through. First, because writes are made
to the cache, write accesses complete much more quickly. Second, data may
be overwritten before they are written back, in which case only the last update
needs to be written at all. Unfortunately, delayed-write schemes introduce
reliability problems, since unwritten data are lost whenever a user machine
crashes.
Variations of the delayed-write policy differ in when modified data blocks
are flushed to the server. One alternative is to flush a block when it is about to
be ejected from the client's cache. This option can result in good performance,
but some blocks can reside in the client's cache a long time before they are
written back to the server. A compromise between this alternative and the
write-through policy is to scan the cache at regular intervals and to flush
blocks that have been modified since the most recent scan, just as UNIX scans
17.3 713
NFS server
network workstation
Figure 17.1 Cachefs and its use of caching.
its local cache. Sprite uses this policy with a 30-second interval. NFS uses the
policy for file data, but once a write is issued to the server durilcg a cache
flush, the write must reach the server's disk before it is considered complete.
NFS treats meta data (directory data and file-attribute data) differently. Any
metadata changes are issued synchronously to the server. Thus, file-structure
loss and directory-structure corruption are avoided when a client or the server
crashes.
For NFS with cachefs, writes are also written to the local disk cache area
when they are written to the server, to keep all copies consistent. Thus, NFS
with cachefs improves performance over standard NFS on a read request with
a cachefs cache hit but decreases performance for read or write requests with
a cache miss. As with all caches, it is vital to have a high cache hit rate to
gain performance. Figure 17.1 shows how cachefs uses write-through and
write-back caching.
Yet another variation on delayed write is to write data back to the server
when the file is closed. This is used in AFS. In the case
of files that are open for short periods or are modified rarely, this policy
does not significantly reduce network traffic. In addition, the write-on-close
policy requires the closing process to delay while the file is written through,
which reduces the performance advantages of delayed writes. For files that are
open for long periods and are modified frequently, however, the performance
advantages of this policy over delayed write with more frequent flushing are
apparent.
17.3.4 Consistency
A client machine is faced with the problem of deciding whether a locally cached
copy of the data is consistent with the master copy (and hence can be used). If
714 Chapter 17
the client machine determines that its cached data are out of date, accesses can
no longer be served by those cached data. An up-to-date copy of the data needs
to be cached. There are two approaches to verifying the validity of cached data:
Client-initiated approach. The client initiates a validity check, in which it
contacts the server and checks whether the local data are consistent with
the master copy. The frequency of the validity checking is the crux of
this approach and determines the resulting consistency semantics. It can
range from a check before every access to a check only on first access to
a file (on file open, basically). Every access coupled with a validity check
is delayed, compared with an access served immediately by the cache.
Alternatively, checks can be initiated at fixed time intervals. Depending
on its frequency, the validity check can load both the network and the
server.
Server-initiated approach. The server records, for each client, the files
(or parts of files) that it caches. When the server detects a potential
inconsistency, it must react. A potential for inconsistency occurs when
two different clients in conflicting modes cache a file. If UNIX semantics
(Section 10.5.3) is implemented, we can resolve the potential inconsistency
by having the server play an active role. The server must be notified
whenever a file is opened, and the intended mode (read or write) must
be indicated for every open. The server can then act when it detects that
a file has been opened simultaneously in conflicting modes by disabling
caching for that particular file. Actually, disabling caching results in
switching to a remote-service mode of operation.
17.3.5 A Comparison of Caching and Remote Service
Essentially, the choice between caching and remote service trades off potentially
increased performance with decreased simplicity. We evaluate this
tradeoff by listing the advantages and disadvantages of the two methods:
When caching is used, the local cache can handle a substantial number
of the remote accesses efficiently. Capitalizing on locality in file-access
patterns makes caching even more attractive. Thus, most of the remote
accesses will be served as fast as will local ones. Moreover, servers are
contacted only occasionally, rather than for each access. Consequently,
server load and network traffic are reduced, and the potential for scalability
is enhanced. By contrast, when the remote-service method is used, every
remote access is handled across the network The penalty in network traffic,
server load, and performance is obvious.
Total network overhead is lower for transmitting big chunks of data (as
is done in caching) than for transmitting series of responses to specific
requests (as in the remote-service method). Furthermore, disk-access
routines on the server may be better optimized if it is known that requests
will always be for large, contiguous segments of data rather than for
random disk blocks.
The cache-consistency problem is the major drawback of caching. When
access patterns exhibit infrequent writes, caching is superior. However,
17.4
17.4 715
when writes are frequent, the mechanisms employed to overcome the
consistency problem incur substantial overhead in terms of performance,
network traffic, and server load.
So that caching will confer a benefit, execution should be carried out on
machines that have either local disks or large main memories. Remote
access on diskless, small-memory-capacity machines should be done
through the remote-service method.
In caching, since data are transferred en masse between the server and the
client, rather than in response to the specific needs of a file operation, the
lower-level intermachine interface is different from the upper-level user
interface. The remote-service paradigm, in contrast, is just an extension of
the local file-system interface across the network. Thus, the intermachine
interface mirrors the user interface.
There are two approaches for storing server-side information when a client
accesses remote files: either the server tracks each file being accessed by each
client, or it simply provides blocks as they are requested by the client without
knowledge of how those blocks are used. In the former case, the service
provided is stateful; in the latter case, it is stateless.
The typical scenario involving a is as follows: A client
must perform an open () operation on a file before accessing that file. The server
fetches information about the file from its disk, stores it in its memory, and gives
the client a connection identifier that is unique to the client and the open file.
(In UNIX terms, the server fetches the inode and gives the client a file descriptor,
which serves as an index to an in-core table of inodes.) This identifier is used for
subsequent accesses ru1.til the session ends. A stateful service is characterized
as a connection between the client and the server during a session. Either on
closing the file or through a garbage-collection mechanism, the server must
reclaim the main-memory space used by clients that are no longer active. The
key point regarding fault tolerance in a stateful service approach is that the
server keeps main-memory information about its clients. AFS is a stateful file
service.
A avoids state information by making each request
self-contained. That is, each request identifies the file and the position in the
file (for read and write accesses) in full. The server does not need to keep a
table of open files in main memory, although it usually does so for efficiency
reasons. Moreover, there is no need to establish and terminate a com1.ection
through open() and close() operations. They are totally redundant since
each file operation stands on its own and is not considered part of a session. A
client process would open a file, and that open would not result in the sending
of a remote message. Reads and writes would take place as remote messages
(or cache lookups). The final close by the client would again result in only a
local operation. NFS is a stateless file service.
The advantage of a stateful over a stateless service is increased performance.
File information is cached in main memory and can be accessed easily
via the connection identifier, thereby saving disk accesses. In addition, a stateful
716 Chapter 17
5
server knows whether a file is open for sequential access and can therefore
read ahead the next blocks. Stateless servers cmmot do so, since they have no
knowledge of the purpose of the client's requests.
The distinction between stateful and stateless service becomes more
evident when we consider the effects of a crash that occurs during a service
activity. A stateful server loses all its volatile state in a crash. Ensuring the
graceful recovery of such a server involves restoring this state, usually by a
recovery protocol based on a dialog with clients. Less graceful recovery requires
that the operations that were underway when the crash occurred be aborted.
A different problem is caused by client failures. The server needs to become
aware of such failures so that it can reclaim space allocated to record the state of
crashed client processes. This phenomenon is sometimes referred to as
A stateless computer server avoids these problems, silcce a newly reincarnated
server can respond to a self-contained request without any difficulty.
Therefore, the effects of server failures and recovery are almost unnoticeable.
There is no difference between a slow server and a recovering server from a
client's point of view. The client keeps retransmitting its request if it receives
no response.
The penalty for using the robust stateless service is longer request messages
and slower processing of requests, since there is no in-core i,_'lformation to speed
the processing. In addition, stateless service imposes additional constraints
on the design of the DFS. First, since each request identifies the target file, a
uniform, system-wide, low-level naming scheme should be used. Translating
remote to local names for each request would cause even slower processing
of the requests. Second, since clients retransmit requests for file operations,
these operations must be idempotent; that is, each operation must have the
same effect and return the same output if executed several times consecutively.
Self-contained read and write accesses are idempotent, as long as they use an
absolute byte count to indicate the position withilc the file they access and do
not rely on an incremental offset (as is done in UNIX read() and write()
system calls). However, we must be careful when implementing destructive
operations (such as deleting a file) to make them idempotent, too.
In some environments, a stateful service is a necessity. If the server employs
the server-initiated method for cache validation, it camcot provide stateless
service, since it maintains a record of which files are cached by which clients.
The way UNIX uses file descriptors and implicit offsets is inherently stateful.
Servers must mailctain tables to map the file descriptors to inodes and must
store the current offset within a file. This requirement is why NFS, which
employs a stateless service, does not use file descriptors and does include
an explicit offset in every access.
Replication of files on different machines in a distributed file system is a useful
redundancy for improving availability. Multimachine replication can benefit
performance too: selecting a nearby replica to serve an access request results
in shorter service time.
The basic requirement of a replication scheme is that different replicas of
the same file reside on failure-independent machines. That is, the availability
17.5 717
NFSV4
OurcoV,era.geofNFS thus .far has. 0p1y considered Version 3 (orV3)NF  .. The
mostrecentNPS standard is Version 4 (V 4), and it differs fundanrentalJy from
pr~vious versimi.s. Jhe most significant ch9nge is that the protocol is now
stqteful,meaping tha:tthesetv~er maintains the.state ofthe client session from
thE: time the r~J1lote file is 0pt::ned untiJ itis closed. Th.t1s, theNFS protocol now
provides open() ar;td c1o$e () operations; previous V:ersions of NFS (V\Thich
are stateless) .proyide .np such operations. Furthen))ore, preytous \Cersions
specify s~parate protocols.  or J :lounting remote fil~ systews and for lockii1g  
remote  files .. V4 provides ali of.. these features under   l phlgle prqtocol. In
patticular; the 1nrnmt. protocol was elimin  ;1.ted, allowing 1\[FS to work with
netWork fitewalls, The nJ.ount protocol was a notorimis security hole in NPS
implem,entations~ .   ..       . . . . .. .  
  .Additionally,  V4 has. enhan edthe ability of.dients Jo cache. file  data
local)y: This. featurE; i~prov~s tne performapc~ of the disttil:mt(3d file system,
a.s plients are   able to reso~ve more file a9cesses from the loc~l c~che rgther
thanh.  ;lVingto gpJhroughthe S~!:Ver. '(:4 ali()WS diel):tSJO req)c!estfile Jocks
from s~rvers as we'll. .If the, senr~r grqrct~. the request,. the client maintains
the loci   ,tmtil it. is released or its lea.st= expires.   (Clier~ts. ar,e als() permitted to
r~new. ex~stil'tg least=s,.) Traditiora11y1 UNIX~ba~~d:systems .provide advisory
Jile locking, whereas Windows operatirg systen1~ use mandat()rylockil1g  To
  alloV\T l'\[PS towm)   wellwithnon-UNIXsyste1fts, V4t1QW.p.rovides mandatory
locking as vvell. The new lockinga11d caching mec~anisms are based. on the
concept ()f d~legaHon, whe~ eby the server delegates responsibilities for a
 file's lockand contents. to .the client thatrequested tnel()ckcrhat delegated
client maintains  in cache. the .current version of .the file., and .. other  clients  can
   ... ask that. deleg21ted client for lock access, a1i.d filt= confentsuntifthe del:egated
client reli11quishesth~lock andde~egation. .   .  . .  . . . ..  . .. . ...
 . Finally, whereas.preyiousversionB ()f NPSarebasedon the UDJ network
ptqtocol, \[4 is based on .TCP,whioh allows itto betteraclj\lstto varying traffic
loads on. thel}etwork: peleg2lting these responsibilities. to cliel!cts reduces the
 foado11the s.eryet and.i~proves.cache.coherency.
of one replica is not affected by the availability of the rest of the replicas.
This obvious requirement implies that replication management is inherently
a location-opaque activity. Provisions for placing a replica on a particular
machine must be available.
It is desirable to hide the details of replication from users. Mapping a
replicated file name to a particular replica is the task of the naming scheme.
The existence of replicas should be invisible to higher levels. At lower
levels, however, the replicas must be distinguished from one another by
different lower-level names. Another transparency requirement is providing
replication control at higher levels. Replication control includes determination
of the degree of replication and of the placement of replicas. Under certain
circumstances, we may want to expose these details to users. Locus, for
instance, provides users and system administrators with mechanisms to control
the replication scheme.
718 Chapter 17
17.6
The main problem~ associated with replicas is updating. From a user's
point of view, replicas of a file denote the same logical entity, and thus an
update to any replica must be reflected on all other replicas. More precisely,
the relevant consistency sen1antics must be preserved when accesses to replicas
are viewed as virtual accesses to the replicas' logical files. If consistency is not
of primary incportance, it can be sacrificed for availability and performance. In
this fundamental tradeoff in the area of fault tolerance, the choice is between
preserving consistency at all costs, thereby creating a potential for indefinite
blocking, and sacrificing consistency under some (we hope, rare) circumstances
for the sake of guaranteed progress. Locus, for example, employs replication
extensively and sacrifices consistency in the case of network partition for the
sake of availability of files for read and write accesses.
Ibis uses a variation of the primary-copy approach. The domain of the
name mapping is a pair   primary-replica-identifier, local-replica-identifier  . If no
local replica exists, a special value is used. Thus, the mapping is relative to a
machine. If the local replica is the primary one, the pair contains two identical
identifiers. Ibis supports demand replication, an automatic replication-control
policy similar to whole-file caching. Under demand replication, reading of
a nonlocal replica causes it to be cached locally, thereby generating a new
nonprimary replica. Updates are performed only on the primary copy and
cause all other replicas to be invalidated through the sending of appropriate
messages. Atomic and serialized invalidation of all nonprimary replicas is not
guaranteed. Hence, a stale replica may be considered valid. To satisfy remote
write accesses, we migrate the primary copy to the requesting machine.
Andrew is a distributed computing environment designed and implemented
at Carnegie Mellon University. The Andrew file system (AFS) constitutes the
underlying information-sharing mechanism among clients of the environment.
The Transarc Corporation took over development of AFS and then was purchased
by IBM. IBM has since produced several commercial implementations
of AFS. AFS was subsequently chosen as the DFS for an industry coalition; the
result was part of the distributed computing environment (DCE)
from the OSF organization.
In 2000, IBM's Transarc Lab announced that AFS would be an open-source
product (termed OpenAFS) available under the IBM public license, and Transarc
DFS was canceled as a commercial product. OpenAFS is available under most
commercial versions of UNIX as well as Linux and Microsoft Windows systems.
Many UNIX vendors, as well as Microsoft, support the DCE system and its DFS,
which is based on AFS, and work is ongoing to make DCE a cross-platform,
universally accepted DFS. As AFS and Transarc DFS are very similar~ we describe
AFS throughout this section, unless Transarc DFS is named specifically.
AFS seeks to solve many of the problems of the simpler DFSs, such as
NFS, and is arguably the most feature-rich nonexperimental DFS. It features
a uniform name space, location-independent file sharing, client-side caching
with cache consistency, and secure authentication via Kerberos. It also includes
server-side caching in the form of replicas, with high availability through
automatic switchover to a replica if the source server is unavailable. One of the
17.6 719
most formidable attributes of AFS is scalability: the Andrew system is targeted
to span over 5,000 workstations. Between AFS and Transarc DFS, there are
hundreds of implementations worldwide.
17.6.1 Overview
AFS distinguishes between client machines (sometimes referred to as workstations)
and dedicated server machines. Servers and clients originally ran only 4.2
BSD UNIX, but AFS has been ported to many operating systems. The clients and
servers are interconnected by a network of LANs or WANs.
Clients are presented with a partitioned space of file names: a
and a Dedicated servers, collectively called Vice
after the name of the software they run, present the shared name space to the
clhe local name space is the root file system of a workstation, from which
the shared name space descends. Workstations run the Virtue protocol to
communicate with Vice, and each is required to have a local disk where it
stores its local name space. Servers collectively are responsible for the storage
and management of the shared name space. The local name space is small,
is distinct for each workstation, and contains system programs essential for
autonomous operation and better performance. Also local are temporary files
and files that the workstation owner, for privacy reasons, explicitly wants to
store locally.
Viewed at a finer granularity, clients and servers are structured in clusters
interconnected by a WAN. Each cluster consists of a collection of workstations
on a LAN and a representative of Vice called a and each cluster
is com1.ected to the WAN by a router. The decomposition into clusters is
done primarily to address the problem of scale. For optimal performance,
workstations should use the server on their own cluster most of the time,
thereby making cross-cluster file references relatively infrequent.
The file-system architecture is also based on considerations of scale. The
basic heuristic is to offload work from the servers to the clients, in light
of experience indicating that server CPU speed is the system's bottleneck
Following this heuristic, the key mechanism for remote file operations is to
cache files in large chunks (64 KB). This feature reduces file-open latency and
allows reads and writes to be directed to the cached copy without frequently
involving the servers.
Briefly, here are a few additional issues in the design of AFS:
Client mobility. Clients are able to access any file in the shared name
space from any workstation. A client may notice some initial performance
degradation due to the caching of files when accessil  g files a
workstation other than the usual one.
Security. The Vice interface is considered the boundary of trustworthiness,
because no client programs are executed on Vice machines. Authentication
and secure-transmission functions are provided as part of a connectionbased
communication package based on the RPC paradigm. After mutual
authentication, a Vice server and a client communicate via encrypted
messages. Encryption is performed by hardware devices or (more slowly)
720 Chapter 17
in software. Information about clients and groups is stored in a protection
database replicated at each server.
Protection. AFS provides for protecting directories and the
regular UNlXbits for file protection. The access list ncay contain information
about those  users allowed to access a directory, as well as information
about those users not allowed to access it. Thus, it is simple to specify that
everyone except, say, Jim can access a directory. AFS supports the access
types read, write, lookup, insert, administer, lock, and delete.
Heterogeneity. Defining a clear interface to Vice is a key for integration of
diverse workstation hardware and operating systems. So that heterogeneity
is facilitated, some files in the local /bin directory are symbolic links
pointing to machine-specific executable files residing in Vice.
17.6.2 The Shared Name Space
AFS's shared name space is made up of component units called The
volumes are unusually small component units. Typically, they are associated
with the files of a single client. Few volumes reside within a single disk
partition, and they may grow (up to a quota) and shrink in size. Conceptually,
volumes are glued together by a mechanism similar to the UNIX m01mt
mechanism. However, the granularity difference is significant, since in UNIX
only an entire disk partition (containing a file system) can be mounted. Volumes
are a key administrative unit and play a vital role in identifying and locating
an individual file.
A Vice file or directory is identified by a low-level identifier called a fid.
Each AFS directory entry maps a path-name component to a fid. A fid is 96 bits
long and has three equal-length components: a volume number, a vnode number,
and a uniquifier. The vnode number is used as an index into an array containing
the inodes of files in a single volume. The allows reuse of vnode
numbers, thereby keeping certain data structures compact. Fids are location
transparent; therefore, file movements from server to server do not invalidate
cached directory contents.
Location information is kept on a volume basis in a
replicated on each server. A client can identify the location of every
volume in the system by querying this database. The aggregation of files into
volumes makes it possible to keep the location database at a manageable size.
To balance the available disk space and utilization of servers, volumes
need to be migrated among disk partitions and servers. When a volume is
shipped to its new location, its original server is left with temporary forwarding
information, so that the location database need not be updated synchronously.
While the volume is being transferred, the original server can still handle
updates, which are shipped later to the new server. At some point, the volume
is briefly disabled so that the recent modifications can be processed; then, the
new volume becomes available again at the new site. The volume-movement
operation is atomic; if either server crashes, the operation is aborted.
Read-only replication at the granularity of an entire volume is supported
for system-executable files and for seldom-updated files in the upper levels
of the Vice name space. The volume-location database specifies the server
17.6 721
contammg the only read-write copy of a volume and a list of read-only
replication sites.
17.6.3 File Operations and Consistency Semantics
The fundamental architectural principle in AFS is the caching of entire files
from servers. Accordingly, a client workstation interacts with Vice servers
only during opening and closing of files, and even this interaction is not
always necessary. Reading and writing files do not cause remote interaction (in
contrast to the remote-service n  lethod). This key distinction has far-reaching
ramifications for performance, as well as for semantics of file operations.
The operating system on each workstation intercepts file-system calls and
forwards them to a client-level process on that workstation. This process, called
Venus, caches files from Vice when they are opened and stores modified copies
of files back on the servers from which they came when they are closed. Venus
may contact Vice only when a file is opened or closed; reading and writing of
individual bytes of a file are performed directly on the cached copy and bypass
Venus. As a result, writes at some sites are not visible immediately at other
sites.
Caching is further exploited for future opens of the cached file. Venus
assumes that cached entries (files or directories) are valid unless notified
otherwise. Therefore, Venus does not need to contact Vice on a file open to
validate the cached copy. The mechanism to support this policy, called callback,
dramatically reduces the number of cache-validation requests received by
servers. It works as follows. When a client caches a file or a directory, the
server updates its state information to record this caching. We say that the
client has a callback on that file. The server notifies the client before allowing
another client to modify the file. In such a case, we say that the server removes
the callback on the file for the former client. A client can use a cached file for
open purposes only when the file has a callback If a client closes a file after
modifying it, all other clients caching this file lose their callbacks. Therefore,
when these clients open the file later, they have to get the new version from
the server.
Readin.g and writing bytes of a file are done directly by the kernel without
Venus's intervention on the cached copy. Venus regains control when the file is
closed. If the file has been modified locally, it updates the file on the appropriate
server. Thus, the only occasions on which Venus contacts Vice servers are on
opens of files that either are not in the cache or have had their callback revoked
and on closes of locally modified files.
Basically, AFS implements session semantics. The only exceptions are
file operations other than the primitive read and write (such as protection
changes at the directory level), which are visible everywhere on the network
immediately after the operation completes.
In spite of the callback mechanism, a small amount of cached validation
traffic is still present, usually to replace callbacks lost because of machine or
network failures. When a workstation is rebooted, Venus considers all cached
files and directories suspect, and it generates a cache-validation request for the
first use of each such entry.
The callback mechanism forces each server to maintain callback information
and each client to maintain validity information. If the amount of callback
