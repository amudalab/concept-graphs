Introduction to Probability theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 1
Basic Principles of Counting

(Refer Slide Time: 00:14)
 
So, we will be talking about the course on probability theory and its applications. Somehow, when you utter the word probability to a layman, it does not sound very familiar or you know, one does not feel very comfortable with it. But my attempt in this course would be, that at the end of the course you feel, that you can understand what all goes behind computing the probability of an event.
So, basically probability theory is estimating the possibility of outcome of an event. So, this word possibility, that what are the, how possible, how probable the event is, is actually done by counting. And so therefore, before I start giving you axioms of probability theory, I would like to begin with the basic concepts of counting because that helps you in estimating the possibility of the occurrence of an event and I will try to explain what we mean by an event and so on. So, as we go on, hopefully, that you will understand all these terms.
So, let me just begin by, so therefore, the first topic I am going to talk about is counting and I will start with an example. So, suppose there is a small community, which consists of 12 women and each of whom has 2 children. Now, if one women and one of her children, so it has to be the pair, a women and her child. So, if the pair has to be chosen as mother and child of the year, how many different choices are possible? So, let us just, very simple way of counting.
So, what I am saying here is, that first experiment would be number of possibilities of the, first experiment would be choosing the mother. Out of the 12 women, we choose one of the woman as the mother of the year. And so the number of possible outcomes is 12 because there are 12 women and one of them will be appointed or chosen as the woman of the year.
And then we will, so second experiment would be selecting one of her children as the year as the child of the year. So, once you have chosen the mother of the year, then she has 2 children. So, only one of them can qualify to be the year of the child, I mean, child of the year. So, therefore, the possible outcomes are 2. So, then we say, that the total number of choices is 24.
So, I sort of broke up this event, though I will call it event of choosing the mother and child of the year by first saying that I will chose the mother, and then one of her children would be chosen as the year, child of the year, right. So, therefore, the number of choices are 24, right.
(Refer Slide Time: 03:17)
 
So, if, if now I want to sort of formulate this into the basic principle of counting, then the basic principle says that if there are two experiments to be performed and experiment 1 results in any one of impossible outcomes. So, I have way of finding out, that whatever my first experiment and the possible outcomes of that event are m.
So, for example, here my first experiment was choosing the year, mother of the year and since there are 12 woman, out of which I have to choose the mother of the year. So, there were 12 possible outcomes of this experiment. Any of the 12 women could have been chosen as the mother of the year. So, the first experiment results in m possible outcomes. Now, for each outcome of experiment 1 that means, for each possible outcome, each of the m possible outcomes here then I want to know what are the possible outcomes of the second experiment?
So, in that example mother had 2 children. So, it could only be one of the 2 children who would be chosen as the mother of the year. So, now here we will say, that if for each outcome of experiment 1, there are n possible outcomes of experiment 2, then together there are mn possible outcomes of the 2 experiments, right.
So, I hope this, once you understand this basic principle, of computing, of counting, then you know, things become simple because you have to first, first find out what are the possible outcomes. And then we will talk about, when we define the concept of an event, then we will try to find out in how many ways that particular event can occur. So, here the total number of this thing are this.
Now, if you want to generalize this concept of counting, so this will be generalized basic principle of counting. And here, we will now say, that suppose I have r experiments, which could be 1, 2, 3 and whatever the number and then again we will start saying first one, the first experiment results in n 1 possible outcomes. So, the first experiment results in n 1 possible outcomes. Now, for each possible n 1 outcomes of the first experiment, right, for each possible n 1 outcome of the first experiment there are n 2 possible outcomes of the second experiment, right. And then the third stage we will then count for each possible outcomes of the first two experiments, right, because two experiments have taken place.
So, for each possible outcome of the first and the second, that means, now you have n 1 possible outcomes of the first experiment, n 2 for each of the experiment outcome here, you have n 2 possible outcomes. So, total number of outcomes become n 1 n 2. Now, for each possible outcome of n 1 and n 2, the third experiment, if possible, outcomes will be n 3 and so on. So, you will go on counting this and therefore, by a simple arithmetic you can see, that the total number of possible outcomes would be n 1 into n 2 into n r. That means, at each, for each experiment whatever the possible outcomes, you will multiply them all. So, this gives the generalized principle of computing.
(Refer Slide Time: 06:25)
 
So, let us look up at this example, example 1.2. How many 8 place license plates are possible if first four places are to be occupied by letters and last four by numbers? That means, the first four can be any of the alphabet A, B, C, D. So, there were 26 choices for the first, for first four places and then for last four have to be the numbers. So, which means, there can be any of the digits 0, 1, 2, up to 9, right.
So, now again, as I quoted the generalized principle of counting, so number of the first experiment would be choosing the first place of the license plate, right. So, then I have 26 choices because 26 alphabets are there. Then, again, for each of the alphabet I choose here, for each of the 26 alphabets I choose here, I can again choose the 26 alphabets again, right. If I have a letter A here, for example, then I can choose any of the A, B, C, D, 26 alphabets here. So, again the next outcome, that means, the outcome for each outcome here, there are again 26 choices of the second experiment and so on. So, again for the third.
That means, now once have chosen the first 2 alphabets here, then again for any each of these outcomes, 26 into 26, I can again choose in the third place any of the 26 alphabets. So, then the third choice is again the number of possible outcomes are the number of choice, choices are 26. And same, the same argument goes for the fourth place.
And similarly, for the numbers I have chosen 1 of the 10 numbers here. Then, again after having chosen all these, I can again choose any of the ten numbers here and then in the third place also any of the ten numbers and so on.
So, this will be and you can just see, I have left a question mark for you to compute the number it will be a big number. So, this many license plates can be there if you have this kind of arrangement that the first four places have to be occupied. So, it is eight letter license plate number and so the first four places have to be occupied by alphabets and the last four by digits, right.
Now, if I change the experiment and I say, that repetition of letters and numbers is not permitted. So, the moment I say that once I have chosen a letter here, then the same letter will not be repeated here, here or here. So, then by a way of counting will be this. Now, for the first place I have any of the 26 choices, any of the 26 letters can be chosen here. But once I have chosen a letter here, then that same letter is not permitted to be chosen here. So, now, my choice at for the second experiment for every possible outcome here, goes down to 25 because whatever alphabet I have chosen here, I cannot chose it again. So, therefore, my choices here are 25.
And once I have chosen alphabet for the first place and the second place 2 alphabets have been selected, then both these are not allowed to be chosen again. So, therefore, my choice for the third place would come down to 24. So, out of 26, two letters have been already chosen and they are not allowed to be chosen again. So, this would, choice will be 24. And then similarly at the fourth place I will be having a choice of 23. So, if you just keep using this generalized principle of counting, which I enumerated sometime ago, then you see, this is how you will, right, done the possible outcomes.
And similarly, for the numbers, for the first place I will have choice of 10, but once I choose a number here, then my choice is limited to 9, and after this again I can only choose out of the 8, which are not repeated, which have not been already be chosen. And similarly, for the fourth place my choice will be left limited to 7 numbers, which have not been repeated. So, this is the kind of…
So, the generalized principle of counting helps you to come out with the possible number of outcomes of an experiment, right, or event here. What we want to say, because this was, as I am counting, I am saying this is eight experiments choice of each letter for each place of the license plate and the choice of number I counted as experiment. So, had eight experiments here and used the generalized principle of counting to find out the possible number of outcomes right.
(Refer Slide Time: 11:00)
 
Now, another possible another way of counting is done by through permutations and combinations, and let me now here try to explain the difference between permutations and combinations.
So, here let us say, we have collection of 3 novels. And so I will just say, that authors are A, B and C, then 2 mathematic books and again I will distinguish them or differentiate them by the authors and call the authors as D and E and one physics book. Now, I will call the author as P. So, there are 6 books. And since I am distinguishing books by the authors, so it is not just novels, I am saying, that the, I mean the authors are A, B and C. So, they are different novels I am distinguishing. Similarly, I am differentiating between the 2 mathematics novels and of course, there is one physics book. So, the question is how many arrangements are possible if the books are to be distinguished by the authors.
So, I am, I am wanting to make arrangements of these books and arrangements would be, would be differentiated because the, I will be, I will be referring to the books by the authors. So, it is not just novels or a mathematics book. So, therefore, possible arrangements, now here again let us just say that we are, yeah, ok, right. So, here that means, in the first place if we now count the thing, that means, I can, I can say, that there are 6 places, right.
So, now, the choice for the first place, that means, I am just arranging the books like this in a line, in a row, suppose. So, the choice for the first place would be any one of the 6 books, right, because I am differentiating the books by the author. So, therefore, for the first place the choice is 6 books. Once a book is placed here, then there will be 5 more left, right. I am saying again. So, therefore, out of the 6 experiments I am just saying what are the possible outcomes. So, once I have chosen 2 books here, then I am, I am left with picking out the book for the 3rd place from among the remaining 4 books and then 3, 2 and 1. So, the total number is 6 factorial, which is 720, right.
Now, these 720 arrangements are known as permutations of the 6 books. And the permutation word is essentially saying, that the permutations are the ordered arrangements of the books. Now, ordered, I mean, that if I am writing, say for example, ordered arrangement, I want to say ordered arrangements. So, if I am writing here, say it could be, that I am, right, I have chosen all the 3 novels here, right and then of course, let us say, mathematics books you have D and E.
So, it may be, you have this and you, right now if I have the order B arrangement, B A C E D P, then you see this arrangement is different from this. Because now here is the 2nd author, if we call the book by B as 2nd novel, then the 2nd novel is occupying the 1st place and this is 1st, the novel by the 1st author is occupying the 2nd place. So, here the arrangement and therefore, this, this order is also considered here in this arrangements and therefore, I will say, that this is different from this order, this arrangement is different from this order, that arrangement B A C E D P.
So, this is the idea, that 720 permutations are the ordered arrangements of the 6 books. And so how you place them depends on, that means, I am distinguishing between which author is occupying the 1st place, which author is occupying the 2nd place and so on. So, therefore, this way it will be 720. But if you do not distinguish between the, if you do not distinguish between the authors, that means, I just treat the 3 novels as novels and in that case, this and this arrangements would be the same, and right. And in fact, you can see how many possible arrangements.
See, I can have here C A B E D P. Now, you can tell me 3 more because these 3 letters, A, B, C themselves, I can arrange in 3 factorial ways, that will be 6, 6 ways I can arrange these 3. And therefore, all those arrangements, once if I do not consider the, I distinguish, do not distinguish between the 3 novels by the authors, as long as they are just novels, then that arrangements, all those 6 arrangements will be counted as 1 arrangement.
(Refer Slide Time: 16:08)
 
So, when we are looking at the arrangement of the books, the novels, 3 novels, 2 maths books and 1 physics book. So, once we do not order, we do not worry about differentiating the books with respect to the authors. In that case, you see, as I tried to show you, that the 3 novels, since they will not be distinguished by the authors, so then for every arrangement, for every arrangement in which only the arrangement of the, arrangement of the author has been changed, the other books remain the same. In that case, 6 of those arrangements will amount to 1 arrangement because the 3 novels can be arranged in 6 different ways.
And if I leave the math books and the physics book intact, then all 6 arrangements in which only the arrangement of the novels have been changed, then those 6 arrangements will amount to 1 arrangement. And similarly, corresponding to each of those, if I leave everything intact and only disturb the arrangement of the math books, then since I am not differentiating between the author, those arrangements will not be different because that 2 math books, whether the author D or E, whichever comes first does not matter to me. So, in that case, I will then divide.
So, that means, when I am counting the arrangement where the order is not important and that comes out to be 6 factorial is, was the arrangement, total number of arrangements where the order was important. But if I do not care about the order, that I mean, I do not distinguish between the authors, in that case the arrangements will become 60. So, this is what now I am trying to come to. So, the permutations, the order was important. And then I had total number of permutations. That means, that the order of the objects was also being considered right.
So, now, the general principle, that I am trying to ((Refer Time: 18:08)) that in general, number of arrangements of n objects, where n 1 are alike, n 2 are alike, and n are alike, n r are alike, that means, there are only r different kinds of objects. And since, so therefore, surely here n 1 plus n 2 plus n r adds up to n, right. So, have n objects. But n 1 of them are the same, then n 2 are alike and similarly, n r of them are alike. And in that case, when I am wanting to make, arrange the n objects, then the total number of objects would be, because n factorial would be the arrangements of n objects when I am distinguishing between each of them, right, whatever the way of distinguishing the object, whatever it is. So, that would the total arrangement.
But since I had tried to show you through this example of arranging the books, that if n 1 are alike, then those n 1 can be arranged in n 1 factorial ways and they will amount to the same arrangement because I am not differentiating between the order. So, therefore, I will divide this total number of arrangements here by n 1 factorial, n 2 factorial and n r factorial. So, that will give me the total number of, so that becomes the number of combinations. Well, that means, arrangements where the order is not important would be the number of, total number of combinations.
Now, let us look at this example. So, a tennis tournament has nine competitors, competitors. So, and then 3 from India, 2 from Japan and 4 from Malaysia. Now, if the results of the tournament are announced by nationalities of the players in the order in which they are placed. So, it is not, you know, you are not distinguishing the place by the names, only their nationality is being considered. In that case, 3 from India would be just 3 Indians and it does not matter which one gets the first position, third position or whatever it is. So, here it will be just all the 3 players would be considered the players from India.
So, another way of looking at it is, that you can think of these people as one entity because they, they are just representing the same country. So, similarly 2 from Japan would be just distinguished by their nationality and not by their names and 4 from Malaysia.
(Refer Slide Time: 20:54)
 
So, therefore, if you want to now find out how many such lists are possible, that means, what, what is the arrangement of the position, that these 3, the players from the 3 nationalities occupying in your list, first, second, third, up to there will be 9 positions. So, then the total number of lists, that you can have would be 9 factorial. So, 9 is the total number of players. And if I was going to distinguish them by the names, in that case, they would have been 9 factorial arrangements of the way in which the order, in which players would occupy position in the tournament. But since we are not considering the names, we are only considering the nationalities.
So, for example, we then divide this number by 3 factorial, 4 factorial and 2 factorial to get the total number of lists. So, the 3 Indians can occupy any of the positions and they will be the same. So, that means your 6, 6 lists in which if 3 Indians were occupying different positions in the sense, that I just arrange, rearrange the position, that are that means, 3 Indians, if they just appear. See, suppose you consider the 1st position, 2nd, 3rd, 4th, 5th, 6th, 7th, 8th, 9th, same thing. So, if this was Indian, this is an Indian and let us say, this is an Indian, right.
Now, what are the 3 names? If I see, if you had a name, here is the Indian 1, Indian 2 and Indian 3. Then, I can have Indian 2 here, Indian 1 here, Indian 3 here and this way you can go on, right. Indian 2, Indian 3, Indian 1 and just see, that you can write, you can rearrange these 3 in 6 possible ways. So, other arrangements will be the same.
But if these 3, I can arrange in 6 different ways, but for me they are the same because in my list it will appear as I, I, I, I, I, I. So, this will not be there, right. So, all these arrangements will be the same and so all these 6 arrangements will account to same. Therefore, I am dividing this number by 3 factorial and similarly, for the 2 from, I mean, sorry, here, in this case here, that was the example for the books. So, here I am dividing this number by 3 factorial, 4 factorial and 2 factorial to get the possible number of lists. So, just trying to make the concept of counting clear, so that you can, then you know, when you have to compute the possibility of the occurrence of an event, all these things will come in handy.
So, now again, I am trying to enunciate this principle, that if you have a collection of n objects, in how many ways can we select r objects. That is again the same thing because you can say, that you can put the n objects in a row and then you are picking up r out of them. So, that, that is the different arrangement. This is another way of saying the same thing, right.
So, here, by your principle of counting, when you have, you can say, that you have arranged all these n objects in a row and then you are picking of one of them. So, then for the first place, that means, when I want to pickup r objects from this list of n objects, the first object, there are n possible ways of selecting the first. So, we are counting the same thing again by a different way. So, here you have n ways of selecting the first object. Then, since you have already selected the first object, you are left with now n minus 1 ways of selecting the second object, right. And similarly, it goes on depleting. And finally, for the rth object that you want to choose, you are left with n minus r plus 1 because you have already selected r minus 1 objects. So, n minus r minus 1, this is the number. So, this many ways you can select the rth object, right.
Now, since it does not matter again because I am not distinguishing between the r objects, that means, the order is not important once. You see, out of these n objects I have collected r objects. So, it does not matter which one came out first, which one came out second, as long as the set of objects is the same. So, that means, my way of selecting may have been, you know, because I picked, when I picked up the 1st object, that counted in the 1st object, 2nd and 3rd, so on. But then finally, what I have with me is the set of r objects and it, though in, in that set the 3rd or the 4th object could have been selected 1st, does not matter, right. So, therefore, what we are saying is, now you have n minus r plus 1. So, that means, the total number I should have written the number here, let me write somewhere here.
So, the order is, when the order is immaterial, I am saying, that this is, let me, let me just write it here. So, that means, what I am saying is, that the first object I could pick in any of the n ways. Then, for the second object to pickup I had only n minus 1 choices available with me and so on, up to n minus r plus 1, right. So, this number. And since what we are saying is, that the, it was not important the order in which the r objects were selected, it is only the final subset of r objects, that I have with me. So, therefore, I will divide this by r factorial and so you can, right.
This number, you see, if you have up to this, this number, you can write as n factorial divided by r factorial n minus r factorial. So, this is the final. So, that means, this is the number of combinations I can have, because by selecting r objects I can call an arrangement, that was here. That means, the n objects that I have, I pick up r, I put them first and then the remaining n minus r. So, essentially the r objects, that you pick, it does not matter in what order you pick.
So, therefore, the total number of ways in which I can arrange my n objects gets divided by r factorial and obviously, the last n minus r objects also. The order is not important because finally, you have divided these n objects into r n n minus r, right. So, it is simply, which r objects get selected, it does not matter in what order they got selected. So, therefore, the total of number of ways in which you can pickup r objects from n objects would again be given by this number and I would, normally we say n choose r. This is the notation for this number n factorial divided by r factorial n minus r factorial. So, this is n choose r.
(Refer Slide Time: 27:36)
 
So, again let us take up an example. So, a jury of 7 is to be formed from a group of 30 people, how many different juries can be formed? So, just carry over what we discussed just know. So, there are 30 people and you have to pick up 7 people from this set of 30 people, which will form a jury, right. And so we want to know how many, the question is how many different juries can be formed. So, this is like we discussed, n objects, you want to pickup r objects from there and how many ways are there, how many possible combinations are there, that is what we are looking at. So, obviously, you can see, that the number of juries would be.
So, first, first person in the set can be chosen out of the 30 people. Then, once you have chosen that person, you are left with 29 choices and again, after these two you are left with 28 and so this number is 24. And now, what we are saying, that it was, it was not at all important as to when we have selected the 7 people. Since it is the subset of 7 people, it does not matter which one of them got selected first. So, the order is not important. It is only, that finally I have this subset of 7 people. So, therefore, 7 we will have to divide by 7 factorial to get the possible number of juries because this 7 set of people that you are forming the jury, you are not looking at when the first, when the, in what order they got selected, that is not important, right. That is what I am emphasizing again and again, that here the order of selection is not important, it is just that you want a subset of 7 people and therefore, this will be the total number of arrangements.
And so here with this number we can write, because this is up to 24. Remember, this is n minus r plus 1. So, here your n is 30 and your r is 7. So, when you want to divide, from 36 you are left with 24 and so this is the total number if it was important as to in what order people got selected for the jury. So, it is not important, it is not being considered, it is immaterial. So, therefore, I divide the 7 factorial, then this number can be written as 30 factorial divided by 7 factorial into 23 factorial, which by our notation is 30 chose of 7.
Now, in case the group of 30 consists of 10 women and 20 men and if it is required, and if it is required that 2 women and 5 men should form the jury. So, now, we are saying, that out of 10 women 2 must get selected and out of the 20 men 5 men should get selected to form the jury. So, in that case the number of groups of women that you can form out of, you know, by choosing 2 out of 10, this will be 10 chose 2. Here, again the order is not important. I just want to form, select subset of 2 people, 2 women from out of the 10. So, that will be the total number of ways in which I can select the 2 women from the 10 women.
And similarly, I can, 20 choose 5 is the number of ways in which I can select 5 men from the set of 20 men. And so the total number would be, because for each subset, that I chose here of women, there will be this many. So, I am now using here by generalize principle of counting. And so the total number of ways in which I can, the number of juries of 2 women and 5 men can be formed is this. So, just through examples I am trying to make the concept clear.
(Refer Slide Time: 31:23)
 
And now, let us see, that you can, all of you have used binomial theorem and you know, that if you want to express, if you want to expand this number x plus y raise to n, then the formula is n choose k x raise to k y raise to n minus k, and you have done it by induction and so on, the proof. Now, let me give you this combinatorial proof of binomial theorem using this concept of counting, that we have learnt here. We can use this and show, that the expansion of this term can be written in this way.
And so let me consider the product x 1 plus y 1 into x 2 plus... So, there are n terms here, right. Now, when I am multiplying each term here, final in the product would be consisting of n factors, factor of n of the x i’s and y j’s, that means, each term of this, project, product will contain, when you count the number of x i’s and y j’s, that total number would be n because you have n factors, right. But certainly, in any factor when you look at the x i’s and y j’s, if the, if an x i appears, then in the same index will not be for y because you see, x 1 and y 1 are in the same term here. So, therefore, when I multiply, either I will be multiplying x 1 by the other terms and so then y 1 will not appear in that, right.
So, therefore, in any product, the x i’s and y j’s that you have, if an x i appears, the corresponding y j will not appear in that product, right. So, in other words what I am saying is that the any term of this product, which will contain, let us say, k of the x i’s and then the remaining n i n minus k of the y j’s would be such that. So, you are choosing, essentially, each term here would contain, let us say, when I am looking at the term containing only k of the x i’s and so remaining n minus k or y j’s. So, then how many ways can be there? How many such products can be there in which...
So, you know this is containing the each term in this product has n factors containing x i’s and y j’s. So, then if I am looking at all the terms, which contain k of the x i’s, right, then that means, I am out of the x 1, x 2, x n, these n x’s I am choosing k of the x i’s, right. And then of course, the moment I choose my k x i’s, then the y j’s got to the n minus k y. y k’s, y j’s got, get select automatically because in the ones, which are not appearing in my x 1, x 2, the product x i’s that I have now taken, now remaining indices will be, will go to the y j’s right. So, here, that means, and that was the way of choosing k x i's out of the n x i’s x 1 x 2 x n in n choose k, right.
So, therefore, the number of terms, which contain k of the x i’s is this many terms. And so this whole product, either what will happen, say for example, if you look at it, product y 1 y 2 y n, no x i appears. So, either, so the k can vary from 0 to n. The terms will contain either 0 x i’s, then 1 x i, 2 x i’s and so on. So, you want to add up all such things. You are counting the total number of terms in this product and that total number will be given by summing up n choose k from 0 to n. And when you choose like this, then that means, your k of the x i’s are here and n minus k are you are adding up, right.
So, these things, then I put, put of x i equal to x for all i and y j equal to y for all j. So, in that case, your k of the x i’s, that you took from here, they all become equal to x, x raise to k y raise to n minus k. So, then therefore, this product and when once you put the x i’s together equal y i’s are together, then this whole product coincides with this. And so you have a nice way of, you know, proving the binomial theorem.
Now, I can, immediate application of this is, that if you want to count, you know, have n objects and you want to count how many subsets can be there of these n objects, you, when of course, the empty also be considered as a subset. That means, nothing gets chosen from the n objects. So, you have subset consisting the empty set. Then, you can have subsets consisting of only one element from one object, from these n objects, subset containing 2 objects, 3 objects and so on.
So, if you want to count the total number of subsets, that you can form of this n objects, then since I told you, that n c k gives you the number of subsets of size k, right, and so you want to count this number n c k from k varying from 0 to n. And which, if you look at this expansion here, essentially of putting x is equal to 1 and y is equal to 1, so that this all becomes 1. And so you are summing up on this side when you put x is equal to 1 and y is equal to 1, this reduces to 2 raise to n. So, the total number of subsets. This is another nice way of counting the number of subsets that you can form, given n objects.
(Refer Slide Time: 36:52)
 
So, extending this concept that I just enumerated for you for the binomial theorem, now we can take over, go up to multinomial coefficients. So, this is a set of n distinct objects is to be divided into r distinct groups of sizes n 1, n 2, n r for the binomial theorem, r was 2. So, now it is n 1 plus n 1 n 2 n r where of course, all the n i’s adapt to n. So, I am dividing this n objects into r sub groups. And the size of each group, the first sub group is n 1, size of second group is n 2 and so on, right.
So, then using the same principle I want to choose form n, n 1 possible groups. So, the number of possible groups of size n 1 is n n 1, n n choose n 1, right. Are you also, this is, actually this is also written as n c n 1. So, combinations, so n 1 combination, that means, you want to choose n 1 objects out of n. So, what are the possible number of ways? So, any of these notations is acceptable, fine.
So, the first group will be, the number of groups of sizes n 1 would be n choose n 1. Then, since I have already chosen n 1 objects out of n, so then I want to choose the second set of objects, n 2 consisting of the set of objects must be n 2 in size and then. So, out of n minus n 1, I want to choose n 2. So, therefore, each group of size n 1, the number of choices of the second group is n minus n 1 choose n 2, right. And so you extend this concept and so finally, the last choice would be, because now you will be left with n minus n 1 minus n 2 minus n r minus 1, r minus one subsets.
r sub groups have already been chosen. So, then these many, you are left out of this, you want to choose n r objects. So, again the number of possible ways is n minus n 1 n 2 minus n r minus 1 choose n r right and. So, we will say, that the total number of groups is the product of all these, right. And so via notation this would, well the first one would be n factorial divided by n 1 factorial n minus n 1 factorial. Then, the second one would be n minus n 1 factorial divided by n 2 factorial n minus n 1 minus n 2 factorial and so on.
So, if you see, that this will be my total expression and then the terms cancel out because you have n minus n 1 factorial here and this is n minus n 1 factorial. So, it cancels out. So, these terms will cancel out, you know, in pairs. And so in the denominator you will be left with n 1 factorial, n 2 factorial and n 3 factorial up to n r factorial.
And this is what, again what we are saying is, that we are deciding whatever objects we have, putting in one group we are saying they are all alike, the same principle you are using and so we, the arrangements will not matter in whatever way you choose, in whatever order you choose, it is immaterial. So, therefore, again I am, I can arrange my possible objects, n objects in n factorial ways. But since I am, I am grouping them into r different sub groups and each group, the number of objects is, we are not differentiating between the objects in one group. So, then the total number of ways would be n factorial divided by n 1 factorial n 2 factorial and n r factorial, right.
(Refer Slide Time: 40:38)
 
And now, this helps us to expand the examples. This gives the multinomial theorem, that if you want to expand x 1 plus x 2 plus x 3 plus x r raise to n, then it will be, because remember, in this product, just as I showed you for the binomial theorem, you want to choose. So, because each product here will consist of some powers of x 1, some powers of x 2, some powers of x 3 and x r. And so here I am now saying, that this n 1, n 2, n r will vary from, because every product here will contain 0, x 1, 1 x 1, 2 x 2 to 2 x 1 and so on and different. That means, whatever the powers, each term here you can see in the, in the product this term will appear and so your n 1 plus n 2 plus n r must be… Because each term, this is raise to n.
So, each term in this expansion will contain n x i's together. That means, you add up the indices of x 1, x 2, x r, they should add up to n and that is what is given by this, right. So, therefore, using this concept this is how you can write the expansion, right. And if you look at this example, where x 1 plus x 2 plus x 3 raise to 3, then you see, I can choose my n 1 to be 3. So, that means, this subsets contains just the power of x 1, powers of x 2 and x 3 are missing here, right. So, therefore, the expansion, this is 3, 3, 0, 0, x 1 raise to 3, then here again you are choosing a subset from 3, which consists only of powers of x 2. So, 0, 3, 0 and so it will be x 2 3.
So, I showed you the, you know the idea behind this. And then now I am using it repeatedly to say that how I can write the expansion of this, right. And so therefore, you can see, that the way I can choose my numbers n 1, n 2, n r. So, if they add up to n, so in the case when you have your r is 3 and your n is also 3, so then these numbers must add up to 3, right. You are dividing your number 3 in three possible ways, so that they add up to 3. So, here these are the possible, right. And the final thing is 3, 1, 1 when each x 1, x 2, x 3 has only power 1. So, this is the expansion.
And now, in, in, in the assigned exercise sheet, that we will just show you I am asking you how many terms are there in the, in the multinomial expansion and remember, because which is actually counting number of subsets, right, here essentially accounting the number of subsets, which you can have, you know, like you have r, this thing here x 1, x 2, x 3, x r. So, essentially my question is how many terms there in this expansion. And so I have already discussed this case with you for the binomial, how I use for answering the number of subsets of, total number of subsets of n objects. So, here you have to use the same concepts and tell me how, how many terms are there in this multinomial expansion. So, let me just show you the, discuss the exercise sheet.
(Refer Slide Time: 44:11)
 
Question 1 is straight forward, 18 workers are to be assigned to 18 different jobs. So, the important part here is, that each job is different from the others and therefore, this will be ordered arrangement of the 18 workers. So, you can write down how many possible assignments are possible. That means, an assignment would mean, that you assign one particular worker to a particular job. So, then in how many ways you can do this is the idea here, right.
Now, consider a group of 25 people. If everyone shakes hands with everyone else, how many handshakes take place? So, that means, that persons shakes heads with another person, then both have shaken hands with each other. So, just keep that in mind. And you can immediately write down what the answer will be for number 2.
Now, here in question 3, four separate awards it can, it can be, you know, somebody getting the highest marks, highest cumulative performance index, best sports man, leadership quality, etc. So, you can have 4 different awards given to these, to the students. The idea is to select from a class of 36 students, students who can be given this award.
Now, in case student can receive any number of awards, then it will be different number of arrangements, that you can have or different ways in which 4 awards can be given to student or more than 1 student. In number 1 the condition is, that the students can receive any number of awards. So, you have to do a counting that way. In number 2, we say, each student can receive at most one award. So, that means, either a student receives an award or student does not receive an award. So, this, this is the way you have to count.
Now, question 4 is interesting. Using combinational argument prove, that n chose r. That means, selecting r items from n items is equal to selecting r minus 1 items from n minus 1 plus selecting r items from n minus 1. So, you can, if you write down the expression for n minus 1 chose r minus 1 and plus n minus 1 chose r, you can show, that these two add up to n chose r.
But I want you to give a combinatorial argument and you can see here, in the first term it says, n minus 1 chose r minus 1. That means, I am keeping away one particular object or item from the n that are there. Then, I am selecting r minus 1. So, that means, the first set of numbers, n minus 1 chose r minus 1 gives you the number of ways, which you can pick up, r minus 1 objects from n minus 1 when a particular object is being selected. So, when you add that to this selected group, then it will become r object from n objects.
Now, the second says, that n minus 1 chose r. That means, that particular, see the thing is, either a particular object or item, that you have picked is either there in a collection of r objects or it is not there. So, the first case says, that yes, it is going to be collection of r objects. So, once you add it to the set of r minus 1 objects that you have selected, then it becomes r. In the second one, what you are saying is, this is a set of, this is a set of selections in which that particular object does not appear. So, you have separated that objects and then from the remaining n minus 1 you are choosing r. So this is a kind of combinatorial argument you are giving to prove the identity.
And so you see, I have already shown you, that you can, by combinatorial you can give, show, you prove the binomial theorem. Now, similarly you can try to prove number of such identifiers through combinatorial arguments. Then, question 5 we have already discussed. In how many ways can r objects be selected from a set of n objects if the order of selection is to be considered?
So, question 6, one delegate each from 10 countries that include delegates from India, Pakistan, Bangladesh and Sri Lanka are to be seated in a row. So, the arrangements have to be row delegates from India and Sri Lanka are to be seated next to each other and delegates from Bangladesh and Pakistan are not to be seated together, how many seating arrangements are possible.
So, the idea here is, that you know, you, you have 10 different positions, people are sitting in a row and you want people delegates from India and Sri Lanka to be seated together, right, which means, that I can treat those two as one person. In that case, it will be 9 people, then who have to be arranged because delegate from India and delegate from Sri Lanka have to be together. So, that means, the total arrangement is 9 factorial. But since the people are sitting in a row, that means, the arrangement, that first the Indian delegate is sitting and then the Sri Lankan, or the Sri Lankan delegate is sitting first and then the Indian, so this will count as the two different arguments and therefore, the total number of arrangements would be 2 into 9 factorial in which the delegates from India and Sri Lanka are together.
Now, you do not want people, delegates, Bangladesh and Pakistan to be sitting together. So, now again consider the situation when they are sitting together. So, we will subtract the number of… So, in that case, now look at the arrangements in which delegates from India and Sri Lanka are together and delegates from Bangladesh and Pakistan are together. Then, you know, you will have 8 different positions to arrange because these 2 delegates will be together. That means, they can be treated as 1 person, right, and therefore, it will be, total number of arrangements will be 8 factorial.
But then again you have to, it can be 2 possible, you know, like as I told you, the arrangement can be India-Sri Lanka or Sri Lanka-India. Similarly, it can be Bangladesh-Pakistan, Pakistan – Bangladesh. So, therefore, essentially you will be subtracting from 2 into 9 factorial, the number of arrangements in which all the four, I mean, delegates from Bangladesh and Pakistan are together and delegates from India and Sri Lanka are together. So, that will be 2 square into 8 factorial. And so you subtract this number from 2 into 9 factorial, that should give you the required number of people, number of ways in which you can have the required arrangement.
How many terms are there in multinomial expansion of x 1 plus x 2 plus x r raise to n? So, here again I am wanting you to do this exercise. See, the whole idea, either way I explain to you this expansion was, that you are essentially dividing your number n into r smaller numbers, n 1, n 2, n r ((Refer Time: 51:18)) sum up to n. So, in how many ways can you partition this set of n number into r subsets, so that they all add up to n. This is the whole idea.
And so you will see, that from this identity x 1 plus x 2 plus x r raise to n. You have to put all these x 1 x 2 x r equal to 1 and so you get r raise to n is equal to the number of terms that appear in the expansion, multinomial expansion of this term, right.
Then, finally, a total of 6 gifts are to be distributed among 9 children, so that no child receives more than one gift. This is exactly the same as, you know, in part 2 of 3, right, because here also we said that no student should get more than one award, should get at most one reward, award. And so here also we are saying, that the total of 6 gifts are to be distributed among 9 children, so that no child receives more than 1 gift, ok.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 2
Sample Space Events Axioms of Probability

(Refer Slide Time: 00:17)
 
So, today I will talk about axioms of probability. So, I start talking to you about developing the theory of probability, and here to begin with this, first it is very necessary to discuss basic concepts and notations of set theory. So, I will begin with the concepts of set theory and give you some notations, and then after that, it will be possible to define the axioms and then build the probability theory based on these axioms, okay. Now, of course, a set you have already been using this word, and so I will just formally write down that a set is a collection of objects, points, whatever you may consider, whatever the collection, and this can be finite or infinite; the number of elements of the set may be finite or infinite.
So, enumerable examples, now if you have to consider a town with its population, then, obviously, the people living in the town would be a finite number. So, that will be a finite set, and if you consider a set in r 2 which is bounded by a closed curve and then if you consider all the points in this set and they will finite; in fact, they are not even countable, right. So, a set in r 2 bounded by. So, this will be infinite set and so on. Now we will always refer to when I develop the concepts of set theory, there will be a universal set which I will refer to as omega and then we will take subsets of omega and define all the possible; whatever the operations we can do on this set of subsets of omega, right.
Now definition 2 point 1; for two sets a and b subsets of omega; that means contained in omega, we define sum joint or union referred to by two different names. So, basically, the union of two subsets a b, then we define it as a union b and this is equal to all elements of omega such that omega belongs to a or omega belongs to b, right. And if you look at it, diagram was why so I have this because set as my set omega, this is a, this is b, then you see If you consider all this portion; this will be a union b, because the element which is either in a or in can be or which is in both a or b, then that constituted your union of the two subsets a b, okay.
Then, similarly, intersection or product is other two names given to of a b, and the notation is a intersection b and this is here for all omega in capital omega such that omega belongs to a and omega belongs to b. So, the common base, and here in the diagram, you see that the intersection would be this, this portion, right, which I have shaded differently. So, this portion will denote the intersection of the two sets and it is not coming properly, fine. Then, similarly, you would define complement of a set a which means and we denote it by a c or a bar. So, complement means that, okay, I did not write down the definition; that means this is a compliment is all omega belonging to this or that omega does not belongs to a; this is the idea, right. So, if this is your a and this whole is omega, then all elements which are not in a from the set a complement, okay.
(Refer Slide Time: 03:56)
 
Definition 2 point 4 is difference of two sets a b is the set a minus b; they refer to it as a minus b or a intersection b compliment. So, that is all omega the universal set such that omega belongs to a, but omega does not belong to b because it is intersection b complement. So, if you use the definition of the product, then the elements here must belong to both a and b complement; that means the elements which are belonging to a but not belonging to b. So, in that case, I have drawn the figure; figure three should be so a and this is b, no, so I have to say b compliment, okay. This is not shaded correctly.
Yeah, so if I am saying that this is whole of a and this whole is b I am referring to, right, because the elements here are in a and not in b. So, this is the right diagram for a intersection b compliment, right, which is a minus b. So, all components all elements which are in a but not in b will be referred to by this one here, okay. Now let us just so what we are asking you [FL]. So, I probably drew the okay. So, this was the figure for this, right, okay. So, we will do it here. So, now it says that question is draw the event diagram for a complement intersection b. So, here if you have this and if this is a and this is b, then if I want a complement intersection b, then an element which is in b but not in a. so, then it will be this; this is what I had drawn, okay.
So, the elements here, they are not in a but in b; that is a by intersection b, okay. Again I will take some more examples. Omega let us say the universal let contains the numbers 1 to 10, okay, and then if I define a as a set of all odd numbers and b contains 2, 3, 4, 5, 6, then a union b would contain elements which are here as well as in b. And so, the union will be 1, 2, 3, is here 4, 5, 4 is here. So, it will get added here, 5 is here, then 6 is in b. So, that gets added, and then 7 and 9. So, this is your a union b, right, and a intersection b, you have to look for the common numbers in a and b.
So, 3 and 5; 3 and 5 are the common numbers. So, that forms your set a intersection b. And, similarly, you can write down all the others; for example, a compliment would be all even numbers, right, because this is all odd. So, a compliment would be all even numbers, then similarly b compliment you can write down the numbers which are not present in b. And then whatever other operations we have defined, you can work out the examples. Now I will take the case of the infinite term set. So, here is you take omega to be all collection of x comma y; that means points in r two. So, these are the points in r 2 such that x is non-negative y is less than or equal to 0.
So, if you consider this as a whole plane r 2, then your omega is on this; that means here y is less than 0 and x is positive. So, whole of this quadrant last quadrant; in arc 2, this is the first, second, third and fourth quadrant. So, we are in the fourth quadrant omega, obviously, then is a infinite set, okay. Now if I take a to be the set consisting of all points for which the x coordinate is greater than 0 less than 12, and y of course is less than or equal to 0, then of course the picture is not; if this is my number 12 on the x axis, then you can see that the whole of this we can say set. Again it is an infinite set where y is less than 0 and x coordinates are between 0 and 12 that forms a, right, and b is all x between 0 to 15 and then y is minus 0 and 0. So, minus 10 and 0, okay; so, this is minus 10 and 0, fine. 
So, that means if I draw a line here, then my b extends like this and x is up to 15. So, now in this case your b is this set. So, b is this portion, right. The x is expending up to 15 and y is from 0 to minus 10. So, that is your b. Now you see that if you want to write a intersection b, then this will be all points x y such that x because you see in a, x is between 0 and 12; in b it is between 0 and 15. So, when you want to take all common points in a and b, then it will be x between 0 and 12, and here your y is less than or equal to zero. So, y in a was extending up to infinity. So, in this case, the common thing would be that y is between minus 10 and 0. So, that will give you the intersection, right.
And of course I have already used the concept that a is a subset of b or that means here a and b are subsets of omega. So, here you can see that b is not a proper subset of a, because you can find points which are in b but which are not in a. So, this is the other concept that you use. So, here I have said that b is not a proper subset of a; that is I showed you that there are points in b which are not in a, alright, and that you can see because the set of elements this we have already seen that when you take points for which the x coordinate is between 12 and 15 and the y coordinate is between minus 10 and less than 0. Her of course x is greater than 12, because a contain x less than or equal to 12.
So, if the point is not in a, then the corresponding x coordinate should be greater than 12, alright, and this is less than or equal to 15. So, these are the points which are in b but not in a. So, b is not a proper subset of a. So, now let me just also give you a formal definition of a proper subset; what do we mean by a proper subset? That is if b is a subset of a but b is not equal to a, then we say that b is said to be a proper subset; that means when b is a subset of a and b is not equal to a, it means that there are points in a which are not in b, whereas because b is a subset of a. So, all points of b are all elements of b are also elements of a but since b is not equal to a; that means there is at least one element of a which is not an element of b.
And so then in that case, we say that b is a proper subset of a, and we write it as without the equality sign here. So, b is a proper outset of a; this is the notation for. So, therefore, now at least whatever words I used the word not a proper subset. So, now you know what is a proper subset?
(Refer Slide Time: 11:49)
 
So, now let me continue with the definitions and with the basic concepts of set theory. If a and b are said to be mutually exclusive or disjoint, if a intersection b is empty; that means there are no common elements in a and b, fine. So, for example, in the example 2 point 2 that we just considered, you know the coordinate in the subset of r 2, you see a intersection b is actually this set which has so many points and so it is not empty. Therefore, a and b are not disjoint or they are not mutually exclusive and so as we go along and see so many examples when a and b have sum points in common, then they will not be considered disjoint if they do not have any not points in common, they will be considered as disjoint or mutually exclusive.
Now some more concepts dealing with laws and this thing dealing with union, intersection and complements of sets; so, here if now I am talking of a, b and c, there are three subsets of your universal set omega, then idem potency law says that you know when you operate a with itself, then a intersection a is a or a union a will also be a. So, that means the union and intersection are either the operations we have defined for the sets these two are idem potent, okay. Then commutative law says that it does not matter whether you add a to b or you add b to a. So, therefore a union b is equal to b union a. Similarly, a intersection b is b intersection a.
So, the order is not important which is that you write first. Associative laws here if you are saying you are taking intersection of a with intersection of b intersection c, then you can also write this as you first take the intersection of a and b and then take the intersection with c. So, it does not matter. So, the associative law holds here. Similarly, with union also; with respect to union also the associative law holds; that is whether you add a to the union of b and c or you add, first take the union of a and b and then union with c; it does not matter, they are the same.
Now the distributive law is with respect to both the operations, intersection and union. So, when you take a intersection b union c, you can write this as a intersection b and then union with a intersection c. So, a gets distributed, alright. And, similarly, a union b intersection c will give you a union b, then intersection a union c. So, these laws hold, and just for completeness sake, I have written them down here. Then De Morgan’s laws are also important and we will be using them throughout, and therefore, it is better to talk about them right now. And so the first laws say that an intersection b complement is equal to a complement union b complement, fine.
And if you see diagrammatically of this set is omega and if this is a and this is b, then a intersection b is this, alright, the darkly shaded portion. And so its complement will be the portion which is shaded by the lines, and you can see that the portion shaded with the lines is nothing but the union of a complement and b complement, alright. Because this portion gives you b complement and this portion gives you a complement. So, the union of both the two, so the two is equal. But you can also prove it otherwise. See what we are saying is that if omega belongs to a intersection b complement, this implies that omega does not belong to a intersection b, right, which means that omega should not belong to at least one of them.
Because if omega belongs to both a and b, then omega will belong to a intersection b. So, since we are saying omega does not belong to a intersection b, this implies that omega does not belong to a complement or omega belongs to b compliment, aright. If you do not what omega to belong to both a and b, then it must belong to either a complement or b complement which implies by our definition of union that omega must belong to a complement union b complement. Now remember, okay, I did not say this out in the beginning but I should have said that whenever you are wanting to say the two sets are equal, then what does it mean?
Yeah, maybe I should spell it out; a equal to b implies, yes, component wise that if omega belongs to a, this implies omega belongs to b. And if omega belongs to b, it should imply that omega belongs to a, fine; this is the way of saying that the two sets are the same. So, here when I want to show that these two sets are the same; right now I have shown you that if omega belongs to an intersection b complement, then it must belong here, but I must show the other way also. That is if omega belongs here, then it should belong to this and which I am showing.
Similarly, if omega belongs to a complement union b complement that means if it is here, then this implies that omega either belongs to a complement or omega belongs to b complement which implies that omega does not belong to a intersection b, alright, because either omega belongs to a complement which means that it does not belong to a or it does not belong to b which means that omega does not belong to a intersection b, and so it belongs to a intersection b complement. So, I have shown you both ways, and therefore the two sets are equivalent. 
(Refer Slide Time: 17:54)
 
So, similarly, I am writing out all the other laws here De Morgan’s laws which you can sit down and work out yourself. So, there you will have to show that you first start with an element here and show that it belongs here, then you will have to pick up any element from here and show that it belongs to set on the left. So, that exercise you should now sit down and do for the remaining De Morgan’s laws but we can just look at them. So, this is in a way a complement of this says that a union b complement is equal to a complement intersection b complement.
Then if you take the complement of the complement, you get back to the set a, alright; that of course in words you can immediately say it out. And one way to classify correct wise is that one set is the subset of another. So, b is a subset of a if and only if when you take the intersection, you will get the set b, fine. If b is a subset of a set a, then when you take the intersections, the only element all the common elements must belong to b; similarly, union you can characterize that if b is the subset of a, then a union b is equal to a, because b is not adding any new elements to the set a union b. And therefore, a union b remains equal to a.
Now so far I had defined union intersection complements for two or three sets. But now we can extend this notion to any number of sets, and here I am just taking i to be the index set where this index set can be I can be having finite element of finite indices or infinite indices. And so this holds for whatever the status of I is. So, now if all these are subsets of omega i is in the index at i, then you can say that the intersection of all the subsets such that i belongs to i is omega belonging to the universal set such that omega belongs to a i for all I, alright. So, if an element is present in all the a i, so then it will be present in the intersection, and union of course would imply that omega belonging to a I for at least one i, right.
And omega belongs to the union if omega belongs to at least one of a i’s, okay; it van belong to more than one, but it must belong to at least one of the a i’s, right. And then, similarly, using the concepts here the definitions here, you can define now that this is not written very nicely, okay. So, i belongs to I if you are taking the intersection of all a i’s so that I belongs to i. And then you take the complement. So, then by this law, you immediately write it down as union a i complement, yeah, and again in words you can say it out the same thing. And, similarly, here this is the equivalent of this when you are taking more than three sets or two sets; this is union a i, i belonging to i. The complement of this will be the intersection of the complements of all the a i’s, right, okay. 
So, given this now let us get started with taking about how we go about defining probability of an event and so on. So, before that I will simply spell out what we mean by sample space and then events and then we talk of how we go about estimating the probability of events, okay. So, again I will begin with the examples to give you an idea what we mean by sample spaces. So, for example, if you consider the experiment of tossing a coin; so, a single coin is tossed. And so what are the possible outcomes? Either I will get a head or a tail; these are the two possible outcomes.
So, you just collect all the possible outcomes of an experiment and that will be our concept of a sample space and again I will refer to it as for that particular experiment this is my universal set. Similarly, if I toss two coins together, now the thing is that you are tossing two coins and so let us just name one coin as number one and the other as number two. In that case, you see when both of them show heads and this will be h h. Now here if the first coin shows the head and the second coin shows the tail, then it will be h t. And if the first coin shows a tail and the second coin shows a head, then the outcome would be the t h, alright, and in case of both of them show t t tails, then this will be t t.
So, this will be the set of all possible outcomes when you tossing two coins together, okay. And so this will be your sample space; this would be the sample space. If you are now tossing 2 6 faced die. So, here again what we will do is we will say that we will number one die as number 1 and the other die will be number 2. And so, therefore, the outcomes will be recorded as whatever the numbers shows for the first die and whatever the number shows for the second die. And in that case, it will be s pair of numbers. So, 1 to 6, and therefore, the possible outcomes will be 1 1, 1 2 and 1, 6; that means the first die shows 1 and the second dice shows 1, 2 or 6. And, similarly, you can then say that it is 2 1, 2 2, 2 6.
So, therefore, it is important when you are throwing two die, then you have to number them as 1 and 2, so that because what shows the arrangements because here this is an ordered arrangement, and therefore, there is a difference between 1 2 and 2 1, okay. And so, we have to record all possible outcomes, and therefore, here this will be the collection of all 36 outcomes, and that will constitute your sample space, okay. So, therefore, I am just trying to show you that when you consider an experiment, then you have to be very careful in recording the outcomes. And so here when you are tossing two coins, then we will have to number one as first coin and one as second coin, and then we can record the outcomes.
Similarly, when you are two die, then you have to you know locate one die as number 1 and the other one as number 2 to be able to record all possible outcomes in a proper way. Then the possible outcomes I have not listed but this table shows that you know it can be the first one is the first die is showing one and then the second die is also showing 1, then it could be 2 up to 6. Similarly, it could be 2 1, 2 2, 2 6 and 3 1, 3 2, 3 6 and so on up to this. So, here the total number of possible outcomes you see will be 36, right, and again I will refer to this as a sample space. So, now formal definition of a sample space can be immediately said and that is if the set containing all possible outcomes of an experiment is the sample space corresponding to that experiment, okay.
It is not very clearly written but you can just read it; that means the set containing all possible outcomes of an experiment is the sample space corresponding to that experiment. So, this will be our concept, and here you see that in this case of course when do any experiment, you except the outcomes to be finite. And so, my sample space in this case would be the number of I will just list the number of possible outcomes and that collection of possible outcomes. So, you can see that the sample space can have any kind of structure.
So, here in case, for example, it was h and t means these are the possible outcomes; in this case, it was h h, h t, t h, t t. And now in this case it is pair of numbers where the numbers can differ from 1 to 6 for wither this thing and so collection of those 36 pairs of numbers are the elements of sample space omega and that will be. So, now I will go on defining the concept of events and then we will try to estimate the probability of events.
(Refer Slide Time: 26:37)
 
Now I will defined what we mean by an event. So, any subset E of the sample space idea, first idea of a sample space is clear; that means all collection of all possible outcomes. Now any subset of the sample space is known as an event; we will define this way. And we have seen that, if for example, two subsets are there e and f is subsets of omega; they both are events. Then whatever operations we have done so far we have discussed on the subsets, then e union f, e intersection f, e complement and whatever. We discussed all those various operations on the subsets, then all those will again be subsets of omega, and therefore, by our definition they will again be events.
So, in fact, when I told you the extended concept of union and intersection where you took number of subsets whether finite or infinite and again if you take their intersection and union and complements and so on, they will again all be subsets of omega. So, therefore, you can see that the collection of events becomes very very large and in fact, it is formalized which I am not actually taking to you about; I will just mention the name that it is known as the sigma algebra of events. So, essentially what we have to remember is that, however, way we can generate subsets of omega, then those which can be obtained as through union, intersection and complement. Through these three operations whatever subsets of omega we can obtain, they will all the considered as events for the corresponding experiment, okay.
Now examples are there; when you toss a single coin, we saw that the sample space omega just contained these two possible outcomes. And now the subsets can be if the single turns h t and of course we always include consider pi also as the subset. So, therefore, these will be possible subsets or the events in this case. When you are tossing two coins, then you see your possible outcomes were four, in fact, h h, h t, t h, and t t. Now you can start forming subsets; I have just written down a few. You can take this each outcome of each element of the sample space omega as subsets, and so it is an event. You can put two together; that means either head or tail or tail or head, and this will again also form an event and you can then perform.
In fact, in the last lecture I have shown you that if set has whatever the number of elements, then the possible number of total number of subsets of that set would be 2 raise to 4; remember it was an application of the binomial theorem and so on. So, the number of subsets here, in fact, would be 2 raise to 4 which will be 16. So, you can list out all the possible events that can be formed for this particular experiment of tossing two coins. Now again as an example when you are tossing two 6-faced die, then consider the subset which has both the numbers that means both the phases show the same number, alright. So, both the numbers are the same and so here the components in a would be 1 1, 2 2 pairs, 3 3, 4 4, 5 5 and 6 6.
So, this will be one event; that means you can also describe it in words that both the phases both the numbers are the same. And b for example I have listed pairs which were the two numbers add up to 7. So, the sum of the two numbers adds up to 7, and this way you can go on continuing. In fact, here the number of subsets will be very large because omega itself contains 36 pairs, and so the number of subsets would become this thing, right. Yeah, but now one word of caution and that is when we are defending the sample space, we have to be careful as to what our experiment is.
And here, for example, you have to; in fact, I have to say that there are two possible cases. One is with replacement wherever this is relevant, and the other possibility can be without replacement, okay. So, we have to be careful on how the experiment is being conducted and then you can define your sample space that means the possible outcomes that can be there of the experiment. 
(Refer Slide Time: 31:28)
 
So, now consider the case that two cards are to be drawn from a pack of 52 cards, and if you are doing this drawing of the card; that means you draw a card. You look at it, note it down somewhere and then put it back in the pack and then again you draw the second part. If this is your experiment, then let us say that I comma j stand for. So, you note down when you take out a card, you look at the number; you look at the card. So, then the first index here tells you what card it is, what type; that means whether it is a club, spade, diamond or heart. So, I will refer to c s d or h; that means four possibilities and j will stand for the number from 1 to 13; that means whether it is an ace; that is number 2, number 3 or number 13, right.
So, then this pair will denote the type of the card that you got, and so your omega will be collection of all two pairs I comma j and k comma l where again k indicates the type of the card and l indicates the number. So, therefore, I and k can be anything from c s d h, because you are doing replacement and then j and l are the numbers 1 to 13. So, essentially, the way you can describe the experiment is that the first draw of the card, it can be any 52 cards. And, since, you have replaced it in the pack, again your choice of drawing a card is from among the 52 cards in the pack. So, therefore, the total number of outcomes that are there is 52 into 52, okay. And so this actually by the way denotes the cardinality of a set, which means that what is the total number of elements in the set.
So, here the sample space will consist of 52 into 52 such collection of pairs, okay. So, to indicate you what the cards you have got. But now if you are doing it without replacement, then you do not want I and k to be the same and j and l to be the same; that means once you have drawn a card, it is not there in a pack. So, it will not appear again, right; in that case, your choice will become that means in the first draw you have a choice from among the 52 cards, but in the second draw, it will be only out of 51, because one card has been replaced is not there; it is kept aside.
And, therefore, in this case you will have to be careful because your choice of the sample space will contain such pairs but there I will not be k and j will not be l. So, the whole idea is to say that we just do not write out you have to be careful when you spell out all the possible points that can be there in the sample space, okay. Now let us begin talking about the axioms of probability; that means how do we characterize a function or whatever we mean by a probability; I mean what type of characteristics it should have? So, here again I am now referring to the sample space omega and then e is some subset of omega which again is an event. So, then we say that the function p which will assign. So, essentially what we are saying is that p assigns, okay, I am writing capital P.
So, P is assigning E to a real number; that is it takes it to P E which belongs to the real number r, right. So, we can say that this is a mapping or an assignment. So, here for every event E for every subset of omega, I am assigning real number. And so, P E is a real number here, and P E must be between 0 and 1; that is the first requirement. Then for the whole sample space p omega should be 1, alright, and axiom three says that for any sequence of mutually exclusive events; that means you just take any collection of events a i that means subsets of omega such that they are mutually exclusive which means that e i intersection e j is empty for all I j in I, alright.
So, this is the collection which can be a finite, infinite; it does not matter, but we are referring it to as an index set I and then probability of union E I, i belonging to I should be equal to the sum of the probabilities. So, because the events are mutually exclusive, they are disjoint. So, therefore, when I add up the compute the probability of the union of these E I’s, then it should be equal to the sum of the probabilities. So, these are the three characteristics that we associate with the probability function, and using this, you see that any function f p which satisfies these three axioms will define the probability. And this is actually what we say is that p E is probability of occurrence of e.
So, remember in the beginning I started saying that we would be trying to develop the theory of occurrence of an event. So, here we have now defined something which we refer to as the probability of occurrence of e. So, this is and we will now see that what things you can derive. So, basically using these 3 axioms, we will be able to build up the probability theory. And the first simple observation that we can make is that n this case for axiom three, if you choose your e I to be the whole set omega that is your sample space and all other e i’s you choose as empty sets, right, for i greater than or equal to 2 because this axiom must hold.
So, here the union will become your set omega, right, because all other e i’s are empty, E 1 is omega. So, union gives you omega and from here from axiom 2 p omega is 1. So, you get this. Okay, p omega I have to write that is secondary and that is not a big deal. I mean, okay, what I am saying is that this validates the axiom because we have already assumed that p omega is 1 and so here also if you put e 1 as omega and all other e i’s as empty sets, then you get p omega is 1, alright. Now here in this case, if you look at this, you want to compute the probability of let us say h and t. So, here if I take what will be my subsets here this would be in the first example, my e 1 would be h, e 2 will be t, alright.
So, in that case from this axiom, what I will get is that p e 1 plus p e 2, alright, is equal to 1, because e 1 union e 2 is my whole space omega; p omega is 1. So, therefore, I get that p e 1 plus p e 2 is this but then I should be able to compute, okay. Then what I am trying to say is that from here, I should be able to show that p e 2 is equal; of course, from here it follows that p e 2 is 1 minus p e 1. 
(Refer Slide Time: 39:31)
 
So, we got that using axiom three in the case when single dice rolled tossed and then we got that p e 1 if e 1 is the event that it is showing ahead and e 2 is the event that it is showing a t, then we got that p e 1 plus p e 2 is 1 which is equal to probability of h plus probability of t. Now we understand the concept of unbiased coin; that means it is equally likely whether a head shows or a tail shows. In that case, the two probabilities are equal; that is what we mean by an unbiased coin. And so, therefore, it will immediately follow from here that p h equal to p t is equal to half, because they both most add up to o1. So, therefore, what is what I am showing how you apply the axioms to arrive at the probabilities of the events. So, here of course that it is an unbiased coin.
Similarly, when a die is rolled and so you have the 6 number showing up, either of any of the six numbers can show up. So, here again applying axiom three, you will see that the probabilities of all numbers but that means p 1 plus probability of p 2 plus up to probability p 6 and that should be equal to 1. And since we are again saying that all size are equally likely which means that probability of p 1 is equal to probability of p 2 means it is equal to the probability of 2 that it is equal to probability 3 and so on. So, all six together; that means essentially what we are saying is that six any of them; this is equal to 1 which implies that p 1 is 1 by 6 which is equal to all other this thing, right, for I varying from 2 to 6.
So, we immediately conclude that probability of each phase showing up is the same which is 1 by 6. Now what happens is that most of the time in many, many situations, we now already because of the nature of the experiment and so on that the elements of the sample space have equally likely outcomes because that is how I showed you these two example that when you are throwing up a unbiased coin, then you know that whatever the outcome has the same probability that a head showing up or a tail showing up, they are the same. Similarly, as I said that if you are throwing up a die and you have no reason to say that it is loaded die or a biased die, then in that case we except that any of the six numbers have the same probability will show up the same.
So, we will see that and of course we have to be what I am trying to say is that I am giving you an alternative way of defining the probability of an event, but the basic assumption for this definition is that your sample space has this property that all the outcomes in the sample space have the same probability equal likely chance of occurring, right. If that is there if this is satisfied, then let us just start with this definition that suppose omega has n number of points; that means the cardinality of omega is n and the number of points in a where a is an event, okay. A is subset of omega, alright, and then we are saying that the number of points in a is n, then we define the probability of a as m divided by n.
That means the number of points available in a or you can also there is another way of saying it that the number of favorable cases; that means the number of points which actually are in a; that means for occurring of a those are that points which will occur. So, then the definition of the event a is number of favorable cases for a divided by the total number of cases; that means total possible outcomes and the outcomes which are part of your event a. So, then this is the definition, and now you can very quickly verify that the three axioms, because remember I said that any definition of probability must satisfy the three axioms. So, since a is subset of omega, this means cardinality of a is less than or equal to cardinality of omega, right, which implies that m is less than or equal to n, alright. Therefore, probability a is less than or equal to 1 and also by definition, probability of a is greater than or equal to 0, because m is either 0 or it is a positive number. So, therefore, this satisfies the first axiom, right. 
(Refer Slide Time: 44:30)
 
Then, similarly, probability omega would be n by n which is 1, alright, because omega has n points. So, therefore, n upon by verifying the definition; so, this probability is 1. So, this axiom is also satisfied. Now if I take a set of events a i’s in an index set I capital I, and here, since, we are taking the omega as the finite space. So, I is also a finite index set and then cardinality of each a i is m I; that means the number of points of the sample space in a I is m I, alright. Then we want to look at the probability of union a I, and here the a I’s are disjoint, because, remember, I am verifying the axioms 3 of probability. So, here a I’s are disjoint; that means the elements of the sample space which are in one a I are not in any other.
So, all these a i’s are disjoint meaning that the points in one a I the elements of sigma in one a I are not in any other a I, alright. So, in that case, now if you want to compute the probability of union a I I belonging to I, then this will simply be because the number of elements of omega sigma of omega in union a I will be sigma mi. Since, the elements in each a I are different from all others; so, therefore, we will just add up the total number of points which are in the union here will be sigma m i. And so by our definition, this will again be when you are computing the probability for this union, it will be sigma m i I belonging to capital I divided by n.
And now here the sigma I can write as individual sigma’s that means I can write this as summation of m i by n I varying from 1 to n and each m I by n. So, for a particular I, the m I by n is the probability of a i and so this is the sum of the probabilities. So, axioms 3 are also satisfied here. So, that means this particular definition when you assume that the outcomes, the occurrences or the elements of sample space have equally likely chance of being of occurring, then I take the definition of the probability of an event as the number of elements in that events number of elements of the sample space in that event divided by the total number of elements in the sample space.
So, m by n if I take that as the probability here, then, since, it satisfies all the three axioms; so, this is a very convenient way of computing the probability provided of course you can assure that the outcomes in the sample space are all equally likely. And, yeah, if you can assume that if you can assure that, then we can use this way of computing the probability of any event where we can just look at the number of favorable cases for a particular event and then count them up and then divide by the total number of outcomes in the sample space, and you get this anyway. Now we just want to make another comment here note here and this is you know we sometimes refer to the probability in terms of percentage.
So, for example, if you make a statement that in a group of 20 people, ten percent are smokers; sometimes he also refer to be probability in this way. So, this would be interpreted as probability of a member of the group being a smoker is 0.1. So, 10 percent; so, 10 upon 100, okay, and here if you want to interpret it in terms of your m by n, then you see your n is 20 and the ten percent of 20 is 2. So, m is 2; so, therefore, 2 by 20 which is 1 by 10 which again is equal to 0.1. So, please remember that as the course develops, we will often be referring to the probabilities in terms of percentages and so the interpretation is simple, alright, okay. You just take the fraction which is so 10 percent means 10 upon 100, and that gives you 0.1. So, that will be your probability.
So, exactly the same way you are counting as you are doing here m by n. So, therefore, all the conditions all the axioms are satisfied. So, this is also a proper definition, but of course this is valid when you can assure that the all outcomes in the sample space are equally likely, alright, okay. So, I will quickly take up this example. Now here a committee of 5 is to be selected from the group of 6 men and 9 women, alright. Now if the selection is made randomly, so this is important. Since, the selection is made randomly; that means that the choice of any of the men or any of the women is equally likely.
Under this assumption, we will say that what is the probability that the committee consists of 3 men and 2 women? So, if you want to compute this, I will apply this definition because the example here the experiment here satisfies this condition. And therefore, you see now here I will apply this thing multinomial thing. So, you want to select 3 men out of 6, and 2 women out of 9 women. So, this gives you the total number of points in your set a, right, or the event E or if you define the event E as 3 men and 2 women are selected, then this cardinality is given by 6 3 9 2, alright.
And the total number of ways in which you can select 5 people from the set of 15 is 15 choose 5, and therefore, the number of favorable cases is this, total number of cases is this. So, the probability of selecting a committee of 3 men and 2 women is given by this ratio. And, similarly, here an urn contains n balls of which one is special. If k of these balls are withdrawn one at a time with each selection being equally likely; so, here again the same thing is stated. So, if each selection is being equally likely; that means whatever the balls are left, choosing the ball from there is equally likely, then what is the probability that the special ball is chosen. So, here again the probability of the special ball is chosen. So, here you see you have to choose the special ball, so 1 upon 1; the probability of choosing that is 1 upon 1.
Then from the remaining n minus 1 you want to choose k minus 1. So, this gives you the number of favorable cases. The number of cases in which the special ball will get selected and then the total number of ways of selecting k balls from n balls is n c k. So, that number when you compute comes out to be k by n. So, the whole idea is that things become much easier if you have this condition being satisfied, then this is very convenient way of determining the probability of an event.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 3
Conditional Probability Independence of Events

(Refer Slide Time: 00:14)
 
So, after having defined the axioms of probability I am trying to, I try to show you how probability function can be obtained. Let me now derive a few propositions using these axioms. So, the topic that I am going to talk about is simple propositions. So, proving this that proposition that P phi is 0, so the axiom 3 we have taken we take E 1 to be omega and then E i s are all, all remaining E i s are empty. 
And here we will take the index set be a finite index set. So, it does not matter; I have to prove it for, I have to just show that P phi is 0. So, whether I take; so here it is convenient to take i to be a finite index set. So, I take i to be a finite index set. Then all other E i s are empty sets. So, therefore, the condition for axiom 3 is satisfied, because certainly E 1 is disjoint with an empty set, and all other sets are also because they all are empty. So, they are disjoint. 
So, therefore, the I write down applying the axiom 3; I say that P omega plus, p phi, and phi gets added i minus 1 times, because 1 has gone here; so 1 less than the index of i, to the cardinality of i. So, therefore, this is P phi into, cardinality of i minus 1; this has to be equal to 1 because this is P omega, right. Since you add up all the E i s then this all add up to omega; remaining sets are all empty sets. 
So, this is by axiom 2 this is 1, right; and so and therefore, since i is a finite number which is greater than or equal to 2 because we are saying that at least 1 set which is equal to omega, and the other there is at least 1 set which is the empty set. So, therefore, the number of, the cardinality of i has 2 or more than 2; and so this number is not 0.
Therefore, here, you see, because P omega, P omega cancels out; then you get that, and also P omega is 1. So, anyway, this cancels out; and we are left with this; this left is equal to 0 which means that either this is 0 or this is 0, but then this number is not 0 since cardinality of i is 2 or more than 2, so P phi must be 0; so this is how we obtain the preposition that the P phi will always be 0. 
Now, proposition 2 is this actually; that probability of the, complement of the event E is 1 minus probability of the event E; and this can be very simply derived. And see here the attempt is to show you that once you define the axioms and then using the axioms logically, we can derive at so many results and build up a good structure. So, that then you can estimate probabilities of more complex events and so on. 
So, now for any event E, E union E compliment is omega, right; either the element of omega is in E or is in E compliment, so this holds. Then, since E and E complement are disjoint sets, they are mutually, this thing, exclusive. From axiom 2 and 3 it follows that P (E) plus, P (E c) is 1. So, from axiom 3 it say that probability of E into, probability of E union E complement is P (E) plus, probability of E compliment. And then axiom 2 says that probability of omega is 1; so this is what holds.
And therefore, from here it immediately follows that probability of E compliment is 1 minus P (E). So, that is your second proposition. So, therefore, now using the basic 3 axioms I have been able to arrive at the result that P phi is 0. And then now I have shown you that P of the, probability of the compliment of an event is 1 minus the probability of that event.
Proposition 2.3 says that now, we can see that the results are getting more and more complex. So, if the 2 events, E and F, subsets of omega, then probability E union F is equal to, probability E plus, probability F minus, probability E intersection F. And you see that, in case, E intersection F is empty then this will be 0, because we have just derived the result that P phi is 0, so in that case P E n F will be this; and then this is again is valid for axiom 3 because in case E intersection F is empty then E and F are disjoint, and then we said that probability of the union is the sum of the probability, right. So, this is in complement with you axioms, and so on. 
Now, let us start proving this result. So, I first say that E union F is E union E compliment intersection F, right; because this set E union F, so either whatever the elements of F are E that cover, that is covered here, and the remaining elements of F are not in E, but they are in E compliment. And therefore, you can write E union F as E union E complement intersection F. 
Now, by doing this, you see, I have broken up this union into, the union of 2 disjoin sets because E intersection that E complement of F is empty; so there cannot be any element which are in E compliment. So, therefore, this is empty. So, now axiom 3 again says because these 2 sets are disjoint; therefore, probability of this union, so probability of E union F is equal to probability E plus, probability E complement intersection F because I could decompose this union into the union of 2 disjoint sets. And so I can immediately apply axiom 3, and I get this, right.
Now, we will try to write, again decompose up in a way so I can make use of the axiom 3. So, now, F is F intersection omega, but then omega as we said we can write as E union E complement; I just used it here. So, then F intersection of E union E complement which I can write as F intersection E union, F intersection E complement; this is by the distributive law which I defined sometime ago for you; so therefore, in the earlier lecture. So, therefore, this is equal to this; and here again you see that these 2 sets are, ok; it should be union; be careful because we have no meaning of putting a plus sign here; these are subsets, fine. So, this is equal to this; now, here again both the sets are disjoint.
(Refer Slide Time: 07:29)
 
So, therefore, when I write probability F, I can simply write it as probability E intersection F, this probability E complement intersection F, by using our axiom 3. Now, from here, from this relationship I can now compute probability E compliment intersection F as equal to probability F minus, probability E intersection F, right. And this, I will then substitute in 1. So, I will get P (E) plus, P (F) minus, probability E intersection F. 
So, substituting this in 1, we obtain the desired result, that probability for any 2 sets probability of the union of those 2 sets is sum of the probabilities of the 2 sets minus, the probability of the intersection of the 2 sets. And it is very intuitive argument for this, for the validity of this result. Now, since you see P intersection F is a subset of E and F, both, right; E intersection F is at a common element, so they occur in E as well as in F. 
And therefore, when you are adding up the probabilities P (E) plus P (F), probability of E intersection F, gets added twice. So, I have to subtract it once to make the equation balance. And therefore, this is the result, right. And even through Venn diagram you could explain that when you; see this is A, this is B. So, probability A is this area, probability B is this whole area; when you put them together, you have added this area twice because this is your A intersection B. You have added this area twice, and therefore, you need to subtract it once, so that the 2 equations are balanced, ok.
So, you may get corollary of this result P (E) union F is P (E) plus, P (F) minus, P (E) intersection F, is that if A is a subset of E then the probability of A is less than or equal to probability of E. Now, we can write E as, because A is a subset of E, therefore I can write E as, this subset E I can write as A union A complement intersection E, right. Because if this is E and this is subset of A, so then this is A and this portion is your A complement intersection E, right.
So, therefore, and then these 2 will be disjoint sets. So, therefore, P will be P (A) plus, P (A) complement intersection E; again we are applying axiom 3 because I have decomposed the event E into sum of 2 disjoint sets, 2 disjoint events. And therefore, the probability of P (E) would be P (A) plus P (A) complement intersection E. And since P (A) complement intersection of A is greater than or equal to 0, therefore, this implies that from here that your P (E) is greater than or equal to P (A). 
So, we get consequence, and I will just put it down so that for complete in a set, otherwise one can immediately; once you have proved this result, you can conclude this result immediately. So, once you have these 3 propositions now you can see, you can get some more results; you can compute probabilities of more interesting and complex events. 
So, consider this example. Example, this says that 20 percent of Indians smoke cigarettes, 40 percent smoke bidis, and 7 percent smoke both cigarettes and bidis. So, what percentage of people do not smoke both? So, you are asking what percentage of people do not smoke cigarette as well as bidi. So, now here if I write the event E as set of people who smoke cigarettes, and F is my set of people who smoke bidis, right. 
Then, I first compute E union F. So, probability of E union F by adding the proposition I just proved is P (E) plus P (F) minus, P E intersection F, right, which is 2.2 plus 4; this is 20 percent, 40 percent, and then minus 0.07; so therefore this comes out to be 0.53. And I am looking for the, what percentage of people do not smoke both. So, if this is E union F, right; so E union F, remember, again I was talking of de morgan laws, this compliment was E compliment intersection F complement, right. 
So, this is people who do not smoke cigarettes, people who do not smoke bidis, so the intersection will give me the sort of people who do not smoke either cigarette or bidi, right. So, therefore, I am computing E union F complement. Now, here I have used proposition 2, I think 2.2. We are also; I have computed probability of E union F, so now, I want to compute probability of E union F complement which is 1 minus probability E union F; and so therefore, this is 1 minus 0.53 which is 0.47.
(Refer Slide Time: 13:09)
 
See, we have already, you have come across continuity of a function on the real line, now we want to introduce this concept of probability function as a continuous set function. And this is very useful because often when we have to take limits of sequences, of your sequences of events, and then we need to have this notion of probability as a continuous function on the sets, so that I can inter change the limit on the, in the process of taking the limit and probability, in taking the probability. So, these are what we are going to formulize. 
See, sequence of events E n is greater than or equal to 1 is said to be an increasing sequence if E 1 is contained in E 2 contained in E n, and so on, right. So, this is the notion of increasing sequence of events; and then similarly a decreasing sequence would be when E 1 contains E 2 contains E n, and so on. So, for increasing sequence E n, we define the limit of E n, n going to infinity as union i varying from 1 to infinity E i, right. 
Because, anyway, it is a increasing sequence of this in fact is E n; and therefore, there is nothing new in the definition, because these subsets are all, events are part of E n. So, therefore, union actually is, because you want to take the concept of inter changing the probability in the limit, so this is why we are doing it. For decreasing sequence E n, we defined the limit of E n as if intersection i varying from 1 to infinity of E i.
Now, the proposition is that if E n is either increasing or decreasing sequence of events then limit P E n; so here this will be mean result that limit probability E n, as n goes to infinity is probability limit of E n as n goes to infinity. So, what we are saying is that you can interchange the operation of taking the limit and taking the probability because of continuity of P on the sets. 
So, let us just quickly look at the proof. Consider the case when E n is in increasing sequence; and then we can also go with the proof when E n in decreasing sequence. So, define new set of events F i as follows: F 1 is E 1, then F 2 is E 2 intersection E 1 complement. So, therefore, you see whatever common components of E 1 are there, and E 2 they are there anymore; so F1 and F 2; F 1 is E 1; F 2 is E 2 intersection E 1 complement.
So, therefore, you can immediately say that F 1 and F 2 are disjoint, right. Then finally, this way you want to find F 1 as E n intersection union, i varying from 1 to n minus E i n complement. So, all the previous sets, E i s, you take the union and take its complement, then you take the intersection in the end so that is E F n. So, therefore, here you can see the systematically the way we have defined F 1, F 2, F n, and so on, that these are all disjoint subsets or disjoint events, right.
(Refer Slide Time: 16:32)
 
And so that is what we are saying that F i, i is greater than or equal to 1 are disjoint. Now, union i varying from 1 to n F i, is union E i, right, because I am not taking away anything; it is just the common parts I am removing, and so making these disjoint. But, otherwise all the elements of, all the components of E 1, E 2, E n are all there. So, union F i, i varying from 1 to n is union i varying from 1 to n E i. And therefore, you know, the limiting case also, this will be true, right.
Now, probability union E i, i varying from 1 to infinity is probability this, because this wholes; so therefore this is also probability of E i union i varying from 1 to infinity, F i. And since, F i s are disjoint I can write this as summation i varying from 1 to infinity P F i, since, F i s are disjoint, right; I can write this. And now, this side you see, this is nothing but limit E n by our definition, right; we defined that union E i, i varying from 1 to infinity is limit E n and goes to infinity. So, this is this. 
And from this side you see this is sigma P F i, i varying from 1 to infinity which can be written as limit n going to infinity of summation i varying from 1 to n P F i which; again here this you will write as union i varying from 1 to n F i, and then this will be limit; so this is E n, right. This part is also union F i, yes; you can see it immediately that union F i is E n because E n is an increasing sequence; and therefore, this is this. So, now this is what you wanted to show, right. Probability limit E n, n goes to infinity is equal to limit probability E n is n goes to infinity, for an increasing sequence. 
Now, when the sequence is decreasing then you see E n complements will be increasing, right; because E n s are decreasing, so E n complements would be increasing; and so you apply what we have just proved to this sequence of events E and c; and so probability union i varying from 1 to infinity E i complement is limit probability E n complement, and n going to infinity, right.
But, this union is nothing but intersection of E i, i varying from 1 to infinity complement that is what your de morgan’s law is that we have done in lecture 2 or lecture 1, I think the previous lecture. So, then this is this. Therefore, intersection E i this thing, from here, this is, because this is equal to this number because we have taken this as increasing sequence, and this is equal to this; so it follows from here, and this is equal to this, right, this thing.
And this you can write as 1 minus probability intersection E i, i varying from 1 to infinity because this is complement, probability of the complement event; so 1 minus probability intersection i varying from 1 to infinity E i. And this is same thing; you are writing probability of E n complement; so this will be 1 minus P E n. So, this comes to this side. So, here you have this. And this cancels out 1, 1. 
And therefore, this now is by your definition because it is a decreasing sequence, so by definition i varying from 1 to infinity E i is limit E n as n goes to infinity. So, therefore, you have proved the result for both. And now there we will be many occasions where we will be using, I mean referring to because P is a continuous function, continuous set function; therefore, I would be very often exchanging the process of taking the limit and the probability.
(Refer Slide Time: 20:35)
 
So, now, I will define another new concept which is the conditional probability. And we will just see that how starting from the 3 axioms I am able to develop more and more theory about the probability. So, conditional probability again I will take an example first. So, suppose you have 2 fair dice, the dice we can also call phial; all these words are synonyms. 
So, when you have the example we had considered of rolling or tossing 2 dice; then if my event A is that the first dice shows 2, and B is the event that sum of the numbers on the 2 phases is, they add up to 6, right. So, the first dice is already showing a number 2. Now, in the conditional probability, that means knowing that the first dice has shown 2, then if I want to sum up the 2 numbers on the 2 phases to be 6; and now you want to find the conditional probability of the given A.
So, therefore, see, what will be the B intersection A; that means, the first dice showing 2, and then you want the sum of the 2 numbers is 6, that means the other dice must show the number 4; so this gives you the intersection of A and B, 2, 4, right. And here, given that your first dice; so the probability that the first dice has shown 2, then the second dice can show any of the 6 numbers. 
And therefore, the probability of A, because this probability is probability of P intersection A divided by probability A. So, probability A will be the first dice showing the number 2, and the second dice is showing any of the 6 numbers; so therefore this add up to here; so the probability of 2, 4; just one of the 36 equally likely elements because we are assuming that the dice is unbiased, both the dice are fair. 
So, the probability of this pair occurring is 1 by 36; and each of these is again equally and each of them has probability 1 by 36; that is the 36 upon 36 which will be 1 by 6; and therefore the outcome is 1 by 6. So, this is how you compute the conditional probability. And so we say that probability of B, given A is the conditional probability of B given that A has occurred. 
So, once you know that this event has taken place, now you are wanting to find out the probability that B will occur. So, therefore, this will be conditional probability of B, given A; that means, you want to compute the probability of B, once you know that certain event A has already occurred. 
Now, so the formal definition would be that if P (A) is positive, that means A is an event which actually may occur. Then, if probability P (A) is greater than 0, we say that probability B conditional A is equal to probability of A intersection B divided by, probability A. So, this is the definition; and this is the valid one because we have already assumed that P (A) is positive. 
So, here we can immediately say that this implies, that probability, you can also write, the way of writing probability A intersection B is, probability A into probability B conditional A; so this is a very impotent formula which we keep using. So, let me illustrate this concept through this example. Now, in the game of bridge 52 cards are dealt are equal to the 4 players; that means, each player gets 13 cards. 
So, the 4 players are A, B, C, and D. A and C have both been dealt 7 clubs amongst them. What is the probability that B will have 4 clubs? This is the question. Now, the event that has already occurred is that A and C both together have 7 clubs amongst them. Now, we want to find out the probability that B will get 4 clubs. So, here again I am using multinomial coefficients, and I am saying that the number of ways in which 4 clubs out of; see, because they have been, there are 7 clubs amongst them; number of ways in which 4 clubs out of remaining 6; this should be 6, sorry; this should be 6 because 7 clubs have been dealt to A and C, so you are left with 6 more clubs; and therefore, this will also be number 6.
So, now, you want 4 of the, out of remaining 6 clubs you want 4 of them to go to player C, player B, right. And so if he gets 4 clubs, then that means, since he is getting 13 cards, so after the remaining 19, so this will be then 20. So, in the remaining 20, A should get 9, right. So, I have to collect the thing here also. This is 6 and this is 20. So, I am make the, I have computed this probability by using the multinomial coefficients that, you know, the 2 sets of cards; and so the choices are from 6, 4 out of 6, and 9 out of 20. 
(Refer Slide Time: 26:25)
 
And the total ways in which it can be dealt 13 cards out of the 26 cards because 26 have already been given to A and C. So, out of the remaining 26 it is given. So, total number of ways in which that can happen is 26 choose 13; and this is this. Now, you have to explain this in terms of; so I am saying that the conditional probability of B getting 4 clubs, when A and C are already been given 7 clubs, is given by that number. 
And then I would like you to know because; so just bringing it out how this will fit into this definition. And I will come back and then discus with you again a few and figure it out how this fix into that definition. Now, let me give you another extension of this concept of conditional probability; and then so just want to point out here that, you know, this is a name. So, therefore, the positive will occur, we put after s. This is the name of the, such a station.
 And so those formula which we will, as we go on we will show that it is very useful way of computing certain probabilities, conditional probabilities of course; and so we are consulting over the, telling over the formula is; and then taking some examples to illustrate how it is. So, suppose E and F are 2 events, then as I have already shown to you, I can write E as E intersection F union, E intersection F complement, right. 
Since, F and F complement are disjoint, and so E intersection F, and E intersection F complement are disjoint. And therefore, in exactly we have concluded that P E, can be written as P E intersection F plus, P E intersection F complement. Now, we can generalize this formula; because if I have n mutually disjoint P of E intersection F i, right. If you remember this then that means, I am giving you a formula for computing probability of E, by conditioning E on the F i s. 
So, if I have a set of these mutually exclusive F i s such that they add up to, the union is equal to my whole sample space omega; then I can decompose P E in this way; and then using the conditional probability formula for E intersection F i I can write this as this; and now this is a way of computing P E by conditioning E on the occurrings of F i s, into F i. Or, in other words, you can also look upon this as a; because your P F i s, summation this will be equal to 1, remember; because this is equal to this; they are disjoint. 
So, probability of union F i s will be sum of the probabilities of P F i s; and therefore that will be equal to 1. So, this is equal to 1. So, I can treat probability F i s as weights. And therefore, this formula saying that P E is the weighted average of probabilities E conditional F i by the weights P F i. So, whatever conditioning event you take here you multiply it by the corresponding weight. So, there are many ways of looking at it. 
Now, why I am discussing this is because suppose that E has occurred then you want to find out the probability of occurrence of F i. See, actually the role of the 2 events saying that suppose E, here I was computing E dependent conditional occurrence of the events F i s. Now, I am saying that if I already know that E has occurred then what can be the probability of the occurrence of a particular F i. 
Because, see, the thing is that F i intersection F j is empty; and union F i is omega. So, therefore only one of the events can occur here exactly, because they are mutually exclusive, so 2 events cannot occur at the same time; so this is occurred. So, in that case what we are saying is that when E has occurred I want to compute the probability of F i occurring, right; so that means, I want to compute the probability F i, given E, given that E has occurred. 
So, again using this formula that I just wrote it, this will be P F i intersection E divided by this; because probability E, I have just computed for you, is given by this. And this is F i intersection E by my definition of the conditional probability. So, this is this. Now, P F i, given E is the posterior probability of F i when E has occurred. So, I am going to call this as the posterior probability of F i, given that E has occurred. And so now, I take up an example to show you, what we mean by this. 
(Refer Slide Time: 31:55)
 
So, I will give you now an example of computing the base probability. And here, I am considering this example; and i you know, even in some other previous examples in the other lectures I have mentioned F i, which means that I am taking these examples from the book by Shelton Ross. And I will give you a proper, the 2 books by Shelton Ross which book I referred to while preparing this lecture; so I will give you the proper references at the end of the this section. 
So, now, let us understand this problem very well. There is an insurance company. It divides its clients into 2 classes. See, there is, somehow, there is this information that a sort of people, are both accident prone, then some others; there is some ways of computing this. And this may be because of the past history or something; you know, if somebody has had lot of accidents and somebody has not had, then you know, because it shows companies they depend on the this kind of data. 
So, let us see that class 1 is the set of people who are accident prone, and class 2 is the set of people who are non-accident prone, that means they had very few accidents in the past. Now, in the period of 1 year, the whole thing that we are looking at is during given period of 1 year, fixed period. The probability of accidents for class 1 of people is 0.4; that means, the probability of accident prone, having an accident is 0.4, and the probability of non-accident prone person having an accident is 0.2, and in that fixed period of time that you have. 
And it is also known that 30 percent of the population is accident prone. That means the number of people being in set 1, the probability is 0.3, ok. Now, suppose the event we are looking at is that a new policy holder will have an accident within a year of purchase of the policy. So, there is a person who has just bought a policy, insurance policy. And now, you want to compute the probability this person will have an accident within the year, ok; within the year of the purchase of the policy. 
So, again using this decomposition principle I say that probability E can be written as probability E condition on i into, probability i plus, probability E condition on 2; so that means this is the accident prone, and this is non-accident prone. So, probability E condition on 2, into probability 2; that means the people having accident, right; when I said that P 2, I mean that probability of a person who is non-accident prone having an accident. 
And here, this is the probability that an accident prone person has an accident. And I have this probabilities, right. I have this probability. So, the whole thing is accident for set of people in i, which I am writing in short form as P i, and for this I am writing P 2. So, this we can easily compute because this conditional probability is given to me which is 0.4, right; given that the person policy holder is accident prone; if he has an accident that probability is 0.4. And the probability that the person in accident prone, 0.3. 
So, therefore, this number is 0.4 into 0.3 plus, the probability that the person policy holder having accident when he is non-accident prone; that probability is given to me as 0.2. And then the probability that he is non-accident prone is 0.7. So, when you compute this number, this comes out to be 0.26; that means, a new policy holder having an accident within a year of purchase of the policy is 0.26. 
Now, I want to compute this conditional probability i, given E; that means, an accident; so when you look at the intersection; so this will actually be by our definition i intersection E divided by P E, right; which means that; see, if you just read this, this intersection of 2 event says that a new policy holder. That means, a person who has purchased a policy currently and is accident prone will have an accident within a year of purchase of the policy, right. If you read carefully, the event i intersection E, E simply says that a new policy holder that was a person who has just purchased the policy will have an accident within a year; I says that the person is accident prone. 
So, therefore the intersection will be that if accident prone person, the policy holder will have an accident within a year of purchase of the policy. So, that is this. And this is divided by P E, right. Now, what I will do is because, so i, given E conditional E, I do not have; but I have this probability. So, therefore, using this definition of, remember I gave you the alternative definition of intersection of the set. 
So, this is P i intersection E; I can write this as P E, given i; that means, accident prone and then the person is having an accident within a year into, P i divided by P E. P E, I have already computed as 0.26. And so here, this is 0.4 into 0.3, this I already know, right, remember, from here the first part, and so this is; so now this goes up to 0.4615. 
So, earlier probability for accident, for accident prone, right; earlier probability for an accident prone person to have an accident was for; earlier probability for accident for i was, sorry; this is 0.4, right; probability of accident for an accident prone was 0.4. But now, the posterior probability; that means, after knowing that the person had an accident, remember, I am computing now that policy holder has had an accident.
So, the probability accident prone person having an accident mean that he has had an accident has now gone up to 0.4615. So, the posterior probability of accident for the accident prone has gone up from 0.4 to 0.4615. So, actually this is a little complex concept and I will keep coming back to it through examples to make sure that you, you sort of get a better feeling for these computation of base probability, ok.
(Refer Slide Time: 39:16)
 
Now, the moment you define conditional probability, you then come to the concept of independent events. So, let me first motivate the reason, motivate the definition. And so here you see what is being said is that, if this conditional probability of E given that F is occurred, is equal to P E; that means, that the occurrence of F has no effect on the occurrence of E, right; because this probability has remained unchanged, eventhough I know that event F has occurred. 
So, these are the kinds of things because you want to know what kind of events can have effect on the occurrence of some events and so on. So, this is also very important concept and you need to know how compute it. So therefore, if this is so then you see, by definition of the conditional probability of E given F is P E intersection F divided by P F, but then we are saying that this is equal to E, probability of E, right. 
That means, I am just trying to formulize this concept that if occurrence of an event is not dependent on some sense on the occurrence of another event, then we would be defining the concept of 2 events being independent. And so this is, essentially this is what you will say; that if this is equal to this, then occurrence of F has no effect on the occurrence of E. 
And now, by our definition of conditional probability I will write it as this; that since this is equal to P E, this implies that probability of E intersection F is P E into P F. And so this is our concept of 2 events being independent. And so I will just write down the definition 2.9 which says that 2 events E and F are said to be independent, if P of E intersection F, that means, probability of E intersection F, is equal to P E into P F, right. 
So, let us look at this example. A card is selected from an ordinary pack of 52 playing cards. Now, E is the event that selected card is a king, fine; and then F is the event that the card is a club. Then, we can immediately show that the events E and F are independent which you can also argue intuitively also, that the king need not be a club, and so on. So, let us now show that; this gets validity by definition also. 
See, to compute the probability of E that the selected card is a king, so since there are 4 kings in the pack, so therefore, the probability of P E is 4 by 52. And selected card is a club, so 13 cards belong to the club. So therefore, the probability of F will be 13 by 52. And P of E intersection F is probability king of club, so that is only 1 card, and therefore the probability of that is 1 by 52. So, therefore, P of E intersection F is P E into P F which is 13 by 52 is 1 by 4; and so 4 into 4 gets cancelled. And so P E into P F is also 1 by 52. So, the 2 probabilities are equal; and i therefore, E and F are independent. 
So, if you look at this other example; 2 fair dices are rolled; and i if E 1 is the event of sum of 2 numbers is 5; and F is the event that the first dice shows 3. Then you see E 1 intersection F is simply with the event 3, 2; that means I must have the pair 3, 2, then only, you all know that this is already 3, so then this number must be 2 inorder for the sum to be 5. 
And this again the probability is 1 by 36; but P E 1 is what? That means, E 1 is the sum of the 2 numbers being 5; this is (2, 3), (3, 2), (1, 4) and (4, 1). So, these are the 4 possible pairs which will give me the sum as 5; and so this probability will be 4 by 36; each being equally likely. And the first phase showing you 3 is 1 by 6 because here again each phase is equally likely, each number is equally likely. So, then this probability of E intersection F is not equal to P E into P F. So, we will say that P and F are not independent events. 
(Refer Slide Time: 44:16)
 
Now, consider the event E which is the sum of 2 phases is 7, right. So, if I change the event from E 1 to E which requires that the sum of numbers on the 2 phases is 7; then you can see that these are the pairs which are valid, so this event. And therefore, they are 6 in number. So, probability E will be 6 upon 36 which is 1 by 6; and probability F already we have seen which says that the first dice must show number 3, so that probability is again 1 by 6. 
And so now you see that, if you look at the event E intersection F, since F says that the first dice has to show the number 3. So then for the sum to be 7, the second dice must show the number 4, so this is the only possible element of omega which is favorable to yield this section F. So, therefore, here the probability of E intersection F is 1 upon 36 which is equal to P E into P F. 
So, therefore you see, you can see how one can define events which given the event F; for example, what are the event which are independent of F, and which are not. In the earlier case when we took the event E 1 to be, the event of the sum of the 2 phases is 5; then you saw that P E n f where E 1 and F are not independent; then if I take the sum to be 7 then it says the 2 events are independent. 
And now, if you try to define another event E 2 phase which says that the sum of 2 phases is 8. Then again you can show that F and E 2 will not be independent. So, you should now play around and get a feeling for the definition by constructing different; take the same experiment that is throwing up of 2 dices; and then try to construct a set of events which are independent, which are not, and so on. So, you can get better feeling. 
Now, continuing with the, again as you see you define a concept; then using the axioms we come up to new propositions; and you see the theory keeps developing. So, if 2 events are independent then you will say that E and F complement are also independent which is very intuitive and if you able to rationalize it, but in any case, we will prove it analytically also. So, the proof is simple. 
If E and F are independent then by definition probability of E intersection F is P E into P F; and i since we have already seen that you can write P E as probability of E intersection F, plus probability of E intersection of F complement. So, then we want to compute this; so this will be, from here probability of E intersection F complement will be P E minus, from here P intersection F, but then because E and F are independent.
So, P E intersection F, I can write as P E into P F; and so you see this comes out to be P E multiplied by 1 minus P F. I can take P E common outside. 1 minus P F is probability F of complement. And therefore, probability of E intersection F complement has been shown to be equal to P E into P F compliment; and therefore, by our definition E and F complement are also independent. And which says that if occurrence of F has no effect on the occurrence of P; and when I say occurrence that means the probability we are talking of. 
So, E and F being independent shows that occurrence of F is not equal to the occurrence of E. Therefore, occurrence of, non occurrence of F shows somewhat have an effect on E. So, that is what we have concluded, that if E and F are independent, then E and F complement are also independent. 
Then, now here, I am again just make it a statement and I want you to construct examples for yourself, so that we are saying is that, if suppose E and F are independent, and E and G are independent, then E may not be independent of F intersection G. Now this may not sound very intuitive. But, you can construct sets E, F and G to show this, right; so that means, now, I have already told you to explain this the example that I took earlier. 
And now I want you to also construct sets E, F and G, construct an experiment; and then construct the corresponding events E, F, and G to show that if E and F are independent, and E and G are independent then E may not be independent of F intersection G. And infact, you can, you know, that the throwing of 2 dices that I have taken up to experiment. And there also you can construct such E, F and G to show this is valid, this statement is valid. But then I can come back and discuss some examples with you. 
Now, if you want to extend the concept of independence of 2 events or more than 2, then I will just show how things start becoming difficult, even if you just take the, want to extent the concept to 3 sets, that means if 3 events E, F and G are independent then we require that not only should the probability of intersection of E with F with G. And intersection with G should be equal to the product of the individual probabilities. 
But, when you take 2 at a time, these 3 sets, from these 3 sets, then P of E intersection; that means, any 2 subsets here should also be independent. It is not just that the product of the, probability of the intersection of the 3 sets is equal to the product of the individual probabilities, that when you take 2 at a time then also that should be, the condition of independent should be satisfied. So, all 4 conditions have to be met before we can say that the 3 sets, E, F and G are independent.
(Refer Slide Time: 51:02)
 
So now, here again we need to construct; and we can immediately see that the moment you have increased the number of sets, and you want to talk about their independence, then this will get more complex; and the number of conditions will go on, becoming larger and larger. So, therefore, I just leave it at this point for this thing. And then one can always look up at textbooks where they will give you conditions for any independent sets, I mean, any number of subsets. 
So, here again a interesting way to try to understand this concept would be to construct subsets E, F and G which may satisfy not all the conditions, but only some, to show that all 4 conditions are necessary for independence of the 3 events, E, F, and G. So, I will now take up set of exercises too, and then we will come back to constructing examples for these situations.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 4
Random Variables Cumulative Density Functions Expected Value

(Refer Slide Time: 00:18)
 
Let me fill up a few gaps in the last lecture. So, for example, this was I had discussed this card game bridge game; there was an example number 2.7, which I was talking about a game of bridge in which 26 cards have been dealt to people to the players a and c. If you remember there were 4 players a b c d. So, 26 cards have been dealt to the players a and c with 7 clubs. So, we wanted to compute the probability that player b gets 4 clubs, right. Now I was trying to say that I was trying to show this as an example of computing the conditional probability that is already 7 clubs have been dealt two players a and c.
So, what is the probability of b getting 4 clubs? But now I wanted to then show you that, and, of course, we solved out the problem; I told you this is the probability, but then it is not possible to explain this through the conditional probability argument. So, therefore, I just want to tell you that there are other ways of computing this probability and that is by reducing the sample space. So, now, instead of you know taking the distribution of 52 cards to the four players; I am just reducing the sample space, because 26 cards are now left, out of which 6 are clubs because 7 have already been distributed to players a and c.
So, then this is now your multinomial distribution. So, what you are saying is that out of 6 clubs, b should get 4, and then from the remaining 20 cards, he should get the other 9 cards. So, that way he gets 13 cards. So, this is the number of ways in which he can get 4 clubs out of 6 and 9 cards out the remaining other 20 cards. So, this is the number of ways in which this can happen, and the total number of ways in which he can get 13 cards out of 26 is 26 choose 13. So, this is the actual probability, and this we can get by reducing the sample space. So, this is another technique which is very helpful and at times you can very easily compute the required probability by doing this, right.
So, you do not have to always go through the actual formula; you can always play around with alternative ideas also, okay. Now remember I asked you to construct examples when we were talking of independence of three sets, right. And in that case, I showed you that there are four conditions which have to be satisfied before you can say that the three sets are independent. And then I asked you to construct a counter example to show that suppose the last three are satisfied; that means pair wise, if we choose any two sets from here, they are independent. They satisfy the condition of independence; that means your probability of e intersection F is p e into p f probability of e intersection g is probability of e into probability of g, and similarly probability of F intersection g is product of the probability p F into p g.
So, you can construct situations where let us say last three conditions are satisfied, but the first one is not satisfied. And so I believe into leave my hand on this example here. Suppose your sample space consists of these four numbers. So, where each number is equally likely; that means the probability of any number coming up as a result of the experiment has probability of 1 by 4, because they are equally likely, and there are four elements in omega your sample space. Now let us choose e to be as consisting of the numbers 1 4; F to be consisting of the numbers 2 comma 4 and g 3 comma 4, alright.
In that case, you see if you see the probability of P e p f and p g is 1 by 2 because there are two numbers totally four. So, 2 by 4, again we are using the same concept, because outcomes are all equally likely; therefore, I am using the m by n version of the probability. And so this is half for each of the sets, then probability e intersection F. Now e and F have only four in common. So, that is one singleton, and that probability is 1 by 4 which is the product of p e into p F.
So, similarly, you see that the pair wise independence has been you can easily verify that the three sets are pair wise independent, but when you write e intersection f intersection g that again results in single number 4. And so this probability is 1 by 4, but this is not equal to p e into p F into p g which is 1 by 8, okay. And, therefore, now you get an idea and you should try to construct one example of your own to show that pair wise independence of three sets is not enough to say that the three sets are independent I mean the three events are independent, right. We should be able to construct and as I said that extending this becomes little more cumbersome and so we will leave it here only, right.
(Refer Slide Time: 05:41)
 
Now exercise two, of course, I have given you the corrected version, okay. So, this is there, and question ten in exercise two, I want to revisit because when I was reading it last time; I said that this needs a little thought. And so let us revisit the problem. So, actually you are given the data that a battery as a lifetime. So, there is a probability that the battery will last for more than or equal to 10000 kilometers that probability is given to be 0.8. And the probability that it will last more than or equal to 20000 kilometers, the probability was given as 0.4 and then that it will more than or equal to 30000 kilometers also a probability is associated with it.
And you were asked to find that if you have bought a battery which is already run for 10000 kilometers what is the probability that it will be running for more than 20000 kilometers; that means its lifetime will be more than 20000 kilometers if it is already run 10000 kilometers. So, this is a simple case of conditional probability computing the probability that the lifetime say if I let l, denote the lifetime of the battery. We are wanting to compute the conditional probability of the event that the lifetime is more than 20000 kilometers given that it is already 10000 kilometers old the battery; it has run that much and so by our formula.
Now when you take the intersection of these two, so obviously, this is a subset of this. And, therefore, the intersection simply becomes l; that means you are wanting the lifetime to be greater than or equal to 20000 kilometer when it is already run for more than 10000 kilometers, right. So, the intersection of these two would be this, because you want the battery to run 10000 kilometers and you want the battery to run 20000 kilometers. Intersection would mean that you want the battery to run for more than 20000 kilometers and so this is divided by the probability of this event which is l greater than or equal to 10000. And, therefore, this is equal to 0.4 by 0.8 which is half. So, this is the solution.
So, I just thought that if you have thought about the problem may be some of you have already done it but then this is the right answer, okay. We have talked of condition probability but I just thought that should formulize this in some more in the sense that see we are defining now given an event a, then we are computing the conditional probability of events conditioned on f, right. So, want to show that this is the function that you have defined here that conditional probability function satisfies the three axioms of probability and not too difficult to compute to show, because the first axiom requires that this for any event e, the conditional probability with respect to F must be within 0 and 1, alright; that is the first axiom,
So, here if you take probability e condition on F, then by definition this is this. Now you see that e intersection F is a subset of F, alright; this is a subset of f. And, therefore, we have already shown remember after giving the axioms, we proved some propositions and there I showed that if subset is subset of another subset, then the probability would be. So, that means here probability e intersection F will be less than or equal to probability F, alright. This is because this is a smaller event in the sense that it is a subset of this; therefore, the probability of this is less than or equal to this; this we could easily show, right.
And by definition, of course, probability e condition F is nonnegative, alright. This is nonnegative; this is nonnegative. So, this is nonnegative. So, therefore, the first axiom is satisfied, because p intersection F is less than p f. So, I divide by this; this is less than 1, and this is nonnegative. So, first axiom is satisfied. Now second axiom said that your probability omega should be one so here for us because we are conditioning on f. So, the corresponding axiom would be that probability, okay; this should be again the same thing. I have to say that omega condition on F, so what will this be? This, and, therefore, now when you take omega intersection F, this will be probability F this is equal to 1, right, okay. So, therefore, probability f divided by probability f is 1. So, probability for mega condition on f is 1. So, the second axiom is satisfied and the third one requires e I intersection f divided by p f.
(Refer Slide Time: 11:36)
 
Now this I can write as see here this is this, then because distributive law holds, this can be written as union e I intersection F, I belonging to I this thing. Now because e I intersection F are disjoint, since, e I are disjoint, right. I have taken sequence of disjoint events e I is here. So, e I intersection F r disjoint and probability p, the original probability function satisfy axioms three, alright. And therefore, this can be written as summation of probabilities e I intersection F divided by p F, alright, which is equal to. So, this can be written as summation probability e I condition F, alright, I belonging to I. So, the third axiom is also satisfied.
Therefore, the conditional probability function is also a probability function; that is it satisfies the three axioms, okay. Now again I just want to continue working because conditional probability function is an important concept. So, again little elaborated example that I would take gamblers. Oh, here fine. So, this problem would be coming after I define for you the conditional probability. Now I want to discuss the Gambler’s Ruin problem which is interesting example of use of conditional probability. So, let us see there are two gamblers a and b, and they bet on the outcome of the toss of a coin, alright.
Now if on each toss if h occurs that means if the head shows, then a collects one unit from b and if tail occurs; that means if t occurs, then b collects one unit from a. So, this is all a simple game. You toss a coin and then if the head shows, a gets the money, and if tail shows, b gets the money from a, okay. Now tossing of the coin continues till one of them runs out of money. So, that is the Gambler’s Ruin problem, right. So, one of them will end with all the money and the other one will have no money left. So, suppose total money is 15 units, I am just taking a number 15.
You will see that through a solution, it does not matter; whatever the amount of money that they start with and has I units. So, that means b will have 15 minus I units with him, okay. Now tossing of the coin are independent events, and we are assuming that the coin is biased. So, therefore, probability h is p and probability is 1 minus p. We will also consider the case when p is half, okay. Now if we want to find the probability that a ends up with all the money and we have assumed that at the starting point, a had I units of money with him, alright. So, let e be the event that a ends up with all the money and let p i denote the probability because we are staring the game when a had I units. So, I am just denoting it by p I which is the probability of e ending up with all the money and a had i units to start off, right.
(Refer Slide Time: 14:59)
 
Now we have been using this technique very often, because when you are tossing a coin, your sample space is consisting of just h comma t, right; two points on the sample space. And so you can write p e in terms of conditional probability p given h; that means now this we are saying that we are starting the game. So, the first toss of the coin either results in h or in t. So, this is conditional of e; that means this is the probability of e this is the event that a ends up with all the money starting with I units when the first toss results in head. So, this is that event, right.
So, that into p h plus this is again the similar interpretation that a ends up with all the money when the first toss of the coin shows a tail, alright. So, this is this into p t. Now when the first toss of the coin gives you head, then a collects one unit from b. So, therefore, the money at the end of this after the first toss, a ends up with money I plus 1, alright, and if the first toss shows a tail, then a will have to give one unit of money to b, and therefore, he will have I minus 1. So, therefore, as I said in the beginning, I am denoting by this p I because a had I units of money when the game started.
So, therefore, this equation can be rewritten as p I is equal to p I plus 1 because this will be then the probability that now a has I plus 1 units, and you want to compute the probability that a ends up with all the money, alright, and then this into p; probability of getting a head, then here a will lose one unit of money to b. So, it will be p I minus 1 into 1 minus p. So, 1 minus p we can also write as q. Now since p plus q is 1, I can multiply this by p plus q and write this equation in this way, alright. And then rearranging the terms that means see p I plus 1 minus p p i I bring here, and p I minus q I take to this side.
So, I get this equation from this equation, and that gives me that p I plus 1 minus p I is equal to q by p into p I minus p i minus 1. So, I get a recursive relationship between this p I’s, okay. And boundary conditions are that if p had no money; obviously, the probability of his ending with any money is 0, because, he will not be able to play the game, alright. So, p 0 is 0 and p 15 because the moment he has won the game and so the probability is 1. So, p 15 is 1, okay, and p 0 is 0, alright. So, therefore, now we use this recursion and we start with I equal to 1. So, when I is equal to 1, this will give me p 2 minus p 1 is equal to q upon p; p 1 minus p 0. So, p 0 is 0.
And therefore, I get this equation, then when I put i equal to 2 in this recursion, I will get p 3 minus p 2 equal to q by p, p 2 minus p 1, but p 2 minus p 1 from here is q by p p 1. So, it will be q by p whole square p 1. And so this way you can go on writing the differences. So, p 15 minus p 14 will therefore become q upon p raise to 14, because whatever the number here and that is 1 less than this. So, the power of q by p is 14 into p 1, alright. Adding up, we obtain; so now I add up all these equations, then you see these things will cancel out in pairs, alright, and you will be left with p 15 minus p 1, but p 15 is 1.
So, this is 1 minus p 1 is equal to and on this side q by p you can take outside. So, it will be 1 plus q by p plus q by p whole square and so on up to p raise to 13 into p 1, alright. And now this is a geometric series; I can write down the sum. So, this will be 1 minus q by p raise to 14 upon 1 minus q by p. Now this is a finite geometric progression. So, therefore, it does not matter. The only thing I need is that I can do this if q by p is not equal to 1, alright, because, otherwise, I will be dividing by 0.
(Refer Slide Time: 19:28)
 
So, if q by p is 1, then p 15 minus p 1 you immediately get is 14 p 1; in the last equation you substitute q by p is 1 everywhere. And so from here, you will get p 15 is 15 p 1, alright, because p 1 gets added here. And, therefore, p 1 is 1 by 15, and now you can easily compute your p 2, p 3 and p I, okay; by going backwards you can compute your this thing, fine. So, we consider the case when q by p is not 1; in that case, what we got from the last slide is 1 minus p 1 is q by p 1 minus q by p raise to 14 upon 1 minus q by p using the geometric progression series sum.
So, if you take p 1 to this side, then you get this. And now you just simplify, and after simplification, you will get that 1 minus q by p raise to 15 upon 1 minus q by p into p 1 is 1. So, p 1 is 1 minus q by p upon 1 minus q by p raise to 15, alright. And so the required probability again from your recursion equations, you will immediately get that required probability p i; that means when a started with I units of money would be 1 minus q by p raise to I upon this, because that sum will be up to q by p raise to I minus 1 and so you will get this. So, you substitute for p 1, so 1 minus q by p will cancel out, and you will get this, alright.
So, now if you want to find the probability that b ends up with all the money replace p by q and I by because now for b the p is q and the money that b starts with is 15 minus I. So, when you make these two replacements, you will again get the formula for using the probability that b ends up with all the money, alright, okay. 
(Refer Slide Time: 21:31)
 
Now again continuing with some more results on conditional probability; so this is proposition of 2 point 5. What we are saying is that suppose you are given that conditional probability of a given b is 1, then you can show that conditional probability of b complement given a complement is 1. So, here I could have also given this as an exercise, but I just thought I will show you some more ways of doing it and then you can apply it to; for example, I think you can show that conditional probability of a complement given b will also be or okay, that will be independence, fine, alright.
So, right now just look at the definition. So, the conditional probability of a given b is this. Now since this is equal to 1, it follows that probability a intersection b is p b. So, the moment you get this result, you can see that a probability a union b which is written as p a plus p b minus p a intersection b this will because this thing is 0 p a intersection b minus p b. So, it reduces to p a. So, therefore, your probability a union b reduces to p a, alright, and, therefore, when you take the complement of a union b. So, probability of a union b complement will be 1 minus p a, which is nothing but probability of a complement and so then again by De Morgan’s law we had seen that a union b complement will be a complement intersection b complement.
So, this probability is, therefore, probability of a complement, alright, and hence, your probability of b complement conditioned on a complement is this. Now since these two things are the same, therefore this reduces to 1. So, one can go on, and, therefore, now the idea would be that you should get interested enough to try out many more results related to conditional probability, solve more examples, okay. Now final result on conditional probability is now this is conditional independence. Remember we defined independence of two events if the probability of the intersection of the two events is equal to the product of the individual probabilities.
Now same thing gets extended. So, we say that e 1 and e 2 are said to be conditionally independent given that event F has occurred. So, if probability e 1 conditioned on e 2 intersection F is probability e 1 conditioned on f; that means the occurrence of e 2 the same definition that we gave for independence of two events. Occurrence of e 2 has no bearing on this probability, alright. So, that means when you condition it on e 2 intersection F, it is the same as conditioning on F and e 2 has no role to play, alright. Now in fact so we will just write it out. So, this is one definition but you can come to a better result and this is we say that e 1.
So, therefore, by definition e 1 condition e 2 intersection F, this probability can be written in this way, alright. And this is given to be by the definition of e 1 e 2 being conditional independent; this is probability event e 1 conditioned on F, alright. So, therefore, from this two, you get that this probability is equal to e 1 F and this probability of e 2 intersection F I can write as e 2 conditioned on F into p f, alright. So, this is the result and this one also again now I can condition on f. So, this will give probability e 1 intersection e 2 conditioned on F into p F and this. So, p F p F cancels out, because remember, whenever you talk of conditional probability with respect to the event, then that probability has to be positive; otherwise, you cannot define it.
So, of course, it is understood that p F is greater than 0. So, therefore, I can cancel out p F here and I will be left with probability of e 1 intersection e 2 conditioned on F is the product of the individual conditional probability is that is probability e 1 conditioned on F into probability E 2 conditioned on f. So, this is you just extend the original definition of independence of two events to in the same way, and so I will take up now an example a little elaborate example to show you the use of conditional independence. 
(Refer Slide Time: 26:18)
 
After defining conditional independence of two events respect to the occurrence of another event, I will now take up this example. It may look a little complicated, but it shows good use of concept of conditional independence. So, here again this example I have taken from Sheldon Ross. Surprisingly, this book I will give you the reference later on. It has lot of new and innovative examples, and, therefore, I am using a quiet few of them here in this course. So, now consider the situation when there are k plus 1 coins in a box, right, and the probability of choosing the I th coin there k plus 1 coins in the box and if I pick up the I th coin and toss it.
Then the probability of its showing a head I th coin shows a head is I by k and I varies from 0 1 to K. So, that means, you can see that when i is 0; that means if you pick up the zero th coin, then the probability of its showing a head is 0, which means both sides must be tails. Then if you happen to choose the second coin, the probability of its showing a head would be 2 by k, alright. And similarly, if we choose the coin the k plus 1 th coin which has the number k, then the probability of showing a head would be k by k which is 1. So, probably this particular coin the k plus 1 th coin is having head on both sides. So, whatever it is, the situation is this.
Now a coin is randomly selected from the box and is repeatedly tossed, this should be repeatedly if the first. So, let me just make the correction here. So, it is repeatedly tossed, okay. If the first n tosses all result in heads, what is the conditional probability that the n plus first toss will also result in a head. So, that means I pick up a coin at random from the coins which are there in the box. Then I repeatedly toss it and if the first n tosses have shown heads, then I want to compute the probability that the n plus first toss will also result in a head. So, let us see; we will start finding out how to compute this probability.
So, suppose c I is the event that the i th coin is initially selected and this could be any of the 0 1 to k numbered coin, alright, then F n is the event that the first n tosses resulted in heads. And then h is event that we want. So, n plus first toss results in head. So, I want to compute the conditional probability of h given F n, given that F n has occurred. So, we have had n tosses and now I want to compute the probability that the n plus first toss will also be a head; we will show head. And this is the expression. So, I am going to derive it for you.
Since, one of the k plus 1 th coin will be selected, right. So, then F n can be written as F n union c I because at least one of the coins. So, this probability, probability of c I union c I, I varies from o to k will be 1, alright. So, F n can be written as F n union I varying from 0 to k c I, and therefore, probability h conditional F n which can be written as this, then from F n I can write this expression union F n intersection c I, alright, and again by the distributive property of intersection and union, I get that this can be written as probability of union I from 0 to k h intersection F n intersection c I, alright, because this is this and then this because you see all the c I’s are mutually exclusive, right, because one of the coins will gets selected.
So, therefore, these events become mutually exclusive and so probability of the union can be written as sum of the probabilities, I varying from 0 to k h intersection F n intersection c I divided by p F n, alright.
(Refer Slide Time: 30:57)
 
Now this cone I can write in terms of conditional probability as h condition F n intersection c I into probability f n intersection c I divided by p F n, alright. Then this remains this; this again I can write in terms of conditional probability c I condition f n into p f n. So, p f n p f n cancels because f n is given event. So, therefore, probability f n cannot be zero. And so I get this expression which is written here, alright, okay. Now it is reasonable to assume that repeated tosses of the I th coin are conditionally independent. This is I am using the concept; that means to assume that the repeated tosses of the I th coin are conditionally independent with respect to of f n.
That means see I am considering the case when coin was picked up randomly, then it resulted in tosses showing heads. And now when I tossed further, so then they will be conditional independent of f n, okay, which means that probability h condition f n intersection c I is actually probability h condition c I only. So, f n has no main role to play here, right; this is what our definition of remember we said that e 1 given e 2 intersection F. If I wanted to say that e 1 and e 2 are conditionally independent with respect to F given that F has occurred, then this is probability e 1 F; that means e 1 and e 2 are conditionally independent when F has occurred.
So, then e 2 has no role to play on the occurrence of conditional happening of e 1 given F. So, the probability would be independent of the event e 2. So, the same thing here we are saying that here F n because it is conditional on F n. So, this probability is F n has no role to play here and so probability h given c i. So, this is what we are assuming here, and therefore, each of this probability is I by k, alright. So, now that means I can now apply this in the formula here and this is I by k. So, that means you are getting because you have got n heads have shown up and probability of each head is i by k, and I am assuming that the tosses are conditionally independent.
So, therefore, this is I by k raise to n and the n plus first toss gives you a head will be 1 upon k plus 1 because there are k plus 1 coin there. Sorry, so this probability is what am I writing here, yeah, c I f n. So, h given f n so let me just check out here. This is c I f n, right. So, a probability of picking up the I th coin. So, again if we just pick up the I th coin that probability should be 1 upon k plus 1, because any of these coins are equally independent, remember. A coin is randomly selected; so that means any of the coins is equally likely when you pick up from the box. So, therefore, the probability of picking up a coin is I by k plus 1. So, therefore, this becomes this.
And, similarly, here, yeah, so actually what is happening is that c I f n; yes, I missed out on the spot. So, probability is c I given F n I have rewritten as this. So, this is probability F n condition c I into p c I and then this is sigma j varying from 0 to k F n. So, the probability f n I am writing in this way f n condition c j into p c j. So, this is where so now probability f n given c I is since the things are conditionally independent, the probability of picking up a head remains the same. So, when you want to pick up n heads, this will be I by k raise to n and probability c I will be 1 upon k plus 1, right. And then here similarly this is summation.
So, j varying from 0 to k j by k raise to n and 1 upon k plus 1, because now here your j is varying; this corresponded to the I th coin that you have chosen. So, this is the thing. So, this is just a computation I wanted to illustrate maybe you can say that it is an engineered problem or whatever it is, but somehow you could make use of the concept of conditional independence and arrive at this result. And again through methods of calculus, you can actually show that if k is large, then this probability is approximately equal to n plus 1 upon n plus 2, okay.
So, therefore, it gets simplified when you have a large number of coins in the box, but, otherwise, continuously you broke up the. So, here in this expression, yes, c i conditional f n; this also I had to rewrite in this decomposed form and then apply the probabilities to get this expression. So, that was missing here, yeah, okay, fine. So, this is an example and often there will be situations when you would be coming across the concept of conditional independence. Let me discuss exercise two with you; again I will just try to give you brief hints.
(Refer Slide Time: 37:02)
 
Question one says that you have to compute the probability that only exactly one of the events e and F occurs and that is equal to probability e plus probability F minus 2 and of course when we say minus 2 probability e f; that means e intersection f. So, that notation is also acceptable; you do not write the intersection sign. You simply say e F; so that is what it means, right. Now if e F and g are three events, then you have to find expression. So, again I am just wanting you to be familiar with how you write express events in terms of your complements, union and intersection. So, here I want you to write, find expression for the events, so that of the three events e f and g, only e occurs.
So, if you want to write this, then in the two you have to write exactly two of them occurs, right; exactly two of them occur. So, the third one should not occur. So, you can imagine that you will have to use unions and complements, right. Now in question three, this is actually very simple; the slash sign the condition sign is sort of dim but anyway. So, this says that if probability a is greater than 0, then show that probability of a intersection b condition on a is greater than or equal to probability a intersection b condition on a union b. So, that is very straightforward actually.
 (Refer Slide Time: 38:35)
 
And now you have to show that the conditional probability of a intersection b given a is greater than or equal to conditional probability of a intersection b given that a union b has occurred. So, it is very simple, because you see a is a subset of a union b, and as we have already discussed that probability of a union b will be greater than or equal to probability of a, right. And in the left hand side when you compute the conditional probability, you will have a in the denominator. Numerator is probability a intersection b because a intersection b intersection a is again a intersection b. So, this is what actually you have to figure out.
And, similarly, on the right hand side, the numerator is the same, but denominator would be probability of a union b. And since probability a union b is bigger or equal to probability a, you have the required inequality. So, I just gave it to you to be able to just you know figure out these things, and therefore, then you can answer the question. So, if you write the expressions, you can immediately give the answer to this question. Now the problem four is from Sheldon Ross; actually it should say Sheldon Ross or Ross Sheldon. In answering a question on a multiple choice test, you know where you have more than one choice and you have to take the right one.
A student either knows the answer or she guesses. Let p be the probability that she guesses. Assume that a student who guesses at the answer will be correct with probability 1 by m, where m is the number of multiple choices, right, because if she is guessing, she does not know. So, out of the m choices, any one of them is equally likely; so the probability is 1 by m. What is the conditional probability that a student knew the answer to a question given that she answered it correctly and I have given the answer here. So, now what are we saying what is the conditional. So, please enter probability.
What is the conditional probability that a student knew the answer to a question given that she answered it correctly? So, use the concept of conditional probability and then you should be able to do it, right. And now again this problem is from Sheldon Ross; at a certain stage of a criminal investigation, the inspector in charge is 60 percent convinced of the guilt of a certain suspect, okay. So, his conviction is that the 60 percent; that means 0.6 is the probability of the person being guilty. Now suppose that a new piece of evidence shows that the criminal has a certain characteristic such as left handedness, baldness, brown hair, etc.
So, it tells out that through some eye witness who may have seen the criminals of doing the act, the eye witness can only say that the person was either left handed; one of the characteristics is owned by the criminal is uncovered. So, through some facts, it is found out that whoever committed the crime has one of the characteristics, right. If 20 percent of the population possesses these characteristics that means in a town, crime has taken place and so what they are saying is that 20 percent of the population possesses this characteristics. How certain of the guilt of the suspect should the inspector now be? Instead of how it should be now be, if it turns out again, yes, if it turns out that the suspect is among this group.
So, now this is the situation for computing the base probability because you see first initially the inspector is 60 percent convinced of the guilt of a certain person. Now it has been know that the criminal possessed some characteristic which it turns out that this suspect has that characteristic. So, therefore, the probability of the suspect being a criminal would go up. So, the posterior probability after knowing that the criminal possesses the characteristic will go up. So, therefore, I want you to compute the posterior probability here.
Problem six says a parallel system functions whenever at least one of the components work. Consider a parallel system of n components and suppose that each component independently works with population 1 by 2, find the conditional probability that component one works given that the system is functioning. So, here you have to use concept of independence and the conditional probability.
(Refer Slide Time: 43:35)
 
Problem seven says that you have to either prove or give counterexamples to the following statements which are self explanatory. You should be able to either show that the statement is valid; otherwise, you construct examples to show that it is not. Now problem eight I am asking you to show that if e F and g are independent, then you have to show that e is independent of F union g. See remember now here I am using the definition of three events being independent. So, you have these four conditions that will be satisfied and then you can easily show that e is independent of F union g. In fact, whatever subsets you find by operation of you know taking intersection, union or complement and then taking operations on those.
You can show that e will be independent of any of such event which is obtained by doing the operations of intersection, complement and so on from F and g; this is what we are saying here. Now store a b and c have 50, 75 and 100 employees and respectively 50, 60 and 70 percent of these are women, alright, okay. So, that means store a has 50 employees and of which 50 percent are women. So, you can immediately say that 25 are women. Similarly, 75, so 60 percent of the employees in store b are women and then 70 percent of the employees in store c are women, alright.
Resignations are equally likely among all employees regardless of sex. One employee resigns and this is a woman; what is the probability that she works in store c? So, now here again I am asking you to use Bayes formula to compute the probability, okay. So, one employee resigns that is given, and this is a women. So, this is also given; that means a women employee resigns, you have to find out the probability that she works in store c. Tenth, the probability that a new car battery functions for over 10000 kilometers is 0.8. The probability that it functions for over 20000 kilometers is 0.4, and the probability that it functions over 30000 kilometers is 0.1.
So, these are all conditional probabilities. If a new car battery is still working after 10000 kilometers, what is the probability that its total life will exceed 20000 kilometers and then its additional life will exceed 20000 kilometers? So, problem ten, we will have to answer; yeah, okay, maybe we will leave out problem ten from here and we will revisit it later on. But problem eleven you can answer easily. Suppose that a person chooses a letter at random from reserve. So, instead of chosen suppose a person chooses a letter at random from reserve; that means it can be any of the letters r e s v and then chooses one at random from vertical.
What is the probability that the same letter is chosen? So, this of course is your earlier from counting the number of combinations that are favorable to this thing; that means see the two letters that are common between these two words are r and e; that is it, right. So, you have to now find out the number of ways in which r will get selected from both or e will get selected. And you can see that for example in the first word reserve, r appears twice out of r e s e r v e and r in vertical appears only once. So, you can accordingly find out the probabilities and then find out that and since the operation of choosing letter from reserve and from vertical are independent events. The required probability would be the product of these two.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 5
Discrete Random Variables and their Distributions

(Refer Slide Time: 00:19)
 .
I will now introduce the concept of random variables. So, the whole idea is let me begin by giving some examples first. Suppose two dice are thrown up, and they are fair dice. So, you can say that may be two fair dice are thrown up. Now, let X denote the sum of two numbers that show up, that means the two numbers whatever 3 4, 1 2 whatever the two number show up when I throw the two dice, I add up the sum, I add up the two numbers and I denote that sum by X. Now, we can see that the number the values of X will vary from 2 to 12. 
Now, since the outcome of tossing of the two dice is not certain, so that is a random phenomena, because any phase can show up, so any number can show up. Therefore, you see that the value of X is dependent on the tossing of the coin and whatever the outcome. So therefore, this is what we mean by a random variable, so this is actually now you can see that. Before I start calling it a random variable I should explain more, see when X is equal to 2 when it corresponds to the point 1 comma 1 of the sample space. I had earlier in my lecture shown you, when we were talking about when I introduce the concept of sample spaces. 
I had shown you that omega the sample space will contain 36 pairs of such points i j, where i varies from 1 to 6 and j varies from 1 to 6. So, when X is equals 2, this actually corresponds to the outcome 1 comma 1 of the sample space both the phases much show one each, and therefore the sum will be 2. Similarly, X is 3 then it can be either 1 comma 2 or 2 comma 1, so both of them add up to 3 and so on. So, essentially trying to say, so one can now give a formal definition of random variable that is, so X is a real valued function that maps the sample space omega into real line. 
And we call, so these X what we have described so through examples, this X is called a random variable and subsets, because these are all subsets this is the singleton, this is the subset containing two points of omega and so. This is the again the number when X is 12, it will again corresponds to the singleton 6 comma 6. So, such a function which is a real valued function, and when it maps the subsets of the sample space corresponding to an experiment to real numbers, we will say that it is a random variable. Now, if you again taken other example considered the experiment of tossing a coin, till two consecutive heads appear. So I toss a coin and unless I get two heads consecutively I will not stop. 
Now, the sample space can be if it happens in two tosses then I will get the outcome will be H H null stop here, but if you does not show head in the first trial, then it may show in the second and third, so that means this will happen in three trial, three tossing of the coin and so on. So this will continue, and this may not have finite process this may not be a finite process, because you may continue throwing up to a tails. So now, X is number of toss is required for two consecutive heads to appear. 
(Refer Slide Time: 04:01)
 
So, you see here for example in this case X will be equal to 2, then it corresponds to the outcome H H. If X is 3 then it corresponds to the outcome T H H. First toss gives you tail, and then the other next two tosses give you heads. Then X equals to 4 will correspond to this, and so you can go and writing different values of X, what will be corresponding subsets of the sample space omega. So, again I will reiterate the same thing that since the value of a random variables are determine by the outcome of an experiment. We can assign probabilities to the values it takes, because the probabilities associated with the outcomes of the sample space. 
And since random variable is mapping subsets or this event from the sample space to real numbers, I can assign probabilities. So, for example in throwing up of two fair dice, see even probability X is equal to 2 would be then in that case, probability of the singleton 1 comma 1 which is 1 by 36, because every pair each of the 36 pairs is equally likely, since the two dice of fair. Then when probability of X equals to 3 would be corresponding to the probability of the subset containing the pairs 1comma 2 and 2 comma 1, so this will be 2 by 36. So, just for your benefit, in fact you can complete you for completed the table by yourself. 
So, this I will shown you for all different values of that X can take from 2 to 12, what are the corresponding subsets, and then the associated probabilities. And since, one of the X must take one of the numbers, since X must take one of the numbers from 2 to 12, since you are throwing up two dice. So, two numbers will show up and there sum will be one of the numbers from 2 to 12. So, then these are all possible around events that can take place. And so, probability X equals to I from to i vary in from 2 to 12 should be 1, so this is the probability mass function, as we are I going to formally define the concept of probability mass function now.
(Refer Slide Time: 06:17)
 
So, the random variables can be of different types, let me first consider the case when X is the discrete random variable. So, as the names suggest, it means that it takes countable number of possible values. And let say that the random variable takes the values a i, i varying from 1 to infinity. Now, of course when I say countable countably infinite or countabley finite, it can be either case, but the values are sort of you can enumerate the values that it will take. Now, so therefore we will say that probability X equal to a i is positive, because these are the values that it takes and therefore they will be positive probability associated with each of the these numbers. 
So, this will positive and for all of the values of X it will be 0, that means when x is not equal to a 1 a 2 up to these thing, whatever the number of a i, then the probability at points which are not equal to any of these values is 0. Now from axiom 3, since X must take one of the values a i, therefore when you add up the probabilities 1 to infinity, all these probabilities must add up to 1 by your axiom 3. Now, this function which assigns probabilities to different values of a random variables that is called and in the case when it is a discrete random variable, we call it the probability mass function. 
And as we have already seen the any probability function must satisfy 3 axioms. So here, in short we also write pmf for probability mass function, all the time you can are go and writing these 3 letters. So, normally I will be referring to it as pmf. Now, it helps to plot p x on the x y plane, so consider the probability mass function p (1) is 2 by 3, p (2) is 1 by 6 and p (3) is 1 by 6, so the random variables here is taking the values 1, 2, 3 and these are the probabilities associated with it. So, you can draw a bar chart, so the idea is that you I know erect rectangles, so the height here is, this height is 2 by 3 and this height will be 1 by 6. So, that means the rectangle bar is centered at the value 1 and the height is 2 by 3, so this is the idea. 
Similarly, here this height of the bar is 1 by 6 and same as 3. Now, you I have already was to give you one other random variable, which shows giving you the sum of the numbers that show up when you throw to a fair dice. So, you can try to draw the bar chart for that random variable that will be a big one, because the values will takes from 2 to 12. Now, so having defined random variable or the discrete case. Let me now associate some other functions with it so cumulative distribution function, so probability mass function we have already defined.
(Refer Slide Time: 09:28)
 
Now, this is the cumulative distribution function, which again I will be referring to as cdf in the short form. So for every real number x the cdf of a random variable X is given by this equation. So, capital F x of x is the notation for the cumulative density function, and this is actually the probability of X less than or equals to the real number x. And so here this right hand side is actually the probability that your random variable X takes all values less than or equals to x, this is the idea. It immediately follows that if you want to compute the probability X greater than a and less than or equal to b. 
Then this is this can be written as probability X less than or equal to b, minus probability X less than or equal to a. Sees that is why this is X greater than a, because you are subtracting for all sample points for which this capital X is less than or equals to a. So, the probability of that, so therefore this becomes X greater than a. And this in terms of our cumulative distribution function, we write F X (b) minus F X (a). Now, all along the notation for this probability is cumulative distribution function, and if some place by mistake I call it as cumulative density function, then that has to be ignored the proper terminology is cumulative distribution function. 
If you want to find out the probability of X lying in an interval, then you can define this in terms of, why should have actually said this is as F X (b) minus F X (a). So, you can immediately see, because here this is actually the equal to the event that X is less than b and X is greater than a. So, X greater than a implies opposite of X less than a, so therefore minus X less than or equal to equals to a, because then this gives you the values of. If you feel that you still need from explanation you can do it for yourself to say that, see for basically what you are saying is that from X less than or equal to b, you want to subtract the because a is less than b. 
So, you want to subtract all values of X less than or equals to a, then you will get the this thing that X lies between a and b. Now, if X takes the value x naught see, because after all X is a discrete random variable, then the notation would be that F X (x) naught, and then F X (x) naught minus, so this actually says that your approaching the value x naught from the left. So from values which are less than x naught, so where F X (x )naught minus is the limiting value of F X (y), where y goes to x naught minus. And this notation means that, if you are number here is x naught, then your approaching they number x naught from the left of x naught minus this. 
So, and this we will be clear in a minute, because so now let me just spell out the values here, so essentially what I am saying here is that. If x 1, x 2, x n are the let say the finite n values that the random variable x takes, then an x 1 is less than x 2 is less than x n, see than what is happening is? That the distribution function F x is the step function, because you see you say probability X less than x 1. Then this is 0 in this case, because it is not taking any values less than x 1, and x 1 is the smallest value here. So this probability 0, but then if you want to say probability X less than or equals to x 1. If you now do this, then what happens? 
This is equals to probability X equals to x 1, because it is not going to take any other value any value less than x 1, only value in this region that X will take is equals to x 1. So, this is actually equals to, so in this case because is the first value this is equal to x 1. And so this is what happens? Now, so that means up to values less than just less than x 1, your when if you want to draw the graph, which I am showing you here, I am drawing the graph fine. So, let me show you the graph for this first, you sees what is happening is that here the random variables taking the value 1. So, before that the value will be 0. So therefore, if I want to draw the cdf the cumulative density function for that random variable, then you see it is 0. 
And it is 0 till at the point 1 it takes a jump, because at point 1 when x 1 is 1 this will be equal to probability of X equal to 1 which is 2 by 3. So therefore, the function from 0 will take the jump, and so it will be this thing. And then you see, for probability X less than or equal to less than x 2 if I do this. Then here it is again continuous to take this only, because less than x 2 or if you want to write 1 here in this case and this is 2. Then as long as X is strictly less than 2 the number there is no other probability, because X is only continuous to take the value 1, and here also it takes the value 1. 
So, as long as X is strictly less than 2, that means as long as I am here some way here and not taking the value 2, my value of the cumulative density function remains constant. So, this is like a step function, it continuous to be the same value as probability X equals to 1. And then the moment I say probability X less than or equal to 2, then this will be probability X equal to 1 plus probability X equal to 2. Because now, for X less than or equal to 2 there are two possibilities X can be equal to 1, on X can be equal to 2. So, then the two probabilities will get added up, so that means it will be 2 by 3 plus 1 by 6 which will be 4 by 6 was will be 5 by 6. 
And you see so from 2 by 3 it takes a jump, and at 2 the value now becomes 5 by 6. And so the jump, and you can see that this jump that it takes is equals to the probability of that discrete random variable at that point, that means probability X equals to 2. So, till up to this point this was probability X equals to 1, the moment I said probability X less than or equal to 2, it become probability X equals to 1 plus probability X equal to 2. So, the value of the cumulative distribution function jump by the probability of X equal to 2. And finally, when you talk about probability X less than 3 again, it will continue to be this, because there will be no other value of X here. And then the moment you make it less than or equal to it will take a jump, the figure is not accurate it will be this. 
And so I here again, the moment I say equal less than or equals to probability of X equals to 3 will get added to it, and so again the jump will be by the probability, so that means this will be a discrete function or and a jump function or a step function whatever you can call. And the point of discontinuities or the point of jumps that it takes will correspond to the values of the random variable, and the amount of jump that the functions takes will be equal to the probability of the equal to the probability of that of the random variable, taking that particular value where you considering the jump.
(Refer Slide Time: 17:54)
 
To continue with the general case, when X takes the values x i, i varying how 1 to n, and x 1 is less than x 2 less than x n. Then value of f remains constant in the interval x i minus 1 comma x i, because it takes the value x i minus 1. And after that it does not take any other value when a variable, so the cumulative density function remains the same. And you see this is the sign this say that is a closed at this end, and this is the open that means in this interval the values began from x i minus 1 to all values which are less than x i. 
So therefore, for all these values your cumulative density function remains constant, which I will interpreter saying that because it is constants in this interval. Therefore, it is right continuous, because I am approaching from here, if I approach from the right hand side that means larger value then x i minus 1. Then I will approach x i minus 1 this value of the function remains the same it is a constant, so it continuous and it attains the value at x i minus 1. So, the same value and therefore the function is right continuous, and what we just saw is that it takes a step or a jump equal to the size of the probability x i. So that means at x i, it takes a jump which is equal to the probability of the random variable at that point x i. 
And also we have see that it is an increasing function, and since this will be when you want to compute this, see this is equal to probability X less than or equal to x n. And by this mean it has taken all the values for X less than or equal to x n means it has taken all the values x 1, x 2, x n. So all the probabilities has been added up, actually so this is nothing but summation x i, i varying from 1 to n, and therefore it must add up to 1. So, this is what, now let me formulize properties of the cumulative distribution function. So, as we have seen that the function has to be a increasing function. So that means what do we mean by, when we say a function is increasing, that is the a is less than b. 
Then the value of the function at a must be less than or equal to the value of function at b, and this can be easily explained, I have already done it through example, but you see that the event X less than or equal to a is a subset of the event X less than or equal to b, because b is bigger than a. So, all the values that are that give you this event also all the points of sample space which give you this event also are here. And therefore, as we have seen from our proposition using the axioms of probability, that probability of this event must be less than or equal to probability of this event. 
And that is what this represent, this represent for probability of this event, and this represent for probability of this event. Therefore, this in equality follows, and so the function is a increasing function is a non decreasing function. Then limit F (x) as x goes through infinite is 1, so we will take an increasing sequence, let say of values x n to x, increasing that means values keep on increasing. So we approach that means if you have an x here, and you are approaching x from here, so all these values are increasing and you are reaching up to x. 
So, then again because of this property the event X less than or equal to x n, this are the subset of the event X less than or equal to x n plus 1, because x n plus 1 is bigger than x n. And therefore, limit probability X less than x n as goes to infinity. Actually, because this goes to infinity, so therefore this events the merge into X less than infinity, so all possible value of X get covered up just as. So therefore, this becomes equal to probability X less than infinity, and therefore this must be 1 because all value of X get covered up in this event, and so this must be equal to 1.
Then we say that the limit F (x) as x goes to minus infinity is 0, so the argument here is same except that here we took an increasing sequence to x n. There we will take decreasing sequence of this is as X goes to minus infinity, so limit F (x) is 0. So we can argue, because here I am say that as X goes to infinity F (x) is 1. So, when you take the decreasing sequence, events will be that means if I take decreasing sequence x 1, x n, where this is greater than this, then this is greater than x 2, this is greater than x n. So, then the event could be when n goes to infinity, because I am taking decreasing sequences. 
So, then it will become empty set, so this will be probability, see you will be considering the event X less than x i. And this is bigger than probability X less than or equals to x i plus 1, so this is the whole idea, so just reverse the argument. And so therefore as you go on, there will be nothing common as n goes to infinity this will be nothing common to… Because I am saying x goes to minus infinity, and so here there will be nothing common, and so this will finally converge to this will become probability X, what shall I say here. The symbol you have to uses that you have to say that x is empty, let me this becomes probability of the empty set that is what will happen? 
So therefore, the limiting value of F (x) as x goes to minus infinity must be 0, because there will be no values of x that are possible, once x goes to minus infinity, so same as to. Then f is right continuous, because any b and any decreasing sequence b, and you take a b and any decreasing sequence to b n. So, same thing I am saying your approach b from right, your approaching this of the sequence b n is coming like this from right hand side. And limit F (b n) as n goes to infinity is F (b), because same thing here X less than or equal b n or decreasing events, the sequence b n convergence to b. 
(Refer Slide Time: 24:48)
 
So the events converge to X less than or equal to b, and so what we are trying to say that X less than or equal to b n, this event will contain the event X less than or equal to b n plus 1. And finally, will also all of them will contain the event X less than or equal to b. And so therefore, probability of X less than or equal to b n will be greater than or equal to the probability of X taking the values less than or equal b n plus 1and so on. And finally this, so now by the continuity property of the probability function P. We get that limit F b n will be equal to F (b), because this is the value you know you are taking the limit here as n goes to infinity. So therefore, because P is a continuous function probability function which is continuous, therefore this will be equal to F (b), and so these proof the right continuity of F.
 And so now we have shown all the four properties 1, 2, 3, 4 of the cumulative distribute function, and so any cumulative distribution function must satisfy all these four criteria. And in fact, these 4 conditions are necessary and sufficient for any function to be a cumulative distribution function corresponding to the random variables X. So, this is importance, so whenever you want to characterize a function which is which you says a cumulative distribution function for a random variable X, then you have to show that these 4 condition are satisfied by that function before you can take it to be the cumulative distribution function. 
Now, so if you take the example that we have been referring back to all the time. This is when two dice are rolled up, and X denotes the random variable X denotes the sum of the two numbers that show up, then the expect so this is fine, so that is it. Now, I started give you the example, but first let me now define a very important term a commodity or quantity which we associative with the random variable expective value of a random variable X here. So, if X is the descriptive random variable having the probability mass function p (x), the expectation or expected values E (X) is defined by E (X) is equal to sigma x into p (x) such that, so that means you multiply x by it is corresponding probability, and then you add up. 
So when you add up all this products, so which is over all x so that p (x) is positive, because if p x is 0 then the contribution here will be 0, so we take this some over all possible x is for which p x is positive. So, if you add up these values when we define this as the expected value of the random variable X. Now, so therefore we consider this example now, consider the example it which two fair dice were rolled up, and X denoted the sum of the two numbers that show up. 
So, in that case had given you the table of you know for different values of X what will be the probabilities, so if you just refer to the table, then you can come see that this will be the thing, and this add up to 255 upon 36 which will be some number close to 7 little bigger than 7. So, this is the expective value of the random variable, that means in other words what you saying is that, if you sort of keep throwing the two dices, and at the numbers and then that means you take the average, so that means suppose you throw up the number 100 times throw up the two dice100 times. And then add up the numbers that show up, and then divide that by 100 that will be close to your expected value.
 



(Refer Slide Time: 28:57)
 
Now, here if you look at this expression what does it say? Now, since p x for all x such that p (x) is positive is 1, this you can say that expected x is the weighted average of the values that X takes with weights as the corresponding probabilities. So, they can be some more interesting interpretation of the expected values which are you show you right now. So, E (x) can also be interpreted as the center of gravity of the masses p (x i), i varying from 1 to n located at points x i, i varying from 1 to n that means you can imagine that the p (x i) are the masses, which you place at the point, corresponding points x i. And then you take the center of gravity of this distribution of masses is also which is same as the expectation X.
Now, see that means imagine a weightless rod in which weights of masses p (x i) are located at corresponding points x i, i varying from 1 to n, so that means imagine that this rod weightless rod, and you have placed these points the masses p x 1 at x 1, p x 2 at x 2 and so on. So, I have taken the points to be x 1, x 2, x n you know this one distribution, but it could be anywhere distributed but whatever the diagram will be the same, that p x 1 is the mass located at x 1, p x 2 is mass located at x 2 and so on. Now, the point at which the rod will balance itself is known as it is center of gravity.
So, from this thing you can this is the notation, and so this is exactly what is given by the expression E (X). So E (X) can be the notation it can also be referred to as the center of gravity of these different masses, which are the probabilities located at the corresponding points x i. Now, note that here I have just taken when I find E (X), I took x 2 I said that x takes finite number of values and hence this quantity is a finite quantity, and therefore it is defined therefore it exist. So, wherever the different cases I will discuss them as that when we are right. Now, we also refer to E (X) as the first moment of X. 
So, for when X is the discrete random variable and it is taking finite number of values. So then I can also define expectation X square which will be sigma x i square p (x i) for all i varying from 1 to n, obviously the summation is over, all those i for which p (x i) is positive. Now, even if the random variable X is taking countably infinite values, then also if then I can you know take any function of X, and I can accordingly write down the expectation of that function of a random variable. We will formally define expectation of you know g of x, when g of x is some function of a random variable X. 
So, that we will take care later on, and of course for a continuous random variable also we will define in a formal way, but right now I can just say that because it is a summation sign. So, and if as long as the summation is finite number, I can define these expectations and so here for example this will be the second moment, and also the linearity of expected function, because it is a summation. So therefore, it is a linear function that means if I take c x plus d y two random variable x and y, then also I will be able to write the expectation of c x plus d y will be c times expectation of x plus d times expectation of y. 
So, because of this summation thing, of course if x and y have the same to a probability mass function. Then so what I am saying is that right now, wherever if I am using the linearity of the expectation, then I am doing it this scenario when your x takes may be i finite values or countably infinite values, when wherever this summation is finite number. I can treat E as a linear function, and also I can define the expectation as a of a any function of a random variable in this way. Now, here I would like to top of an example also. 
 


(Refer Slide Time: 34:17)
 
So let see, then the second moment can also be defined here, which is the second moment if this is the first moment, then the second moment would be expectation of X square, which will be summation i varying 1 to n x i square p (x i). And then very important quantity that we are associate with random variable one is of course E (X). And the second one is variance X, which is the expect that means it is now the expectation of X minus E (X) and then whole square. So, you say that this is the moment second order moment of X about it is expected value. 
See these are all for example this is the moment E (X) is the first order moment about the origin, and this is about 0 this is also the second order moment about 0, but now here this is the second order moment about it is expected value. Now if I open up this bracket when I get this, and now when I will take E inside, because as we have seen writes definition expected value is distributive, I can take it inside the bracket. So this will be E X square minus since E (X) is finite quantity already, so they will be E (X) here, so 2 comes out constant. 
In fact I am assuming that what I am saying is that, if you take C some constant, then this will be C times expected X, which immediately follows from the definition, because as here defining this as summation x i p (x i). So if I consider the random variable C X instead of when C X will takes the values C x i, and so here when I want to compute this will have C is present here, but since C is a constant till come out. And so this will be simply C X. 
So therefore, when I take E inside, this will be to twice E X into E (X) then this is again a constant. So, therefore this is simple be E (X) square there will be no expectation. Again I am using the property that if random variable is taking constant value, then wills I this is not a random value essentially, this is a constant. So, if X C for all possible values then will be the expectation was simply be C, because this is probability 1, so the constant whenever random variable is just equal to a constant this expectation would be just that constant value. So this is this, and therefore minus 2 X square plus E (X) square, so that reduces and therefore this becomes E (X) square minus, so therefore you can also say that the variance of a random variable X is a variable of random variable X is second order moment about the origin. So, expected X square minus it is expectation whole square, so this is what we. And therefore we will go and computing this as we introduce our special random variables and so on. So, the first one of the simplest random variable that we talk about is a Bernoulli random variable, this was this is name after the swish mathematician James Bernoulli, and I think 1700 something probably he define this random variable. And you will see that it is a very basic random variable, and it we use this to build up on other special kinds of random variables. So, this describes a situation or this random variable describe the situation in which the outcome is either success or a failure, so very simple you perform an experiment and the outcome would either be a success or failure. So, for example if you toss a coin, you can say that coming of a head is a success and coming up of a tail is a failure. And so, the values that X will take, we just see we associate X equals to 1 with the success, and X equals to 0 with the failure. And then let us say that probability p X equal to 1 is p and so where of course p is a number which belongs to 0, 1.
And I am taking the open interval on both side, that means p is not 0, I am defining a meaning full random variable or a meaning full experiment, in which the outcome is either a success or a failure. And so the probability X equals to 1 will be p, and probability X equals to 0 will be 1 minus p. So, now if you compute the expectation or the first moment of this random variable, then this will be simply one in to p, because the random variables taking the values 1 or 0. So, 1 in to p plus 0 in to 1 minus p, and therefore this is equal to p the probability of a success. And the variance by this formula, so when you compute the E (X) square, so here E (X) square 1 square is 1, so 1 square in to p plus 0 square in to 1 minus p, so which again is p. So, the where second order moment is also p, and so this is p minus the first order moment first squared which is p square, so p minus p square so this is the variance. So, where you simple quantities which you can write away compute, and now we will further on use other special random variables discrete random variables, and then of course one will talk about continuous random variables also.
(Refer Slide Time: 40:14)
 
So, let me just illustrate interesting aspect of the expected value, here I am taken this example functions in rows, a class of 120 students are driven in 3 buses to a musical concert. Now, 36 are seated in the first bus, 40 in the second and 44 in the third, when the buses arrive one of the120 students is randomly chosen, from the group of this all get down from the bus, one student gets picked up. Let X denote the number of students on the bus of the randomly chosen student, see now we carefully understand the event that I am telling you, X is the number of students on the bus of the randomly chosen student.
So, we picked up one student randomly, and then now you want to the because again that is a random process have chosen one of the student out of 120. Then X is the random variable, which denotes the number of students on the bus, on which this randomly chosen student was sitting. So, we have to find E (X), so find the expected value. So, first of all you see that since student is chosen randomly, any student is equally likely out of the group of 120 I choose any one of them. 
So, therefore the probability of the student in chosen from the first bus X equal to 36 is 36 by 120, then probability X equal to 40, because the second bus, so that will 40 upon 120, because that many students are travelling in that by the second bus, and finally probability X equal to 44 will be 44 upon 120. So, now if I want to find out the expected value of this random variable, then the expected value will be the random variable takes the value 36 into the probability of that bus being chosen, so it was 36 upon 120, then 40 into 40 upon 120 plus 44 into 44 upon 120. 
Now, when you add up these numbers this comes out to be 1208 by 30 in which is 40.2667, but if you just compute the because if you look at the event that you take any bus, then the probability of being chosen is 1 by 3, it because every buses equally likely. So, if you want to compute the number of students on the expected number of students on the bus of the randomly, this is later on. 
Now, on the other hand average number of students on a bus is 120 by 3, yes because I will add up, because each bus is equally likely to be chosen, so that probabilities 1 by 3, so that in to 36 plus 40 plus 44 that will be 120, so this is number is 40 now this number is less than 40.2667. And this what I want to point out here is that you see the expected number of students on the bus of the randomly chosen student is more than the average number of students on a bus.
So, just think about it and why is this happening, because you see the bus in which the largest number of people or I should say the more the number of students on a bus the more possibility of that student being chosen as be a student, it because you know the large number of students are coming from that bus, in which more students were travelling. So, the possibility of choosing that student is higher than choosing from other students. So, just think about this thing and so I thought I will end this lecture by giving you this interesting example. And so you will as we go on we will see various, various implication uses of these measures expected value variance and so on will introduce some more.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 6
Discrete Random Variables and Their Distributions

 (Refer Slide Time: 00:20)
 
Defining the distribution function, where we said that the this is equal to F b. So, probability x less than or equal to b, now we can immediately write down the formula for the probability of x being in an interval using the distribution function. So, here the idea that we are going to write x between a and b, so am taking script in equality here. And so then you see I am writing this set the event x less than or equal to b as a union of two disjoint events x less than or equal to a, then union x between a and b, so x strictly greater than a less than or equal to b.
So, these are disjoint events and they add up to the union is equal to this event, then because they are disjoint when I write the take the probability, it will be the sum of the two probabilities. So, probability x less than or equal to a plus probability a less than x less than or equal to b and so this probability then can be written as difference of probability x less than or equal to b minus probability x less than or equal to a. And therefore this is F b minus F a, and you can see immediately that, if you want to write equality here, then this event could be x strictly less than a.
So, in that case we will have to write a minus and so on, so therefore since in the discrete case it matters whether equality is there are not, so therefore this is the way I have written it. And then of course, if you want to also have the probability that x is equal to a and I will simply add to it, so plus it will be P a, because x equal to a again is disjoint from this set; and so I can write here plus probability a and so on. So, you can get various forms of the probabilities for x being an interval, you can write it through your distribution function, so this was for lecture 5.
Now, I will start defining, since we have already talked about Bernoulli random variable, which was a very basic random variable, discrete random variable, so will define a discrete random variable which is known as the binomial random variable and then notation is B n comma p. So, here n independent trials are performed each resulting in a success or a failure, so we just say that when you perform a trial, then either the outcome is a success or it is a failure.
Now, probability of success we say is p and that is why the notation B n comma p that means, number of trials is n and the probability of the success is p. And so x the random variable denotes the number of successes, so in n trials you want to know how many successes have occurred, because it is an uncertain event. And the probability of x equal to R is given as n c R p raise to R 1 minus p raise to n minus R, so obviously if you looking for R success in n trials, then they can be any of the R trials out of the total n trials, so n c choose R, I mean n choose R and then since R success so p into R into 1 minus p raise to n minus R.
So, R success and n minus R failures and this is for R varying from 0, 1 to n, so for any value of R you can substitute here and get the corresponding probability that x is equal to that R. And now you can sum up this all the probabilities, so that means for R from 0 to n sigma probability x equal to R, then this will be summation R varying from 0 to n n c R p raise to R 1 minus p raise to n minus R and this you can see is the binomial expansion of p plus 1 minus p raise to n, that is another reason why it is called the binomial random variable.
So, when you write p plus 1 minus p raise to n, this adds up to 1, so therefore this is p m f and of course, so the x is the binomial random variable with probability mass function defined by 1. So, now let me again emphasize this fact that when the random variable is discrete, we describe it is probability mass function that means, when it gives you the function which specifies the probabilities for different values of the random variable x; when that is known as probability mass function.
And when we talk of continuous random variable that means, when the random variable can take all possible values interval, then the function which describes the probabilities of the random variable, that is known as probability density function. So, I will try to keep this thing always in mind, but sometimes may be it may happens that I have random variable is x and instead of saying the probability mass function, I may have used the word probability density function.
But, remember that we make this distinction that for discrete random variables it has to be probability mass function, and for continuous random variables it is the probability density function. So, the notation is B n comma p, so that means binomial and you only need these two parameters, what is the number of trials and what is the probability of success. And so now, you want to verify that this actually is a valid p d f and for which for this verification, I will need to say that all the probabilities must add up to 1, because x can take any of these n plus 1 values.
So, the sum of the probabilities for all these values must add up to 1 and you see that this is nothing but the expansion of p plus 1 minus p raise to n the binomial expansion; and therefore, this number is 1, so 1 raise to n is 1, so that verification is straight forward.
(Refer Slide Time: 06:49)
 
So then I immediately want to compute the expected value of this random variable, so that will be because this x is equal to R, so R into n c R p R 1 minus p raise to n minus R, R varying from 0 to n. So, now here because this is n c R, so you will having the denominator maybe I can use the, so here if I take an outside see the thing is that n c R you can write as n factorial upon R factorial n minus R factorial. So, R if I take out, then this will be R minus 1 factorial, so the R cancels out and n I have taken out from here, so this will become n minus 1 factorial.
So, and then n minus R you can write as n minus 1 minus R minus 1 and therefore, by taking out n here and canceling out the R, I get n minus 1 choose R minus 1; and since you see in this summation R is from 0 to n and when R is 0, this term is the first term is 0, so therefore no contribution. So, therefore, this summation can as well be written as R from 1 to n and this what you have. So, here if I take out p, then I will be left with p R minus 1, so this n p is outside, this n is outside and then you have this.
So, now you can see is again a binomial expansion of p plus 1 minus p raise to n minus 1, because their powers are all n minus 1, so therefore this is 1 and so you are expected value is n p. So, again a straight forward computation we should, because able to figure it out and can also say that a Bernoulli random variable is binomial 1 comma p, it is binomial random variable with parameters 1 and p.
(Refer Slide Time: 08:53)
 
Let us look at this example give taken from Sheldon laws, so it says that it is known that screws produced by certain company will be defective with probability 0.01. So, the p is given here, so here defective we are treating as a success, so the probability of getting a defective screw manufactured is 0.01 and these of course, the defectiveness of the screws is independent of each other. The companies sells these screws in packages of 10 and offers a money back guarantee that at most one of the 10 screws is defective; that means, if more than one a screw is defective in a package of 10, the company will take back the package and refund the money.
So, the question is what proportion of package is sold must the company replace, so that means you wanting to find out the probability of packages of 10 that have more than one screw defective. So, that means, you are wanting to find the if x is the number of, you say that x is the number of number of defective screws, then what is x is binomial 10 0.01. So, because we are treating a defective screw as a success, so therefore in a package of 10 the probability is 0.01, so this is binomial 10 comma 0.01.
And you want to find the probability, let x is greater than or equal to 2, because when x is greater than or equal to 2, the package will be returned back and the money refund it, so here I have said that where x is binomial this. So, therefore, a now this event I can write as compliment, so 1 minus probability x equal to 0 and probability x equal to 1, so these two are acceptable and if x is more than 1, then it is not, so 1 minus, so these two you can see that. Now, x equal to 0 is the probability, so 10 c 0 into p raise to 0 1 minus p raise to 10 and x equal to 1 will be 10 choose 1 p into 1 minus p raise to 9.
And now your 1 minus p is 1 minus p 0.99 and so you write down this number, you can use your calculator to compute it, it comes out to be 0.004. So that means, 0.4 percent of the package is will have to be returned, and this is you can see that this kind of calculation is very helpful to a company, which is trying to budget it is manufacturing of the screws. And anywhere situation you want to know that what is the of course, nobody saying that this exactly 40 percent of the package is will have to be returned, but now the company has an idea as to 4 percent, 4 percent of the package is have to be returned.
So, there is some idea and a guideline for the company to see what can happen. Now, the next thing that we want to compute about the binomial random variable is it is variance, so first we will compute expectation of x square, second order movement. And so that will be given by R square n c R p raise to R 1 minus p raise to n minus R summation is from 0 to n, here again you see for R equal to 0 the first term is 0, so there is no contribution. And I will do the same thing, I will cancel one R with this ((Refer Time: 12:43)) one here and then one R am left with, p I will take outside and then n of course, also we should have written which I have done here.
So, in that case you will because left with R n minus 1 and the same thing, same trick I will do and this is it, n minus R I will write is n minus 1 minus R minus 1, so this is p raise to R minus 1 and this is the whole thing. And the one R that is left here, I will write it as a R minus 1 plus 1, now you see you can break up this sum into two, so R minus 1 times this whole thing, you see now is the expectation of a... So, I define why is a binomial n minus 1 comma p, so why is binomial random variable where n minus 1 trials I have taken place, probability of success is p.
So then you see in this summation I should have written here 1 to n, then R minus 1 into this term, this whole thing summation R from 1 to n will give you the expectation of binomial n minus 1 comma p. So, therefore, that will because n minus 1 into p, so n minus 1 into p and plus 1 and then this summation this again is the say same thing p plus 1 minus p raise n minus 1, so that is equal to 1.
So, therefore, you get n p times E y plus 1 expectation of y plus 1 from here, an expectation of y is n minus 1 p and this is plus 1, so n p into this. So, now, for the variance you have to write n p into n minus 1 p plus 1 minus n p whole square and when you simplify you get this ((Refer Time: 14:30)) and some people also write this as n p q, where q is 1 minus p. So, easy way to remember and you see some more applications of and of course, as the course progresses you will continue to see where all you can use the concept of a binomial random variable.
(Refer Slide Time: 14:50)
 
Let us look at this proposition about the random variable binomial n comma p, so then as x goes from 0 to n, this number probability x equal to k increases monotonically and then decreases monotonically reaching it is largest value, when k is n plus you see integer part, largest integer part of n plus 1 into p. See p is a fraction, so n plus 1 p may not be an integer, so when we write brackets like this, it means that the largest integer for example, if you consider 5 by 2, so the largest integer here would be 2, largest integer which is less than n plus 1 into p, so this is this.
Similarly, if you consider what shall I say 9 by 4, here again the largest integer will be 2, because 4 times 2 is 8 and then it is 1 by 4, so this is what mean by that. So, that means, the binomial probabilities they keep on increasing, reach the largest value highest maximum and then starts decreasing this is the idea. And so we want to prove this result, so let us look write down probability x equal to k upon probability x equal to k minus 1; and so if you write down the expressions this is what you get.
So, then things cancel out n factorial n factorial, you have n minus k factorial n minus k plus 1, so therefore, you will be left with n minus k this will come in the numerator, so n minus this is the bracket over k minus 1 upon k p upon 1 minus p. Now, this should be we want know for what values of k the probabilities are increasing, so I want this to be greater than 1. And if you simplify this means that k into 1 minus p should be less than n minus k minus 1 into p or k into 1 minus p plus this is less than n p, so this give you this. So, the as long as k is less than n plus 1 into p, the probabilities is, because you say this is probability x equal to k divided by probability x equal to k minus 1, so this number is greater than this number as long as k is less than n plus 1 into p. So, that means, and since k is an integer, we will say that this goes on increasing till k reaches the largest integer present in n plus 1 into p, so that is what we say.
So, that means, k less than or equal to this integer part in this number, probabilities are increasing and when k is greater than this, because the any quality will get reversed, so then they are decreasing. And if n plus 1 into p is an integer then of course, that will because the maximum value otherwise, because here it is strictly less and this is less than or equal to... So, k will the probability x equal to k will attain it is maximum value for n 1 into p that means, when this is an integer, otherwise it will attain it is maximum value for the largest integer present in n plus 1 into p. So, I will show you the diagram now for a particular this thing, the bar chart for a binomial distribution, so the here will look at the bar chart when the random variable is parameters are 10 comma half that means, your p is half and the number of trials is 10.
ten (Refer Slide Time: 18:42)
 
So, you see here if you look at this thing 1 by two, so that means for x equal to 0, then when k is equal to 0, the probability p 0 is 1 by 2 raise to 10 and that is depicted by this small bar here and then x equal to 1 it starts to increase and then at 5 it is maximum. So, if you look at, see we said that, so what is your n plus 1 into p this is equal to 11 into 1 by 2, so this is 5 1 by 2, so the integer part is 5. So, as just now we looked at the we proved this result, that in this case the maximum will value will be attained for the largest integer present in n 1 plus n plus 1 into p which is 5.
So, therefore, you see the largest bar is corresponding to k equal to 5 and then again the values start decreasing and you also see that in this case, because p is half, therefore the graph is symmetric about the value k equal to 5. So, just want to explain that this is 1 0 2 4 into p raise to k, because the horizontal axis is k and here just to otherwise numbers would have been, because probabilities are less than 1. So, therefore, just to make them whole numbers we multiplied everything by 1 0 2 4, which is 2 rise to 10, if we multiply all the probability, then they become integers.
So, this is what your a binomial bar chart will look like, for the particular value and p is equal to half and I have shown you also that how it will continue to the probabilities will continue to increase, reach a maximum for the integer part of n plus 1 into p and then start decreasing.
(Refer Slide Time: 20:55)
 
Now, let us look at the distribution function of the binomial random variable that means, you want to compute probability x less than or equal to i and here, you see the expression would be you have to sum up all these probabilities from 0 to i for the individual probabilities at the random variable takes. Now, these numbers can be very very large, in fact if your n is moderator large and you want to compute even for n equal to 20 and if you want to compute for, let us say i equal to 16, then you will have add up 17 terms here and this can become very tedious.
So, there is a very simple and nice formula which you can recursive formula, because we obtained this here in this expression I have this here, so just place k by k plus 1, then k minus 1 becomes k, so in that from that formula you get this recursion. So, which says that, if you have obtained probability x equal to k, then you can obtain probability x equal to k plus 1 by this simple formula, recursion formula. And you can see that to start off when x is equal to 0 when x takes a value 0, then this will be 1 minus p raise to n.
So, once you have compute this, then p x equal to 1 will be from this formula p upon 1 minus p k is equal to 0, so this is n and p x equal to 0. So, therefore, this will because p x equal to 1 will be p upon 1 minus p n 1 minus p raise to n, so that means you if you have already computed this number, then you have to simply multiply the probability x equal to 0 by this number to get probability x equal to 1. And then similarly probability x equal to 2 would be this number multiplied by probability x equal to 1 which we have already computed here.
So, a nice simple recursive formula that you have obtained and you can write this compute the program feed the values and then it will go on computing. That means, you have to just feed the value n and p and then it will compute the successive probabilities for you; so this is the computational part, because the wise things can become very tedious. Now, another special kind of discrete random variable is the Poisson random variable and this is named after the mathematician S D Poisson, who defined this random variable in 1837.
And he in fact, wrote a book which was application of probability theory to law suits, criminal trials etcetera, so you see the kind of applications that the Poisson random variable has. And at that time in 1837 he wrote this book, where he apply the theory Poisson random variable to predicting things about law suits and criminal trials etcetera. So, x is a random variable which takes values 0, 1, 2 up to infinity, lambda is the parameter and lambda has to be positive.
Then we define the probability that x is equal to R by this number, E raise to minus lambda lambda raise to R upon R factorial, defines a probability mass function of the random variable x and this is the Poisson p d f. And now you want to make sure that this defines the p d f that means, you have to show that summation probability x equal to R is 1; so very simple calculation will immediately give you the verification that this is indeed a p d f.
(Refer Slide Time: 24:55)
 
So, to show that the probability mass function define for Poisson random variable is valid p m f, we add up all the probabilities here which is equal to this, but you see lambda raise to i upon i factorial i varying from 0 to infinity is nothing but the expansion of E rise to lambda. So, therefore, E minus lambda into E raise to lambda gives you 1, gives you E raise to 0 which is 1, so we have check the validity and of course, each of the probabilities defined are also non-negative.
So, therefore, what we have defined is the probabilities for the Poisson random variable forms a valid p m f, probability mass function. Examples of random variable that obey Poisson probability law, some of the situations am just writing down to get give you better feeling for the random variable. And this is for example, number of misprints on a page or a group of pages of a book, which we believe is a random phenomena.
Number of people in a community living up to the age of 90, which again is a random phenomena, because how long one is for how long one lives is not certain event. Then number of wrong telephone calls dialed in a day, a wrong numbers what I mean is wrong telephone calls dialed in a day, this could be at particular exchange or you mean take a particular number and then count a number of times the wrong telephone calls come. Number of customers entering a post office in a day, then number of alpha particles discharged in a fixed period of time from some radioactive material. Now, you see that here all the situations, there is some sort of discreteness and that is why we are saying that these situations can be modeled by a Poisson random variable. You can just get the feeling, because you cannot have two numbers dialed simultaneously, there as to be a gap; then number of misprints of course, will be current discretely told some gap of time and so on.
Now, I want to show you the relationship and as we go on the discrete random variable that I defined, I want to show relationships between among these discrete random variables. So, Poisson approximation of the binomial random variable and this is when n is large, so for n large and p small, then you expect that n p would be a very, a moderately small number, n p and so we defined that is lambda. So in other words, what you are saying is that a p small and n large and then this n p number sort of approach is reasonably small number equal to lambda.
Now, let us look at the binomial probability for x equal to i, when x equal to i when x is equal to i, then this is the probability defined, then let me start writing, so here if I take this, then p is lambda by n. So, I will make that substitution here lambda by n raise to i 1 minus lambda by n raise to n minus I, then if you cancel out the n minus i factorial part here, you will be left with n into n minus 1 n minus i plus 1. And then this n raise to i, I am writing here and i factorial is underneath, because you see am trying to converse to the Poisson probability. So, lambda raise to i upon i factorial and this one 1 minus lambda n raise to n and then divided by 1 minus lambda n raise to i. Now, this n 1 n cancels and I am left with n raise to i minus 1 and you will have i minus 1 terms here, so I take n inside and divide.
(Refer Slide Time: 29:07)
 
So, therefore, each of this term becomes 1 minus 1 by n 1 minus i minus 1 by n, so the this n raise to i gets absorbed here, lambda i raise to i factorial 1 minus lambda n raise to n and this. Now, as n goes to infinity becomes very large, then 1 minus lambda by n raise to n will approach E raise to minus lambda, so I hope you are all familiar with this limit. And then 1 minus lambda by n raise to i, because as n becomes large lambda is fix, so this number is becomes smaller and smaller and so this will approach 1, for n sufficiently large.
And then and all these numbers again as n goes to infinity are becomes very large, each of these numbers approach 1, so the product is 1, so therefore this is gone and this raise goes to E raise to minus lambda. So, the whole thing approximates to lambda raise to i upon i factorial E raise to minus lambda, which is the Poisson probability. So, essentially I should say that this approaches this and this is your, so these things are actually inter linked. And therefore, for large n your binomial probability is the same as the Poisson probability that is one result.
Now, they computing the expected part expectation of a Poisson random variable again straight forward, sigma 0 to infinity i lambda i E raise to minus lambda upon i factorial. So, here I do the same trick as I did for the binomial, so lambda E raise to minus lambda you take outside, then your i becomes, this summation becomes 1 to infinity lambda i minus 1 upon i minus 1 factorial, which is again the expansion of E raise to lambda.
So, lambda E raise to minus lambda into E raise to lambda it gives you lambda, so whatever the parameter of the Poisson distribution that is also it is mean, so this is one result. And now variance also straight forward again the same thing I will do as, I did for the binomial expectation of x square we find out, then again the i cancels lambda you can take outside and the i that is left you write it as i minus 1 plus i and this thing. And just do the same argument as we did for the binomial, you will see that i minus 1, this will give you the again a Poisson this thing expectation of a Poisson with lambda parameter.
So, this will be lambda plus 1, because this should be plus 1, i minus 1 plus 1, so 1 because these are again Poisson probability, so will add up to 1, so this is what you have; and therefore, variance will be given as lambda into lambda plus 1 minus lambda square, which is the expectation. So, this is a particular situation where your expectation and the variance are the same, and both are equal to the parameter of the Poisson distribution.
Now, best way to give you feeling about particular random variable is always through examples, so here let us look at the Poisson error model and as I said this is same the first one there, that is your modeling the number of printing mistakes done by let us say high speed printer. So, here it says that certain high speed printer makes errors at random on the printer page, on the making an average of two mistakes per page. So, on the average two mistakes are made per page, assuming that the Poisson distribution with lambda equal to 2 is approximate to model, the number of is appropriate actually I should say, I should say appropriate.
Let me correct the word appropriate, appropriate to model the number of errors per page, what is the probability that obtained page is produced by the printer at least 7 will have no error. So now, you want to probability that when the 10 pages are printed, 7 of them are without any errors.
(Refer Slide Time: 33:49)
 
So, we assume independent of error from page to page that means, number of errors that occur on one page is independent of the number of errors that occur on the second page and so on. Now, let x be the number of errors on a page, then as we have said that we will model this pi the Poisson random variable and so probability x equal to R will be E raise to minus 2 into 2 raise to R upon R factorial, where R can vary from 0, 1 to anything.
And we said that, since the average number of errors made by the printer on a page is 2, so am taking 2 as the parameter of the Poisson random variable that am using to model this particular situation, so this is what is given to you. Now, if you want the probability that a page is error free that means, there are no errors, so probability of x equal to 0 is equal to E raise minus 2. Now, the thing is that you want to find out the probability that at least 7 pages are error free, so you see we modeled this situation by a Poisson random variable to find out the probability of a page being error free.
So, that I got as 0.1353, which is equal to E raise to minus 2, but now there is a next step and see that is why example is very interesting, because you see is now you will make use of the binomial random variable. Because, having no errors on a page is the success, let us treat that as a success and since we have said that and we are looking at a 10 pages, so I will consider scanning every page as a trial of the experiment, and if there is no error on the page then that will be a success.
So, this is ideal for a binomial random variable, this situation is ideal, because since pages are the errors from page to page are the independent, therefore I will treat this as 10 independent trials. And if a page turns out to be error free and that is a success and what is the probability of a page being error free that is 0.1353 that means, the probability of a success our p is 0.1353 and the number of trials is 10, so this is a binomial random variable.
And so probability that at least 7 pages are error free, I require that 7, 8, 9, 10 at least 7, so the error free pages can be 7, 8, 9 or 10 and the probabilities will be 10 choose 7 E raise to minus 2 raise to 7 into 1 minus E raise to minus 2 raise to 3. Similarly, for 10 choose 8, we will write the expression E raise to minus 2 raise to 8 and so on, then 10 choose 9 E raise to minus 2 raise to n into 1 minus E raise to minus 2 plus 10 choose 10, which is E minus 2 10.
And even as I have saying that here also the computations have to be done by using a calculator or a computer, so I write down the numbers this is into 10 raise to minus 4 and so the probability is 0.0007, so which is very low. So, therefore, what you will say is the probability that 7 pages out of 10 will be error free is a very very low probability, has very low probability, so chance of this happening is very small. Now, again I will try to take as many examples are possible, so make the concepts clear, so first this question am taking, because that will lead to a Poisson approximation which I want to show you.
((Refer Time: 37:56)) So, first consider the situation here that, n people are present in a room what is the probability that no two of them celebrate a birthday on the same day of the year. So, this is the first question, what is the probability that no two people will be having a same birthday, celebrate it on the same day and then we want to ask the question how large did n be. So, that the probability is less than half that means, how many people should be there in a room, so that the probability of any two of them having the same birthday is less than half. We want to first look at this question and then I will take you to the how I approximate this situation and give you the through Poisson and then again show you the connection between the two.
(Refer Slide Time: 38:52)
 
So, the birthday problem as we saw that, if no two of them have the same birthday then of course, we will write it as 360... see the first person can have a birthday on any of the 365 days and we are of course, ruling out the leap year, so nobody has the birthday on the 29th February. So, this is 365 upon 365, then the second person can have in the group, group of n people the second person can have is his or her birthday on any of the remaining 364 days and so 364 upon 365 and so on.
So, this will go on up to 365 minus n plus 1 upon 365, so this gives you the probability that no two of them have the same birthday and we want the number n such that, this probability is less than half. So, the probability that no pair, no two people in the group have birthday on the same day, we want that probability to be less than half and we want what should be the smallest number of such people. So, that this probability is less than half and so it turns out that n greater than or equal to 23, satisfies this inequality.
Now and of course, then I started calculating backwards, so for example, for n equal to 23, for n equal to 23, 365 minus n plus 1 is 343, so then I started computing 343 upon 365, 344 upon 365 and so on. And then just 363 upon 365 when you come up to this point, then the probability just turns less than half and so the next number is 364 by 365 which is also less than 1, so the probability will remain less than half. And of course, the last number is 365 upon 365 which is 1, so therefore and in fact, if I took n to be less than 23 that specify took n to be 22, then this will not happen.
Because, then you will be starting with 344 and then when you calculate backwards it will not turn less than half, so this is just enough and that means, if you have more than 23 people in the group, then the probability will be still less than half, so this is the idea. Now, here calculating it otherwise become difficult, because what is happening is that you are in the group if a and b have the same birthday, then it is possible that b has a same birthday with c and so this thing is transitive.
And so it is not very easy, I mean one cannot daily assuming dependence to calculate the actual probability, but we will see that some approximation is possible and so we will see that. But, so this is interesting to see that, even group of people having 23, I mean group having 23 persons the probability that no two people have the same birthday is less than half.
(Refer Slide Time: 42:01)
 
So, let me continue with the Poisson approximation of what we discussed the common birthday problem we discussed, so now suppose choosing a pair is a trial, choosing a pair of people present in the room, then there are n c 2 pairs that I can, different n c 2 pairs that I can choose. Now, consider E i j as a trial i j i naught equal to j such that, and of course, what I mean by this is that am choosing the i'th in the j’th person here, i and j are different having the same birthday.
So, E i j would be considered a the event, when I choose the pair i j it is the success, if they have the same birthday. Now, in question 7 of the exercise 3, which I will be discussing at the end of having gone through all different types of discrete random variables. So, the exercise 3 question 7 am asking you to show me that these pairs the events E i j are pair wise independent. So, of course, choosing of each pair is independent and then I want you to show that the pairs E i j that means, this set of events E i j i naught equal to j.
That means, n into n minus 1 by 2, such events they are all pair wise independent, which means that i j and E l k this is important, I must show i j and E l k, where i is not equal to l and j is not equal to k. So, between different sets of pairs when you choose, different sets of events I will, so that is what I should say that when you pick up two such events from here, where i is not equal to l and j not equal to k, then any two such pairs are independent events, this you should do as an exercise at the end of this chapter.
Now, x is the number of successes in n c 2 trials having the same birthday, so let me now start looking at the Poisson approximation, so number of successes in n c 2 trials having the same birthday. And this am calling as and so as I discussed with you is a binomial n into n minus 1 by 2 comma 1 upon 365 remember, I showed you that pair of people having the same birthday, the probability is 1 upon 365 and the number of trials that I have is n into n minus 1 by 2, so this is a binomial random variable.
If I do the Poisson approximation, then we said that the corresponding Poisson parameter would be n p and so that will be n into n minus 1 by 2 into 1 upon 365. So, this is my n p and now you want to compute the probability that no two people have the same birthday that means, you want to find out probability x equal to 0, which is E raise to minus n into minus n into 1 by 2 into 1 upon 365, so which is this number. So, the next part of the question was what value of n that is twice this the inequality, that this is less than half, no two people having the same birthday that probability should be less than half.
So, we should take the logarithm of both the sides, then this is minus n into n minus 1 upon 730 l n of E is 1, this is less than minus l n 2, so minus minus cancels inequality reverses. So, therefore, n into n minus 1 is greater than 2 into 730 and you can see that n equal to 23 will satisfy this equation. And therefore, this also is validated, the answer that I got earlier by other arguments, now I have been able to validated by... So, therefore, this is what, so these examples that am trying to show you that, how you model and sometimes your modeling can be such that, the getting the answer can be very comber some, but sometimes when you model it in the right way then you can get the answer.
So, here the computation was quicker, then because remember there I was solving the, I was trying to say 365 into 364 up to 365 minus n plus 1 divided by 365 raise to n, this should because less than half. And so I was wanting to compute an n and you could see that, this will require trying out trial and error of lot of values of n before you get the answer and we got the answer I showed you that the answer would be 23. But now, if you model the situation through Poisson random, approximation of binomial through Poisson, then you get the answer in a much simpler way.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 7
Discrete Random Variables and Their Distributions

(Refer Slide Time: 00:15)
 
So, I will be taking about some other discrete probability distributions. So, the next one is negative, the negative binomial random variable, and this name is very suggestive. We consider the binomial distribution, which where the random variable, was representing the number of successes, where the number of trials is fixed. So, you perform n trials, probability of success is p, and then we asked for the probability of r successes. Now here it is the reverse, what we are saying is that independent trials are performed. Probability of success is p, p between 0 and 1. Trials are conducted till r success is occur. So, now it is the opposite; that mean now you go and conducting the trials, till r success is have occurred, and so x will be the number of trials required for r successes. In the binomial case, the trials were fixed, and you have to then ask for the probability r successes. Here the number of successes is fixed, and you are saying, what are the numbers of trials that you are required, so that r success is take place. 
So, here the random variable is the, number of trials. So, probability x equal to n and it is very simple to write it down, because so that means, see you will stop your experiment, the moment you hit the r x success; so that means, up to n minus 1 trials. If I want r successes occur in n trials, then up to n minus 1 trials r minus 1 successes should have occurred, and therefore the probability of that is n minus 1 choose r minus 1. Here we are using the binomial concept, and then p r minus 1 r minus 1 successes and 1 minus p n minus r failures, and then the last one is the success. So, therefore, the total number of successes add up to r, but you are here wanting r minus 1 successes to occur anywhere up to n minus 1 trials, the last trial must be… So, the n’th trial in this case must be a success. So, your n can vary from r r because you want r successes. So, at least r trials have to be conducted. So, therefore, n is r r plus 1 and so on, and this number can go on up to infinity. 
Now, since the experiment continues till r successes occur. So, therefore, when you add up n equal to r to infinity probability x equal to n, this must add up to 1, and therefore, this is a combinatorial argument, to say that what we have defined here, is a probability math’s function. Analytically also 1 can show, that this sum will equal one, but then you require little more mathematics. So, therefore, we just satisfy ourselves, by giving this combinatorial argument, that we will continue the trials still a success occur; the r success occur. And also probability x equal to n is non negative for n varying from r r plus 1 n and so on, so this defines a p m f, so this is a valid p m f: When r is equal to 1; that means, if you just looking for the first success, and x is the number of trials required for the first success, then obviously, you put r equal to 1, so that becomes 1 and so this is 1 minus p n minus 1 into p; that means, the first n minus 1 trials must end up in failure.
 So, therefore, 1 minus p rise to n minus 1, and the moment you hit a success you stop. So, 1 minus p rise to n minus 1 into p and n can vary from 1 onwards. x is now called the geometric random variable, and the corresponding p m f is the geometric distribution. Now, interesting application of a negative binomial random variable, and the distribution. So, this is known as the Banach match problem. Banach was a very famous mathematician, and he was a heavy pipe smoker. So, he does not waste time in looking for the match box and then lighting up a match, to light his pipe. He would carry 2 match boxes; one is in his left hand pocket, and the other one in the right. So that wherever he puts his hand, he gets a match box and he lights his pipe. Therefore, that is how he was dependent on smoking his pipe. So, each time he needed a match, he would equally likely take it from either of his pockets. 
(Refer Slide Time: 05:21)
 
So, it was equally likely that he would put his hand in the right hand pocket or on the in the left pocket, so probability of that is the same. And now consider the moment when the mathematician first discovers, that 1 of his match box is empty. So, now, assume that both the match boxes initially carried N matches. So, we are asking what is the probability that the other match box contains exactly k matches. So, that means, initially both had capital n number of match sticks, in the match boxes, and then when he discovers that 1 of the match boxes is empty, and the other 1 is contains exactly k matches. So, this is what we have to find out the probability of this event. So, let us say that, consider the case when the left hand pocket has k matches left; that means, right hand pocket is empty, and left hand pocket has, the match box has k matches left. 
Here again I should say when the left hand pocket match box, is having k matches left, so I have left out that match box; that is the mathematician discovers the empty pocket at the. see he emptied the n match sticks in the right hand pocket, and here he emptied n minus k, because k are left in the left hand pocket, and then on the n plus 1 nth, when he put his hand in the n plus 1 nth, or when he takes out the match box at the 1 plus nth time. I mean from the right hand pocket, then he discovers it is empty. So, the total numbers of trials are n plus n minus k plus 1, so exactly situation of a negative. So, taking out a match stick from the right hand pocket as a success. So, we will (( )) is a success. So, let us say that. So, we will say that, the right hand pocket, taking out or putting the hand in your right hand pocket, and of course, when you put as long as the match box has a stick, you are also taking out stick match stick. So, therefore, whichever way you want to put it, but anyway taking out a match stick from the right hand pocket is the success. 
Here looking for the n plus one th success, but where actually he discovers that it is empty. So, that a consequence of the match box getting empty, but essentially what we are saying is that putting his hand in the right hand pocket is a success, and putting his hand in the left hand pocket is a failure. So, random variable x which is equal to the number of trials required for n plus 1 successes. So, this is the exactly the case for a negative binomial distribution, and what we are saying here is, that this is actually; that means, this is happening, when you have add this many trials n plus 1 plus n minus k and therefore, by our argument, see the last one he discovers that it is; that means, at the 2 n minus k plus one’th trial, he discovers that the left right hand pocket match box does not have any sticks left in it. So, this would be 2 n minus k, if you n minus 1 r minus 1 and then 1 by 2 rise to 2 n minus k plus 1, so this will be the probability. 
But then since, either of the pockets could have emptied first. So, therefore, what we have saying is twice this. So, the required probability is, since either pocket can be emptied, required probability is twice of that, and so when you multiply by 2 this 1 disappears the required probabilities 2 n minus k choose n into 1 by 2 rise to 2 n minus k. Now, again these results I am just giving you without, because handling this thing, requires lot of mathematics, you will not do it. So, I will just simply say that, expected value of negative random variable, which has parameters r and p; that means, r number of successes are required, and p is the probability of success; that is r by p, and the variance of a negative binomial r comma p random variable is r into 1 minus p upon p square. 
So, for example, if you are throwing of a die; x is the random variable which is the equal to the number of throws of a die, required till number 1 shows 5 times. So, your r is 5 here, and p, because die we are assuming is fair die, so probability of each number showing up is 1 by 6. So, probability of number 1 showing up is 1 by 6. So, our p is 1 by 6 r is 5 and therefore, by this these 2 formulae, expected value of x is 5 upon 1 by 6 which is 30, and where is; that means, at least the expected value, the expected number of trials throws of the die required, so that number 1 shows 5 times is 30, and the variance is again by this formula comes out to be 130, 25 into 6. No this one 50. So, this is 150. So, that is about negative binomial and geometric distribution.
(Refer Slide Time: 11:27)
 
So, another discrete random variable which is quite useful, is hyper geometric random variable. So, I will demonstrate this through an example, and define this variable and corresponding distribution. So, consider an urn containing N balls, out of which m are white, and n minus m are black. Now a sample of size n is drawn, without replacing the balls; that is important, the experiment is conducted without replacing the balls. So, I keep taking out the balls and put them aside. So, now if x is the random variable, which counts a number of white balls selected. So, sample of size n is drawn. Total numbers of white balls are m. So, now, we look at the probability of the number of white balls being equal to k. So, k can obviously vary from 0 1 to m, because there are m white balls. So, the probability would be. Now here you see, we are using the multinomial distribution. 
So, out of m white balls, you want to select k, and out of the remaining N minus m black balls, you are selecting n minus k black balls. So, your total sample size is n balls, and the total number of ways of selecting small n balls from N balls is n choose n. So, this we have already gone through, when we were talking about the counting procedures. So, this gives you the, total number of possible ways in which you can select n balls out of N balls, and the number of ways which you can select k white balls from m white balls, and n minus k black balls from N minus m black balls. now here of course, this is meaning, when k such; that n minus k is less than or equal to n minus m, because. See, there is some connection between m k and n.
So; obviously, if my number m is very large, then I can select k number of balls, but then n minus k becomes negative, or n minus k is, so that means, it has to be less than or equal to n minus m, but then see, by convention if n minus k turns out be greater than n minus m, or n minus k is less than 0, then by convention we say that this n minus m choose n minus k 0. So, therefore, this has a meaning. So, we do not have to worry, because then there will be the probability would be. If k such that n minus k is greater than n minus m, or n minus k is less than 0, then these probabilities will be 0, and so there will be no math’s attached with those values of k. So, this is your this thing, and again; since when we are drawing out a sample of n balls, white ball may appear or may not appear, and a white ball numbering 1 2 3 up to m, may appear may not appear.
 So, this takes care of all possible cases, and therefore, this is a valid p m f. So, that means, what we are saying is, that summation probability x equal to k, k varying from 0 to m is equal to 1, and also these probabilities are all non negative. So, therefore, this is a valid p m f. So, this exercise you must do every time, we define a random variable and its corresponding probability math’s function. Now, let me just show you an example of, where we use, where we make use of hyper geometric random variable and its distribution, acceptance sampling in quality control. So, what you do is, of course, I have give you the numbers here are small, but usually the numbers are much bigger than what I am using here. So, suppose 200 items in the lot; some instrument or something is being delivered by a manufacturer, the whole lot is of size 200, and the claim by the manufacturer is, that no more than 10 percent are defective. So, this is the claim. 
Now; obviously, people do not have time and energy and man power, to actually inspect all the 200 items, and usually this number is very big. So, what the practice is, and that is why it is acceptance sampling. So, what you do is, after the shipment is received, a sample of size 10 is taken. Again the numbers are all, just for convenience sake, but usually there will be more realistic numbers. So, anyway a sample of size 10 is taken without replacement, and if there are at most 2 defective, the lot is accepted. So, you just at random choose a sample of size 10, from this whole lot of 200 items, and then you inspect those 10 items, and you have taken out the sample by without replacement. So, you inspect those and then in that sample of size 10, if you find 0 1 or 2 defective you will accept the whole lot, and you will say that it is ok, and then if there more than 2 defective, then you will reject the lot. So, this is what you call acceptance sampling in quality control.
(Refer Slide Time: 17:33)
 
So, let me just show you simple you know combinational exercise here I will do. So, that means for example, if 5 percent are defective in the entire lot, then it contains 10 defective and 190 non defective. So, here the claim by the manufacturer is that no more than 10 percent are defective. So, let me consider the case when 5 percent are defective in the entire lot, then it contains 10 defective and 1, because 5 percent of 200 is 10. So, 10 are defective and 190 are non-defective. So, now if you want to compute the number of defectives in a sample of size 10, x is this. Then you want to compute the probability let x is less than or equal to 2, which means probability x equal to 0 plus probability x equal to 1 plus probability x equal to 2. So, this is what you want to compute, and I will just show you the calculations here. 
(Refer Slide Time: 18:36)
 
So, what I am showing you here the probability, of number of defectives being x. So, that will be, this is the case when we are, say assuming that 5 percent are defective in the whole lot. So, then it is 10 choose x and then 190 are non defective. From the non defective am choosing 10 minus x, and then divided by 200 choose 10. So, this is a hyper geometric probability of choosing x defective; the samples size containing x defective, our sample size is 10. Hence probability of accepting a shipment that is 5 percent defective. So, we are saying, if at most 2 are defective in the sample size of 10. So, that probability would be probability x equal to 0 x equal to 1 and x equal to 2, which I have written down here, and if you look at the numbers. These are the 3 probabilities you add them up, and they come out to be 0.99 0935; that means, the probability of accepting the whole lot is 0.99. Now, if there are 10 percent defective, then there are 20 defective in the whole lot and 180 non defective.
(Refer Slide Time: 20:01)
 
So, in that case, the hyper geometric probability of x defective in your sample of size 10, would be 20 choose x ,180 choose 10 minus x, because you are taking a sample of 10 and divided by 200 choose 10, so this will be the probability of having x defective in your sample of size 10, which is taken without replacement. So, therefore, in that case the probability, of accepting the shipment that is 10 percent defective. Again, we want number of defective in the sample, to be not more than 2, so it can be 0 1 and 2. So these are the numbers, and here the probability is 0.9347. So, this is less than the probability that we attain for, when the shipment had 5 percent defective. That is the probability of accepting a 10 percent defective shipment is smaller, then the probability of accepting a 5 percent defective shipment. So, obviously, the less the defective, the more the chance of accepting the shipment, because the probability of getting 2, at most 2 defective in a sample of size, 10 will be smaller, if 5 percent are defective and when 10 percent are defective, this is what it is saying, and therefore, you can experiment with other values of the number of defective items in the whole lot, and then you can compute the probabilities accordingly.
(Refer Slide Time: 21:34)
 
So, relationships among hyper geometric, binomial and Poisson distributions. So, let me show you. I have already shown you, how binomial will approximate to Poisson, when n is large and the number of trials is large, and your n p converges to moderately small number. So, now here let me show you the inter connection between all these 3; in fact, 4 discrete random variables that we have discussed so far. So, now, again we say that population is an objects, and a number of a number of type a objects are there in the population, so the others are not a type. And the sample of size n is drawn without replacement. So, sample of size n is drawn without replacement, where of course, n has to be between 1 and N, and a has to be between 0 and N, and while discussing the hyper geometric series, I told you that even if this number is bigger than this, and by convention this is 0, so there will be no mass. 
So, we are really do not have to worry about the values of, as to what the, when I am writing this. hu sorry This is x. So, now, if I want to, and let p be a by n. This is the proportion of item, I am not using it now, I will be using it later on anyway. This is the proportion of items, item of type a, in the original population. So, I am denoting this by p, which I will make use of later on. Now, this probability; that is your sample size of n, contains x objects of type A. So, that will be choosing from a num x. a is the total number of type a objects, you want to select, so your sample should have x of them. So, this is a choose x, then remaining the population n minus a are the other kind of objects, from this you are choosing n minus x other kind of objects divided by the total ways in which you can choose a sample of size n from N. Now just write down these expressions. 
So, this will be a factorial divided by x factorial a minus x factorial. This will be n minus a factorial divided by n minus x factorial n minus a minus n plus x factorial. And then this is the denominator, so this flips over, and you get here in the numerator n factorial n minus n factorial divided by n factorial. So, let us simplify this expression what I will do is, this n factorial comes here, then x factorial and n minus x factorial. This I put together and you can see that am heading towards the binomial distribution, and then you see here, a factorial divided by a minus x factorial. So, the terms after a minus x plus 1 will cancel out. So, you will be left with a a minus 1 a minus x plus 1, from here and this is gone. 
And similarly here this many terms will go away. So, you will because left with n minus a n minus a minus 1 up to n minus a minus n plus x plus 1. One more from here, that will be up to that many terms. And then here similarly; n factorial I have used. Here now here n minus n factorial, so those terms will cancel out and you will be left with n n minus 1 up to n minus n plus 1. So, this is ok from here to here, this is fine. Now what I am doing is. So, this term this I can write as n choose x, then from here if I remove a from each of this, and this is a rise to x, because this is a a minus 1 a minus x plus 1. So, x minus 1 is comes from here and this is the accept a, so a raise to x this comes out. Then similarly if you remove n minus a from here, from each of them, from each of these terms n minus a, so that will also be in number n minus x, because this is n minus x plus 1, so when you include this point you will get this. So, this is 1, and then this is this, and similarly here it was, would be 1.
(Refer Slide Time: 26:30)
 
So, 1 minus 1 upon n minus a, and this is what you had, and then n rise to n we have taken, because here, this is minus n plus 1. So, you take out n from each of them and divide correspondingly. So, you will have N rise to small n, that is this here. Now, what I will do is, I should have written down this step here, what I am doing is, I will write this as, this is this. So, I will write this as maybe I will write it here. So, this is n c x, then a by n raise to x, out of this and then into divide by n. So, 1 minus a by n raise to n minus x, so all this, is equal to this, which is your binomial probability of choosing x items from n; that means, your number of defective, or number of type a items, from the sample size n x this, is probability is that. Now, this you see here, what we are saying is that x by a small; that means, a is a big number, large number; that means, the number of type a objects in your total population, is large. 
Then this number is also small, and this number is also small; that means, your N is very large, in such a situation you can see that, all these numbers go to 1 all of them, and this also goes to 1. So, this whole reduces to approximately number 1. So, this probability hyper geometric probability, of choosing particular type of objects, in your sample, that probability reduces to the binomial. Now I should have, I did not properly point it out here. See when we conduct the binomial experiment, we say that, the trials are occurring independently, and then you keep counting number of successes. So, in other words in this situation, the binomial experiment would be, when you are replacing the balls, because getting a white ball is a success, and so in the binomial situation you replaced back the ball that you have taken out. So, each time the probability remains the same, of getting a white ball, which is equal to a by n; see here a by n p. So, this actually comes out to be this p raise to x 1 minus p rise to n minus x. So, this is what I got. 
So, that means, the difference between a hyper geometric and binomial is, that you know for small values of the population size, it is without replacement the hyper geometric, but if you make the population size is large, and as I said all these 3 numbers should be small, in that case the hyper geometric reduces to is approximated by the binomial probability. And I have already shown you that binomial can be approximated by Poisson, where we were saying the same thing, that this should be small. So, in this case n into p, our p is a by N. 
So, this number should be moderately small, then we say that for capital n being large. Then we say that the binomial can be approximated by Poisson, or the binomial probability goes to Poisson, and here I have shown you that a hyper geometric goes to binomial, and by the same argument that I have shown you here, when I talk about, when I take lambda to be n into a by n, then you can show by again manipulating the terms; that the hyper geometric will go to Poisson, already in the earlier lecture I have shown you, that Bernoulli is binomial 1 p. So, relationship is there that when you have n, when you add up n Bernoulli random variables, you get the binomial. So, this diagram shows you the relationship between the, various discrete distributions that we have discussed so far.
(Refer Slide Time: 31:26)
 
Let us now look at the other types of random variables, which are continuous random variables. So, far we looked at discrete random variables, and their special cases. Now I want to describe continuous random variables, and then again we will look at the special cases of continuous random variables. So, essentially, these are random variables of which possible outcomes are uncountable infinite. So, here you cannot count, and therefore, for example, if you take a subset in r 2, then the number of points, is uncountable, and similarly if you take an interval on the real line, and you consider all possible real numbers, that is a uncountable set. 
Examples are lifetime of a transistor, because you do not know when exactly a transistor will fail, but see you might say that, because you have finite clock, so you can say, it failed at this, you can actually say that the lifetime is finite, but then it depends on your counting system. I mean as fine as you make it then you know the lifetime, you can treat this as a uncountable infinite; the arrival of a train at station and so on. So, 1 can go on adding list to this, and as we go through the topic, we will come across so many continuous random variables. Now, one way to define a continuous random variable would be, that suppose there is a non negative function f x, define for all real x on the real line minus infinity to infinity, having the property that for any set b of real numbers. 
The probability that x belongs to b, is integral of the function, this non negative function f by d y over b. So, here by our definition we are saying that if x belongs to the whole real line, then the probability of that will be integral minus infinity to infinity, and f by d y d y is 1. So, we are putting this condition, and therefore, by definition f is now known as the probability density function, as a post to probability math’s function, because now this is a continuous case. So, we differentiate between the continuous and discrete by. So, in this case the function is probability density function, and for the discrete case, we called it probability math’s function. So, this is for the random variable x. So, if there is a function like this, and if a it satisfies these conditions. So, it is a non negative function, then we say that f is the probability density function of the continuous random variable x.
(Refer Slide Time: 34:31)
 
So, let me give you some more idea about continuous random variable. So, you know one can also define a random variable x, as a variable whose distribution function is continuous everywhere. So, actually the name continuous random variable, has come from here, because the distribution function of a continuous random variable is continuous; that is why we call the random variable continuous. So, actually there is nothing about, you know calling a random variable continuous or discrete. We actually say random variable is discrete, because it is cumulative distribution function is discrete; that means, it has jumps, and we say that a random variable is continuous, if its distribution function is, f x is continuous. So, this is everywhere; that is 1 definition.
Another one can be, random variable x is said to be absolutely continuous, if their exist an integrable function f x from r to r. So, that f x is non negative, for all x belonging to r, and its distribution function f x satisfies the equation that f x of x is equal to minus infinity to x integral of f x t d t, x belonging to r for n for n real number. That means, the probability x less than or equal to small x, that probability is obtained as integral of minus infinity to x f x t d t x belonging to r. And then if you see that, since the distribution function has the property that limit f x x as x goes to plus infinity is 1. So, therefore, you see the value of this integral minus infinity to infinity f x t d t will also be equal to 1, and hence these function small f x that we are saying has to be non negative, is actually the p d f, for the function x. So, either way, either you define it through F, and then you say that f, the small f will be the p d f, or sometimes you may define this small p d f, and then small f to be the p d f and then you define the distribution function anyway. 
So, the thing is that, most of the time in this course, I will not saying absolutely continuous of the time, but whatever is absolutely continuous I will call it continuous, and then I will distinguish between mixed random variable, so; that means, discrete random variable, mixed random variable, and continuous random variable. So, what I refer to, is continuous random variable, will be is actually by definition absolutely continuous, because the way we have been handling, we are defining the continuous random variables and the p d f’s in this course, this definition this is a right one. I mean we are following this definition that capital f x x is equal to minus infinity to x f x t d t x belonging to r. So, whichever way, but I just thought that ,one needs to say little more then what I said in the lecture, about a continuous random variable, and of course, through examples we will come to know, quite bit more about the various kinds of continuous random variables that we come across, and their properties. Now, if b is an interval, then probability x belonging to a, b will be a to b f x d x, and this what I am trying to show you; that if this is, the curve of f x, then this implies that it is actually the area of the curve. 
(Refer Slide Time: 38:26)
 
And of course, I have written it out here, that in terms of your yeah I will come to that. So, then and if a equal to b, then this this reduces to probability x equal to a, and that means, a to this sorry b a. So, the integral will be from a to a f x d x and by again definition of the integral, this is 0. So, therefore, mass at a point for a continuous random variable is 0; that all the probability that a continuous random variable, assumes a fixed value is 0, this is what we are saying by this. right and therefore. So, I will come to this point is that see the interval I have been writing as an open interval, but here I have written as closed. So, it does not matter, because where that you include the point a or the point b or both, the masses at the individual points at the fixed points a and b are 0; that means, no probability attains to fixed values of the random continuous random variable, therefore, it does not matter, whether I write it as this or as a I write it is in open interval. 
And then, since the probability x less than or equal to x. am sorry this is not correct I want to say here, this is X. So, this is now we are defining the cumulative distribution function, the probability x is less than or equal to x, and this will be in by our definition minus infinity to x of f y d y. So, this is the cumulative distribution function of x, and from the figure you can see that, this is again f b minus f a, so; that means, this will be that area from minus infinity to a under the function f x; that is f a and then this area up to b would be f b. So, you are essentially looking for the area, between in the script inside the script and so this is area into the curve. So, I have shown you that, for the x is a continuous random variable, then the cumulative distribution function, has been defined according to this, and so we can also then, have the concept of a of the probability in an interval a to b and that is the area under the curve. 
Now, let me just make emphasize 2 points here, that you see as a post to discrete random variable, where it was important whether in an interval, when you are talking of probability of random variable in an interval, then whether the n points are included in the interval or not. For a discrete random variable it mattered, because every point has some positive probability, I mean are non negative. Now for a continuous random variable you see, it does not really matter, because there is no concept of a probability at a point, the idea that at a point the probability is 0. So, therefore, whether I say a less than or equal to x less than or equal to b or a strictly less than x less than or equal to b has no relevance. So, therefore, it is understood, and see that is why am writing the integral from a to b here, f y d y. So, for continuous random variable, at a point there is no concept of probability, or the mass, whatever or the density, because it is a density. 
So, we measure it on an interval. Secondly, for a continuous random variable, we will call it cumulative distribution function; that is the proper notation. And here again, if some places, it may just happen that, without realizing it I may have used the word density, but does not matter. The proper notation is that it should be cumulative distribution function, when your random variable x, or in fact, for this notation, holds for x continuous or discrete random variable. So, the word is cumulative distribution function. We saw that for a discrete random variable, it was summation, and here it will be in the form of an integral, because you are computing the probability of random variable continuous random variable over the an interval. Now we want to check that f x has the properties of a c d f, and so the first thing you want to check is, that this limit of f x x as x goes to minus infinity will be 0. 
So, I should have said that this is equal to 0 here, and of course, this is immediate, because the limit as x goes to plus infinity, would be this integral minus infinity to infinity f y d y, and since f is a probability density function by definition minus infinity to infinity, this integral should be equal to 1, so that part is. So, now for this, again the argument may look repetitive, we have already used it elsewhere, but let me just repeat it. So let x n be a decreasing sequence, such that x n is going to minus infinity. Now we define the events E n, which are all points in the sample space for which X is less than or equal to x n. Then you see again E n, this as n goes to from 1 to infinity, is decreasing sequence of events, and limit E n is n goes to infinity will, be empty, because you know as n goes to infinity, you will be talking of event where x is less than or equal to minus infinity. So, they can be no real number, which is less than minus infinity, and therefore, E n n goes to infinity is phi, is the empty set. And again by continuity of the probability function, you will say that probability of you know limit probability E n as n goes to infinity, is same as limit probability E n as n goes to infinity by continuity and therefore, this will be phi, because the probability of empty set is 0.
(Refer Slide Time: 44:40)
 
So, this properties also satisfied, and will verify the other properties also, and for to show that it is monotonic, for a less than b. This is f x, we want to show that f x is less than or equal to f b. Now since capital f x b can be written as minus infinity b then b being bigger than a, I can break up this integral into minus infinity to a f y d y plus from a to b f now. This is non-negative, f is a non negative function, this is a finite interval, because b is greater than a. So, again this number is something non negative, therefore, your probability or your f x b is bigger than f x a. So, the function F is monotonic, and therefore, it satisfies all the conditions for cumulative density function, and hence we our definition is proper here. Now the question, if you just define a function like this, and you ask whether is it c d f of the random variable x, then what do we all need to verify. We need to verify that, for minus infinity; that means, you need to verify that minus infinity to 0, E raise to x by 2 d x this is equal to what. 
See it should from minus infinity to infinity it should be 1, this should, no sorry I am showing this is a c d f. So, this is not p d f am not checking is p d f. So, what is happening is, E rise to x by 2 limit as x goes to minus infinity, because this is x less than 0. So, as x goes to minus infinity this should go to 0. So, that is fine, because x goes to minus infinity E raise to x will go to 0. So, this goes to 0. Now, look at limit 1 minus E raise x by 2 as x goes to plus infinity. So, what is happening here. This portion goes to infinity. So, therefore, this is going to minus infinity, and not equal to 0. So, therefore, this does not define c d f. So, we can continue I mean 1 can try to see if any one of the condition fails to be satisfied here, we will conclude that the function that we are looking at, is not a c d f. And similarly as we have done it for the discrete case also, we check very 5, and we define continuous random variable, that the whether it is a valid p d f or not, probability density function. 
Then I will also try to later on give you examples, where the random variable can be the mixed kind; that means, some for some portion of the real line, it may behave like a discrete random variable, and then for some points on the real some portion of the real line it may be continuous random variable. Now another thing that I want to point out is, that since you are defining your c d f as this. So, necessarily by the theory of integral calculus, it turns out that this has to continuous function. 
So, that another way of differentiating between; that means, if for a certain part of a real line, your c d f is continuous, then we will assume that the corresponding the part of the random variable is a continuous random variable. And we saw that when it is a discrete random variable, your graph of capital the c d f has jumps, and the jumps are equal to the probability of the random variable at that particular point. So, therefore that means, you can have now c d f, which is for in part step function, and in part it is a continuous function. So, I will try to give you examples of such, and then that case we will say, that the random variable is the mixed kind. So, that means, all kinds of random variables exist, discrete, mixed kind, and continuous.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 8
Continuous Random Variables and their Distributions

We will go through exercises on discrete random variables when I will try to give you small hints, so that you can work them out yourself.

(Refer Slide Time: 00:2
 
Now, the question 1 says that each voter is for proposition that petrol price should be slashed by rupees 5. So, people are supposed to vote for this with probability 0.9. So, the probability that a person will vote for this that the prices should be slashed by rupees 5 is 0.9. What is the probability that exactly 7 of 10 voters are for this proposition. So, you should be able to guess what distribution you have to use here. At least one half of an air plane’s engines are required to function in order air plane’s there is a apostrophic there.
So, at least one half of an air plane’s engines are required to function in order for it to operate. So, if there are, obviously we are assuming that even numbers of engines are there. So, half of them have to function in order for the plane to be able to fly. So, if each engine independently functions with probability p, for what values of p is a 4 engine plane more likely to operate then a 2 engine plane. So, please first write down the probability of two or more engines working for a four engine plane, and two for two engine planes, it would be 1 or 2 engines working for two engine plane in terms of p, and then write down any quality that you want the probability for the four engine plane to be higher. So, what would be the values of p for which this is any quality would be satisfied.
Question 3: A new boy purchases papers at rupees 2.50 and sells them at rupees 3. However, he is not allowed to return unsold papers. If his daily demand is binomial random variable with n equal to 25 and p equal to 1 by 3, then approximately how many papers should he purchase so as to maximize his expected profit? So, now, see you start with you do not know exactly how many news papers he buys. So, let us say the number is r. That means r successes binomial random variables. You know the probability. What is the probability? It is when this daily demand is the binomial random variable with this, right. How many papers should he purchase? So, essentially what you have to show here is that the expected value would be a function of r, the number of news papers he buys, right and that you have to then maximize with respect to r.
So, that will tell you what the optimum value of r will be because here see when you take the expected value depending on the demand, it will tell you that when he is able to sell a newspaper, he earns 50 paisa. If he is not able to sell a paper, then he loses 3 rupees. So, accordingly you have to write down the expected profit for this newspaper boy and then, maximize it and find out the optimum value of the number of papers he must order.
(Refer Slide Time: 03:28)
 
If X has a distribution function F, what is the distribution function of e rise to x? So, you have to find that out. Again apply the definition. What is the distribution function of alpha X plus beta, where alpha and beta are constants, alpha not equal to beta. Then, question 5: Let n be a positive integer valued random variable. Show that expected value of n. So, n takes positive integer values. So, expected n is sigma i varying from 1 to infinity probability n greater than or equal to i. So, it is a matter of writing out the expression for e n and then, rearranging the terms, so that you can get this answer.
Six problem: If X is Poisson random variable with parameter lambda, show that E raise to X n is lambda E raise to X plus 1 raise to n plus 1. Now, use this result to compute E expected value X raise to 4. This is straight forward from a set of n randomly chosen people. This problem I have already discussed with you in one of the lectures. I explained the notation E ij that a person i and j have the same birthday. Assume that each person is equally likely to have any of 365 days of the year as his or her birthday. So, then you have to find these conditional probabilities that I have written out here and then, I am asking the question are E 3,4 and E 1,2 independent.
Then, what can you say about the independence of the events E 1,3 and E 1,2 and you can almost guess what the answers would be. Leave it. Anyway, you have to work it work out, and show that they are that means you have to show that the probability of E 3, 4 intersection E 1, 2. That means, all these four people are having their same birthday will be product of the probabilities of E 3, 4 into E 1, 2 and so on, right.
(Refer Slide Time: 05:23)
 
A question 8 prove the recursion formula for X Poisson which is probability X equal to i plus 1 lambda upon i plus 1 into probability X equal to I with lambda as its parameters. So, Poisson random variable with lambda as the parameter, then you have to show this and if you start with probability X equal to 0 equal to E raise minus lambda, then you can compute probability X equal to 1. So, 1 from this recursion formula, then I also want you to compute probability X less than or equal to 100 when the mean of the Poisson distribution is lambda 100, and you can compare your results because Poisson tables are not easily available. So, in the website, you can go and look at the tables.
For a hyper geometric random variable, determine a probability X equal to K plus 1 upon probability X equal to K. So, here also I am asking you to find out the recursion formula. Question 10: The number of eggs laid on a tree leaf by an insect of a certain type is a Poisson random variable with parameter lambda. However, such a random variable can only be observed if it is positive. Since, it is 0, then we cannot know that such an insect was on the leaf because there will be no eggs present on that leaf. If we let Y denote the observed number of eggs, then probability Y equal to i is equal to probability X equal to i, given that X is greater than 0, where X is Poisson with parameter lambda. So, find E Y. So, I am asking you to find the conditional expectation of X.
Question 11: Each game you play is a win with probability P. You plan to play 5 games, but if you win the fifth game, then you will keep on playing until you lose. So, here negative binomial would be used to find the expected number of games that you play. Find expected number of games that you lose. So, I hope you are enjoy doing this exercise.
(Refer Slide Time: 07:18)
 
I will continue with the new examples and some more results about the cumulative distribution function because it is a very important concept and also, we go along with special distributions and so, we will be able to get more familiar with the whole idea. So, let us consider the function G x which is defined here for x less than 0 by this, and for x non-negative by this, then we want to show that limit of G x as x goes to minus infinity must tend to 0, which it does because e raise to x goes to 0 as x goes to minus infinity. Similarly, limit of G x is x goes to plus infinity should go to 1, and that also you can see because this is e rise to minus x. So, as x goes to infinity, this portion goes to 0. We left with 1. So, that is fine. Then, you want to show that G x is mono and G x is monotonically increasing. So, we take the derivative here because G is a continuous function differentiable also.
So, I can take the derivative and if the first derivative is non-negative which it is e raise to x half. This is non-negative for all x. Therefore, G x is monotonically increasing. So, G prime x will be half e raise to x for x less than 0, and it will be this is a minus sign. So, there is minus 1 will come from here. So, it will become plus. So, that will be half e raise to minus x for x greater than or equal to 0. So, we see that G prime x is non-negative for all x. This is the non-negative function. So, therefore, G prime x is non-negative for all x which implies that G x is monotonically increasing which is again a property of G that of a cumulative distribution function.
So, we are just verifying that this qualifies to be cumulative distribution function and then, other properties we will check G satisfies all the conditions for being a c d f, right. Now, we also have this result that if f is continuous in an interval, then f the integral of f from minus infinity to x, this is differentiable on that interval. So, wherever whichever region f is continuous capital X, the cumulative density function would be differentiable. So, that means, if you are given c d f and then, it is differentiable, then you can differentiate it and say that it will be equal to pdf wherever the function is differentiable right and also, we have seen it already that since this is equal to probability x less than or equal to x, then this is integral minus infinity to x of f y d y and this defines again the area under the curve from minus infinity to x.
So, now, given this since we have verified that this is the valid c d f, let us now find out the probability density function which we said that we get by differentiating the c d f. So, here you see G prime x is half e raise to x if x is less than 0, and when you differentiate this part, the minus sign becomes plus. So, this is half e raise to minus x which is for x non-negative. So, actually this is very important that when you define the pdf, you have to specify where it is defined because that means where it is non-zero, and where it is 0 because you have to say where the mass is of the random variable.
So, it is very important. Sometimes people just forget this and you simply write this only which is not correct because you must specify the region in which it is defined. That means where the mass exist now. So, therefore, this and this is a non-negative function. You see that right and now, you can verify that this is valid pdf by integrating it from minus infinity to infinity. So, that will be minus infinity to 0 e raise to x, right and then, plus half 0 to infinity e raise to minus x d x, and you can see that the integral would be half e rise to x minus infinity to 0. That will give you, so at 0; it will be 1, right. So, that is half and minus half. So, when you integrate this, it will be minus sign half e raise to minus x 0 to infinity. This again gives you half. So, half plus half is 1. So, therefore, we have verified that your small f x is p d f and also, that this is c d f.
(Refer Slide Time: 12:19)
 
Let us take another example of this cdf. Now, here an electronic component functioning time before it fails can be considered as continuous random variable x, and suppose it is pdf is given by this, so therefore, you want the first question is for what value of lambda is f x? Pdf. Obviously, we apply the condition because it is a non-negative function. So, the second condition is that from 0 to infinity, since here again you see the mass is of x, non-negative for x less than 0, it is 0, right. So, I will integrate the function from 0 to infinity and e raise to minus x by 50. So, this becomes minus 1 by 50 comes to the top to the numerators of minus 50 lambda e raise to minus x by 50 from 0 to infinity. So, at infinity, this is 0 and at 0, it will be 1. So, 50 lambda is equal to 1. This is a condition we need, so that this is a valid pdf. So, we get that lambda is 1 by 50.
So, the first question has been answered. Now, I want you to compute probability x less than or equal to 150. So, you compute 0 to 150, 1 upon 50 e raise to minus x upon 50 dx which comes out to be this and then, it is 150. So, at 0, it is 1 and then, this is minus e raise to minus 150 by 50 minus 3. So, look up the value for this from your calculator and you get the answer. Now, as I said that there are discrete random variables, continuous random variables and mixed kind of random variables. So, I will take up this example for a mixed random variable.
Suppose you have given this example capital F x, right. So, I plot it for x less than 0, it is 0. So, this is a portion. Then, you note that here this is x less than 0, for x equal to 0, and greater than 0 than this part operates, right and therefore, the value jumps to 1 by 3, ok. Then, it continues to be 1 by 3 till x reaches 1, but it is not equal to 1. So, therefore, at this point, it is 1 by 3 and then, it is like this and here at 1 here. So, you see the continuity part is satisfied. There is a jump here again at x equal to 1 because at x less than or equal to 1, less than 1 is 1 by 3. The moment you attain the value x equal to 1, it jumps to 2 by 3. So, here again the jump is of 1 by 3 and then, after that you see what happens is this is x upon 3. So, if x varies from 2 to 3 at 2, see this is 2 by 3 and this is also 2 by 3, x equal to 2, right.
So, it continues like this. This slope is of this line 1 by 3 and then, of course at 3 as long as say this is the line and then, it becomes free. So, you see here you have both kinds that the functions take as jumps. So, it is a step function for some values and then, after that it is a continuous function. So, therefore, that is what I have said that here, and we have already seen that how we compute this difference, but I am saying that probability x equal to 0, this will be f 0 minus f 0 minus. So, f 0 minus is 0, f 0 is 1 by 3 and therefore, the values 1 by 3 probability is x equal to 0, and probability x equal to 1 will be f 1 minus f f 1 minus. So, that will be because f 1 will be 2 by 3 and f 1 minus is 1 by 3.
So, again the difference is 1 by 3. So, the two jumps are of 1 by 3. So, this is what will happen and here again I want to point out. See the result that we have shown that probability x less than or equal to x or of course, even for an interval same thing when I have shown you last time that the area under the strip would be the probability when x lies in an interval. So, here this thing is valid only when f is continuous. So, this is x is a continuous random variable now. So, therefore, for discrete and mixed kind, we will not apply this result.
So, only when the random variable is completely continuous, you can apply that result. So, here this is this result. So, one has to be careful and say keep this in mind. You cannot compute this by area under the curve because see the p d f would not be this. This is your cumulative density function, right. So, pdf would be for these two values. It will be a bar chart and then, it will be this thing. So, therefore, the concept of area under the curve does not apply for mixed random variable or for discrete random variable. It only applies to continuous random variable.
You know computation of cdf is very important. You should check. The idea should be very clear in your mind. How you can go about doing it and the validity you must make sure that when you consider a function to be cdf, it must have all the properties that we have you know said that the cdf must have and so on. So, you know this even was not enough. You should work out many more problems to get familiar with this concept.
(Refer Slide Time: 18:15)
 
We will talk about uniform random variable now which is one of the simplest and very widely used continuous random variable, and try to get the feeling about this particular distribution. So, now see suppose we pick number at random between 0 and 1. So, this is important we pick a number at random which means that any number is equally likely been using this term, very often describing events and so on. So, we pick a number at random between 0 and 1. The probability that it lies in the interval 0, x should be proportionate. It would be the proportion that the length of the interval 0, x is of the length of the whole interval 0 and 1. This is what we mean by picking a number at random.
I will repeat that if you are saying that I pick a number here and I say that it is lying in this interval 0, x. X is of course number which is less than 1, then the probability that the number lies in this interval should be the proportion that the length of this interval is of the length of the interval 0, 1. And if you can recall that when we in the discrete case, I had told you number of ferule cases divided by the total number of cases. It is sort of an extension over the same concept that if I am saying that the probability that the number that I pick up lies in this, then length of this interval divided by the length of the total interval should be the probability that the number I have picked lies in this interval, and this innocence captures the concept of uniform random variable or what we keep saying a number is equal likely in this interval and so on, right.
So, this will be when we are saying that probability of the number lies here. That means, this actually describes that probability, right because we are saying number that I pick between 0 and 1 lies in the intervals 0 x. That means, the number is smaller than or equal to x. So, it is between 0 and small x. So, therefore, this is f x and what am saying is that the cumulative density function is x upon 1 which is equal to x. If x is in between small x is between 0 and 1, so I immediately get the cumulative density function of this random variable and if you draw the picture, you see it is like this because as x goes from 0 to 1 and then, it stays at 1.
So, you see there is no discontinuity here, no jumps here. Therefore, this represents the continuous this is the graph of cumulative distribution function for a continuous random variable, the pdf. Of course, now we can use this fact that this is differentiable from 0 to 1 and so, the derivative of this function will give you the pdf f x equal to 1 in interval 0 1 and 0 otherwise. It is so simple, right.
So, this is one special case when I said that the random variable is defined on the interval 0 1. So, it is uniformly distributed in that interval. In general, we say that x is uniform random variable on the interval alpha, beta. If it is probability density function is given by 1 upon beta minus alpha x lying between alpha and beta and 0 otherwise, so you see I will again repeat that whenever am defining pdf or a cumulative density function, I have to define the region on which it is specified. So, of course for the cdf, it goes up to infinity because after whatever the values are over, then it stays at 1, ok.
So, therefore, you see here again this is proportionate to the length of this. So, the length of the interval is beta minus alpha, so 1 upon beta. So, here for example if you draw the graph of this pdf of random uniform random variable, this will be alpha and let us say this is beta, then this is the length. So, this height is 1 upon beta minus alpha which is greater than 0, and you see if you look at the area under this curve, this is rectangle height. So, the area is 1 upon beta minus alpha into the length. Length is also beta minus alpha. So, this is equal to 1. So, this is a valid pdf and the area under the graph you know that concepts.
So, now if you are for example, if you if you want the probability that x is less than or equal to some gamma, where gamma is some number here, right then it will be this area under the curve. So, this is how you can simply picturize, not go wrong with it, but just make sure that you write the probability correctly and always validate. You always make sure that you have the right number and then, you want to compute the expected value of general uniform random variable. This will be 1 upon beta minus alpha integral alpha to beta x d x which comes out to be x square by 2 alpha to beta. So, 1 upon beta minus alpha into beta square minus alpha square by 2. That leaves alpha plus beta by 2.
So, very simple way to remember whatever the interval for the uniform, you just add the two end points; divide by 2 and that gives you the expectation. So, it is a middle point expectation. So, what will it be? Yeah, just see here this is the alpha. So, alpha plus beta minus alpha by 2, right because the length of the interval has midpoint of this interval is beta minus alpha by 2 which you add 2 alpha to get to this point, right. The length here is beta minus alpha. So, half of the length, this length is beta minus alpha by 2. Add it to alpha and this gives you alpha plus beta by 2, right.
So, that is the midpoint, right. The expectation x square will simply make it beta cube. So, x cube by 3 and from alpha to beta, this will be beta cube minus alpha cube by 3 and you know expand this divide by beta minus alpha, you get this and then, for the variance, it will be expectation x square minus expectation x whole square which when you simplify comes out to be 1 by 12 beta minus alpha whole square. So, again here it is easy to remember the formula for the variance length of the interval square divided by 12. So, the length of the interval is beta minus alpha, square it up, divide by 12 and that gives you the variance of the uniform random variable.
(Refer Slide Time: 26:05)
 
Let us look at this example. Bus is arrived at a specified stop at 15 minutes interval starting at 7 am. So, that is the first bus arrives at 7, then the next bus will arrive at 7.15, then 7.30, 7.45 and so on. So, at interval of 15 minutes, the bus keeps arriving if a passenger arrives at the stop at a time that is uniformly distributed between 7 and 7.30 am. So, this is again an example because you cannot (( )) that time of the arrival of a passenger can be sort of treated as a continuous random variable. You might say that. Now, your clock gives you discrete time, but essentially the concept is that we will treat this as a continuous random variable. So, here the distribution of his arrival time is a uniform random variable between 7 and 7.30 am with equally likely what time he arrives from 7 to 7.30 am, ok. So, then you have to find the probability that he waits less than 5 minutes for a bus. So, he waits for less than 5 minutes for a bus.
(Refer Slide Time: 27:19)
 
See since the person should have to wait less than 5 minutes, therefore the event at we are asking for is 10 less than x and less than or equal to 15. It should be not less than or equal to because we want that waiting time to be less than 5 minutes. So, equality would have been valid if we had said that the waiting time is 5 or less, but here we are saying the waiting time is less than 5 minutes. So, therefore, it should be 10 less than x. So, make the correction because while computing the probability, I think I have said 10 less than or equal to x. Similarly, here it will be 25 less than x.
So, see here if he has to wait less than 5 minutes, then it should be arriving. So, his arrival time should be greater than 25 and less than or equal to 30. So, please make that correction, then computation. I said the probability part, it does not make a difference, but here it will with the event have to be described correctly. Then, you see he should arrive between 10 and 15. See his time is between 7 and 7.30, right. So, the first bus arrived at 7, the next is going at 7.15. So, if he has to wait for less than 5 minutes, then he should arrive to 10, right and then, it should be bet less than 15 because he has to get the bus. So, this 5 minute interval if he arrives in this interval, then he will have to wait or less than 5 minutes, right. Similarly, it is if he arrives in this time interval 25 and 30. So, this is in minutes and then, again he will have to wait for at most 5 minutes. Is that ok?
So, the event that he has to wait less than 5 minutes for a bus. So, these two events capture this event and since, they are disjoint, I can add up the probabilities, right. This and this are disjoint because the person cannot arrive at both the times, both time intervals. Either he arrives here or here. So, therefore, these are the two events. So, the probabilities add up and here the probability as I told you, this is simple. When you divide I was drawing the figure for you somewhere here. So, it is the length of the interval divided by the interval in which your variable lies just what example we looked at, right.
So, this length interval is 5 and 1 by 30 because his distribution is uniform. Distribution and the length of the interval is 30. So, 1 by 30 is the probability of being, I mean the pdf is 1 by 30. So, therefore, this is 5 by 30 plus 5 by 30 which is 1 by 3, right. Now, the second part is he has to wait more than 10 minutes. So, if he has to wait for more than 10 minutes, then he should either arrive in this interval because if he arrives anytime between 0 and 5 minutes in the see x. So, that is what is important. I should have specified x is the minutes past 7 am when the passenger arrives at the stop.
So, x is the random variable because the arrival itself is a random variable. So, therefore it is random phenomena. So, x, the number of minutes which is past 7 am when the passenger arrives at the stop. So, therefore, if you want to describe this event that he has to wait for the bus for more than 10 minutes, then he should either arrive. That means the x should lie between 0 and 5 or between 15 and 20 because if he arrives at 15 minutes, the bus has just left. So, he will have to wait for the next bus which will come at this thing 7 if he comes at 7.15. Then the other one will come at 7.30. So, he will have to wait for more than 10 minutes, right and up to 20 because if like he arrives at 7.20, then he will have to wait for 10 minutes because the next arrival would be at 7.30, right. I hope that this event is described by these two again. These two are disjoint.
So, therefore, we can add up the probabilities and this will be 5 by 35 by 30 which is 1 by 3, ok. Now, important usefulness of random variables because there will be many variations when we will see how uniform distribution is used. For example, in simulation you need to generate random numbers from a particular pdf and simulation is the order of a day. Sometimes if you cannot get physical data, you try to generate it.
(Refer Slide Time: 32:26)
 
So, here what you will do is, you want to generate random numbers and we can use this concept of cdf very nicely here. So, take X to be a random variable and capital F is the corresponding cumulative distribution function. Now, define the random variable Y which is F X because now whatever the function F, I just place a capital X there. So, this becomes a random variable again and this is uniform 0 1. So, this is the way where we will use the property of a cumulative distribution function. Now, you can show immediately this property because if you consider the probability of Y less than or equal to small y, then this is the probability of F X less than or equal to y, right which you know will be 0 if y is less than 0, right and will be FX inverse y if y is between 0 and 1, and this will be 1 when y is greater than or equal to 1.
Now, I have to use the concept of F inverse here which I did not mention earlier. Now, a whole idea is that here let us take x to be continuous random variable. In that case, your FX is monotonically increasing which we have seen through so many examples also that FX and we proved that also. This is one of the properties that FX is an increasing function and therefore, x inverse FX inverse will exist. So, there is no problem in case x is. So, I am now giving you this property of generating of random number for a continuous random variable, but they are certainly even when x is a discrete random variable. This may not be unique, but you can very usually you know there ways of determining unique value for the FX inverse which is possible.
So, see whenever x is not continuous random variable and is discrete, then for certain interval as we saw, the value of the function FX will remain constant. So, we can decide that the inverse, when we take the inverse, we will take the smallest value of y. So, that is possible. So, we can define, we can determine the inverse in a unique way whether the function random variable x is discrete or continuous. So, this will be valid for both of them, but here I am just now talking about x being continuous random variable. So, therefore, now again this thing can be written as F X of F X inverse y and therefore, from the definition of F X and F X inverse, this comes out to be y which is that means, your capital Y has a uniform distribution 0 1, right.
So, the idea is that you generate random numbers u1, u2, un random numbers from the uniform. So, of course, you might check it how do you do that and there are methods, there are computer methods for generating random numbers, but which are actually pseudo random numbers. So, there are whole lot of techniques and lot of available for generating these random numbers which are actually pseudo random numbers from the uniform 0 1. Once you do that, then you will say that the x i given by f inverse of u i are random numbers from the distribution of the original random variable that you started, right.
So, the process is that you generate random numbers from the uniform 0 1 and then, take the x i which have given by F inverse x u i, and these would be the random numbers from the distribution of x. So, now, you see you can immediate application of your uniform distribution. So, you can generate any number of values from the specified pdf to you know do all kinds of analysis that you want to do about that data.
(Refer Slide Time: 36:27)
 
So, I would like to revise the concept of expectation of a random variable now and for the discrete case, we saw that it is defined as summation x i p x i over all x i for which the probability is positive, right and if these values x i that the random variable x takes r finite in number, then this will be the you know finite number because you are adding up p x i are all between 0 and 1. These are finite in number, and then this will add up to a finite number. So, in that case whenever the random variable takes a finite number of values, the expectation always exist, right, but we also saw that in case of Poisson random variable where the values are taken by the variable r countable infinite, in that case the expectation which is the sum of this series, we could add up and show that it is actually equal to the parameter of that Poisson and in fact, it is right.
So, this is also called the mean of the Poisson distribution. So, for this case where the values taken by the random variable are infinite, countable infinite, the expectation exists. So, therefore, there always has to be when we define the function e x, we will say that this is the expectation provided. It exists.
So, now look at another random variable which takes countable infinite numbers. For example, take the probability of x equal to n as c upon n square takes values 1 to infinity. Now, since you want this to be a valid pmf, so the summation n to 1 in 1 to infinity of probability x equal to this should be capital X equal to n is this summation, right and therefore, this is equal to you know this series is a convergent series, and it is known that the sum of the series 1 to infinity 1 upon n square is actually pi square by 6, right. So, your c must be 6 by pi square.
So, once I defined my c to be 6 by pi square, this is valid pmf, but when you want to compute the expectation, the expectation would be c sigma n into 1 by n square n varying from 1 to infinity, but then this sum series 1 by n summation 1 to infinity, we all know is divergent series and therefore, expectation does not exist, right. So, therefore, one has to be cautious and careful and make sure that I mean e x is defined only if it exists.
Similarly, in the case of continuous random variables, this integral may not always exist even if your f is a valid pdf probability density function, and I will give you an example here. This is known as the pdf, where F X is equal to 1 upon pi into 1 upon x square x varying from minus infinity to infinity. This is known as the Koushish distribution pdf and here again, this is a valid pdf because integral minus infinity to infinity 1 upon pi 1 plus x square d x. So, integral of 1 upon 1 plus x, x square is tan inverse x minus infinity to infinity 1 upon pi and then, tan inverse of infinity is pi by 2 tan inverse of minus infinity is minus pi by 2. So, therefore, this becomes plus and this is equal to 1.
(Refer Slide Time: 40:19)
 
So, this is again a valid probability density function, but when you want to compute the expectation of this random variable, you have to integrate this particular integral and you can show that here you see if I make this substitution that x square is equal to, so actually this is running proper integral and I will just consider the integral from 1 to infinity. Let us see and if this does not exist then, obviously 0 to infinity will also not exist and therefore, this whole thing will also not exist. So, let us put x square equal to t and then, your d x x d x is d t. So, x d x you replace by or there will be 2 somewhere should have because this is then your 2 x 2 x d x is equal to d t. So, this will be 1 by 2 here, right, x d x is 1 by 2 d t. So, this is integral of this is l n of 1 plus t 1 to infinity and you know that l n of infinity is infinity.
So, therefore, this integral does not have a finite value. So, your expectation does not exist and hence, your variance will also not exist. Now, since variance of x would be e x square minus e x whole square and we have just seen that e x does not exist for this particular random variable. So, therefore, variance also will not exist because it has to be e x square minus this. So, if this does not exist, that means, this is not finite. Then, obviously variance will also not be finite. So, we will say that it does not exist. So, I just thought that I will be putting this note here before we proceed with the other theory of probability theory, so that you can find, you know you cannot always be sure that the expectation of a random variable will exist.
Now, another very important or widely used concept in probability theory is that of normal random variable and its probability density function. So, the function is defined by 1 upon root 2 pi sigma e raise to minus 1 by 2 sigma square x minus mu square, where mu and sigma are parameters of the normal pdf and x varies from minus infinity to infinity. Now, you can look at this thing here e raise to minus 1 by 2 sigma square x minus mu whole square. So, it can be shown by people have already drawn the graph for a different values of x and mu and sigma. So, this is a bell shaped curve and it is symmetric about mu that you can see from here because x minus mu whole square.
So, it is symmetric. That means, on either side of mu you take the value, this sign will not matter and therefore, this is symmetric about the value x equal to mu and this distribution was discovered by, was defined by let us say French mathematician Abraham De Marvn in 1733, and can you believe that he was not very, he use to make a living, he used to spend time in a you know at that time dengue gambling house. He would be sitting in the evenings, spend whole evening there and trying to help people because he used this concept of the normal distribution to approximate binomial distribution and binomial distribution.
He was used to help people because it was a gambling house. People would come to bet money and of course, would want to win their bets. So, he would give them the probability of you know winning which bet and so on and so, he actually used this concept for approximating binomial distribution and we will be discussing those approximations little later on. So, this is how, but the concept he introduced is very important and very widely used one, and I think by the end of the course, you will also see how important this concept is to the probability theory and you know for various estimations that we want to make about different events and their probabilities. So, now let us see whether this is actually a valid pdf.
So, we want to integrate this function from minus infinity to infinity and show that the integral is equal to 1. So, here what I do is, I make the transformation. Yeah, I have made transformation y is equal to x minus mu by sigma, so then d y is d x upon sigma. So, d x upon sigma appears here which gets replaced by d y and 1 upon under root 2 pi is here. Then, this is e raise to minus y square by 2. This remains from minus infinity to infinity because mu and sigma are finite numbers. So, then we have to now integrate this, and let me call this integral as i. So, if I multiply this by another integral, this is the notation.
So, i square now will become a double integral 1 upon 2 pi minus infinity to infinity minus infinity to infinity e raise to minus y square plus t square by 2 d y d t. See t and y are dummy variables. So, it does not matter and therefore, I can say that this is also i minus infinity to infinity 1 upon 2 root 2 that becomes 2 because you multiplying them. So, e raise to minus t square by 2 d t. So, this is what you have and now, we want to be able to compute this integral and there this is where we will use polar coordinates. So, let me show you the computations.

Introduction to Probability Theory & its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 9
Continuous Random Variables and Their Distributions

 (Refer Slide Time: 00:14)
 
To compute that double integral, I make use of the polar coordinates, that is, I make the transformation x is equal to r cos theta y is equal to r sine theta. Then, you know, that dx dy, the element of area in x-y plane gets transformed to r dr d theta, that is the element of this term. Your r varies from 0 to infinity because r is a non-negative variable and theta varies from 0 to 2 pi. This is your polar coordinate transformation.
So, therefore I square, then becomes 1 upon 2 pi 0 to infinity 0 to 2 pi and e raise to minus half r square because this was x square plus y square will become r square cos square theta plus r square sine square theta since cos square theta plus sine square theta is 1. So, it reduce to r square. And this r dr d theta, right. And again, this is in a nice form because now you see, you have r here and you have e raise to minus half r square.
So, again we will make this transformation, right, that r square is equal to t that is what I am doing here. And so, your 2 dr, dr will be dt. So, r dr will be half dt and so, that is what I have written here, half dt and this will go to e raise to minus half t. So, this is and you write, and see the limits are 0 to 2 pi 0 to this thing.
Now, here what I have done is, already theta does not appear here anywhere. So, therefore, this is simply 1. So, with respect to theta this just integrates. So, 2 pi, which I have written here and then is only integration respect to r. And to integrate this I make the transformation r square is equal to t and so, this helps me to reduce it further. And this is, you know, minus 2 times e raise minus half t 0 to infinity. So, this reduces to this, which is equal to 1. So, we have verified, that the normal p d f, that we have defined is valid p d f.
And then, now the second step is to compute the expectation and instead of computing for e x we will compute expectation of x minus mu by sigma. That will be easier because we know, that the expectation of x is actually mu. So, we will show, that this expectation is 0 and therefore, get the answer immediately. So, here the, only in this integral you get this term x minus mu by sigma and so, again I make the substitution x minus mu by sigma is equal to y and that reduces the integral to this. Again it is of the same form. You see, that is why the expressions may look cumbersome, but the working is not very difficult and it is just a question of little patience and you start seeing where the calculations are going. So, now we have this.
So, again you make the transformation y square equal to t, the same steps, and you get this. And so, so now, what I am saying is, that before I make this substitution I will break up this integral to minus infinity. See, one way I can immediately from here conclude, that this integral is 0 because this is an odd integral, right. y is here, this is here, the change of sign will not matter. But here the change of sign will matter since this is from minus infinity to infinity, this integral will be 0, you know one of the… So, I just thought, that I will show you the steps.
So, what I am doing is, I am breaking it, breaking up this integral from minus infinity to 0 plus 0 to infinity and then, when you make that transformation, that y square is t, then you see, this becomes plus infinity because when y is minus infinity square will be plus infinity. So, this is from, so this would be infinity to infinity to 0 and the integral will be e minus half t, just as we did here and then, this will be 0 to infinity. So, now, it is a same integral expect that here the limits are upside down. So, when you change the limits it will become minus sign. So, there will be a minus sign here and the same integral with the plus sign. So, when you add, the result is 0, ok.
So, I just showed you the steps, in case you are not very sure, but otherwise we could have concluded our computation at this step only and said that this is equal to 0. So, since this 0 expectation of x minus mu by sigma, sigma is a constant, goes out. Therefore, this implies, that expectation of x is equal to mu. So, I had shown you that the normal p d f is symmetric about mu and this is also the mean. And in fact, mu has all the properties, that too now I will show some more properties of mu.
(Refer Slide Time: 05:26)
 
Similarly, to compute the variance of x, which is actually, since mu is the mean, it is actually expectation of x minus mu whole square, right. And this I will write in this form. So, now here what you have to do is, again if you have first make the transformation, that x minus mu by sigma is t, so dx by sigma can be replaced by dt, right. And the limits remain the same. So, this is the simple integral and this way comes sigma square because you have x minus mu whole square. So, this is sigma square t square. This is it.
Now, what I do here is, the t square I break up into t and t because this integral we have handled already, right. Well, computing this thing and so, therefore, we will do integration by parts. This will be my first function. That means, I take the integral of this, multiply by this and then, the derivative of this into the integral of this. This is your formula, right. So, this integral I have shown you is e raise to minus half t square, this t into this thing, and ok, no, no, why am I, ok, I am actually computing this for you. So, I am saying t e raise to minus half t square. dt is half, when I make the transformation t square is s, then 2 dt is ds. So, this reduces to this and therefore, is this right.
Now, applying integration by parts. The integral of this I have already computed for you is, this minus e raise to minus 1 by 2 s and so, this will be t into, when I transform back again substitute for s from here, this is t square. So, then t into e raise to minus half t square minus infinity to infinity, you can see, that this is 0, right, because this is t square. And so, in the denominator t square e raise t e raise to infinity is much, much larger than t in the numerator. So, therefore, this will be 0. You will be left with this
And then, here again this is what, this is your in a normal p d f where your mu is 0 and sigma is 1. So, the 1 upon root 2 pi is missing. So, therefore, this integral will be equal to root 2 pi because with 1 upon root 2 pi this will become 1, right. So, therefore, this whole thing is 1. So, this is, this integral is equal to root 2 pi, so I write root 2 pi, which cancels with this and this is sigma square. So, therefore, the variance of the random variable. So, therefore, the parameters are, now it is very clear what the parameters denote, mu is the mean and we say normal mu sigma square mu is the mean and sigma square is the variance.
So, we just saw, that normal distribution, the parameter mu is the mean and sigma square is the variance. Now, suppose x is n mu sigma square and we consider the random variable y equal to alpha x plus beta where alpha is a positive number and alpha and beta are some real numbers, right. So, I mean, I am continuing with the properties of the normal distribution.
So, if you want to find out the p d f of y, then we start with the cumulative distribution function. So, probability y less than or equal to t is probability alpha x plus beta less than or equal to t, which reduces to this and since alpha is positive, the inequality remains in that. So, this is t minus beta upon alpha, ok. And so, this is your cumulative distribution function y, which is equal to the cumulative density function of x, but the parameter the t replaces is, gets replaced by t minus beta by alpha, right. So, now, if you differentiate both sides, that means, differentiate with respect to t, then this will become the p d f, right.
And this is d dt of f x t minus beta by alpha, which will be 1 by alpha into f x of t minus beta by alpha, right. The derivative of capital F x will be the p d f of the random variable x. And so, when you substitute, you write down the expression for this, it will be 1 upon alpha 1 upon under root 2 pi into sigma e raise to minus 1 by 2 sigma square and your t gets replaced by t minus beta by alpha minus mu whole square. This simplify the expression, this gives you t minus beta minus alpha mu whole square. Here, you have alpha sigma and this is 2, sorry, the alpha in the denominator comes here. So, this will be, there will be a into, into alpha square also.
I hope you can read it, anyway I am speaking it out, may be let me just rewrite it whole thing here. Yeah, this is 2 alpha square sigma square. And so, by our definition of the normal p d f this will be n, the mean now becomes beta plus alpha mu at the various becomes alpha square sigma square instead of sigma, right.
So, therefore, you see, that if you make this transformation where x is normal mu sigma square, then for y, the expectation will become alpha mu plus beta, which anyway, you can show from here also. This is alpha expectation of x plus beta because beta is a constant and so, this is alpha mu plus beta. And the variance will be, just think because the constant will not matter, since you will see, when you write down the variance, you will write down this minus, I mean, this minus this. So, beta will cancel, alpha will come outside and so, it will become square.
And so, either way you can verify, that the, for the, for this random variable then mean will be beta plus alpha mu and the variance will be alpha square sigma square. So, you can see, that you can carry on the properties of normal variant.
(Refer Slide Time: 11:55)
 
Quite easily, now immediate consequence of this result is, that if x is n mu sigma square, then z, which you write as x minus mu by sigma will be normal 0, 1, right, because what is happening? Your, here alpha is actually 1 by sigma. If you compare it with the expression alpha x plus beta and your beta is minus mu by sigma. So, now if you substitute, because we said, that the mean will become alpha mu plus beta for that one. So, here it will become mu by sigma minus mu by sigma, so it is 0, right. And similarly, you can show, that the variance will be 1. So, the transformation x minus mu by sigma results in a standard normal variant and which we refer to as n 0 1.
Now, we have tables for computing the various probabilities for normal 0 1 and you see, that you can then compute the probabilities for any random, normal random variant through this and that is what, because, because of that transformation, right. And I will work out few examples to show you how it goes. So, anyway this is the standard notation for, for a standard normal variant. This is your probability minus infinity to x. So, that means, this is a cumulative density function. So, this will be 1 upon root 2 pi minus infinity to x e raise to minus half y square d y. So, this probability is given the notation.
Now, the tables are given for x non-negative, you know, for values of x going up to… We will, we will also later on see, that we do not need the values to be tabled for very large values of x. Then, for x less than 0 we use symmetry of the p d f around because this standard normal. So, this is, this is symmetric about the origin, right. And this is your, this is this, right.
Now, the symmetry means, that if you have x here, then the area to the right of this number is the same as the area to the left of minus x. This is what symmetry means. Because this area, this area are equal, therefore, and since this is half area and this is 0.5, so therefore, this shaded portion here same as the shaded portion here, and so the formula is this. So, if you tabled your values for x positive, then for x negative you can get by this and we can verify this formula right away.
If you want to compute phi of minus x, then that is minus infinity to minus x of fx dx. Now, if you write y as minus x, then x becomes minus y. So, the limits go from infinity to y, right, infinity to y f of minus y dy, right, and there is a minus sign here. So, you interchange the limits. This becomes y to infinity f of minus y dy, which is 1 of minus, no, phi minus y, right, because this is now y to infinity. So, therefore, by the formula this is this, but phi of minus y is phi of x. So, therefore, I have shown you, that this is 1 minus phi x. So, this formula has been verified.
So, now you can get values of the cumulative density function for negative, positive, both of x, right. So, let us look at few examples. Suppose x is normal (2, 4), that means, the mean is 2 and the variance is 4. So, then you want to find the probability, that x is between 2 and 4. So, I will use that transformation. So, here, sorry, this should be z, that means, what I am doing is, I show, I will write in detail.
I am subtracting 2 and dividing by 2, so less than x minus 2 by 2 less than 4 minus 2 by 2. So, this probability goes here, right. And now, so this is 2 minus 2, 0. And this is your standard normal variant, right. x minus mu by sigma is normal 0, 1 for which we always have this notation of z, right. And this is 4 minus 2 by 2, which is 1. So, this probability you can compute in terms of the standard normal variant in this way and by our notation this is phi of 1 minus phi of 0.
And from tables I get, that phi of 1 is 0.8413 and phi 0 will be 0.5 because we have said, that the standard normal is symmetric, the p d f is symmetric about the origin. So, this portion of the, so this area under the curve will be equal to 0.5 and this will be also 0.5. So, phi 0 will always be 0.5 because this is the area for phi 0, right, less than or equal to x less than or equal to 0. So, that would be half of the area, which is 0.5, right. So, therefore, this is the probability.
So, therefore, very conveniently, once you have the tables available for this standard normal, you can compute it for any normal variant, right. And again, find probability x less than 0 for this variable. So, here again I make the transformation x minus 2 by 2 less than, so this will be minus 2 by 2. So, this is probability z less than minus 1, so which is phi of minus 1. And then, I use this formula, this formula. So, phi of minus 1 is 1 of minus phi 1. phi 1, I already know, is 0.8413. So, this is 1 minus 0.8413, which is 0.1587, right.
(Refer Slide Time: 18:25)
 
Now, when you want to compute absolute x minus 1 greater than 3, so what are you saying here? You are saying, that your x minus 1 should be greater than 3 and x minus 1 should be less than, that means, x minus 1 should be less than minus 3 and x minus 1 should be greater than 3, yeah. So, from here what do you get, that x should be greater than 4. So, from 4 to infinity. And from here you get, that x should be less than minus 2. So, that means, it should be from minus infinity to minus 2. So, that is what we have done. I have written, that this event is equal to the, that means, x must be either here, minus infinity to minus 2 or it must be in the set 4 to infinity. Well, I have used a different notation here than here, does not matter.
Now, since these two sets are disjoint, you can see, right, minus infinity to minus 2 and this is 4 to infinity. So, I can write the probability as the sum of the individual probabilities and so, I get this. And again, I transform my variable x minus 2 upon 2. So, this remains minus infinity, this is minus 2, so minus 2 by 2.
And here, again I use the same transformation to reduce it to standard normal variant and therefore, this becomes phi of minus 2, yeah, because phi of minus infinity is 0 plus 1 minus, this will be what, this is 1 and this is infinity. So, here phi infinity is 1 and this is minus phi of 1, right. Because yes, you all agreed, that this is phi of infinity, I mean, this phi of infinity will be 1. So, therefore, and phi of minus 2 you can write is 1 minus phi 2, again by our formula for computing negative probabilities in terms of positive this thing and therefore, this is it.
So, I just substitute the values. phi 2 from the tables is 0.9772, this is 0.51 and so, this is the answer. So, one can go on and therefore, the whole idea would be, that you sit down, calculate a few of such probabilities by yourself to become familiar.
Now, let us just take an example here. The annual rainfall in inches in a certain region is normally distributed with mean 40 inches and sigma, that is the standard, we call by the word, I did not name it, but sigma, this is under root sigma square is referred to as standard deviation, this is also known as standard deviation. So, standard deviation is 4 that means, variance is 16. What is the probability that starting with this year it will take over 10 years before a year occurs having rainfall of over 50 inches?
So, let us understand the problem first. They are saying, that the annual rainfall is normally distributed. That means, if every year you add up the total rainfall in that particular region, then those numbers will be fitting a normal distribution, which has mean 40 inches and standard deviation 4, right. So, the numbers that you get as the total rainfall in a year for different years, so that has a normal distribution, right. Now, they are asking for a probability, that starting with this year you go on for 10 years and within those 10 years, no year will have rainfall more than 50 inches. So, it is, you know, actually compounded event, it is not a straight forward. So, let us see how we go about computing this probability.
So, to compute the probability x greater than or equal to 50, I will do the same trick, reduce this probability in terms of a standard normal variant. So, since mean rainfall was 40 inches, so x minus 40, standard deviation was 4, so this now reduces to a standard normal variant. So, therefore, the required probability is the same as probability z greater than or equal to 5 by 2, which is oh, oh, oh this is 1 minus, sorry, this has to be z greater than 5 by 2 would be 1 minus 5 phi by 2, right, and so, this will be 1 minus of this 1 minus 0.9938 and so, this will not be the required probability. We will have to write the number, anyway.
So, what we will do is, yeah, I will continue to say, that p is 1 minus 0.9938 or maybe, I will just do this. So, this is 1 minus 0.9938. So, this is the probability of, is the probability of rainfall. So, the probability would be standard normal variant greater than or equal 5 by 2, which will be 1 minus phi of, phi by 2, 5 by 2 and that is 1 minus 0.9938 because phi 5 by 2 is 0.9938. So, this is probability is.
Now, this we can look upon as the probability of rainfall being more than 50 inches in a year and this we will treat as a success. That means, now you can say, that in a year the experiment is to measure the rain and if the rainfall is more than 50 inches, we treat that is a success, right. So, that is what I said, that the problem requires because the event is complex.
So, first we computed the probability of the rainfall being more than 50 inches in a year, which came out to be this. Now, I want to find out, that in 10 years, rainfall not more than 50 inches in any year. So, that means, if I treat those 10 every year as a trial, that means, the trial is, you add up the total number of rainfall in that year and then you say, you are saying, that in 10 years there should be none of the years, that you count from beginning from this year, the rainfall is more than 50 inches. That means, in other words, there is no success in these 10 trials and so, the probability of no success in 10 trials would be 1 minus p raise to 10, which must be 0.9938 raise to 10. So, again please compute this number because I had made a mistake.
So, here this is, this will, whatever this number, you can now use your calculators to compute this probability to say that that will be the probability, that in 10 years the rainfall will be less than 50. So, this is. So, I am just trying to show you, that how you first use the normal of approximation, and then I mean the standardization and then, you, you use the binomial random variable to compute the actual probability.
(Refer Slide Time: 25:59)
 
So, median and mode of a normal distribution. This, again see, that is why, I mean, when you look at all these properties of distribution, you, you realize, that it, it is a very interesting one. And this is, suppose, what we mean by the median of distribution is the number for which the, for which your cumulative density function has the value 0.5. That means, the area of the, if you have this thing here when this is the, this is the point where this is x naught. So, this area is 0.5 and this area is 0.5.
And since we have already said, that the normal distribution is symmetric about x equal to mu, so that immediately clear, that the area to the left of mu is 0.5 and area to the right of mu is 0.5. So, immediately we know, that a median, the median is also at x equal to mu, right. Now, to define the, to obtain the mode point, this is the point at which F x, the probability density function attains its maximum value. We did this for the binomial also, remember, and what was the number at which the random variable attains its maximum probability.
So, now, in this case, we will have to find out the maximum, the value, the value of x at which this function attains its maximum value. So, this will be done by finding out the, differentiating it, finding out the critical point and putting this equal to 0. The derivative, now you see, that here this is the derivative. So, this portion is not 0. So, therefore, this is the only portion, which will be 0, and therefore that gives you x is equal to mu. So, x, x equal to mu is the point of maxima or minima essentially, or it could be a point of inflection. But, so now, we have to look at further the second order derivative to determine the nature of this critical point. And I have written down the expression for second derivative, that means, you differentiate this expression again and compute it at, evaluate it at x is equal to mu.
So, then you see this, this portion goes 0 because x equal to mu and here also, when you put x equal to mu, you essentially get this. So, this is again e raise to 0, which is 1. So, you simply get minus 1 upon 2 pi sigma square, which is less than 0. So, if, if the second derivative has negative sign at a critical point, that point must be a point of maxima. So, that much from calculus we can obtain. I am sure, therefore, it is really interesting, that x equal to mu is the mean, median and mode. So, it is all the things combined into 1.
Now, another important, as I told you, I have been, I have mentioned, that de Moivre was used to, you initially defined this normal distribution to approximate binomial probabilities. So, let us, formula is the procedure here. So, this is de Moivre Laplace limit theorem, which is, that if S n is the number of successes in n trials of a binomial random variable (n, p), then for any a less then b. So, here of course, for the binomial the mean is n p and the variance is n p q, right. So, for any a less then b if you want to look at the probability of a less than S n minus n p upon root n p q less than or equal to b.
So, you see, what we have done is, we have standardized this binomial random variable of successes in n trials, number of successes in n trials. So, it will be S n minus n p upon and root n p q right. So, then it is the de Moivres Laplace theorem says, that this probability can be approximated by phi b minus phi a where phi is your cumulative distribution function for the standard normal distribution or for the standard normal variant. So, this will be phi b minus phi a as n goes to infinity.
So, that means, for large n you can approximate this probability by phi b minus phi a and later on, we will show, that this actually is a very general, I mean, you can talk about a more general result when you do not really need to have the distribution as binomial. And for any distribution, this kind of thing, which we call as a central limit theorem, we will talk about it later.
But right now, de Moivres Laplace limit theorem simply say, that if you have a binomial random variable, then if you want to compute the probability, that S n minus n p upon under root n p q. So, this lies between a and b, a strictly less than this, then this can be approximated by phi b minus phi a. This is the Laplace theorem. So, now, we will use this.
(Refer Slide Time: 31:38)
 
And so we say, that now suppose, you want to compute the probability, that c is strictly less than S n is less than or equal to d and here, of course, it is understood c is also less strictly less than d, then we will standardize the whole inequality in the sense, that we will transform. 
This to c minus n p upon under root n p q and this will be less than S n minus n p upon under root n p q, which will be less than or equal to d minus n p under root n p q. And now, you see, this becomes standard normal variant and so, you’re a gets replaced by this in the theorem and your b gets replaced by this, right. And so, I can say, that by the de Moivre’s Laplace theorem, that this probability, which is the same as this can be approximated by phi of d minus n p upon under root n p q and phi of c minus n p upon under root n p q. So, this is the whole idea.
So, therefore, and these are, these values are tabulated. So, given c d have n n p, you can look up the tables and compute this probability. And of course, if you want to compute the actual probability, then we will see through an example, that it can be very, very cumbersome. So, in fact, this is a very useful theorem and it in a very simple way allows you to compute, approximate these, compute this probability, right.
And of course, then we will continue with the computations for approximating these probabilities and what they said is, that this is good enough as long as your n p into 1 minus p is greater than or equal to 10. That means, you do not require too many very large values of n, but as long as, of course, if this number is larger than 10, you get a better approximation and that you can also for yourself experiment with problems where you try to increase the value of n and then see, that your, the estimate will improve. So, anyway, but this gives good approximation as long as n p into 1 minus p is greater than or equal to 10.
(Refer Slide Time: 33:53)
 
Now, there is important aspect to this approximation and that is the continuity correction factor, which I will discuss here. So, you see, look at this curve. So, I have the binomial curve here, the bar chart. And then, the red line curve is the normal approximation and you see, what we are saying here is, that if you are asking for the probability x greater than c. This is the shaded portion that you are looking for.
So, here you want to say, that probability x greater than 7, if you are asking for this probability x greater than 7, yeah. So, then if x greater than 7 means, that x is greater than or equal to 8. So, to get that event, to get that probability, if you want a good approximation, see we are the rectangle, the bar, that represents the probability at 0.8. So, that is starting from 7.5. You want to cover that whole area because you are wanting probability x greater than or equal to 8. So, therefore, you will need to say, that your approximate, approximating standard normal variant should b greater than or equal to 7.5 and not 8.
So, because the, so you will want to say, for the continuity factor you will say, that you will do it from 7.5 because you want to use a, approx, include the area, which is at the point a. The probability, which is represented by, at the point a by this bar, should get added to the, to your estimate, right. And similarly, if you are wanting, let us say I am.
So, I have that table here, just look at the example. So, if you have x equal to 6, that means, a single value, if you have x equal to 6, then you would want it between 5.5 and 6.5 because that is the rectangle, the bar that you constructed at 6 that stands at, from 5.5 to 6.5 and the length, the height is the probability of that x equal to 6, right.
So, therefore, the continuity factor, that you require would be for probability x equal to 6, it will be 5.5 and 6.5. Your x must vary, then because see, the discrete situation, you are now approximating by a continuous situation. Then, as I said, x greater than 6 would be x greater than 6.5 and if x is greater than or equal to 6, then you are including 6, then you will have to go little further down, right. That means, you will have to start from 5.5. If it is x greater than or equal to 6, then you will begin from 5.5. So, x would be greater than 5.5 if x is less than 6. That means, x is less than or equal to 5, then again you will say, that x is less than 5.5. So, that is very clear from this graph. And x less than or equal to 6 would be x again.
See, the moment you have equal, then you have to go a little ahead of it, 6.5 and if it, it is strict in equality, then. So, the rule is very clear. And by looking at this figure you can always… So, if you keep this in mind, then you will not go wrong because you will realize, that you have to, you have to include the area under the bar or the rectangle, which is for that particular value, the limiting end value. And so, you will have to accordingly to give the correction factor, right. So, this is called the continuity correction factor because you are estimating a discrete situation by this thing.
So, if you use the continuity correction factor, now let, let us give this thing, let us give, let me give you, show you the calculations through an example. And so, let me show you an example through an example how we, what I mean by the continuity correction factor.
So, let x be the number of times a fair coin, so fair coin means, that the probability of showing a head and a tale are the same and that equals half, right. So, lands heads when it is flipped 49 times. x is the number of times head shows up when I have flipped fair coin 49 times. Now, find the probability, that x is equal to 25. Use the normal approximation and then compare it with the exact probability. So, I want to compute probability x equal to 25.
And as I told, I just discussed with you, that since this is the binomial random variable, you are trying to approximate it by a normal distribution. So, the bar is actually, when x equal to 25, the bar starts from, 20, 24.5 and ends at 25.5. So, this is the bar, right, and this, the height is the probability that you associate with x equal to 25. So, 24.5 and 25.5. So, therefore I have to change the two approximate again. I should say this, that the approximate this thing will be 24.5 less than or equal to x less than or equal to 25.5. So, I am now approximating this event by this event, right, because of the continuity factor and then, because the mean, yeah, I am sorry, this should not be 49. I have to write it correctly here.
So, now for this binomial random variable, your number of times, you flipping the coin is 49 probability, that your p is half. So, therefore, n p is 49 into 1 by 2, which is 24.5, right. So, it should be 24.5, right and your variance is n p q. So, that is 49 into 4 divided by, divided by 4. And so, under root of that would be and that is why, I choose this 49 to make it perfect square. So, that is 7 by 2. So, this is now standardized. So, x minus 24.5 divided by 7 by 2 would make it standard normal. And so, this is the event that you want to, you want to now find out the probability. So, this is this, right. And therefore, this is equal to 0 and this is 1 upon 2 by 7. So, therefore, this is equal to phi of 2 by 7 minus phi 0.
Now, this is phi of 0.28 minus phi 0, phi, phi of 0.28 from the normal tables is equal to 0.6103 minus 0.5, right. And so, this comes out to be 0.1103. So, this is our probability that we have obtained for x equal to 25 through normal approximation. And remember, the condition was, that your n p q must be greater than or equal to 10.
So, in our case our n p q is how much? n p q number is 49 by 4. So, which is more than 10, right, that is, our n p q is 49 by 4, which is equal to 42, sorry, 12 point something, 12 4’s are 48. So, 0.25. In fact, so this is more than 10, right. And so, we applied the approximation and this is the result that we got, right.
Now, exact probability if you want to compute using your binomial computations, then you see, it is actually 49 choose 25 and 1 by 2 raise to 49, 49 trials and your p and q are the same. If you write out this number, 49 into 48 up to 25 because that will be 49 minus 25 plus 1 and then, 20 factorial 1 upon 2 raise to 49. It took me almost half an hour to compute from, sitting at the computers and this number comes out to be 0.11275.
So, if you just look at this here and that is what I am saying, now you compare it with, so third decimal place, the number differs the value differs and therefore, I would say, that this is a good approximation. And here, you see our n p q was only, 10, 12.25. And if you take larger n, that means, if you had flipped the coin more than 49, then this number would have improved.
And just see the phenomenal calculations you had to do even for n equal to 49, I mean, multiplying these numbers, 24 numbers getting 25 factorial multiplying 2 49 times and then dividing. So, this this the amount of calculation, that you would have to do for the exact probability certainly is not required. If you can approximate this probability by this simple method because this table, these values are already available to you. And so, this is what I am trying to say, that you know, as we go on, you will see the numerous applications, uses of this concept of normal distribution and its computations.
(Refer Slide Time: 43:20)
 
So, I will continue with the examples of you know, binomial, the normal approximation of binomial probabilities and this is, these are two good examples from the book by Ross Sheldon. As I told you, that this is the book on probability theory and at the end of the course I will give you all these references. So, I just thought I will, you know, give you feeling of, you know, some more examples to, to reinforce the idea that the approximations of discrete probabilities can be done by the continuous random variables and in the very effective way. So, let us look at this example.
The ideal size of a 1st year class at a particular college is 150 students. From past experience the college knows, that on the average, 30 percent of those accepted for admission will actually attend the college. So, therefore, you know, people tend to apply to more than one college and then they, of course, decide which is the best one for them? So, the college has the experience, that only 30 percent of the people who have been accepted for admission will actually attend the college. So, therefore, the college adopts the policy of giving admission to 450, 450 students, so that finally, when they, you know, drop out, after the dropout rate, they will still be left with the, with the class of size 150. This is the idea. So, they decide to offer admission to 450 students. Now, compute the probability, that more than 150 1st year students attend the class, right.
So, given that 30 percent is the, so this is the probability of a person attending who has been given admission, will attend college is 0.3. So, therefore we want to find out. So, here, of course, we will say x is the number of students who attend college and so, the value of x will be equal to the, we can treat the person who has been given admission and attends college as a success. So, out of 450 people x will be the number of students who attend college. So, this would be a binomial random variable with n as your 450 and your p as 0.3 right. So, this is binomial (450, 0.3), because we are treating, that the experiment has been performed. That means, admissions have been offered to 450 students.
And out of this those who attend, who all actually come attend the college is a success. So, the number of successes we are saying is a binomial random variable, right. So, therefore, you have to compute the probability. So, actually you want that the class size should be, so you have to compute the probability of more than 150. That means, it should be 151, 152 and so on. So, therefore, when you write probability x greater than or equal to 151, then your continuity factor when you apply, then this will become 150.5, right because you are actually asking for the probability, that x is greater than or equal to 151 because more than 150.
So, therefore, we just standardize this, you know, this variant and that would subtract x minus n p. n p is 450 into 0.3 and then divide it by n p q. So, 450 into 0.3 into 0.7 and do this to the right hand side also. So, you get this and then, of course, the advantage of taking in solved example is, that you have the calculations done for you. So, here this is actually the phi of 1.59. So, this number reduces to 1.5.
So, therefore, this is your standard normal probability from minus infinity to, sorry, this is, yeah, to 1.59. So, we are writing this as 1 minus phi of, so this number is 1.59. So, this required probability is 1 minus phi of 1.59, which comes out to be this, 0.559. So, hence this reduces to 6 percent of the time more than 150 of the 450 accepted students will attend college. So, the college is in good situation, because it is only 6 percent chance, that more than 150 people will actually come and attend the college those who have been offered admission. So, this was one situation.
(Refer Slide Time: 47:57)
 
Now, another interesting problem. This is, see to determine the effectiveness of a certain diet in reducing the amount of cholesterol in the blood stream, 100 people are put on a diet. After they have been on the diet for a sufficient length of time, their cholesterol count will be taken. The nutritionist running the experiment has decided to endorse the diet if at least 65 percent of the people have a lower cholesterol count, right.
So, after the trial period, at the end of the trial period, you will again take a, test their cholesterol in the blood stream. And if the count is lower for 65 percent of the people, then after going on the diet, so the nutritionist will, have I made the sentence complete, running the experiment has decided to endorse, so the nutritionist will endorse the diet and say, yes, it is thus proven to lower the cholesterol in the blood.
So, now what we want to find out is, what is the probability, that the nutritionist will endorse the diet. That the nutritionist endorses the diet, will endorse, there I write, will, will endorse the diet if, in fact, it has no effect on the cholesterol level.
So, what we are saying is that suppose the diet has had no effect on the cholesterol, but what is the probability, that the nutritionist will still endorse it. So, therefore, now the way we are arguing out and so, we have to now decide how to model the situation. And the idea here is, that you know, it is either way. See, people may on their own have their cholesterol count come down and so, the chance of that happening is, we know, equally likely, either your cholesterol count goes up or it comes down. So, that is the equally likely situation and therefore, it is being said that ok, you can just take p equal to half. So, therefore we are assuming, that the diet has had no affect on the cholesterol level.
So, but the since we, the count is going to be taken after the trial period and then, if it turns out that 65 percent of people have lowered their count and they will be, then the diet will be endorsed . So, therefore, we will work with p equal to half. So, I hope it is clear. So, what we are assuming is, that chance of the count being going up and down is equally likely. So, therefore, we will take p to be half. And x is the number of people whose, whose cholesterol level is lower, right. Then, see what, what we are looking for is, so the binomial random variable.
And therefore, this is, this is the probability, sigma 65 to 100 100 i half raise to 100, right, because r and n minus r, both are will up to end. This is p is half. So, this is nothing and of course, you can see, that this is ((Refer Time: 51:03)) stupendous task, you know, trying to compute it this way. So, therefore we will say, that essentially, we are looking for probability x greater than or equal to 65 and again add the correction, continuity correction factor, so it will be 64.5 and then n p would be 100 into half and, and p q will be 100 into half into half, which becomes 25. So, under root 5 and this is 50. So, this is what you are looking for and this number comes out to be 2.9.
So, therefore, it is the required probability is 1 minus phi of the normal standard normal probability 2.9 from minus infinity to 2.9 and this comes out to be 0.0019. So, which is very small and therefore, the chance that you know, with p as half the chance, that the 65 people out of those 100 will have their cholesterol lowered is very low and therefore, the diet will not get endorsed.
So, anyway because the diet was not having as, as we said, that probably the diet has no affect on the cholesterol level, so therefore, it does not get endorsed. So, no loss, nobody is lost. So, this is how, you know, one can go on and look at different situations and then try to see. So, I just thought, that these two will also add to your, you know, experience of handling, you know, these problems and also reinforced the idea of, you know, computing, you know computing these, what shall I say, messy probabilities by you know, approximating through continuous random variables and making your task easy.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 10
Continuous Random Variables and Their Applications

 (Refer Slide Time: 00:19)
 
After discussing we normal random variable, we will today talk about the exponential random variable, a continuous random variable x whose PDF for some lambda greater than 0 please note that, the parameter has to be positive. Then f x is equal to lambda e raise to minus lambda x for x non negative and 0 otherwise is said to be exponentially distributed, all has an exponential distribution whichever way you want to say it. So, again we validate that this is the PDF indeed a PDF. So, it is non-negative since lambda is non-negative.
So, therefore by definition this is non-negative and the integral from 0 to infinity lambda e raise to minus lambda x d x would be minus lambda upon lambda e raise to minus lambda x 0 to infinity. So, it infinity it is 0 at 0 it is 1, so and with the minus sign, so minus minus plus, so this is equal to 1, so this is indeed a PDF, then you want to compute it is distribution function. And here this would be 0 to a, so this is probability x less than or equal to a, therefore this is integral 0 to a and this again comes out to 1 minus e raise to minus lambda a, a greater than or equal to 0, because our variable itself is non-negative.
Now, we verify the conditions that CDF must satisfy and so limit f a as a goes plus infinity is 1 from here you see as a goes to infinity this will go to 0. So, this reduces to 1 and I should have also written down the limit f a as a goes to minus infinity, see we have any way said that x is less than, I mean for x less than 0, this there is no math’s and when can I say it from here if a is less than 0 than of course, this integral is not defined, I mean if a is less than 0 than this integral is 0 are you can argue that there is no math’s for x less than 0.
So, limit f a a goes to this is 0, then f x is monotonically increasing, so therefore, you take the derivative of f prime of f x, which is f prime x that will come out to be lambda you differentiating. So, your f x would be well you treat a as x does not matter, so if you are differentiating this, so lambda would come here minus lambda minus lambda minus plus e raise to minus lambda x and since lambda is non-negative because, lambda is greater than 0. So, therefore, this is again non negative and so the function is monotonically increasing.
So, all the properties of cumulative density function have been are satisfied, then we find out the expectation of the random variable and that will be integral lambda 0 to infinity integral 0 to infinity x e raise to minus lambda x d x and by integration by parts I treat this as the first function. So, this will be this and now you see that at 0 this is 0, so therefore, and this is 1, so the product is 0 at infinity e raise to minus lambda x goes to or if you can write it as x upon e raise to lambda x, then e raise to lambda x goes to infinity much faster than x does, so the ratio tends to 0.
So, therefore, no contribution from this term and you are left with just this, so therefore, again you integrate minus 1 upon lambda e raise to minus lambda x there would be infinity that gives you 1 by lambda. So, the way to remember is that if lambda is a parameter for the exponential distribution and it is defined in this way, then the inverse of the parameter is your mean or the expectation some places people define it as 1 by lambda minus 1 by lambda x.
So, in that case you are expectation will become lambda, so it is inverse of the parameter whatever you use for defining this, the inverse of that will come out to be the. So, then to find out variance you find out the expectation x square and I have not done the calculations here. But, again in the same way you will have to two iterations of the integration by parts, here x square is the second function, this is the first function and you continue doing it, so then that comes out to be 2 by lambda square.
And therefore, variances 2 by lambda square minus 1 by lambda square, which is equal to 1 by lambda square. So, quick example normally this would be associated this distribution was would because, you know when you go to any public place where there is a service counter for example, post office or railway booking and so on. Now of course, it is mostly online, but still people have to go to counters for all the services, then you know the time that the clerk will take to service the customer is most of the time random variable.
And, so exponential variables do model that situation quite few this thing, so suppose the length of service at a post office counter in minutes is an exponential random variable with parameter lambda is equal to 1 by 15. So, immediately you can say that the exceptive number of time that the exceptive duration of service to a customer would be 15 minutes. Because, the expected value of the this random variable would be 1 by lambda, which is 15 minutes.
(Refer Slide Time: 07:00)
 
If someone arrives immediately ahead of you at the counter find the probability that you will have to wait 15 minutes between 15 and 30 minutes to find the probability that you have to wait for 15 minutes. That means, at least 15 minutes, so therefore, the event would be x greater than or equal to 15, where is x is your time for you have been to wait. So, probability x greater than or equal to 15, which will be equal to 1 minus probability x less than 15.
And therefore, we have computed this already while computing for x less than exponential distribution. So, this would be 1 minus of 1 minus e raise to minus 15 by 15 because, your lambda is 15, so therefore, this probability comes out to be e raise to minus 1, which is 0.368. Since, as I have said that because, we have already made this computation that this will be equal to 1 minus e raise to minus 15 by lambda and your lambda is 15. So, therefore, this will be equal to e rest to minus 1 and so this is 0.368. 
So, similarly for the second one probability 15 less or equal to x less than or equal to 30; that means, you are waiting time is now between 15 and 30 minutes. So, that will be again by the same computations will be f 30 minus f 15 and which again would be 1 minus e raise to minus 2 because to be 30 by 15, which is minus 2 and then this is minus of 1 minus of e minus 1. And so because this is less than or equal to 15 and so less than or equal to 15 less than 15 for a continuous distribution, so it will be this the probability.
And, so it is e raise to minus 1 minus e raise to minus 2, which is 0.233, now I want to show you another important property of the exponential distribution. So, first of all we will talk about the memory less property and we say that random variable x said to have the memory less property. If probability x greater than s plus t given that x is already greater than t is equal to probability x greater than s for all s and t non negative, which means that it does not matter how long you have already waited, if you are asking for this probability x greater than s plus t then it is same as probability x greater than s.
So, therefore, the system we are modeling does not have memory less property and so we are talking of random variable whose distribution satisfies this condition. So, now I will show you that the exponential distribution among all continuously distributed random variables are among all continuous PDF's exponential distribution have the probability of being memory less distribution, which are discrete and which have also the memory less property.
But, among continuous distribution random variables, which is exponential distributed has the memory less property. So, in case this random variable is exponentially distributed with parameter lambda, then you see if you write down this expression probability x greater than s plus t given that it is x is greater than t, then this will be this because, even the product of these two would be intersection of this two when should be x greater than s plus t, you would because, it is t smaller than s plus t.
So, this reduces to this expression x greater than s plus t divided by x greater than t, now by our definition this is because, f a is 1 minus e minus lambda s. So, 1 minus f a would be simply e raise to minus lambda a, so here it e raise to minus lambda s plus t divided by e raise to minus lambda t and which is this, which is equal to probability x greater than or equal to s. So, exponential random variables are memory less and in fact, little more arithmetic would be required or calculus to show, that if you impose this property.
Then you can actually show that the only exponential random variables have the memory less property. So, since this is being our first course I am omitting the mathematics here, but who was interested can sit down and work it out and see that, when you start with this condition for a continuous random variable, then you will see that only exponential random variables the PDF, which will satisfy this condition will actually the exponential PDF.
So, let us again look at an example, suppose that the number of hours before a transistor phase is exponential distributed with mean 500 hours. So, here the lambda is 100, if a person desires to go on a long trekking trip of 300 hours and uses the transistor in his radio, then we want to find out what is the probability that the transistor will not fail.
(Refer Slide Time: 12:27)
 
What is the probability that the person will be able to complete his trip without having to replace the transistor. So, he wants that the probability that the transistor will not fail for 300 hour long tracking trip that he is undertaking, so the solution is that affects is one upon 500 e raise to minus 1 upon 500 x. Because, in the problem it says that the hours the lifetime of the transistor is exponential distributed with mean 500, so as I was telling you if the mean is 500, then the parameter will be one upon 500.
So, therefore, the PDF of the random variable representing the lifetime of the transistor would be given by this x nonnegative. So, therefore, probability x greater than 300 is simply e raise to minus 3 by 5 because, it is e raise to minus 300 upon 500 which is e raise to minus 3 by 5 and you can compute this value from the table. So, what can be said when the random variable is not exponential distributed and that case the memory less property is not there.
And, so this would be simply conditional probability in terms of capital f and so that is it you see the advantage of having random variable, which is memory less. Now, another thing that is useful and can be again for exponential random variable it gets quite simplified and that the hazard rate function or sometimes you also called the failure rate function. So, if x is a random variable which is representing lifetime of some item and of course, it does not non negative variable and the CDF the PDF is given by small f and CDF by capital F.
Then hazard rate function called the failure rate function is denoted by lambda t and is defined as follows. So, lambda t is small f t that is the PDF divided by 1 minus CDF, so and the simple explanation is possible, so here again what we are saying is that x belongs to this is the bracket here, t plus delta t, delta t is very small and then given that x is already work for t now what we are saying, that it will fail just after t because, t plus delta t. So, x lies in the interval t comma t plus delta t given that it has been functional till time t.
And, so this is probability x belongs to t comma t plus delta t, delta t is a positive quantity very small. So, therefore, when you take the intersection these two you get this event divided by probability x greater than t and so this will be by our definition f t plus delta t minus f t divided by 1 minus f t. So, now, you see the limit of this delta t becomes smaller, then you know you divide by delta t and multiply by delta t, so this divided by delta t remember limiting value of this is the derivative of f at t. So, which becomes f prime t into d t upon 1 minus f t and f prime t is your PDF f small f t divided by 1 minus f t d t. So, therefore, the definition of the failure rate because, as we see that it should fail just that t time, time t is rate has been functional up to time t then it fails.
(Refer Slide Time: 16:24)
 
So, now if f t is exponential you see when you write out this will be small f t, so the PDF is mu e raise to minus mu t, I used symbol mu because, lambda is already being used here and this is 1 minus f t would be e raise to minus mu t. So, you see this is mu a constant, so for exponential random variable we have that rate is a constant, it is not a function of t. Otherwise, as you see that this will be a function of t, so the hazard rate function is dynamically changing depending on the time.
That means, if you are talking of lifetime, so as it should be, but for exponential distribution exponential is simple, since it is memory less therefore, the hazard rate function does not change it is a constant. So, this is the rate of failure and so because it is memory less, it does not matter how old the instrument is the probability of it is failing any time is same. And so here the rate is also constant mu is therefore, also referred to the rate of the exponential distribution. So, now, mu is the parameter this is also the rate of failure for exponential distribution and we saw that one upon mu will be the mean of the exponential distribution.
(Refer Slide Time: 17:40)
 
So, given hazard rate of function lambda t for a continuous random variable, it is possible to determines it PDF. So, we will just show because, you see lambda t I can write as d d t of f t 1 upon minus f t and then if I take the integral of both the side attach a minus sign. So, there is minus sign here, this is 0 to x lambda t d t and this is integral 0 to x minus f prime t, I written this as f prime t d t upon 1 minus f t, now by formula for integration because, derivative of this is this therefore, this will be l n of 1 minus f t.
So, therefore, l n of 1 minus f x because, you computing from 0 to x, so there is 1 minus f x will be and this is integral minus 0 to x lambda t d t, I hope this is clear. Because, see this will come out to be l n of 1 minus f t and this is from 0 to x, so 0 to x when you put x here, this will be l n of 1 minus f x and at f 0 is what, f 0 is 0. So, l n of 1 is 0, so therefore, the contribution from here you get is l n of 1 minus f x, you remember limit f x as x goes to minus infinity 0. So, therefore, I am just using that. So, that reduces to l n of 1 minus f x and this right hand side this is minus 0 to x lambda t d t.
So, therefore, you can say 1 minus f x is equal to e raise to minus 0 to x lambda t d t and so f x you can write down from here as 1 minus of e raise to minus integral 0 to x of lambda t d t. So, if I know lambda t, then I can integrate here and then my f x will be of this form, so; that means, it is enough if you know the hazard rate function of random variable, you can determinate distribution. So, once you know the equality density function, you can determine the PDF also.
Now, I will just illustrate the concept some more through an example, this is see it is said that the death rate of a smoker is at each stage twice that of a non smoker. That means, this that your age gets reduced by half, if you are a smoker compared to what a non smoker. So, what is the ratio of the probability of a non smoker to that of a smoker of surviving up to the age of, so suppose I am just saying that, what the both of them surviving up to the age of 60 given that both have survived up to 50 years, you want to find out the probabilities.
So, may be ratio part is not important all I am saying is let us find out the probabilities that non smoker will survive up to the age of 60 given that he or she has survived up to 50 years. Similarly, a smoker the probability what is the probability of a smoker surviving up to 60 years, given that he had survived up to 50 years. So, I will define lambda s t as the hazard rate of the smoker and lambda n t as the hazard rate of non smoker. So, now, let me just right now take instead of 50 just let me take some years A age A.
So, what we are saying is that a probability that a non smokers life time is more than 60 years given that the life time of the non smoker has been more than A is the conditional probability. Because, again the intersection these two because, 60 is more than A, so this is probability that the non smoker has been, the life time will be more than 60, so that becomes 1 minus f n 60 divided by 1 minus f n A. And from here, I will see this is 1 minus f x is e raise to minus integral 0 to x lambda t d t. So, that is would be 0 to 60 lambda n t d t and 1 minus f n a will be 0 to A lambda n t d t e raise to...
So, this is what we just computed here and therefore, if you take this upstairs, then you see the integral this become e raise to A to 60. So, this will be e raise to minus integral of A to 60 lambda n t d t and this let me call as p n, so the probability of smoker surviving up to the age of 60, given that he has already survived up to the age of A.
(Refer Slide Time: 23:01)
 
And correspondingly for a smoker this probability of surviving up to 60 years given that he had survived up to A years is lambda s t d t and I am calling it as p s. So, if the belief is that lambda s t is twice lambda n t; that means, the death rate is twice as high for a smoker compared to a non smoker, then I substitute for lambda s t twice lambda n t here. So, that will be twice lambda n t and so this would becomes square of I would not writing the step I mean actually this is equal to e raise to minus A to 60 lambda n t d t square, which is probability p n square.
So, the effect is that the probability gets squared up for a non smoker, so the probability of surviving up to the age of 60 for a smoker is square of the probability of the non smoker surviving up to the age of 60. So, this 50 was not really because, A could be anything here, so given at that is why we said, that at any age at each stage, so therefore, it does not matter when you are making this comparison. So; however, the old both the people are after that if you want to say what is their age of surviving up to 60, when the probability for the smoker is square of the probability for the...
So, now, here as I said that if you take lambda n t to be 1 by 30; that means, remember I am taking the situation when. So, that means, this is now because, this is constants, so therefore, I am taking the exponential situation, that is the random variable the lifetime is random variable is the exponential distributed, then a probability that non smoker reaches the age 60 would be because, this lambda n t is 1 by 30.
So, you want to compute will it come out to be e raise minus 1 by 3, e raise to minus you are saying this is 50, 60 and 1 by 30 d t. So, what will that be 1 by 30 into 10. So, this is I mean e raise to minus, this is e raise to minus 1 by 3, so if this is a constant; that means, it corresponds to exponential random variable. And so this is e raise to minus 1 by 3 which turns out to be 0.7165, so for a non smoker and for a smoker it would be a square of this, which will be 0.5134.
So, see how fast the probability has reduced because, person smoking, so the probability of a smoker surviving up to the age of 60 is 0.5134 and for a non smoker it is 0.7165. So, that we wanted can have many more applications and it has will go long may be I have put some problem related to hazard rate function in your exercise 4 also.
(Refer Slide Time: 26:42)
 
Now, we continue with some more special continuous random variables and the next one is the gamma distribution and x is said to have gamma distribution with parameter alpha and lambda, both the parameters have to be positive PDF is given by this equation. So, effects is lambda e raise to minus lambda x lambda x into raise minus 1 upon gamma alpha and that is why the name.
(Refer Slide Time: 27:05)
 
So, this is let me show you the calculation for the gamma alpha, so let us compute the value of gamma alpha for alpha greater than 1. So, therefore, the definition is this is equal to 0 to infinity e raise to minus y, y rest to alpha minus 1 d y right, so integration by parts and therefore, this will be the derivative here is e raise to minus y should be minus. So, here this is minus e raise to minus y, y rest to alpha minus 1 0 to infinity and then this becomes plus because, minus minus is plus.
So, therefore, this will be plus 0 to infinity then derivate of this is alpha minus 1 y rest to alpha minus 2 e raise to minus y d y. Now, let us compute the values at the end points, so for y equal to 0, see this will be 0 because, alpha is greater than 1 and that is why it is important. So, alpha is greater than 1 therefore, this is a positive power, so therefore, this is 0 and of course, at 0 e raise to 0 is 1, so this is equal to 0 and again y goes to infinity, then this goes to infinity faster than this here again because, alpha is greater than 1, so this exponent is positive and therefore, this will go to 0.
So, therefore, no contribution by this term and so your integral, so gamma alpha reduces to just this, which by our notation will be gamma alpha minus 1 should. So, therefore, I did not write, so here it relatively; that means, this integral will be now alpha minus 1 and so for positive integral values of alpha, if I you know go and doing it iteratively. So, for integer values of alpha positive integer values of alpha, this we can see is gamma alpha would reduce to factorial alpha minus 1.
You can see that because, as go on, so the finally, what you will have be this will be then I should have, this is alpha minus 1. So, this should be equal to alpha minus 1 gamma alpha minus 1 from here alpha minus 1, so therefore, as you go on the next iteration it will be gamma alpha minus 2. And so as we go on alpha is a positive integer therefore, you end up finally, with just integral 0 to infinity e raise to minus y d y and so this will reduce to alpha a factorial of alpha minus 1 for alpha be positive integer.
Now, it can also be shown that the gamma function is defined for alpha between 0 and 1, this is also possible we can also show that the integral will is defined that it will be finite value. So, for all values of alpha between 0 and 1, the integral is also defined; that means, gamma alpha is defined for alpha between 0 and 1. And one important value is gamma 1 by 2, which is root pi and this integral we will obtain this values later on in the forth coming chapters.
So, I will talk about fractional values of gamma alpha between 0 and 1 and there are tables available for fractional values of alpha. The tables available non negative fractional values of alpha tables are available and for alpha equal to 1 the gamma distribution reduces to the exponential distribution.
(Refer Slide Time: 31:00)
 
All of to check the see our gamma PDF is given by this, so when you put alpha equal to 1 this term is gone and so your PDF reduces to lambda e raise to minus lambda x and gamma alpha is also 1. So, therefore, you will be the gamma PDF reduces to lambda e raise to minus lambda x for x no negative, so therefore, for alpha equal to 1 the gamma distribution reduces to the exponential distribution. So, this is one relationship and then I will show you some other relationships between many other this thing.
Now, you want to again check that this PDF is a valid PDF and therefore, I have to show that this integral will evaluated to 1. So, here of course, you put lambda x equal to y, then lambda d x is equal to d y and immediately this integral reduces to e raise to minus y lambda d x gets replaced by d y and this is y rest to alpha minus 1 upon gamma alpha. And so from here you see that divide by gamma alpha here and this equal to 1, so the validation is complete.
So, therefore, this is the valid PDF and now you want to compute the expectation of this gamma random variable, then you have to multiply this by x and integrate, but it is easy to manipulate because, I will add x to this and lambda also. So, I divide by lambda, there I multiply by alpha and multiply here by alpha, so this becomes gamma alpha 1 by our definition. So, this will be gamma alpha 1 and this will be lambda x rays alpha, so; that means, the PDF of gamma here the parameters are alpha plus 1 and lambda.
So, therefore, since this is again the PDF for gamma alpha 1 comma lambda, so again it will integrate to 1 and so you will be left with alpha by lambda. So, the expected value of alpha, lambda, gamma, variable is alpha upon lambda, so; that means, if the convention to write this first and then this. So, then this divided by this that is you are taking the gamma distribution alpha comma lambda, then similarly expectation x square can also be just by simple manipulation computed immediately, what I will do I need lambda square here to bring together with this.
So, I divide by lambda square and I multiply by alpha alpha 1 to make it gamma alpha plus 2 and this will be lambda x rays to alpha plus 1. So, again this is the PDF of gamma alpha plus 2 lambda, so this will integrate to 1 and I will be left with alpha into alpha plus 1 upon lambda square. And so variance will be this quantity minus alpha lambda whole square and that gives me alpha upon lambda square, so simple calculations to tell you the required quantities.
(Refer Slide Time: 34:25)
 
Now, let me just show you an application and this application may be I will using a concept which we have to do, but it does not matter I still start that this would be good time to mention this application. So, here see this is we are considering the case on alpha is positive integer, when alpha is equal to n is a positive integer, now gamma distribution e raise as the distribution of the time one has to wait, until the total n events have occurred.
So, it is like you go to a railway booking counter, then you have people ahead of you in the queue and each person as I have told you that the we will treat service time as random variable. So, and remember that the I shown you that the service time being random variable can be an exponential random variable, so for each person the service time is random variable and then since there different people independent people. So, each one get serviced, so then the total time would be sum of that many independent random variables.
And exponential distributed random variables this is the idea, so now, the what I am trying to show you is that, the gamma variable is actually the time one has to wait till all people ahead you have been serviced and you have also been serviced. So, the way we will measure it is that when I am saying alpha is equal to n, so here I could be counting that you also have been serviced. So, then until a total of n events have occurred and of course, later on when we do the poison process and so on, then the whole thing will become much more clear.
But, you can just get a feeling for the application that I am trying to discuss here, so now, let T n be the time at which the n th event is occurred. So, when T n less than or equal to T this event could that mean, if and only if all the n events are occurred by time T, T n is the time at which n th event occurred. So, now, T n less than or equal to t will be that by time t all the n events have should have occurred, means in our particular case all n people have been serviced by the railway ticket booking counter.
Now, let capital N t be the number of events in 0 t, see in this particular case if the people ahead of you like say n minus 1 people ahead of you, you are the nth person. Then; that means, the time span you are taking is 0 to t, then that many people should have arrived in the time 0 to t, when they are n people in the system, then only they get serviced this is how. So, in this case there are n arrives in this time and so when we look at probability T n less than or equal to t, if you want to compute this probability.
Then this is same as probability n t greater than or equal to n because, at least n events in 0 t; that means, at least n arrives must be there can be more. But, when we are talking of n people to be serviced in this span of time, then at least at many people should have arrived that many events must be there in the system. So, this is what it is and this we will therefore, because this discrete thing people arriving are discrete events.
So, j this is to be j from n to infinity probability n t equal to j probability that there are j people in this system time 0 t. And then you summit of from j equal to n to infinity, now this is the part, see very often when you talk of events discrete events occurring in span of time, under certain conditions it can be shown that these will be poison arrivals. That means, the number of arrivals in a span of time would follow a poison distribution and therefore, probability n t this I will proof oftenly and we are talking about process is also one.
So, then in detail I will discuss how you arrive at this probability when you under certain assumptions you can show that the probability n arrivals in the time 0 t would be given by this. So, you summed up j to n, so it means for n t equal to j actually n t is the poison random variable and so the mean value becomes lambda t because, you are taking the span 0 t, so this will later on we explained. So, therefore, this is your poison probability is summit up from n to infinity.
Now, this is your cumulative distribution function for t n to find out the PDF, I will take the derivative, which is f t n of t and. So, we differentiate this expression with respect to t and you see first differentiate this and lambda comes out and j, so j lambda e raise to minus lambda t, lambda t rest to j minus 1 divided by j factorial minus derivative of this, which will be lambda minus lambda e raise to minus lambda t, lambda t rest to j divided by j factorial. And here j varies from n to infinity and so just rearrange the things little bit j when cancels out here. So, it will be j minus 1 factorial lambda t rests to j minus 1.
(Refer Slide Time: 40:17)
 
So, what you see is that here the terms are from starting from j minus 1 and here it is j, so you see things will cancel out in pairs. And except the first term here will be left out, which will be lambda e raise to minus lambda t lambda t rests to n minus 1 divided by n minus 1 factorial, that is only one because, when you put j equal to n plus 1 here that will be lambda t rest to n upon n factorial. And here also j equal to n it will be n factorial and lambda t rests to vise it j minus 1 here.
Because, when I am differentiating with respect to this one here then lambda t rays to j remains in that, so this is it. So, therefore, this term will cancel out with the second term here and then the third term here will cancel out to the second one here and so this will process will go on only the first will be left out here, which is lambda e raise to minus lambda t lambda t rest to n minus 1 upon 1 minus 1 factorial, so this is now gamma distribution with parameters and gamma lambda.
So, therefore, the amount of time a person has to wait till he serviced and if there are n minus 1 people ahead of you in the queue. And so that is random variable and just now shown that when the arrivals are poison, then this will be gamma distribution with parameters n comma lambda. So, in this case this is also referred to as n erlang distribution that is another name in literature you might some books may referred to this distribution as n erlang.
So, we have got some feeling about the gamma distribution and as we go on I will give you some more inside into the thing. Now, the other distribution continuous variable distribution, which is of important is the beta distribution, so a random variable x with PDF given by the equation f x x is 1 upon this is the beta function a comma b x rays to a minus 1 1 minus x rays to b minus 1 x between 0 and 1 and 0 otherwise.
(Refer Slide Time: 42:34)
 
The integral we denote by b a comma b, so this is 0 to 1 x rays to a minus 1 1 minus x rays to b minus 1 d x, where a and b both are positive. Now, again just as for the gamma distribution, we can show that for a greater than or equal to 1 and greater than or equal to 1 the integral will converge. And in fact, for integer values just like we did for computation for gamma distribution, it can be shown that this integral will be equal to gamma a gamma b by gamma a plus b.
So, therefore, I should again correct my statement here that is the beta PDF is this function divided by this. So, it becomes gamma a plus b divided by gamma a gamma b and therefore, the integral will ((Refer Time: 43:23)) to be one, so the beta PDF is actually this divided by this number and so we denote this integral by b a comma b which is. So, therefore, it has I will since defined for all a b positive, now for a greater than or equal to 1 and b greater than or equal to 1, you can show by integration by parts the integral will converge and will be equal to this.
Therefore, fractional values of a and b also it can be shown that this is defined the integral is defined and it is equal to gamma a gamma b upon gamma a plus b. Now, many useful applications of the beta distribution and one case that it models random phenomenon whose set of possible values is some finite intervals c comma d. So; that means, all possible values of this random phenomenon occur between within a certain interval c comma d.
And, but ((Refer Time: 44:24)) we have here defined the variable to be from 0 to 1, so then by scaling and shifting, we can transform this interval to 0 1. And of course, one obvious transformation is that y is equal to x minus c upon d minus c, so then all possible values of x which are within c d will now be, so the corresponding y variable will have all values between 0 and 1. So, and then we will see for applications of the beta distribution and will compute the other quantities related with the beta distribution.
Now, I am just trying to give you the pictures of graphs of this beta distribution for different. So, now, when a is equal to b this graph is symmetric, the graph of the beta function PDF is symmetric and for example, a equal to 3 it will be something like this and as a becomes bigger, the mass gets concentrated this the graph becomes narrow or and this is symmetric. So, if you draw for a equal to 10 probably it will be something like this peak the peak will be higher and so on.
Now, for a not equal to b the graph is asymmetric and skewed towards the left, so for example, a equal to half it is almost skewed towards the y axis and as a increases again the skewness shifts to the center. And this of course, the graphs are not drawn to scale, but they indicated a upon a plus b is equal to 1 by 20, so in this situation suppose a is 6 we can find out what the value of b is and so on. Now, there are situations see for example, if you have a big project, in which you have lot of jobs and so of course, a big project will be made up of number of jobs.
And this project may not have been handled completely before, so there is lot of uncertainty about the job completion times. And as a project manager he has to or he or she has to you know sometimes be have some estimate as to how long it will take for the whole project to be completed, which means that, must have a good idea as to how long it will take for each job to be completed, now in the absence of any previous experience because, jobs have not been performed.
For example, of course, this is no very old example that when they would trying to put a man on the moon, then it was completely new project all the job that made up the project new. So, people had no idea about the how long it will take for the jobs to be completed, but there are certain finites span and then of course, you do not expect just like as for the normal distribution for example, it is a symmetric distribution. But, then here there was no reason to believe that the completion time distributions will be symmetric.
So, therefore, beta distributions fitted the bill very well because, here were the distributions, which have they finite span and even though it is a continuous distribution and then it was not symmetric, so and so on. So, then huge projects were then the time estimations were made using beta distributions, so interesting applications, so where job completion times are not protectable, you have no idea. Then again by integration by parts, you can show that expected value of x is a upon a plus b and where else x will be a b upon a plus b into a plus b plus 1.
So, beta distributions again you want get’s time one can talk about I can give an idea, how the time estimates are done using a beta distributions. Now, as we go long we also keep coming back to distributions of large functions of a random variable and I will just do some sample functions here, and then try to give general result. So, let us say suppose x is uniform 0 1 and; that means, x is taking a non negative values, then if you define the function y equal to x e raise to n then; obviously, x e raise to n will also remain in the interval 0 to 1, that means the range for y is between 0 and 1.
And, so if I want to find the PDF of y, then probability y less than or equal to small y is the same event as probability x n less than or equal to y and this will be probability x less than or equal to y 1 by n. So, remember this is because the value here are non negative, so this is the same as this inequality the n the root and now if you do differentiate both sides, this will give the PDF of y and here when you differentiate this, this will give you PDF because, now effects right this side is f x y 1 by n. So, you are differentiating respect to y and so this effects y e raise to 1 by n into derivative of y 1 by n, which is 1 by n y e raise to 1 by n minus 1 and y between 0 and 1 so but for a uniform random variable this is equal to 1.
(Refer Slide Time: 50:11)
 
And therefore, the PDF of y reduces to 1 by n y e raise to 1 by n minus 1 when y is between 0 and 1 and 0 otherwise, take another functions. So, now, you take the function y equal to x square and this case you are not saying that x can only take no negative values, x can take negative values also. Then you see, when you write down this event probability y less than or equal to small y, which is probability x square less than or equal to y. Then this will be then equal to this event that capital X is between minus root y and plus root y.
Because, I did not if I you know sort of put the restriction that x has to be non negative, then; obviously, this it would have been just this part, this part would not have been there. But, since I am allowing x to take all positive negative values therefore, this will be equal to this event right and so by again our this thing writing the momentums of the accumulative density function, this will be affects root y minus effects of minus root y.
And then so we differentiate again respect to y and d d y f f y is the, so here this will be affects root y and then derivative of root y which usually 1 upon 2 under root y, this is x and plus affects minus root y. So, the minus minus will become plus because, there is minus coming from here, this is the minus here already, so plus affects of minus root y into 1 upon 2 root y.
(Refer Slide Time: 51:56)
 
So, this would be your PDF are y equal to x square, now the third kind of function that I am looking at here is y equal to mod x. So, x has a PDF affects, then here than in this case y will have nonnegative values, even though x is negative values, so we write down the event probability y less than or equal to small y, this is probability mod x less than or equal to y, which again can be written as x between minus y and y because, the absolute value has to be less than y y is a positive number.
So, therefore, in magnitude the value x even if it is negative, it has to be higher than minus y. Because, if you are saying that mod x should be less than or equal to 3, then you are x cannot be minus 4 because, absolute value of x would be 4, which is not less than 3. So, therefore, the values of x have to be between minus y and y and therefore, this is f y minus f of minus y and when you differentiate respect to y, you get PDF of capital y, which is affects y again minus sign gets converted to plus because, there is a minus coming from the derivative of minus y.
So, this y greater than y equal to 0, so one can go on, but then I will just summarize all these in this theorem. And so this is the x is the continuous random variable and affects it is PDF, suppose g x is a strictly monotone increasing or decreasing function, so this is now very clear and it is differentiable. So, strictly monotone means that it is either going like this the function like this or it is coming like this, so monotonically decreasing or monotonically increasing. Then the random variable y equal to g x has a PDF given by this and it will take a few minutes to this prove this result.
(Refer Slide Time: 54:05)
 
So, in this I just realized that in the statement of the theorem, this absolute value sign is missing, but that is important and I will show you why. So; that means, when y equal to when you are looking at the function g x of the random variable x and we are finding the PDF of y, then f y of small y is affects the PDF of x into at g inverse y. And absolute value of d d y of g inverse y, when y is equals to g x and 0 if y is not equal to g x and of course, here what we are saying that the Fourier's values are not being consider. Because, when you take the inverse function to be here see it is monotone function, so the relationship between. That means, this would be I do not have to worry about extra values here, so this will be fine, so now, let us look at the proof of the theorem.
(Refer Slide Time: 55:01)
 
So, we start with the event that y is less than or equal to small y, which is equal to this and this I can write x less than or equal to g inverse y now because, the function is monotonically increasing. So, this inequality from here, this inequality is the valid outcome because, it is increasing, so the inequality will not change a function g we have assumed is increasing function. And therefore, this is equal to f x of g inverse y is it, so differentiate both sides with respect to small y.
Then this f y y, which is d d y of this thing and in the step you get this is the PDF of capital Y, which is here when the differentiate capital F X you get small f x. So, that is g inverse of y into the derivative of this ((Refer Time: 55:55)) and now here because, the function g is monotone, this gain a result from calculus you can show that positive derivative. And f affects being the PDF of x this is non-negative, so the product is non-negative when therefore, this is non-negative, so this satisfies the condition.
And of course, you can verify that this is also valid PDF; that means, the integral would be 1 and so this is it. So, when you are taking the increasing function then because, the this part is nonnegative I do not have to put the bar sign here, but when g is decreasing, then you see, the probability the event g x less than or equal to y will the transform to x greater than or equal to g inverse y. And that is what I am showing you that if this is the function g x, then you are saying g x less than or equal to y.
So, g x less than or equal to y, so beyond g inverse y are the values of which your function is less than y, in the function is decreasing. And so the inequality here will reverse and that will be x greater than or equal to g inverse y and therefore, f y is 1 minus this you will write as 1 minus f x of g inverse y and then again differentiation of both sides will give you f by y, then minus f x g inverse y and derivative of this. Now, since g is a decreasing function, this derivative would be negative, so minus minus this will make it positive.
And that is why it is important that we write the absolute sign here because, your PDF cannot be negative that is a first condition. And which terms out to be because, when the function is decreasing his will be negative, so minus into this become non negative and so here again this would be positive. So, this is for the completion sake that I wrote down this theorem, but normally what we do is we ((Refer Time: 50:00)) you know do compute the PDF we write down the equivalent event, when you a function of a random variable. And then of course, differentiating both the sides you try to get the PDF for the function of a random variable, but at times it also helps to be able to use the theorem, so this thing.
(Refer Slide Time: 58:22)
 
Now, let me just show you as I was saying that one can either obtain results directly or using the theorem. So, if x is an exponentially distributed random variable with mean 1 by lambda, then you show that expectation of x e raise to k is k factorial upon lambda k, k varying from therefore, any finite value of k is what you had. Now, direct solution I am giving you, so solution 1 I should have said actually this is solution 1, which is a direct solution.
So, here because I know the PDF of x, so expectation x e raise to k will be 0 to infinity x e raise to k lambda e raise to minus lambda x t x. Remember we are told that the mean is 1 by lambda, so the parameter the distribution would be lambda e raise to minus lambda x t x and integration by parts treating this is the first function. So, the lambda lambda cancels minus e raise to minus why I am writing t here will be lambda x into x rise to k 0 to infinity plus minus and minus sign makes it plus 0 to infinity e raises to minus lambda x and then x rise to k minus 1 d x into k.
So, you see this integral will come out to be this and then I again multiply and divide by lambda. So, then this become my regular gamma functions, so one upon lambda, so this is we I k minus 1 into k by lambda, this integral because, when I differentiate this, this k will come out all the k should have been there, you have differentiated x k, so k is already there k is here. So, that k I am writing k by lambda and then this integral is your I k minus 1, our I k was lambda e raise to minus lambda x x rises to k and d x integral from 0 to infinity.
So, now, this integral light denote by I k minus 1 and therefore, you expected value of x k as you go on doing it by iteratively here of course, k is a positive integer. So, this is k factorial upon lambda k into I 0 finally, right if I go doing it repeatedly, so this becomes then for if I write down for I 0, this will be k factorial upon lambda k integral 0 to infinite lambda e raise to minus lambda x d x, which turns out with this, this integral is one because, anyway you know that this PDF of an exponential distribution with the parameter lambda.
So, therefore, this integral is 1 are you can directly show that this is 1 and therefore, this is the answer, now we want to use the theorem. So, using the theorem that is you compute the PDF of the random variable x is to k; that means, I compute the PDF of the function of the random variable and then through that root I try to compute the expected value. So, if I define my y’s x rise to k that I am trying to compute y less than or equal to small y, which is probability x rise to k less than or equal to y, which is then x because, everything is non-negative.
So, therefore, the inequality will be converted to this that is x less than or equal to y rise to 1 by k and then f y y that is the PDF of y now will be f x of y rise to 1 by k into 1 by k y rise to 1 by k minus 1. Because, this I will be writing this is as f x of y 1 by k right and so e y will therefore, be 0 to infinity y into f f y y d y which substitute for f y y in terms of f x. So, this will be 0 to infinity y lambda e raise to minus lambda y e raise 1 by k 1 by k y rise to 1 by k minus 1 d y.
And, so e y is now here I can put y rise to 1 by k is s, so then 1 by k y rise to 1 by k minus 1 d y is d s. So, this whole thing goes to d s and so I have now here s rise to k. Because, y will be s rise to k and lambda e raise minus lambda s t s and this is now we recognize that if I take divided by lambda rise to k and combine lambda here. So, lambda s rise to k and so this your gamma PDF and therefore, did not PDF in sense that I must have here gamma k plus 1.
So, therefore, this integral will therefore, be equal to this integral v equal to gamma of k plus 1 and then divided by lambda k. So, that is another way of and since this is an integer k is an integer positive integer, so this will be k factorial upon lambda k, which we got here also, so you know whichever is convenient one can try to get the result either way.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 11
Function of Random Variables Moment Generating Function

I will begin this lecture by discussing exercise is 4 with you, this is on random variables their pdf, cdf, and expectation, etcetera.
(Refer Slide Time: 00:19)
 
So, let us look at question 1, consider the function f x given by C times 3 x minus x square, for x lying between 0 and 4 and 0, otherwise. So, the question asked is could effects be a probability density function for any value of C, now without proceeding further we can just see that, since the function can be written as x times 3 minus x, so it will be negative for x greater than 3 and your interval is 0 to 4. So, density function and if the sign of C you might say that we can makes C negative, but then when x is equal to 2 say for example, then 3 x minus x square is positive.
So, in that case again C times 3 x minus x square will become negative, so in fact for no value of C is the current function PDF, because it is not non-negative for all values of x in the interval 0, 4. Now, we say that suppose we require the function to be a probability density function, when x is between 0 and 3, so that make sense, because then in the interval 0 to 3, 3 x minus x square is non negative, so then C will be chosen as some number which is also non-negative, in fact positive.
And the condition they way you will obtain C would be you integrate the given function from 0 to 3 and then the integral must p is equal to 1, so therefore you can answer this question in this way. The question 2 the probability density function of x, the life time of a certain type of electronic device measured in hours is given by, so f x is equal to 15 by x square x greater than or equal to 15 and 0, when x is less than or equal to 15.
So that means the device is guarantee to run for more than 15 hours, now find probability x greater than 30, so again you can do it by finding out the c d f or integrating this function from 30 to infinity. Because, this is say 15 by x square is x greater than or equal to 15, what is the cumulative distribution function of x and what is the probability that 6 of such types of devices, at least that out of... what is the probability that of 6 such types of devices at least 3 will function for at least 15 hours, what assumption are you making.
So, here of course, you see you will assume that the devices are independent of each other and then you will do the raise by finding out. So, probability of 1 device functioning for more than 15 hours and then you have to say 3 out of 6, so you can understand what all you have to do, this will become a binomial probability, where the p will be the this integral for at least 15 hours. So, will function for at least that 6 of such types of devices at least 3 will function for at least 15 hours, so it will be 15 and more.
So, I will leave it to you to do the rest, question 3 for a random variable y show that E y, the excepted value of y is 0 to infinity probability y greater than or equal to y d y minus 0 to infinity probability y less than minus y d y. Actually question 5 should precede question 3, in question 5 I am asking you to do the same thing for a non-negative random variable y, in that case the second part of the integral will not be there, because y less than minus y.
So, here in question 3, I am asking you to show that for a non-negative random variable y, E y is equal to 0 to infinity probability y greater than t d t. So, once you show this then you can go to question 3 and do the rest, when y you can take positive negative values both.
(Refer Slide Time: 04:46)
 
Question 4, x is a random variable that takes on values between 0 and C that is probability x lying between 0 and C is 1, so show that variance x is less than or equal to C square by 4. So, I am just asking you to get an upper bound for the variance and you see the only information you have given is that, x lies between 0 in C, so all mass of this random variable is between 0 and C. 
(Refer Slide Time: 05:15)
 
Now, there is a hint, one approach is to first argue that exception x square is less than or equal to C E x, you see this a non negative random variable, yes it should be said that. Because, 0 less than equal to x less than C, so it imply that C is non-negative, therefore this in equality exception of x square is less than or in to C times E x, you see actually x square is less than or equal to C x, yes for all variance of x between 0 and C, because x is non negative and C is a non-negative number. So, from their you get this inequality when you take the exception on either side of this inequality and then you show the rest, so I will not discuss second hint, there you should think and then get the answer.
Question 5, we have already, now question 5 the second part is that you have to obtain exception x raise to n and show that it is equal to this 0 to infinity and x raise to n minus 1 probability x greater than x d x. So, here again the hint is that you start with E raise to x n as 0 to because so therefore you write y equal to x n and then you will do this and then because of the substitution y is equal to x n, so d y will be n x n minus 1 d x and that is how you are getting this part, so this you should be able to do.
The question 6, the number of minutes of playing time of a certain high school basketball player in a randomly chosen games, so this should be player, so I have just cut the... So, that means number minutes of playing times of a certain high school basketball player in a randomly chosen game, is a random variable whose probability density function is given in the following figure. So, this is the graph of the p d f for the number minutes that a player in a basketball team gets actually to handle the ball in a sense, find the probability that the player plays over 15 minutes.
So, therefore, here as remember I have told you that this probability if you are saying that the player plays over 15 minutes, then you are asking for the probability x greater than or equal to 15. And so here you will integrate or you find out the see the 15 will be some way between 10 and 20, the height of the graph a different places. So, the area to the right of 15 on the x axis, on the minute axis that area would be the probability that the player gets to spend more than 15 minutes on the field while playing the game.
Then since similarly, between 20 and 35, so between 20 and 35 you the area, so this will be the area you can immediately find out just by looking at the graph, you do not have to do any integration or anything. So then because any way you are this thing does not given to you the functional form of the p d f is not given. So, just by looking at the graph you find out the area between 20 and 35 and that will be the probability, that the player gets that many minutes play between 20 and 35, less than 30 minutes same thing, so this will be this.
So, the area to the left of 30 will be the answer and more than 36 minutes it will be somewhere here, so to the right. So, this we just illustrate that how when it is convenient, you can just look at the graph of the p d f and find out the required probabilities. Question 7, suppose that the travel time from your home to your office is normally distributed with mean 40 minutes and standard deviations seven minutes, so the time that you would spend in going from home to office is a normal distribution with 40 minutes as it is mean and standard deviation 7.
If you want to be 95 percent certain that you will not be late for in office appointment at 1 PM, what is the latest time that you should leave home, so you have to read this problem at least 2 to 3 times. And see the what we are asking is that you want to know the travel time, which you can be sure of the time 95 percent time that which you have to find the probability of reaching from home to the office, the time which will be possible for 95 percent of the time.
So, here that means, if x is the random variable denoting the time that you take from home to office, then x minus 40 and x you will say in minutes, so x minus 40 upon 7 will be the standard normal variant. So now, you want to find out the probability that when this z is less than or equal to some number t is equal to 0.95, so from the tables you get the value of t. So, corresponding value of x is 40 plus 7 into t minutes, thus starting time would be 40 plus 7 t minutes before 1 PM, then you are likely to be in the office 95 percent of the time in time.
That means, you will be in the office by 1 PM 95 percent of the time, so just read this problem carefully and then... Now, question 8, the median of a continues random variable this I have explain to you, that the median means that half of the area lives on one side, and the other half lives on the other side. And now I want you to find out I think I have already done it for the normal distribution, I showed you that for a normal distribution x equal to mu is the median.
So, now, for uniformly distributed over a b and exponential with mean lambda, find out the median, so this I have discussed in the class. If x has hazard rate function lambda x t, compute the hazard rate function of x of a x, a is the constant, where a is a positive constant. So, you can apply the formula definition of the hazard rate function and get the answer, the lung cancer hazard rate of a t year old male smoker A t is such that this. Now, here I have discussed in the lecture, that if you are given the hazard rate function, then you can compute the c d f of the random variable.
And so assuming that a 40 year old male smokers survives all other hazards, so we are just considering the death, because of smoking what is a probability that he survives to age 50 to age 60 without contacting lung cancer. So, I have discussed part of this problem with you in the lectures, he should be would do it. Now, finally, x is uniformly, no this is 11th problem, x is uniformly distributed over minus 1 and 1, so while discussing functions of random variables in the last lecture, I discusses this how you will handle probability mode x greater than half.
X is less than minus half and greater than half, then the density function of the random variable mode x, so this should be able to do it. Question 12, the number of years a radio functions is exponentially distributed with parameter lambda equal to 1 by 8, so that means the mean is 8, if Jones buys a used radio, what is the probability that it will be working after an additional 8 years. So, now remember this is an exponential distribution, it has the memory less property, so therefore you can answer question 12 also. So, now I hope with all this hints you should be able to enjoy doing this exercise.
(Refer Slide Time: 13:18)
 
So, let me now continue with in the last lecture I discussed functions of random variable, how you find out their c d f and p d f and p m f, now let us talk about expectation of function of random variable. So, if x is discrete random variable with p x as it is p m f, then we define and g is some function real valued function I should have said that, g is a real valued function of x. So, here g x is a real valued function of small x only, then expectation g x would be, because g x it is self will be a random variable, since x is a random variable, g x will be a random variable.
And so this is summation i, p x i, g x i, so let us see how we arrive at this form, see the thing is that you start with this summation. Then what I do is I group together all the x i’s for which the value of g x i is y j, because g may not be a single valued function, so here for all possible values of x i’s which give me the same value of g x i. So, then I group this summation here, so I say j here and then I am summing over i where g x i is y j, so although g x i is get summed up here and then for all those g x i is y j, so then I will write y j here, that this summation goes over all i said the g x i is y j.
So, I am summing up all the probabilities p x i all x i for which d x i is y j and so this becomes summation y j and this probability is the add up, because the x i’s are discreet and distinct values. So, therefore, you add up the probability, then that will give us over all i’s at the g x i is y j, so this becomes probability of g x is equal to y j of the even, this is a discreet case. So, for all possible values of x i for which g x i is y j, so therefore this, this whole thing here is equivalent to this.
And so now, this becomes sigma j y j, so this is g x i equal to y j and then probability of g x equal to y j, so therefore by definition this is exception g x, so this is you are the way we definite for a discreet random variable. So, the simple formula is this and I would try to validate it for you by manipulating the summation terms. Then in question 5, exercise 4 you have been ask to show I just discussed it with you, so we have been asked to show that acceptation x will be 0 to infinity, probability x greater than y, when x is a non-negative continues random variable.
So, here we are I am just writing out this expression for the case when x is a non-negative random variable, so now when I want to talk about expectation g x, I will do it for I will obtain this formula when g x is non-negative. And then you should be able to take care of because remember question 3 is your general version, where x can be negative or positive both, so in that case g x can be also general function taking negative, positive values both, but once you understand this you will able to do that also for the general case.
So, I am doing it for g x non-negative, so expectation g x will be using this formula because g x is non-negative, so 0 infinity probability g x greater than y d y, this is I am using that question 5 of exercise 4. Then here this, what I am doing is see therefore, see I have tried to show you the g x is this function, so now here I am separating out the integral what I am doing is for g x greater than y, I am integrating this f x d x.
So, suppose this your value y, then you are integrating this area, but then y varies from 0 to infinity, so that means from ((Refer Time: 1753)) here, here, here, so the whole area this whole area and g x from 0 to infinity is being integrated here. Then I can always change the order of integration, I can no add the integrate in this way, so that means here it will be 0 to g x. So, first of all from here I can come here 0 to infinity, then I from here I come x g x greater than 0, so here g x greater than 0, then I am integrating this way here in this way and then this is 0 to g x.
So, you are y, the integration respect to y is from 0 to g x and then g x is going from 0 to infinity when g x is greater than 0, I have drawn it this way it could be whatever it is g x, so you may start from here are your function may be like this it does not matter. So, when you here the order of integration, first I was integrating respect to d x and now I have change the order of integration. So, when I change the order of integration my y first varies from 0 to g x, so from 0 to g x d y and then my x varies from corresponding to g x positive, so this way.
So, therefore, I am taking this these lines and the lines corresponding to a fixed x will be from 0 to g x and then as x varies I am integrating along this lines, so this is how I am covering this area. So, this is it now 0 to g x d y simply becomes g x and then this is integral x, so the g x is positive of a g x f x d x, last integral the competition has to be for all x such that g x is greater than 0, this is equal to this. So, now it will be good if you can sit down and do it for a ((Refer Time: 19:54)), that means you do it now for the negative part and then you can just add it up expectation for... So, in other words, I am also telling you how to do you your problem 3, first do 5, then do 3 and then you can applied to get this results for the general function x g x.
(Refer Slide Time: 20:22)
 
And so now, immediately you can write down that if you take a x plus b as a function of the random variable x and the expectation will be a is E raise to x plus b. Now, you can verify the writing the actual expression that means, you can write out this expression and then show that what you get will be a into expectation x plus b. Similarly, for the variance, see the expression is a x plus b minus a E x minus b whole square and b b cancels out, so you left with a square x minus E x whole square expectation of this.
Then since a square being a constant comes out, this is a square expectation of x minus E x whole square and which is a square times variance x. So, I just handled it for this, because this is very, we already use this formula in fact, so I thought let us formula is once we talk about expectations of random variables, then I talk about their expectations and so on, in the applications. Another interesting expectation of a function of a random variable is the moment generating function and this is a very very important.
Because, in the since that sometimes it gives you extra information about all the information that you can sometimes get more easily here, if the moment generating function. So, let us say the definition is that m x t is the expectation of e raise to t x and m x t I will write here is the moment generating function of x for all values of t, for which this exists. And so some time ago I had shown you that, these need not all the time exist and so whenever for all values of t for which this exists we will say that this is the moment generating function of x.
So, t is a real number, so as t varies and sometimes for all values of t this may exist, but sometimes it may not exist for all values of t. So, for the discreet case when x is a discreet random variable and p is it is p m f, then m x t will be expectation e raise to t x p x, because just now we note down the formula that for any function of random variable expectation g x is summation i p x i g x i, so I am applying this formula.
And therefore m x t for a discreet random variable would be summation e raise to t x into p x for all x, the summation is over all those x for which p x is positive, because otherwise their corresponding contribution here will be 0. Then x a continues random variable with f x as it is p d f, then m x t will be minus infinity to infinity e raise to t x f x d x for all values of t for which t integral exist, this is the same thing. It is only define, the moment generating function is define for those values of x for which the corresponding expectation exists.
(Refer Slide Time: 23:41)
 
So, if I differentiate the expression for m x t, the moment generating function for x this is d v t of E e raise to t x and then I am taking the differentiation sign in side. And this is easy explain, because in the discreet case since this expression for the moment generating function the summation is a convergent series, so therefore differentiation can be passed through the summation sign. Because, this is a convergent sum, so therefore of course, we are taking it for all values of t for which this is convergent.
So, in that case I can pass through the summation sign the differentiation sign, now if x is a continues random variable, then it is required this can be shown again, because it involves higher level mathematics, so I am not doing it here. This is that if the moment generating function for x exists, for all values of t in the interval minus a comma a that means, this is some interval around value t is equal to 0. For sum a a real number if this exists then it can shown, that you can exchange the differentiation and integration sign.
So, in case your random variable x at is 5 these property that the moment generating function will exists for all values of t, in an interval around the origin, around the 0. Then you can interchange the two signs and then therefore, when you differentiate you take the differentiation sign in sign, it will become expected value of x e raise to a t x, because you differentiating respect to t. So, will write x here and the at t is equal to 0 you can see that M prime x 0 will be E x, which is the first moment and so on.
So, the first derivative of the moment generating function evaluated at the 0.0 is the first moment of x, the mean or the expected value of x and similarly, if you differentiate again then you will get x square here, expectation x square e raise to t x, so M double prime 0. That means, the second derivative evaluated at t is equal to 0 will be give you expectation x square which is the second moment. So, in general the n th moment or the n th derivative of the moment generating function evaluated at t equal to 0 will give you the expectation of x raise to n. And so once you have these moments therefore, you can make these thing that means, if you just compute the moment generating function, you can get the information about all the moments through this formula.
(Refer Slide Time: 26:29)
 
So, let me now start applying the definition of the moment generating, function to special random variable that we have a gone through so far. Binomial random variable the expectation value of e raise to t x would be sigma R varying from 0 to n e raise to t R, because x takes the value R, so e raise to t R n c R p raise to R 1 minus p raise to n minus R this is the expression. I will combine e raise to t R with p raise to R, so this becomes n c R p e raise to t whole thing raise to R in to 1 minus p raise to n minus R.
And this you can see is again binomial expansion of the expression p e raise to t plus 1 minus p raise to n and this exists for all values of t, because the expansion valid no matter what the value of t is, so this is... And now you see what we are trying to say is that if you get an expression like 0.3 e raise to t plus 0.7 raise to n, if you given this as m g f and you can immediately say by looking at the form of the moment generating function, this is the moment generating function of binomial random variable with p as 0.3 and this is your n.
So, the two parameters you can immediately find out by looking at the moment generating function. And if you differentiate this expression once, then see from here it will be n derivative of this p e raise to t, you should have said here e raise to t n p e raise to t, then E raise to t p plus 1 minus p raise to n minus 1. And so at t equal to 0 this number reduces to n p, which is the expectation of x, similarly if you differentiate this expression twice, this e raise to t is missing some were.
So, then it should have been sum of two, so will have to rewrite the expression here, so it will be see for example what I am doing is, so e raise to t is here, so I am differentiating this again, so this whole will be n minus 1 and p here, then e raise to t. So, e raise to 2 t, because there is an e raise to t plus you will have to take the derivative of this, which will be n p e raise to t e raise t p plus 1 minus p and this whole thing raise to n minus 1, and in case when you compute this at the value t, then this becomes 1.
So, you left to the n p and minus 1 p this also is equal to e raise to t is 1, so this is 1, 1 raise to n minus 2 is 1, then here also the contribution would be n p, so is it so n p e raise to t. So, the second moment I am getting as and then from here n into n minus 1 n square, so ((Refer Time: 29:54)) this is not correct, so therefore this will be plus, so that means here when you put t is equal to 0 you are getting n into n minus 1 p square, this is ok and from here you will get another n p.
Because, this is 1, this is 1 and the whole thing is 1, so this is plus n p, now it make sense, because you have a n p, so n square p square minus n square p square goes away, then minus n p square plus n p. So, minus I should write out the, so minus n p square plus n p, which is n p into 1 minus p, so n p q this is the formula for the variance, so please be carefully when you are differentiating this expressions.
Similarly, we can apply now, we can obtain the moment generating function for a Poisson random variable and this will be expectation e raise to t n lambda raise to n into e raise to minus lambda upon n factorial and varying from 0 to infinity, here again I will couple e raise to t n with lambda. So, this would be come lambda e raise to t n into e raise to minus lambda n factorial, so now this is what the value of the random variable that you taking, so at x is equal to n; and this will be if you take e raise to minus lambda outside, this is the expansion of...
So, lambda e raise to t raise to n upon n factorial is the expansion of e raise to lambda e raise to t, so that expression where look a little complex, but handling them is not much of a problem. So, here the whole thing adds up to, so therefore in this case also the series is convergent for all values of t and so that is I am saying define for all values of t and this can be rewritten has e raise to lambda e raise to t minus 1.
So, if you differentiate, so here again say for example, if I get term, if I say that in m g f is say 3 e raise to t minus 1, then immediately by looking at this function, I will say that the corresponding random variable is a Poisson random variable with mean 3. And m g f of a random variable x will characterize the probability distribution function of x, so even you differentiate this again, so let me go through the calculations, because they might be some error again.
So, first derivative of m with respect to t, here would be the derivative of this would be lambda e raise to t, so lambda e raise to t, when into e lambda e raise to t minus 1 and evaluated at t is equal to 0 that gives you lambda, which is expectation of x. Second order derivative, so their two terms now involving t, the first one the derivative is lambda e raise to t into e raise to lambda e raise to t minus 1 plus, the derivative of this would be lambda e raise to t lambda e raise to t and the same term here.
Again evaluated at t is equal to 0, you get lambda from here and you get lambda square from here to this lambda plus lambda square. So, variance is lambda plus lambda square minus lambda square, expectation of expectation x whole square, so therefore this is again lambda, so verification alternate ways of computing the same quantities. Exponential random variable with lambda as it is parameter, then this would be 0 to infinity lambda e raise to t x into e raise to minus lambda x t x and here, again I couple the terms the powers of e.
(Refer Slide Time: 33:59)
 
So, I get so the moment generating function would be 0 to infinity lambda e raise to minus lambda minus t x t x, which I can rewrite as lambda upon lambda minus t integral 0 to infinity lambda minus t e raise to minus lambda minus t x t x. And you can see that this integral is defined for all values of t less than lambda, because this exponent must be see this quantity must be negative, this quantity must be positive, so that minus of this is negative and then at infinity this will go to 0.
And therefore, the integral is define only for lambda, for t less than lambda, for t greater than or equal to lambda the integral does not exists. So, this is important to note and therefore, that is what I was saying, that the moment generative function need not exists for all values of t, we have to specify the values of t for which the integral exists.
(Refer Slide Time: 35:01)
  
Now, make the substitution to integrate this, you make the substitution y is equal to lambda minus t x, this gives you d y is lambda minus t d x and therefore, this integral transforms to lambda upon lambda minus t. See here this lambda I wrote as lambda upon lambda minus t into lambda minus t, so to get it in the proper form. So, then lambda minus t d x transforms to d y, this is d y and e raise to this thing is e minus y simple integral this this.
So, therefore, minus e raise to minus y 0 to infinity is lambda upon lambda minus t, m g f exists for t less than lambda and not t less than or equal to lambda, you can say that the corresponding random variable exponential with parameter lambda. And if you do the simple verification here, derivative would be lambda upon lambda minus t whole square, they will be a minus sign with this, but then since this in the denominator another minus sign, and they both multiplied to be positive.
Therefore, M prime x 0 is lambda upon lambda square which is equal to 1 upon lambda, now similarly you can compute the second order moment and then... So, that is why you know that the name is very is just a moment generating function, this function generates the different moments for the probability density function. Normal distribution again it may look very compresum, but actually it is simple manipulation of the terms and you get the answer.
So, for a normal distribution the moment generating function would be, so 1 upon root 2 pi sigma minus infinity to infinity e raise to minus x minus mu whole square upon 2 sigma square plus t x, computing expectation of e raise to t x. So, here I combine this in this square terms, so this becomes 2 sigma square x t, 2 sigma square x t, so I collect the x terms, so the x terms are twice mu plus sigma square t plus sigma square.
Now, I want to make a perfect square and the origin is obvious, so that the part of the integrant will add up to or integrate to 1, so you see to this I must have x minus mu minus sigma square t whole square. So, therefore, I have added mu plus sigma square t whole square to make this perfect square, so therefore I must subtract, so minus mu plus sigma square t whole square and the mu square from here is determinant.
So, therefore, this is what you have, so this square plus mu square minus this, now if you simply this the mu square cancels out, your left with minus 2 mu sigma square t plus sigma 4 t f’s square. So, this term I have written out here is this separated at out and this is the constant, because there is no function of x here, this is d x in fact, d x goes here. And you see that this integral in that case, now this is p d f of a normal random variable where the mean is mu plus sigma square t not mu, but does not matter the other things remains the same.
So, this is the p d f of a normal mu plus sigma square t and sigma square the variance does not change this is under root of sigma square and this is 2 sigma square, so only the mean have shifted from mu to mu plus sigma square t. And therefore this integrates to 1, the p d f of a standard normal variant this integrates to 1 and here, you left with just this part 2 sigma square t mu plus sigma square t square divided by 2 sigma square, so this is it. So, when you cancel out the sigma square part you left here with mu t plus t square sigma square by 2, so a simple form here again.
And you can now differentiate this and that means, let just take the first derivative, what would be the first derivative this is t, so this is e mu t plus sigma square t square by 2 in to the derivative of this, which is mu plus twice, so sigma square t, so the t is equal to 0 this is 1 and this is mu. So, the first derivative of the first mean, the first moment which is the mean I similarly differentiate at again and then find out the second order moment and the variance.
So, I think these illustrates quite well the concept of moment generating function and how you make use of it and of course, that it definitely characterizes the p d f’s, because by looking at the form of the m g f you can say what the distribution would be, and what would be the corresponding parameters. Then they still more interesting applications of the m g f, this is when I talk of jointly distributed random variables and then you can use of the concept of independents and so on. So, the all these things get connected and I will try to show you the further properties of the m g f.
(Refer Slide Time: 40:50)
 
So, let me now look at the moment generating function for the gamma random variable, so the expectation e raise to t x would be 0 infinity lambda e raise to minus lambda x lambda x raise to alpha minus 1 upon gamma alpha into e raise to t x d x. So, again combine this thing and here you see t less than are equal to lambda, then only because this is the not define unless I mean the whole integral will become improper, if t is greater than lambda. So, therefore, this integral will exists as along as t is less than or equal to lambda, so now you have the this expression.
So, again the trick is that I tried to manipulate the integral add, subtract, divide or multiply, so that I get in to a familiar form plus a constant into a constant, so here you see the parameter shifts of lambda to lambda minus t, so that is what I will do. And that is not difficult, because this lambda I can write as lambda upon lambda minus t into lambda minus t. So, this becomes my parameter here, this is e raise to minus lambda minus t x, now this lambda same thing I will do, I will replaced by lambda minus t and then divide lambda minus e raise to alpha minus 1.
Because, this is alpha minus 1 and the lambda raise to alpha minus 1 comes out, so you say this part is now independent of, this is independent of x, the remaining portion all these is now the integral of the p d f of a gamma distribution with the parameter lambda minus t and alpha. So, instead of parameter being lambda it is now lambda minus t for any fix value of t and so the parameter will change as you, but given a value of t, then this will be integral of the p d f of a gamma distribution with parameter lambda minus t and alpha. So, therefore, this whole integral this thing is equal to 1 and I am left with the term lambda upon lambda minus t raise to alpha and so this is your m g f.
(Refer Slide Time: 43:15)
 
Now, if you recall for an exponential distribution, the m g f is lambda upon lambda minus t, if lambda is the parameter, so what is turning out to be the exponential is gamma 1 comma lambda, that means the I been saying it out the other way. So, alpha is the first, so that means here I want to say this is gamma alpha and lambda minus t, the alpha comes out to be the first parameter, this is the second. So, then your exponential is 1, if you looking at gamma alpha lambda, then for alpha equal to 1 this becomes exponential lambda.
And here you see the, so therefore now through when I talked about jointly distributed random variables, sum of independent identically distributed random variables and so on, so there will be lot of inter connections at I would like to show. So, essentially what we will be deriving here is that, first of all the result that if you have some of two independent random variable, then the m g f of the sum is the product of the corresponding m g f.
So, here you see applying that iteratively, it turns out that gamma alpha lambda is actually the sum of independent exponential distributed lambda variable, exponential distribution random variables each with parameter lambda, that means identically... So, in case alpha is an integer, then gamma alpha lambda is some of alpha independent exponential random variables with parameter lambda, so this is what the result will be.
And therefore, that is what I am saying that you will be able to show these kind of things through the help of m g f, because here this is lambda upon lambda minus t raise to alpha, and this is alpha of the mu add and their independent. Then the m g f of the some of these alpha independent exponential random variables will be gamma distribution, because the m g f of this some would be the m g f here, which is alpha times this. So, you multiply the corresponding m g f, when the variables are independent and then if you talking of the m g f of the sum.
So, we will develop this theory as soon as a talk of jointly distributed random variables, now just 2 questions before I finish this topic. And this is x is a continues random variable with p d f x, show that expectation of absolute x minus a is minimized when a is equal to the medium. So, we have defined the median for you and here, see what we are saying is this will actually come out to be a function of a write this expectation and therefore, you want to minimize that means, differentiae respect to a, the expression that you obtain for this expectation of absolute x minus a.
And then find out the critical value or the value at which this becomes minimum, so you will after show that it is the point at which the area under the curve is half. Now, I will just give you a hint, so expectation absolute x minus a would be absolute x minus a f x d x, which you can like either x is less than a or x is greater than a, for x less than a we will integrate from minus infinity to a.
So, then this will be a minus x f x d x, because the integrant has to be positive non-negatives, so this would be a minus x for x less than a and then a to infinity x minus a f x d x. So, the idea that you differentiate with respect to a, now all of you have already done this much calculus you can integrate, so this will be when you have in differentiation and the integral sign, essentially you to apply that. Your limit is function of the I mean you are treating a as a variable now, because this whole thing is a function of a, so you can do this.
Now, similarly just take an example, so let x be and mu sigma square, so x is normally distributed with parameters mu and sigma square and has m g f m t define psi t is log of m t, then show that psi double second order derivative of psi at 0 is variance x. And so interesting function that you can define through your M t, we will also be talking of the characteristic function. So, now, for example, M x t for a normal is this, so if you take log of this, which way we are calling as psi t, then this will be equal to mu t plus sigma square t square by 2.
And so if you take psi prime t, this is mu plus sigma square t and then psi double prime t will be simply sigma square which is and therefore, this is also psi, because that is a constant. So, the second order derivative of psi is a constant, so if psi square is 0 is also sigma square, so this is the answer. And so one can go on I am doing lot of interesting thing with this, and I will be developing some more results here in the next lecture.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 12
Jointly Distributed Random Variables Independent R.V. and Their Sums

 (Refer Slide Time: 00:15)
 
Now, we going to talk about Jointly Distributed Random Variables. See they may be events, which need to be describe by more than one random variable, so they may be the you know random phenomena concerned with the event or more than one dimension. And therefore we need to be able to of course, then we from two dimensions we go to multi dimensions also, but right now to keep it simple, we will first talk about two dimensional random variables and then may be a extend the notion two, more than two.
So, if x and y are two random variables, we define their joint cumulative distribution function as follows, so probability F of x less than or equal to a comma y less than or equal to b is actually the probability that x is less than or equal to a and y less than or equal to b, a and b two real numbers between minus infinity and infinity. So, essentially in this diagram, if this is b, then you are asking for y less than or equal to b and then x less than or, so it will be this whole region, if you can see this line and this line, so whole of r 2 extending from here to this end that will be a, so we are talking of the probability over this region. Then the moment did you find the joint CDF, a Cumulative Distribution Function, then you can talk of the marginal CDF of a, so example for example, marginal CDF of x can be obtained from F (a, b) as follows, sorry this should be (a, b).
The probability part comes here x less than or equal to a, y less than or equal to b, so therefore, from F (a, b) we can obtain the marginal CDF of x as follows, so this is the F x (a), which is probability x less than or equal to a. So, this will be actually therefore, that means, this means that y is allowed to take any possible value, so therefore y probability x less than or equal to a and y less than infinity. So, now let me just define it in a proper way in the sense that, this is also the same as b going to infinity.
So, limit that means, if I take the event x less than or equal to a, y less than or equal to b and then I take the limit, so you see what will happen as b goes to infinity, so x less than or equal to a, y less than or equal to b, you are talking of this, then when say b 1. When you talk of this y less than or equal to b 2, where b 2 is greater than b 1, then this is a bigger event. this event is contained. So, therefore, now you have a sequence of these events which are increasing, so increasing sequence of events b is goes to infinity.
And if you remember my definition of probability as a continuous function, continuous set function, so then in that case I told you that we can in that case extended, when you have a increasing sequence of sets, then when you are computing the probability you want to take the limit, then the probability of the limit is the limit of the probability. So, therefore, I can take limit outside and this will be limit is b goes to infinity of the this event x less than or equal to a, y less than or equal to b.
So, we take the probability here and therefore, this will be limit and this is now your F (a, b) by definition, so this limit b going to infinity of F (a, b) and this will be then F (a, infinity), so F a and F (a, infinity) are the same. Similarly, if you want to compute the marginal of y, then will take the limit F (a, b) a go to infinity which will be F (infinity, b). So, exactly in the same way will argue out that the b remains the same and then a keeps increasing, so again you have increasing sequence of sets and so when you take the probability I can exchange the limit and the probability and get the answer.
So, now similarly you all to compute and then of course, you see the properties where we have defined for a cumulative distribution function must have for a single variable. So, the same will apply and you can apply them to F x and F y, so through those you can get the property for the joint. Because of property that F x and F y possess combine them, when you can, then put together the properties that you are joint cumulative distribution function must have.
Now, suppose you want to compute the probability of x greater than a and y greater b, so this we can write as 1 minus probability of the compliment of this event, which is x greater than a, y greater than b a compliment and then, since x and y are independent, in the sense that I can write this as. Now, this can be written as x less than or equal a union, y less than or equal to b, if you recall your De Morgan's law as so on. So, then this will be 1 minus probability x less than or equal to a minus probability y less than or to b and then, you add probability x less than or equal to a, y less than or equal to p.
And this diagrammatically also you can immediately see that, this how from here we have to get here, because you are computing the probability x less than or equal to a and y less than or equal to b. So, this will be you see x less than or equal to a would give you ((Refer Time: 06:23)) this region, and y less than or equal to b will give you this region. So, you see the region extending from here x less than a, y less than b is this region which you are have subtract it twice, because once when you do it for x less than a, probability x less than or equal to a.
So, it is this and then this region is coming into it, then when you subtract probability y less than or equal to b then again this whole region is coming and therefore, you add this again, so in words of your I should have written this that means, your. So, therefore, I simply write this probability in terms of 1 minus F (x a) minus F (y b), so this will be equal to 1 minus F (x a) minus F (y b) plus F (a b). So, therefore, to make the equation correct I add this once and then, because I need to subtract only c I need this region, so the valid region that I require is this.
And therefore, from 1 I subtract this whole and so this got subtracted twice, therefore I add it once to make it proper, so this will be your... That means, now one can compute whatever probabilities you want related to these two random variables, it can be done once we have made this definition.
(Refer Slide Time: 07:56)
 
Now, in general if x is lying in the interval a 1, a 2 and y in the interval b 1, b 2, then this can be written as F (a 2, b 2) plus F (a 1, b 1) minus F (a 1, b 2) minus F (a 2, b 1), so here again we will just simply diagrammatically look at the equality that we have here. So, x is varying between a 1 and a 2 and y is varying between b 1 and b 2, then F a 2, b 2 is this whole area, in fact if it is only non negative variable then it is this region. So, just assume for argument sake that this is both the variables are non negative, but otherwise it will extend to infinity and this will full extend to infinity.
So, anyway because this is F a 2, b 2 is probability x less than a 2 and y less than b 2, so in the case of non negative variables this is the total region, then F (a 1, b 1) is this ((Refer Time: 09:12)) region, let me this here. Then F (a 1, b 2) is this whole thing and F (a 2, b 1) is this region here, so you see that here you are subtracting this region twice and in this a 2, b 2 you are adding it and then you are adding this, so that gets cancelled out and this region also gets cancelled out. So, from the whole of F (a 2, b 2) you are finally, left with this particular region, this is the idea I am equating the probability with the area in a sense and that is what I am trying to explain. So, if you this picture in mind and you can always make the right competition.
(Refer Slide Time: 10:08)
 
Now, in case x and y are discrete random variables, they joint mass function can be written easily. because here you are simply wanting to compute these probabilities. probability x equal to a y equal to b is p (a, b) this is how we will define. So, if we can compute this probability, then that is the probability a, b and this for all possible values, if the appears a, b taken by x, y. And then, we can also compute the marginal probability mass function of x, which will be simply probability x equal to a and this will be your summing these probabilities over, so fix the x at a and then summing it over all possible values of y.
So, your summing up p (a, y) for all possible values of y that will give you the probability that x attains the value a, because here the value poison is not is a material, therefore you submit of over all possible values that y will take, similarly p y (b) will be summing up this probabilities x, b when p x (b) is positive. So, in this case you want to sum up overall possible values of x to get the probability that y will take the value b, and we will go through an example here. So, let us consider this 3 balls are randomly selected from an earn containing 2 red, 3 white, 4 blue balls, so the total number of balls is 9.
And now you want to find the joint distribution function of x and y, when where 3 balls are chosen from the earn and x represents number of red balls and y number of... So, I pick up the 3 balls from the earn, then I note the number of red balls present in those 3 balls earn and the number of white balls, so now we want to write down the joint mass distribution function for x and y.
(Refer Slide Time: 12:36)
 
So, let us now continue with the example with which they were the earn contains 2 red balls, 3 white and 4 blue, total number of balls is 9. So you want to compute the cumulative mass function for the variables x, y, where x is the number of red balls and y is the number of white balls, when you pick up 3 balls from the earn. So, I will just compute a few words, then you can try to complete the table I think maybe I have completed it already.
So, when you want to compute the probability of (0, 0) that means, x is equal to 0 and y 0, so which is no red ball and no white ball, so that means all the 3 balls that you pick up from the earn must be blue. So, the probability of all 3 balls being blue is 4 c 3 and total number of ways in which you can pick up 3 balls from 9 balls is 9 choose 3 and so this number comes out to be 1 upon 21, which is here; then I should have computed p (0, 1) and I think I have written it here as, so it is this number is actually, so it is got mixed up.
So, this is 1 by 7, so that is probability 1, 0 is 1 by 7, so if you want to compute have I done it somewhere here, no so therefore let us just quickly compute this number p (0, 1). So, (0, 1) is a probability no red ball and 1 white ball, so this will be no red ball that means, 1 pi white balls in 2 blue balls, so blue is 4 c 2 and 1 white out of 3, so this is 3 choose 1 divided by 9 choose 3. So, let us quickly compute this should be 6 3 and then, from here you will get a 6 and this will be 9 into 8 into 7, so 6 3's are 18 and this will be twice, twice 4, then 2 and 3, so this is 3 by 14, so 3 by 14 is this I have, so 3 by 14 is this number.
And this way I have it some computation where 0, 2 you have to compute and so on, so I will shown you some computations here p (1, 2), then p (1, 0), p (1, 1) we have computed and so you go on. So, now the whole ideas is that once you have completed this, then as I was saying that if you want the marginal distribution for x then, so for example if you are looking for the probability let me just take it from here.
(Refer Slide Time: 15:40)
 
So, if you add up the numbers here, this is what probability x equal to 0 when you are giving values to 0, 1, 2 and 3, in other words you are adding up probability, let me write it as (0, 0) plus probability (0, 1) plus probability (0, 2) plus probability (0, 3), so they can be 3 white balls, because total number of white balls is 3. So, all this will give you the probability at x is equal to 0, because when you pick up the 3 balls if it does not contain any red balls, then those 3 balls will either contain 1 white ball, 2 white balls or 3 white balls.
So, all these probabilities add up to the probability x equal to 0 and so this will be quite similarly, when you add up the second row that will give you probability x equal to 1, said third row will give you probability x equal to 2 and this be probability x in to 3, but since this is all 0, because there are no then number of red balls is only 2, so you cannot have number of red balls in the sample that you pick up as equal to 3. So, therefore, this is all zeros, similarly here you cannot have the combination (3, 3), because you are picking up only 3 balls and similarly (3, 2) (3, 1) is also not possible from here (2, 2) and (2, 3) is also not possible.
So, these are the only numbers and you see this now finally, because this is probability x equal to 0, probability x equal to 1, probability x equal to 2, which are all the possible values that x can take in your sample of 3 balls, because there only at most 2 white balls that can appear in a sample. So, this must add up to 1 and similarly, see when I add up these probabilities this will be give me the probability of y is equal to 0 that means, there is no white ball in the sample, when you add up these numbers this will give you the probability that y is equal to 1 and similarly this.
So, all these four when you add up that should also add up to 1 and that will give you good checks, so again at means when we are defining the marginal PDF and so on, then we must continue to check the validity. And so make sure that your calculations are ok, because otherwise you will know that you have made a mistakes somewhere, so you can go back and check. So, all these numbers, so the numbers here will give you the marginal distribution of y, here the numbers will be marginal distribution of x and so on, so this how you write down the joint probability distribution of two random variables.
(Refer Slide Time: 18:45)
 
Now, take another example, so that I want to make sure that you understand how the calculations are being done. Now, this is an example in which there is a community, in which 15 percent of the families have no children, 20 percent of the families have 1 child, then 35 percent of the families have 2 children and 30 percent have 3 children. Now, the probability of they are the children being a boy or a girl is same, that means it is half half, so once you pick up a family at random.
So, the experiment that we are doing here is let you pick up a family from the at random that means, any family is equally likely, then you want to find out the number of boys and girls in that family. So, both of them are random variables that means, number of boys in the family and the number of girls in the family, this family that you have picked up at random. So, here again let us see I have made few calculations, so if you want to compute p (0, 0) then that means, no children, so of course this is straight forward you know that 15 percent of the families have no children, so this is simply 1.5, so which we write here.
Then when you want to compute p (0, 1) that means, no boy just 1 girl, so this is the event probability of 1 girl child, now I write this as a conditional probability is saying that probability 1 child into probability 1 girl given that there is 1 child in the family. So, that will come out to be 0.20 in to half, because there is only 1 child in the family, p (0, 1), so that means, only 1 girl and no boys, so this total number of children in the family is 1, so that probability is 0.20. Then it being a girl or a boy the probability is the same, therefore it will be in to half, so that is 0.10 that is a number you enter here.
And similarly, if you want to compute p (0, 2), then it will be 2 children and so I am writing the conditional straight away, so 2 children probability of that and then, 2 girls given their 2 children. So, this is 0.35 from here, families having 2 children that is 0.35 and then 2 girls, so 1 by 2 in to 1 by 2, so divide it by 4 and so that is 0.875. Then when you want to compute I have done it here, it is not very this thing, but any way it is coming maybe I can just show the calculation in a better way, so when you we want to have a (0, 3) that means, all the children are girls.
So, this again will be probability 3 children which is 0.30 when into 1 by 8, because all the 3 are girls, so 1 by 2 raise to 3. And therefore, you divide this by 8, so this is 0.0, then 3 will be 24 then 6, then 8 7' s are 56 and then, 40 and 8 5' s 40, so 0.0375. So, when you add up this numbers this will here will be the probability that x is 0 that means, no probability when you pick up a family at random from the community, there are no boys in that family. So, that number will come out to be this you can add it up, similarly this will give the probability at x is equal to 1 that means, 1 boy in the family, probability x equal to 2 and this will be probability x equal to 3.
I am here also you can see that this these combinations and of course, because the boys and girls are equally likely, so the tables once you have computed this part, then this is symmetric, because whether having a 1 1 when you have 2 children, so it is whether girl or boy is same, therefore this will be the same. Then 1 2 see this one we are having, ((Refer Time: 23:06)) this is 2 0, I am sorry 0 1 and 1 0, so that was a number, then this number for example, 2 1 and 1 2, so this two numbers.
So, this is symmetric, because boys and girls are equally likely, similarly here whether all the 3 children in the family are boys or all the 3 children or girls, the probability must be the, so I am sorry this should be 0.375, so make that corrections, so this will 0.0375. And then again as we had said when you add up all these probabilities, they should add up to 1 and here also you will get the marginal’s, so this will be probability y equal to 0, probability y equal to 1, probability y equal to 2 and probability y equal to 3.
So, I would like you to complete the tables, I have made some computations for you this so this is the same, now you have to make just these two computations and then you can complete the table. So, this gives should give you an ideas to how to go about computing joint, if I when the variables are discrete, how to compute the joint distribution function for discrete random variables.
(Refer Slide Time: 24:25)
 
So, let us continue with the jointly distributed random variables, suppose x and y are continuous, so I will now define in other way in the sense at now I will define this through your joint PDF and so. We are saying that if there exist a function F (x, y) real valued function, which is defined for real x and y having the property that for every set C a subset of R 2 that means, all the pairs of values, which are there in C, then (x, y) belonging to C that means, you see the convention is this a pair of co-ordinates, then the first value is for x, and the second value is for y.
So, then probability (x, y) belongs to C is this, so now this is different from the way we define the cumulative distribution function right in the beginning, so of course two will must to the same thing. So we have the probability should be f (x, y) d x d y for it continuously distributed, a jointly distributed continuous random variable. So, f (x, y) is called the joint PDF of x, y and if A and B are two subsets in R square, then probability that x belongs to A and y belongs to B will be integration over a with respect to d x and actually see one should make a convention that this must refer to the later one here.
So, I should have said this is d y and d x, because just a convention, so therefore when you writing the limits, range, then it is nice to remember that this one refers to the second integral and this is the first, so the order has to be maintained. So, therefore, this is A B, so I should written d y d x of f (x, y), so the same thing is being on the sort of repeated and therefore, if your F (a, b) as we defined earlier is now x lying between minus infinity in a, y lying between minus infinity and b; then the partial derivatives here delta square delta a delta b f (a, b) will be f (x, y) (a, b).
So, this is the relationship between the cumulative joint cumulative distribution function and joint PDF. And then of course, the marginal distributions here, so this will be x belonging to A and y is from minus infinity to infinity. So, in that case your integrating with respect to y from minus infinity to infinity and this integral, when you integrating with respect to y will be the marginal. Just as I showed you in the discrete case, that you add up for all the possible values of y to get the marginal and the probability of x for a certain value.
So, same here, the marginal respect to x will be you integrate the joint PDF from minus infinity to infinity and for the marginal of y the PDF of marginal y, this would be integrating respect to x from minus infinity to infinity. Then of course, depending on whatever the region of actual definition else, now let us just take up this example. So, if you have this function define here, which is define for all values of x is from 0 to infinity and for all values of y from 0 to infinity, and it is 0 otherwise, so it is in the first quadrant that the function is defined.
(Refer Slide Time: 28:04)
 
Then verify that this is joint PDF, so therefore the total integral from 0 to infinity and this should be 1, so suppose I just integrate respect to y first, so the integral is minus e just to minus y from 0 to infinity that gives you 1, because at infinity this is 0, at 0 this is plus 1. So then this is this now you integrate this respect to x, so x is minus 3 upon 3 e just to minus 3 x going from 0 to infinity, which is equal to 1 now if you want to compute this particular probability, then your limits will be...
So, this time have taken care of the order, so this is 2 to infinity for x and for y it is from 0 to 1 and so again the same integral you do it respect to y first, take the limits and then this is 1 minus e just to minus 1, then you integrate this respect to x and this will be, so the final answer will be this ((Refer Time: 29:08)), and so you can go on. So, this is nothing new except that your dimension has increased and the same concepts are there, the same axiom will be followed. And so we will now continue developing this theory and then, talk of independent random variables, jointly distributed independent random variables, then we will talk of some of random variables. So, of course the thing is let this concept can be extended to more than two and expect that the writing part is in little TDS, but the same thing will follow.
(Refer Slide Time: 29:44)
 
So, I will just revisit this, I had shown you this probability try to computing this probability, I had drawn the diagrams, so let me just make it more clear, because I had a feeling that I did not do a very good job last time. So, let us see probability x greater than a and y greater than b, then if this is my origin this is x equal to a, this is y equal to b, then this is the area that you want to compute the probability on, your region x greater than a, y greater than b is this event represented by this area.
So, now we said we will write it as x less than or equal to a, so x less than or equal to a is this whole area, extending on this side the whole area and then, y less than or equal to b will be this area. So, therefore, all this and all this gets covered and you see this area the area that is x less than a, y less than b this is, so this portion because when you are covering x less than a, then it is all of this y less than b then it is all this. So, therefore, x less than a, y less than b this particular area gets covered twice, so you and here and therefore, you get this.
So, therefore, 1 minus of all this, that means if I write a probability x less than or a plus probability y less than or equal to b minus this, then I will get the region corresponding to this and therefore, so 1 minus of that and that will be the probability for this. So, just wanted to revisit this thing and here also in the other example that we had taken, we would talking of a community in which there are families and they were probabilities associated with families having no children, 1 child, 2 children and 3 children.
So, I thought that though I asked you to compute add compute it is some probabilities for you and I asked you to compute the remaining one, but I realize that probably you need a little more working out and the so I thought I will give you the hints here. For example, when you computing (1, 1), then it is the probability 2 children into a conditional probability that it is either a boy girl or girl boy. You see when you are saying 1, 1 so then it can be, the first child is boy and the second is girl or the first child is a girl and the second child is a boy.
So, therefore, this will be 0.35 into, because a probability of families having 2 children is 0.35, then into actually boy girl will be 1 by 4, because each of them are equally likely what since they had two possible cases, so 2 into 1 by 4 therefore this is half, and so this number comes out to be 1 1, this is 0.175. Now, for 1 2 when you want 1 boy and 2 girls, then that means the 3 children, so the probability of having 3 children is 0.3, 30 percent of the families have 3 children, so this is 0.3.
And the conditional probability of having a boy and 2 girls and then, with 3 children, having 3 children and then, 1 boy and 2 girls. So, now here again you need to say that see it could be the first child who is the boy other two are girls, then it is first girl, then boy, then girl and girl girl and boy, so these three possibilities are for there, therefore it become 3 by 8. Because, each of them is half, so then when you have these three possible cases favorable for your event, then this is 3 by 8, so 0.3 into 3 by 8 that comes out to be 0.1125 and at the rest we had computed.
And then these are the marginal, so that means this I told you is probability x equal to or B equal to 0 and probability B equal to 1, probability B equal to 2 and probability B equal to 3. Hence similarly here, this is the marginal for probability girl is 0, no girl in the family of course, so probability no there is 1 girl in the family, 2 girls and 3 girls and then, you see that this adds up to 1. Because, they are marginal PDF' s are probability mass functions and so so once you find out the joint, then you find out the marginal's and then you can do all other competitions that are required the expectation, variance and everything you can compute as we have done it for you.
Like even for the joint also you can do it, expectation (x, y) you will do it and so you will multiply that I think I have given you the expression p (x, y) this we worked it out this into your values that x and y takes imply y is positive and so on.
(Refer Slide Time: 35:10)
 
Now, I will continue with some more examples of the continuous random variable, so here let us see you take a circle of radius R and let us say it centered at the origin, so the equation of the circle is x square plus y square equal to R square. So, when you are taking the inside of this circle then it is less than or equal to R square, so this is the circle given to you, and we just pick a point and inside the circle, then that is a random because and we are saying that all points are equally likely to be picked up, inside the circle.
Then let x represent the x co ordinate of the point that you are picked up y is the, capital Y represents the y coordinate, so now both x and y are random variables and since any point in the circle is equally likely, therefore it will be a constant the PDF of (x, y) that joint PDF of (x, y) will be a constant inside the circle and 0 outside. And this is an example of a two dimensional, two variable uniform distribution, so this represents uniform distribution, because any point in the region in on the circle is equally likely.
And then, now you want to find out the value of C, so we will have to say that this must integrate to 1, the whole thing and since this is simply minus infinity to infinity and minus infinity infinite d x d y, this is an element of area. So, when you integrate over the whole of this circle you will get the area of the circle by everybody, so this is you have already done it in your class 12 and so on. So, then C into pi R square is equal to 1, therefore your constant is 1 upon pi R square which is expected, one dimensional also I have told you that when you had uniform random variable this was the length of the...
So, if this was point a this was b, then the probability density function for this uniform random variable was 1 upon b minus a, which is 1 upon length of the interval in which the random variable is defined. Here the pair (x, y) is defined inside the circle when it is uniformly distributed this pale and that means, that the PDF must be 1 by pi R square, the area of the region, in this case it is the area of the circle. Now, you want to compute the marginal of x, and marginal PDF of x and marginal PDF of y, so for x you will integrate from minus infinity to infinity f (x, y) d y.
And this what I want to point out that is, so you are fixed value of x, if you are fixed the value of x, then how does a y vary, y varies along this card and the length of the card is because this length is x, this is R the radius of the circle, so this length is under root R square minus x square. So, therefore, this point has the co-ordinates x, under root R square minus x square and this point has co-ordinates x, minus under root R square minus x square. So, your y varies from minus under root R square minus x square, 2 under root R square minus x square, so this is it.
This reduce, because there is no other ((Refer Time: 38)) outside this, so this is C into d y and this C is 1 by pi R square, so this becomes twice under root R square minus x square. And this is defined for all x between minus R and R, because your x varies from this point to this point along this, and see your x various along this, your y varies along this, so the whole circle gets covered. Similarly, because the symmetry, so your marginal of y will be twice under root R square minus y square upon pi R square, where again y varies, this got next step, this is minus R less than or equal to y, less than or equal to R, 0 otherwise.
Now, suppose you want to find out the distribution of random variable d, which is the distance of the point from the origin, so this is under root x square plus y square. So, you take any point here and then, this is the distance length would be under root of x square plus y square. So, we find out the distribution function of d which will be F D (R), so that means, probability d less than or equal to R, now since everything is nonnegative, distance is a non negative number, R is non negative.
So, this event is the same as squaring up both the sides that means, x square plus y square less than or equal to R square, the two events are the same. And again by the same argument that for x square plus y square less than or r square, so all points inside the circle having radius R, all these points will satisfy this or define this event, every point inside the circle of radius small r. And therefore, the area here is pi R square small r square and divide it by the PDF, which is pie r square, so you can you know want you can do it from by integrating in everything.
But, this is a straight forward because everything is uniformly distributed, so therefore, the probability of a point lying inside the circle small r is pi R square. Just as we said that the you know; that means, this is the area, which is favorable to our event and then the density of the function is of the 2 pair is 1 up on pi square R square. So, therefore, the probability the distributional of function of D is R square up on capital R square, so now, if you want to find out the PDF of D would be did differentiating this respect to small r. 
So, 2 R up on R square and small r varying from 0 to capital R because now D is a non negative random variable and the value of D will vary from 0 to R. Because, the point is here, then this way and this way, so you can go up to capital R and similarly we can find out the expectation of D, which will be 2 by 3 R. So, you now geometry helps, you draw pictures, then you can you know get a good idea is to how to go about solving a problem. 
So, and the moment you have more than one, you know if you consider a pair of random variables. And you can see that the complexity will increase the moment to consider higher dimension you know; that means, 3 random variables together joint density function of three. But, and as I go long I will try to solve some more problems relating to two random variables joint distributions of two random variables.
(Refer Slide Time: 42:43)
 
So, another example on joint distribution of random variables, suppose f x y is a function given like 6 by 7 x square plus x y by 2, x is between 0 and 1 and y is between 0 and 2. So, then you want to verify this represents a PDF of the variables x y, so I just integrate from as 0 to 1 and 0 to 2 and the working out shows that this x square y plus x y square by 2, if your differentiating with respect to y. Because, I have written the limits with respect to y first 0 to 2, so let us integrate respect to y first.
And therefore, this is what you get and then you this you look at this, then integration respect to x 0 to 1. So, that will give you this function and finally, you get the integral to be equal to 1, so therefore, the function does represent because it is a non negative function, since x and y are both non negative. So, this is a non negative function, the integral in the defined the specified area integrates to 1, so it represents PDF, now to compute the marginal the PDF of x or the marginal of x, you see I have already done it here.
Because, you have to integrate this integral from 0 to 2 d y, so this integral gives me the marginal of x. So, therefore, this is 2 x square plus x 0 less than or equal to x less than or equal to 1 and you see that if I now integrate this from 0 to 1, it will give me the answer 1. And hence this is also a PDF it is non-negative, in the specified region and of course, and I should also say 0, otherwise it is very important that here definition of the PDF’s must be complete in the sense that you must specify the region on which it is defined.
So, here it is in between x 0 and 1 this is the PDF is defined by this function and it is 0 otherwise, then you are asked to compute x greater than y. So, if you have to compute x greater than y, then see I have written down this the line with represents x equal to y, so this is that region over which you want to compute this probability because you have specify the event. So, then it will be see here, if you are integrating with respect to x then you fix a y; that means, when I am integrating respect to x by x is varying, so y is fixed. 
So, when you fix a y in this region how will your x vary from y to 1 because this represents 1 here is this line. So; that means, you are integrating from here to here for a fixed y and as y changes from 0 to 1, you will cover the whole area like this, so therefore, range for a variable x is from y to 1 and y varies from 0 to 1. So, this is very important and again I will keep a repeating this that draw the diagram you can two dimensions you can always do it and then you get a feeling for how the what are the ranges of a integration and, so on.
So, integration respect to x gives me a x square x cube by 3 plus x square y by 4 from y to 1 and that is important because I must integrate respect to x first, since limits for x are in terms of y. So, then I will first integrate with respect to x and then that function as a function of y and then I integrate with respect to y, so this has to be the order you must keep this in mind. And so finally, this comes out to be 15 upon 56, so the arithmetic should be correct, now here what I was saying is that suppose you had to compute the event probability y greater than x.
So, in that case you see what will happen is it is this region, which you have to do it, so then you see you will have to break it up in to or what you can do is may be now it is not necessary. Because, then if y is greater than x, you will want to write the limits; that means, for a given x how will a y vary, that is no problem, so y will vary from here to here; that means, it will vary from x to 2. So, I will integrate respect to; that means, if y is varying from x to 2, so we will have to integrate respect to y here, so the limits would be x to 2 and then x varies from 0 to 1.
So, this will give you this probability, if you integrate first with respect to y x to 2 the same function and then you integrate with respect to x because for a given x. So, this how when you have the diagram you can immediately see that given value of x, the corresponding value of y can range from x to 2, then that is it you can compute this.
(Refer Slide Time: 48:27)
 
Now, just look at another example, and maybe we do not need to compute it fully, but I will give an idea here, this is f x y is defined as c into y square minus x square into e rise to minus y, now the limits for x are from minus y to y and y varies from 0 to infinity. So, therefore, to draw the diagrams see what I have said is that, when y is fixed then my x is varying from minus y to y. So, it has to be between the lines, this is x equal to y and this is x equal to minus y or minus x equal to y whatever whichever way.
So, this is this, and this is this line, so you are x is in between these two lines and your y varies from 0 to infinity. So, it is this region extending to infinity, this is the region and, so once you know this, then there is no problem because anyway you was first want to find out the value of c. So, find value of c sorry that this defines a PDF, so then you can integrate and you see with the what will happen is that you come up to here, now this is y cube a is to minus y.
So, you will have to you know do integration by parts and it will have to be done 3 times because you know you this will be a first function this is second. So, you will have to in the first iteration you will get y square, then you will have to do it again to get y and then get rid of the y. So, therefore, it will be 3 times you will have to repeatedly apply integration by parts to get the value of c, so that this integral finally, has to be equal to 1 and this...
So, once you have the diagram in front you, you cannot go wrong you, you can always find out the correct limits, and then decide how to you know like what I was doing is I was dividing the region in a certain way to do the integration, which you have already done in your while you would doing your calculus course.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 13
Independent R. V. and Their Sums

I will start by talking about Independence of Random Variables, when they are jointly distributed.
(Refer Slide Time: 00:23)
 
So, just again an extension of the same concept that we talked about for single random variables, now here one can write it in two, three ways, x belongs to A and y belongs to B, so their two subsets a b of the real line. And then a probability this should be equal to probability x belonging to A into to probability y belonging to B, and this should hold for all possible subsets A, B of R.
Now, in other words if the events, so another way of saying is that this event and this event are independent for all A, B subsets of R another way of saying it. Then an equivalent definition of independence of x, y would be that you now allow you take real numbers a, b and then you are saying that x is less than or equal to a, y is less than or equal to b is equal to probability x less than or equal to a in to, this should hold for all and b and this is if and only if.
This or you, then by using the 3 axioms you can show that this and this are the same definitions that you can, then can take to real numbers and you can describe your events in that way. So, this will immediately employ that you are distribution function, cumulative distribution function for the joint cumulative distribution function can be written as a product of the individual cumulative distribution functions. Now, if x and y are discrete, then we say that we can equivalent way of writing it is or this is how we can p x, y is p x (x) into p y (y) that means, individual probabilities for all x, y.
And surely this definition and this definition are the same, because this is the general one which covers both continuous and discrete. Now, if you just can take A as single term x and B as the single term y, then this follow from here, because x equal to A, so A, B that means x, y, if A is simply a single term, B is also single term y, then this becomes x, y and this is probability x into probability y of course, with respect to x and respect to y.
So, I mean two follows from one, when you choose the sets A, B to be single terms and the other way it is valid, because if star is valid for all x, y; then you can you can write this definition as the first part of star as summation p x y, x belonging to a y belonging to p that is our definition. But, since this is x and y are said to be independent, then this can be written as p x (x) into p y (y), where x summing over all x’s in A and summing overall y in B, then you can separate out the summations you can write out this way and therefore, this is probability x equal to I did not… So, probability x belonging to A into probability y belonging to B, which is the same as this, so if this is valid star follows and if star is valid, then double star follows, so this is whole idea.
(Refer Slide Time: 04:05)
 
Now, and of course, in equivalent condition for this, for the continuous case would be, that the joint PDF, can be written as the product of the individual PDF, so now you have so many equivalent ways of expressing the same concept. I will take this example function Sheldon's law, a interesting to again show the computations and the how we make use of independence of random variables.
So, here a man and a women decide to meet at a certain location, if each person in dependently arrives at a time which is uniformly distributed between 12 noon and 1 pm. So, they arrival time of both of them is a random, I mean for the man and the women both are random variables and this is the time is between 12 noon and 1 pm, now you have to find the probability that the first who arrive has to wait longer than 10 minutes, so therefore that is why I converted the PDF as 1 by 60 for each x and...
So, here let me define the random variable x as time and minutes past 12 noon when the man arrives and similarly, time in minutes past 12 noon when the women arrives at the fix part, so both are random variables. And they uniformly distributed between 0 and 60, so that means the PDF will be 1 by 60 for each, so when you take the joint PDF that will be 1 by 60 square; and will say that x and y bit vary between 0 and 60. So, the probability that you are asking for is x is the probability for the man to arrive, so if the man arrives first. then x plus 10 should be less than or equal to y that means, this is the time when the women arrives.
So, the man has to wait because he is the first to arrive he has to wait for longer than 10, that is probability x plus 10 less than y, but since x and y are continuous random variables computation of the required probabilities alright. And similarly, if the women arrives first then y plus 10 should be less than or equal to x, but since x and y are identically distributed independent assumes. So, therefore, the two events are the same, so that means, the probability will be exactly the same from symmetry.
So, twice probability x plus 10 less than or equal to y, this what we have to compute and so you write down the limits you see for x, for x the limits are 0 to y minus 10, x is less than or equal to y minus 10 and x varies from because the arrival, the man can arrive at 12 noon itself, so x will be 0. So, x actually varies from 0 to 60, so here it is 0 to y minus 10 and the women can arrive has to, because the man has to wait 10 minutes or more, then it should be 10 to 60; so the arrival time of the women would from 10 to 60, so this is what is important.
So, once you fix the limits and the joint PDF, then computing the probabilities is not a problem, so one has to spend time in just thinking as to how to event is described very clearly. So, here the limits for y for the women arrival time would be have to from 10 to 60 and this is from 0 to y minus 10 here, so therefore you integrate respect to x and they simply x, so y minus 10 by this thing. And then when you integrate respect to y it will be y square by 2 minus 10 y, from 10 to 60, so this will be 2 by 60 square and this would be 1 by 2 60 square minus 10 square and then minus 10 into 60.
((Refer Time: 08:27)) So, we will continue from here, this was y square by 2 minus 10 y from 10 to 60, so then this becomes 60 square minus 10 square, this one by 2 and minus 10 into 60 plus 10 into, this 10 into 10, so when you compute this form 10 to 60. So, this is minus 10 into 60 plus 10 into 10 and so when you simplify the numbers this here, this would become 2500 upon 60 square and this is 25 by 36. So, desired probability is this much that means, who ever arrives first at the meeting place will have to wait for more than 10 minutes, the probability of that is 20 upon 36.
(Refer Slide Time: 09:25)
 
So, let me continue with the with examples of jointly distributed independent random variables, now is the interesting examples, it is called the Buffon's needle problem, Buffon was a French naturalist and so he formulated this problem. It is say that table has parallel lines drawn on it and the distance between two consecutive parallel lines is D, now you drop a needle on the table and of course, one possibility is that the needle lies like this, so it does not intersect one of the lines, but suppose it does intersect one of the lines, so that is what we have to find out.
So, a needle of length capital L, where L is less than or equal to D, the distance between two consecutive parallel lines is randomly thrown on the table, what is the probability that the needle will intersect one of the lines, so we have to compute this probability. And now here I would drawn this diagram, so this is the needle at B is the middle point of the needle and you drop a perpendicular form here to the nearest line, so that is x, so that will be a random variable, because you do not know the position.
So, that mean the two random variables that describe the position of the needle is the distance of the centre of the needle from the closest dearest line and the angle it makes with the nearest line, so that angle I am calling as theta. So, this theta and this is a distance which is x, so these are the two this thing and we are saying that you see, this thing is if this is the centre point, then this is L by 2.
A length of the needle is capital L, so this length is L by 2 and if you are O B is less than L by 2, then the needle will intersect the one of the lines, so that way geometrically this is describing. So, this is making use of geometry to also explain things and probability theory, so here x is a random variable equal to the distance of the centre of the needle from one of the lines. And so now, you can see that x upon in the right angle triangle O A B x upon O B will be sin theta. So, sin theta in the right angle triangle O A B x upon O B sin theta or x is O B sin theta that is O B is x upon sin theta.
And this has to be less than L by 2, so this is our condition for the needle to intersect one of parallel lines drawn on the table. So, and x varies from 0 to D by 2, because it can come up to here, because after that it is a same thing, then the position of the line will become like this. So, it this can up to D by 2 and theta can vary from 0 to that means, either needle almost lies on the parallel line all it makes a, it stands like this, these are the two, so theta varies for 0 to pi by 2, so these are the ranges for the two...
And of course, since any position is equally likely, we will say that both the random variables x and theta are uniformly distributed, so x is uniformly distributed in the interval 0 to D by 2 and theta is uniformly distributed from 0 to pi by 2. So, you see the one of the density PDF for a uniform random variable is the 1 upon length of the interval in which this define, so here it is pi by 2, so 2 by pi and here it is 2 by D, so this is the joint PDF that is 4 upon pi D.
So, now you want integrate, you want to find out the probability x is less than L by 2 sin theta, this is our condition, so therefore theta varies from 0 to pi by 2 and x will vary from 0 to L by 2 sin theta, then this is to be 4 upon pi D d x d theta, so this is the integral which will give you the required probability. And so that is simple enough, because respect to x see this is independent of x and theta both, so here you get integral x and so that will be L by 2 sin theta into 4 by pi D.
And then you integrate respect to D theta here, so that will be minus cos theta 0 to pi by 2 which is equal to 1, so the required probability is 2 L upon pi D. So, one can constructs interesting examples and so here, we use the independence of the two random variables to compute their joint PDF and then which I think I probably be now... So, we have already shown this that the joint PDF will be the product of the two marginal PDF' s independent.
(Refer Slide Time: 14:58)
 
Now, in another preposition and this sometimes makes life easy and you can immediately find out the independence of the random variables, so this if and it holds for discrete and continuous both. So, what it we are saying that random variable x and y are independent, if and only if they join density function f x of x, y can be written as a product of two functions h x and g y. So, this would only a function of x, this is function of y and you see the range the limits are also independent, so x varies from minus infinity to infinity, y varies from minus infinity to infinity.
And since, so what we are saying is that since the integral, double integral here is equal to 1, because this is a PDF, so this implies that when you replace this by h x into g y and the integral separates into two single integrals and so this is this lap to be something like C 1 and this C 2, so this product is 1. So, therefore, see 1 upon C 1 h x will be a PDF and 1 upon C 2 g y will also be a PDF, because by definition this is C 1, so 1 upon c 1 will be 1 and here 1 upon C 2 will be 1.
So, therefore, this is the thing that means, always able to convert these two, since this is the PDF and if it is a product of two such functions, single variable functions, then we will be able to convert both of them into PDF' s this is the idea. So, let us just look at few examples, if your join density function is given as 12 e raise to minus 3 x into e raise to minus 4 x, this is minus 4 x and x between 0 and infinity y between 0 and infinity, when you see I can multiply this by 3 and this by 4.
So, this now is your exponential with parameter 3, immediately recognize it this also is exponential with parameter four and so both are PDF’s; and so therefore, you conclude because it says if and only if, see this is the part. So, we have told you already that if they are independent, then the joint PDF will be a product of the individual PDF’s and here I am saying that, if f x, y can be written like this, then again x and y are independent. So, therefore, I can immediately conclude that x and y are independent, because your f x, y can be written as the product of two PDF’s.
Then if you look at this function here, x e raise to minus x plus y, now here again I can break it up into two functions x into e raise to minus x and this e raise to minus y. So, this I know immediately is exponential with parameter as 1, lambda equal to 1 this 1 and here I can quickly verify that this is also a PDF, which means that integral of x e raise to minus x from 0 to infinity d x and if you now integrate this by parts, then you you get minus e raise to minus x x. Take this as the first function, so 0 to infinity this gives to 0, then you have plus 0 to infinity e raise to minus x d x which integrates to 1. So, therefore, this is the PDF and this also is the PDF, so the proposition again tells us that x and y have to be independent random variables.
(Refer Slide Time: 18:39)
 
So, let me now show you take another example see f x, y is 24 x y and you see here you can decompose it into a function of x and a function of y. So, let us now, but the thing is that the area of integration, so this is x between 0 and 1 y between 0 and 1, but x plus y less than 1. So, you see here the connection is there and therefore, the suspicion is that the two random variables are not independent and we will see.
So, I have shown here the area and over which the valid region, so this is x plus y less than one, this is the line, so here in the square 1 1, this is the area on which you have to concentrate. So, now, first let me verify that this is the PDF, so therefore see your range for x will be from 0 to; that means, given a value of y, if I am integrating with respect to x then I fix a value of y and then I draw a line, so therefore, I will be my range for x is then from 0 to see when you fix 1 minus y.
So, x varies from fixing a y then y range for x will be 0 to 1 minus y and that is what have written here 0 to 1 minus y 24 x y d x d y and. So, even you integrate respect to x this x square by 2 0 to 1 minus y and so the integral is the value of the integral is 1 minus y whole square by 2. And here just open it up take y inside. And then you integrate you this is what y square by 2 minus 2 y cube by 3 and y of 4 by 4 from this is 0 to 1 right. And, so this will be when you substitute the values at 1 you get this which is equal to 1.
So, we have verified this is the PDF and now you compute the marginal’s and we will show that the product of the marginal's is not equal to the join density function. So, because that condition was if and only if remember, so here when you integrate respect to y. So, gain this will be now 0 to 1 minus x; that means, your fixed x, so once you fix an x then your y will vary like this, so from 0 to fixing x, so y varies from 1 minus form 1 minus x. So, this will be the length of the range for y, so therefore, 0 to 1 minus x, x y d y and again this will be x into 1 minus x whole square the same integral that we did 
And, so this will be 12 into x 1 minus x whole square x varies now from 0 to 1, similarly the marginal of y same integral because the symmetric the function is symmetric with respect to x and y both and the limits are also. So, therefore, this will be this and y between 0 and 1, so you see that f x y is not equal to f x into f the marginal's, so therefore, the 2 random variables are not independent. So, when you say that you can break up the joint PDF into individual you know functions of the single variables, then make sure that the range is are also independent.
Otherwise, the random variables will not be independent, so we will continue and then may be will keep coming back to so but independence is a very important concept does simplify lot of things in probability theory. Now, let me start talking about sums of random variables I have already told you earlier that how we can, I know get the distributions for sums of independent random variables. So, here again the catch word is independent we need that, so now for example, if x and y are 2 random variables, which are independent and if f x, y is the joint PDF.
Then, if you want to write the distribution function for the random variable x plus y this will be given by this, which will be, so now, here again the same thing that we used in this case. So, since x plus y less than or equal to t, so if you are integrating with respect to x and y is, ((Refer Time: 23:09)) so this will be minus infinity to t minus y range for x and then the range for y will be minus infinity to infinity. But, since this is x and y are independent, so this can be written as a product of the individual PDF’s the marginal PDF’s.
So, therefore, I can separate out my integrals minus infinity to infinity f y y d y and minus infinity to t minus y f x x d x. And, so this you know gives you what, this is the probability of capital X less than or equal to t minus y, so therefore, this is your cumulative distribution function for x at t minus y this integral. And this is the integral minus infinity to infinity f y y d y, so this is called convolution of because here this is the distribution function for x at t minus y minus infinity to y, well not exactly you are well I am writing small f y d y. So, anyway this will be called as a convolution because this is at y and this is at t minus y, but I will make things more clear here. See now if you want to if I differentiate this with respect to t then I get the PDF for x plus y.
(Refer Slide Time: 24:41)
 
And you say that here this is this and remember we have done it already we can exchange the integral and the derivative sign provided this thing here is differentiable. And, so I take the derivative inside this gives me this and this now f x t minus y d d t will give me the PDF of x at t minus y and this f y y d y minus. So, now, this is also this you can see better as a convolution of the 2 PDF ‘s f x and f y, so f y y then f x is t minus y, where we are looking at the event this less than or equal to t, so this is called the convolution.
And sometimes it comes in handy, but I will try to show you again; that means, my philosophy is that you should try to use geometry and direct methods as much as possible to get answers. The formulae are important and sometimes they are very helpful and I have shown you, that at times it has helped us to use the derive formulae to get the result, but sometimes it also helps to do things directly. So, let us take this example, some of 2 uniformly distributed independent random variables x and y on the intervals 0 1.
So, now, I want to find out the PDF of the random variable x plus y, where both x and y are uniformly distributed on the interval 0 1 and they are independent. So, then the variable z which represents the sum, will now vary from 0 to 2 because this varies from 0 to 1, this varies from 0 to 1, so the sum can be vary from 0 to 2. So, as I am saying we will do it (( )) using the formula directly I will try to compute the cumulative distribution function and see.
So, therefore, the diagram is here 0 to 1, 0 to 1, x axis, y axis, now you see what happens is if your t is less than or equal to 1, see t equal to 1 gives you this line x plus y equal to 1 and this portion is covered by t greater than 1. So, as long as t is less than 1, you see this is uniform, so; that means, uniform mass over this region, so therefore, to get this probability I just need to compute the area of this triangle. So, it would get probability x plus y less than or equal to t, it is simply the area of this.
Because, the joint density function is what, your join density function is 1 into 1, which is 1 because both are uniform on the intervals 0 1. So, the mass spread over is you know is same uniform unit and so the area of the valid region would be or probability, so here as long as t is less than or equal to 1. The area was therefore, if you take this or you take this, then it will always with the area of this triangle.
So, therefore, this is half t square because this side is t and this is side t, so base and height are both t, so half t square for 0 less than t less than 1. Now, when t becomes more than 1, then you see it is no longer because it is this a region which is a triangle, but you need this area. So, therefore, what I will do is from the total are 1, I will subtract the area of this triangle and that will give me the required probability, so this line is x plus y equal to t and therefore, it intersects x equal to 1 at t minus, so therefore, the y point is t minus 1 because t is greater than 1.
Similarly, this is t minus 1 1, so then both these lengths this point is 1 1, so when you do it 1 minus t of minus 1 plus 1, so 2 minus t. So, this length is 2 minus t, this is length also 2 minus t, so the area of that triangle is half 2 minus t whole square and therefore, the required probability is 1 minus 1 by 2 into 2 minus t whole square, when t lies between 1 and 2. So, see looking at the diagram things become really simple and therefore, when you differentiate this respect to t, in this case it becomes t 0 less than t less than 1.
And for this because this is a minus sign minus sign, so 2 2 cancels 2 minus t as t varies between 1 and 2. So, now, if you draw the picture graph of f to t between 0 and 1 it is given by this line and between 1 and 2 it is given by this line, so it is a triangle, so therefore, this is also known as triangular distributions. Now, I leave it to you to try out the convolution formula and then see that you should get the same answer. So, you can sit down and verify for yourself the formula is clear here for different values of t you will have to. So, here of course, your this thing will be from 0 to 2 because your t can vary from, but looking at the diagram things really become simple and you can, so where ever possible use geometry or direct methods.
(Refer Slide Time: 30:19)
 
Now, trying to look at this example, where you have x is uniform (0, 1) and y is exponential with parameter 1 and x and y are independent. So, now we want to look at the, so the joint density function of x and y will be just the product of the individual PDF's, so this is for the uniform it is 1 and for the exponential it is e raise to minus should have written e minus y, so this it is ok here I just wrote here e minus y. And so your y varies from 0 to infinity x is between 0 and 1, so now you want to find out the probability that x plus y is less than or equal to t that means, this is your F of x plus y t, this what you found want to find out.
And so you see now here what I have right now written is when 0 is less than t, less than or equal to 1, so you see the region of integration as I had told you is x between 0 and 1 and y non-negative, so going to infinite. So, this is the region for integration and I was trying to tell you that we have to separate out the integration into two parts, because you see for x plus y less than or equal to t as long as t is between 0 and 1, then this is this area which will has to be covered. So, therefore, for example if you take the line x plus y equal to t, if this the line, then the limits for x are from 0 to t and for y will be from 0 to t minus x.
So, therefore, t between 0 and 1 these are the limits and so you can, therefore integrate respect to y first, so that will be 1 minus e raise to minus t minus x, because integral of this will be minus e raise to minus y and so from 0 become 1 minus e of minus of t minus x d x. And then you integrate respect to x the limits are 0 to t and so this will be x and because this is plus x, so this will remain minus e raise to minus t of minus x from 0 to t and therefore, this is your cumulative density function for t between 0 and 1. Now, for t greater than 1 with lines would be like this, express y equal to t which is greater than 1.
So, in that case you are for a given x your y will vary like this form 0 to t minus x, and x will vary from 0 to 1, because when you are talking of t greater than 1 this line, then x will vary from 0 to 1 and t will vary from 0 to t minus x. And therefore, for t between 1 and infinity it will be 0 to 1, 0 to t minus x, e raise to minus y d y d x and again the same integration. This one is exactly the same and then from 0 to 1 with respect to x, so this will be minus e raise to minus t minus 1 plus e raise to minus t plus 1.
So, please just verify that these are valid cumulative density functions of course, here as t goes to 0, this goes to 0, t goes to 0 this is 0 and this is 1, so 1 minus 1 is 0 and as t and from here as t goes to infinity you can see that this will go to 1. Because, this will go to 0, this will go to 0 and you will be left with 1, have I written it correctly here let us just make sure, let us t goes to infinity then this goes to infinity also and so e raise to minus of t minus 1 also goes to 0, so therefore the limiting value is 1. So, this is the valid cumulative density function and therefore, now you want to compute the PDF then just differentiate.
So, this will be 1 minus e raise to minus t as t is between 0 and 1 and this one here would be minus e raise to minus t and then this will be plus e raise to minus of t minus 1, so this is your PDF for... So, therefore, all these things as you work out and get experience, you can get a experience. you can get feeling how to go about big and the diagram in of course, you can do it in two or three dimensions. So, therefore, the diagram helps to tell you that you have to break up the integration into two parts, so between 0 and 1 for t between 0 and 1, the limits for x are different and when t is greater than 1, the limits become difference. So, therefore, this can only you can get the feeling by looking at the figure and then you know deciding accordingly, so we continue with some more of these examples.
(Refer Slide Time: 35:16)
 
So, expectation of x plus y is equal to expectation x plus expectation of y, now let us just try to first to show this under independence of x and y, so then I can write the joint density function as the product of individual density functions. And so e of x plus y, this should be x plus also see your are integrating x plus y integral minus infinity to infinity minus infinity to infinity x plus y into f x (x) into f y (y) d x d y. So, I have written the joint density function as the product of individual density function and so therefore, one can then separate out the integrals.
So, this would be x f x (x) f y (y) d x d y and here it will be y, now then since if you integrate respect to y, then integral f y of y d y will be 1, because this is a PDF of y; and so you will be left with x f x (x) d x minus infinity to infinity. And similarly, here integration respect to x will result in 1 and so you will get integral minus infinity to infinity y f y by d y and this is E x plus e y. But, I want to point out that it is not necessary to show that this result, you do not need independence of x and y actually it is always true.
And that you can immediately verify, because if x, y is the joint density PDF of x, y, joint PDF of x and y, then e of x plus y we write in this way, integral double integral minus infinity to infinity x plus y f x y, this is this of x, y. Then again I write this as sum of two integrals which is this and this, but we know making the same argument that minus infinity to infinity of f (x, y) x y d y will give you f x of the marginal density of x. And then so it will be come out to be integral x into marginal of x density function of x plus, similarly y you first integrate respect to x here to get the marginal of y and then you get this.
And therefore, this of E x plus E y, so for showing that E of x plus y is E x plus e y you do not need independence of x and y, but under independence we can show another result, which is that expectation of x y, product of x and y is actually product of the expectations. So, there is a E x into e y and this for this I will need independence, because now I will write E (x, y) as this double integration x, y and the joint can be written as the product of the marginal’s, so f x (x) into f y (y) d x d y.
And now here again I can separate out the integrals, so this is integral x of x d x minus infinity to infinity into minus infinity to infinity y f y d y; and now each of this, this is E x and this is E y, hence y gets these are the product. And this result now I will prove in while showing that the under independence variance of x plus y is equal to variance of x plus variance of y, which holds only when x and y are independent. So, therefore, once we have shown this result we can now derive that result.
(Refer Slide Time: 38:55)
 
To compute the variance of x plus y, we will require the result that I am giving right now, we will use independence of the variables x and y. So, let me just right down variance x plus y is expected value of x plus y minus E x minus E y whole square. So, I open up the square term, then this will be x minus E x whole square plus, this should not there plus y minus E y whole square plus twice x minus E x into y minus E y. Now, from linearity of the expectation function we have seen it earlier, that it expected function is a linear function.
So, it follows that the expected value of the whole expression I can take expectation inside and therefore, this will be expectation of x minus E x whole square plus expectation of y minus E y whole square plus twice expectation of x minus E x into y minus E y. Now, this is the place where I will use the linearity of x and y, because if x and y are the independence of x and y, if x and y are independent and x minus E x into y minus E y are also independent this being a constant.
So, it can immediately be concluded that, if x and y are independent and then x minus E x and y minus E y are also independent, therefore the expectation of the product can be is equal to the product of the expectations. And therefore, expectation of this product is equal to expectation of x minus E x into expectation of y minus E y and so now, here you see that this would be E x minus E x which is 0 into E y minus E y which is also 0, so with the whole thing is 0. And so this expression reduces to simply expectation of x minus E x whole square plus expectation of y minus E y whole square, which is equal to variance x plus variance y. So, when trying to compute the variance of sum of two variables, two random variables, then I need to be able to write it like this, I need x and y to be independent.
(Refer Slide Time: 41:09)
 
Now, let me show you what independence means to us and of course, interesting relationship between various PDF's that we have discussed or into special kinds of random variables. Now, if x is gamma s lambda that means, parameter s and lambda and y is with gamma with parameters t and lambda, so lambda is the same, but these two numbers differ, then x and y are independent. Then x plus y is gamma s plus t, lambda that means, the first parameters either second parameter is the same, then the first one get added up, when you add up the two random variables, at this I will show you using the m g f, because I missed out on the m g f.
So, m g f is also straight forward because this is expectation of e raise to t x plus y. So, then this way because I will write it as e into t x and into e into t y right this function I can write as this then again I just told you that. So, you might say that y are these independent that can also be shown that if 2 function are independent, then their functions are also independent. Of course, under certain condition, but e raise to t x and e raise to t y are also independent random variables, so when I write expectation of the product that will be the product of the expectations.
See this nothing much to you can actually use the again write the joint this thing, because joint density function will again with the product of individual PDF’s. So, even when you write this function here as an integral you will separate out the integrals and again just as you prove this result exactly you can show by this expectation is equal to the product of the expectations right. So, then; that means, if x and y are independent then there m g f of the sum is the product of the individual movement generating functions.
So, there is a important result and that is what I am going to use here, so I am showing you that we know that when x is gamma s lambda. It is movement generating function is given by lambda upon lambda minus t raises to s and the movement generating function of g t, lambda is lambda upon lambda minus t rise to t. And so the sum would be the product of the m g f ‘s, so the m g f of the sum is the product of the m g f ‘s and so this becomes lambda upon lambda minus t raise to s plus t.
So, now, I am concluding immediately that this; that means, they p d f of x plus y is gamma with parameters s plus t, lambda while defining m g f for you and looking at it is properties I had mentioned that m g f uniquely characterizes the p d f of the random variable, if you know the m g f of a random variable then can tell from what is the p d f of the random variable this can also be proved, but I will simply use the result here. 
And so therefore, once I know that the m g f of x plus y of this form then I will conclude that this; that means, the p d f of x plus y must be s plus t, lambda. And now let me this, I had already mentioned this relationship between the exponential and gamma I said that exponential lambda is gamma 1, lambda; that means, the first parameter is 1 and the this is the common thing. So, when you have a exponential random variable it is also gamma 1, lambda.
Now, if x and y are independent exponential lambda random variables both having the same parameter, then by this result x plus y will be gamma 2, lambda. So, I am using this result here that the first parameters get added up if the second parameter is the same, since the exponential x and y both are exponential with, so they are both gamma 1, lambda, so their sum will be gamma 2, lambda and so on right.
So, and now what I am trying to say here is that concept of independence of two variables can be extended to many more in the discrete case I already shown you that characterizing the independence of more than 2 variables becomes tedious, but we can anyway use the end results. So, here see the thing is that you can sequentially use this result you know about m g f’s about variance and expectations. So, what we saying is that if x 2 first of all you have 2 variables x 2 and x 1 are independent then once you have this then you can apply that x 3 is independent of x 1, x 2. So, then you can apply the result; that means, you can go on adding.
So, what I am trying to say here is that if you have two exponential random variables both with the same parameter I add them. So, I get a gamma to 2, lambda then add x 3 to it so; that means, I will be talking of x 1 plus x 2 plus x 3, so this will become 3, lambda. So, the concept can be recursively used, so here then you will say that x 4 is independent of these 3 and so on. So, finally, x 1 is independent of x 1 x 2 up to x n minus 1, so this is the whole idea.
So, therefore, now I can say that when you have gamma s, lambda where s is an integer. So, if you look at this result then s is a integer, so gamma s, lambda is the sum of s independent exponential lambda random variables. So, when s is an integer gamma distribution has been built up by adding exponential distributions as of them right and if you remember when I was talking of the gamma distribution and then we were looking at the, so we had said that suppose there is a service counter. 
And they are people I had a few who are n minus 1 you are the another person then gamma and lambda you can; that means, the time that you have to spend and we had said that if this time taken to service each customer is exponential with parameter lambda. Then the total time till the another person gets serviced; that means, this is this includes the servicing of n minus 1 people ahead of him and then the n the person is this person. So, when then total n people get serviced that will become gamma and lambda.
So, this was the connection and so we I had use this and I had told you that we will be able to show this prove this result also that the n exponential distributions with the same parameter lambda will add up to gamma distribution with parameters n, lambda. So, I will continue this exploration more in the coming lectures.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 14
Chi-square R.V. Sums of Independent Normal R.V. Conditional distr

(Refer Slide Time: 00:16)
 
So, after obtaining expression for E x plus y, in fact we showed that E f x plus y is E x plus E y and under independence of x and y, we showed that variance of x plus y is equal to variance of x plus variance of y. Then we can generalize these results for any finite number of random variables. So, therefore if you have x 1, x 2, x n as a n identically distributed random variables, discrete or continuous, then expectation of x 1 plus x 2 plus x 10 will be equal to expectation of x 1 plus exception of x 2 plus expectation of x n. So, want to show that say that this is you can always take the some of the expectation. Sorry, I mean expectation of the sum as sum of the expectations. So, first these have to be identically distributed.
Now, if the x size are also independent, then we can also extend this result at variance of x 1 plus x 2 plus x n is equal to variance of x 1 plus variance of x 2 plus variance of x n, because as we saw if the case 2 variables that the product term vanishes. So, here also because independence, the product term because you will have two products of two things at a time. That means of the kind you will have an expression like expectation of x i minus expectation of x i into x j minus expectation of x j. So, under independence this will go inside and therefore each of the term will vanish. So, you will only get, this square terms will be left. When you square up this minus the expectation of the sum and therefore, you will get the sum of the variances. So, under independence, you get that result. Now, formula for the variance of sum when the random variables are not independent will be discussed later.
So, we will give you a general formula when the variables are not independent. So, this is one thing and so, we can use it for computing various expectations. So, now let me discuss interesting result which is called Boole’s inequality, and let me first just describe what we want to say here. This is that if you have A 1, A 2, A n as n events and when corresponding to these n events, I define the corresponding indicator variable. That means, x i is 1. If a i occurs i varying from 1 to n and its 0 otherwise. So, therefore, then I will let x be the sum of these indicator variables, these n indicator variables. So, in other words, x denotes the number of the events a i that occur fine because x i is 1 if a i occurs. So, if x for example, if capital x is 5, then that means, 5 of a i’s have occurred. This will add up to 1 plus 1 for 5 events which have occurred, right and define another variable y which is equal to 1. If x is greater than or equal to 1 and 0, so otherwise means that you see if x is 1 or greater than 1, then y is 1, but if x is 0, then y will be 0.
So, from definition it follows that x equal to 0 implies y equal to 0. Since, your x is otherwise greater than or equal to 1. See either an event occurs or it does not occur. So, if anyone of the events occurs, then x will be at least 1 and if none of the events occur, then it will be 0. So, therefore, x is always greater than or equal to 1 or it is 0. I mean if 1 of the not always. What I mean is that if at least one event occurs, the next will be always greater than or equal to 1. Otherwise, if none of the events occur, then x will be 0 and in that case, y will also be 0.
So, therefore, it implies that x is greater than or equal to y, right because x will take value 1 or 2 or 3 your y is 1 and whenever x is 0, your y is 0. So, it is clear that x is always greater than or equal to y, and this implies that your expected value of x will also be greater than or equal to expected value of y because this being x minus y is non-negative. Therefore, expectation of x minus y. Now, I am just writing the general expression here. So, that means, for example a general expression for e x minus y would be minus infinity to infinity x minus y f x y x y d x d y. So, this integrant is non-negative and therefore, the integral will be non-negative. So, it follows that your E x must be greater than or equal to E y, ok. So, that is the important result. That is how through this, we will derive the Boole’s inequality finally. 
(Refer Slide Time: 05:17)
 
Now, look at E x. So, E x is expectation of i take it inside being linear function. So, I can exchange the expectation and summation sign. So, sigma i varying from 1 to n expected x i, but expected x i is what expected x i 1 into probability x i equal to 1 plus 0 into probability x i equal to 0. Since, x i take values only 1 and 0. So, this is 1 into probability x i is equal to 1 plus 0 into probability x i equal to 0. So, this is 0, and this probability x i equal to 1 is probability of occurrence of a i and therefore, this is 1 into P A i which is P A i, right. So, you are some of the expectations of x i is equal to sigma P A i.
Now, x i’s are, you can see that x i’s are Bernoulli random variables, right because x i’s take value 1 or 0 and the probability of success as you can call it is P A i for x i, right. Now, what is probability y? So, probability y is probability that at least one of the A i occurs. So, this is union A i varying 1 to n. So, this is at least one of the A i occurs. So, well which way would we are saying y is equal to 1 if x is greater than or equal to 1 and this translates to x is greater than or equal to 1 if at least one of the events A 1, A 2, A n occurs, right. So, this is probability union i varying from 1 to n A i. So, expectation E y will be 1 into because y is 1 if x is greater than or equal to 1. So, this is union i varying from 1 to n A i plus 0 into probability union A i complement, right. Probability of this complement of this event and therefore, this is also equal to E y is equal to simply probability of union A i varying from 1 to n.
Hence, we obtain Boole’s inequality which says that sigma i varying from 1 to n P A i is greater than or equal to probability union A i varying from 1 to n. So, in other words, it says that probability of occurrence of at least one event out of given n events. So, probability occurrence of at least one event is no greater than the probability or some of the probabilities of occurrence of individual events. So, this in other words is your Boole’s inequality which you might say is simple to accept, or this sounds very reasonable, but we had to go through this process to be able to derive this inequality, right. So, this says at least one of the events must occur. So, probability of that and that cannot be greater than some of the probabilities of the individual events, ok.
Now, let us further go on. I want to again continue with using whatever we have developed about adding up random variables and then, computing their expectations and other results through summing up random variables. So, now, look at the chi square and random variable. So, this random variable is defined as summation i varying from 1 to n z i square, where each z i is standard, normal i varying from 1 to n, right. Thus, the expectation of z i is 0, and the variance of z i is 1. So, each of the z i is standard, normal, then look at these. So, we want to compute first of all, we want to compute the c d f of z i square. So, this will be let me write, make it clear.
So, F z i square y will be probability z i square less than or equal to y, and in one of the earlier lectures, I have already discussed. So, what you are saying is that your z i square should be less than or equal to y, which means that your z i should be less than root y. So, it should lie between minus root y and root y, your z i, right, so that the square does not exceed y. So, this probability can be written as because you will be taking if this probability z i less than root y, then you want to subtract z i less than minus root y. So, this is the probability, right and therefore, when we differentiate this side, I will get the P d f of z i square, this is z i square which will be equal to (( )). So, from here we will differentiate. So, see derivate of a root y will be 1 by 2 root y in to f of z i root y minus f of z i minus root y and for standard normal c.
You see what is your this thing is standard normal 1 upon root 2 pi because sigma is 1 is equal to E raise to minus y square. So, it is root y. So, it will be root y square on 2 because sigma square is 1. So, therefore, when you square up the minus root and root y, they are both give you E raise to minus y by 2. So, this becomes, so this is twice E minus y by 2 and these two, so that cancels out. So, I am left with 1 upon root y 1 upon root y E raise to minus y by 2. Now, this I can rewrite because you have 1 upon root 2 and 1 upon root 2, I am writing as 1 upon 2 into 1 upon 2 raise to minus 1 by 2, right. I am doing this, so it is 1 by 2 is going, yeah.
So, 1 by 2 into 1 upon 2 minus 1 by 2, you write this way and this is left by root 2. Root 2 cancels out and you are left with 1 by root 2, right. So, this whole thing I am writing as 1 by 2, 1 by 2 y raise to minus 1 plus half root pi because this is 1 upon 2 raise to minus half. So, 1 upon 2 raise to minus half into 1 by 2, this whole thing is actually equal to 1 by root 2 which appears here 1 by. So, this 1 by root 2, I am writing in this way, right and now, you see if you can remember your gamma distribution, then my lambda is half and my alpha is half because this is alpha minus 1 and then, this is lambda y raise to alpha minus 1 e raise to minus lambda y and then, lambda. So, this is my gamma. Of course, when you look at the p d f gamma p d f, then it has to be divided by gamma alpha.
So, what I am doing is I am writing this as gamma p d f and then, multiplying by 1 by 2, gamma 1 by 2 because I have divided here this expression, this numerator I have divided and multiplied by gamma 1 by 2. So, when I divide this by gamma 1 by gamma of 1 by 2, the whole thing becomes gamma p d f with parameters half and half, and I have gamma 1 by 2 here and thus, a root pi. Now, since this is p d f on the left hand side, this should also be p d f and therefore, you see that these two must be equal. So, this implies that earlier lecture when we were talking, discussing the, when I introduced the gamma distribution m, I told you that it take that gamma of half is root pi, but now you have an immediate justification that gamma of half must be equal to root pi. And of course, as I said that for other fractional values of gamma f, this gamma function you can tables are there and for integer values we had already seen for positive integers. We also saw that gamma alpha will be alpha minus 1 factorial and so on. So, now we continue with this discussion. So, therefore, each z i square has a gamma half, half distribution, now gamma square n. Sorry, chi square n is z 1 square plus z 2 square plus z n square and z i’s are independent.
So, then applying the m g f results, we see that you can add up the p d f’s here. The parameters and you will again because each is gamma, each z i square is gamma distribution half and they are n of them, they are independent. So, therefore, the sum will be gamma and by two half. That means there will parameter lambda will be half and this will be n by 2. So, you see how I mean using all the results that we have. So, I thought this was good way to show you how we use these tools that we are generating and then, you can see the breakup of. So, once you have a gamma distribution, then you can see that by adding up these independent gamma distributions a h gamma random variables, you get a chi square n and of course, in a special way.
(Refer Slide Time: 15:12)
 
So, this is another interesting result. So, when you have seen that if n is an integer, then gamma n is simply n minus 1 factorial. So, if n is even, then your this thing will be factorial of n by 2 because n is even then this is an integer. So, gamma of n by 2 will be n by 2 minus 1 factorial, but if n is odd then you will be left with gamma half. So, for example, if you say n is 7, then gamma of 7 by 2 will be 5 by 2 into gamma 3 by 2, then 3 by 2. Sorry 7 by 2 gamma 7 by 2 is 5 by 2 gamma 5 by 2 which will be 3 by 2 gamma 3 by 2 and then, that will be half gamma half which is root pi here. So, this you can compute. So, therefore, now you know you can compute this for all values of alpha integer, non-integer you can find out, right.
So, this was an application of, therefore you see first you square up independent, normal, standard normal variants. Sum them up, you get a chi square distribution and you are showing is that for n, this is chi square with n degrees of freedom. So, then chi square n is actually obtained by adding up gamma half.
(Refer Slide Time: 16:34)
 
So, I should also mention the importance of chi square distribution. So, if you are talking of chi square n distribution and we said that the n stands for the number of standard normal variable that you are squaring and adding up. So, you can think of because you see this is x i minus mu i upon sigma i whole square. So, this would be your z i, alright and your z i square.
So, you are summing up and so this can be treated as this. This can be looked up on as you know to an attempt to estimate the errors involved and one attempt to hit a target in n dimensional space when coordinate errors are taken to be independent unit probable random variables, right. So, this is you know you can difference from the mean or whatever kind of error you want to, you know talk about and talk about their distribution and so on. Then, chi square random variables come in very handy in that and in fact, it is most widely used distribution in statistical analysis. So, chi square distribution has lot of importance and very often used for your statistical analysis. So, now let me get back to sums of independent normal variables and this is if x i’s are independent normal random variables, x i’s varying from 1 to n or independent normal variables with respective parameters mu y sigma i square, right. That means the x i th normal random variable mean is mu i, and the variance is sigma i square i varying from 1 to n, then sigma x i is again normally distributed with parameters sigma mu i, and that mean as sigma mu y and the variance as sum of the individual variances, because the random variables are independent. So, anyway that we know already that the variance for this would be sigma i square and we also know that the mean for sigma x i will be sigma mu i. These results we have already done, but to show that these sums will again be normally distributed, that is the important thing.
Now, here again I am going to see. The thing is that I have been using m g f’s moment generating functions to talk about summation of independent random variables, but it takes sometimes. They introduce the concept of moment generating function much later. So, they actually do it through you know writing the joint density function because these are independent random variables. So, the joint density function will be a product of the individuals and then, they manipulate that term and actually come to the result. So, maybe you should also do that to get to know better feeling, but I find that the treatment through m g f is very convenient. So, the m g f of x i is E raise to mu i t plus half sigma i square t square. This is for the normal mu i sigma i square and since, x i are independent i variant from 1 to n, m g f of sigma x i is the product of the individual x moment generating functions, right.
So, this we have done already. So, the moment generating function of sigma x i would be E raise to mu 1 t plus half sigma 1 square t square and then, E raise to mu t mu to t plus half sigma 2 square t square and so on up to n, and therefore you can add up because these are the powers. So, E raise to sigma i varying from 1 to n mu i t plus half sigma i varying from 1 to n sigma i square t square. So, this is again as I said that the uniqueness of that means given this m g f, I can immediately conclude that the corresponding distribution is normally distributed with mean sigma i varying from 1 to n mu i and this is variance sigma i vary from 1 to n sigma i square. So, using the m g f, you can get these results much quicker, otherwise you have to though the other root is also not difficult one. It is just that you have to write out these long expressions and then, show that this sum of independent normal random variables will be again a normal random variable and these will be the parameters.
(Refer Slide Time: 21:30)
 
So, to give you an example about how to make use of the fact that sum of independent normal random variables would also be normally distributed, let us look at this example. This football club team will play 44 game seasons. So, you know with during summer, they all play game. So, different teams, so there are 44 games that particular teams will be playing. So, 26 of these with will be with class A team and the remaining 18 games will be with class B teams. So, probability of winning A match against A team is 0.4 because A teams are better than B teams and probability of winning A match against the B team is 0.7. So, results of different games are independent. We are not assuming that there will be any sort of dependence in winning of a game with one team and the other. So, we want the ideas to approximate the probability that the team wins 25 games out of those 444 games played, and second probability that you have to compute is that the team wins more games against class A team’s than class B teams.
So, let us start by defining the random variable XA as the number of matches one against class A teams and XB is the number of matches won against class B teams, fine. Now, of course XA and XB are binomial random variables because win is the success and the probability of success is point 4. So, you can find out that out of 26 games played by this team with class A team, then the number of that means, if XA is equal to R, then you will find out it will be a binomial probability and similarly, XB is also a binomial random variable, right. Now, expectation of XA will be 26, right. The formula is NP. So, 26 games played and probability of winning match is 0.4. So, this is NP. So, that comes out to be 10.4 and the variance is NPQ, right which will be 26 into 0.4 into 0.6 is 6.24, then similarly XP being binomial with parameters 18 and 0.7.
So, the expectation of XB will be 12.6 and variance XB equal to NPQ which will be 3.78. Now, the idea is that we start approximating or remember when I told you about approximation of binomial distribution by the normal distribution. The condition was that I mean it is said that if NPQ is greater than or equal to 10, then the approximation is considered good, but here of course that condition is not being satisfied because NPQ in these cases 6.24 and this case, it is 3.78. But still we are going ahead with the approximation just to get an idea because I want to show you the application of adding up normal, where required probability is that XA plus XB together that number of matches one against class A teams, and the number of matches one against class B teams, they must add up to more than 25 or more than 25.
Now, even though I may approximate XN XP by normal, but they are discrete random variables. They are binomial. So, the continuity correction factor must be used here. So, this will be since this is greater than or equal to 25, this will be 24.5 because remember you have this on 25. So, your bar is like this. So, the bar starts from 24.5 and you want to approximate this. You want to include this area because the probability here is greater than or equal to 25. So, it will be 24.5. So, probability XA plus XB is greater than or equal to 24.5.
(Refer Slide Time: 25:50)
 
Now, I standardize this probability by subtracting the mean, which has 23. 12.6 and 10.4 adds up to 23 and the two variances add up to 3.7 and 6.24 is 10.02. So, this is what you have. This becomes standard normal variant and therefore, this probability z greater than 1.5 divided by square root of 10.02. So, this will be 1 minus pi of this number comes out to be 0.4739. So, the required probability is 1 minus the normal table, the standard normal probability of this number. So, this is 0.3178.
Now, XA minus XB is also approximately normal minus 2.2 and 10.302 as the variance, right. Therefore, probability XA minus XB greater or equal to 1 because you want the probability that matches against class A team’s matches one against class A team’s is more than the matches one against class B team. So, therefore, the difference must be greater than or equal to 1 can be more and so, here again we standardize. So, this is XA minus XB minus 2.2 which comes plus and this is under root 10.02 which is greater than or equal to 5.5.
So, here again these term continuity correction factor is used. See a subtract 0.5 from here, so that becomes 0.5 plus 2.2 up on this under root of 10.02. So, that is Z greater than or equal to 2.7 up on under root of 10.02 which comes out to be this. From tables you look up the value which is 0.1 minus of that will be 0.1968. So, this is the probability. So, in fact the probability is low of winning more matches because obviously, this probability is much lower compared to the probability of winning a match against B team. So, as we go on more and more examples of all these concepts that we are talking about. Now, let us come back to sums of independent Poisson random variables. So, X is Poisson lambda 1, Y is Poisson lambda 2 when and X and Y are given to be independent random variables.
So, let us look at the distribution of X plus Y. So, now, since X and Y are independent, m g f of X plus Y will be the product of the m g f’s of X and Y. So, m g f of a Poisson lambda 1 is E raise to lambda 1 into E raise to t minus 1 and m g f for Y is E raise to lambda 2 E raise to t minus 1. So, therefore, this adds up to E raise to lambda 1 plus lambda 2 E raise to t minus 1 and this is Poisson lambda 1 plus lambda 2. So, therefore, you immediately get the result and as I told you earlier that you might try to do it directly, right. That means, you may obtain the cumulative density function for X plus Y, distribution function for X plus Y and then from there you can compute.
(Refer Slide Time: 29:11)
 
So, having learnt the trick to use m g f for finding out distributions of sums of random variables, I will still write it down for binomial and Poisson and so on. I think Poisson we have already done. Now, let us look at the sum of independent binomial random variables. So, here again the x is binomial n, p and y is binomial m, p, then we want to look at the sum and x and y are independent. So, then again m g f of x plus y will be the product of the individual m g f’s. So, here it is p e raise to t plus 1 minus p raise to n, and for the random variable y, the m g f is p into e raise to t plus 1 minus p raise to m. 
So, when you multiply, the powers get added up. So, this is p e raise to t plus 1 minus p m plus n and therefore, it immediately follows that x plus y is binomial and plus m, p. So, if the probability of success is the same, then if you are looking at two random variables in one case, the number of trials is n. In the other case, the number of trials is m, then the sum will again represent the binomial random variable, either number of trials gets added up. So, probability of success remains the same. So, now, I have seen this thing for sum of these distributions. So, whenever you come across something new, you can read it up and understand.
What is going on? Now, let us look at the conditional distributions also. We have looked at conditional probabilities and we have looked at base conditional probability and so on. So, now, let us look at conditional distributions. So, remember that when E and F for two events, then we define the conditional probability of event E given that event F has occurred and this was defined as probability of E intersection F. That means, both the events must occur divided by the probability of occurrence of F. So, these were the events. Now, when you come to x and y are two discrete random variables, and you want to write down the conditional probability of x given y, where capital Y is let us say small y and x, small x. See if you want to compute this, then it will be again just borrowing it from here. It will be probability x equal to x y equal to small y divided by probability y equal to y which you can write in your notation as p x, y upon probability y equal to small y.
Now, sometimes I may write this suffix, sometimes I may not. So, it does not matter, but you understand from the context that this is for a single variable and this is for a joint p m f, right. So, this is for all y. That means, this conditional probability is defined for all y, such that probability y is greater than 0. I am dividing by number, which I must ensure is positive which is non-zero and since probabilities cannot be negative, so the number must be positive. So, for all possible values of y for which there is a positive probability, I define it this way, right, so conditional p m f of x given this. 
Therefore, this defines the conditional p m f of x, given that y is equal to y. Now, conditional cumulative distribution function of x given y is equal to y would be you know f x given y. So, that will be probability x less than or equal to small x, given that y is equal to y which is then probability x equal to a, given that y is equal to y and you are summing up over all a for which is less than or equal to x. So, therefore, the conditional notation is the conditional probability of a given y, where a is less. So, you are summing up over all a less than or equal to x.
(Refer Slide Time: 33:28)
 
Now, if x is independent of y, then we know that this probability, the conditional probability will be written as because here this will be the product of 2 and divided by probability y equal to y. So, therefore, it will reduce to probability of x equal to x. So, therefore, we are just trying to show you that whatever we did for the events, the same thing goes over for the random variables and there corresponding distributions. Now, just look at this example. If you given that probability of 0, 0 is 0.3. That means, x taking the value 0, y taking the value 0.
So, therefore, your x takes the value 0 1 and your y takes the value 0 1. So, therefore, the four probabilities p of 0 1 is 0.3, p of 1 0 is 0.2 and p of 1 1 is 0.2. They all must add up to 1. So, you want to calculate the conditional p m f of x, given that y is equal to 1. So, first of all you need probability of y equal to 1, right in the denominator. So, therefore, this is equal to p of 0 1 plus p of 1 1, right. That gives you the marginal of y which is a probability of y equal to 1. So, that is 0.5 and hence, probable conditional probability of x given y equal to 1. So, if you want to find out, then you see the possible value of x has 0 and 1. So, you will find out both the probabilities, a conditional 0 given 1 y equal to 1. So, that will be 0 1 divided by y equal to 1, probability of y equal to 1.
So, 0 1 from here is 0.3 divided by 0.5 and that is equal to 3 by 5. Similarly, probability x equal to 1 when y is given to be 1, so that will be p of probability 1, 1 divided by probability y equal to 1. So, it will be 0.2 divided by 0.5 and so this is 2 by 5. So, similarly you can compute the p m f well, ok.
(Refer Slide Time: 35:42)
 
So, this conditional, you can fix a value of x and then, compute the conditional p m f of y. Yes. Now, this is another interesting example. This says that if x and y are independent Poisson random variables with respective parameters lambda 1 and lambda 2, calculate the conditional distribution of x given that x plus y is n. So, now, the condition is on the sum x plus y equal to n and you want to find out the conditional distribution of x. So, first let us compute probability x plus y, and as I just showed you just a few minutes ago that if x and y both are independent Poisson random variables, their sum will be also Poisson and the parameters will get added up.
So, this is e raise to minus half lambda 1 plus lambda 2 lambda 1 plus lambda 2 raise to n divided by n factorial. So, this is easy because we have already of course, seen the distribution for x plus y then yeah you now want to compute the probability for example, x equal to k when x plus y is n. So, for finding the conditional probability of x given that x plus y is n. So, now, if x is k, then this says that your y must be n minus k, right. See I mean here you will be writing probability, yeah. So, x equal to k and x plus y equal to n that will be product and then, divide it by probability x plus y equal to n. So, intersection of x equal to k and x plus y equal to n is equivalent to the event that x is k and y is n minus k divided by probability x plus y equal to n, and since again x and y are independent, this probability I can write as the product of individual probabilities. So, this will be a probability x equal to k into probability y equal to n minus k divided by probability of x plus y equal to n, and this both being x and y, both being Poisson, this is e raise to minus lambda 1 raise to k divided by k factorial. Then, the other probabilities e raise to minus lambda 2 raise to n minus k divided by n minus k factorial. This may not look very, let me rewrite n minus k factorial, but it is there and then, e raise to lambda 1 plus lambda 2 probability of x plus y equal to n which we wrote down here.
So, this is lambda 1 plus lambda 2 raise 1. Then, there should have been e raise to, yeah lambda 1 plus minus e raise to lambda 1 plus lambda 2 and n factorial goes to the numerator. So, therefore, collect these terms n factorial divided by k factorial and n minus k factorial that comes here, right and then, you see here this is lambda 1 plus lambda 2 raise to n and you have lambda 1 raise to k and lambda 2 raise to n minus k. So, I break up into lambda 1 plus lambda 2 raise to k into lambda 1 plus lambda 2 raise to n minus k. So, then I get that terms lambda 1 upon lambda 1 plus lambda 2 raise to k, and lambda 2 upon lambda 1 plus lambda 2 raise to n minus k and you see these two numbers. That means, lambda 1 upon lambda 1 plus lambda 2 plus lambda 2 upon lambda 1 plus lambda 2. This adds up to 1. So, if I denote this by p and this number is 1 minus p, right.
So, in that case, then this looks like that means a conditional probability x equal to k, given that x plus y is n is binomial. So, therefore, different values of k you will get these probabilities which are exactly the binomial probabilities for the parameters n, and your probability of success is lambda 1 upon lambda 1 plus lambda 2. So, I think through this course I have been trying to show you that even though you have these different random variables, you how you can get through process of addition, conditional , and so on. You can see the connections between the various distributions here. And therefore, you know that makes those things more interesting and of course very useful also.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 15
Conditional Disti Joint Distr of Functions of R. V. Order Statistics

(Refer Slide Time: 00:15)
 
So, let me now talk about the conditional distribution when the random variables are continuous. So, in that case, it will be probability density function x given y. So, the notation will be this. So, you will write it as the joint of f x y at x, y divided by the marginal of y at small y, right. And see the way to explain this is because since we know that the continuous case, the probability at a fixed point is 0.
So, therefore the way to look at it is you know if I multiply both sides by d x and then multiply and divide by here, then you see this represents, this will be the conditional probability of x given that capital wise Y and X is between x comma x plus d x and here on the right hand side you can it will be you can interpret f x comma y d x d y as probability x less than or equal to x plus d x comma y less than or equal to y. That means capital Y between y and y plus d y, you can look at this way, d y d x are small divided by, so this will be probability capital Y between small y and y plus d y.
So, therefore you can say that this ratio represents the conditional probability of x lying between small x and x plus d x, when you are given that capital y is between y and y plus d y. So, this is what I have expressed here that capital X will belong to x, x plus d x given that y belongs to y comma y plus d y.
Now, let us just look at an example. So, suppose this is a joint density function x lying between 0 and 1, y is between 0 and 1 and you can verify that this is joint p d f. That means, double integral of this expression should be equal to 1 when your x and y are between 0 and 1, but to find out the conditional. So, if I wanted to write down the conditional p d f of x given y and I need to compute the marginal of y which I hope the arithmetic is, so this will be when you integrate right 3 x into 3 minus x minus 2 y. This will be the expression between 0 and 1. So, this will be 9 by 2 minus 1 minus 3 y minus 3.
Yeah. So, remember that because y, capital Y is fixed at small y, yes. So, this is the marginal, yeah this is the marginal y. So, obviously it will be a function of y only, but I had something else in mind which I will tell you right now. So, now, if you want to find out the conditional of x given y, then that by definition is this ratio f x, y divided by f y of a small y and this will be because I have computed f y y for you. So, this is the ratio and therefore, this comes out to be this. So, that means, for a fixed x and y, this will be the conditional p d f of x given y as. So, here your x will vary between 0 and 1. Now, if you have to find out this probability x greater than half given that capital Y is equal to y. 
(Refer Slide Time: 04:14)
 
So, this will be the integration half to 1 of this conditional p d f, where y is being treated as constant, right. So, you integrate respect to x and here again, this is arithmetic 3 x square by 2 minus x cube by 3 minus x square y because a 2 cancel from half to 1 and then, this is the denominator which I do not have to do anything. So, I do the computations here. Please verify the arithmetic thing should be add up. So, the final expression is this which will be the function of y because here you are given a value to x, all values of x greater than or equal to half. 
So, therefore, this conditional probability x greater than or equal to greater than half or does not matter for a continuous case, it does not matter given that y is y. It turns out to be this expression. So, once we have this and I think for the continuous case for the discrete case also, we wrote down the distributed cumulative distribution function or cumulative, these things and then, you can write down the probability conditional probability mass function also exactly in the same way. So, therefore, this is nothing new. Maybe I did not actually write down the expression, but that does not matter.
(Refer Slide Time: 05:44)
 
So, let me now begin the topic Joint Probability Distributions of Function of Random Variables. So, just before this I talked about joint distribution of random variables. Now, let us take the joint distribution probability distribution of function of random variables because this also we need often to compute certain probabilities and so on.
So, now x 1 and x 2 are jointly distributed continuous random variables with x 1 and x 2 is there joint p d f. So, then suppose y 1 is a function of x 1 and x 2 and y 2 is a function of x 1 and x 2. So, g 1 represents a function of x 1 and x 2 which is represented by y 1 and g 2 is a function which represents y 2, where g 1 and g 2 have to satisfy certain conditions and this is what we were saying that if you look at these two equations, then they must be unique solution. In fact, if they are more than 1 or you should be able to fix the values of y 1 and the values of x 1 and x 2, that you will take corresponding to values of y 1 and y 2. So, in other words, what you are saying that we should have the solutions in a deterministic way. We should be known liquidity about it. So, x 1 should be h 1 of y 1, y 2 and x 2 is h 2 or y 1, y 2.
So, I can solve this set of equations to get the values of x 1 and x 2 for given values of y 1 and y 2 and then, this second condition is that this Jacobian as we call it, they should be set of partial derivatives which are continuous. So, the first order partial derivatives I have not written here or maybe that also has to mentioned first order partial derivatives of g 1 and g 2 are continuous. So, therefore, they exist and continuous.
So, first order partial derivative exist are continuous. Then, we define this determinant which is delta g 1 by delta x 1, delta g 2 by delta x 1, then delta g 1 by delta x 2 and delta g 2 delta x 2. So, the notation is sometime some people also use a notation. This will be y 1 y 2 upon x 1 x 2 and so on, because whatever you have in a denominator, there would not to other notation for the Jacobian also, and this should not be a 0 for all x 1 x 2 in the valid region. So, this should be a non singular matrix and therefore, its determinant is not 0. Now, this quantity we called a Jacobian determinant here and then, the transformation is that means, when you wanted to find out the p d f of y 1 y 2 respect to p d f of y 1 y 2, then that can be obtained in terms of the p d f of x 1 and x 2 as this f x 1 x 2.
Now, here of course you will substitute for x 1 in terms of because you are able to solve x 1 and x 2 in terms of y 1 y 2. So, you can substitute that here this will be the absolute value. These two lines indicate an inverse of the Jacobian. So, you have this matrix, compute this determinant and then, take in inverse and the absolute value, ok.
Now, I will try to give you feeling about see what this says is that the fact that this is none. You can see that if it was 0 p d f of f y 1 y 2 at small y 1 y 2 is defined, since the division by 0 is not permissible, but otherwise there is no point in talking of such transformations, where the Jacobian is 0 and there are. So, many ways you can interpret this concept of Jacobian, but I will just try to show you now one aspect here, and that says that absolute value of the Jacobian determinant at a point p gives us the factor by which the function expands or swings the area and bracket volume if you’re talking in three-dimension near the point p.
So, it will swing if the absolute value of Jacobian is Jacobian determinant is less than 1 and it will expand if the determinant of the Jacobian is greater than 1 and near the point p. So, if you are the coordinates that we are considering are x 1 x 2 and y 1 y 2 in the transformed plane, then near the point p in the transform space. So, the area in the x y plane in the x 1 x 2 plane will get transformed to the area element of around the point p. That means we are talking in terms of element of area around p in y 1 y 2 plane by the value determinant of the Jacobian.
(Refer Slide Time: 11:00)
 
Let us consider this example. So, x 1 and x 2 are jointly distributed random variables with f x 1 x 2 as their p d f and let y 1 be equal to x 1 plus x 2 and y 2 is x 1 minus x 2. So, we defined two new random variables as function of x 1 and x 2. So, this implies that your x 1 is half y 1 plus y 2 and x 2 is half y 1 minus y 2. So, Jacobian if you want to compute, then it will be the derivative of this with respect to, so here when you differentiate respect to y 1, this will be 1 and differentiate respect to. That means, differentiating x 1 with respect to y 1 and y 2. So, this is 1 and 1, then you differentiate x 2 with respect to y 1 and y 2, it will be 1 and minus 1. So, the value of this determinant is minus 2 and if you take the absolute value, it will be 2 and the inverse value of the inverse of the Jacobian determinant of the Jacobian and with absolute value will 1 by 2.
So, according to this formula, our p d f for y 1 y 2 would be equal to half f of x 1 x 2. The p d f for x 1 x 2 when you substitute for x small x and small x 2 in terms of y 1 and y 2, so this is y 1 plus y 2 by 2 and this is y 1 minus y 2 by 2, right. So, what I am trying to say which I said few minutes ago is that you know you can treat if you have to take a small element of area which is d x 1, sorry d y 1 d y 2. Here in y 1 y 2 plane, this is d y. So, element of area we treat this density as the probability density over d y 1 and d y 2 and here, if you look at this part, this will be the probability density over the element of area d x 1 and d x 2. And in this case of course since we are taking very small element of area, I can treat I can say that this is half times.
The density is the relationship between the two densities. I am just trying to give you feeling about this anyway and then, you can see here if you take the particular case that x 1 and x 2 are uniform 0 1, both are distributed uniform and both are random variables, uniform random variables over 0 1. Then, you see your transformation and if I am taking y 1 as x 1 plus x 2 and x y 2 x 1 minus x 2, then you see here this p d f of y 1 and y 2 by that formula would be half into 1 because the uniform that I am treating as independent. So, I am taking 1 into 1, right. The pdf of` both the f x 1 and x 2 would be simply product of f x 1 into f x 2. So, both being uniform, this is 1. So, this is the formula you get and the range is y 1 plus y 2 varies from 0 to 2. So, you can get individual ranges which I have drawn here. So, the area when you consider x 1 x 2 variable, this is the area, right and this equals 1 the area, right.
Now, this gets transformed to this kind of region in y 1 y 2 planes, right. If you draw this y 1 plus y 2 equal to 0 and y 1 plus y 2 equal to 2, which are these 2 lines and y 1 minus y 2 equal to 0 is this and y 1 minus y 2 equal to 2 is this line. So, it is this area which you get. So, a gets transformed to b and you see the area here is 2 units, this is 1 unit and 2 units and this is what I want to explain that since Jacobian is a constant, therefore you see this probability density is same over the whole area and that is the feeling I want to give you. So, the relationship between the two areas here because now that the Jacobian is a constant. So, therefore, the area a, which is 1 unit goes over to area 2 in the y 1 y 2 plane. In other words, you can also say that because this density and into 1.
So, when you integrate over the whole of b, this whole thing we should add up to should integrate to 1, alright which is half area b which is 1. So, area b is 2 and when you equate the 2 p d f’s for example, do this and integrate. So, see this area if you just do this, this is 1, right and this area this area also has to be 1 where I am in the integral. So, I am trying to say that this integral and this integral both, this has to be 1 and this must be 1, but this is related this half. So, therefore, this will be twice this. So, therefore, the density will turn out to be half. So, therefore, this density will be half of this because this much add up to this integration must integrate to 1, this integrate to 1. If you just took the x 1 and x 2 variables and these values half, so this is equal to twice this. So, therefore, the density for this one becomes half the density for x 1 and x 2. This is my own interpretation and I am trying to give you.
(Refer Slide Time: 16:40)
 
Now, consider when x 1 and x 2 are independent exponential random variables with respective parameter lambda 1 lambda 2, right and their wait I am treating, again I am treating them as independent. So, therefore, with a same transformation that y 1 is x 1 plus x 2 and y 2 is x 1 minus x 2, then the p d f of y 1 y 2 by that formula would be because Jacobian is again inject inverse of the Jacobian is half and the determinant and this will be lambda 1 lambda 2 product of the 2 pdf’s for x 1 and x 2 with x 1 replaced by y 1 plus y 2 by 2 and x 2 replaced by y 1 minus y 2 by 2, and the limits here would be because x 1 goes from 0 to infinity, x 2 goes from 0 to infinity. So, this will be this since they both are no negatives. So, this is it.
So, now, you can compute the individual limits for y 1 and y 2. Now, finally, if x 1 and x 2 are independent standard normal random variables, then you see this will be your joint would be because you are independent. So, your joint anyway it will be 1 upon, what it is? Root 2 pi e raise to minus 1 by 2 and their standard normal. So, simply x 1 square is for this thing and 1 upon root 2 pi e raise to minus 1 by 2 x 2 square. Now, sigma square is 1 mean is zero. So, these are two individual p d f. So, you multiply them. So, that becomes 1 by a 4 pi 1 by 4 pi into 0 root 2 pi root 2 pi. So, the half the Jacobian is half and this product is 2 pi. So, 1 upon 2 pi into 2, this becomes 1 by 4 pi and then, this is e raise to minus half y 1 plus y 2 plus whole square by 4 y a because your x 1 is x 1. I am writing as 1 by 2. So, this should be [FL]. So, 1 by 2 and then, y 1 by y 2 4 whole square and then similarly, minus 1 by 2 x 2 square x 2 is y 1 minus y 2 by 2.
So, the square gives me y minus y 2 whole square by 4, right and the variance of y 1 plus y 2 is 2 variance of y 1 minus y 2 is 2, right because again y 1 and y 2 are independent. I have computed this for you, fine. We will come to this conclusion later on. Let me continue with this. So, now what I have done is I have written this expression y 1 plus y 2 whole square by 4 plus y 1 minus y 2 whole square by 4. See the coefficient here the half I have left out just these two terms. So, then they add up 2 because the product term here will be 2 y 1 y 2 plus 2 y 1 and y 2. Here, it will be minus 2 y 1 y 2 divided by 4. So, that cancels out and you get twice y 1 square plus twice y 2 square. So, therefore, 2 upon 4, that gives you half y 1 square plus y 2 square. So, this whole thing reduces to e raise to minus 2, then y 1 square plus y 2 square by 2, right and then, I can again write 1 by 4 pi as 1 upon on the root 4 pi into 1 upon on the root 4 pi.
So, now I am saying that this is 1 upon root 4 pi into e raise to minus 1 by 2 y 1 square by 2 into 1 upon 4 root 4 pi e raise to minus 1 by 2 y 2 square by 2. So, you see the p d f here separates out into two single variable pdf’s. So, I will conclude that y 1 and y 2 are independent and you see that. Therefore, the variance y 1 plus y 2 actually I can also compute the variance of y 1, right. So, variance of y 1 plus y 2 is 2. Why I am saying that variance of y 1 plus y 2, where am I concluding from here? No no no no, this is a wrong statement. That is why I am saying that this is not right. Yeah this is because x 1 and x 2 are independent. Therefore, I should have written variance x 1 plus x 2 is 2. Variance of x 1 is 1, variance of x 2 is 1 and these are independent. So, this is this. Similarly, variance of x 1 minus x 2 is also 2, right.
(Refer Slide Time: 21:55)
 
So, therefore, y 1 when you are looking at, so y 1 is what y 1 is. Y 1 is here. Where did I define it? Yeah, y 1 is x 1 plus x 2 and y 2 is x 1 minus x 2. So, therefore, y 1 and we have all also seen that the sum of random variables is again normal. So, here the mean is 0, variance is 2. So, y 1 is normal and y 2 is normal and therefore, this is accordance with because if y 1 is normal 0 2, then you are dividing by the variance square. So, y 1 square by sigma square is 2 sigma square.
So, this is y 1 square upon 2 sigma square 1 upon root 2 pi into root 2 because standard deviation will be root 2. So, that becomes 1 upon root 4 pi. So, this is all in accordance with this and therefore, you can say that a y 1 and y 2 are also independent normal variables and this happens only because you see that is why I took three examples for the same case. I first took x 1 and x 2 to be jointly uniform and then, we wrote down the p d f of y 1 and y 2. So, what that come out to be simply this, right which you cannot say it is constant in this area. That is all.
So, from here it probably will follow that this is a uniform. You think about it, but when you took the distributions for x 1 x 2 to be exponential, what you did not get is any separation here. So, therefore, here you cannot conclude that y 1 and y 2 are independent, but when you took the x 1 and x 2 to be standard normal independent random variables, then it turns out that x 1 plus x 2 and x 1 minus x 2 are also independent and normally distributed. So, this happens for a normal distribution for when x 1 and x 2 are normally distributed independent random variables. Then, these functions will also be normally distributed and they will be I mean for x 1 plus x 2 and x 1 minus x 2. I am not claiming that this will happen for any functions of normal random variables, but in case when the functions are x 1 plus x 2 and x 1 minus x 2, then they turn out to be independent. They will be normal. Yes, that of course we know from the property of normal distribution. Already we have seen it. So, this is the case.
(Refer Slide Time: 24:41)
 
Let me continue with another example of a function of random variables. So, here x 1 and x 2 are independent random variables, each exponentially distributed with parameter lambda. So, now, with the question asked is, all the random variables u equal to x 1 plus x 2 and v equal to x 1 upon x 2 independent. So, therefore, we will find the joint density function of u, v and see if it can be separated out into a function of u and a function of v. So, like the Jacobian or the Jacobian is here, this is 1, the partial derivative or v is the partial derivative of 1 upon x 2 and minus x 1 upon x 2 square. So, therefore, the determinant is equal to this which can be written like this, right.
Now, compute to the inverse functions. So, here for the second equation, you see that x 1 is v x 2. Therefore, this now we substitute in this equation. So, for x 1, that will be if you write it down that is why I am doing here. So, if you write it for x 1 plus x 2 and x 1 is u into x 2, we just said that x 1 is v x 2. So, v x 2 if you write out here you do that and therefore, when you write x 1 as v x 2, so v x 2 plus x 2. So, x 2 outside 1 plus v, your x 2 becomes u upon 1 plus v. Then, from here you get x 1 is u v upon 1 plus v and if you write x 1 plus x 2, that comes out to be u. Well, that is already given to us. It is simply a verification, fine.
So, then you will sub that is the formula gives you the joint pdf of f u v which is Cobain inverse. So, x 2 square upon x 1 plus x 2 absolute value of this which is equal to this and then, because x 1 and x 2 are independents, so the joint p d f is a product. So, for each, the p d f is lambda into e raise to minus lambda u lambda x x lambda x 1 and then, lambda. So, here it will be lambda times x 1 plus x 2 which we have which are given to be as u. So, this is your p d f for and of course, you will substitute for x 1 and x 2 in terms of u and v. So, you can immediately see that x 2 square is u square upon 1 plus v square and then, x 1 plus x 2 is u. So, therefore, your final function is u upon 1 plus v whole square lambda square e raise to minus lambda u.
Now, I was trying to see we draw the picture, but again see the reason for a x 1 x 2 is a whole of first quadrant, and it looks like that for u and v also because u and v are also both no negative and both are extending to infinity. So, it appears that here since the regions are infinite, therefore, I cannot show you any swanking or anything and in any case, this is dependent on the point. So, this Jacobian is not a constant here. So, it will be dependent on coordinate values x 1 x 2 and so on.
So, therefore, I cannot do much here, but you see now this and of course, your limits for u are from 0 to infinity and for v from 0 to infinity and now, you can write this down as a product of two functions. So, lambda square e raise to lambda u into u is 1 and 1 upon 1 plus v square is the other function. So, since I have and remember I gave you this proposition in the earlier lecture that if there is a p d f which can be written out separately as a function of single variables, then each of them must be p d f themselves for the corresponding random variables.
So, now I want you to verify y that the two functions represent the p d f. That means, this is a p d f from 0 to infinity show that this integral is 1. Similarly, this integral from 0 to infinity is 1, right which you can do by heat iterative integration here and they both are no negative. So, therefore, we will conclude which I did not write here that u and v are independent. So, I will now talk about exercises 5 which is you know collection of problems from whatever we have been discussing in 3 to 4 lectures.
(Refer Slide Time: 29:39)
 
Let see again as usual I will try to give you some small hints and you should be able to work out the problems. In question 1, 3 balls are chosen without replacement from an urn consisting of 3 white and 8 red balls. So, X i equals 1 if ith balls selected is white. So, you know you have first, second and third balls which are chosen without replacement. So, if the ith ball is white, then you put X i equal to 1 and 0 otherwise. So, give the joint probability match function X 1 X 2. So, again you will make that chart we have shown you, right. You know rows will be before x 1 and columns will be before x 2 and then, you can write out for different values and then, I want you to write the joint probability match function of x 1, x 2 and x 3.
So, now in this case, you will have to simply write three values because it will be x 1, x 2 and x 3, all of them right. So, three-dimensional I have been discussing with you, two-dimensional so far. So, I thought let me include this and let see how you try this problem. Question 2: The joint probability density function of x and y is given by this function e raise to minus x plus y x and y between 0 and infinity, then find probability x less than y. So, now, this is a event. That means the region. So, you will draw the line.
(Refer Slide Time: 31:07)
 
So, here it is simple. This is this. So, the whole of first quadrant is a valid region. Now, you want to find the probability. So, it will be under this region X is other way. This is X less than Y. sorry. So, it will be this region, right. So, therefore, fix your limits accordingly and you will be able to immediately write down the limits from here because X has to be less than Y. So, therefore, X cannot vary from beyond Y. So, it will be 0 to Y and then, Y of course varies from 0 to infinity and then, a probability X less than a. So, in the b you will have to find the marginal of X first and then, compute this probability.
(Refer Slide Time: 31:51)
 
Yeah, this is problem 3. Now, problem 3 says you are given the joint density function of X and Y, which is f x y 2 if 0 is less than x less than y, y is between 0 and 1 0, otherwise x and y are independent. So, now, as I told you since the limits of x are dependent on y, my immediate reaction would be that now they are not independent, but you will have to find out the marginal, so that the joint is not the product of the marginal’s. If x and y are given by this, a new function which is f x y equal to x into e raise to minus x plus y 0 then and if now the limits for x and y are independent of each other. So, in this case, again you can break up your joint p d f into x into e raise to minus x into e raise to minus y. So, therefore, they should turn out to be independent, yeah.
Next question 4 says that two dice are rolled. Let X and Y denote respectively the largest and the smallest values obtained. Compute the conditional mass function of Y, given X is i for varying from 1 to 2….6. So, let me use fixed value of i of X and then, say are X and Y independent. Why all these two answers? So, you are quite familiar with now rolling of two dice and how you write down the probabilities. So, therefore, you should be able to answer question 4.
Question 5: The joint probability mass function of x and y is given by. So, this is now discrete set of random variables and you are given the probabilities here. Compute the mass function of X given Y is i varying from 1 to 2. So, there will be two conditional mass functions. One for when y is equal to 1 and other is y equal to 2.
Are x and y independent? Apply the condition for independence and compute x y less than or equal to 3, probability x plus y greater than 2 and probability x upon y greater than 1. So, here you see the values of y are not 0, anywhere y takes the values 1 and 2 and x takes the values 1 and 2. So, all questions are valid and you should be able to answer them.
(Refer Slide Time: 34:19)
 
Six is again you are given a joint density function of X and Y and here you see it why varies between minus and x and minus x and x. Draw a region, find the addition distribution of y given that x is equal to x. So, I have just included all these things. They are different from each other, but then you get an idea when you solve these problems. X and Y have joint density function given by 1 upon x square y square. X and y are greater than or equal to 1. Compute the joint density function of U equal to XY and V equal to X by Y. It should be what the marginal densities are.
So, anyway joint these things, density function you will compute by using the Jacobian method, right and then try to draw the regions because for X greater than 1 and Y greater than 1, it is simply these things. When you see this is 1 and this is 1. So, in the original thing, this is the region, alright and here, of course I can give you a hint because when U is equal to XY, so you will have to write X in terms of U and V in terms of Y and then, you see that the V region, how the region is transformed. So, do it because I have given you an idea already and you have to then compute the marginal densities of U and V, ok.
(Refer Slide Time: 35:56)
 
So, eighth question. Eight is once should have been suffix, but does not matter. Let X 1 to X n be independent exponential random variables having a common parameter lambda through all of them comes in. That means, they are observed value from exponential distribution with parameter lambda determinant, the distribution of minimum X 1 X 2 and X n. So, this is what I have already discussed with you, right finding out the p d f of x bracket 1. That means the smallest to the n sample values.
If X and Y are independent binomial random variables with ith, so we just make the correction with identical particulars n and p. So, X and Y are the same binomial distribution. I mean the same binomial distribution show analytically that the conditional distribution of X, given that X plus Y is m is the hyper geometric distribution. There should be have been a full stop is the hyper geometric distribution also gives a second argument that gilds a result without any computations in the ninth problem. You are given to a binomial independent binomial random variables with identical parameters n and p. So, you have to find the conditional distribution of X, given that X plus Y is m and you to show that this is a hyper geometric distribution and this again added this problem because I have already shown you a similar one. I solved the similar problem in the lecture and also, gave a second argument that gilds a result without any computations.
So, the hint is given here and you can argue that is given a total of m heads is the number of heads in the first n flips has the same distribution as a number of white balls selected. So, you figure out the hint and then, see if it is useful, ok.
(Refer Slide Time: 37:43)
 
Now, the tenth problem is random variables X and Y are said to have bivariate normal distribution if the joint density is given by this. So, here I have not discussed in the lecture, but I thought you should be able to work on this. So, bivariate normal random variable distribution is of this form, where you have this squared term with respect to x with respect to y and then, you have the product term and of course, the rho part which will by the time you get to this problem, I think I would have discussed with you which is the correlation coefficient. So, this is the expression, but anywhere right now this is a.
So, now you have to show that the conditional density of X, given that Y equal to y is a normal density with parameters. So, you see the moment you fix your Y, then you can rear in the terms and write name in the form, so that this becomes a mean of the conditional variable. That means, conditional density of X given that Y is y and the variance will become sigma x square into 1 minus rho square.
So, it is just a question of you know manipulating the term and since, you already know what you have to show. Therefore, this is not going to be difficult, so that X and Y are both random variables with respective parameters mu x sigma x square and mu y sigma y square. So, here you see if X and Y are 2 normal bivariate, then the joint density function is given here above and then, you can show that when you do the integration for when you integrate f x y with respect to y from minus infinity to infinity, you will get mu distribution with mean mu x and variance sigma x square. And similarly, when you integrate with respect to X, you will get the a marginal of Y which will come out to be normal with mean mu y and variance sigma y square.
(Refer Slide Time: 39:51)
 
So, part c says that show X and Y are independent when rho is 0. See now here if you look at the expression f x y, then by putting rho equal to 0 you see this coefficient on the root 1 minus rho square will become 1. Then, 1 upon 1 minus rho square will become 1 and the product term in the exponential will become 0. So, the joint density function will become product of marginal of X and Y, right. You can see immediately because I can write 2 pi as root 2 pi into root pi root 2 pi, then sigma x into e raise to minus 1 by 2 x minus mu whole square upon sigma x square into 1 upon rho root pi sigma y e raise to minus 1 by 2 y minus y mu y upon sigma y whole square. So, it will become product of two marginal. So, therefore, 2 x and y. By our theorem, X and Y are independent and the converse is also true that of course if that I have talked about the converse, the actual thing is that if X and Y are independent, then of course rho must be 0. That is what I am saying here, so that X and Y are independent when rho is 0.
So, here I am asking you to talk about the converse. The theorem is that if X and Y are independent, then rho must be 0. So, this is what you have to show and also, what I am saying is that the converse is true. That means, if rho is 0 for a bivariate, a normal random variable, the x, y being a bivariate normal distribution having a bivariate normal distribution. Then, if rho is 0, we can also show that X and Y are independent. So, we will discuss in lecture 17 also and then, later on I will show you that the covariance of a bivariate normal random variable, where x, y is given by rho. So, this we will discuss much later in lecture 23.
(Refer Slide Time: 42:16)
 
See in part c of question tenth, we have to show that X and Y are independent when rho is 0. So, what I have we have said so far is that if eleventh problem, the joint density function of X and Y is given like this and here, x varies between 0 and 1 and y varies between 0 and 2. First question is X and Y are independent? Yes, you can answer because the limits are separate and the joint p d f can be separated into X into Y, but I would like you to find out. So, anyway you are finding out the density function of X, the density function of Y and then, find the joint distribution function. So, you are asked to find the cumulative distribution function and then, find E Y and find probability X plus Y less than 1. So, again this is I have just included this as an exercise that you get more familiar with how you work out these different integrals.
(Refer Slide Time: 43:51)
 
This is another problem number 12. The p d f random variable X is shown below. This is a single one. Find density function of 1 upon x. So, this I have included because I thought we have not discussed many functions of a single random variable. So, therefore, find the density function of 1 upon X, e raise to x, ln X. 1n x is again the log with base e and a X plus b. Again, it is simply an exercise to get familiar with you know how you find the limits and so on. The ranges for different functions and so if X 1 and X 2 are independent random variables with same probability distribution function as X, find the probability distribution function of X 1 upon X 2 and X 1 X 2. So, you may feel that somewhere other things are repeated. It does not matter as much as practice as you can to get a good feeling about how you handle this.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture No - 16
Order Statistics Covariance and Correlation

(Refer Slide Time: 00:15)
 
So, we showed that covariance of x and y is 0, but then and of course by definition also it was clear that x and y are not independent, but we can also show analytically; and that is see just consider this conditional probability x equal to 1 and y equal to 0, given y equal to 0. So, probability, conditional probability x equal to 1, given y equal to 0. So, it will be equal to probability x equal to 1, y equal to 0 divided by probability y 0, y equal to 0, but this is by definition it is equal to probability x equal to 1. And then here it will be probability x equal to 1 plus, probability a cumulative distribution function because probability y is 0; so should be not. Yes. So, this is y 0 when x is not 0. So, x is 0, x is not 0; that means, x is value 1, and x is value minus 1. 
So, therefore, this is 1 by 3 divided by 2 by 3 which equals half, but this is not equal to probability x equal to 1. See, if x and y are independent this conditional probability should have been equal to probability x equal to 1; so therefore, x and y are not independent.
(Refer Slide Time: 01:32)
 
In the last lecture, I defined covariance and then I also defined the correlation, and just tried to show you that correlation is nothing but the dimensionless version of covariance; and now here, a few more examples of or uses of a covariance. So, you saw that when you wrote variance x 1 plus x 2, the formula was variance x 1 plus variance x 2 plus twice covariance (x 1, x 2). So, in general, if x 1 and x 2 are not independent then I afford to compute the variance of x 1 plus x 2, I need covariance (x 1, x 2), right.
And, in general, if you take it, if you take sum of n variables and you want to compute the variance, then by the formula it would be because again the property that we defined for the variance, you can just apply them iteratively; and this will be sigma i varying from 1 to n, variance x i, right. Because it will be covariance of x 1, x 1, x 2 comma x tends to 1 and then the product terms where x i and x j are different; i and j are different.
So, this will be equal to twice sigma covariance (x i, x j) if you put i less than j, because remember for the covariance also we said that covariance (x i, x j) is the same as covariance (x j, x i). So, if you impose this, i less than j, then it will become twice because covariance (x 2, x 1) I will write as covariance (x 1, x 2). So, then it will become twice this; or you can write this as summation i j where of course, you have to say that, i is not equal to j, then it will be covariance. So, whichever formula suits you, you can use that. So, this will be covariance (x i, x j) simply; without the two if you simply summing over all possible values of i and j, so that, i is not equal to j, right.
Now, interesting, again an example to show you that how you can make use of these properties that we have enunciated for covariance. So, consider the multinomial distribution, remember they were n objects and then they were k categories, multinomial distribution with k categories. So, then probability of, success in 1 categories p 1, p 2, and p k; and we have already discussed this distribution and we saw that the probabilities for successes will behave like binomial. 
So, for example, in category 1 it will be binomial n p 1, it will be binomial n p 2, and so on. So, this is how you defined the (multinomial distribution, p vector) where p vector is p 1, p 2, p k. So, these are the probabilities of being a particular category which means, success in the first category, so on. 
So, now if you want to compute covariance (x i, x j) for any i, j, then for, i equal to j, it will be the covariance (x i, x j) will be covariance (x i, x i), which is we know is variance x i; and since each, x i, is binomial and n p i, x i, is binomial n p i. So, we know from the binomial distribution formula that the variances, n p i into 1 minus p i, right.
Now, for, i not equal to j, we want to compute covariance (x i, x j). So, let just do it for x covariance (x 1, x 2). So, the question asked is what do you expect; should this be negative, covariance (x 1, x 2); see, the idea is that now after having defined correlation also, we see that this measures the linear relationship between; and of course, we still have to talk about kosis law of equality and so on.
So, anyway the expectation is that this will be negative, why? Because, you see if the total number of objects is fixed which is n, right, now if large number of people or objects are in x 1, then accordingly x 2 the number will not be that large. So, there will be negative correlation or negative relationship between x 1 and x 2, and that is what covariance will measure here. So, and we will see after computation that it actually comes out to be a negative number. So, variance (x 1 plus x 2) is variance (x 1) plus variance (x 2) plus twice covariance (x 1, x 2) which we wrote down earlier.
Now, it turns out that we can compute these 3 things because variance x 1 is n p 1 into 1 minus p 1 plus, variance x 2 is n p 2 1 minus p 2; and x 1 plus x 2, again we had seen that when you merging 2 binomials like n p 1 and n p 2 then the sum will behave like a binomial (n, p 1 plus p 2). So, there must have, you must have done some exercises also or you can just sit down and obtain this result for yourself. 
So, therefore, variance for x 1 plus x 2 would be n times p 1 plus p 2 into 1 minus p 1 minus p 2; and so from this relationship it is this quantity that we want to compute. So, therefore, 2 covariance (x 1, x 2), will be, just take this to this side, so n p 1 plus p 2, I am just opening up the bracket. So, n (p 1 plus p 2) minus n p 1 plus p 2 whole square which you can write as, I do not why I have written it as. So, this is plus, right; plus 2 p 1 p 2. 
And then, you see the terms will cancel out because p 1 square plus p 2 square; you see here this is n p 1 plus p 2 and this is minus n p 1 plus p 2 which cancels out, right; and then plus n p 2 square plus n p 1 square and minus n p 1 square plus p 2 square. So, everything cancels out; you are left with, minus 12 p 1 p 2. So, therefore, this is less than 0 because p 1 p 2 and n all are positive cumulative distribution function 0. So, the covariance; and so once you know that the covariance (x 1, x 2) is minus n p 1 p 2, you can immediately conclude that covariance (x i, x j) will give minus n p i, p j. 
So, this was made possible because of this formula which was again written down using covariance. And now for this multinomial distribution you can immediately write down the formula for a covariance (x i, x j) as this, cumulative distribution function; relation coefficient also which will again turn out to be negative. Because the correlation coefficient will be simply this divided by standard deviation of x i, and this will be standard deviation x j, which we already know, right, because it will be n into p i 1 minus p i under root, and this will be n into p j 1 minus p j under root. So, therefore, this computation has become so simple.
(Refer Slide Time: 08:57)
 
In the example where we took x 1 to be x, and x 2 equal to x square, and I said that probability x equal to 1 is equal to probability x equal to minus 1 is half. Then we saw that expectation of x and it was equal to expectation x cube was 0 and therefore, you could see show that covariance (x 1, x 2) where x 1 is x and x 2 that x square is 0. 
Now, actually what you can, you can always show this if whenever x 1 that is x is normal 0 sigma square; that means, expectation of x is 0; and or x 1 has any other distribution which is symmetric about 0 because you saw that x here is symmetric about 0. So, probability (x equal to 1) is equal to probability (x equal to minus 1) is half. So, this is symmetric about 0. 
So, now if I take, instead of this if I have taken a distribution of x to be normal 0 sigma square or any other distribution which is symmetric about the origin, then you can show that covariance (x 1, x 2) is 0. So, therefore, you can construct so many examples where covariance is 0, between 2 random variables, but they are not independent because there is a definite quadratic relationship between the 2. 
And so knowing one value, knowing value of one you can predict the value of 2, second variable exactly. And therefore, this is what you want to, sort of through this example I thought we can show you and emphasize this fact again that covariance 0 just says that the 2 variables are uncorrelated, but their need, they need not be independence. So, independence goes much deeper than that.
Now, very interesting inquality and very powerful one which we can show, see right now; if their expectations exist then this is the inequality; that means, expectation of x y square, expectation of x y square, sorry, expectation x y whole square 1 minus of 1 minus r 1 t into 1 minus r 2 t. So, the same principle will be used and you can show that expectation y square. And, equality holds, if I know only if for some constant, a, y is a x; that means, there is a linear relationship between x and y. So, if x and y are linearly related then the kosis words inequality would be satisfied as equality, otherwise it will be restrict inequality.
So, now we are, in this we are assuming, let us see, y square, is a positive value random variable. So, expectation y square can be either 0 or positive, right. Now, if it is 0; so we are assuming that expectation y square is positive because if it is 0, so when can expectation y square be 0 because y square again is a positive random variable. So, it will take only positive values, and so when you write the expectation it will be possible values of y square into the probability with which it takes its values. 
So, therefore, that will be positive sum. So, that cannot be 0 unless y is 0. So, that is clear. So, therefore, if expectation y square is 0, it will imply that y is a 0 variable, y takes only 0 value, and then this inequality will be satisfied because if y is 0 this is 0 and this is 0. So, both sides you have 0, and so the inequality satisfied is equality. So, therefore, it is safe to assume; I mean, there is no harm in, no loss of generality I take it to be. 
(Refer Slide Time: 12:43)
 
So, f x j x will be j n c 1, f x, F x raise to j minus 1, 1 minus F x raise to n minus j. Now, we can compute the p d F for x 1, the first order statistics independently, and then we can confirm that the, what we have obtained follows by this formula also. So, let us consider the probability of x 1 less than or equal to x. So, then the compliment of this event will be probability x 1 greater than x, right; this is less than or equal to x, so then here it will be, x 1 greater than x, the compliment.
Now, if this smallest statistic, the smallest or the statistic is greater than 1 it implies that all the statistics must be greater than x. So, x 1, x 2, and x n, and all must be greater than x. So, the 2 events are equivalent, and therefore, I can say that the probability x 1 greater than x is equal to 1 minus of F x raise to n, right; because the probability for this is 1 minus or for any x, for any x i greater than x, the probability is 1 minus F x and therefore, since all of them have to be greater than n. So, this is 1 minus F x raise to n, right. 
And then, so therefore, I can write the cumulative distribution function for x 1; and this should be, x; F x 1(x) will be 1 minus of this; 1 minus of x 1, x 2, and x n, all greater than x, right. And therefore, this will be 1 minus of 1 minus F x raise to n because this is what you have here; and this is equivalent to, or for x 1 greater than small x, and then implies all these are greater than small x; and therefore, this is the event, right.
 And so when you differentiate both the sides you get F x 1 (x) as n; then minus minus becomes plus and the derivative of this is f x, and this is 1 minus F x raise to n minus 1. So, if you substitute, j equal to 1, here this will be 1, and; this should have been n c j. So, n c 1 which is n, then F x; and this of course, j is 1, so 1 minus 1 is 0, no contribution, then 1 minus F x raise to n minus 1; so the 2 match 0, because t is a real number, so therefore, this is satisfied. 
(Refer Slide Time: 15:22)
 
Now, if it is equal to 0 then E x plus t y whole square is equal to 0, if and only if E x y because, that means, that this equation is satisfied as equality, equal to 0. Then the discrepant must be equal to 0. So, this is it, right. So, this is one part. And, now we have to, we want to show that under, for what value of t this will happen. So, you see from here because x plus, expectation of x plus t y whole square is 0, this as we have argued earlier, the random variable itself must be 0 with probability 1, right; x plus t y has to be 0 because otherwise its expectation cannot be 0, right.
So, now, the thing is that from here itself you can say that we can compute the value of t which makes this happened, right; which makes the discrepant equal to 0. But, as you see, if I do it here, if I take the expectation, here it will be E x plus t; and let us say the value of t naught, t which is a t naught we are looking for. So, this is equal to 0. So, from here we say that y cannot be compute the value of t naught, but you see I cannot guarantee about E y being non 0, right. And so therefore, I cannot compute the value of t naught from here. 
So, what we do is if we multiply by this y, then again x y plus t y square is a 0 random variable, right, because this is 0. And so now, if I take the expectation, so this will be 0 equal to expectation of x y plus t y whole square. And so then from here when you are doing expectation inside this will be t naught is expectation x y upon p y square. 
So, therefore, kosis words inequality is satisfied as equality, if and only if, right; if and only if x can be written as, this is t naught. So, from, since this is now 0, I have computed the required t naught. So, this will be x is equal to minus E x y upon E y square into y. Now, this is a linear relationship between x and y. So, kosis words inequality is satisfied, whenever x and y are related linearly; and this is the constant which relates x and y, right. And, we will see the implications of this. 
Now, using kosis words inequality we can prove following properties of the correlation coefficient rho; and so for any, x 1, x 2, any 2 random variables we will first show that your value after correlation coefficient lies between minus 1 and 1; and this is what we meant by standardization. And, because covariance, the only difference between correlation coefficient and covariance is that you divide covariance by the standard deviations of x 1 and x 2; and then you get a standardized quantity. And so this will be between minus 1 and 1; and if it is 1 then they are positively related for x 1 and x 2; and if it is minus 1 then they are negatively related. So, we will just go through these properties in a few minutes.
(Refer Slide Time: 18:59)
 
In the kosis words inequality, replace x 1 by x 1 minus expected x 1, and x 2 by x 2 minus expected x 2. So, then the inequality would look like expectation of x 1 minus E x 1 into, sorry, expectation of the product, x 1 minus E x 1 into x 2 minus E x 2; this whole square, is less than or equal to, expectation of x 1 minus E x 1 whole square and expectation x 2 minus E x 2 whole square, right. Because the kosis words inequality we obtained for any 2 random variables x, y. 
So, here I can replace the variables x by x 1 minus E x 1 and y by x 2 minus E x 2. So, this is valid, right. And, so which means that, which reduces to covariance (x 1, x 2) whole square is less than or equal to variance x 1 into variance x 2. So, kosis words inequality really simplifies proving these properties of the correlation coefficient. So, but this is nothing but if you divide this by this then it says that covariance (x 1, x 2) whole square divided by variance x 1, variance x 2, is less than or equal to 1. 
So, if I take the square root then, a positive past of the square root then this will be less than or equal to 1, right. So, with the, so for absolute value of the correlation coefficient is less than or equal to 1. So, the first property is easily proved using the kosis words inequality. And now, you want to show that if it is satisfied as it quality; and remember in the, when we proved the kosis words of inequality we showed that x will be equal to expected x y upon E y square into y. So, this was it.
Now, here I have replaced x by x 1 minus E x 1 and y by x 2 minus E x 2, and here to so this becomes. So, therefore, this will be because of our transformed variables. This is x 1 minus E x 1 is E of, expected value of x 1 minus E x 1 into x 2 minus E x 2 upon sigma square x 2, and this is x 2 minus E x 2. So, this is the linear relationship between x 1 and x 2. But, this quantity you can see is the covariance, and then you write, you need variance of standard deviation x 1 into standard deviation x 2. So, this will come here. 
So, you know, just rewrite this expression. So, 1 sigma x square I keep here, the other is here; now here I am dividing by sigma x 1; so I multiply; and therefore, this is what I get. Now, this quantity; I did not say here. So, the 2, part 2 was we had to show that rho is equal to 1. So, we start with this. So, if I start with this then in the kosis words we said that if it is satisfied as quality then we get this relationship which then the minus E x 2.
And so just divide by sigma x 1 here. So, therefore, this would be; so we said that if; so that means, you are just getting the specialized linear relationship; you can write it little differently; the same thing here we can write in this way because we are saying that rho is equal to 1, right. So, then you can predict the actual relationship, till actual linear relationship between x 1 and x 2, if you.
And, similarly if rho is equal to minus 1 then there will be a minus sign here; the same analysis will be done, right. So, this is what we are trying to say is that, you know, your quantity rho is correlation coefficient; is measures the linear relationship nicely; it captures the relationship, linear relationship. But it fails to show you the relationship when it is a quadratic or it is non-linear, and rather I should just say that when the relationship between 2 variables is a non-linear, then it fails to. So, being 0 does not help you, right. So, therefore, that means, you cannot conclude that other variables are independent if the covariance is 0.
So, now let us take this special case, and show you that in, when the 2 variables are normally distributed then you can show that the variables being uncorrelated implies independence, and the other way. Of course, the other way you know, if 2 variables are independent then certainly the correlation coefficient will be 0, but we will show it the other way; that is if the correlation coefficient is 0 then the variables are independent; and this is valid true for a normal distribution only.
(Refer Slide Time: 24:14)
 
So, here just look at the bivariate normal distribution. So, bivariate normal distribution you have the means are mu 1, mu 2; variances are sigma 1 square, sigma 2 square; and the correlation coefficient is rho. So, the expression for the p d F for a bivariate normal distribution is 1 upon 2 pi sigma 1 sigma 2, under root 1 minus rho square. And therefore, you see this is valid because rho we have just shown is between minus 1 and 1; the absolute value rho is less than or equal to 1. 
So, and then exponential E raise to minus 1 upon 2, 1 minus rho square; then x 1 minus mu 1 whole square upon sigma 1 square plus, x 2 minus mu 2 whole square upon sigma 2 square minus, 2 rho into the product term divided by sigma 1 sigma 2. So, this is the expression for a bivariate normal distribution, right. So, the proposition is that if x 1 and x 2 are independent or x 1 and x 2 are independent, if and only if they are uncorrelated. So, this is what we can finally establish after giving you so many examples where un-correlation or uncorrelated did not mean independence. 
So, if rho is 0 then you can see immediately from here this expression simplifies, this becomes 1, this is also 1. So, it will be 1 upon 2 pi sigma 1 sigma 2; then E raise to minus 1 by 2, right; and x 1 minus mu 1 upon sigma 1 whole square plus, x 2 minus mu 2 upon sigma 2 whole square; this term is not there anymore. So, now you can immediately decompose this E raise to this. So, therefore, you can write this as product of 2. 
So, here it will be 1 upon root 2, say, 2 pi i I can write 1 upon root 2 pi sigma 1; then the x 1 term, you know, put together here; and the x 2 term is this. And, you can see that these are 2 p d fs; and each of them say, this is normal mu 1 sigma 1 square, right; p d F separate p d fs, and each is normal. So, therefore, in fact, so much simplification here, right. The moment you say that they are uncorrelated, then they are also independent by our definition, right. 
If the product of, if the joint p d F can be written as the product of individual p d fs or the marginal p d fs then it will be said that the variables are independent. So, therefore, and so if and only if part gets proved because rho 0 implies independence, and of course, independence implies that rho is 0. So, therefore, the proposition is established; that is if x 1 and x 2 are independent then they are, if and only if they are uncorrelated, provided x 1 and the joint p d F of x 1 and x 2 is a bivariate normal distribution. So, you can see how we are relating the result that we are getting; and then of course, all these simply, finally gets used, and you know, estimating lot of probabilities that are useful to you.
(Refer Slide Time: 27:41)
 
So, in the sum I am just discussing the exercises 6 which I will be discussing at the end of this lecture. So, there is a question that I have posed there, and I have asked you to show that correlation coefficient can be written as, rho x y, variance x plus, variance y minus, variance x minus y, upon twice under root of variance x into variance y. So, essentially what I am saying is that the covariance (x, y) can be written as variance x plus, variance y minus, variance x minus y divided by 2, because, this anyway figures in the definition of rho (x, y). 
So, this answer is straightforward. You start with variance x minus y, and so that will be x minus E (x) minus, y of minus E (y) whole square, expectation of this whole square, right. And, open up the brackets; so this will be expectation of x minus E (x) whole square plus, expectation y minus E (y) whole square, and minus twice product term expectation of x minus E (x) into y minus E (y), right. 
And this can be; so this I can bring to this side; so therefore, immediately you have variance x plus variance y, minus variance x minus y is equal to this; but this is nothing but your covariance. So, in fact, now you can divide this by, rho x rho y, and 2 you can take to the other side. So, it just because see, what happens is that all these different expressions for the same thing that you keep using are handy, sometimes it helps to, because you know these where values, because you, from the known standard distribution of these variables; then you can immediately write down the correlation coefficient.
Now, again see, by theme now here has been to show you as many examples as possible about, you know, the covariance other or the correlation coefficient being 0, but variables are not independent. And, you can see how, you know, contrived them a look at these examples, but they make a point. So, now, here x is normal 0 sigma square, and suppose y is independent of x. 
So, x is normal distributed 0 sigma square, and y is independent of x; and the probability y equal to 1, equal to y minus 1, is half. So, therefore, and this imply that your expectation y is 0, right; if probability y equal to 1 and y equal to minus y is half then your expectation y is 0.
Now, define another variable z which is equal to x, y. So, you see, immediately from here probability z equal to x is half, and probability z equal to minus x is also half because y is either 1 or minus 1, right. Now, if you compute, probability z less than a, then this will be x less than a; and that is with probability half, right; because z is equal to x with probability half, and then x is equal to minus x. 
So, if you are writing; so you will be writing, z less than or equal to a, which is minus x less than or equal to a. So, this is equivalent to, x greater than or equal to minus a, right. So, that is what I have written, probability x greater than minus a, into half. But remember, x is normal, normally distributed; and if x is normally distributed it is a symmetric about the origin, and so x less than a, and x greater than minus a, are the same probabilities.
Now, if you can carefully see, you see, in the normal because 0 sigma square. So, therefore, if you take this thing here, so let us say, this is, take a to be positive and that is the same thing; and this is minus a. So, x less than a, is, you see, from the normal thing, this area and this area are the same, right. So, x less than a, is this all probability; and x greater than minus a, is this which are the same, right; because a tails these values are the same; therefore, this area and this area are the same, right. 
Therefore, this event is the same as, x less than a; and though therefore, this follows from the x being symmetric about the origin. And so again it is not necessary here that they should be normally distributed because I think anything which is symmetric about the origin would have done the job, right. So, therefore, this is that; and so this is equal to; I should have put it here. So, from here it follows- this is probability x less than a. So, that means, z and a, z and x, have the same cumulative density function from the same c d F which implies that they have the same p d F also. So, x and z have the same c d F, and they have the same p d F, right.
(Refer Slide Time: 32:51)
 
Now, if you compute the correlation coefficient between x and z, that should be expectation (x z) minus E (x) into E (z) upon sigma x into sigma z. But, E (x z) is expectation x square into y, and your E x and E z. So, E x is 0, and therefore, E z will also be 0 because this is normal. So, that means, you need a distribution which is symmetric about the origin. So, therefore, then its expectation will also be 0. So, you therefore, I do not think you need this x to be normally distributed, fine.
So, then this part is 0, and this is E x square y, because x, y; and x and y being independent this is E x square into equal to E (y), right. But, E y is also 0, remember; y is again symmetric; y is 1, and y is minus 1. So, with probability half, both the values have equal probability. So, E (y) is 0. So, E (y) being 0, you get this as 0. So, therefore, the correlation coefficient i 0, but x and z are completely dependent by definition as we saw, right; x and z are completely different- these things because they have the same c d F, they have the same p d f, but still they are uncorrelated. 
So, this is; again, you know, I am just, wherever I get these kind of examples I just thought I will bring them to you to show you the, ok. And, so right now we have said reasonably good amount joint probability density functions which was the, so more than 1 variable; then we talked about how we can obtain joint density functions of more than 1 variable.
(Refer Slide Time: 34:25)
 
Now, let me talk of order statistics; so you know further application of the same concept. So, see if you have a sample of size n, random samples, so x 1, x 2, x n, are the observed values; and the c d f, they are coming from the same distribution, so you can say these are also identically independently distributed random variables because it is a random sample. So, c d F is; that means, the cumulative density function is denoted by F, and the probability density function is denoted by small f. 
So, when you order the observation, so this will be smallest one. So, therefore, this will be the notation; so x 1 less than or equal to x 2, less than or equal to x n. So, this is the order arrangement of the n sample values that you obtained, ok. Now, so the question arises, can we find of course, one would want to talk about the joint density function of all x 1, x 2, x n, and in particular you would want to find out the density function for the p d f. So, either both of them are continuous or both are discrete, this is when we are defining the conditional expectation.
(Refer Slide Time: 35:47)
 
So, the nature of the 2 variables should be same in the sense that either both are continuous or both are discrete, right. So, then the definition is of course, straightforward because now x is equal to x, so this is fixed; this is given to you. So, now, you have to find the expectation of y, given x equal to x, would be from minus infinity to infinity, y times f conditional distribution of y, given x. So, this would be the definition. This is the case when, x and y, both are continuous.
And, in the discrete case, it will be, the summation will be for all x for which p x, x is greater than 0, because remember this conditional p d F will have p x x in the denominator. So, therefore, we will only consider summation to those x for which this is positive; and then of course, probability y, given x, for all y for which this is positive because otherwise the product will be 0. So, under this condition you can for the discrete case, when x and y are both are discrete, you can define the expected, conditional expectation by this formula.
(Refer Slide Time: 37:00)
 
So, we will start from the, take this example of a discrete case, where the joint density function is given as probability x equal to x, and y equal to y. So, even from this table you can immediately see, now x equal to 1 and y equal to 1. So, this is the probability. So, you can read the table. So, this is 1 2, 1 3, 1 4, and so on, right. And, you see when you add up these probabilities, they give you what? 
They are the values of x equal to 1, x equal to 2, x equal to 3, x equal to 4. So, you immediately get the probability for y equal to 1. So, therefore, when you add up these rows, the numbers give you the marginal p d F of or probability mass function for y, right. So, this point 2 is the probability when y is equal to 1. Similarly, y equal to 2 because the possible values of x are 1, 2, 3, 4.
So, when you add up these probabilities 1 2, 2 2, 3 2, and 4 2, you get the probability of y equal to 2, so that adds upto 0.5. And this is, similarly probability y equal to 3 is 0.3, and these 3 must be add up to 1. Similarly, here when you add up the probabilities of, the conditional probabilities, x equal to 1, and y varies from 1, 2 and 3, they will give you the marginal for x. So, this will be the probability x equal to 1, this will be the probability x equal to 2, x equal to 3, and x equal to 4; and they also add up to 1, right.
So, now from our definition, see I am writing f where it should be ps, but does not matter because the discrete case we are used to habit of writing the p in terms of ps, the probabilities, so does not matter. But, you see now here you can immediately find out probability, conditional probability of x when y is 2. So, conditional probability x 1, y is equal to 2. So, for example, here when you want to compute conditional probability of x equal to 1 given y is equal to 2. So, calculations are simple; y is equal to 2 is given; you are given by this, right; and so conditional probability. So you will divide by a probability y equal to 2 which is divided by the standard deviation of x 1 and standard deviation of x 2; y is equal to 2 is 0.1 divided by 0.5 which turns out to be 0.2. 
Similarly, conditional probability of x equal to 2, given that y is equal to 2, will be this joint density function of x equal to 2, y equal to 2, divided by the probability of y equal to 2, which is 0.5. So, again 0.1 upon 0.5 is point 2; and similarly the other 2 computations. And, if you remember, I have not analytically proved it, but we should be able to, maybe that is what we should do next time. 
So, here in any case you see these probabilities also add up to 1, as they should because this is now the, you have got the conditional which is also a probability mass function; and therefore, the probabilities here should add up to 1. So, it is 0.4 which is then 0.54; and so 0.54 plus 0.46 is 1. So, you just do verification, right.
So, now we want to define the, compute the expectation value of x given y is equal to 2. So, I mean you just take the definition that we wrote down. So, here the marginal’s are given to you; point, now this is be 1.4. So, the expectation here would be when x is equal to 1 then the probability that you obtained; I am computing it for y equal to 2, sorry. So, we have computed these probabilities. So, when x is equal to 1, so when you are computing this expectation y is equal to 2, so then it will be value of x equal to 1 into, the probability that you get; the probability match function when y is 2 and x is 1, right. Is it ok?
So, the expression that I wrote down, see here it will be, you are computing see y is fixed. So, you are computing the expectation of x, given y is equal to 2. So, as x takes different values, given y; so you will multiply by the corresponding probability when x is; for example, x is 1 and y is 2. So, x is 1 and y is 2; this is the probability when x is 2, and given y is equal to 2 then this is 0.2. So, we will take those probabilities, the conditional probabilities, and multiply by the corresponding values that x takes, right. 
So, the conditional probability are here; this is this; 0.14 is this and 0.46 is this. So, I multiply by the corresponding values that x takes; and therefore, this is 2.28. In fact, I am going to talk some more in terms of the functional aspect of expected value of; in other words, in fact, we can sit here when I am talking of expectation of x given y equal to, Y equal to small y. 
So, you see, because you are taking expectation with respect to x, so then you will be, this will turn out to be a function of y. So, I start giving important example, but we will discuss this in detail in the next lecture. So, this will be a function of y because you have taken expectation with respect to x. So, that part is gone; x part is gone; it is no longer a function of x, but it will continue to be a function of y, right. 
And then we will see what kind of relationships we can predict on what, how we can use this. So, but initially through this example I just want to show you how you go about computing these conditional expectations; this is the whole idea. So, similarly you can compute the expectation of x, given y is equal to 1. So, now I did not do this detail calculation here, but you can see that when you wanting to compute.
For example, here x is 1 and then given y is equal to 1, so x is 1 you will be writing that probability. So, I will divide 0.02 by 0.2 because y is equal to 1. So, y is equal to 1 is this. See, you simply have to, just as we computed the probabilities for, conditional probabilities for x equal to 1, given y is equal to 2, I simply divided these numbers by the corresponding probability, y equal to 2. So, here also, when y is equal to 1, you divide these probabilities by this, and you get the conditional probabilities of x equal to 1, y is equal to 1.
And here, 0.06 divided by 0.2 will give you the probability that x is to, conditional probability x is equal to 2 and y is equal to 1. So, this way you can show. So, this know, so that is what all I have done; I have divided this by 0.2. So, then I have written it as 0.1 into 1; so computing the conditional expectation; so multiply by 1. 
Then, similarly 2 times 0.06 divided by 0.2. And then, 3; so 0.08 divided by 0.2; and then 0.04 divided by 0.02, and 4 into that, right. So, that number comes out to be 2.7, right. And, in the same way, you compute the expected value of x, given y is equal to 3. So, here I will take 0.07 divided by 0.3 into 1, and 0.03 divided by 0.3 into 2, and so on. So, you will compute those expectations. 
And now, as I am saying that if you take this expectation; and yes, this I have just now written down this expression; we will spend lot of time on it, trying to show you. But, computationally you see, if I now want to compute the expected value here, as I told you, this is a function of y, right. So, when you want to compute expectation through conditional expectation of x, y, given equal to y, then all I have to do is to multiply by this corresponding. For example, 2.7, I will multiply by the probability that y is equal to 1 because this is the conditional expectation of x, given y equal to 1. So, I will multiply by; so you can treat this as a function of y. So, this into the probabilities that y takes the value 1. So, that will be 0.2 into 2.7. 
Similarly, this will be the condition; this is the conditional expectation of x, given y equal to 2. So, this is again will be 2.88 into probability that y is equal to 2 which is 0.5; so 0.5 into 2.88. And similarly, here a probability that y takes the value 3, and that into the expectation, here conditional expectation. So, this number comes out to be 2.82. And, we can verify that this is actually equal to E raise to x because this is the marginal density of x. So, to compute the expectation of x, I will multiply 0.19 into 1 plus 0.19 into 2 plus 3 times 0.23 plus 4 times 0.39 which again gives me the number 2.82. So, the 2 numbers are equal.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 17
Covariance Correlation Cauchy-Schwartz Inequalities Conditional Expectation

(Refer Slide Time: 00:15)
 
There order statistics. So, let us just begin with the first one. So, if you want to find the density function. So, cumulative, we will start with c d f, because once you have obtain this, we can obtain the p d f also. So, here f x j is the c d f for the j x order statistic. So, which means and... So, the value f x j x means that this is the probability of x j being less than or equal to x. And what does this mean, if this is the j th order statistic; that means, up to 1 2 x 1 x 2 up to x j, they should all be less than or equal to x at least. So, at least j of the x 1 x 2 x n should be less than or equal to x. More can be less than x, but at least I am saying, I am co computing the probability that x j should be less than or equal to x; that means, at least j of x 1 x 2 x n should be less than or equal to x. So, now I can write, since it is at least, so it can be j j plus 1 j plus 2 which are less than or equal to x. So, therefore, this probability can be written as summation i varying from j 2 n though probability of exactly i of x 1 x 2 x n are less or equal to x. So, should be clear.
So, therefore, this implies that. I can write this probability as n c i, because out of the n, you are choosing i, any of the i can be less than or equal to x n c i, and then this is f i x, because i of them you want to be less than or equal to x. So, this is this into 1 minus f x. So, the remaining n minus i are greater than or equal to x. So, because exactly i of them are less than x, so therefore, remaining n minus i are greater than or equal to x. So, therefore, this will be the probability of that. So, you are summing this up. And now let us give it more concise form. So, because this is of course, very unwieldy you cannot. So, now consider the integral, and this is way you look see how we can relate, you know summations with integrals and so on.
So, consider the integral j n c j 0 to f x t raise to j minus 1 1 minus t raise to n minus j d t, and let me call this integral I of j minus 1. So, this index and n minis j index of 1 minus the power of 1 minus t. Now if you integrate by parts, so integration by parts will give. Here let me treat this as the first function. So, integral of this will be j upon t j upon j then 1 minus t is to j minus j, this computed from 0 to f x plus n minus j upon j 0 to f x t j and derivative of the second function. So, the derivative would be n minus j 1 minus t raise to n minus j minus 1, so this is what you get by integration by parts. So, here of course, at 0 this is 0 at f x it will be. So, here I have written also the j part. See this j cancels out, because both the terms have j in the denominator. 
(Refer Slide Time: 03:32)
 
So, this cancels out, and you are left with n c j f j raise to x 1 minus f x is to 1 minus j plus when you come to the integral this will be n minus j into n c j n minus j i of j n minus j minus 1, because j here this was j minus 1 this is minus 1 this was n minus j this is n minus j minus 1. Now, very nicely you can simply just write down this expression and this, and manipulate the terms and you can immediately see that this whole this can be written like this; j plus 1, and therefore, this will then become. Well the whole thing why did I write, because my i j is together. So, therefore, I do not have to write this term this is note there because I am trying to say that, you manipulate this, even this is not correct I should have written the integral here only. So, let me just say this is not correct. let me write continue writing the integral and j. So, what are we getting here; 0 to f x 0 to f x t raise to j 1 minus t raise to n minus j minus 1 d t, and then I am saying that you manipulate this and you can write this as. So, let me rewrite this, I am writing as, because now you need j plus 1 n n minus j n minus j minus 1, 0 to f x t raise to j 1 minus t raise to n minus j minus 1 d t. 
So, this whole thing can be written as i of j n minus j minus 1. So, therefore, you see, the iterative relationship is there. So now, this plus integral, where the power of the term 1 minus t raise n minus j has now become n minus j minus 1, power of t is going up right j minus 1 to j and so on. So, now, iteratively when I write, I will again get a term when I integrate this by part, I will get it term here plus than this actually j plus 1 f x is raise to j plus 1 then n minus j minus 1, and then another integral which will be i j plus 1 n minus j minus 2. So, this way iteratively when you do it, this power finally, becomes 0 and this will become your n. So, therefore, you can show, this summation is equal into the integral, and this what I have said that is. So, finally, you can show that this integral that I write down in a beginning, is equal to this sum, which is equal to your cumulative density function of x j. And this you should have recognized by now, because this is. 
See this is the beta integrant, together with the, or beta function when you want to make it p d f. And since the limits are from 0 to f x therefore this is called incomplete beta function. So, finally, I have been to able to replace, get this probability, the cumulative density functions, in terms of this integral. So, when you differentiate both sides of a double star, you will get f x j from here. It will be the p d f of x j, and this is you know differentiation under integral sign. So, since this is function of x, this will become f x here, and otherwise you just substitute for t f x and so you get the same, that for special cases; say for example, when you are sample values of from the uniform distributions, or I think from, may be from normal distribution. We will see through a examples, then it is easier to get this explicit expression, for your c d f and for your p d f. So, we will go through this example, to see how. And of course, the question arises as to why we are doing this, and you will see that. 
Let us just go through this example and you will know why we are talking about obtaining p d f for these order statistics. So, if you have a sample of size 2 and plus 1 independent and identical distributor and variables are observed, then the n plus first. See n observation from this side and on this side. So, n plus first is on the center, smallest is called the sample median. So, when you arrange them order them, and then the n plus first 1 smallest, is called the sample median. 
So, now let us say we want to find out the. So, we have a sample of size 5 from uniform 0 1, is observed, find the probability that the sample median is between 1 by 3 and 2 by 3, and this you know when your handling data’s, large data’s, sometimes you are only interested in what the median of these sample size is. So, we will go about, now obtaining the expression, because you want to find the probability of the sample median between 1 3 and 2 by 3. So, here you are actually talking about x 3; your j is 3 here, because sample size is 5. So, the median will be determined by the third ordered, third smallest statistic.
(Refer Slide Time: 09:36)
 
So, x 3 is the median, when you of the sample of size 5. So, x 3 will represent the median of the sample, so by our formula. See you remember the formula was j n c j f x F X raise to j minus 1 1 minus f x n minus j minus 1 for f x j. So, put j equal to 3 here, and this will give you 5 c 3, and 3 times this, and then f x. Now for a uniform distribution, your p d f is just 1 the interval 0 to 1. So, this is 1, and this is given by, you know for a uniform distribution.
(Refer Slide Time: 10:17)
 
So, proof of Cauchy Schwartz inequality, now expected value of y square can be greater than or equal to 0, it cannot be negative, because this is y square. So, therefore, when you integrate y square from minus infinity to infinity or whatever it is into f x which is a p d f non negative. So, therefore, this must be non negative. But then y expected value of y square equal to 0 would imply. So, two things are possible; either expected value of y square is 0, or expected value of y square is greater than 0. 
So, if it is 0, then this imply that probability of y equal to 0 is 1, because this expected values this, that needs, see you will write value of y square, whatever possible values is y square takes, into the probability of y square taking a particular value and so on, and this will imply that probability of y equal to 0 is 1. And hence, probability of x y equal to 0 is also 1, yes because this is a certain event, y taking the value 0 is the certain event; hence probability x y equal to 0 is also a certain event and so the this probability 1, and therefore, this implies, that expected value of x y is 0, because this takes the value 0 with probability 1. 
So, 1 into 0 plus, or you integrate or whatever it is, whichever you want to write it down, expected value of x y will be 0, and the inequality therefore, will be satisfy because this is 0 and this is 0. So, the inequality is satisfied. So, therefore, we will now proof for the case, when then expected value of y square is positive. x 1 less than or equal to x. So, I will look at the opposite event, which is greater than or equal to x. So, if first order statistic is greater than x; this implies that all the sample values must be greater than or equal to x. 
So, this is equal to what, 1 minus f x raise to n, because if the first order statistic is greater than x, since it is a smallest, all other values of bigger than x 1, so all of them must satisfy this inequality, and therefore, this probability is 1 minus f x raise to n, and we are interested in finding out the F x c d f. So, that will become 1 minus of this. So, 1 minus of this, which is equal to 1 minus of this, will give me my f x 1 x, this is the whole idea, so therefore, this is what you have, and which I can write as 1 minus 1 minus f x raise to n. So, when you differentiate with respect to x, you get the p d f here, and this will be simply minus minus becomes plus. So, n times derivative of this is small f x. So, n f x into 1 minus f x raise to n minus 1. So, this will be a general expression. 
So, now what I am trying to say is that, with this expression also and now. Let us just substitute j equal to 1 here. So, what do you get; this is 1 and so if you substitute in this formula, it will be n c 1 which is n, then f x and this is 1 minus 1. So, this is 1 this is 1 minus f x raise to n minus, this is minus j minus 1, how am I getting. So, this is coming out to be j is 1. So, this is coming out to be n minus 2, accordingly, say for us it should be 1 minus f x raise to n, and at least from here it appears that this should be this, and I do it n times, I differentiate, and then I take this so it should be n minus 1. 
So, where is this other 1 missing, because you taking j to be 1. So, are you sure this is n minus j or minus n minus j minus 1. Let us just verify that, what is the formula, correct formula; it has to be n minus j. It should be n minus j. Let us just make sure so that we do not make the mistake of n minus j. So, see that helps to verify. So, you see this is n minus j and therefore, j is 1 so it will be n minus 1, so both things match. You can obtain it directly or you can do it through the formula, the formula that we have obtained. Now, just a simple example to show you, now let us see it also helps to write down the joint p d f of all the other statistics, that you see. 
Actually, what is happening is this is some arrangement of the sample values x 1 x 2 x n, and the possible arrangements of these n sample values is n factorial. So, one of them will match this order and so you can you can do the thing through the regress mathematics, by showing that the, your r n region can be divided into n factorial regions, and each factorial, in each 1 of these factorial regions the, one arrangement of the sample values is there, and when you do the transformation, because you have to do it over whole of r n. So, the Jacobian will be one of the permutation matrices, and the value of the permutation matrices is always 1. I mean you take the positive part, otherwise the value of the permutation matrices plus minus 1. 
So, without going into all that, we can simply say that, the joint adjective function would be n factorial into, you see since the variables are independent, the joint density function of the sample values x 1 x 2 x n is nothing, but the product of the individual density functions, and may be if you want to feel good you can, but I am not writing this I am simply saying this is x 1 and this is x n, but they are the same. 
So, therefore, I am not writing these indices. So, all of them are the same p d f and therefore, this would be n factorial into f x 1 into f x n, this is the whole idea, so the general expression, where x 1 x 2 x n are varying from minus infinity to infinity. Because after all the order statistics is only one of the arrangements, and there are n factorial possible arrangements of the sample values of the n sample values. So, now to find joint p d f, x will be equal to expected value of x y upon expected value of y square into y. 
So, the minus sign is not there, see it gets cancel out. So, x I x j then what is happening in this, I will integrate this. So, for i minus 1 sample values, the limits of integration will be from minus infinity to x i, because i minus one of them have to be less than or equal to x i. For variables between x i and x j order statistics x i x j, the limits are x i to x j, and for variables having values greater than x j, the limits of from x j to infinity. So, once I do this integration; that means, I will be integrating for i minus 1 then for variables between x i and x j, and then for all the variables having values greater than x j. 
Let me write it this way. So, then once you do this, you will get the joint density function of. Remember, because for marginal when you had the joint density function, to obtain p d f of one of them, you would integrate respect to the other one, and then get the marginal p d f for the first variable. So, here also we have done the same, and therefore, these remain intact, and for the remaining; see this is f x i raise to i minus 1, because you are integrating from 0 to from minus infinity to x i and for variables between x i and x j, you are integrating from f x i to f x j. So, this is j minus i minus 1, and this is 1 minus f x j and minus 1, so this minus 2. So, these add up to n minus 2, and then you have the remaining 2 x i and x j. So, this will give you the joint density function. So, out ultimate aim say therefore, see the range of the sample values is also of lot of interest, in many situations, so we want to ultimately find out the range of the sample values. So, let me just define 2 random variables here, which are r is x n minus x 1. So, this is the range, and v is the largest sample value, and here of course, you should try to see that you can compute the p d f of x n directly, and then again verify from this formula. 
So, for when you want to find out the p d f of v of x n, when you say probability x n less than or equal to x, which would mean that all the sample values are less than or equal to x. So, you will immediately get, this thing to be f x raise to n. So, the cumulative density function of x n will immediately come out to be f x raise to n, and you would differentiate. So, n times f x small f x into F x, so raise is to n minus 1. So, here you can directly get this also. Anyway, so we have to find out the p d f of capital r. So, can derived the p d f of; see x 1 x n. Now first I need to know the joint p d f of x 1 and x n, once I obtain that, then these are functions of x 1 and x n, so I will use my transformation formula, and get the joint p d f of r and v, and from the joint p d f of r and v, I will then finally get the p d f of r, this is the whole idea. So, for to derive the p d f of x 1 and x n from your this formula, I will simply write i as 1 and j as n. So, i 1 this term is gone, and here also this term is gone, this term is gone. So, you are left with n factorial upon n minus 2 factorial.
 So, n factorial upon minus 2 factorial, then this f x n minus f x 1 raise to n minus 2, and then this is out, because n minus n is 0 and so this is f x 1 f x n. So, this is your joint p d f of x 1 and x n. Once I have this, then I will make the transformation, that I will write r as x n minus x 1 and v as x n. So, then from here you will go get the relationship for. So, x n comes out to be capital V and x 1 comes out to be v minus r, and then you write the Jacobian. So, r is my first variable. So, this will be minus 1 1 and then here it will be 0 1. So, the Jacobian absolute value is 1. So, now, I can get the joint density function of r n v. So, with Jacobian as 1, absolute variable Jacobian is 1, and these this transformation; that is your x n is v and x 1 is v minus r, in this 1 we just substitute for x 1 x n multiply by the Jacobian.
(Refer Slide Time: 23:02)
 
So, then your f of f of r v; that means, capital R is equal to small r, and v then this function this p d f of r and v can be obtain from this p d f n into n minus 1 f v minus f v minus r which is your x 1 this is n minus 2, and this is f of v minus r f v, and here of course, it is understood that r is greater than 0, because r represent the range and x n is greater than x 1, greater than or equal to x 1, so this is the case, and of course, we have range is 0 there is no point. So, we are taking r to be some positive number. So, therefore, once I get the joint p d f or r and v, now my interest is in the getting the p d f of capital r. 
So, I will integrate this, and in general you will integrate from minus infinity to infinity. Well why should I say from minus infinity to infinity, it should always be from, it should be r, because you see here your x n is r plus x 1. So, since this is non-negative then I mean, ok fine. In general, it would be minus iterative, because x 1. In general we are allowing x 1 to take vary from minus infinity to, this sample size is from minus for a population, which is from minus infinity to infinity. So, in that case this is fine. In general we can write as minus infinity to infinity. Now, as a special case consider, the case 1 x i r from uniform 0 1.
So, as a special case consider x i i varying from 1 to n, from uniform on 0 1. Then this function this p d f will reduce to whatever I written here the f r r. So, I am writing this. So, the p d f of the range variable would reduce to n into n minus 1, and now in this case it will be r, because as I am saying not that this is non-negative, if f all of the sample values are coming from uniform 0 1, all values are non negative, and therefore, this x n has to be greater than or equal to r plus. So, in x n is your v. So, when this values v and this is r. So, then v has to be greater than or equal to r. So, now in the joint density function, you are integrating with respect to v, to get the p d f of r. So, then that will be the range will be from r to 1, because variables are from 0 to 1. So, then this will become v, this will be v minus r raise to n minus 2, and both the p d f are 1 1. So, 1 1 d v, this is your this thing, and you can see the simplification v cancels out this r raise to n minus 2 d v. So, the integral here would be v, which will be 1 to r 1 minus r. 
So, therefore, this is your p d f for the range, and now you can find out the possible. So, for a sample of size 10 from uniform 0 1, the probability that the range is larger than 0.8. So, these questions are of full out of interest. So, you want to find out the range of values, the sample that you have observed. So, if you are saying that the range is larger than 0.8 then you want to compute the probability that capital R is greater than 0.8 therefore, you will integrate this function from 0.8 to 1, and if you simplify here you get the answer is 0.6 to 4, which is a pretty large probability, of range values being more than 0.8, the range of the sample being more than 0.
(Refer Slide Time: 27:04)
 
So, another example; now from the normal distribution, because I thought we had had enough cases for uniform. So, if x 1 and x 2 are identically independently distributed, from a normal 0 one; that means, the mean is 0, and the variance is 1. So, this is a sample, x 1 x 2 is a sample from normal 0 1. So, find the p d f of x 2, which will represent the max of x 1 and x 2. So, we will again obtain this, without using any formula. So, here again as I explain it to you, that if you want to find the c d f of cumulative density function for x 2, second the largest one, then this will be probability x 2 less than or equal to t, which will imply that both the values x 1 and x 2 should be less than or equal to t, and since they are independent, this is equal into probability x 1 less than or equal to t into probability x 2 less than or equal to t, and coming from t and 0 1 will be root 2 pie e raise 2 minus 1 by 2 t square d t. So, this is our notation for phi t for a normal distribution. So, this is standard normal distribution, so phi t. 
So, therefore, this will be phi square t. So, the cumulative density function for the max of 2 sample values x 1 and x 2 coming from normal 0 1, is given by phi square t. So, then if you want to find the p d f, just this differentiate this, which would be twice phi prime t f t. So, phi prime theta will be nothing, but the normal p d f, which is given by this, so it will be twice phi t into 1 by root 2 pi e raise to minus half t square, so minus infinity to t. So, this one can, then you know integrate find out, whatever probability you are interested in. So, it looks like in that at least the, normal if your sample is from a normal distribution, or from uniform distribution, you can you know easily obtain p d f of the order statistics. in other cases also, one can see of course, there method for computing difficult integrals, by many other ways, by numerical methods. 
Now continuing with our joint distribution functions, and the other important parameters that we need to look at, and define here is; covariance variance of sums, and correlation. So, this will also have a lot of implication, and see here of the purpose of before I talk about, define the covariance and the variance, and then the correlation, simple proposition, which in fact, there was no need to prove it also, but I have written it down for completeness sack; x and y are independent, so if x n y r independent random variables. 
This is understood random variables, then for any function h n g. For any functions h n g, expectation of g x into h y, is expectation of g x into expectation of h y; that means, the independence carries over to, the function g x and h also. So, here this is the proof is simple, because if you want to write the expectation of g x h y, it will be minus infinity to infinity, minus infinity to infinity g x h y f x, y d x d y, but since x and y are independent, the joint density function can be written as the, product of the marginal densities. So, here when you write this as; f x and into f y, then I can even separate out the integrals, because it will minus infinity to infinity g x marginal of x into minus infinity to infinity h y into marginal of y into d y, and so by definition this is e g x into e h y. So, once we have this behind us, then we can talk of, define the, first of all the covariance. 
(Refer Slide Time: 31:30)
 
So, the idea of covariance between 2 variables x and y, is denoted by, this is the notation, and is defined by the covariance expectation of x minus e x into y minus e y, and if you open up this, if you expand this expression, this will be x y minus x e y minus y e x plus e x into e y, when I take the expectation inside, it will be expectation of x y. Then this will be expectation x into expectation y. Then this will be minus expectation y into expectation x plus this. So, one of them the 2 of these will cancel out each other, and you will be left with. So, this is a simpler expression to handle, when you are talking of covariance. So, it is expectation x y minus e x into e y, this is the definition of covariance, and let us see what does it indicate, or why do we. So, now if x and y are independent; see if x and y are independent, then e of x y will be written as e x into e y. So, then e x into e y minus e x into e y will be 0, so covariance. So, therefore, if x and y are independent, this implies that covariance x y is 0. 
But, unfortunately the converse is not true; that is, covariance equal to 0, does not always imply independence of the random variable. Very simple, I will tell you, that the converse of this result is not true. So, independence always implies that the covariance is 0, but if the covariance is 0, it need not imply that the variables are independent. So, let us see, we defining random variable x, which takes 3 value. So, probability x equal to 0, and probability x equal to 1, and probability x equal to minus 1 is equal to 1 by 3, so all 3 are equally likely. Then I am defining a random variable y, which is totally dependent on x. So, y 0 if x is not 0 and y is 1 if x is 0. 
So, now if you look at the values of this product, this will always be 0, because y 0 when x is not 0 and y is 1 if x is 0, so this product will always be 0. If the product is 0, so the random variable just takes only 0 values. So, then this expectation will be 0, because variable is taking all possible values as 0. So, this is expectation of x y 0, and you see from here expectation of x is 0. see x and z having the same p d f and c d f, does not imply the that x and z are dependent, but we see here that when given x, z can only take the values x and minus x, we have just see this, and therefore, x and z are completely dependent, because what will be the expectation of x. 
So, expectation x will be, so this 0. So, expectation of x is 0; therefore, from the covariance formula, this is 0, this is 0, so the whole thing is 0. So, covariance 0, but we know that x and y are not independent, yes x and y are not independent, if you want you can do this way, what was the. I mean, what will you use you will use, you can show that probability x y, because they are discrete random variable, so all possible values. 
So, in fact, x y takes all 0 values. So, therefore, here you have to show that. How would you want to go about doing it, normally for a discrete thing you want to show that for all possible values, of this product, the probability. So, for all of them, is not equal to the product of individual probabilities. But here you will have to yeah you will have to write out in detail, but anyway you can, as it is there is not much to really prove, because the way you are defining your y, it is totally dependent on x. So, that gives you the. So, therefore, covariance 0, does not in imply independents of the random variables.
(Refer Slide Time: 36:21)
 
So, continue with this, let’s take another example here; let x 1 be sine 2 pi u and x 2 is cos 2 pi u, so 2 different functions of a uniform random variable 0 1. So, u is your uniform random variable on 0 1. We consider random variables, obtained by taking functions sine 2 pi u and cos 2 pi u. Now, let us see, if functions sin 2 pi u and cos 2 pi u right now let us see if you compute expectation x 1, this will be 0 to 1 sin 2 pi u d u, which will be minus 1 by 2 pi cos 2 pi u from 0 to 1 which is 0, because cos 2 pi minus cos pi cos 0 both are 1. So, this becomes 0. Similarly, you can show that expectation of x 12 will also be 0, and when you compute the. So, therefore, the covariance of x 1 x 2, will reduce to, just expectation of x 1 x 2, but expectation of x 1 x 2 will be, you see sin 2 pi u into cos 2 pi u will be sin of 4 pi u divided by 2. So, again this is same kind of function from 0 to 1. So, that value will also be 0, but then x 1 plus, because x 2 will be 1 minus x 1 square under root. 
So, therefore, the covariance is 0, it does not suddenly imply independence of x 1 and x 2, which you can see otherwise also, because x 1 square plus x 2 square is 1. I will come back to this example in a while. Now, properties of some which we can immediately show; properties of covariance function. So, this is, first of all it does not matter, what order you write, covariance x comma y, is same as covariance y comma x, because this expectation of x minus e x into y minus e y. So, the order is not important. Then when you take both x and y to be the same, then co covariance x x, because that is expectation of x minus e x. So, square this will covariance x. 
So, therefore, this is equal to variance x, and if you take covariance e x comma y, then again by definition, because a will be here, a will be here also, you will be able to take it out, and it will be a times covariance x comma y. And then you can apply this principle in general, because we have already shown it for this, and then since because of this. So, you can show that if you take summation; sigma a i x i i varying from 1 to n sigma j varying from 1 to n v j y j. Then again, taking all possible products here, and covariance you can take it, because its expectation function which is linear. I can take it inside or the summation sign so this can be written as this, and then this is summation that will be outside, and then here this is a i b j will come outside, and this will be covariance of x i x j. So, this is the general expression, and I will show you nice application of this, after a while. How you can use this formulae to simplify some computations. 
(Refer Slide Time: 39:35)
 
Now, the moments you define the covariance function, you will be immediately have define the correlation coefficient rho, and we will see the implication and the usefulness of this parameter, so if x 1 and x 2 are two jointly distributed random variables. Then the correlation coefficient rho, is covariance x 1, x 2 divided by variance of x 1 into variance of x 2. Now, of course, this definition is valid, only when sigma x 1 and sigma x 2 are finite and. In fact, there should not be zeros, because if you are x 1 and x 2 or any of them is a constant variable, taking only constant values; that means, no randomness about it. Then your sigma x 1 will be 0, so you cannot divide by 0. So, this quantities is defined, only when sigma x 1 and sigma x 2 are finite, and they are not 0. In fact, this applies to your covariance function also, but expectation x 1 expectation x 2, should also be defined. So, in fact, I should when I defined the covariance function, I should have spelled out that the definition is valid, or as long as your expectation functions exists, are defined. 
Now, you can see, you can immediately see that here, the covariance function, the correlation coefficient, can be define nicely in this way, and once you define it this way, then it becomes dimension less, because I have standardize the way root x minus e x divided by define divided by the various standard deviation, and y minus e y divided by stranded deviation. So, this becomes. If you remember how this standardize your normal variate. So, the same thing we are doing, and once you do this then this becomes dimension less. Now, if you want you can try it out here, because see the covariance you are defining as expectation of x minus e x and y minus e y. So, this you are defining it is this. So, here also it is, and then for the covariance you simply taking rho x and then rho y. So, by this definition, I can take this inside, so there is no big deal. I mean I am not doing anything manipulation here, simply taking this inside, because we have already seen; that the constant can be take outside or inside, does not matter. 
So, therefore, now becomes standardize (( )). So, this is dimension less definition of the correlation. Now, we used the word. So, if see rho x 1 x 2 0; obviously, is possible when the covariance is 0. So, essentially when the covariance is 0, we use the word; that x 1 and x 2 are uncorrelated, and you have already seen, that 2 variables been uncorrelated, does not mean independence. So, therefore, we have coin this word; that 2 variables are uncorrelated, if and only if the correlation coefficient as we call it rho is 0. 
So, this is our terminology that x 1 and x 2 are uncorrelated, provided the covariance is 0 between the 2 random variables. And we will now through Schwartz inequality and so on I will show you, that the number rho, measures the relationship again between, it tries to show; co covariance simply showed you that, whether I mean if the variable are independent then the covariance is 0. Now here rho gives you much more information than that. It will show you that, see we will first of all show that rho is less than or equal to 1 always, because we have standardize the thing, divided by the stranded deviations, and then we will show that rho is equal to 1, then they are perfectly related the 2 variables. 
And this actually measures the relationship, but again here we will try to show you that, it may not always measure the. It may it may predict linear relationship very well, but not non-linear relationship, but so we will come to that. Anyway, so this is a very useful parameter, and here also I think the same example, I was trying to take, is that if your x 1 is x and x 2 is x square, so it is the square of x then. See this is the relationship between the 2 variables x 2 is equal to x 1 square, and the covariance will come out to be. So, covariance will be expectation of x 1 cube minus expectation x 1 into expectation x 1 square. Now if I take x 1 to be a variable, which takes 2 values x 1 is 1 and x 1 x 1 is minus 1, both the values it takes it probability half.
 Then you see expectation x 1 is also 0, and expectation of x 1 cube is also 0, because this will also be 1 into half, then minus 1 into half, and this will also be 1 into half and half n minus 1 into half, and this will be 0. So, therefore, your covariance is 0, so this will imply that your rho is 0. So, the variables you are saying are uncorrelated, but certainly they are not independent. Now, another immediate use of the word uncorrelated, we can show here, while computing the variance of sum of 2 variables, and this can might be extended to many more, you know when you have sums of more than 2 variables. So, here for example, the variance of x 1 plus x 2, you will define as x 1 minus e x 1.
(Refer Slide Time: 45:50)
 
So, now we will compute the expected value of x given Y, and therefore, the values of Y will vary. So, when you write this expression, computing it through conditional expectation of x, for different values of y. So, then this will be see conditional expectation of x given y equal to 1. So, that into probability y equal to 1 plus conditional expectation of x given y equal to 2 into probability y equal to 2 plus conditional expectation of x given y equal to 3 into probability y equal to 3, and this, because we have made these computation, so you see that 2.7 into probability of y equal to 1, which is 0.2 from here, and then plus 2.88 is the conditional expectation of x given y equal to 2. So, 2.88 into 0.5, which is 2.88 into 0.5 plus conditional expectation of x given y equal to 3, which is 2.833. So, that into 0.3, this is 0.3, and this adds up to 2.82 which is the same as this, which we computed from here. 
So, this is what I want to show you, and therefore, here remember even if somewhere in the text sometimes, you find that capital letter is missing, whichever the conditional. So, whenever we talk of expectation, then the whole idea is that; this expectation of x given Y, when I write the random variable here, then this is the random variable. And so I can talk in terms of expectation of this random variable, and this will be of course, the probability; that means, the value of e x given particular value of y. 
So, you compute this expectation, for a particular value of y multiplied by the probability of that particular value y, and then you add up for all possible values of y, and then you get this. So, therefore, you can break up the expectation x, also in this way. So, expectation x in other words we are saying, is expectation and then again expectation conditional y. e x 1 plus x 2 minus e x 2 whole square, and when you open up the square it will be x 1 minus e x 1 whole square plus x 2 minus e x 2 whole square plus twice expectation of x 1 minus e x 1 into x 2 minus e x 2. 
So, this is variance x 1, this variance x 2, and this is covariance x 1 x 2. So, now from here it follows, that variance of x 1 plus x 2, is variance x 1 plus variance x 2, if and only if covariance x 1 x 2 is 0. So, if and only if; like if covariance x 1 x 2 is 0 then you get this, and if you saying this variance is equal to this, then covariance must be zero. So, this is if and only if relationship, and for this result to be true, it is not necessary x 1 x 2 to be independent. See earlier we had talked of independence, then I talked of some of 2 independent random variable. I had shown you that this will be equal to this. But now we are saying, since we have different find this term uncorrelated. So, what we are saying is, that for variance of x 1 plus x 2, to be equal to variance x 1 plus variance x 2. It is enough that the covariance is 0 or the variables are uncorrelated. It is not necessary for x 1 x 2 to be independent. It is enough, if x 1 and x 2 are uncorrelated. I cannot write it here, but this is uncorrelated. So, this is one advantage, one use of this function. We will talk about this some more in the next lecture.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 18
Conditional Expectation Best Predictor

(Refer Slide Time: 00:15)
 
I will continue with the example, I was discussing at the end of lecture seventeen. So, this was the conditional p d f of x 1 2 given equal to x 2, and you are given the marginal of x 2 also. Then we had to find constant c 1 and c 2; of course, the criteria’s that they should be, they are p d f. So, the integral in the specified region must be one. So, we made these computations in the in last lecture. So, by saying this integral 0 to x 2, because given n and x 2 when you draw this, your x 1 will be varying around 0 to x 2, because this is the region of integration. So, 0 to x 2 integral, this equal to 1 implies c 1 is 2. Similarly by integrating this from a 0 to 1, because of this marginal of x 2, then this comes out to this gives us c 2 equal to 5. So, the joint p d f of x 1 and x 2, will be conditional of x 1 given x 2 into the marginal of x 2. So, the product of the 2, which we already have now with us, since we have computed c 1 and c 2. So, that will be the joint p d f of x 1 and x 2, and that we also computed as 10 x 1 2 square, where the range for x 1 from 0 to x 2 and x 2 varies from 0 to 1. Now, is this a p d f surely, because it is a product of 2, this we have verified as a p d f, this we have verified as p d f, so the product must also be a p d f. So, there is no need to verify this again, though if you want you can integrate, respect to x 1 from here to here, and for x 2 0 to 1, and you can show that this is a integrate, so double integral will come out equal to be 1. 
So, now we have to find in that number three, is compute the probability of x 1 between point 2 five and point five. So, to do this, I need to compute the marginal of x 1 marginal p d f of x 1, and that will be taking the joint p d f, and here you will be integrating respect to x 2, so given an x 1 this is the line, and therefore, your x 2 will vary from x 1 to 1. So, this is the range for x 2. So, x 1 to 1 you integrate the joint p d f, to obtain the marginal p d f of x 1, and so this comes out to be. So, you integrate in respect to x 2. So, x 2 cube by 3 10 x 1, so this is the a expression for the marginal. So, once you have the marginal for x 1, then you want integrate again the marginal from 1 by 4 to 1 by 2, to obtain the probability, and the number that I get is this. So, maybe you need to simply this further, and get the right answer. Then fourth one required you to find the conditional probability, of x 1 given x 2 is 5 by 8, so this is for again 0.25 to 0.5.
(Refer Slide Time: 03:28)
 
So, the conditional density function we already have; which is c x 1 upon x 2 square, but x 2 is given to 5 by 8. So, we have to integrate this from 1 by 4 to half 2 x 1 upon 5 by 8 whole square d x 1. So, here this is the simple these things x 1 square by 2 which is 1 by 4 to half, and what you get is, 12 by 25, but now since we have also talked of conditional expectation, I thought we will include that part also here. So, for example, you are asked to find the expected value of x 1 given x 2 is equal to x 2. So, you will find out the expectation here; that means, it will be the joint p d f it will be the conditional p d f of x 1 given x 2 equal to x 2, which is 2 times x 1 upon x 2 square, and since you are finding the expectation here with respect to x 1, so it will be 1 into this. So, this is the integral, and of course, 1 varies from 0 to x 2. And you are integrating with respect to x 1. So, 2 by x 2 square come outside, and then this will be 1 square, so which is x 1 cube by 3 and 0 to x 2.
So, you simplify and this is the expression 2 by 3 x 2 which is a function of x 2. So, which is to be expected, because in this integral you are integrating with respect to x 1, and the limits of from 0 to x 2, and since x 2 is given to be 2. So, this will turn out to always be a function of x 2, when you are finding expectation of x 1, given x equal to x 2, which I mentioned yesterday also we defined. Now this is a straight line passing through the origin. So, the expectation that comes out is a function of x 2, and this is a straight line passing through the origin. So, that means, here the relationship is linear; that means, the expectation of x 1 given x 2 equal to x 2, is a linear function of x 2. then therefore, follows that expected value of x 1 given x 2 X 2, will be 2 by 3 x 2, will be a random variable. See the whole idea here is, that this was repeated earlier also, what we are trying to say here is, that for a particular value of x 2 this is what you get, the expectation value of x 1, slash conditional x 2 equal to small x 2. 
Now, as values of x 2 vary, then this becomes the expected value of x 1, condition on the random variable 2. So, the notation that we called it 2 by 3 X 2, so this is a random variable. So, for the different particular values of x 2, we will get the expected value from this formula, this is the whole idea right. And therefore, since this is now a random variable, we can again talk about the expected value of here, and I had done this even earlier, in the last lecture also the same thing. So, therefore, the expectation of x 1 condition on x 2, will be just the 2 by 3 into a expectation of x 2, which will by the formula would be, you know integral 2 by 3 0 to 1 2 f x 2 x 2 d x, and this will turn out to be the expected value of x 1. So, when you take first expectation of x 1 condition on x 2, and that comes out to be a function of x 2, then you take expectation again, and then you will get the expectation of x 1. So, this is idea being repeated in the last lecture, and I have asked you to verify. So; that means, you will have to compute the marginal of x 1, and then which I think you already here; yes that say conditional p d f. So, you will have to compute the marginal of x 1, and then find out the expected value of x 1 independently, and verify that this it comes out to be the same, what will get from here. Further I will continue with this concept, and take another example to make these things clear, try to do it.
So, this was an example I got from the net; roll a die, until we get a 6. So, this is the experiment. You continue roll a die, until you get a 6. And let y be the random variable which is equal to the total number of rolls, till a 6 comes up. So, you continue rolling the die till a 6 chose up and then you stop. So, and x is the number of, once we get in this process. So, when you are rolling a die, you keep noting also the number of times 1 appears, and then of the experiment stops the moment a 6 comes up. So, x is the number of once you gets in this process. Now, you are asked to compute expectation of f x given y is equal to y; that means, the number of times you have to roll the die, is small y, and then this process you want to compute the expectation of x, given that you had to roll the die y number of times.
(Refer Slide Time: 08:38)
 
So, Y equal to small y means; that there were y minus 1 rolls the die, which one not a 6. All the numbers are appeared, but the 6 did not appear, because the experiment will stop the moment 6 appears. So, y minus 1 rolls did not show a 6. Now, therefore, you see an x is the number of once that comes up, before the experiment ends. So; that means, in this showing that you get, the y minus 1 rolls that you made of the die; x is the number of ones that show up. So, when you can treat x as a binomial random variable, with the number of experiment as a y minus 1, and the probability of occurrence of a 1 is 1 by 5, because remember up to y minus 1 rolls 6 is not appearing. So, and the other five numbers are equally likely. So, the probability of 1 showing up, is 1 by 5, and the number of experiments that you make is y minus 1. So, we will treat occurrence of 1 is success, and occurrence of 2 3 4 5 as a failure, and therefore, x can be treated as a binomial random variable, with n equal to y minus 1 and p equal to 1 by 5. So, you see the whole idea, is that how you can compute a certain quantity that is required, by just realizing how the experiment has been conducted. So, therefore, immediately you can say expected value of x when y is given to be small y, is slimily because for a binomial random variable, the expected value is n p. So, n here is y minus 1 and p is 1 by 5. So, without any hassle, we get to the expected value; the conditional expected value of x given y is equal to y.
Now, this is again a function of y; that is as y takes values possible values 1 2 3 and so on, the points 1 by 5 y minus 1 will lie on this straight line, expected value of x by y; that means, conditional expectation of x given y capital Y is a random variable. Now conduct the experiment and get an outcome omega; that is omega is string of 1 2 3 4 5, ending with a 6. So, like we conduct the experiment we keep rolling a die, till we get a 6, and we record the outcomes at each roll of the die. So, it will be string of these numbers, ending with the 6, so omega is that. Then you compute how many numbers are there in the string, so that means, how many times we have to roll the die. So, now you can say that y small y is the value of Y at omega, because omega represents a string, and y counts the number of elements in this string. So, this is actually our relationship small y is Y at omega. So, y is number of rolls of the die to get a 6. So, y omega is a random variable, surely because this can go on depending. I mean when the 6 shows that is not a certain event, so there is a chance element here, and therefore, y omega is a random variable, and then you compute the expectation of x given y equal to y, which we did right now. so; that means, you are relating omega with this, because given a omega you computed the y, and then you compute the expected value of x given y equal to y.
So, that is expectation of x given y equal to y is a mapping; that maps omega to 1 by 5 y minus 1, and remember I defined a random variable also is a mapping, because as I said random variables associate, with the sample base real numbers. So, here also what you have to happening is that, this expected value of x given y equal to y is a mapping that maps omega to this, where y is capital Y omega. So, therefore, omega is mapped to 1 by 5 y omega minus 1, which is a random variable. So, now when you write capital Y omega. So, the idea was to explain to, again in a different way why we are saying that this is a random variable, though it should be clear, because as values of y change. There is a probability associated with what value y takes, and therefore, this is again a random variable. You can go ahead and makes some more computations; for example, if you look at variance. So, again the conditional variance of x given y equal to small y, I know because I have said that x is a binomial random variable, so this number I know, and for this number also I know. So, if you want to compute expectation of x, is square given y equal to y, then this minus this is equal to the variance. And therefore, I can say that, yes and this is equal to n p q, by the binomial formula, so p q and n. So, 1 by 5 into 4 by 5 into y minus 1; so 4 by 25 y minus 1 is the variance, and expectation x given y equal to y, we already computed as 1 by 5 of y minus 1. So, therefore, expectation of x square given y equal to y, is variance plus this, which is 4 by 25 my y minus 1 plus 1 by 5 y minus whole square, which is 1 by 25 into y minus 1 whole square. So, when you simplify this expression you get this y minus 1. So, this is a quadratic function of. I should say here quadratic function of small y.
(Refer Slide Time: 15:00)
 
So, the random variable represented by expectation x is square given capital Y, is a random variable, which is this. So, this becomes a quadratic function of y. So, I hope this gives you a little inside into, what we mean by. And now another roll that a conditional expectation place, is as a best approximation. Conditional expectation as a best approximation, and I thought we should talk about this to, give you some more feeling, and this is value of the random variable is observed. So, suppose a value of random variable is observed, and based on this observed value, an attempt is made, to predict the value of a set second random variable y. see sometimes maybe easier to observed value of the certain random variable, and then if based on that observed value, you can makes some attempt to predict value of another random variable, that helps you, because then you do not have to conduct another experiment, to obtain value of y, but of course, the value that you predict from knowing the value of x, may not be the exact one. So, let g x denotes this predictor. So, suppose, so some function of the random variable x. So, this denotes this predictor, so that is x equal to x is observed, and then g x. So, g of small x, is our predictor for the value of y, so for one value of y, and then you observed another value of capital X and g of, that value of x will give you another a predictor for the value of y, so this is the idea.
Now, how to choose g, because you have to have some concept, as to what is the g that is acceptable to you; of course, the quality that g must be possesses, that it should be as close as possible to y. So, now, whole idea is, what do you mean by closeness here, and how can we define. And of course, later on also, when we talk of limits and so on, and conversions and probability in law, these things become more clear. But right now, that we say that our criteria criterion is to minimize, expectation of g x minus y whole square. So, this is my criterion, then I want to choose that g, which minimizes this expectation g x minus y whole square. So, expectation of this should be as small as possible. Now, we will show that g x equal to expectation y condition on x is a best choice. So, this is a whole idea, and therefore, you see another roll that the conditional expectation place, and the proposition is. So, we want to show, that expectation y minus g x whole square, is greater than or equal to expectation y minus expectation y given x whole square. So, then this will establish, that this is a smallest value of this, and therefore, the best choice for g is expectation y given a conditional for expectation y given x. So, we will just prove this proposition for you.
(Refer Slide Time: 18:37)
 
So, before we proved this proposition, I will like to state a theorem, and fact that proof is also straightforward. So, the theorem says that if x and y are 2 jointly distributed random variables, and h x is a function of x, whose expectation exists. So, then if you have the conditional expectation of f x given y and then we take the expectation again, this will come out to be expectation of h x. Now this is on the same lines as if you say that expectation of x given y, and then you take the expectation again. So, this is E x, remember we have already shown this result. So, on the same lines we are trying to show that, expected value of h x conditioned on y, and when you take the expectation again it will come out to be expectation of h x provided of course, the expectation of h x exists.
So, I have just written down for the continuous case. I have just written down the expression for x expectation of the expectation of conditional of h x on y, then it will be minus infinity to infinity minus infinity to infinity h x. the conditional p d f would be f x y x y divided by f y, because this condition on y, and then since you this turn out to be a function y. So, when I take the expectation again it will be f y y d y d x, and this you can see that, this will cancel out, and it will get expectation of h x. Now, similarly the result can be stated, that if you take a function g of y and then condition on x, then just reverse the rolls of x and y, and then you will get here a expected value of g y; that means, your expected g of y condition on x, this will turn out to be expected value of g y. provided of course, a expectation g y exists. So, this is this and then proof, in case x and y are discrete random variables, you can just imitate the proof for the continuous case. So, once this theorem is there, we will be using it in to prove this proposition. So, let me now consider the proof of the proposition.
(Refer Slide Time: 20:59)
 
So, this is I am considering y minus g x whole square, condition on x, and because my proposition I am taking condition on x. So, now, add and subtract expected value y by x you was in the bracket. So, then this is expected value of y by x plus expected value of y by x minus g x whole square condition on x, open up the brackets. Then this will be y minus E x y by x whole square, condition on x expectation of that plus the square of this expected value of y by x minus 0 whole square. Then condition on x expectation plus twice a product of these 2 terms. So, say the condition on x separately, and then the expectation of that. So, twice E of that. So, then let me call this, equation as a star, denoted by star
Now, see for given value of x equal to x, this will be a function of x. remember we have shown you that the expectation of y condition on x. So, for a fixed value of x it will be a function of x. So, for the purpose of taking this expectation, because that expectation with respect to, ya this will be ya. So, therefore, I can treat this as a constant, and so this comes out to be expected sign. So, this is a function of x and hence can be treated as a constant. So, because I will be computing it for different values of x, this thing, and for every fixed value of x, this will be a constant. So, I can take it out of my expectation. So, therefore, y minus E of y by x condition on x into expectation of this, I can take this outside, and then this will be expectation y minus expectation y by x condition on x.
Now, here again, you see when you bring x inside, it will be y by x y condition on x and this does not change, because this is already on condition on x. So, this will become expectation of y by x. I mean this of course is outside. So, this portion will be expectation y by x minus expectation y by x, which is 0. So, therefore, the in the star expression this portion has no contribution, this is equal to 0. So, the right hand side, this reduces to simply the, expectation of y minus expectation y by x whole square condition on x, this expectation of expectation y by x minus g x whole square condition on x. So, this is what you have.
(Refer Slide Time: 23:52)
 
And since for a given value of x y minus g x is a function of y. Therefore, by the theorem above; this will be a function of y only, because this will be a constant for every fixed value of x. and so by our theorem, expected value of expected value y minus g x whole square condition on x. So, for different values of x, this will be a function of y only. So, for each fixed value of x, it will turn out to be expected value y minus g x whole square, and then for the whole different values of x to the whole thing will become y minus g x, expectation of y minus g x whole square. See it is a same concept scalding over. And similarly expectation of y minus expectation y by x whole square condition on x, will turn out to be expectation y minus expectation y by x whole square. I mean this whole square and then the expectation; this is what we are doing. So, you get that when you you know you have this because this is equal to zero. So, I got yes, where is the greater. So, the right hand side, when I take the expectation, I get; see we started out from here, you started out from here, and then this got 0, then I took expectation of both the sides. 
So, this became expectation of y minus g x whole square, and this became expectation of y minus expectation of y by x whole square plus expectation y by x minus g x whole square. So, the conditional things disappeared, and since this expectation of squares are non-negative. So, therefore, I can this, because this portion; the expected value of y by x minus g x whole square, this will non negative, y by x minus g x whole square this will be non-negative. So, therefore, my equality will be convert into an inequality, and this what you have. So, this is what we are trying to prove, at you know for any function of g x for any function g of x, if you take this expectation y minus g x whole square. Here again if you want to put this, then this will always greater than or equal to expectation of y minus expectation y by x whole square, expectation y by, and this whole square expectation of that. I should first say y minus expectation y by x whole square and expectation of that. So, this is what we wanted to prove.
So, in order words you see the process, that you are observing value of x, and then computing the expectation y given x, and in the earlier lecture when I had considered, define this conditioned expectation, and conditional expectation and taken this discrete case. So, I showed you how, you change keep changing values of x, then you will compute the expectation y given x. So, this in a way we are treating as a good approximation for the value of y, and when we are when our criteria criterion is, in terms of minimizing this expression, then; obviously, no other function of x, will qualify to be the best predictor, except for the expectation y given x. So, in this way we are treating or showing that this can be also looked upon as a very good approximation, for the value of x. So, for the different values of x will compute this, I mean we will observe possible values of x. All possible values compute this, and this will give us the different values for of y. so; that means, you can compute this expectation, for. Well, yes there is, still a few questions which I are not answered, and hopefully we will continue, looking at this again.
(Refer Slide Time: 28:11)
 
Now, take this example, you can show that for any real number a. In fact, what we have shown here, can be also. you know This you can show very easily, that expectation of x minus E x whole square, is always less than or equal to expectation of x minus a whole square, for any real number a. and you know the same thing here, you will write minus E plus E minus a, open up the square and so on, and then again one part, when you look at this thing E x minus a. So, this is the constant, and therefore, when you are taking the expectation of the product term, this will come out, and see the second factor will be expectation of x minus E x, which will be 0. So, for the same reasoning, you can show that this is always a less than or equal to this. So, you can do this for, any real number a.
Now, look at the, example of bivariate normal distribution of x and y, and we have already looked about this p d f, which is you know in terms of sigma x sigma y and rho. So, these are correlated, because; I mean I am just taking the general case, x and y are not necessarily independent. So, this expression, in exercise 5 of and question 10, I asked you to show that conditional distribution of x, given y equal to y, is again a normal p d f with mean this, and variance equal to rho square. Now why am I writing rho square, this should be sigma square. sorry  So, this will be sigma square into 1 minus rho square. So, this is your mean, and that is your variance. So, therefore, expectation of given y equal to y, will be this mean, because this is for capital Y equal to small y. So, this is mu x plus rho into sigma x upon sigma y y minus mu y, which is again a linear function of y.
(Refer Slide Time: 30:28)
 
So, what we have found is that, when x and y have a bivariate normal distribution, the best overall predictor, because according to our proposition, of x with respect to y, turns out to be, mu x expected value of x condition on y, is mu x plus rho sigma x upon sigma y into capital Y minus mu y, and this turns out to be linear in y. So, that is all we can say that the best overall predictor, in case x and y are bivariate normally distributed, then the best overall bivariate of with x respect to y, is this expression which is the conditional expectation of x given y. It turns out to be this, and this is linear in y. So, this is all what we can say, or to talk of this linear product linear predictor and so on; that is another thing, that we have to go about it in a different way, and I have to first defined what we mean by linear predictor and so on. So, right now all we are saying, is that the best overall predictor, in case x and y are both normally distributed; that means, they have a bivariate normal distribution. Then the best overall predictor, would be a linear in y. And similarly if you are talking of the best overall predictor of y with respect to, and that will be linear in x.
Now, let us just further continue talking about a conditional expectation. So, now, we will show, that expectation x y is expectation x into expectation of x expectation of y given x. So, this is what a simple calculation we will do. Now here of course, I have not written out all the steps. So for example, when you want to write expectation x y, so actually the starting expression will be x y into the joint d x d y. So, this is the thing, but as we have seen that the joint p d f of and y, can be written as a product of marginal of x into the conditional of y given x. So, therefore, this is what I am writing here. So, expectation x y. I am writing as x y f x x into f of y given x, d x d y.
Now, the thing is that. So, y integral y into f y by x conditional this, conditional p d f of y given x. So, this I can separate out, and I can write this as y, because this is not of, when I integrate this is given value of x is fixed here; f y given x. So, X into small x so I integrate this respect to y. And then, so I can just separate out this double integral into minus infinity to the infinity x f x, and then this will come out to be a function of x. So, then that whole thing I will integrate as a function of a d x, and so you can immediately see that this is expectation y given x, and then x times f x this gives you expectation of x into expectation of y by x. So, simple calculation, but again just emphasizing the fact that, this is a random variable, and therefore, becomes a function of x, and so you compute this expectation again, and you get this. So, you know you were using a conditional expectation to compute expectation.
Now, let us go through this exercise for computing rho, and of course, for different situations you can use different techniques to handle it. So, now here if you are given x and y, have a bivariate normal distribution, so this is mu x mu y sigma x square sigma y square and rho. So, this is the bivariate normal distribution, and you are given that a rho is greater than zero. So, you have to find the conditional expectation of y between 4 and 15 given x is equal to 5. I am sorry I mean you are given that this probability is equal to 0.954 you have to determine rho. So, rho is the unknown here, and therefore, you want to determine that. Now, from our this result, that x given y is this. So, what will be this thing. 
(Refer Slide Time: 35:21)
 
So, from here only you can write here, that expectation of y given x, this will be mu y. we just replace x y by y mu y plus rho sigma y by sigma x, and then this will be x minus mu x. So, this is the formula which, I have written it already. So, this is mu y plus rho times y upon sigma x into x minus mu x; that will be this. And then since x is given to be 5 and mu x is also 5. So, therefore, this part is 0, and so expectation y when x is equal to 5 is 10. So, the conditional expectation y or the mean is 10. So, y by x is normally distributed, with mean 10, and the formula for the variance would be. So, variance formula for the variance y given x equal to 5, is rho y square 1 minus rho square, which is 25 times 1 minus rho square. So, this is the variance, therefore, this is what I have written here. So, this is normally distributed, with mean 10 and variance 25 into 1 minus rho square. So, therefore, I will standardize, usual thing that we do. So, now, computing this probability, I will standardize the a variate here, which means I will subtract 10, and divide by the. So, divide by the standard deviation. So, standard deviation is 5 under root 1 minus rho square; this is what you have. So, this becomes a 6 by 5 under root 1 minus rho square. So, this is the c d f for the, probability less than or equal to this.
So, therefore, I mean the cumulative density function, for the standard normal. So, this minus this is minus 6 this, and again from symmetry of the standard normal distribution, around the origin. We can write this as twice phi of 6 upon 5 under root 1 minus rho square minus 1, because this can be written as 1 minus of phi of 6 upon 5 under root 1 minus rho square minus sign outside. So, therefore, this is what you get, and you are given this is equal to 0.954 or a 6 upon this, is equal to 1.954 by 2 which is 0.955. So, if you look up these standard normal tables, the value of z which corresponds to 0.977 is 2; that mean, phi of 2 is 0.977. So, this you can obtained from the tables, for the standard normal and. So, this means that this number 6 by 5 under root 1 minus rho square should be equal to 2. So, from here, you do a simpler arithmetic square everything, so you get 136 a 1 minus rho square is 36 upon hundred. So, rho square is this. So, the absolute rho is 0.8, but you are given a rho to be positive, and therefore, we will take a positive value from here, which gives you rho is 0.8. So; that means, x and y are positively correlated. If rho was minus 0.8, then we would say that and y are negatively. So, the relationship between this. Of course, throughout this we have also been able to establish, that your correlation coefficient or the covariance can measure effectively, linear relationship between the variables, but it fails to show you a quadratic relationship and so on, so we saw that.
(Refer Slide Time: 39:32)
 
So, this comes to sort of our treatment of a conditional expectation, and how this can be used, for computing various things. In fact, for computing your actual this thing, because we have shown other that this result also expectation, is expectation x and so on. And then here this result we have obtained for you, and then I have also shown you the roll of a conditional expectation as a best predictor, so this is it. Let me now discuss exercise 6 with you, which is related to what all we have discussed in the last three lectures.
(Refer Slide Time: 40:12)
 
So, a fair die is rolled three times. There should be a full stop instead of comma. Let a random variable x i be equal to the number that appears on the i th trial, for i varying from 1 to 2 3, and then we defined y as the max of x 1 x 2 x 3, so the largest numbers. So, up to on the die has been rolled 3 times, then you record the numbers that were that show up, and then you take the maximum one. So, y is the value of the maximum of x 1 x 2 and x 3. Find distribution function and probability density function of y. So, the distribution function means; cumulative distribution function, and probability density function of y. So, this is question one. Question seven consider the joint probability density function of x comma y, given by f x y of x comma y. So, here it should be x and y as suffixes are the bigger the capital one and small x y is equal to 2 minus x minus y x between 0 and 1 and y between 0 and 1 0 otherwise.
Now, here a part three, I want you to find. So, part 1 says, find the conditional probability density function of y, given X equal to small x, and then in part 2, I want you to find the expected value of y given capital x equal to x and E y. Then three I want you to find out E y, though. I want you to show that E y is actually equal to E conditional expectation of y given x. So, what we have been doing in a lecture also. We have been verifying, you know we have been computing E y independently, by first computing the marginal of y, and then its expectation, and secondly, by breaking it up into first the conditional probability conditional expectation of y given x, and then we take the expectation again. So, you have to say that the 2 processes redo the same answer.
Now, question two I already discussed with you in the lecture. So, you can have an alternate expression for the correlation coefficient, when x and y are given to be 2 random variables. Question three, is that x and y have the joint probability density function f x y equal to one. So, y lying between minus x and x and x between 0 and 1, so please be careful when you draw the boundaries for y, because you see 1 boundaries y equal to minus x and other is y equal x. So; that means, your y varies from. I hope you can just make sure that. So, you can, see along the x axis, you will have 1 line, y equal to and the other will be in the in the fourth quadrant y equal to minus x, and therefore, your y will be vary from minus x to x. So, this is what you have to careful.
And then you have to draw the graph of. So, given the joint density function, you will compute the conditional, because you have to draw the graph of expectation of y given x equal to x, as a function of x. So, you know how to do it. You have to compute the conditional p d f, and then compute the expectation y given x equal to x, and also you have to draw the graph of. So, find out both the conditional p d fs; conditional p d f y given x, and conditional p d f x given y as a function of y. So, you get some feeling about the. Question four. So, suppose the conditional probability density function of x 2 given x 1 equal to x 1, is given by this function. This is the conditional p d f, so x 2 positive, and its 0 otherwise. So, the reason on which it is defined. So, x 1 equal to x. and that f x 1 a marginal of x 1, is also given by this function, where x 1 is positive. So, both the variables are supposed to be positive, take positive values, and so again I want you to find out expectation of x 1 given x 2 equal to x 2, and then also find expectation x 1, and correlation x 1, x 2. So, you should be able to do it, because you have all the tools and this thing.
Question five; x 1 comma x 2 to be a 2 dimensional discrete random variable about are 2 discrete random variables with joint probability functions. So, now, you have to compute correlation x 1 x 2, and are x 1 x and 2 independent random variables. So, remember even if your correlation coefficient is 0, it will not necessarily imply that x 1 and x 2 are independent. So, to verify you will have to compute the you know show that for, or find at least 1 pair of values of x 1 and x 2 for which the probability x 1 equal to that number and x 2, equal to a particular number, is not equal to the product of individual probabilities. If you can show that, then you can conclude that x 1 and question 4 not independent, but otherwise you will have to go on verifying for all possible pairs, which means you have eight pairs. So, for eight pairs if you can show that the probability of the product, is equal to the product of the individual probabilities, then you can conclude that they are independent. For the discrete case, this is the only way you can do it.
(Refer Slide Time: 46:19)
 
Question 6; using the result that we just obtained this result for I just obtained it for you, that expectation or I am sorry here there should be no comma. So, expectation of x y. So, p is removed the comma expectation x y is equal to expectation x into expectation y given x. So, I just proved this result for you. Now using this result, show that covariance, again here this is x, expectation y given x is covariance x, y. So, the comma in the last 2 terms is, but here when you saying the result is expectation x y. So, comma is to be removed, therefore, you can use this result, or show this result, using what we have proved just now.
Question seven consider the joint probability density function of x, y given by f x y of x comma y. So, here it should be x and y as a suffixes are the capital once and small x y, is equal to 2 minus x minus y x between 0 and 1 and y between 0 and 1 0 otherwise. So, part 1 says find the conditional probability density function y given X equal to x, and then in part 2 I want you to find the expected value of y given X equal to x and E y. Then three I want you to find E y, though I want you to show, that E y is actually equal to E a conditional expectation y given x. So, what we have been doing in the lecture also. We have been verifying, you know we have been computing E y independently by first computing the marginal of y, and then its expectation, and secondly, by breaking it up into first the conditional probability a conditional expectation y given x and then we take the expectation again. So, you have to say that the 2 processes redo the same answer.
Question eight; is x y z are 3 random variables and a and b are 2 constants, proved that covariance of x comma a y plus b b is this. So, I had done for you when the constant a was with x, now you please do this, you should not be, because remember. In fact, you can immediately do it, because covariance x comma a y plus b is covariance a y plus b comma x and therefore, from that result, but then I have added up plus b here. So, please work it out, and show that this result is true. Then the correlation coefficient of x comma a y plus b, there will be no, because you see a numerator there will be a from here, and then in the denominator also when you take the variance of a y plus b, a will come out and. So, the a a will cancel and of course, a has to be positive here, because in the variance you will take out a, only if a is positive otherwise you have to take out absolute of a.
So, let x 1 x 2 x 3 be 3 independent random variables, each with variance sigma square. So, there are three independent random variables with the same variance, if we define new random variables. So, here w 1 is x 1 w 2 is root 3 minus 1 upon 2 of x 1 plus 3 minus root 3 upon 2 of x 2 and w 3 is a linear combination of x 2 and x 3 show that a correlation coefficient of between w 1 and w 2, is equal to the correlation coefficient between w 2 and w 3, which is equal to half. While w 1 and w 3 are uncorrelated. So, I just try to I mean the purpose of giving the exercise was that you see that, taking this linear combination some turn out to be correlated, and some pairs turn out to be uncorrelated. So, this is what you have to show.
Now, tenth question is a fair die is successively rolled, and let x and y denote respectively the numbers of rolls necessary to obtain a 6 and a 5. So in fact, the 6 part we discussed took at length and now. So, you are asking for. So, is the number of rolls required, till a 6 shows up and y is the number of rolls required until a five shows up. So, now, find expectation x so; that means, you will write down the probability match functions for x and y, and then compute E x, compute conditional expectation of x given y is equal to 1, and conditional expectation of x given y is equal to 5. So, it should be easy computations; once we have already handled the case, when you had to roll the die till a 6 showed up.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 19
Inequalities and Bounds

(Refer Slide Time: 00:15)
 
So, the next topic we want to talk about, is inequality, statistical inequalities. And of course, one we have already seen, which is the Cauchy-Schwartz inequality, but there some other important, once which we will talk about now. Now the role of inequalities, is that you get bounds on probabilities of certain events, and this is different from the approximation, because the inequalities make a very definite statement. So, it is a definite fact about randomness. You have some event, and you want to you are able to say that, the probability of this event, will be less than or equal to a definite number. 
So, you give a bound, lower bound upper bound, whatever is possible. Mostly we will see that we talk about upper bounds. And of course, another thing is that, this is different, the inequalities give you information which is different from approximations, because approximation may be good bad, but here the inequalities trying to tell you, the probability of a certain event, is less than this particular number, which the approximation does not says. Approximation says that the probability may be this, and then depending on.
So, therefore, they have a very definite role to play; the inequality, in your statistical analysis of data and so on. So, see what happens is that when, in the absence of much knowledge about the distribution of sample values, you take different kinds of samples, and then you do not know much about the distribution of the population from which you are taking the samples. And then to derive bounds for probability of events, you know depending on the sample values, is is very helpful, and that is what we do through this inequalities. So. In fact, it may just happen that we may know, the mean or the variance of the population with the sample values are coming, and that is it, we may not know the nature of the distribution exactly. So, then it helps to, be able to compute bound on the probabilities of certain events.
So, the first one, simple one is Markov inequality, and this the statement, is that the x is the random variable, that takes only non-negative values. Then for any real number a greater than 0; probability x greater than or equal to a, is less than or equal to expected x upon a. And this is not difficult to prove, because if you are now define this indicate valuable where variable. So, which takes value 1, when x is greater or equal to a and 0 otherwise. so; that means, yeah. So, now, when you write x greater than or equal to a. This implies that 1 is less than or equal to x by a; that is and since i is equal to 1 whenever x is. So; that means, I can write that i is less than or equal to x by a. Now taking expectation of both sides. So, when I take expectation of both side, I get expectation i which is less than or equal to expectation x by a, but expectation x by a is 1 by a expectation x. So, this I am just relating the 2 random variable i and x. So, this is 1 by a this. And expectation i would be, because this is i is equal to 1 with probability x greater than or equal to a. 
So, expectation would be 1 into probability x greater than or equal to a plus x equal to i equal to 0 into probability that x is less than a, but since i is 0, so that is no contribution. So, expectation i is actually equal to probability x greater or equal to a into 1. And where did we use, the fact that it’s non negative variable. I used it from here, saying that if I is less than or equal to x by a. then the expectation will also, when I take the expectation of both sides, the inequality will remain intact. And therefore, this is less than or equal to 1 by a E x, or probability x greater than or equal to a is less than or equal to 1 upon a into expected x. So, you see if for this event, just knowing the expectation of the random variable, I can compute a bound for the probability of this event, which is given by 1 by a into E x.
(Refer Slide Time: 05:10)
 
Let us look at the Chebyschev's inequality, which says that if x is the random variable, with finite mean u and variance sigma square. Then for any k positive, expectation of x minus mu, absolute value greater or equal to k. it should not be expect probability. Chebyschev's inequality is for giving an upper bound on a certain probability, which is probability absolute value of x minus mu greater than or equal to k, is less than or equal to sigma square upon k square. So, mean excess of mu and its mean. So, when you take. So, actually this can also be written as expectation of x minus mu whole square and then divided by k square. So, that is the variance. And of course, I do not need the absolute sign once I have taking square. 
So, it is this is the actually expectation of, whatever the function here. So, you were taking x minus mu. So, expectation of this whole square divided by k square. So, we are defining this for mu as the mean of x and k some positive number. So, this is the inequality. So; that means, this gives you a bound. The inequality gives a bound on this probability, which has to less than or equal to sigma square by k square. Now we will use Markov inequality to probe this, we just this Markov inequality. So, now, let me define y as x minus mu whole square, and this will be therefore non negative, and the Markov inequality requires, is define for, is valid for random variable which takes only non negative values, which is greater than or equal to 0, and will take a to be k square.
So, then the Markov inequality will give us, that probability x minus mu whole square, greater than or equal to k square, is less than or equal to expectation of x minus mu whole square by k square, expectation of this divided by k square; E x. So, this is E x by a, where this is a and this is your x. So, then I am writing expectation my x is x minus mu whole square. So, expectation of x minus mu whole square by k square. So, by markov inequality this is this and then you are saying because my a k square and my x is x minus mu whole square. Now, just see that this event x minus mu whole square greater than equal to k square, holds if and only if this holds. Since, k is give taken to be positive, so if this is true than this is true, if this is true then this must be true. So, if the other same events and therefore, I can replace this probability by the probability, absolute value of x minus mu greater or equal to k. This is less than or equal to sigma square by k square. So, the inequality is established, and then we will through examples and so, we will the various ways in which this simple inequality can be used. 
Now, the thing another, just want to make a note here that, often we are asked to obtain bound for a probability like this, which has a strict inequality. So, this is probability of x minus mu absolute value of x minus mu greater than k. But then we know that this probability is less than or equal to probability of absolute value of x minus mu greater than or equal to k, because you are taking a bigger subset here. So, this probability is bigger than this probability, and hence and since we have a bound for this, through Chebyschev's inequality. 
So, the bound is also valid for this probability. So, that mean we can say that probability mod x minus mu greater than k, is also less than or equal to sigma square by k square, this is a whole idea. And through when we discuss many examples, it will turn out that we have to actually compute, this bound for this probability. So, we will see that, this can be again estimated by, not I should not use the estimate because this probability is less than or equal to this, and Chebyschev's inequality gives as a bound for this. So, therefore, the same bound is valid for this probability also.
(Refer Slide Time: 09:47)
 
Now, one can also obtain, I mean 1 can there are more than 1 ways of obtaining these inequalities. So, I will just give you the alternate proof, which says that if and. So, I will start with the expression for sigma square which is, expectation of x minus mu whole square. So, you are taking k on either side. So, now, I can and this integral will be minus infinity to infinity of x minus mu whole square f x d x. So, this integral I break up into. So, minus infinity to mu minus k; that means, this point, and then it will be mu minus k 2 mu plus k and then mu plus k 2 infinity. So, I break up the integral. So, the total integral minus infinity to infinity, I break it up to these three. 
Now, if you look at this expression for example, here x is greater than mu plus k. It is going up to infinity, and remember k is positive number. So, x greater than mu plus k implies that your x minus mu is greater than k. So, it actually this is implied. So, if this wherever x is greater than mu plus k, it means at x minus is greater than k, and similarly here your x is less than mu minus k. So, for x less than mu minus k, it implies that your x minus mu is less than minus k. And this is a, because again this is, you know x minus mu whole square you are integrating x minus mu whole square f x d x from mu minus k 2 mu plus k. So, this must be a non negative quantity. It can or be negative, because this is non-negative, this is none negative. So, therefore, the equality if I remove this, then the inequality changes to inequality.
(Refer Slide Time: 11:49)
 
 Secondly, as we said that in this interval mu plus k 2 infinity, x minus mu is greater than k. So, here again f x is a non negative function. So, if I replace this by k square then I am taking a lower value of the whole integral. So, again the inequality gets strengthened, and similarly here; your x minus mu is less than k in this interval also minus infinity to mu minus k, your x minus mu is less than minus k. So, square would be, what will happen to square x minus mu whole square will become greater than k square. In this interval again, because x minus mu is less than minus k. So, when I square up x minus mu whole square, it will greater than k square. So, then in both these integrals, I replace x minus mu whole square by k square, I am taking the lower value, underestimate of the integral, and therefore, sigma square is greater than or equal to k square of f x d x, this is minus infinity to mu minus k plus integral mu plus k 2 infinity k square f x d x.
But, this is nothing but k square of is a constant. So, this is probability x less than or equal mu minus k plus this is probability x greater than or equal mu plus k mu plus k 2 infinity, but then if you bring mu to this side, this will be probability x minus mu less than or equal to minus k. Here this will be probability x minus mu greater than equal to k. So, probability of absolute value of x minus mu greater than or equal to k. So, what is written is this strict inequality, but it should actually be, probability of mod x minus mu greater than or equal to k. So, we have the inequality sigma square greater than or equal to k square probability of absolute value of x minus mu greater than k, and so that gives us the inequality, if you wanted to prove. So, this is Chebyschev's inequality. This again gives you a upper bound on the probability mod x minus mu greater or equal to k, once we know the variance x.
So, this proof can be imitated for the discrete case also; that is when x is a discrete random variable with finite variance, and there will be a probability mass function also defines with it, and immediate corollary is that, if you put k equal to epsilon sigma, where of course, epsilon sub non negative number. Then the Chebyschev's inequality becomes greater or equal to epsilon sigma; this is less than or equal sigma square upon epsilon sigma square which is 1 by epsilon square, and if I divide here by sigma, sigma being a non positive number. So, inequality does not change, and probability x minus mu by sigma. So, this is, you can say standardized variable, you standardize variable x. So, this greater than or equal to epsilon, is less than or equal to 1 upon epsilon square; simpler version of the Chebyschev's inequality. So, we would like to now work out some examples, to see how these bounds can be used.
(Refer Slide Time: 15:22)
 
So, let us consider a few examples on these inequalities that we have just discussed. This example says that is a random variable, with mean and variance, both equal to 16. So, compute a lower bound on probability that x lies between 0 and 32, using Chebyschev's inequality, because here we cannot use Markov inequality. It is a 2 sided thing. and yes and again I am fine ya. So, therefore, we will use the Chebyschev's inequality here. The solution says that you convert this probability to probability of 0 minus 6. So, just subtract 16 from both the sides. So, it will be probability 0 minus 16 less than x minus 16 which is less than 32 minus 16. So, the 2 events are the same, and then this reduces to probability of absolute x minus 16 is less than 16. This is minus 16 and this is 16, so absolute. So, now, this is in the form of. Well this is the opposite of the, compute the lower bound for greater. So, now here I will have to write this is 1 minus probability absolute x minus 16 greater than or equal to 16. We had strict inequality here. So, this was strict, and therefore the opposite event would be. The compliment event would be absolute x minus 16 greater than or equal to 16. Since Chebyschev's inequality gives an upper bound. So, when I replace this by its upper bound minus of that will become. So, the equality here will change to greater kind. 
Because I am writing; for this I am writing a bigger number, but the minus will become a smaller number, and therefore, this probability will be greater than or equal to 1 minus expectation of x minus 16 whole square divided by 16 square, but this we know is the variance of x which is 16. So, therefore, this is 1 minus 16 upon 16 square, and so this is 15 by 16, and you can see, that is a fairly loose bound. So, 15 by 16 is a number close to 1. Yes and there will be, but anyways. So, I am trying to show you that, these bounds that you get are rather loose. They are not very tight, but some situation they are quite helpful also. Now another example is, from fast from past experience; a professor knows, that the test score of a student, taking her final exam, is a random variable with mean 65; that is not bad. if the mean is 65 out of 100 then students are good. So, let us see, given upper bound for the probability that the students test score will exceed 85. So, you need a upper bound for the probability. So, therefore, we just know that the mean is 65, and that is it, and using that we compute. 
(Refer Slide Time: 19:06)
 
So, here you will to answer this, you will simply use Markov inequality, and that will give you probability x greater than 85. So, your a is 85. So, this will be less than or equal to expectation x upon 85, which will be 65 upon 85, so 13 by 7. Now, Markov inequality says, that probability x greater or equal to a, is less than or equal to expected x by a, but we can also use this Markov inequality for computing an upper bound, for the event x, for the probability of the event x greater than a. Since probability x greater than a, is less than or equal to probability x greater than or equal to a. So, therefore, probability x greater than a will be less than or equal to expected value of x divided by a. So, therefore, when to compute the upper bound for the probability x greater than 85, I could use the number E x divided by 85, and this is what we will use for future computation also that follows. So, this is the answer that you get from Markov inequality.
Now, if there is a additional information, that the professor knows that the variance of a student’s test score is equal to 20. So, if you have knowledge of the variance, then you can use Chebyschev's inequality, and then you will say that probability absolute x minus 65, is greater than 20. So, this probability will be less than or equal to expectation of x minus 65 whole square upon 20 square, because this is your k. So, that is 20 square, and therefore, since we know that the variance of x is, x obviously, is the test score. So, then that is 20, so 20 upon 20 square this is 1 by 20. Of course, the number are little contrived, does not matter. See this event, is actually probability x minus 65 greater than 20. Either this is greater than 20, or this is less than minus 20. So, and you were looking for this probability, but in any case, this is probability x minus 6 x is less than 45. So, I could write plus here, because the 2 events are disjoint. So, in other words if you want a bound for probability x minus 65 x x yeah this. This will, your probability x greater than 85 plus probability x less than 45, which is 1 by 20.
So, in other words, your probability x greater than 85, this is less than or equal to 1 by 20, because this will be something positive. So, you will subtract from 1 by 20. So, therefore, this bound is definitely, I mean there is a dramatic difference between 13 by 7 and the number which is 1 by 20. So, you see the moment you have more information about the distribution, about the random variable, you can get better bounds for the the bounds are tighter. So, this was just, I think I just sat down and contrive these numbers and though, so they may not be look realistic, because 20 is a probably high number for the variance. So, therefore, there is a dramatic change, because you see this this had no knowledge of the variance. So, I just computed this. So, this number we computed knowing the expected value. So, if here the variance is much smaller, then; obviously, this probability will also be, this bound will be higher.
So, this is just to show you that the difference between the two bounds. Now the second part of the problem is, that how many students will have to take the exam, to ensure with probability at least 0.9, that the class average would be within 5 of 65. So, how many students. So suppose, we assume that there are n students, were taking the exam, and then the class average would be given by. So, class average would be a summation x i, i varying from 1 to n divided by n, which in our notation we can also write is x bar. So, that will be your class average. So, what they saying is, that the class should be within 5 of 65. So, it is either 5 less than 65, or a 5 more than 65. 
So, therefore, this class have average should be within 60 and 70. So, this is the probability that you have to. You are told that this probability should be at least 0.9, and then you want to know how many students should take the exam, so that this probability is at least 0.9; that means, its greater than or equal to 0.9. So, here again I am trying to standardize, or cut it in the form of the Chebyschev's inequality. So, x bar minus 65, because mu of x bar is, the expected value of x bar is also 65, since each exercise. So, therefore, the 60 minus 65 less than or equal to x bar minus 65, less than or equal to 70 minus 65, and then I can also here divide by. So, what is the variance of. Here variance x bar will be variance of, any of the x i the same divided by n.
So, because variance x i divided by n square, so this becomes this, so under root of this. So, that will be under root of 20 by n. So, if I divide both sides by under root of 20 by n, the event does not change. So, this is what I have now, and this is 1 minus probability x bar minus 65 upon under root 20 by n. So, this gives me; that mean this is my, I mean I am applying Chebyschev's inequality here; this is greater than 5 by under root 20 by n. So, this would be again, because I am writing 1 minus of this. So, if you have less here; that means, this is less than some number by Chebyschev's inequality. So, minus that will become greater, and so this is 20 by n into 25, because what is the; have I written it correctly here. 
So, you want to Chebyschev's inequality this will be what. This is this number, if I just write this number, this is less than or equal to expectation of x bar minus 65 upon 20 by n this whole square divided by, you can say 25 n by 20, but this has variance 1. So, actually it should be yes. So, see this has variance 1, because I have standardize it. So, expectation x bar minus 65 upon under root 20 by n whole square has variance 1. So, the number is 20 upon n 25. So, this should be, and this is greater than or equal to. So, my probability and therefore, if I put this equal to 0.9, then my at least part is satisfied. So, the value of n that gives me this quantity equal to 0.9 will satisfy, because the probability that I have written on the left hand side, is greater than or equal to this.
(Refer Slide Time: 27:42)
 
20 upon 25 n equal to 0.1 implies n is equal to 8 and not 80 as written. Therefore, for n greater than or equal to 8, the class average will be within 5 or 65. So, you know lots of different kinds of probabilities you can obtain via, you know using the Chebyschev's inequality you can get the bound, you can get estimates of the numbers and so on.
(Refer Slide Time: 28:11)
 
So, let us consider this example; it says that, it cost rupees 1 to play a slot machine. See now some of you have an idea that you put in 1 rupee, and then if you are lucky, some money comes out, otherwise nothing comes out. So, the machine is set by the house. So, wherever your this slot machine is put, the machine is set to pay rupees 2, with probability 0.4 5 and nothing with probability 0.55. So, you see you put in a rupee and then with probability 0.45, you expect to get 2 rupees. Otherwise with the probability 0.55 you do not expect to get anything. So, you lose that rupee fine. So, fine a proximate probability that after 10,000 plays of the machine, the houses winnings are between rupees 800 and rupees 1200. 
So, you see a winning means that when the house has to pay, to the player then its loosing. Since when the player puts in 1 rupee, and the house has to pay 2 rupees, then that is a loss for the house. So, therefore, x I is equal minus 1 is with probability 0.45, and x i is equal to 1 probability point. So, this represents the earning of the machine, in the i th play of the game, when the some slot machine is being played for the i th time. So, x i is equal to minus 1 with probability 0.45, and this is 1 with probability 0.55. And of course, you can see that E x i, the expected value of x i will be minus 1 into 0.45 plus 1 into 55. So, this is 0.1 as you expect, because otherwise why would people or house want to invest money in a slot machine, if the expected earning is not positive. So, this is 0.1 per game of the slot machine.
And similarly, the variance x i would be 0.99, because it will be expectation x i square. So, once you put x i square, then this will become plus 1 into 0.45 plus 1 into 0. 55 which will be 1. So, expectation x i square is 1, and then expectation x i whole square will be 0.1 square, so this becomes 0.99. So, the variance of each x i is 0.99, and earnings of the house are represented, total earnings are 1 to 10,000. 
So, sigma x i summation from 1 to 10,000 gives you the earning of the house, in which you know losses and incomes are included. The net net income the net earnings of the house is sigma x i i varying from 1 to 10,000 and. So, expected value of the earnings is rupees 1000, because this is 0.1 multiplied by 10,000 which gives you rupees 1000, and the variance sigma x i is 9900. Now I have not standardized this here. It is ok to carry on the computations with these values. So now we have to compute the probability, that total earnings of the house lie between rupees 800 and 1200. So, here again we will do the same thing, we will try to standardize this probability, and I will subtract the expected value of sigma x i which is 1000 rupees on either side and so that gives me that absolute of sigma x i i varying from 1 to 10,000 minus 1000 is less than 200.
So, again we have it in the right form, in the sense that. Now I will write this as 1 minus probability sigma x i i varying from 1 to 10,000 minus 1000 should be greater than or equal to 2. So, it saying between 800 and 1200, so I am taking strict inequality here. So, therefore, the compliment event will have greater or equal to 200. So, I have set it right for the use of Chebyschev's inequality. So, again the same reasoning, that this thing is less than I get a upper bounds, so therefore, minus of that will give me the lower bound, so minus of that. So, therefore, this will be, this is less than or equal to variance of sigma x i divided by 200 square. So, variance of sigma x i is, remember this is 9900. So, therefore, this is greater than or equal to 1 minus 9900 upon 200 square, which is equal to 1 minus 9900 upon 40,000, so this becomes this. So, again; that means, this close to 0.75, the probability. So, you would expect that, because 10,000 place, and you know the machine the expected value from each play of the machine is point 1, expected earnings. So, therefore, this is probably not a very bad bound. So, at least. So, here of course, the probability is at least 301 upon 400, it can be more. So, it is understood that the Chebyschev's bound are not tight, but it gives you an idea. It gives you a feeling about the probability of the event that you are trying to estimate.
(Refer Slide Time: 34:13)
 
Another example, because I feel that the there are so many different situation, where you have to learn to how to compute, how you can apply Chebyschev's inequality, and therefore, I just have collected the lot of a different examples. So, let us look at another example here, which says that a fair die is rolled, and what you mean by independently 3 times, which means that there is not bias, so the outcome are independent. So, the outcomes of the dies roll 3 times, whatever the outcomes are independent outcomes. Now you define x i as 1 the i th roll yields a perfect square. 
So, x i denotes the random variable, which is equal to 1 if the i th roll gives me a perfect square and 0 otherwise. So, first find the P m f of x i, and I need to do all this work before I apply the Chebyschev's inequality. So, the P m f of the x i, and then of y is equal to x 1 plus x 2 plus x 3, then you have to find the P m f of y, and then verify Chebyschev's inequality. So, we will compute the actual probability, and then also get the bound by the Chebyschev's inequality and compare. so; obviously, we expect that, since this gives us a upper bound so the actual probability that we compute, will be less than what we get by the Chebyschev's inequality this is whole idea, and I thought that we can if we you work out in detail, you will get a good feeling about a whole thing.
So, anyway. So, let us see the solution procedure. Now 1 and 4 are the only perfect squares, in the sixth numbers that come up when a die is rolled. So, 1 and 4 are the only perfect squares, and therefore, probability x i equal to 1 will be 2 by 6, which is 1 by 3 and probability x i equal to 0, will be 4 by 6 which is equal to 2 by 3 for all i, and i’ s are all. So, and x i are independent. So, now, you take y to be x 1 plus x 2 plus x 3, and y takes values 0 1 2 and 3, because none of the die show a perfect square. So, then this values 0, one of them shows a perfect square, two of them show a perfect square, or all three show a perfect square. So, the values possible values of y are 0 1 2 and 3, and not difficult to compute the P m f of y, because y equal to 0 means that all 3 variables take 0 value, and since they are independent. Therefore, it will be product of probability x 1 equal to 0 x 2 equal to 0 and so, that x 3 equal to 0. So, it will be 2 by 3 square, which is a cube, which is 8 by 27.
Similarly, probability y equal to 1, will be. see now here, I just take this case that x 1 is 1 and x 2 and x 3 are 0, then they can be 3 such combinations; where 1 of them is 1 and the other 2 was zero. So, this will be 3 times, this particular probability, which is again using independents x 1 equal to 1 is 1 by 3. So, 3 times 1 by 3 into this is 2 by 3 raise to 2, which is 4 by 9. So, the probability 12 by 27, and y equal to 2 again the same case, that if I take this particular event x equal to 1 equal to x 2 and x 3 0, then again the 3 combinations which will give me the same value of y which is equal to 2. So, three times probability x 1 equal to 1 equal to x 2 and x 3 equal to 0. So, this will give me 3 into 1 by 9 into 2 by 3, which is 6 by 27, and probability y equal to 3 requires that all 3 must be equal to 1, and that probability will be 1 by 27. Now you can just make sure that, you have computed the right P m f, by adding up all these probabilities. So, 7 plus 6 13 13 plus 12. This is 1 and 6 7, 7 and 12 19 19 and 8 27. So, all these probability add up to 1. So, this is a right P m f.
Now, therefore, we can immediately compute expected value of y, which is 1. I mean I leave that to you, because now you have the probabilities, multiply by the corresponding value of y, and you add up and get this this. Similarly expected value of y square is 45 by 27. So, the variance comes out to be 18 by 27. So, now for example, probability y minus 1 greater than half, if you want an estimate for this upper bound, then this is less than or equal to expected value of y 1 whole square y minus 1 whole square into 4 1 by 2 square, the denominator will become 4. Now, this certainly there is no verification is needed, because the actual probability cannot be more than 1, whereas, this number coming out to be more than 1, because you have put a number 1 by 2 here. Are you with this, because 4 into 87 by 27, this number is greater than 1. So, here I do not need any verification. So, more meaningful verification will be; for example, I want to say that probability y minus 1 absolute value greater than 1, is less than or equal to. So, this will be variance y upon 1 which is 18 by 27. So, now we will actually compute this probability, and show that it is less than 18 by 27, to make sure that this actually gives you an upper bound. 
(Refer Slide Time: 40:25)
 
If you observe that b is y is also distributed has a binomial distribution with the parameters 3, 1, 3. So, the probability of success is given by 1 by 3, and number of rolls is 3. And therefore, immediately you know that hence expected value of y will be n p. So, 3 into 1 by 3 is 1, and the variance of y will be 3 into 1 by 3 into 2 by 3 and P q which is 2 by 3, but we computed this independently as 18 by 27 which is also 2 by 3. Now just want to we are we are testing the, we are comparing the actual computation of probabilities with the Chebyschev's bound. So, if you want to look at this probability, absolute value of y minus 1 greater than or equal to 1. So, you see that here; y minus 1 greater than or equal to 1, implies that y can take the value 0 2 and 3, because y is 0 then absolute value of minus 1 is 1 which is equal to 1. So, remember the event, is greater than or equal to. Therefore, y can be equal to 0 2 and 3, and in that case this probability will be equal to probability y equal to 0 plus probability y equal to 2 plus probability y equal to 3. 
So, you make this computation 8 by 27 plus 6 by 27 plus 1 by 27; which is equal to 5 by 9, but if you compute the Chebyschev's bound, then this will be variance y upon 1 1 square is 1, and this is variance y which is 18 by 27 or 2 by 3. So, you see when you compare these two numbers, you will say that Chebyschev's bound is a loose upper bound, because 5 by 9 is less than 2 by 3; say 15 is less than 18, when you compare by 9 is less than 2 by 3. And then let us see take another event. So, this will be probability absolute value of y minus 1 greater than or equal to 2, which is simply probability y equal to 3. So, we can use the binomial probabilities here and. So, y equal to 3 would be simply 1 upon 27, 1 by 3 raise to 3. So, this by the Chebyschev's inequality will be variance y upon 4, because your k is 2. So, this 18 by 27 into 1 by 4, which comes out to be 1 by 6. So, when you compare 1 by 27 with 1 by 6, the gap widens. This is loose upper bound, by the Chebyschev's inequality. 
And now if you want to look at the event probability absolute value of y minus 1 greater than or equal to 0, then we cannot apply the Chebyschev's bound, because this number has to be positive; remember k greater than 0, so that is required. So, therefore, I cannot compute a bound for this. So, you may compute the actual probability here, but Chebyschev's bound cannot be computed. What I have tried to show you, is of course, through various examples how to get the probability required to compute the lower bound by Chebyschev's inequality. So, doing that, and then also try to give you feeling, that the bound we are computing are, loose bounds they are not tight ones. And thirdly, now what I would like to show you in the next lecture is that, apart from computing bounds, it has also proved a very useful tool for showing. We will be talking of conversion theorems in the next lecture, and that is where I will show you, how useful a tool the Chebyschev's inequality is. So, that will be the next.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 20
Convergence and Limit Theorem

So, in the last lecture, we had introduced these inequalities – Markov inequality and Chebychev’s inequality.
(Refer Slide Time: 00:15)
 
But I feel that revisiting them is necessary because some aspects need to be emphasized. And in fact the Markov inequality has its strength, and its simplicity and its generality, because the inequality is very simple to state, but this can be very useful and powerful at places and also the strength lies in its generality, because it just that you need to know that there is a random variable, whose expected value exists; and that is it. And then you can you know state facts about certain probabilities.
(Refer Slide Time: 01:01)
 
So, let us see interesting applications of the Markov inequality. Consider a group of 500 people. Now, the kind of… You are going to ask this question – is it possible that at least 90 percent are younger than the average of the group. Then, the next question is – is it possible that, at least 50 percent are older than twice the average age. And, another question could be is it possible that more than one-third are older than three times the average. So, let us try to see what kind of answers Markov inequality will give you. So, for the first part, of course the answer is yes and I will explain why. But, if you look at the… 
If you try to get the bound from the Markov inequality, the inequality says that, for X greater than or equal to E X – probability that X is greater than or equal to E X will be less than or equal to E X upon E X, because you take E X of this and then divide by this, which is equal to 1. So, that is no bound, because you know that, all probabilities are less than or equal to 1 and the converse of this event would be probability X less than E X, which would then be greater than or equal to 1 minus 1 – converse of this, because this is less than or equal to 1. So, this will become 1 minus 1, which is 0.
So, again, does not give you any information. So, that is what we are trying to say. We are saying that, possible that, at least 90 percent are younger than. So, younger than means that, you want to compute the probability of the event that, X is less than E X –younger. This is what you want to compute. So, I should have said here this is comma. Therefore, the Markov inequality just tells us that, this is greater than or equal to 0. So, that is no help. But, of course, you can rationalize the string that, the answer would be yes, because there may be some people who are very old; and therefore, they will make the average go up to… So, even if 90 percent are younger; that means what we are saying is that, the answer to this is yes, because 90 percent are younger. Even then the few people, who are very old, will lift the average. And so this inequality would be… This is the probability of 90 percent are younger would be satisfied; that means probability X less than E X is equal to 90.9 would be satisfied.
(Refer Slide Time: 03:33)
 
So, to answer the second question, what we want is that, older than twice the average age; that means you want the probability X greater than twice E X; and you want a bound that, this is at least 50 percent people are older than twice the average age. So, if I want this probability, then this is less than or equal to probability X greater than or equal to twice E X, because this event is bigger than this event. And, this why Markov’s inequality would be less than or equal to E X upon twice E X. So, we divide by this. And so, that is equal to 0.5. Therefore, the answer would be yes, because probability that, X greater than 2 E X equal to 0.5 is a possibility. Yes, but probability X greater than 2 E X greater than 0.5 is not a possibility. But, since this is possible, we will say that, the answer is yes that, at least 50 percent will be older than twice the average age. So, interesting applications.
Then, to answer the third part, that is, probability X greater than 3 times E X; and you want a bound on this. So, this is less than or equal to probability X greater than or equal to 3 times E X; same argument is earlier. And, this by Markov’s inequality is less than or equal to 1 by 3. So, here you want that, at least 1-3 are greater than the probability; that, at least one-third are greater than thrice the average age. So, the answer is no, because this is less than or equal to 1 by 3. So, this cannot be more than. So, this event – the probability of this event cannot exceed 1 by 3. So, the answer here is no. Now, similarly, let us look at the Chebychev’s inequality, which says that, probability – absolute value of X minus mu greater than or equal to c times sigma is less than or equal to sigma square upon u divided by the square of this, which is c square sigma square. So, this is equal to 1 by c square – 1 by c square. And so, if you consider the event that, probability of absolute value of X minus mu greater than or equal to twice sigma, then this will be less than or equal to 1 by 4, which is 0.25.
(Refer Slide Time: 06:21)
 
So, now, if you look, compare this with the some of the actual probabilities, then for X being distributed as normal mu with mean mu and variance sigma square. And, you are looking at the probability that, absolute value of X minus mu is greater than or equal to twice sigma; then the actual probability is 0.456. Therefore, you can see that, this is much smaller than 0.25 and if you look at the diagram. Therefore, if this is the mean, the x-axis is this; and then this is the PDF – axis for this PDF. Then, you see here you take the area; that means what you are saying is that, this area lying between, because absolute value X minus mu greater than or equal to 2 sigma means that X lies between mu minus 2 sigma and mu plus 2 sigma. So, these are the limits.
And so, here what we are saying is that, this area would be 1 minus 0.0456. This is the area, which we are depicting here. And so, difference is quiet large. And, this becomes even more significant or more glaring the difference between the Chebychev’s bound and the actual bound or the actual probability. If you take the probability of X minus mu greater than or equal to 3 sigma, then this will be less than or equal to 1 by 9, which is 0.111 by the Chebychev’s inequality. But, the actual probability is actually very small; it is 0.0013, which is… See what here again… Because of the symmetries remember; so, here this would be mu minus 3 sigma and this is mu plus 3 sigma. So, you are asking for… Exactly. So, that area I am showing that means between mu minus 3 sigma and mu plus 3 sigma. So, this whole area I am saying is 0.9987. And, that is because we know that, by symmetry, this area – the tail – this part – tail part, and these two are the same. And so, we have discussed this many times before also. Therefore, that means actually, the tail… that means this tail area is half of this – 0.0065. And, here also the tail is 0.0065. And so, therefore… So, the difference becomes bigger and bigger.
One can go on and looking at these interesting parts that these inequalities. But, at times, they provide you… They are very useful tools and they… As I told you, for the Markov inequality, it can answer some very interesting questions. And, here also we will see various applications of the Chebychev’s inequality. Markov inequality is not able to say much, but you can see… The thing is that, the answer would be yes, because you can always have small number of people who are very aged, whose ages are very big. And therefore, the average… Therefore, the 90 percent can still be younger than the average age, because these older people – they pull up the average. Therefore, the answer is yes.
Now, if you look at the second question, then you are asking for the probability that, X is greater than or equal to twice E X. So, twice the average age. And therefore, by Markov inequality, this would be E X upon 2 E X, which is 1 by 2, which is 0.5. So, Markov’s inequality gives you the bound that, this probability cannot exceed 0.5. And so, therefore, the answer here will be no. So, the answer is no, because here they are asking is it possible that, at least 50 percent are older and twice the average age. So, no; 50 percent will not be older. So, this probability would be always less than or equal to 0.5. And similarly, for the third question, probability X greater than or equal to 3 times E X – that will be less than or equal to E X upon 3 E X; it is 1 by 3. Therefore, again more than 1 by 3 is not possible; more than 1 by 3 are greater than 3 times, because this probability – the bound – upper bound is 1 by 3. And therefore, again the answer is no. So, I just thought that, this gives you another insight into the Markov inequality and its uses. And, one can go and discover more and more about the usage of this particular inequality.
Now similarly, for Chebychev’s inequality, I wanted to just point out that, if you ask for the probability that mod of X minus mu is… Therefore, you have a random variable X, which has accepted value as mu and variance X is sigma square. So, just a random variable with mean mu and variance X sigma square; you are asking the question mod of X minus mu or absolute of X minus mu is greater than C sigma. So, Chebychev’s inequality – this would be sigma square upon c square sigma square; this is 1 by c square. So, in particular, if you put c is equal to 2, then this is a probability that, mod of X minus mu is greater than 2 sigma. 
And therefore, this will be less than or equal to 1 by 4, which is 0.25. So, in other words, here if you… I have drawn the normal curve; does not matter. Therefore, this is minus 2 mu and this will be 2 mu. So, in this, we are asking for the area, that is, the probability that, this is greater than 2 sigma; that means, the area on to the left of minus 2 mu and the area to the right of 2 mu. So, that will give you the probability that, mod of X minus mu is greater than 2 sigma. And, this is less than 1 by 4 in general; universally true. This is universally true, which is 0.25.
Now, if you compare this for normal n mu sigma; that means, if a random variable X is mu sigma, then this probability is 0.0456. Therefore, compared to this, this is rarely loose bound – loose upper bound. But, later on we will see how… No matter… Because of its universality – Chebychev’s inequality, this is very useful improving many other results in probability theory. So, anyway I just thought I will give you an estimate, because the normal curve is symmetric about mu and then it is bell shaped. So, the mass is concentrated around mu for normal. And therefore, this probability would be small, because the area lying on the left of minus 2 mu and to the right of 2 mu will be much smaller than compared to the area, which is around mu. Therefore, this…
And similarly, if you take c to be 3, then the difference is more marked, because probability mod X minus mu greater than 3 sigma is less than or equal to 1 by 9, which is 0.11. Anyway for… So, that means, it says is that, for most of the distributions, the area – the mass of under the curve lies the probability mass – lies within minus 3 sigma. This is minus 3 sigma and 3 sigma; then the area inside here is 0.9987. So, only this much area lies outside; which means half of this. I will have to be very sure that, this is this; then the half of this half; that means, further do it 0.0006. So, this is the area, which lies here and the both. This area is 0.006 and that is 0.006. So, this is the idea. Therefore, Chebychev’s inequality is an upper bound; but, because it is applicable to all the distributions, therefore, it has its own uses and applications.
(Refer Slide Time: 14:46)
 
Now, the third inequality that we want to talk about is Jensen’s inequality. And, this inequality relates expectations instead of probabilities. So, like for example, both these inequalities were giving you upper bounds for the probabilities of certain events. But, Jensen’s inequality relates the expectations. But, before that, before I give you the Jensen’s inequality, I need to define convex and concave functions. And, some you may have already come across, for example, convex lenses, concave lenses – you may have heard of. So, here the function is said to be convex or if it is twice differentiable… If a function is twice differentiable, real valued function. And, it is said to be convex, if its second derivative is non-negative in the domain of f. So, wherever f is defined, then at all those points if you are f double prime x is non-negative, then the function is said to be convex. And, if the double derivative is less than or equal to 0, then the function is said to be concave. So, therefore, the relationship between convex and concave is that, if f is convex, then it will imply that, minus of f x is concave.
So, now, here for example, I have drawn for you convex function twice differentiable. And, what we are saying is that, if f double prime x is greater than or equal to 0, then f prime that… This implies that, f prime x is not decreasing if the… Wherever you take a function f and if its derivative is non-negative, then we say the function is non-decreasing. Here f double prime x is non-decreasing. So, this implies that, f double prime x is greater than or equal to 0; that implies that, f prime x is non-decreasing. So, you see here for example, these are the tangents to the curve; and see these angles – they are negative; they are obtuse. And, if all of you remember the graph of tan x, because slope is given by… f prime x is a slope; tan of the angle – tan of this angle; tangent of the angle that, the tangent at the curve makes. So, you are…
For example, this if you take this is 0; this is pi by 2; then this is pi. And therefore, on this side of this, it is like this. So, the function is obtuse angle and the curve is increasing. So, as the angle becomes… And, then of course, this becomes… The angle becomes up to pi; and so, tan of pi is 0. So, you are derivatives – the tan of these angles are increasing. And then finally, at this point, it becomes 0. And then when you take this, then you can see that, the angles are increasing. Therefore, for obtuse angles, again, tan is increasing. So, this is the idea. Therefore, the first derivative is non-decreasing. Also, that the tangent at any point of the curve lies below the curve, because you have seen. See the function is like this. So, the tangent is this. So, tangent is always below the curve. And so, here when you say that, minus f x; minus f x means you will turn it upside down; you overt. Therefore, a convex function you can say holds water; a concave function will not hold water, because it will be upside down. So, this thing will be up and a function will be like this. So, this will be a concave function.
Now, of course, here I have given you the definition of a twice differentiable. But, for example, if you take y is equal to mod x, this is also convex. But, of course, this is not differentiable. So, none of these things… It is differentiable at these points, but not at the origin. So, this holds, because it is constant. See here the slope is minus 1; here the slope is 1. So, in any case, the slope is increasing, because this is this; here it is not defined, but the… So, this is also a convex function. And of course, there are many ways of characterizing a convex function. So, now, I will state the Jensen’s inequality for convex and concave functions.
(Refer Slide Time: 19:17)
 
So, the Jensen’s inequality says that, if f x is a real-valued convex function, then expectation of f x – this should be capital X, because function f is a function of the random variable X. Then, E – expectation of f of X is greater than or equal to f of E of X; that means you exchange f and E; then the inequality is this kind. So, for X random variable with E X equal to mu finite. So, the requirement is that, the mean – the expected value must exist for a random variable; and if a function f is convex, then this would be E f X is greater than or equal to f of E X.
Now, you can see that, if you replace this by… If you multiply the inequality by minus sign, then the minus sign will go inside and it will say that, expectation of minus f of X is less than or equal to minus f of E X. And, since… So, minus as we said earlier when we were defining a convex function that, minus f will be concave if f is convex. Therefore, for the concave function, the inequality reverses. So, this is the Jensen’s inequality. So, it is just relating the expected values. And, you can… If the function is convex, then the inequality would be greater kind; and for concave, it will be less kind.
Now, you already know that, expectation of for example, X square – if the second movement exists, expectation X square is greater than or equal to expectation of X whole square; that means the function f X here is X square and this we know is convex; everybody knows it is a parabola or the second derivative is 2 – a constant, which is non-negative. So, this is a convex function, but we already know that, variance X can be written as expectation X square minus expectation X whole square, and this is always non-negative. So, from here also, it follows that, expectation X square will be greater than or equal to square of expected X.
Consider the function f X equal to 1 by X. Then, if you just find out the first derivative, this is minus 1 by X square; and second derivative would be see X raise to minus 2. So, minus 2 and minus sign – plus 2 upon X cube. And, this is always non-negative for X positive. And therefore, this is a convex function. And so, by Jensen’s inequality, expected value of 1 by X is greater than or equal to 1 upon expected X. And, quite a few people often mistake this and they say that, expectation of this will be… So, now, you know better, because the Jensen’s inequality says this will be greater than or equal to; they are not the same thing; expectation of 1 by X and 1 by expectation X are not equal. So, this is also you can now assert by using Jensen’s inequality.
You can consider the function log X. log X – the second derivative is minus 1 by X square; first derivative would be 1 by X. So, when you take the second derivative, it will be minus 1 by X square. And, this is less than 0 for X greater than 0. Anyway the function – this is defined for X positive. And so, by Jensen’s inequality, expectation of log of X is less than or equal to log of expectation of X, because for concave function, the inequality reverses. Proof is simple.
(Refer Slide Time: 23:09)
 
So, I will use the first property that, the tangent at any point of a convex function lies below the curve. So, the curve always goes… – it is above the ((Refer Slide Time: 23:18)) And, of course, they meet at this point. So, the tangent is at the point mu; then the value here – the coordinates are mu, g, mu. And so, if I take a plus b x as the tangent to g x at the point x is equal to mu; then g x convex implies that, g x is always is greater than or equal to a plus b x and g mu will be equal to a plus b mu, because the curve and the tangent line – they meet at this point. And therefore, since these holes… Therefore, when I replace x by a random variable, the inequality remains intact. So, g of random variable x is greater than or equal to a plus b of X. And therefore, the expectation will also… They will not change the inequality.
So, when I apply expectation on either side, it will be E of g of x is greater than or equal to a plus b E of X; a and b are constants. So, this is what the proof. And so, a plus b of E X is a plus b mu, which is g of mu; and mu is your expected value. Therefore, this is g of E of X. Therefore, from here you have shown this inequality; the simple proof using the convexity of the function; and then the fact that, when you have inequality. So, this a bigger function than this. So, I hope you all agree that, because even if you are taking X to be a continuous random variable, then if the density function of course, is non-negative. So, here you are taking the difference. So, if you take the difference of g x minus a minus b X, which is a non negative function; then integral – whatever the limits would be also non-negative. And so, this will be satisfied. Therefore, from here to here is no problem. Therefore, you can prove the Jensen’s inequality. Therefore, the figure is also quite explanatory.
Now, an alternate proof, because since we have the definition of convexity, I will use the twice differentiability of the function now. So, since f is convex; so, it is twice differentiable instrument. And, Taylor’s expansion of f x at x is equal to mu up to second order terms yields. So, now, those of you who feel comfortable with calculus, then you know about the Taylor’s expansion that, every function can be expanded in the neighborhood of a point; where, in the neighborhood, it has all these derivatives. And so, here since I have assumed that, it is second order derivative exists. Therefore, I can write f x as f mu plus x minus mu into f prime x plus x minus mu whole square by 2 factorial into f double prime psi; where, psi belongs to mu comma x. So, such a psi exists in the interval. So, whether it is mu comma x or x comma mu does not matter, because you are taking the square here. So, there is a psi in this interval. And therefore, this would be then exact expansion; that is what Taylor says. So, Taylor’s theorem says that, such a psi always exists.
Now, since f double prime psi is non-negative, because f double prime is non-negative in the whole domain. So, this is non-negative and this is a square – square of a real number. So, this quantity is non-negative. Therefore, I can say that, f x is greater than or equal to f mu plus x minus mu into f prime x. So, which… If you write this in terms of… So, f of x is greater than or equal to f mu; I should have written the step x minus mu f prime x – f prime x; just that as we did here in this first proof. And now, you can take the expectation. So, expectation f x – again this is same reasoning; the inequality will not get reversed. So, this will be f mu plus. Now, expectation of x minus mu is 0. So, you are left with only f mu here. And, f mu is f of E X. Therefore, again the Jensen’s inequality has been proved.
(Refer Slide Time: 28:00)
 
So, I just wanted to point out this correction in the Jensen’s inequality proof. See I was giving you an alternate proof; and there I had to expand the function f x by Taylor’s expansion at the point mu. And, the correct expansion is that, f x is equal to f mu plus x minus mu f prime mu plus half x minus mu whole square f double prime psi. Now, instead of mu, it got written as x. 
Therefore, you have to read f prime mu instead of f prime x. And then of course, we know that, psi is a number, which is some number between mu and x. And, by Taylor’s theorem, such as psi always exists. So, we are taking a second order expansion of the function f x at mu. And so, this should read as f prime mu instead of f prime x. And, as we go along, we might also see some more occasions to use this inequality. But, I think this gives you a good feeling about the Jensen’s inequality.
(Refer Slide Time: 29:08)
 
So, an instructing example of the Jensen’s inequality is that, investor is faced with two choices. She can either invest all her money in a risky proposition that will lead to a random written X that has mean m or she can put the money into risk-free venture that will lead to a written of m with probability 1. So, these are the two choices she has. And, suppose she bases her decision on maximizing an expected value of u R, where R is her return and u is her utility function. So, by somebody’s advice or something, she has now decided that, she will base her decision to invest whether in the risk-free venture or the risky venture by maximizing the excepted value of u R; where, R is the return function and u is the utility function. So, u of R.
Now, by Jensen’s inequality, it follows that, if u is concave, then expected u X will be less than or equal to u of E X, which will be u of m. So, the risk-free venture is better. So, here the expected return of u X will always be less than or equal to u of E X, which is u of m. Therefore, it is better to invest in the risk-free venture. Now, if u is concave, then this implies that, E of u X will be greater than or equal to u of m. So, the risky venture is profitable, because the expected return here would be greater than or equal to u of m. This is u, is her utility function; and in the risk-free venture, she gets exactly m returned. Therefore, this will be the total utility to her of the return that she gets from the risk-free venture. And, this is because X is a random returned. So, E of expected value of u X. So, that will always be greater than or equal to u m in case the utility function is convex. Therefore, the risky venture is profitable. And, there can be many more interesting examples of these inequalities that we have just studied.
So, the next thing that we want to talk about, which again has a very important role to play; and these are the limit theorems. And so, let us just first try to understand the concept of what we mean by these limit theorems. So, the first definition that I want to make is the definition of sequence of random variables converging in probability to another random variable. So, here this is at X 1, X 2, X n, is a sequence of jointly distributed random variables for n greater than or equal to 1; that means you must have at least more than one defined on the same samples space omega. And, let X be another random variable defined on omega. Then, we say that, X n converges to X in probability, that is… So, the notation is that, X n goes to X in probability if for every epsilon greater than 0, limit of this absolute value X n minus X is greater than epsilon. So, this limit converges to 0.
So, in other words, in probability, the random variable X n is converging to X. And, please understand. So, here this is different from the concept of usual limit, where the P is missing. So, in that case, when you say that, in value X n, the sequence is converging to X; that means when n becomes larger and larger, the distance between X n and X will be very small, because epsilon is an arbitrary number greater than 0. So, I can go on making epsilon small and small. But, here the limit is in terms of probability – probability of this event; that means of this difference – X n minus X greater than epsilon becomes an impossible event, because the probability is 0. So, this is the idea of convergence in probability.
(Refer Slide Time: 33:16)
 
Then, the other definition that I want to make is that of… And, this is called… This convergence in probability; I have already given one name; it is also called stochastic convergence – convergence in measure – measure is the probability here or weak convergence. So, this is one definition. And, the other is the convergence in distribution. So, we will say that, X n converges to X in distribution or in law if the limit of F X n t; that means the cumulative distribution function of X n. 
So, at the point t, converges to the distribution – cumulative distribution function of X at t as n goes to infinity. And, this must happen at each point t, where F X is continuous; so, that means… And, in fact, obviously, this is also continuous at that point. So, limit F X n t – the cumulative distribution function of the random variable X n – this converges to the cumulative distribution function of F X t of X as n goes to infinity. So, now, abbreviating the notation. So, this says that, F n goes to F; where, F n t is the cumulative distribution function of X n, and F we denote by the cumulative distribution function of X at t.
(Refer Slide Time: 34:40)
 
So, notation for X n converges to X in distribution. We also say that, X n going to X in distribution. So, the notation that I have written down or the cumulative distribution function F n of X n, which is F n going to F – the cumulative distribution function of X in distribution. And, d can also be replaced by l. So, both these notations are valid. So, this is also called weak convergence – weak convergence in law or weak convergence in distribution. So, you can see the difference, because here it is only we are saying that, probability of this event is becoming 0. As n goes to infinity, just the… whereas, here the whole distribution – the cumulative distribution function – the whole of the function is converging to the cumulative distribution function of X at every point t, where it is defined, where it is continuous.
Now, convergence in probability and convergence in law are very important. And, we will see as we go long that, the numerous applications of these convergences; and are easier to prove. Then, the less important types of convergence called strong convergence. So, maybe in this course, I have a chance to look at one or two strong type of convergences also. But, the more widely used are the weak convergences; and these are law and probability.
(Refer Slide Time: 36:19)
 
So, we will now define weak law of large numbers. Law of large numbers states that, if you have a sequence of these random variables – identically independently distributed random variables, I have said that, the expected value of each of them is mu and variance is sigma square and these are finite quantities; that means, the variance ((Refer Slide Time: 36:37)) Then, you define X n bar. So, X n bar would be the average of the values up to n. So, sigma X i; i varying from 1 to n divided by n. And then in simple terms, the weak law of large numbers says that, this sequence of averages X n bar as n goes to infinity; that means when you take n plus 1, it will be average of X 1, X 2 of X n plus x n plus 1. So, this is a sequence that you are generating by taking averages of n, n plus 1, n plus 2 and so, on. And then… So, this sequence converges to the mean of the… or the expected value of the random variables.
Idea here is that… So, actually this will happen in probability. So, the whole idea, because we say that weak law of large numbers. So, the whole convergence – the concept is in terms of probability. And so, what we are saying is that, since its converging in probability, the probability is high that… That means I can take… For large enough n, I can take X n bar as a good estimate of mu; otherwise, how do we have, because we just have these sample values, which we have taken randomly and then we are wanting to estimate the mean of the distribution. So, this would provide a good estimate for mean – for the value mu. For example, if all X i's are Bernoulli, then we know that, mu is of course, is a good estimate of mu; in the sense, this is also the probability P. If the probability of success is P, then for the expected value of each Bernoulli random variable, is also equal to P – the probability of success. And so, what it is saying is that, when you take n large enough, then this would give you good estimate of the probability of success. So, this law of large number provides way of estimating the mean of the distribution. This is the whole idea.
So, formally, if you want to define this concept that… then we will say that, given delta and epsilon greater than 0 – some arbitrary numbers, then there exists a number M, which is a function of epsilon and delta such that when you write this probability X 1 plus X 2 plus X n upon n, which is X n bar; X n bar minus mu in absolute value greater than delta. This probability will be less than epsilon for all n greater than or equal to the number dependent on epsilon and delta. So, this is simply just extending the notion of… Or, just the same notion that you have about continuity when you talk of continuous functions when you want to say that, the function values – this and this for example, can be brought as close as you wish. 
So, this greater than delta will be less than epsilon provided for n begin up; that means n must be greater than or equal to some function, which is a function of number, which is dependent on which is a function of epsilon and delta. So, the whole idea is that, as long as… And, is large enough given the delta and epsilon, you will be able to say that, this probability greater than delta is less than epsilon. So, that means when I choose delta and epsilon small, then this is essentially saying that, the number X n bar comes close and close to mu. So, this is greater than delta whatever I mean… So, the event will become impossible, because if I choose epsilon very small, then this probability is very small; so, of this difference being greater than delta; so, in probability. So, the whole thing is being talked about in terms of probability. So, the proof is simple.
And, here I will use Chebychev’s inequality. So, by Chebychev’s inequality, this says that… Here as we have seen already that, for X n bar, the variance… because they are identically independently distributed, will be sigma square by n. And, the variance and the expected value of X n bar is mu. Therefore, this is X n bar minus is expected value. So, this difference in absolute value greater than delta would be less than or equal to sigma square upon n delta square. So, now, here I did say that, epsilon and delta are arbitrary, but see I can choose the epsilon to be sigma square upon n delta square. So, in a way, epsilon is a function of delta; that is ok. So, then this is… I will choose the epsilon to be sigma square upon and delta square. And then that will give me that, n must be…; that means this number if I denote by epsilon, then this probability is less than or equal to epsilon for n. So, from here n – the smallest value of n would be sigma square of epsilon delta square. But, for all n greater than this number, this inequality will be satisfied. And so, the number capital M epsilon delta can be chosen like this.
So, once we get that n is greater than or equal to sigma square upon epsilon delta square, this inequality is valid. So, what we have shown is that, given epsilon and delta greater than 0, we can find an n such that this inequality is satisfied for all values of n greater than or equal to sigma square by epsilon delta square. So, this is the M of epsilon delta in the definition for limit of the probability when we defined what we mean by limit in probability sense. So, then this is the M of epsilon delta. So, for all n greater than or equal to this given in epsilon and delta, then for all n greater than or equal to this number, this inequality will be satisfied. And therefore, it follows immediately that, this limit of probability of X n bar minus mu in an absolute value goes to 0 as n goes to infinity, because as n becomes larger and larger, I can choose epsilon smaller and smaller here. This was my… This is greater than or equal to delta here I have chosen; yes.
And so, in my definition for when I defined the limit of a probability, then we chose… This is the epsilon we chose – sigma square upon n delta square. So, what we are saying is that, this probability, that is, X n bar minus mu an absolute value greater than or equal to delta is less than or equal to epsilon. So, when I want… So, if I choose this equal to epsilon, then I am saying… And therefore, as epsilon becomes smaller and smaller, n will become larger and larger. And so, from my definition of limit in terms of probability, it follows that, this probability will tend to 0 as n goes to infinity. So, this is what we… 
Therefore, you see again here that, I have made a very good use of Chebychev’s inequality to show you that, this probability – the limiting value of this probability of absolute value of X n bar minus mu will tend to 0 as n goes to infinity. Then, this satisfies the… So, by Chebychev’s inequality, this will be satisfied. And so, we have shown that, x n bar will converge to mu in probability. So, essentially, this is what… So, when you take the limit as n goes to infinity, then this number goes to 0, because as n goes to infinity, epsilon tends to 0. And therefore, this limit of the probability X n bar minus mu will go to 0 as n goes to infinity. So, essentially…
Now, of course, there can be different interpretations; and one of these students interpreted this as like if somebody who is practicing to be let us say a swimmer; so, what he will say is that, that means, no matter how hard I practice, my average performance will remain the same, because in probability, X n bar is converging to mu. So, that means he says that, there is no scope for improvement. But, again the fallacy in his argument is that, see here this result we are proving under the assumption that, X 1, X 2, X n – this sequence is independently identically distributed. 
So, the identity part is not valid when you are practicing; obviously, these things are improving. So, your performance is improving every day. And therefore, to say that, you will never rise above the… that means, your average performance will remain the same no matter how hard you work, is not correct, because your ((Refer Slide Time: 46:31)) themselves are changing; they are no longer identically distributed. Therefore, this is not a good way to interpret the weak law of large numbers, but it certainly gives you a tool for estimating the value of the mean of the distribution from which the random variables are coming.
(Refer Slide Time: 46:55)
 
So, we can now look at these examples to see the application of the weak law of large numbers. So, for example, if the sequence is from exponential 1 by lambda; that means, they are all identically independently distributed random… These samples you are taking from an exponential distribution with parameter 1 by lambda, that is, the PDF is 1 by lambda e raise to minus 1 by lambda x for all x positive. Then, this probability – if you take it X n bar here; X n bar minus lambda in absolute value greater than delta would be less than or equal to again by Chebychev’s inequality, because the… So, here expected X i is lambda – inverse of the parameter here, and variance X i is lambda square for the exponential distribution. Therefore, this would be less than or equal to lambda square upon… So, for the variance of X n bar would be therefore, lambda square by n. So, lambda square by n 1 upon delta square; and this goes to 0 as n goes to infinity. So, we can interact… We can choose… For any delta, we can choose epsilon as I showed you here; and it will satisfy the definition anyway. Therefore, what we are saying is that, X n bar would be a good estimate for large enough n, would be a good estimate for lambda for the mean of the distribution.
Similarly, if you have a Poisson… If you have this family; if the sequence is coming from a Poisson distribution with weight as lambda, then again this will be… So, here you have E X i is lambda. And, variance also is the same for a Poisson. So, this is also lambda. And so, for variance of X n bar would be lambda by n. And so, this probability greater than delta would be less than or equal to lambda upon n delta square. And, this will again go to 0, because lambda and delta are finite as we said that, we are talking about the situation, where the mean and the variance are finite. So, this will again go to 0 as n goes to infinity. And similarly, if you take this sample from… So, I am just giving you a few examples, but you will see that, this is universally true, because there we did not specify; we simply said they should be dependent identically distributed random variables. So, give 3 examples here.
And, if this sequence is from a normal mu sigma square, these are the sample values; then again this will be less than or equal to… So, now, here again E X i is mu and variance X i of course is given to be sigma square. So, variance X n bar would be sigma square by n. This will also go to 0 as n goes to infinity. So, Chebychev’s inequality has proved to be a strong tool for proving weak convergence. And, we will see that, the other… I showed you application of Jensen’s inequality also. And, we will also again look at some more limit theorems, where also we will make use of these inequalities. Therefore, the whole idea is that… Again one needs to emphasize the fact that, we are not saying that, the value that, the X n bar will… In value tend to mu, what we are saying in probably – it will tend to… Therefore, when we say it is a good estimate, this is in terms of probability; if the probability is very high – of this number becoming closer and closer to mu…
So, again, as I said, matter of interpretation, you might say that you go to a casino and you go on putting money in the machines – slot machine; and say for a number of times, you are not successful; so, you will say that, no, it will soon happen. But, that is not true, because again it is the matter of probability. Yes, the probability is high, because the event is getting impossible; I mean this probability is getting to 0; that is fine. But, it may happen that you may have to go on playing at the slot machine for a long time before your luck turns; that means the things change. 
Therefore, one should not say that, yes, surely, what we are saying here is that, it will happen; that means if you flip a coin and you keep getting tails; then surely after sometime you will get heads also. But, it does not say when. And, this is a matter of… So, the important thing to understand is that, we are talking in terms of convergence in probability. And so, this gives you a good way of estimating the mean of the distribution; that means you go on taking large enough samples and then you take the average, and that will give you an idea of what the mean of the distribution is.
(Refer Slide Time: 52:43)
 
So, we will continue the discussion with the central limit theorem and what we are saying is so… Here I want to address the questions for example, what does the distribution of X n bar look like? This is one question we want to answer; and we will use the central limit theorem to do that. And then the second question would be how fast does X n bar converge to mu? So, now, let us look at the… The central limit theorem states that, sigma X i minus n mu upon under root n sigma will converge to n 0… that means, normal – standard normal distribution as n goes to infinity; that means, this variate will… because this is a random variable for all n. So, this will converge to the standard normal variate as n goes to infinity. Now, here because expected value of sigma X i – i varying from 1 to n will be n mu; and variance of sigma X i; i varying from 1 to n will be n sigma square; the X i’s are sequence of independently identically distributed random variables. So, this is… And therefore, you are standardizing by subtracting the mean of this variate. So, minus n mu divided by the standard deviation, which is root n sigma. Therefore, this we are saying that, after standardizing the variate sigma X i, i varying from 1 to n, central limit theorem says that, this will go to n 0 1. So, in this distribution.
And, the weak law of large numbers said that, in probability, sigma X i, that is, sigma X i by n will converge to mu in probability. But, what we are going to say here show… This is to answer the first question, that is, if you now divide by n, then this becomes sigma X i; i varying from 1 to n divided by n. And, there will be an n here and there is a root n. So, that becomes root n times divided by sigma. So, this whole thing. And, we are saying that, this was… Therefore, now, this is… And therefore, the central limit theorem says that, this converges to this variate, will converge to the normal 0 1. So, I can write down sigma upon root n here. And so, essentially, what we are saying is that, X n will converge; that means the distribution of X n bar as limiting distribution of X n bar will be…
So, right now, the distribution of X n bar for large n we are saying will be close to mu normal – mean mu and sigma and variance sigma square by n. And then of course, as n goes to infinity, we are saying that… So, in other words that, the central limit theorem says that, if you take any distribution, the X 1, X 2, X n were coming from any distribution; but, then when you talk of X n bar and for large enough n, then the curve will become bell-shaped; it will get closer and closer to the normal curve for large n. And, the limiting value – this will converge to variate, which has the normal – standard normal distribution. And so, CLT – the central limit theorem implies the weak law of large numbers, because weak law of large numbers only said in probability X n bar will converge to mu. The probability of mod X n bar minus mu will converge to 0. And so…
But, here it is saying that, in distribution. So, X n bar in distribution will converge to standard normal… I should not say, because if I am taking X n bar; if I am simply taking X n bar, then this will converge to n mu of… So, I have simply said it here for X n bar; I have not talked of the limiting value. What we are saying is that, this will be approximated by normal mu comma sigma square by n. So, the proper statement is that, X n bar – the distribution of X n bar for large enough n will look like a normal mu comma sigma square by n. But, you can see that, as n goes to infinity, this thing will become… So, the whole mass will get concentrated on mu only for X n bar. But, then if you look at X n bar minus mu, this absolute value. Then, we are saying that, the… Or, if you are looking at X n bar minus mu upon sigma by root n; then this will converge to… so that this can be approximated by standard normal. But, when you look at X n bar, then this will be approximately normal mu comma sigma square by n.
(Refer Slide Time: 57:37)
 
So, the final theorem we can now state as… So, if you have X 1, X 2, X n and so on – sequence of identically independently distributed random variables; each X i having mean mu and variance sigma square, and this variance is finite. So, if the variance is finite; that means the variance exists; then the means will exist. So, we do not have to separately say that, mu is also finite and variance is also finite. It is enough if you say that, the variance is finite. Then, it implies that, the mean also exists. Then, the distribution of – see this is important – of X 1 plus X 2 plus X n minus n mu upon root n sigma. This converges to the standard normal distribution – 0 1 as n goes to infinity. This is what… that is, in other words, we want to say the same thing is that, the probability that X 1 plus X 2 plus X n minus n mu upon root n sigma is less than or equal to a. 
This will converge to form – there 1 upon root 2 pi integral minus infinity to a e raise to minus 1 by 2 x square dx for all a belonging to R, because this is the cumulative distribution function for… So, this is what you are saying is this is probability Z less than or equal to a; which I have written down here; that is, if you define the random variable Y n as sigma i varying from 1 to n of X i minus n mu upon root n sigma; then the cumulative distribution function of Y n as n goes to infinity will converge to the cumulative distribution function of the standard normal variate Z, and this is for all a.
And, this is what remember; earlier I had defined convergence in distribution or in law, which said that, the cumulative distribution function of sequence of random variables converges to a particular cumulative distribution function; then we say that, this sequence of random variables converges to that particular random variable in law or in distribution. And so, here this is what we are saying that, the sequence of random variables Y n as n goes to 1, 2, 3 up to infinity; then this sequence of random variables converges to standard normal variate in law. So, now, we had looked at the central limit theorem in various forms; its implications. And of course, we will continue looking at its applications more and more.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 21
Central Limit Theorem

(Refer Slide Time: 00:14)
 
So, we will as I said in the last lecture, we will now after having stated the central limit theorem, talk to you about its importance; we will actually see now once I prove the theorem and then I give you applications, you will see how important the theorem is, and how widely used the theorem is. So, as we said that the central limit theorem say that if you have the sequence of identically independently distributed random variables with mean and variance finite, then we say that this, sum of these random variables x 1 plus x 2 plus x n, it will have mean mu and variance n sigma square. 
So, this will go to, this will converge to N (0, 1) as n goes to infinity; that means the distribution no matter what the original distribution of the exercise was; now when you take the sum and you let n go to infinity, then this random variable will converge to the standard normal variant. So, this is convergence in distribution, right. Or in other words, as we can state it in other way also, this is for any, a which is from minus infinity to infinity of finite number. Then, the probability of this number being less than or equal to this random variable, less than or equal to, a, will converge to the standard normal; that means, this is your F z a, fine; and this is your F z n a. So, this converges to this as n goes to infinity. So, in distribution the convergences they are, right.
Now, in order to prove this I need to use this lemma which talks about uniqueness of the m g f, and I will not give a proof for this. We will just except the lemma as it is. So, this says that if z 1, z 2, z n, again is a sequence of random variables having distribution functions F z n, and m g f M z n, right; and greater than or equal to 1. So, the distribution function is F z n, and the m g f of z n would be M z n, and greater than or equal to 1. Let z be a random variable having F z as its distribution function and M z add its m g f, right. 
So, then we, if M z n t converges to M z t that means as n goes to infinity this movement generating function converges to the movement generating function of the variant F z, then we say that the corresponding distribution functions will also converge to the distribution function of z; that means, if, so this is, this talks about the uniqueness of the m g f. That means, if the m g f, M z n t converge to M z t for the variant z, the m g f of z is M z t; as n goes to infinity then the corresponding distribution function of z n which is F z n t will converge to the distribution function of z, for at all points t at which F z t is continuous which means that it is defined, right. 
So, this is the idea; that means, m g f uniquely, and while discussing m g f, I also tried to tell you that m g f uniquely give you your density function or the distribution function because the parameters you can compute; and actually not only the parameter, but the distributions are, is the same. I mean, once you get a m g f you can uniquely fix the distribution, right, of their form of the m g f function. 
So, this is what we are stating here, which we have also been using otherwise. So, now, let us; so the proof is not very difficult to straight forward. So, I am just rewriting this function, this random variable, mu is getting attaching to each of the exercise. 
(Refer Slide Time: 04:22)
 
So, therefore, the same thing can; so now, I am writing the m g f of the random variable which we want to show well converge to standard normal variant and distribution. So, this can be, at a point t, I am defining the m g f. So, this is in fact, e raise to this whole thing into t, right. The m g f of this would be e raise to whatever you want to call it, y n or something, or z n, then e rise to z n t. 
So, m g f excepted value of e raise to z n t you can say, right; which I can write as x 1 minus mu upon sigma root n plus, x 2 root n plus x 2 minus mu, and so on. Now, since x 1, x 2, x n, are identically distributed and independent random variables, so the m g f here, by again by the property of the m g f; well, the thing is that, yes, I should have; so yes, the order has been a little, because I will be talking of the m g f for the independent random variables, you know, more than 1 variable.
So, that should have come, the lecture should have come before that; ok, anyway we can talk about it. So, what I am saying here is that this m g f can be written as the product of the m g f of x 1 minus mu upon sigma root n raise to n because of the independence. This anyway also follows from independence because you see, when you write this let me say, I was saying z 1 plus z n, and you are taking t. So, when you write expectation of this, right, because the p d fs are. 
So, this will be z 1 into F z n because the join density function would be this, right. So, your expectation when you write of this would be whatever given, n th order integral from minus infinity to infinity, depending on if the variants are defined; I am taking the general definition into d z 1, d z n, right. So, then you see you can separate out the integrals, and so each integral will be the m g f of this; and since they are identical it will be the same, right. I am writing f z 1, f z n, where they all the same, f z 1, f z 1. So, therefore, you can immediately see from here that this will be, that this m g f can be written as this because of independence and identically distributed random variables.
 Now, this I can write as, this should have been at t; m g f at t, right. And so let me just separate out this. So, this will be m g f of x 1 minus mu, and I am taking the variant to be t upon root n sigma; so this raise to n. Now you expand this; remember this is, when you writing this, so I am just expanding my t x, and this would be, this will be expectation of 1 plus t x plus t x whole square by factorial 2, and so on, and the expansion of e raise to t x. So, that is what I am doing.
And then, I am taking expectation inside because; so now, if you, in the central limit theorem when I assume that they have finite variance; so another assumption I should have made is that because I am using the m g f way of, I am using the moment generating functions to prove the theorem I should have also said here that m g f x i exist. And so obviously, we will be talking about all those, ts, at which the m g f exist, right, at which the m g f is defined. 
So, therefore, I take this expectation since the m g f exists. So, I can take the expectation inside because the series is convergent series, and so I can take the expectation inside. So, this is what you have raise to n. And, you see here, I am not considering higher powers of t because see this is square then it will be t q, t 4, and so on. So, I am just writing this whole as a, you know, higher order terms of t, powers of t, right. 
So, then see, expectation of x 1 minus mu is 0 because we have taken, assumed that each x i has mean mu. So, this term is 0, and therefore you will be left with this thing. So, and expectation of x and minus mu whole square would be sigma square. So, this is 1 plus sigma square t upon, should be t square and sigma square; there should have been a 2 also; sorry, this will be 2 factorial, and so on. So, therefore, there will be a 2 here, right, because t x square upon 2 factorial, and so on; and then higher terms, higher order terms of t, right; this raise to n. 
Now, so as n goes to infinity, you see, because n raise to half is in the denominator. So, then when you say take the third power it would be n raise to 3 by 2, and so on. So, these things will go to 0 as n goes to infinity. So, but here; so I will ignore this; and then you see what happens to this; 1 plus sigma square. So, the sigma square cancels out, t square by 2 n, right; and so if you write this as t square by 2 into n, and then raise to n. So, I hope, you know, that most of you that this will converge to e raise to t square by 2 because n in the denominator and then n power. So, as n goes to infinity I can safely ignore these terms. 
So, then this will be, this will converge to e raise to t square by 2 because sigma square sigma square cancel out, and you are left with t square by 2 into 1 upon n raise to n. So, this converges to t square by 2 as n goes to infinity, right. And, you know that this is the m g f of random variant which is normal 0, 1, right. 
And so we have shown that using the lemma because I have shown that the m g f of this random variable, sigma x i minus n mu upon root n sigma, that converges to the m g f of a standard normal variant. Therefore, by the lemma I can assume that this random variable converges to N 0 1 in distribution as n goes to infinity. 
(Refer Slide Time: 11:30)
 
So, you know, using the m g f the proof really simplifies. And so in the proof I have used expression, small o of t upon root n sigma. So, the understanding is that this denotes terms of the type, t upon root n sigma raise to r, r greater than or equal to 3; say in that proof proving the central limit theorem I wrote down the terms upto t square, and then I wrote down that the later terms will all be having higher power of t upon root n sigma. So, this is the expression. 
And see, the understanding is that as n goes to infinity, this is for this expression; that means, because r is greater than or equal to 3. So, any way this will go to 0. So, that means, as n becomes larger and larger the terms that become very small. So, their contribution is negligible. Therefore, we ignore them, right. This is the idea. 
But now, for your convenience I have expressed, I have used this term for, this notation for also including the term expectation of x i minus mu raise to r. So, that means, I am taking that this now denotes for me in that proof, this into t upon root n sigma raise to r for r greater than or equal to 3. But then, since we have assumed that the m g f exists for all x i, x i s are all identically distributed. So, the m g f exists; that means, all movements exists. 
So, all movements are finite, and therefore, these numbers are finite for all r; hence the same thing apply; that means, if this becomes small then n becomes larger and larger; this whole thing also becomes very small and goes to 0, right. So, this is the idea that as n goes to infinity this will go to 0. So, therefore, we can neglect the term. So, this is, I have used this expression elsewhere also. 
And, so this is, the understanding is that when you write small o then it means that these are higher order terms whatever you have written down beyond that all higher order terms; that means, of power higher than 2, here for us the way I am using it r greater than or equal to 3. So, therefore, for large n I can ignore such terms in my sum. 
This version of c l t, central limit theorem goes under the name of Lindberg Levy theorem also. Lindberg in 1922 and Levy in 1925 independently gave this theorem; we showed, proved this result; so independent of each other in 3 years gap. So, therefore, this is also sometimes known as the Lindberg Levy theorem, but most commonly it is referred to as the central limit theorem. 
So, the proof is simple. It just using the independence identically distributed random variables and the properties of the m g f. So, through the property of m g f you could show that this sum of the random variables which are independent identically distributed random variables will, minus n mu upon root n sigma, converges to a standard normal variant. 
(Refer Slide Time: 14:36)
 
So, now let us look at this interesting example. This is from Mishra, and I will give you the references at the end of the course. So, a casino has a coin and wishes you know remember casino is people bet; and so game is tossing a coin to show a head. So, casino has a coin and wishes to estimate p the probability of the head on any toss in such a way that they can be 95 percent confident that the estimate p hat is within 0.02 of p. 
So, obviously, they want to have, an idea is to how what is the probability that the coin will throw, show a head when it is tossed. It is important to them because every, whenever a head is tossed then it will be person who is playing the game wins. So, the casino has to pay. So, therefore, they want to be confident that whatever their estimate is that is within 0.02 of p, the actual p, right.
And so weak law of large numbers helps you out here. So, given an epsilon and delta greater than 0, we know that there exists a n naught; this smallest value of n such that for all n greater than or equal to n naught, probability of x n bar minus p greater than or equal to delta is less than epsilon, right. So, for all n greater than or equal to n naught, this difference is greater than or equal to delta is less than epsilon, right. 
And so the complimentary, the event would be that probability x n bar minus p in absolute value is less than delta. So, this probability is greater than or equal to 1 minus epsilon. So, the casino, for the casino problem your delta is 0.02. So, that your x n bar is within 0.02 of p, right. So, it can be either little less than p with; that means, it can be p minus 0.02, and p plus 0.02. So, this is what you want. 
So, your x n bar should be in this interval. So, delta is 0.02; and here 1 minus epsilon is 0.95. So, this probability that your x n bar is within, is in this interval should be, the probability should be greater than or equal to 1 minus epsilon. So, that means, you would be 95 percent confident; this is the idea. So, therefore, just write out this. So, this is exactly what; so once you give the values of delta and epsilon you get that probability x n naught minus p in absolute value, should be less than 0.02. So, this probability should be greater than or equal to 0.95. 
This I do not need to write this because now I am using the value n naught. And, so when you expand this x 1 plus, x 2 plus, x n naught, upon n naught minus p, so this should less than 0.02 is greater than or equal to 0.95. So, this will; so therefore, you can find such an n naught; and therefore, the casino can, by tossing the coin that many times they can find out the estimate p hat for the probability of p. 
(Refer Slide Time: 18:17)
 
Same event can be rewritten as, this has to be or it was not really necessary because since we have said that there is an n, n naught which will do the job. So, therefore, I could have carried it as n only, and then I found it out, but anyway. So, therefore, this is therefore, this everything is n naught here, right. So, now, I have this event, and if I divide all the numbers by, under root n naught p q, because the variance of each x i is p q.
And therefore, the variance of x 1 plus, x 2 plus, x n naught, will be n naught p q; and so divide by the standard deviation; and then therefore, this event is the same as this. So, the probabilities are the same, right; 0.02 n naught, divided by under root of n naught p q. So, I divide throughout by under root n naught p q to, you know, standardize. And, therefore, this I am, this is my random variant now which is the standardized variant; and by c l t theorem, this is the standard normal variant, approximately, of course, right; approximately this is standard normal variant.
And, so probability is a function of, this probability would come out to be a function of because your numbers on the 2 end are, the interval in which you are founding, wanting z to be, that probability will depend on t. Now, the thing is that you are, see, if I find; so here again you have to do n naught, n naught. 
So, the whole idea is that if I put this equal to, if I put t maximum value of n naught p q here, then I will get the, because its denominator if I put the maximum value then this will be the smallest. So, if; that means, this interval will be the smallest; for the maximum value of this number it will be smallest interval; and so probability of this smaller interval, if this is greater than 0.95 then for any other p this probability would be greater than 0.95; that is the idea. 
So, my event what I am doing here is by writing the maximum value for this, this event will be subset of all other events whatever the value of p because q is 1 minus p, right. So, therefore, if this probability can be made to be equal to 0.95 or greater than or equal to 0.95, then for all values of p this will be greater than or equal to 0.95; this is idea, fine.
(Refer Slide Time: 21:02)
 
So, therefore, the and we know that the maximum n p q is 1 by 4 for all 0 less than p less than 1, we know this; I am sorry, for I am writing this p q. So, maximum value of p q is 1 by 4, and therefore, the required probability, since by c l t theorem this is standard normal, so this will be; now let we have started doing it. So, I will write n naught everywhere. So, this will be 5 of which is the, for the cumulative probability.
This is 0.04. So, if I am writing 1 by 4, so this will be 1 by 2; and so you take it here, and therefore, the 0.04 n naught, minus phi of minus 0.04 n naught, right; from here which by symmetry of the normal, standard normal variant this is 1 minus of this 5.04 under root n naught minus 1 minus this. So, this becomes twice 5.04 root n minus 1. 
And, now we want this to be greater than or equal to 0.95, and so when I compute the value of n for, by putting it equal to 0.95, then again for all values of n greater than or equal to n naught this inequality will be satisfied, right. So, the normal tables give me that; so if therefore, this probability becomes 1 plus 0.95 divided by 2. So, now, the normal tables tell me that corresponding to this value 0.975 that means the area under the normal curve is 0.975 that the corresponding value is equal to 1.96. That means, 0.04 under root n naught is equal to 1.96. 
So, from the normal tables corresponding to this probability I get at this number must correspond to 1.96, and therefore, your root n naught is equal to this which is 49; and therefore, your n naught greater than or equal to 49 square. So, that means, for that many sample value or that many trials you have. So, this, with this, that this number n naught which is greater than or equal to 49 square your estimate of p which will be obtained by p hat; so that p hat will be essentially your; so what we are saying is p hat is summation or you can say x 4 9 square bar.
So, this estimate of your p will be within 0.02 of your original p with probability 0.95. So, this is, you know, interesting application of your central limit theorem. And, because we could reduce the whole thing to computing the standard normal probability we got the answer here, right. Now, again I will just try to have a variety of examples to show use of this central limit theorem. 
So, now, here another question that is asked is if suppose you have x 1, x 2, x n, again a sequence of identical independent distributed random variables, and this random variables, right; probability x i equal to 1 is p, and probability x i equal to 0 is 1 minus p for all i; and again p is unknown, right. So, you want to estimate this probability. And, as I told you at, of course, the Greek law of large numbers tells you that x bar will, x n bar will be a good estimate, provided n is large enough, right. 
So, now, let us see, if you put; so now, let us define s n as x 1 plus, x 2 plus, x n; and let us fix t. So, here in this example I am trying to show you the, you know, the accuracy of central limit theorem. And, obviously, we expect better answer from the central limit theorem then if I just use the chebycheu’s inequality. So, this is the whole idea, now by doing, now wanting to do this exercise.
And, so here let us see that; so the question is using chebycheu’s inequality how large an n will guarantee, that this s n which is the sum of these random variables x 1 to x n. So, this divided by n minus p in absolute value is greater than or equal to t is; so if I have fixed the t; yes; so given a, t, then you want this probability to be less than or equal to 0.01, right. 
And, we will now here compare because how large an n. So, chebycheu’s inequality will also give me the answer, give me a value of n; and then central limit theorem will also give me a value of n. So, we will compare the 2 values, right. So, here expected s n upon n is p, and variance s n upon n is p into 1 minus p by n, right; because they are independent random variables identical. So, therefore, we will first use the chebycheu’s inequality, and then compute through the, an estimate n; and then through the central limit theorem also.
(Refer Slide Time: 26:42)
 
So, applying the chebycheu’s inequality because expect to tally of s n upon n is p and variance of s n upon n is p into 1 minus p by n. So, therefore, by the chebycheu’s inequality probability that s n minus n minus p in absolute value is greater than or equal to t. So, this is less than or equal to expectation of this square divided by t square. In other words, the variance of s n upon n; the variance of s n upon n is p into 1 minus p by n. 
So, therefore, by chebycheu’s inequality we get this estimate, and here again we are applying the same logic. So, I hope that you can easily see that the maximum value because if you have 0 less than p less than 1, we are, earlier this thing also I used the fact that max of p 1 minus p is equal to 1 by 4; you can easily check, I mean let us just spend a minute and try to see; that means, this is the function of p, and I can find out the derivative. 
So, the derivative would be 1 minus p by 2, right; and so this is I put this equal to 0. So, that gives me p equal to, I am sorry; this is 2 p because minus p square. So, the derivate is minus 2 p. So, this implies, let p is a half; certainly p cannot be 2 because p is lying between. So, this is a critical value, and to make sure that this gives you the maximum value the second derivate. 
That means, the second if I call, if I am saying f p is p into 1 minus p, then f prime p when you put 0 gives you p equal to half, and f double prime p is equal to minus 2 which is less than 0; so; that means, the critical value that we have obtained will be maximizing value. And, you see, p equal to half gives you the maximum of this, and you can also prove this by concavity, and so on, anyway. 
So, therefore, this is less than this; I mean here; and if I am putting the maximum value the, obviously, this equality will convert to inequality, is less than or equal to this. So, 1 by 4 n t square, right; and this should be equal to 0.01. So, we get the estimate for n; maybe I should put something like this, 1 upon 4. So, your n will be equal to 1 upon 4 t square into 0.01 which is 25 by t square. So, this is your chebycheu’s estimate of this probability; I mean for value of n for which this probability would be less than or equal to 0.01, fine.
Now let us try to apply the central limit theorem. And, the central limit theorem says that this variant when you take as s n by n minus p divided by, the standard deviation which is p into 1 minus p by n, right. So, you divide by, that is the root n go upstairs, and this is approximately normal, standard normal, right; for lodging of n i, you can say that this is approximately this. So, now, you want to compute this probability greater than or equal to t. 
And here again I will write this as; so I am standardizing it and therefore, dividing it by, dividing the whole thing by the standard deviation. So, that gives me the right hand side as root n t upon under root p 1 minus p. So, here again because this is greater, remember. So, then if I put the maximum value as again I do earlier this becomes smaller interval; and therefore, I should have said I think we have list out of the this things, sorry; the absolute value, right; and here also it should be the absolute value, fine. 
So, the interval, I said if you put the maximum value here then this becomes smallest, and so the interval is smallest. So, if the probability is; and then we are wanting the; so for larger interval the probability would be higher. So, therefore, if I am taking the smaller interval, the probability I am wanting to be what was our, this thing. The problem that first, the problem stated was that this should be less than or equal to 0.01. 
So, if I am saying that this should be greater, and so here if I am writing the maximum value, so what will it be; that means, I am wanting the mod z to be greater than or equal to z naught. And, if I am taking the smallest value here, so that means, if this is your 0 then you are asking for, yes. So, you are asking for this probability and this probability to be less than or equal to this. 
Now, if I am taking the minimum value here; that means, I am putting the maximum value here, then, obviously, you will be taking larger area. So, therefore, the value of n which satisfies for maximum value here, will satisfy for all values of p, right. So, this is the idea. Now, let us see; so this greater than or equal to; so therefore, I am substituting 1 by 4 for p into 1 minus p which gives me half, and so that may comes, makes it 2 root n t, right.
So, it is just the same argument, you would draw the figure and you can verify yourself. So, now, you see this is greater than or equal to 2 root n t. So, let me just show you the details here; that means, we are asking for probability z greater than or equal to z naught, right; which is the same as probability z greater than z naught union, probability z less than minus z naught, right. This will be the absolute value; as I said z greater than z naught and z less than minus z naught, right.
Now, these are disjoint events. So, therefore, I can write the probability of the union as the sum of the probabilities. So, this will be probability z greater than z naught plus, probability z less than minus z naught. And so this becomes 1 minus probability z less than or equal to z naught, and probability z less than minus z naught; see here again I can just show you the; so that means, if you have they are. 
So, if you are wanting z less than this is minus z naught; you are wanting this probability; but that is the same if you write z naught here, this is the same as this probability, right. So, therefore, probability z less than minus z naught is 1 minus of probability z less than z naught. So, z less than z naught is this whole probability. So, from 1 minus I will get this which is equal to probability z less than minus z naught, and therefore, I get this. 
So, this is 2 minus twice probability z less than or equal to z naught, where z is your standard normal variant. And, so the same thing I have used here, right. This is your z naught. So, this whole probability is 2 minus twice phi 2 under root n t which should be equal to 0.01. 
(Refer Slide Time: 34:37)
 
So, like you are finding the value of n for which this will be equal, and then higher values of n this will always be less than 0.01. And so this is 0.01, therefore, this tells me that 5 2 root n t; if you bring this to this side and this here, something wrong. So, you bring this to this side, and take this to this side. So, it will be 1.99 divided by 2 which is 0.995. 
And so you look up these standard normal tables, and corresponding to this probability the corresponding value of the variant is 2.57. So, from the normal tables I get that when this number is 2.57 the corresponding normal probability from minus infinity to 2.57 is 0.995. So, therefore, this gives me root n as 2.57 upon 2 t. So, the number by this central limit theorem; and therefore, this imply that your n is 2.57 upon 2 t whole square, right. 
So, this is our central limit estimate, and that is our chebycheu’s inequality estimate; now if you, third part of the question is compare the results for t equal to 0.01. So, for t equal to 0.01 the chebycheu’s inequality gives you a number value of n which is 250000, that means 250000. Whereas, the central limit theorem will only ask for this many sample values. 
So, if you want to estimate the, get the sample size say that s n upon n defers from p in absolute value by; you know, this difference, so that means, the probability that this is greater than or equal to t is less than 0.01. So, that number for central limit theorem is much much smaller compared to the chebycheu’s inequality. So, this was another aspect of central limit theorem which I thought we should have a look at. 
Then, another usage of central limit theorem is to how we approximate the chi square distribution for large values of n because you see that somebody is already done the calculations for the central limit theorem for the, sorry, for the normal variant, standard normal variant. So, we can make use of those tables to compute chi square distribution large values; now, for when the n is large. 
So, the idea here is that if you take x 1, x 2, x n, are again identically independently distributed random variables, each is chi square 1. So, this implies that expectation of x i is 1, and variance of x i is 2, right. And then, also we know from the reproductive property of chi square, in fact, through the joint m g f also we can show; and even otherwise we have seen that because each of them is independent identically distributed chi square. So, x 1 plus, x 2 plus, x n, will be chi square n, right. 
Through, this is, we have already seen it in one way that this when we sum of this independent identically distributed random variable. So, chi square has the reproductive property. So, this sum s n is chi square n. And later on we will also show through use of m g f how quickly you can say that the sum will be chi square n, if each is chi square 1, right, so anyway.
Now, by c l t theorem, s n minus n upon root 2 n, in distribution because we have standardized it, right, subtracting the mean of s n. So, s n will be, the mean of s n will be n because each is chi square 1. So, therefore, this is minus n upon root 2 n that will go into distribution to 0, normal 0 1, right, as n goes to infinity. So, or in other words, chi square is, the mean n normal; approximately you can say, mean n and variance 2 n. 
So, this is the normal whichever the way you want to put it. So, therefore, you want to compute this probability, remember. For large n you want to be able to compute this probabilities using the normal tables. So, therefore, when I standardize this will be s n minus n under root 2 n. So, this will be become a minus upon under root 2 n, right, which is the value 5 of, a minus n upon root 2 n. 
So, therefore, when n is large, I can, the central limit theorem will give me a good approximation. And so for large n this will be standard normal, close to a standard normal variant, and therefore, I can compute this probability for large chi square n by the normal, standard normal table. 
(Refer Slide Time: 39:56)
 
So, now I said I will show you how we can approximate the chi square probabilities using central limit theorem. So, let n be 100, and we wish to; so I shown you that, you know, the formula; I give you the formula; that means, you can standardize the chi square random variable, and used, by using the central limit theorem you can get the probability. So, let us compare the values for n equal to 100, right. 
And we will, so we want to approximate, a, so that chi square 100 less than or equal to the probability that chi square 100 is less than or equal to, a, is equal to 0.95, right, by using the central limit theorem, right. So, central limit theorem said that this can be converted to you see that phi chi square 100 minus, mean is 100 divided by, variance is 200, so under root 200. So, that becomes phi of, a minus 100 upon under root 200. 
So, this will be approximately because we are saying, let us see how if n equal to 100, how good, is it large enough for a good approximation. So, if you put this equal to 0.95 then by the standard normal tables the 0.95 probability corresponds to this value b equal to 1.645. So, therefore, you equate these 2 numbers, and that gives you, a equal to 100 plus under root 200 into 1.645; and that comes out to be 123.2638. 
So, using the central limit theorem, and then we just standardize this variant, right. And then, we said that if n is large enough this must be approximately normal 0 1. And so from there I get this probability. Now, from the tables for chi square 100 if you compute the exact value, then exact value of, a, that comes out to be 124. 342. So, you can see that the approximation is really very, very good; and this is for n equal to 100.
So, the point we are making is that we know if your n is larger you will get a better approximation, better than this; even the difference will be only at the decimal places. And so you can do, you can use your standard normal tables for computing these probabilities. So, this was one another point that I wanted to make about using central limit theorem results. 
So, now, another application of central limit theorem; the question is if x 1, x 2, x n, again are identically independently distributed random variables, and you are given that expectation of each variable is mu and the variance is sigma square, and also that the expectation of x i minus mu raise to power 4 is sigma square plus 1, which is, that is an infinity because sigma you are taking to be a finite number. 
So, the first question is does the weak law of large numbers hold for x 1 square, x 2 square, x n, I mean this sequence of square of the random variables. And, the second question is to find limit of this probability where x n minus mu whole square plus x n minus mu whole square divided by n. So, we are talking in terms of the squared random variables. So, because this central limit, the weak law of large numbers holds for x 1, x 2, x n, because your variance and mean are finite. 
So, now, the question is that is the, does the weak law of large number holds for x 1 square, x 2 square, and sequence of squared random variables. So, therefore, we need to for the, for answering part a I need to say that the variance of each is x i square is finite, right. And, for this I have just made this calculation that, you know, if you open up this expectation of x i minus mu raise to 4 because that is what you given, as sigma 4 plus 1. 
(Refer Slide Time: 44:21)
 
So, yes; and we miss this point, that for the weak law of large numbers I need to say that this x i squares are identically independently distributed, and they have finite variance. So, now, we have done enough of this thing to say that if x 1, x 2, x n, are identically distributed then obviously, x i squares are also identically distributed, right; this much of probability theory we have done so far. And then, that they would be independent can also, will also follow, right; because if x 1, x 2, x n, are independent then these will also be independent. So, I am sure you can work it out by all that we have done in the course by now. 
And now, to show that the variances of this x i squares are finite which will be the same. So, I have just done this exercise, and surely there may be other ways of doing it also, showing that the variance is finite. So, any way I just opened up this expression; you know, then I took expectation inside. And, you can see that, here for example, expectation x i cube, then into q, and then when you can get 6 x i square; now expectation of x i square I know which is sigma square plus mu square, right; because that is already given to me.
And then this expectation x i’s mu. So, therefore, this is what you get- mu 4 minus 4, mu 4 plus mu 4; and here it is 6 times sigma square plus mu square into, mu square, right. And, then, you can write down this thing here. And, this then tells me, see if example here, this is 3 mu 4, because this 6 mu 4 minus, 4 mu 4 plus, mu raise to 4. So, that is 3 mu 4; and this is c sigma square mu square. 
So, you get something like me these 2 expectation of x i raise to 4 minus, 4 times mu x i cube; this is equal to a finite number. And therefore, we can conclude that both are finite, right; and so weak law of large numbers can be applied. So, therefore, I needed this condition. If the x i’s are identically independently distributed, and if the fourth power expectation about the mean is finite then the weak law of large numbers can be applied. 
And now, this probability we just need to again standardize our, this thing. So, summation, i varying from 1 to n, sigma x i square whole square. Now, variance of x i minus mu whole square summation, variance of each x i; I mean when you want to compute the variance of x i minus mu whole square then you are looking for; I should have said this is variance of x i minus, that is ok; variance of x i minus mu whole square that expectation of x i minus mu raise to 4 minus, expectation of x i minus mu whole square, whole square, right; this expectation is squared, right. 
So, which now, since we are given this number which is sigma 4 plus 1, and this is expectation x i minus mu whole square is variance of x i which is sigma square; so raise to 2 will be minus sigma 4. So, the variance of each of this x i minus mu whole square is 1, right. And therefore, variance of summation i varying from 1 to n, x i minus mu; maybe I can rewrite this nicely so that it is readable. 
So, then what we saying is that variance summation x i minus mu whole square, i varying from 1 to n, this is equal to n because each of them has variance 1. So, by central limit theorem this summation i varying from 1 to n minus sigma square divided by root n because each had variance sigma square, mean of x i’s minus mu whole square is sigma square; so then n sigma square divided by, n mean sigma square divided by, root n. 
So, this goes to n 0 1, and distribution as n goes to infinity, and therefore, they required probability. So, therefore, I have divided by, here we are doing this; and yes, root n; if you want to write this as; I can just multiply by root n throughout; something is, you are wanting this to be less than or equal to 1. I am making it x i minus mu whole square, n minus sigma square; and then you are dividing by n, by root n; the required, this thing, we are looking for 1 by root n. So, variance x i minus; this is summation; variance summation x i minus mu whole square divided by n will be n upon n square which is 1 by n. 
So, therefore, you will divide by 1 by root n, and so that, you know, if I bring 1 by root n here in the denominator then this becomes 1. So, therefore, because this goes to standard normal, this whole thing as n goes to infinity. So, this required probability, see absolute this less than or equal to; I have divided by 1 by root n; so this becomes less than or equal to 1. So, this is twice phi 1 minus 1. We have already done this so many times in the absolute values. 
So, this is 2 phi of 1 minus 1; and again from the standard normal tables this is 0.8413; so this number. So, therefore, 2 into 0.8413 minus 1, and that come out to be this. So, integrate probabilities and so on, there is no n 2 in the results; and I will try to, I mean I think I will continue with the discussion on the central limit theorem in the next lecture also.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 22
Applications of Central Limit Theorem

 (Refer Slide Time: 00:14)
 
I will continue with the central limit theorem and its applications. This example I have taken from Sheldon Ross’s book on probability theory. See the idea here is that, civil engineers believe that W, the amount of weight in units of 1000 pounds at a certain span of a bridge can withstand without structural damage resulting is normally distributed with mean 400 and standard deviation 40. So, the weight, which the bridge can withstand is random variable. And so it is normally distributed with mean 400 and deviation 40. Suppose that the weight again in units of 1000 pounds of a car, is a random variable with mean 3 and standard deviation 0.3. So, the different cars will have different weights. Therefore again we have treated this as a random… I mean this example – the weight of a car is treated as a random variable. And therefore the distribution… And the distribution is normal – approximately normal with mean 3 and standard deviation 0.3.
How many cars would have to be on the bridge span for the probability of structural damage to exceed 0.1. So, at a particular time, how many cars are there, and then the weight of these cars exceeds the weight, which can cause structural damage. And so you want the probability of this whole random of this event to be more than 0.1. So, you want to estimate that. You want to estimate the number of cars that would be on the bridge, so that the structural damage can occur. So, we begin by defining P n as the probability that, there are n cars on the bridge, whose weight exceeds W, because that is… So, the event is this that, when it exceeds w, the structural damage can occur. Therefore, this is same as P n. So, this is X 1 plus X 2 plus X n greater than or equal to W. And, that would be… We can rewrite this as probability X 1 plus X 2 plus X n minus W greater than or equal to 0.
Now, X i’s; where, X i’s is the weight of the i-th car; X i denotes the weight of the i-th car. So, this is the total weight of the n cars, which are on the bridge at that time. And therefore, by central limit theorem, because for n large, we have said that, when they are identically distributed random variables – independent random variables, because of weight of each car is independent of the other. So, then sigma X j, j varying from 1 to n would be approximately normal with mean 3 n and variance 0.09 n. Standard deviation is 0.3. So, the variance of the weight of a car is 0.09. And therefore, the variance of the n cars is 0.09n. So, this is approximately this.
(Refer Slide Time: 03:45)
 
Now, W is independent of the X i’s because the weight that the bridge can withstand is independent of the weights of the individual cars. And therefore, where I write sigma X i minus W, this is also approximately normal; yes. And, we will again revisit all these summation of random variables and their distributions. But, right now, we have enough machinery with us to say that, sigma X i minus W, because this is normal – approximately normal. This is normally distributed. So, sigma X i minus W is also approximately normally distributed. And, the expectation or the mean of this normal variate is 3 and minus 400 with minus W. So, mean of sigma X i, i varying from 1 to n is 3 n, and this is 400. And, the variance of course, becomes with the plus sign comes with the plus sign, because they are independent. So, variance of this plus variance of W, which is 1600. So, this is the variance. And therefore, I can standardize.
So, the whole idea is that, this is the variate I am looking at. And, I have said that, this is standard… This is normal distributed with mean 3 and minus 400 and variance this. So, when I standardize, I will say this minus the mean divided by the standard deviation. So, that is standardized. So, now, Z is the standard normal variate and the event. So, when I standardize this, this probability now can be written as probability Z greater than or equal to. So, on this side, it will be minus of 3 and minus 400; I mean bracket minus 400 divided by the standard deviation. So, when I do this operation, I mean this probability is the same as this probability, because this I have standardized the normal variate – standard normal variate by subtracting the mean and dividing by the standard deviation. Therefore, this is equal to this. And so Z is approximately normal.
And now, we want this probability to be greater than or equal to 0.1; yes. And so we look up the tables for the standard normal and we find that, when Z is greater than or equal to 1.28, this is approximately 0.1. So, from the normal tables, I get that, this number should be 1.28 for this to be equal to 0.1. And therefore, greater than or equal to you want. See the whole idea is that, if the number of cars and it is such… So, now, this number – I can say that is equal to 1.28. Therefore, if you take it equal to 1.28, then you get an approximation for n. And, in the sense that, if you write less than or equal to 1.28; then obviously, this probability will be larger. And therefore, the whole thing will still be larger than 0.1; this is the whole idea. So, I get a value of n by equating this to 1.28.
And then n should be greater than or equal to 117. So, here of course, this is a little complex thing to solve, but you can do it or you can start by putting in values of n; and then you can find out for which value of n this is almost equal to this or little less than this. So, one can… There are lot of numerical ways of actually getting the value of n, which satisfies this inequality. So, we can do that. And therefore, it turns out that, n greater than or equal to 117 satisfies the above inequality. And so… that means, if there are more than 117 cars, then these structural damage may occur with probability 0.1. So, there is a chance of 1 in 10 that, the bridge will suffer structural damage. So, this was another interesting example. Actually, you can see the application in the sense that… And then also I chose this example for the reason that, this also is a random variable. And therefore, to convert this event to this event; and then to reduce this to use the central limit theorem and transform this to a standard normal variate; and therefore, get the estimate of the probability that, the bridge may suffer structural damage. So, the interesting example of the central limit theorem.
(Refer Slide Time: 08:27)
 
This is in a town of 20,000 people, 44 percent support an upcoming referendum vote. Say for example, currently, the hot thing is Anna Hazare going to form political party or not. So, you might take a referendum; that means you might ask people to vote on this whether he should do it or not. So, let us say… And, it is… That, the feeling is there. So, maybe this is a small town; and, the feeling is that, 44 percent will only support the upcoming referendum, but… So, then what you do is you conduct a pre-vote poll. So, this happens very often; media person do it; lot of magazines – they do it; they conduct their own pre-vote poll to get a feeling or the opinion – and, of the eligible voters in the town and surveys 100 people. Therefore, if for conducting a pre-vote poll of the eligible voters in their town and surveyed 100 people, what is the probability that the, survey will show that, the referendum will pass. So, one needs to understand what we mean by the referendum will pass. In order for a referendum to pass, it requires a majority vote or 51 percent.
See even though the feeling is there that, 44 percent support, but you never know at the time of the voting, more people may vote for the referendum and so on. Therefore, when you conduct a pre-vote poll and you surveyed let us say 100 people, then if in that pre-vote poll, it turns out that, 51 percent or more support the referendum; then you can say that, the pre-vote poll suggest that, the referendum will pass. But, actually, when the voting is done, and then if more than 51 percent people, who have voted; people who have voted – the 51 percent of those people – if they have supported the referendum, the referendum will pass. So, right now, this is just conducting a pre-vote survey of 100 people. So, then you want to know what is the probability that, the referendum will pass. Therefore, the question is… And therefore, that means, if you are taking a referendum – if you are taking a survey of 100 people, then you want 51 people to… Out of those 100 people, 51 should say yes for the referendum or support the referendum. This is what you want to find out.
So, the probability – therefore, one can model the situation using binomial random variables. So, X i is… I mean if the person supports; if the voter or the people you are surveying – they support the referendum, then X i will be counted as a success; otherwise, it is a failure. So, you will say that, sigma X I; i varying from 1 to 100 is binomial 100 with mean as 0.44 into 100, because probability of a success; that means, P is 0.44. So, I am writing here; I should have written only 0.44. This is not… This is only… So, the P is 0.44. And then the mean of the binomial distribution will be np. And, you want to find out the probability that, the people that you are surveying – the 100 people that you have surveyed, how many would support; that means, number of success is here should be greater than or equal to 51, because then the referendum will pass. 
And, that is why I chose this, because this is depicting a new situation and we are just trying to model it through this thing here and applying central limit theorem. So, this is a whole idea. And therefore… So, I hope this is clear that, this is sigma X i, i varying from 1 to 100 should be greater than or equal to 51. So, from this 100 people, if they get a feeling that, 51 or more will support the referendum, then they can sort of advertise and they can try to influence people and say that, the pre-vote poll says that, referendum will pass and so on.
(Refer Slide Time: 13:00)
 
So, standardizing this variate – sigma X i, i varying from 1 to 100; this will be sigma X I; i varying 1 to 100 minus 44 – the mean of this random variable, which is np – 44 divided by the variance, which is npq. So, 44 into 0.56, because p is 0.44. So, q is 0.56. Therefore, this is the variance. And so under root of that – the standard deviation. Therefore, this probability is equal to this probability. So, this is greater than or equal to 51 minus 44 upon under root 44 into 0.56.
Now, as I have been telling you that, wherever you want to approximate a binomial probability by standardizing the random variable and using a standard normal probability, then you should also use the continuity correction factor, which I have not done here. So, anyway. Therefore… So, that would be… If you are saying greater than 51, then it will be 50.5; that would be the right figure. But, anyways, you can do that computation later on. So, right now, the whole idea is just to see that. Therefore... So, to get a feeling for the kind of numbers that you have that, will the referendum pass or not. So, this is this. And therefore, under root of this comes out to be 4.96. So, this probability; and, this is a standard normal variate. Therefore, probability – this is equal to; or, we are approximating this probability by probability Z greater than or equal to 7 upon 4.96, which comes out to be 1.41. So, Z greater than or equal to 1.41. So, this probability, which from the tables gives you the number 0.079. Therefore, this is a very small probability. And hence, the chance of the referendum passing is very slim.
Then, the town is 20,000 and you are only surveying 100 people. And, when you know that, the chances of… There is a 44 percent support the upcoming referendum. So, the probability of 51 percent or more support the referendum is small; and, that is reflected here. So, through the central limit theorem, you have made this approximation to the probability through the required probability and it turns out to be 0.079. So, the chances of when you survey the 100 people and ask for their opinion – whether they support the referendum or not, it shows that, the chances are very small for the people.
(Refer Slide Time: 15:53)
 
So, again, I mean one can go on and on about the applications of central limit theorem and how to various different situations you can apply it. When I want to get back to… And, other thing that, we had also sort of use… We had used the central limit theorem, but probably did not… And, I have said that, we will prove it later on. But, I just want to add word of caution also to it. So, here this is that, we had X equal to… X is a binomial n comma p; and then we said that, if you want to compute this probability – X less than or equal to s; then you will have to compute these numbers; and, this can be quite messy; i varying from 0 to s. And, see i p raise to i; 1 minus p raise to n minus 1. So, this can be quite too cumbersome to compute. But, then we said that, we can approximate it by a standardizing this thing. And so here this is X minus np divided by under root of npq – the standard deviation. And then this is less than or equal to s minus np.
Now, you add 0.5. Remember I had talked about the correction factor when the binomial is a discrete random variable and we are approximating it by a continuous distribution. Therefore, this continuity correction factor is also added. So, you have 0.5 and this. Therefore, this probability – this cumbersome thing can be approximated by the normal probability, which is s minus np plus 0.5 upon under root npq. And, we look up the normal tables and we can compute this number. Now, the thing is that, of course, when you are approximating, the question does arise – how good an approximation it is?
And, see what happens is that, when for a binomial distribution, if p is close to half, then the binomial distribution is symmetric; in the sense that, the values keep on increasing and decreasing in a symmetric manner. And then because normal itself is also symmetric distribution about its mean; therefore, a normal distribution will give a good approximation as long as p is close to half, because then you are approximating a symmetric distribution – a discrete symmetric distribution by a continuous symmetric distribution. And so… But, when the p is away from half, then the binomial will be skewed may be to the right or to the left. And, in that case, it is not necessary that, the normal distribution will give you a good approximation of the binomial probabilities.
Now, it is said often that, if np is greater than or equal to 30 or np into 1 minus p is greater than or equal to 10, then the central limit theorem will always give you a good approximation of the binomial probabilities, but… And, these are empirical statements. And, in some cases, it may turn out that, when you have np greater than or equal to 30 or np into 1 minus p greater than or equal to 10, you may get good approximations, but it cannot be said that, this will happen all the time, because certainly, symmetry plays a role. And, for p small and n large such that np equal to lambda is moderate; so then in that case, Poisson approximation may be a good approximation. And, I had… When we were discussing discrete random variables, I had shown you that, how a Poisson probabilities can approximate the binomial probabilities. But, then of course, the condition was that, p is small and n is large, and np is moderately small, is reasonable number; then Poisson may give a good approximation for the binomial probabilities.
So, with this word of caution, of course, these approximations can be used and they are very helpful. And so I just thought that, once we have talked about the central limit theorem, we have proved it and shown its applications. I will just revisit what we had done earlier when we talked about approximating the binomial probabilities by standardizing the variate – normal variate and reducing it to a standard normal variate, and then computing the probabilities.
(Refer Slide Time: 20:32)
 
Now, which has problems for you to try on Chebychev’s inequalities, central limit theorem and law of large numbers – weak law of large numbers. Now, the first problem is straightforward; it says that a random sample of size and equal to 81 is taken from a distribution with mu equal to 128 and standard deviation sigma equal to 6.3. With what probability can we assert that, the value we obtain for X bar will not fall between 126.6 and 129. Chebychev’s inequality. So, you can see that, it will be… You will have the absolute value. So, X bar minus… When you essentially… I was saying that would be greater than 129.4 and less than 126.6. So, I have given it specifically, because I want you to then convert it to the form of the… when you are saying that, it is… when you apply Chebychev’s inequality or the central limit theorem. So, we have already tried given exam… I have discussed examples, where you can compute the probabilities given that, n is 81 and the standard deviation and mean are given to you.
Now, you just want to make a comment here is that, as we have seen through examples in the lectures that, the number n… For example, the probability that you get – the bound that you get by using Chebychev’s inequality on the required probability would be loose bound; and, the central limit theorem will give you a tighter bound – a tighter this thing on the probability. Now, the thing is… And, of course, you can also say that… But, one point that is important is that, the probability when you compute it by the central limit theorem, may sometimes depend on the distribution that you are handling; whereas, Chebychev’s is a universal inequality. And therefore, it may give you a loose bound; but, then the number does not change with respect to different distributions. So, Chebychev’s is the general statement – a universal statement. And, later on when I have occasion, I will again point out the difference between the… Even though we say that, Chebychev’s is a looser bound, there are other advantages of using the Chebychev’s inequality.
Question 2 – that the random variables Y n have a distribution that is binomial n, p; prove that, Y n by n converges to p in probability. So, this is the use of weak law of large numbers. I may have already done it for you in the lectures; but, anyway go through it and try to prove it by yourself. Then, the third problem is consider the sequence X n of random variables, where p n is X; probability of X n equal to X is 1, if x is 4 plus 2 by n and 0 otherwise. So, now, here the probability… So, X n is equal to X – the probability of that is equal to 1, if X is 4 plus 2 by n. Does it converge in distribution to some random variable X? So, that means, find out the… You will define the cumulative distribution function. As n goes to infinity, can you find distribution bridge. If so find the distribution function of X; show that the sequence X n converges in probability to X also. So, should be interesting thing, but we go by the basic definitions and then try to solve the problem.
(Refer Slide Time: 24:42)
 
Upon X to X n are identically independently distributed random variables with density function F X equal to 1 by theta and 0 otherwise. It should be equal to this – 0 less than theta less than infinity. Let M n be max of X 1, X 2, X n. So, M n is the random variable, which is the maximum of these n sample values; find the distribution function F n of M n. Does F n converge to sum F’s? Yes, it will. And, see but, we will not talk much about it because… The second part is a little difficult part, but you can certainly see that, F n will converge to some F. So, find the distribution function F n of M n. So, that part is okay; that you can do through the tools that you have already learnt, because when you find out the… To find the distribution function, you have to say probability M n less than or equal to t.
Now, since M n is the max of X 1, X 2, X n, this will reduce to probability that, each X 1 is less than t; X 2 is less than t; X n is less than or equal to t. And, since they are independent, this will reduce to probability X 1 less than or equal to t raise to n. Therefore, you can sort of do it in the regular way, and then see if you can get a feeling for convergence of F n; that is all; we will not talk in detail about it, because this becomes a little complex. If you have given that F X is 1 upon X square and X varies from 1 to infinity, 0 elsewhere. 
So, this is how you are defining this pdf; and, this is the pdf of a random variable X. Consider a random sample of size 72 from the distribution having this pdf. So, that means, the sample – identically independently distributed random variables – they are 72 of them; compute approximately the probability that more than 50 of the items of the random sample are less than 3. See the thing is now – that the problem… I have include this problem, because these two steps. See first is that, you want the probability that, more than 50 of the items of the random sample are less than 3. So, there is a probability I will use this here.
(Refer Slide Time: 27:23)
 
See you are given that, f x is 1 by x square; 1 less than x less than infinity. So, you are wanting to find probability x less than or equal to 3; this is the problem – that more than 50 of the items of a random sample are less than 3. So, this is x less than or equal to 3; this will be 1 to 3 of 1 by x square dx – the probability that random variable, which has this pdf. So, then the probability of x less than or equal to 3 will be given by this, which is minus 1 by x from 1 to 3. So, this comes out to be minus 1 by 3 plus 1, which is 2 by 3. So, now, what I will do is you are selecting a sample of size 72 and we will say that, if a sample has a value less than 3, then that is a success. Therefore, the probability of a success would be 2 by 3. So, now, this gets converted to a binomial situation; where we are selecting a sample of size 72 and we say that, if a sample value is less than 3, then it is a success. So, that means…
Now, the question is that, from a binomial 72 comma p – 2 by 3, I want a sample of the items. So, more than 50; that means, you want that, if you are writing sigma X i; so random variable X coming from binomial 72… Maybe I can write it here. So, essentially, what I am treating is that, X is binomial 72 and this is this. So, I am wanting that, probability X is greater than or equal to 50. And so when you standardize, this will be X minus… The mean is 2 by 3 into 72, which is… This is 24. So, 48 – 48. And, that will be 1 by 3. So, minus 9 – 16 – 4. So, this is greater than or equal to 50 minus 48; that is, 4; this comes out to be 9 ((Refer Slide Time: 29:49)). So, this is the whole thing. So, that is why I chose this example. Therefore, you have converted this to a binomial situation and then you are computing the approximate probability that, more than 50. So, here again, I am now using the central limit theorem; I am standardizing the variate there and then… Therefore, you are computing the approximate probability; because to compute the actual probability, would be – you will have to sum up those 72, 50 and beyond the binomial probabilities of 50, 51, 52 and 72. So, this is this problem.
(Refer Slide Time: 30:34)
 
Now, let us go to measurements are recorded to several decimal places. Each of these 48 numbers is rounded off to the nearest sum of these integers. So, when you say rounding off; that means, if the sum of the original 48 numbers; if the decimal is below 5, then you drop the decimal number point. And, if it is 0.6, 0.7, then you take it to the next integer. This is how we say that, when you round off the numbers is approximated by sum of these integers. If we assume that, the errors made by rounding off are independent and have a uniform minus 1 by 2 comma 1 by 2 distribution, compute approximately the probability that the sum of the integers is within 2 units of the true sum.
So, now, here we are assuming that, the errors made by the rounding off are independent; surely, that you can expect because the errors that occur are not dependent on each other. And then this… Therefore, the rounding off that, you are doing is between minus 0.5and 0.5; thus, I said if the number is something like 10.4, then you will round it off to 10. If the number is 9.7, you will round it off to 10 – an integer. Therefore, you are assuming that, the error part; that means, the actual number minus the rounding – that difference is uniformly distributed between minus 1 by 2 and 1 by 2. The approximate probability that, the sum of the integers is within 2 units of the true sum. Therefore, what we are doing is… So, you have 48 errors – 48 numbers that you are rounding off. So, sigma… And, each is…
(Refer Slide Time: 32:33)
 
Yes, I can again write here that… See epsilon i is the error in the i-th number. So, we are wanting that, summation epsilon… And, each epsilon i is… And, this is uniform minus 1 by 2, 1 by 2; each error is uniformly distributed. Now, you are wanting the probability that, this thing should be less than or equal to 2; I think this is the question that, the sum of the integers is within 2 units of the true sum; which means that, total error that occurs should be within 2 of the original; so that means, sigma epsilon i, i varying from 1 to 48 – this should be within minus 2 and 2; the error can occur either on the… when you round down or you round up. 
Therefore, this total error we are saying, what is the probability that this error is within two of the original sum of numbers. So, I have added up the errors. And so this sum should be greater than or equal to minus 2 and less than or equal to 2. This is what we want to approximate – this probability. And, that again by the use of central limit theorem, we will say because, now, epsilon i's are all uniform. Therefore, sigma epsilon i – expectation of this i varying from 1 to 48, is because the mean is 0. So, this is 0. They are all independent; the errors we have assumed are independent.
And similarly, the variance of sigma epsilon i, i varying from 1 to 48 will be sum of the variances and which will come out to be… So, the variance here is remember it is b minus a whole square raise to… b minus a whole square divided by 12; b minus a whole square by 12. So, this is… The variance here is 1 by 12 and so variance… This will be 48 by 12. So, the variance will be 48 by 12. And therefore, standard deviation will be under root of 48 by 12. So, I standardize. And, here this is what we get; and then by the normal this thing, it says that probability. So, this is actually equal to probability mod z is less than or equal to… This is 48 by 12. So, this is 1. And, that comes out to be 0.6826 from the normal tables.
Of course, you have to do some more competitions here and this will be… Therefore; that means the error can be kept within 2; the total errors of rounding up and rounding down can be kept within 2 with probability 0.6826. So, that is a very… There is high probability. But, if you look at a loose upper bound; that means if you are suppose rounding up all the numbers, then this will be 0.5 into 48, which will be 24. So, that means, an upper bound on the number of total errors – that can occur – can go up to 24. But, here the central limit theorem gives you the idea that, the probability that, the errors will be within 2 is reasonably high. 
So, this is something about the problem I wanted to talk to you about. Varying from 1, 2 and so on is a sequence of identically independently distributed random variables with expected value of psi and is mu, and variance psi and is sigma square. Now, if S n is the sum of the first n sample values, show that S n upon n goes to mu with probability p. This is again just reiteration of the weak law of large numbers. Then, I want you to sit down and work out the proof by yourself. X n… Show that mgf of… as n goes to infinity; t greater than distribution of Y n… And, square. See the notation because we could not get it.
(Refer Slide Time: 37:03)
 
So, X n I am saying is chi square n. So, we have talked about the chi square n distribution also. So, here this is the notation; it looks like… In the print, it looks like X n square, but it is actually chi square. So X n is chi square n and then Y n is X n upon n, because again we wrote X n instead of chi, because chi was not coming out nicely. So, Y n is X n upon n and show that, moment generating function of Y n will go to e raise to t as n goes to infinity, for t greater than 0. So, it is defined for t greater than 0. So, this you can work out. And then what is the limiting distribution of Y n. 
So, once you get the limiting mgf of Y n, then you will be able to say what is a distribution of Y n – limiting distribution of Y n. This is the whole idea through this exercise. And then show that X n minus n; where so X n is actually chi square n. So, chi square n has mean n and variance 2 n. Therefore, now we are standardizing this. So, this is actually the use of central limit theorem, because remember – central limit theorem is convergence in law. So, X n minus n upon under root 2 n for n large will converge to a standard normal variate. So, this is again the central limit theorem.
That X 1, X 2, X n are independent random variables with probability X i equal to 1 – p and probability X i equal to 0 – 1 minus p for i varying from 1 to 2n; that means, each X i’s… So, X i's are identically independently distributed Bernoulli random variables; p is of course, between 0 and 1 and it is unknown. So, this is what we have to estimate. I will get back to this thing. So, now, if you define S n as X 1 plus X 2 plus X n and you fix the t, then the problem says using Chebychev’s inequality, how large an n will guarantee that, the probability of S n upon n minus p is greater than or equal to t? So, the probability of this event is less than or equal to 0.01 no matter what value unknown p has. So, obviously, we are trying to say that, we want to find out how many sample values we should take – X 1, X 2, X n, so that this ratio S n upon n or the average of the sample values is different from p by… So, greater than or… t we have fixed. So, this difference greater than t – probability of that is less than 0.01. So, you want to use Chebychev’s inequality.
(Refer Slide Time: 39:57)
 
So, here by Chebychev’s inequality, as we said, this is S n by n minus p. So, this you want greater than t – probability of this; and, this you want less than or equal to 0.01. Now, by Chebychev’s inequality, because this is the variance of S n by n is because remember – now, S n is what? Each X i is a Bernoulli. Therefore, this is binomial. And so this is the variance of S n, is npq. And so 1 by n; this will be n square. So, this is pq by n. Therefore, by Chebychev’s inequality, this probability is less than or equal to… This is pq by n into t square. And, this you want to be less than or equal to 0.01. So, now, what it says is p’s are known. So, q is also unknown. And therefore, no matter what the value of p is…
Now, since maximum of pq… We have already gone through this in the lecture also; maximum pq is 1 by 4. So, if I take the… If I write the maximum value here since n is in the denominator; so this will… I will get the value of n, which is smaller. See what I am saying is that, this probability is less than or equal to 1 by pq by… This 1 by 4 into n t square. And, this we want less than or equal to 0.01. So, suppose I put this equal to 0.01. And, this tells me that, n should be equal to… From here n should be equal to… If you take n to this side, it will be 0.04 into t square. And, since I have written, see… So, this value has become 1 by 4, is the maximum value of pq. 
So, now… that means, for n greater than or equal to this, this will always be satisfied – less than or equal to 0.01; can you see that? See here I am writing the maximum value; this upon nt square is less than this. So, n would be greater than or equal to this. So, I am taking it… So, if I put the maximum value here, then obviously, I get a value of n, which will meet this inequality, because n will be greater than… Otherwise, if I write the actual value of pq, then what I get – the value of n would be smaller than what I am getting here. Therefore, this will always satisfy this inequality; this is the idea. Therefore, by Chebychev’s inequality, this is the thing.
Now, part 2 says that, using CLT, find the approximate n needed, so that… Now, here you see it has put the word minimum of this probability. And, the probability here is the compliment of the event that you had in the part a. Therefore, it is a same thing, because here the probability of less than t is greater than 0.99. So, exactly… But, the minimum part I will explain again here, because this is now…
(Refer Slide Time: 43:24)
 
By central limit theorem, minimum this… So, minimum this probability will be attained when I put the maximum value of this. And therefore, the minimum… When you write this here, this will be twice 5 and root n into t; and, this is 1 upon 4. So, 1 by 2, so that the 2 also comes here. So, this minus 1. So, that satisfies this. And now, you want to compute again. This you want to say is equal to 0.99; which means that, 2 of 5… 2 root n into t is equal to 1.99. And, now, you can continue. And, in fact, you will find out the value of t, because I think… Maybe we will complete the problem. So, this is 2 divided by this – 0.99; and, the corresponding Z value here; I think from the tables if you look up, it says that 2 root n t is 2.57; I think that is the thing. And so you can compute root n from here. And now, what it says is again… Since you have the numbers… In this case, n comes out to be equal to 2.57 divided by 2 into t whole square.
And, in the third part, it asks you to… When you fix the value of t, I think the value of t is given – 0.01. If you do this, then it wants you to compare. So, for example, from here when t is this, for t equal to 0.01, n comes out to be equal to 250000. And then when you compare it with the central limit thing, I think this comes out to be… It is computed somewhere; I have done it here – 16. So, n will be greater than or equal to 16500. So, this is the idea, because the Chebychev’s inequality gives you a loose upper bound. And therefore, the numbers will be different. So, this is the idea behind this thing. And now, you can sit down and work it out yourself to get a better feeling. Is equal to 1.99 and now you can continue. And in fact, you will find out the value of t, because I think…
Maybe we will complete the problem. So, this is 2 divided by this – 0.99. And, the corresponding Z value here – I think from the tables if you look up, it says that, 2 root nt is 2.57; I think that is the thing. And so you can compute root n from here. And now, what it says is again since you have the numbers… I mean in this case, n comes out to be equal to 2.57 divided by 2 into t whole square. And, in the third part, it asks you to… When you fix the value of t; I think the value of t is given 0.01 if you do this. Then, it wants you to compare. 
So, for example, from here when t is this; for t equal to 0.01, n comes out to be equal to 250000. And then when you compare it with the central limit thing, I think this comes out to be… It is computed somewhere; I have done it here – 16… So, n will be greater than or equal to 16500. So, this is the idea, because the Chebychev’s inequality gives you a loose upper bound. And therefore, the numbers will be different. So, this is the idea behind this thing. And now you can sit down and work it out yourself to get a better feeling.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 23
Strong law of large Numbers Joint MGF

(Refer Slide Time: 00:15)
 
So, now I will talk after having discussed the weak law of large numbers, we will talk about strong law of large numbers. And I will first just take the theorem, this is theorem simply says that if x 1, x 2, x n is a sequence of independent and identically distributed random variables. Each having a finite mean mu equal to expected x i then with probability 1, see this is the important thing.
Now, we are saying that the probability 1, this average of the sample values x 1 plus x 2 plus x n upon n will converts to mu as n goes to infinity. So that means, this is the sure event. So, therefore you can immediately see the difference between the weak law of large numbers, there it sets the probability such an probability x bar converges to or x bar n converges to mu here we are saying that with probability 1, x bar n will converges to mu, so that means, this is a sure event. Provided the expectation of each of the x i is finite.
So, before we start proving the theorem, let us just interpret what does it mean and what we are saying is that if you conduct sequence of independent trails of some experiment E, some experiment. Suppose, you conduct independent trials of an experiment, if say for example, test tossing 2 coins. So, you go on doing that and then E is the fixed event of the experiment. So, you decide that you just decide one of the events that will occur when you are conducting this experiment say for example, you are tossing 2 coins and you want 2 heads to appear three times, see you know one after another. Suppose E is that event, so you go on tossing the coin or the 2 coins and you do the experiment till you are ok. In this case I am talking of the occurrence of this thing. So, maybe we can say that I toss 2 coins ten times.
And then I want to see how many times I get 2 heads; that means, both the coins show head that would be event E for example. So, E is a fixed event of the experiment then and let P E denote the probability of the occurrence of E on a particular trial. So, this is probability of occurrence of E on a particular trial right. Now, define x i as 1 if E occurs on the i th trial. So, I am defining an indicator variable just to show you that how we can interpret this strong law of large numbers. So, it say that if x i is 1, if E occurs on the i th trial and 0 if E does not occur on the i th trial. So, this will be the indictor variable of the event E; that means, if E occurs on the i th trial will say x i takes the value 1, otherwise x i takes the value 0 right. So, then what the strong law of large numbers is saying that see this sequence x 1 plus x 2 plus x n upon n this is converging to mu as n goes to infinity with probability 1.
So that means, and what is this count x 1 plus x 2 plus x n. x 1 plus x 2 x n is the number of occurrences of E in the first n trials right, because x i is 1 E occurs in the i th trial. So, when you add up x 1 plus x 2 plus x n that will be the total number of times E has occurred, when you have conducted the first n trails. You just started and then you started counting, you started your trials and you started to count the number of times E occurs and that is given by x 1 plus x 2 plus x n right. So, number of and strong law of large number is saying that this ratio; that means, the number of times E has occurred divided by the total number of trials that will converge to your expected value of x i, which is equal to P E right. So, this is, if we are denoting the probability of the occurrence of E by P E. So, this is the probability of E right, I mean; I have denoted P E by the probability of occurrence of E. 
And so this ratio will converge to E x i, which is the probability of E right. And this is probability 1. So, this is certain event right. So, if you interesting interpretation and therefore, this, the strong law of large numbers reinforces our concept of the way we had defined probability through relative frequency. 
(Refer Slide Time: 05:30)
 
Now, let us prove the result. So, we have assumed that expectation of x i minus mu raise to 4 is equal to k is less than infinity. So, we are assuming that the fourth movement about the mean is finite and then we show that. So, let us define S n as sigma i varying from 1 to n, x i minus mu then we want to compute expectation of S n 4 right, which would means that sigma x i minus mu this whole thing, i varying from 1 to n this whole thing raise to 4 expectation of this. So now, if you expand this so I should have a mu here also summation.
So, this should be sigma x i minus mu, I am writing sigma this. So, therefore, this whole thing is 4. So, this should be this right and then this whole thing is raise to 4. So, sigma x i minus mu i varying from 1 to n and I am saying S n 4. So, this whole thing raise to 4 and then this expectation. So, when your x i taking the fourth power, sigma x i minus mu raise to, this whole thing raise to 4. So, therefore, I am now, expanding this by the binomial theorem. So, this will be summation i varying from 1 to n, x i minus mu raise to 4 right. So, this is your up to n terms each raise to forth power then you will take 2 at a time, product of 2 at a time. So, it will be 4 times sigma i j varying from 1 to n, x i minus mu cube into x j minus mu, where i is different from j right. 
And similarly then you will again take 2 at a time i and j. And this will be six times x i minus mu whole square into x j minus mu whole square summation i j from 1 to n, i again not equal to j. Then you will take three terms at a time so i j k and that will be plus four times summation i j k all varying from 1 to n, but i is not equal to j is not equal to k. So, all three in this have to be different and this will be x i minus mu whole square into x j minus mu into x k minus mu. And finally, product of four terms, where again i j k l are all different, I should have said here I not equal to j not equal to k not equal to l right and this is also varying from 1 to n right. So, this is x i minus mu into x j minus mu into x k minus mu into x l minus mu. So, this is the expansion. S n raise to 4 and so the expectation is all outside. So, this is the big bracket and the expectation of this. Now, of course, expectation can go inside so linear function. 
So, in the sense that yes, so expectation can be taken inside then I have assumed independence of the random variables x 1, x 2, x n. So, then expectation of the product is product of 2 random variables is the product of the expectations. So, E can also go inside here now inside the summation sign and since expectation of x i minus mu 0 for all i. So, you see that the expectation of this will be 0 and similarly this will not be 0, but here again you have linear terms.
So, expectation of this and expectation of this will also be 0 and here of course, all the four expectation will be 0, because these are independent. So, this will be summation expectation of x i minus mu into expectation of x j minus mu and so on. So, these terms will disappear. So, you are only be left with sigma i varying from 1 to n, x i minus mu raise to 4 and then 6 times summation i j varying from 1 to n, i not equal to j, x i minus mu whole square x j minus mu whole square.
Now, we have already assumed that this is equal to k and this is less than infinity. So, here you have n such terms, again independence tells you that you can just add up these numbers, you can add up k n times. So, this will be n k and then here, you are saying i is not equal to j. So, the choices you can have is n into n minus 1 by 2. So, this many pairs you can have such i j. So, that i is not equal to j. So, therefore, this will be n into n minus 1 by 2. So, that will cancels out with 6 or will be 3. 3 times this is what you will get.
(Refer Slide Time: 10:23)
 
What we are saying is that since variance of x i minus mu whole square, because I am assuming that this always non negative. So, this is equal to expectation of x i minus mu raise to 4 right. If I give write the expression for this. This is the fourth movement expectation of, fourth movement about mu minus expectation of x i minus mu whole square the variance of x i minus mu whole square. 
So, that will be expectation of the square of square of this. So, just say to 4 minus expectation of x i minus mu whole square then whole square right. This of course, is your variance of x i so anyway. So, then since this is non negative therefore, this is from it follows that your expectation of x i minus mu square whole square is less than or equal to expectation of x i minus mu raise to 4, which we are taking to be k. So, therefore, this is also finite right. So, therefore, everything is finite here right. These things are also finite, because this square is finite so therefore, both of these are finite. So, therefore, expectation of S n 4 is less than or equal to if you want to write n k plus 3 n into n minus 1 into k, because each of them is less than or equal to root k. So, that becomes k here right.
And therefore, when you divide the whole thing, both the sides by n raise to 4 expectation of S n 4 divided by n 4. So, this becomes k by n cube 3 k upon n square into 1 minus 1 by n. So, this you can utilize for large values of n. So, this will become 1 right. Now, since 1 upon n cube sigma 1 upon n cube n sigma 1 upon n 4 are both convergent series right. Remember, because sigma 1 by n cube n sigma 1 by n 4. So, n goes to infinity 1 to infinity these are convergent. So now, I can take the; that means, when I take the summation here, this is convergent series, because both these series are convergent. And so I write expectation of sigma and varying from 1 to infinity S n 4 upon n 4 is equal to this, because since this is convergent series, I can take expectation inside. And so I get this here right and yes. So, see this is what we have shown is that this is finite right.
Expectation of S n 4 upon n raise to 4 summation n varying from 1 to infinity, this is a finite series.
(Refer Slide Time: 13:10)
 
So, therefore, with probability 1, this summation n raise to 1 to infinity S n 4 upon n 4 should be less than infinity. I mean see actually, we have shown that each of this is, because each of this is k upon n cube plus 3 k minus n square into 1 minus 1 by n. So, therefore, this summation, when I take the summation here, sigma 1 by n cube sigma 1 by n square they are both convergent. So, therefore, this is a converge series, but because this is we can take E outside right, because of linearity. So, then this is finite expectation of sigma and varying from 1 to infinity S n 4 upon n raise to 4 is finite. And so we are saying that the inside thing the, this expression or this series must be finite, because if there is some positive probability that the sum is not finite. 
If this sum is not finite then its expectation will not be finite and we have shown that the expectation is less than sigma expectation this thing and therefore, that thing is finite. So, this must be finite, because if there was any positive probability that this is not finite then the expectation would not be finite. So, therefore, I am saying with probability 1. So, this is the main point right. I will repeat the argument that, we have said that this is a finite series, but this I can rewrite as expectation this right. And why we are saying this, because this whole is finite, because of this was not finite then expectation would not be finite, but here we have this is, this whole thing is finite. This is equal to this and this is finite. So, therefore, sigma n varying from 1 to infinity S n 4 upon n raise to 4 is finite.
And if a series infinite series has a finite sum it is a convergent series then the n th term must got to 0. Otherwise again from your convergence of series, you know that this is the necessary condition that the n th term must go to 0, if the series is convergent. So, therefore, sigma S n 4 upon n 4, n varying from 1 to infinity less than infinity implies that the n th term must go to 0, as n goes to infinity and if the now this goes to 0 then the fourth power 1 one fourth root of this will also go to zero. So, therefore, limit s n upon n as n goes to infinity is 0 right. And so just replacing the value of S n here, this is sigma x i minus mu by n, n varying from 1 to such a i varying sorry, i varying from 1 to n limit S n goes to infinity is 0 right. And so you can just take summation inside here. So, sigma x i by n i varying from 1 to n limit n goes to infinity is mu. So, this is with probability 1.
So, essentially here I just needed the a fact that to prove this strong law of large numbers; that means, first of all let us just we clear. So, what we are saying is that this will happen with probability 1 so; that means, it is a sure event. And so as n goes to becomes larger and larger what we are saying is that this x n bar, your x n bar will converge to mu. So, little get closer and closer to mu and this is a sure event this is happening with probability 1. In the weak law of large numbers I be just simply said that the probability of x n bar minus mu see this value greater than delta probability of this could be shown to be less than epsilon and then of course. So, therefore, this was only in terms of probability now here we are this is the sure event that x n bar must go to mu as n goes to infinity ok.
Now, the thing is n of course, here I just needed the fact that expectation of x i minus mu raise to 4, this thing is less than infinity right. So, what I want to say is that if the kind of distribution that we have discussed in this course all of them I could show you the existence of m g f and I have not taken any distribution for which the m g f did not exist of which the mean and the variance did not exist. So in fact, all the distribution that we have considered here so therefore, you can see that for all of them this condition will also be satisfied, because if the m g f exists then the force movement will also be finite. In fact, the movement m g f you can what we mean that m g f exists when you expanded you get different powers of t raise to n upon n factorial would give you the n th movement or about the origin.
So, if that is finite then you can see that this will also finite right. And so therefore, the strong law of large numbers also holds for all this distributions as so the weak law of large numbers and strong law of large numbers both hold. And so essentially if only when you have situations where you are well actually yeah, maybe I should not really worry about that part, but essentially the proof has been, this proof has been given under the condition that expectation of x i minus mu raise to 4 is less than infinity fine. And that this is the show event; that means, here this will converge the x n bar will converges to mu as n goes to infinity with probability 1. Now, just want to look at Stirling formula here and see all of you know that n factorial can be approximated by under root of 2 pi n into n by E raise to n. So, many times this is a very useful way of approximating the E factorial right.
And many limiting situations and so on, we it is very helpful to be able to replace n factorial by this and then you can get a good results. So, in other words what we are saying is that n factorial upon under root 2 pi n, n by E raise to n goes to 1 as n goes to infinity, this is the idea right. Now, the solution what we are doing is here is, here we are saying that, lets x i be poison 1; that means, the lambda is 1. So, I mean this thing the parameter for the poison distribution is 1. So, let me take x i this then take n to be sigma x i, i varying from 1 to n. 
So, this will be poison n right. And for poison n your variance; that means, variance of n is also n remember for poison lambda mean and variance are the same and they are both equal to parameter lambda right. So now, if you want to estimate this probability n equal to n this using the central limit theorem, using the central limit theorem I will say that x this can be approximated using the continuity factor the x lies between n minus half and n plus half where x is your normal n n ok, so applying the central limit theorem.
(Refer Slide Time: 21:05)
 
Let approximate this probability by saying that the corresponding normal so for, large n we will say that n behave like normal variable with mean n and variance n right. So, this is what you want to compute and therefore, in terms of. So, I want to write this probability. So, this 1 because x is normal I will write 1 upon under root 2 pi n, because our variance is n. So, standard evasion will be root n and this will be n minus half to n plus half of E minus x minus n whole square to n d x. So, this is my probability using, because I have used the central limit approximation fine. Now, just look at this integrant see what I am saying here is that x minus n whole square upon 2 n at the lower limit n minus half is n minus half minus n by 2 n whole square, which is 1 by 4 into 2 n. 
So, this goes to 0 as n goes to infinity and so E raise to minus something going to 0 is 1 right. And similarly when you substitute n plus half for x then again this will be 1 by 8 n right. So, you see the in the limiting case as n becomes large the two limit come close right and the value of the integrant is close to 1 right, because for n large this is always 1. So, therefore, we can always say that this integral is you can, you take the maximum value of the integrant which is 1 into the length of the interval which is also 1. So, this is this upon root 2 pi n. So, just apply this approximation, because the theorem from integral calculus to this integrant is throughout then you multiply that by the length of the interval. So, you get 1 upon under root 2 pi n right.
As so this probability is approximated by 1 upon under root 2 pi n and but since this is we said this is poison random variable, because we started their option that n is sigma x i. So, then this probability in terms of poison probability can be written as E raise to minus n, n raise to n divided by n factorial. And so from when you equate this 2 and you get that n factorial, I mean you equate with this and then approximate by 1 upon under root 2 pi n. So, your n factorial is under root 2 pi n, n by E raise to n. So, you know see the interesting application I mean, I just came across that this application what I taught discussed with you about central limit theorem. So, the strong law of large numbers we have sort of established, but as we saw that for us actually there will be no difference and we will continue to approximate mu by x n bar and for reasonable large values of n.
(Refer Slide Time: 24:24)
 
So now, I will want to talk about joint movement generating functions we talk about the movement generating function for a single random variable. And then we talked of we know we could compute for independent random variables when you talk of sum of independent random variable like two random variables x and y are independent. Then I could also you know, because of two independence, we could define the movement generating function of x plus y, because it was just the product of the movement generating function of x and y, but there should be a general definition of movement generating function of more than 1 variable when they are not independent. So, therefore, just completing this ah this part of the theory. So, what we saying is. So, the definition simply says that if x 1, x 2, x n are n random variables and then the joint movement generating function of these. 
So, I mean these n random variables. So, we are given the joint density function of the n random variables then we can define the movement generating function of these n random variables as of course, right now I am not listed this simply the expectation; that means, so you now need n real numbers t 1, t 2, t n. So, we will say that the movement generating function of x 1, x 2, x n is actually and I wrote the m g f by m of t 1, t 2, t n this is expectation of E raise to t 1 x 1 plus t 2 x 2 up to t n x n for all real numbers t 1, t 2, t n for which this expectation is defined. And the individual m g f can be obtained from this by putting all but one of the t i s equal to 0 and then getting the corresponding function from here, because then it will be say for example, for the i th you want to compute the m g f of or obtain the m g f of the i th random variable here.
Then I will put all other t i s equal to 0. So, m of x i t would be E t x i right, expectation of E raise to t x I, which will be in terms of the function n here will be simply 0 0 and then t i you write as t and all other as zeros. So, therefore, when you defined the joint m g f you can get the individual m g f also and just as in one variable case we had we did not proved the result, but we stated it and said that if we movement generating function uniquely defines all distribution functions. So, once you have obtained the movement generating function of a random variable then you know what is distribution function and also be and of course, it is unique right. So, here also joint case we will again just assume this result that the movement generating function uniquely defines the joint distribution of x 1, x 2, x n. 
So, yeah, and now, what we want we said uniquely defines this and now under independence yeah. So, therefore, if the joint density function is uniquely defined then we can conclude that, if the random variables x 1, x 2, x n are independent. Then I mean this is the condition if and only if your m t 1 t 2 t n can be written as the product of individual this thing. So, here if you want to write you can into this also in; that means, you can decompose your joint movement generating function into the product of individual m g f. So, I mean assuming that if this result we have sought of accepting that the m g f will define the distribution function uniquely and so now, we can yeah so you want let us show the if and only part. So, now, if they are independent then of course, the things follow immediately, because you will write expectation of E t 1 x 1 plus t n x n and that will be and this you can then write as product and because x 1 x 2 x n are independent. The expectation I can take inside and so this whole thing this can be written as this. This is because x 1 x 2 x n are independent right, product of the expectations and so it immediately follows that this is your m g f of x 1, this is m g f of x n. And so you can write this. 
(Refer Slide Time: 29:17)
 
Now, the other way, now let us show the converse that is now suppose one holds. So, we want to show that, this relationship will also we can conclude from here that x 1 x 2 x n are independent random variables. So, we can see if you look at the right hand side of one. So, this part then this represents the m g f of n independent random variable, because its product of n m g f.
So therefore, and which we know, we have said that if two random variables are independent then the m g f of 2 random variables will be the product of individual random variables. So, just extending that rule this represents the product of this represents the m g f of n independent random variables. Now, the i th of this random variable, the i th term here, m x i t i of which has the same distribution is the x i right. Because, so here each one of them for example, m x 1 t 1. So, this is the movement generating function of x 1 and as we have been saying that the movement generating functions characterize the p d f uniquely. So, therefore, each of the terms here, each of the m g f here determine uniquely the corresponding distribution p d f or so which as of the i th variable right. So, just as for a single random variable the m g f uniquely determines the distribution of the random variable.
The joint m g f uniquely determines the joint distribution. So therefore, from here we can say that the product of the. So, that the joint m g f this will give me, because this is the joint m g f of x 1 x 2 x n. So, this will determine the joint m g f of x 1 x 2 x n, but then that is we have shown is the product of the individual p d f. And this is how we have defined independence of the random variables x 1 x 2 x n that is if the joint p d f which I have written down here. So, the right hand side of one represents the distribution which is the product of individual distribution of x i s and therefore, this is the and so here and therefore, you can expression wise also write that m of t 1 t 2 t n is equal to this expectation of t 1 x 1 plus t 2 x 2 plus t n x n into f x 1 f x 2 f x n; that means, the joint l c d function of x 1 x 2 x n joint p d f is the product of individual p d f.
So this, what we are concluding, we can immediately conclude from here right, because the m g f uniquely characterize your p d f. So, therefore, just using that fact I can conclude that the joint p d f is this and therefore, x 1 x 2 x n are independent random variables. So, we need proof of the fact that if you can write the joint movement generating function as a product of individual this thing then it implies that the random variables are independent. And if they are independent then you can also write the m g f joint m d f, m g f as the product of the individual m g f s. So, we have been using some of these results, but now I have some sought of new supported it by theory.
(Refer Slide Time: 33:07)
 
See in this example, I am just trying to demonstrate the use of you know joint m g f. So, even though you know x and y are independent random, normal random variables each with mean mu and variance sigma square. So, if you start with that then we have already shown that you know by using the method of transformation that x plus y and x minus y are also independent random variables. And in fact, they are normal random variables, but now, you want to use the method of m g f to show that x plus y and x minus y are independent. And then of course, once we have shown once we obtain the individual m g f then as I have been saying that once you know the m g f you can also determine the distribution function or density function of the random variable. So, we will do that. So, just as an illustration of what we have just discussed, I want to go through this example. So, since x and y are independent and they are normal independent random variables and they have both mu and sigma square right.
(Refer Slide Time: 34:34)
 
So therefore, x plus y will be normal 2 mu and then variances will get added, because they are independent. So, 2 sigma square and for x minus y the mean will be 0 and the variance will be again 2 sigma square. So therefore, if you want to write m g f of x plus y, because its normal with mean 2 mu and variance 2 sigma square therefore, it will be E raise to 2 mu s plus half into 2 sigma square s square right this is. And similarly m g f of x minus y will be because mu is 0 the mean obviously is 0. So, it will be E half into 2 sigma square into t square, this is simply t square right. Now by our formula we will write the joint m g f of x plus y and x minus y. So, this will be expectation of E raise to s times x plus y plus t times x minus y for s and t real numbers right s and t belonging to R right, which I can by rewriting this right. So, now, I collect the x terms and the y terms. 
So, this is s plus t is the coefficient of x and s minus t is the coefficient of y. So, this is what you have right. Now, we will use the independence of x and y, because this is simply some s plus t times x which can be your t 1 and s minus t which can be your t two. So, this is E raise to t 1 x plus t 2 y, but x and y are independent random variables. So, therefore, I can decompose this m g f into the individual m g f. So, this will become expectation of E raise to s plus t into x into expectation of E raise to s minus t y right. So now, I can use the independence of x and y, because this is written as this way and so s plus t can be treated as another real number and s minus t can be treated as different real number right. And so because of independence of x and y I can decompose into this right. 
Now, let me right the m g f of, because x is again normal with mean sigma and variance sigma square and this also is mean mu and sigma is the variance. So therefore, when I write the m g f s plus t E raise to s plus t into mu plus half s plus t whole square sigma square and the other will be E raise to s minus t mu plus half s minus t whole square into sigma square right. And then you see we just rearrange the terms simplify the expression. So, s plus t into mu and s minus t into mu will become 2 s mu right. And here the product terms will cancel out the 2 s t here and the minus 2 s t it will cancel out and it will be E raise to half into 2 sigma square s square plus t square right. So now, again I collect the s terms. So, this is E raise to 2 s mu plus half into 2 sigma square s square and this is E half to sigma square t square. 
And this is what exactly see this is the m g f of x plus y, because this is and that is what I am saying. So, this is m g f of x plus y, because this is 2 mu and 2 sigma square and you know, you can also say that these are x plus y is normally distributed with mean 2 mu and 2 sigma square and this is the m g f of x minus y. So, there you see that mu is 0 and the variance is 2 sigma square right. And so since from the theorem that I had just stated and proved to you, this see that if you are joint m g f can be written as the product of the individual m g f then the variables must be independent right. And so we conclude that x plus y and x minus y are independent and also we can conclude that x plus y is normal 2 mu 2 sigma square and x minus y is normal 0, 2 sigma square. So, you know with the series through series of examples, I will tried to revisit the results.
Which we have already I will try to revisit the results, which we have already you know obtained especially; I will apply this concept of joint m g f to sums of random variables. And then try to show you that sometimes this method is easier and we can get the results faster. So, it depends on the situation and of course, lot of experience, but this is also another important tool and I taught that this course we must define this and you know give you the results. So, that you can sometimes when other methods do not work this will proved to be quite.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 24
Convolutions

 (Refer Slide Time: 00:20)
  
So, in this lecture I will be talking about convolution and again this is one of the tools that we will use just like m g f to sometimes compute the distribution function and their density function for different kinds of random variables of the functions of the random variables. Mostly the convolution is use for computing the distribution function of sums of random variables. So, here the definition says that if x and y are independent random variables, the distribution function of x plus y is said to be the convolution of the distribution functions of x and y. So, the distribution function that we obtain for x plus y is will be is called the convolution of the distribution functions of x and y.
Now, if highlight f of x plus y f x and f y denote the distribution functions of x plus y x and y respectively right. So, by notation it is clear that the f x plus y is the distribution function for x plus y and f x is for x f y is for capital y right. Now, for the discrete case the definition would be as follows. So, when the x and y both are discrete random variables and they are independent random variables p of x and p of y denote the p m f of x and y respectively. Then p of x plus y equal to t we will write as summation of p x x, so you fix the value of capital x then the y will take the values t minus x right. And of course, this summation will be over all x for which you are this probability is positive and also it should be such that t minus x the probability y at t minus x is also positive. Otherwise since is the product of these two probabilities whenever one of them is 0. The whole the contribution of that particular term will be 0.
So, simple definition that we will see how we can apply these definition and similarly for the case when for the continuous case that means when both x and y are independent continuous random variables. That let t denote the sum of the two random variable that is t is equal to x plus y then your distribution function for t at small t is probability capital t less than or equal to t. And this we can write as minus infinity to infinity probability x plus y less than or equal to t condition that x equal to x just as here, we chose the value of x and then the corresponding value of y got fixed at t minus x.
So, here you condition it on x equal to x and then probability x plus y less than or equal to t. So, then that into; that means, this is the distribution function into the probability that x takes the value well the p d f of x at small x which will be f of capital x x into d x. And your x reform minus infinity to infinity. So, this is the general expression and of course, it will depend on the range will depend on the values that your random variables take. So, I am use the concept of conditional distribution here and so this is the expression.
(Refer Slide Time: 03:59)
 

And therefore, in terms of f f f y capital f y in small f x you can write this as minus infinity to infinity probability x plus y less than t condition on x equal to x into f x x d x. So, this we can write as f y integration of minus infinity to t minus x of f y y into f x x d x upon f y x. Then this we can do because x and y are independent; that means, the probability x plus y less than t conditioned on x equal to x, I am able to write break it up into f y y into f x x upon f x x d y. And so because x and y are independent and there into f x x d x. So, we are f x x cancels out and we are left with the integration minus infinity to infinity again integration minus infinity to t minus x f y d y f x d x. So, therefore, the first part I can write, I mean the integral minus infinity root t minus x f y d y I can write as probability y less than or equal to t minus x.
So, whole integral is then minus infinity to infinity probability y less than or equal to t minus x into f x x d x. So, I hope there is no doubt about going from here to here right, because when x is equal to x your y will be required to be less than or equal to t minus x and so that is why I have written this probability as a capital f y t minus x into this right. Now, differentiate respect to t since the limits are independent of your t therefore, the differentiation will just go inside. So, therefore, this will become small f t t and this will be equal to. So, only this thing gets differentiated this is the function of t and therefore, it will be p d f of y at t minus x and then integral from minus infinity to infinity of this function, product of these two right. So, this will be your convolution you can either write it in this form or you can write it in terms of the p d fs. And of course, the understanding is that wherever you know for all values of t for which this is defined as and you also take the values of x for wish this is define right.
Now, let us so the basic definition is this and then we will just see how we applied to different cases and of course, there will be reputation in the sense that for sums of independent random variables quite a few cases by other methods by using the transformation method or by the movement generating function.
(Refer Slide Time: 06:48)
 
We have already obtain the density functions for the sums of independent random variables, but here I just want to show you the working of this particular method and therefore, we will just through a few examples. Now, suppose x 1 is the Poisson lambda 1 and x 2 is Poisson lambda 2. So, then t is the sum of the two poison random variables and now you want to find out probability t equal to n.
So, then if I chose x 1 is equal to x then x varies from 0 to n and this will be probability x 1 equal to x into probability x 2 equal to n minus x right. See from here if this is end I fix x 1 at x then x 2 will be n minus x. So, you do some and now since there independent and therefore, I written it this way product of the probability. So, now, this particular probability can be written as e rise to minus lambda 1 and we have missed out on the summation should have been there sorry, summation x varying from 0 to n right, e rise to minus lambda 1. So, this probability is e rise to minus lambda 1 lambda 1 rise to x upon x factorial. 
And this probability would be e rise to minus lambda 2 lambda 2 rise to n minus x upon n minus x factorial and so here also summation x varying from 0 to n right. Now, then just rearrange the terms e rise to minus of lambda 1 plus lambda 2 then I have divided and multiplied by n factorial. So, this is n factorial and then here it will be n factorial divided by x factorial and minus x factorial and then you have lambda 1 rise to x and lambda 2 rise n minus x. Now, this is the you can see that this is the expansion of the binomial expansion of lambda 1 plus lambda 2 rise to n, because your summing see thing this the independent of x, e rise minus lambda 1 plus lambda 2 divided by n factorial. So, this I take outside and then this summation x, x from 0 to n of this will be your lambda 1 plus lambda 2 rise to n.
And so this will be now Poisson with the parameter lambda 1 plus lambda 2 right, this is probability equal to n. So, therefore, e rise to minus lambda 1 plus lambda 2 divided by n factorial into lambda 1 plus lambda 2 rise to n right. So, you can immediately conclude that this is now Poisson with parameter lambda 1 plus lambda 2 yeah. Another example I want you to show that x 1 plus x 2 plus x n is negative binomial and so here now we are extending this concept to more than two, some of more than two independent random variables. Where x size are actually I could have straight away said that x I are independently identically distributed geometric random variables and geometric random variables with probability of success is p.
So; that means, probability x i; that means, probability this is just a geometric random variable and so and the probability of success is 1 that is it. When you describe a geometric random variable you just need to known the probability of success and then you want to find the probability that you will get a success in n trails. So, now, here we first consider this some of two random variables x 1 plus x 2 and so probability x 1 plus x 2 equal to n by convolutions we will write as x equal to 1 to n minus 1, because they should be I mean I cannot make this 0. I cannot have x going to from 1 to n, because in that case when x is equal to n this will be 0 and so anyway this will be not defined on the probability will write it as 0. So, there will no contribution to this sum.
So, I have to take this summation from 1 to n minus 1 right. And then if I fix x 1 at x that means, for the first geometric random variable the success, the first success occurs for x trails then for the second one the first success will occur at the n minus x th trial right. So, the probability of x 1 equal to x is 1 minus p rise to x minus 1 into p right at the x th trail the success must occur, otherwise before that all failures. And similarly here it will be 1 minus p rise to n minus x minus 1 into p. So, when you rearrange the terms here see x minus 1 and this is minus x. So, x minus x cancels out you left with the n minus 2 and this is p square. So, this is equal to sigma x varying from 1 to n minus 1, 1 minus p rise to n minus 2 p square, but you see x is not present here therefore, you just add up this terms n minus 1 times. So, this is n minus 1 into 1 minus p rise to n minus 2 p square.
Now, this you can see is the probability that out of n successes out of sorry, out of n trails to or successes and n minus 2 are failures. So, that means, this is the probability of 2 successes in n trails right, where the law success occurs, where the second success occurs at the end so when the one success can occur anywhere and the n minus 1 trails. So, therefore, this is n minus 1 1, you can write this n minus 1 1 choose 1 and then 1 minus p rise to n minus 2 and p square. So, 1 success occurs anywhere in the n minus 1 trails and then one success occurs at the end and therefore, this is probability of two success is in n trails. So, therefore, x 1 plus x 2 if you let y be equal to x 1 plus x 2.
We show that y is negative binomial with the parameters 2 comma p right. The probability of success is p. Here in the example I probably denoted mention, but it is understood that probability that x i is equal to the probability of success sorry, I should say that, probability of success is equal to p I should have mention that here. So, it is understood anywhere right. Now, we can iteratively show that if you now consider the random variable y plus x 3 then by the same argument will be able to show that this is negative binomial 3 comma p and so on. So, therefore, you can show that this will be negative binomial when x I is a geometric random variable when each x i is a geometric random variable for all i and x i s are independent.
(Refer Slide Time: 14:00)
 
In the in the example, where we consider the sum of the geometric independent geometric random variables all with probability of success is p. Then you see x i was the number of trails required for a success for one success. Therefore, see ah if the corresponding number is n i; that means, the number of trails required for one success for the i th geometric random variable. So, then you see when say x 1 plus x 2 this will be the number of trails required for two successive right. And that number will be then n 1 plus n two. So, essentially when I wore that the sum x 1 plus x 2 is 2 comma p negative binomial.
So, that the understanding is that you want to two success and therefore, the number of trails of course, will be equal to n 1 plus n 2. Then so therefore, finally, when you go and doing iteratively this procedure of in adding on or convoluting these random variables then x 1 plus x 2 plus x n will finally, give you the number of trails required for n successive right. And therefore, this was negative binomial n p right. And the total number of success is trails required would be n 1 plus n 2 plus n n right. Now, the next part was that without any calculation you can also conclude see this was just to show you how you would apply convolution and now here we can also because by just description, because when you say x 1 plus x 2 plus x n that is means you are asking for n success and your probability of success is p. And therefore, x 1 plus x 2 plus x n gives you the number of trails required for n successes when the probability of successes is p. 
So, just by saying it aloud you know since each x 1 x 2 x n is the, is geometric random variable independent therefore, we you add up you can say that this will be a negative binomial and comma p so that is all. We just do because here (( )) required to use convolution right. Now, lets us consider again applied convolution to some of independent uniform random variables both are 0 1 right. So, therefore, the corresponding p d fs all both be 1 as long as x and y are between 0 and 1 and it will be 0 otherwise right.
So, let us define the random variables t equal to x plus y now the thing is that you see will have to and this where the this part comes that sometimes of course, you can easily determine the ranges, but sometimes you cannot be that easy. So, here for example, you see when I write the formula f x x x and f y t minus x. Now, you just see this is define only for between 0 and 1. So, by t minus x also should vary between 0 and 1 and therefore, I have to get this have to write I mean after do this computation for first for t between 0 and 1, because t minus x greater than 0 implies that x is less than or equal to t. See from here this is not define for t minus x being negative.
So, therefore, t minus x has to be non negative, which requires the t should be greater than or equal to t right, greater than or equal to x. And then also t minus x should be less than or equal to 1. So, you cannot take a value of and therefore, t must be less than or equal to from here t must be less than or equal to 1 plus x. Since x can take 0 value therefore, you see immediately from here that your t cannot be more than 1. So, here we will have to the way we are defining this, it will have to be the limits for t would have to be from 0 to 1 right. And then you are x can vary from 0 to 1 when you write now; I mean I am writing the integral this way, but since for x non negative and x between 0 and 1 this is 1.
(Refer Slide Time: 18:10)
 
So, therefore, this will reduce to simply integral 0 to t f t minus x d x now, when I say that my x varies for 0 to t. So, this is also define and therefore, this is also equal to 1 right. As long as x is varying from 0 to t, this is well defined and it is within the range of the values for y and therefore, this also is 1. So, this integral comes out to be t and t between 0 and 1 with this is what I have to drawn you, the curve here this value is also 1 right. So, therefore, the p d f for the some of the two random variables and both are uniform will be given by this.
Now, because x plus y and both can take values between 0 and 1. So, of course, the range this is from 0 to 2 right. And so we have to consider the values of align between 1 and 2 and this case you see again the convolution formula is this. So, t minus x less than or equal to 1 will imply that your x is greater than or equal to t minus 1. So, here immediately you see that t must be greater than or equal to 1 right or x is greater than or equal to t minus 1. So, that is why the range t greater than or equal to 1 right. And then of course, it cannot go beyond two. So, yes therefore, again the same reasoning that this value is 1 and the valid portion region we you can define this and why I am writing. So, this is t minus 1 to 1; that means, my x can vary from t minus 1 to 1 so t minus 1 yes. So, this thing you see at t minus 1 this will be 1.
Because t minus t plus 1 and when this x is 1 this will be t minus 1, because your x has to be greater than or equal to t minus 1. So, therefore, the range is this and again in this range this function is equal to 1. So, the integral is t minus 1 to 1, 1 into d x which comes out to be 2 minus t and that will be your, this graph will be, the function will be represented by this great line. So, therefore, the sum of the two uniform random variables both independent and defined on 0 1, the p d f is triangular distribution yes. So, therefore, you see here you could not have just straight away done this integration from 0 to 2; that means, you could not allow t to vary from 0 to 2, because that could not have given you the valid answer and here you have to break up the region of integration from 0 to 1 and then 1 to 2. And I suppose yeah, because we are writing t minus x. So, we have to do it this way that it x has to be greater than or equal to t minus 1 and we are integrating with respect to x, x cannot go beyond 1, therefore, this will be t minus 1 to 1 right yeah. 
So, another example is now sum of two independent gamma random variables. So, suppose x is gamma s comma lambda and y is gamma t comma lambda then and x and y are independent. So, we have to obtain the p d f of x plus y. So, to define t as x plus y and then by convolution formula f t a we will write as this now, here again we have to apply the same thing, because gamma p d f is defined only for non negative variables. So, therefore, this has to be a minus x has to be non negative. So, therefore, this a minus x no negative, this implies x less than or equal to a yes. And so I can; that means, here while integration has to be from 0 to a now, why I am writing this as yeah.
So right now, I am I will now write the correct range what we just right now substituting for f x x, which will be lambda e raise to minus lambda x and lambda x raise to s minus 1, because x is s comma lambda, gamma s comma lambda. So, the p d f is lambda e raise to minus lambda x into lambda x raise to s minus 1. And this is p d f for y is lambda e raise to lambda a minus x into lambda of a minus x raise to t minus 1. You see as we said x has to be less than or equal to a and now we therefore, this infinity will get replaced by a and you see here e raise to minus lambda x then e raise to plus lambda x that will cancel out you will be left with e raise to lambda a and then here it is lambda x raise to x minus 1. 
So, if you just take out the lambda here it will be lambda raise to s minus 1 and this will be lambda raise to t minus 1 and you have lambda square here. So, the whole thing will be lambda raise to s plus t minus, because this is 2 and this is minus 2. So, you have lambda raise 2 s plus t right and that is what we have written here.
(Refer Slide Time: 23:38)
 
So, this is lambda raise to s plus t e raise to minus lambda a and then you left with x raise to s minus 1 and a minus x raise to t minus 1 d x. Now, make the substitution that x upon a is equal to z. So, this will imply that your d x get replaced by a d z right and your range goes from 0 to 1 instead of 0 to a, because x by a, we have put a z. So, range for z will be from 0 to 1. So, therefore, the constant terms have put outside and so this a comes from here and then you have this and this. Now, you see this looks familiar and this is the beta function. And therefore, since we want to so therefore, we know that this integral from 0 to 1 d z will be equal to gamma s into gamma t upon gamma s plus t right. So, from the definition of the beta distribution we know that this integral must be equal to gamma s into gamma t upon gamma s plus t. And therefore, I replace this whole thing by this thing. So, then gamma s gamma t cancel out you left with gamma s plus t and this is lambda raise to so the lambda be right outside here. And then it will be lambda a raise to yeah, so this makes it s plus t minus 1. So, therefore, lambda a s plus t minus 1, 1 lambda I have written out here, just to conform to the form of the gamma distribution right. And so this is therefore, this is I should have written here, gamma s this is gamma s plus t lambda.
So, we have concluded that, if you take two independent gamma random variables, x is gamma s lambda and y is gamma t lambda then this sum and they are independent then the sum will be again gamma distribution having a gamma distribution with parameters s plus t and lambda. So, the same lambda if the second parameter is same then I can go adding the gamma random variables and the first parameter gets added of course, you are adding independent gamma random variables. So, corollary first is that if x 1 x 2 x n are gamma s I lambda and they are independent random variables then by repeated use as we did earlier by repeated use of convolution it follows that x 1 plus x 2 plus x n will be gamma sigma s I, i varying from 1 to n comma lambda.
So, here of course, this thing is immediate that is your adding with distribution is not changing just the parameter is changing and that also the second parameter the first 1 that is the common one that remains same right. Another corollary, which is that if you take x 1 x 2 x n are identically independently distributed exponential lambda random variables and we know that an exponential lambda here only you can see from the gamma p d f that is a gamma 1 comma lambda right. Then exponential lambda is gamma 1 comma lambda and so when you take x 1 plus x n exponential random variables independently distributed then this is gamma and gamma lambda because the first parameter gets added in this.
So, and we will see uses of all these when we talk about random process is stochastic process is which are Poisson and Marko and so on right. So, I have tried to depict by various, because you had to you could not just blindly apply the convolution you have to make sure that you know when you are applying it you are values of the variables should be sighted this p d fs are defined and so on, so we defined this. Now of course, the question is see we have defined this for independent random variables; that means, the convolution right now we the definition says that they are independent and then you take the sum and then you can talk about the convolution, but can you answer the converse can you that is if you can show that the for two random variables x and y. The distribution function for x plus y can be written as the convolution of the distribution functions of x and y would it imply that x and y are independent. So, this is the question and I will try to answer through a counter example to say that, no it is not necessary, you may get the distribution of this sum by the convolution, but the variables may not be independent.
(Refer Slide Time: 28:31)
 
So, this example is I have taken it from dude witch and Mishra and I told you I have often taken examples from this book dude witch and Mishra and Sheldon and rose and I have give you the references also at the end of the course. So, here and this example is originally due to w t hall and you see how cleverly this has been constructed.
So, see as I said the, we try to answer the question that if the distribution of x plus y is the convolution of the distribution of x and y does it follow oh, does it follow that x and y are independent random variables. So, you want to answer this question, because we have defined the convolution for independent random variables. So, the table here gives you the joint, I should make the at least to look nice. So, this is it. So, therefore, this table gives you the joint probability function, probability maths function of x and y and theta is fixed number, but it is absolute value less than 1 by 9, because otherwise, the entries will become negative.
So, we want this to be valid table for joint probability maths function of x and y right. And you can see that when you add up this for the marginal p d fs are independent of the marginal probability maths functions are independent of theta and this where I am saying that thing has been very well constructed. So, see these will 3 will add up to theta, theta will cancel t plus theta n minus theta it will be 1 by 3. Similarly here this minus theta and plus theta will cancel so this will also be 1 by 3. And finally, these will also 1 by 3 and your column sums also give you the marginals, which are all independent of theta right. And now you want to write. So, we want to verify that the distribution function of x plus y is a convolution of the distribution functions of x and y.
(Refer Slide Time: 30:50)
  
So, the values that x plus y will take a minus 2 minus 1 0 1 and 2 right these are the possible values that x plus y you can take, because your x takes the values minus 1 0 1 and y takes the values minus 1 0 1 right. So, we start with probability x plus y equal to 0 and we will have to verify for all possible values to make sure that this is that x plus y the distribution of x plus y can be obtained as a convolution of distributions of x and y. So, here by convolution I means, I am taking x to be equal to 1 then y will be equal to minus 1 right. And if you take x equal to minus 1 then y will be 1 and if you take x equal to 0 then y will be also 0.
So, these are the 3 you can convolute here this right and probability for x equal to 1 by 3 right, that is what you mean by marginal 1 by 3 into probability y equal to minus 1 that is also 1 by 3. So, therefore, this is 1 by 9, similarly you can immediately see that probability x equal to minus 1 is 1 by 3 and probability y equal to 1 is also 1 by 3 and 0 zero also x equal to 0 gives you 1 by 3 y equal to 0 also 1 by 3 so this is 1 by 3 right. And then similarly, probability x plus y equal to 1 so here also when you want to fix x and then the corresponding value of y. So, here I put x equal to 1 then y will have to be 0 and I put x equal to 0 y is equal to 1 and you should have put if you put x equal to minus 1 then that is not valid right x equal to minus 1 then y can only take a value 0 1 or minus 1. So, this is these are only 2 ways you can convolute the some x plus y equal to 1 here. And therefore, this probability is 2 by 9 right, I have tried to compute just to make sure that see, because even if for one single value the convolution does not hold then I cannot say that.
And so for x plus y equal to 2 only one possibility, x takes value 1 and y equal to 1 so this is also, I have taken this example, because it shows you that when we write f x of x into f y of t minus x. Then you see you have to take only possible values of t you cannot just take any so x plus y equal to 2 will be given by x equal to 1 and y equal to 1. So, this probability is 1 by 9. And similarly x plus y equal to minus 2 will be given by x equal to minus 1 and y equal to minus 1. So, that is 1 by 9 right.
(Refer Slide Time: 33:35)
 
So, now we compute these probabilities without convolution. So, for example, probability x plus y equal to 0 will be probability, x equal to minus 1 y equal to 1 so all pairs that make up x plus y equal to 0 plus probability x equal to 1 y equal to minus 1 and plus probability x equal to 0 y equal to 0. And so from the table we can see that minus 1 1 x minus 1 and this 1 so 1 by 9 minus theta right. And then 1 minus 1 so 1 minus 1 is 1 by 9 plus theta and then 0 0 x 0 y 0 that is this which is 1 by 9 right. So, therefore, this adds up to 1 by 3 minus theta and theta cancel out. So, this is 3 upon 9, which is 1 by 3 similarly x plus y equal to 1 so x equal to 0 y equal to 1 so again 0 1 1 0 and so on. So, 0 1 0 1 will be 1 by 9 plus theta 1 0 will be 1 by 9 minus theta and that is it. Because the sum to be equal to 1 these are the only 2 possible pairs of values that x and y can take. So, 1 by 9 plus theta plus 1 by 9 minus theta is 2 by 9.
So, this also matches with this and this matches with this 1 by 3. And then similarly you can see that x plus y equal to 2 simply be the pair x equal to 1 y equal to 1, which is 1 by 9 x equal to 1 and y equal to 1, 1 by 9 which also matches with this 1 right. And then x plus y equal to minus 2 this is x equal to minus 1 and y equal to minus 1, x equal to minus this is 1 by 9 and here also we got it as 1 by 9. So, we have checked almost for all yes well not exactly may be x plus y equal to minus 1 that is left out, but we have otherwise checked for x plus 0 1 2 2 2 n minus 2.
So, that 1 was 0, but you can easily verify that for all values; that means, the probability maths function of x plus y matches with the probabilities obtained by convolution for all theta less than or equal to 1 by 9. So, therefore, the two things match, but we know that x and y are not independent why, because you just take one pair see I just have to show that for one pair of values this does not hold that this probability x equal to minus 1 and y equal to 0 that is from again from the table is 1 by 9 plus theta, but this is not equal to sorry, yeah what I am saying is that this is not equal to probability x equal to minus 1 into probability y equal to 0. So, x equal to minus 1 from the marginals is this 1 by 3 and probability y equal to 0 this is y equal to 0, this is 1 by 3 right. So, that is 1 by 9.
And therefore, the 2 are not equal as long as theta some positive number of course, satisfying the condition that absolute of theta is less than or equal to 1 by 9. So, for any for a positive theta satisfying this, these two will not be equal and therefore, x and y will be independent only when theta is 0. So, this is an interesting example and must have taken them lot of time to construct such an example. Now, if you try to do it for when x takes only two different values, x and y takes two different values it will not be possible. Then you can think of no trying situation, where x and y take four values each then you have to make sure that you will have to write down this probabilities in such a way that the marginals are independent of theta right. 
And then you can have a chance to show that to get construct such an example that the probability maths function of x plus y can be obtained by convolution, but the variables x and y are not independent. So, it might be a very interesting project, but I am not sure if it possible, but here it definitely lot of effort went into it to show that convolution does not imply independence on that time. 
(Refer Slide Time: 38:30)
 
So, you see according to me we have developed enough machinery to able to now show you some more interesting application complex in applications of the tools that we have of the machinery that we have developed. So, far of probability theory and I would like to now devote the rest of the course on stochastic processes are only simple basic once. 
And because otherwise the, you know what subject on the stochastic process and things can get very complex, but so the first thing would be the first stochastic process that I would like to talk about would be poison process. And the idea you have already talked of poison random variable and then we have also looked at exponential and gamma random variables. And we will see that how these things get you know, we sought of use the different kinds of distribution that we have developed into answering questions to essentially the thing is that you know, you have it is a counting process. And you have a service that is a post office or railway booking counter well there still people will go and book at the railway counters not everybody does it online is not possible for everybody do it. So, whatever these services are there now you want to have an estimate us to how people are coming and what is the...
So, and therefore, then accordingly you can design the surveys. So, that people do not have to wait for a long time to be serviced how many counters should be there and so on. So, these are the kind of things we will talking about and so basically we will be defining n t as the number of people who are entering let us say post office up to time t. So, we will keep a count and will measure the number of people I mean we will count the number of people who enter the post office say starting from 0 time to t time and then we will answer lot of questions depending on that, but then the thing is that because we are calling it Poisson process. So, this four whether the certain conditions, which have to be satisfied by you know this process. 
Because when you are modeling it then we have to have some basic conditions which are met by this particular counting process. And then we will develop the structure and try to answer few questions and the other one would be the other process that we talk about we be mark o process. And so they are both interesting and the basic and they we can sort of develop we will answer lot of questions through these, because we have develop the machinery to do that. So, this would be my you know next few lectures would be on Poisson process and then on mark o processes.
(Refer Slide Time: 41:40)
 
In my last lecture I had told you that we would now we talking about some stochastic processes. And in fact so and one of them is the Poisson process this is you can describe this as a probabilistic model used for describing unpredictable events right, because there is a chance element.
For example when and or the quick will happen or when it certain person walks into a post office these are unpredictable events. So, the Poisson process is a probabilistic model and settles even you model a situation then they are certain rules are certain and of course, so the idea here is that you are modeling a situation where the events exhibit a certain amount of statistical regularity. And that of course, this means that you know you can approximate the occurrences by probability density function. So, these events they exhibit or a approximately exhibit a statistical regularity and so essentially the poison process is a counting process. So; that means, essentially these unpredictable events they get counted by the model that we will create here and then of course, lot of discussion and all lot of conclusions can be based on the counting process.
This is what we will see in the next couple of lectures. Now, the examples as I said are number of persons entering a post office or a bank up to time t. So, always the measure; that means, when I am saying n t is the time to start counting the events start at 0 and then up to time t. So, we count the number of events that take place and therefore, like for example, when you counting the number of persons entering a post office or a bank then this is. So, n event will occur when a person enters the post office right. So, therefore, n t will give the number of people who have entered the bank or the post office up to time t counting from 0, starting time 0, 0 to t number of people who have entered the bank or the post office. That examples could be number of children born in a town or a village up to t days or t months which ever you know time period you want fix the time frame work is decided. 
And then you start the counting process of course, in this case event will occur when a child is born right. So, you keep counting these events. Now, number of goals hit by a hockey player up to time t. So, when the match starts and then after that up to time t may this could be the half time or whatever it is when you identify the particular hockey player in the team and then you say number of goals hit by a hockey player up to time t and here again the events will occur when a goal is hit by this particular player right, because you counting the number of goals hit by a particular hockey player. So, this situation then for example, also you can have if you want to pick up a country or a place where a volcano is and then you want to find out the number of times a volcano erupts. So, here of course, your time spend may be may be 5 years or 10 years and then you may because volcanoes luckily do not erupt very often. 
So, therefore you would your time spend would be much more then for these particular events. So now, through these examples, we realize that whatever our counting process is and this n t must satisfy the following.
(Refer Slide Time: 45:25)
 
So, since it has to be 0, because when this counts the number of events that have taken place; obviously, this has to be 0 positive. Then n t is integer value, because we are counting the number of events and then for s less than t your n s must be less than or equal to n t. So, either no event occurs in the interval this or some event occurs after s, time s. So, therefore, n s must be less than or equal to n t.
So, this number counting process this satisfies this condition. Then for s less than t if you take the difference as so 3 and 4 are you can we club together also, n t minus n s is equal the number events that occur in the time interval s comma t. So, here of course, n s you know you have counted the events up to time s. So, after s you start counting the events at take place up to t. So, this will be open at this end this interval time interval and close at this end. So, s comma t. So, therefore, this is this, now other things that we want to impose, because remember we are thinking of modeling this situation where you want to count the number of events that take place, but certain conditions will have to be met.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 25
Stochastic Processes Markov Process

(Refer Slide Time: 00:14)
 
So, I am going to talk about discrete stochastic processes, and without, you know, spending time on first trying to define stochastic processes and on that discrete stochastic processes, you know, in the abstraction, I would prefer to give you examples, and then, we would try to come to a conclusion. And hopefully, you know, you will be able to define and in fact, you would have, by then, by that time formed your own definition of stochastic processes. Of course, here we are going to write, first talk about discrete stochastic processes. 
Now let us just look at one example: a watch selling shop keeps a particular brand of ladies watch; and the D i - let D i denote the demand for this brand in the i th week. So, let us just say that our planning horizon is 3 weeks. And so D 1 will be the demand for this particular brand of watches in the first week; D 2 in the second week; and D 3 will be in the third week; and then, these are, you know, D i (s) are random variables, because the demands are not certain commodity, because otherwise, shop keeper’s job will be very easy. So, here D i(s) are random variables and they are identically independently distributed random variables. So, this one simplification has been added here. So, the D i(s) are not known; they are not certain events, but they have the same distribution and independent; so, that means, the demand in the first week is independent of the demand in the second week, and independent of the demand in the third week.
Let N i denote the number of watches on hand at the end of the ith week. So, let us say by Saturday evening, the man takes stock of his things that he has - that he has on hand. So, N i will be the same particular brand of ladies watch; he has N i of them; so, that means, N 1 at the end of the first week; N 2 at the end of second week; and N 3 at the end of the third week. Now, orders placed for watches on Sunday evening are delivered before the shop opens on Monday morning. So, this could be Sunday evening or Saturday evening or whatever it is. So, before the new week begins, so on Monday morning, before the shop opens, the watches are delivered; whatever the ordering policy.
Now, suppose the ordering policy followed by the shop owner is as follows: if no watches in stock order for watches; that means, by Saturday evening if he realizes that he does not have any watch of this particular brand, then he will order for 4 watches, and they will be delivered by Monday morning. So that means, if N i is zero, order 4 watches; if N i is 1 - that means, if he has 1 watch at the end of the week in stock, then he will order for 2 watches; and finally, if he has 2 or more watches left over by the end of the week, then he will not order any - so, do not order. So, this is his policy. 
And, of course, sales are lost when the demand exceeds the number of watches in stock. So, if there is more demand, and you do not have that many watches, then you will lose that - those sales; so, fine. So, now, let us look at what would be the position in the following week.
(Refer Slide Time: 03:59)
 
So, N i plus 1 will be let us say… So, this will be N i plus 1 will denote the number of watches on hand at the end of the i plus 1 th week. And how will you compute N i plus 1 given N i? So, this will be, you see, if N i is zero; that means, so this is your i th week and this is your i plus 1 th week. So, therefore, at this point you had N i watches. Now if N i is zero, then you ordered 4, and they were delivered by the time your i plus 1 th week started; so, that means, then you will have at the beginning - at this point - you will have N i plus 4 watches, and then this demand D i plus 1; so, that means, you would meet the demand, and then depending on whether D i plus 1 is - since N i is zero - you will actually have 4 watches on hand and that is why I have written 4 here. So, actually, your this thing will be 4 minus D i plus 1. And if your demand is more than this, then of course, you will say the max of this, because he cannot have negative number of watches.
So, either you have 4 minus D i plus 1; if D i plus 1 is less than 4 or you have no watches left at the end of the next week. So, at this point, if you are able to meet the demand D i plus 1 then whatever the difference, that will be the watches on hand at this point. Otherwise, it will be zero, if D i plus 1 is more than 4, right? So, similarly, if N i is 2, what were the policies? N i is 1; this is N i is 1. So, if N i is 1, then he orders 2 watches. So, this will be N i plus 2 minus again whatever the demand and if this number is positive, then that will be taken as the number of watches on hand at the end of the i plus 1 th week; otherwise it will be zero. So, N i of course, you can write 1 here. So, this is actually it is max of 3 minus D i plus 1 comma zero. So, which ever number is positive that number you will take. So, when N i is 1, and similarly, if N i is greater than or equal to 2, then you are not ordering any watches; 2 or more you do not order. So, your watches on hand at the beginning of the i plus 1 th week is N i and i minus D i plus 1 will be what you are left with at the end of the i plus 1 th week. So, it will be again max of these two.
So, this is how you can… So, you see, the situation at the end of i plus 1 th week is dependent on your situation at the end of the i th week and the demand. So, here two random phenomena on which your state of the system - if you can want to call it; that means, the state occupied by the system at the i plus 1 th week is given to you by N i plus 1 and here this is the current state. So, therefore, you can say that here your N i plus ones are dependent on just N i and D i plus 1. So, the current demand and the state in which you were at the beginning of the i plus 1 th week. So, this is sort of trying to show you the dependence because the variables N i plus 1 which we are trying to, you know, tell us the state of the system at the end of every week. So, this phenomena is dependent on the two random phenomena N i and D i plus 1. So, this is one example and then we will…
So, now, I can sort of give you a definition here saying that N i(s) index by the number of the week form a discrete stochastic process. So, then when you take these N 1, N 2, N 3 - so, these are three random variables, and they form a set. See the thing is that you are giving them an index, which is discrete. So, N 1, N 2, N 3 and the unit of time can be anything - here it is a week, it could be month, it could be an hour, or whatever it is. So, when and therefore, the discrete word. So this is a random phenomenon which is being, you know, sort of index by discrete time period, and therefore, we would call this a discrete stochastic process.
Another example. And therefore, you may. So, of course, this and.
Now the next question to be asked is - why study this? So, for example, I just tried to state one or two questions that the shop owner may want to have answered, but of course, they can be many other questions that you can also raise. So, for example, the shop owner is interested in knowing the following - long term loss of sales due to his reordering policy; you see, because if he can by some mechanism find out what is the sort of estimate - may not be the exact number - but he can estimate the number of sales that are lost, when this number is negative; that means, he is losing out on sales whenever this number is negative. So, if there is a mechanism by which he can find out what is his long term sales, loss of sales due to his reordering policy, because he wants to know whether he really has a good reordering policy or not. And then, also he may also want to know the effects of changes he makes in his reordering policies in the reordering policy; he may also want to change some of the orders there; and then he would want to know would that make the situation better for him.
For example, would it reduce his long-term - say long-term word, I am using here because, you know, it takes a while for any system to settle down; so, we will most of the time, when we talk of any stochastic process we want to analyze it, we would be talking about its long-term behavior. So, whatever the disturbance is and perturbations ,they all settle down after a while, and then you want to look at the system, because, otherwise it will be very difficult to, you know, model any such process, you know, when there are initially lot of tribulations or lot of perturbations, you cannot really analyze or you cannot model such a situation. So, therefore, it is a long-term loss of sales due to his reordering policies and then he may want to know if he makes any changes, how will it affect his again, his revenues – essentially, he is finally interested in revenues that he gets. 
Now, let us look at another example, which is probably a simpler one. So, there is an automobile manufacturing company and has the policy of assigning its white collar employees. So, white collar employees means who work in their offices, office of the sales and so on, to the three sections it has. So, the three sections it has are Production, HR - you know handling human resources, and Sales. So, these are the three, and then see, we will now look at this model – example - and again give you another feeling about the stochastic processes. So, the three sections are Production, Human Resource, and Sales.
(Refer Slide Time: 11:47)
 
So, these are three sections in the automobile manufacturing company where he wants to assign the white collar employees. And then, I mean by he – I mean the owner of that manufacturing - automobile manufacturing - company; and there is no set pattern for reassignments; at least the employees do not know. So, there must be something in the mind of the owners how they would reassign. So, since there are no set patterns known for the reassignments, one does not know in which section he or she will be assigned next. So, after you have been in one section for a while, suddenly you know that you will be transferred, but then you do not know to which one you will be transferred. So, the next assignment may depend on the current assignment; it is possible that wherever you are right now, it may have a bearing on where you will be next. So, these are the kinds of… So, then, if we let X i denote the section assign during i - the 6 month period.
So, that means, now you look at one employee’s profile suppose; just take one employee; look at his profile in the sense that you want to keep on measuring. So, your time period is a 6 month time period; that means, when you get assigned to a section, it is for a 6 month period and then at the end of the 6 month period, there will be another reassignment to sections and you may either stay in the same section or you may get transferred to the another one. So, any way, let X i denote the section assigned during the i th 6 month period. And then, so the whole process can be; that means, the whole process of the sections being assigned to a particular employee can be described by the sequence X 1, X 2, so on. So as long as your planning horizon you will have…
So, X 1 will tell you that in the first 6 months the particular employee is in this section whatever the value of X 1; then X 2 will tell you the section he is in the second 6 month period and so on. And of course, X i can take the possible values. So, let us take, let us number the three sections. So, the first section is Production, second section is HR - Human Resource and the third is Sales. So, X i can take three possible values whichever of the three sections. So, this will describe to you if you like you take it up to X 10.
So, that means, over the 5 years the sequence X 1, X 2, X 3 up to X 10 will tell you the sections to which this particular employee has been assigned. So in the discrete, so this assignment of sections to the employee is a discrete stochastic process and it is indexed by the periods 1, 2, 3 and so on. So now, you get the meaning. So, it is something like the process is evolving over time and there is uncertainty about what the system, what the state - I mean where the system - would be after, you know, each time period; one time period is over, then where will it be next? So, therefore, there is some sort of uncertainty about the whole process, and so this is why we are calling it a stochastic process.
Now for this particular company, an employee may ask the following questions: if an employee is working in sales, what is the probability that after two assignments, he will be working in sales again? This particular employee may want an answer to this question; or for example, if the employee is currently in Production, how many months must pass, on the average, before he enters HR - Human Resource? So, you know, as I said again just as for the first example, I am stating some questions; you can also add some more.
(Refer Slide Time: 15:52)
 
And the third one for example, is if the employee has been with the company for 4 years, how many times on the average he would have been assigned to HR – to Human Resource? Then what percentage of an employee’s assignments will be in Sales? So, these are the questions and many more. 
Now why would these questions be important? Because a prospective employee, who is going to join the company, can ask questions like this, so that he can judge about his prospects in the company. Basically, he would like to know whether he would professionally be satisfied with the company or not. If it turns out that he comes to know that, you know, he will most of the time be with sales, then of course, he may not be wanting to continue, you know, stay with the company because he may not be interested in sales and so on. So, I am just giving an example, but there can be many such questions that can be asked.
So, the N i’s of the first example and X i’s of the second example are not independent random variables; that you can see. In the first example, the N i’s for the number of particular brand of watches that were left at the end of the week that were in stock, and so, we saw that this was dependent on what your demand is in the following week and dependent on your ordering policies. So, you cannot say that N 1, N 2, N 3 and so on, they are independent random variables, you can see that there is some relationship. And similarly, for the X i’s it is possible, see whatever the way they organizers or the owners of the company decide to reassign the sections, certainly where you are and how long you have been in a particular section will have a bearing on where you will be next. So, you can feel that these random variables are not independent. And, therefore, any kind of computations about these random variables will not be easy thing.
So, now we will attempt to define this stochastic process, after these two examples. So, any random process for which time can be measured discretely and can be represented as X sequence of random variables. So, I should add the word here - and - can be represented as a sequence of random variables; then, this is I will call it a random process or I will call it a stochastic process; it is called is called a stochastic process. Or we simply - you can simply - say it is a sequence of random variables index by time. So else stochastic process and definitely you can see that it is evolving over time, and then you want to now look at its behavior. 
And so of course, now you see that if you want to answer any of these questions that I have posed and even on the earlier one, then you see, you may want to know, you would need to know the joint density function of example - if your planning horizon is 5 years, then you may want to know, you would need to know, the joint distribution of X 1, X 2 up to X 10, since they are not independent, and therefore, you cannot say that the joint density function of X 1 to X 10 will be product of individual density function. So, you will have to, you will need to find out, and of course, if your planning horizon is much bigger, then you know, you can just give, you know, you can throw up your hands and say that – no, we cannot compute joint density function of so many random variables. So, therefore, we need to really look at the methods by which we can sort of simplify analyzing such process, or under what conditions can we try to answer questions like this when we are looking at a stochastic process.
(Refer Slide Time: 20:15)
 
So, for the automobile company, just look at the… we can diagrammatically describe the profile of an employee, and so you see, here the horizontal axis is giving you the time period. So, this is the beginning of the planning horizon - so zero period, that means, the start of the process; then, this denotes the first 6 months period; this is the second 6 months period; third 6 months period and so on. So this is, what it is.
And then, here you have the three sections to which the person can be assigned. So, for example, what it is saying is that here in the first 6 month period he was with HR - the second section; and then in the next 6 month period he got assigned to Production, that is your first section; I think this is Production, this is HR and this is Sales. So, then he got assigned to in the second 6 month period he went to Sales; and then again after that, he went to sales in the next this month; that means, 1 year is over and this is the next 6 months in it. So, therefore, you can see that this diagram, and here for example, here from this onwards he continued for two periods consecutively in the Production section. So, this you can diagrammatically describe the profile of an employee in the manufacturing company.
Now let us just give some more terminology. So, set of all possible values the random variable X i takes is called the state space. So, we always describe, so when whenever the system or the process is, whatever situation it is in, so that would be described by the state space and normally what we do is we give it numbers.
So, the possible values in the state space we describe by the numbers. So, for example, here the three sections I have numbered as 1, 2, 3. So, it is easier; because, otherwise, you cannot go writing the possible values that the state space contains; it may different, different things. So, we can just distinguish by the numbers. And so here, for example, this will be X n is i, means the state in which the system is at time period N. So, the value of X n - so, if I am describing the my X i’s are the variables - which are the random variables - which describe the process. And then, when you change these to, that means, when the system changes from one state to another, we call such process as - the change it is called as transition or transitions.
Now as I said that and we have seen the two examples already, simple ones. We saw that the real life situations the processes will be many; many, many processes that are stochastic because there are elements of the process which cannot be determined with certainty, and then we have also seen that, you know, even in such simple examples your X i’s are not independent. So, there will be some sort of dependence among the random variables.
So, therefore, as I was saying earlier, that it will be very difficult to have a combined joint density function of all the possible random variables which describe the states in which the system can be over long time period. And so, you cannot just analyze or answer any questions about the process. 
So, Markov suggested the following simplification. So, he said that the transition from one section to another may depend on the current section occupied and here I should say the word only, the transition from one section to another may depend on the current section occupied. So, when we say depend, this of course, that means, the computation of the probability, the probability with which the process will transition from one section to another, the probability would be dependent on where you are right now - so, the current section. So Markov suggested this simplification.
And for example, in the watch shop example value of N i plus 1 to depend on the values of N i and D i plus 1 only. And the way I was describing to you the values of N i plus 1 which was max of the formulae I wrote down. So that, from there we saw that we were computing N i plus 1 only depending on the values of N i and D i plus 1. So, that was, that was anyway according to Markov’s definition; this is already satisfying the Markovian property.
(Refer Slide Time: 25:12)
 
So, when once you have this, and then that means, in the section assignment problem what we are saying is that - we are saying that if you want to look at X i - the value of X i - then that will depend on… so the probability that you will go from, whatever the value of X i, it will depend on what is the value of X i minus 1. So, sort of the transition from here; so this will depend on this, and then X i will affect the value of X i plus 1 with certain probability. So, this is the kind of dependence we are only allowing or you can say this the simplification. 
So, this makes the analysis of stochastic processes, which satisfies Markov’s property quite tractable, and we will see this, as we go on, we will see that we can probably answer almost all the questions that I wrote in the beginning, about the automobile manufacturing company and the question that - the kind of questions - that an employee may be interested in knowing. So, we should be, we will be able to answer the questions, because if we say that the section assignment process would satisfy the Markov property. 
Now any stochastic process, which satisfies Markov’s property, is called a Markov chain or a Markov process. So, I will be using the word Markov chain or Markov process with the same meaning - synonymously.
So, now, what happens is that with the Markov’s property being satisfied by the process, then we just need to compute the joint or the conditional probability mass function; remember I am talking about discrete processes. So, joint or conditional P M F of neighboring X i’s is computed. So, it simplifies and therefore, you know, we are having two variables, you can very easily compute the joint or the conditional P M F of two variables. And so, with that, we are then able to analyze the process over long term and whatever it is.
So, now if you want to formally state Markov’s property, that is, see essentially what you are saying is - probability X n plus 1 is equal to j; that means, at time N plus 1 your system is occupying state j and if you look at the past history starting from X 0 is i, then it will be X 1 is some i 1 and so on. X n minus 1 is i n minus 1 and X n is i. So, this is the entire past history. So, if you are not assuming the Markov property being satisfied by the process, then of course, to answer this - compute this probability - you would need to know the entire past history, but then, Markov’s property simplifies it and says, that this whole thing can be made equal to probability X n plus 1 equal to j given that X n is i; so whatever the condition; so the current state of a system that helps you to determine, so with some probability where the system will be in the next state, next time period. And so, these are known as one-step transitional probabilities and we will call them as p i j.
So, now here I am not writing anything else, why because I am now making one more simplification; and what we are saying is that, this is actually equal to probability of X 1 equal to j given that X naught is i; so, that means, the starting probability, the starting state of the system, suppose if you were in system was in i - state i - then the next period that it is in j. So, we will denote that one-step transitional probability and we will say that over the long period that the process goes on, this does not change; that means, whether at the time period N plus 1 you are considering the change from X time period N to time period N plus 1 or you are considering the change from the starting - initial state - to the first period. So, those probabilities remain the same and that is why the word stationary. 
So, what we are saying is that the one-step transitional probabilities are stationary. And essentially the explanation here is that whatever process you consider, we are saying that after the initial perturbations and so on, this system has settled down to stationary; this system has become - or the process has become - stationary. So, it is not, and therefore, these transitional probabilities are not being affected by where you are considering - at what time period you are considering the transition. As we go on, we will be looking at a lot of processes and lot of situations - real life situations - where we will see that to assume that we have transitional probabilities have the stationary property is not very unrealistic. So, we will continue with the…I will just continue with defining and giving you how to compute these probabilities and so on. Once you have these probabilities, then what can you do with these?
(Refer Slide Time: 30:40)
 
So, let us start looking at how we will now continue with the analysis of the process. So, therefore, what we would need first to describe the process, and then, what are the quantities that we would require before we can continue with our analysis and trying to answer the questions related to the process.
So, if X naught is the… let us say X naught might be the present assignment by our notation zero. So, this means, whatever value of X naught, that tells us the present assignment of the employees, and then, we are interested in his next assignment. That is, we want to know the value of X 1 in the next time period. So, if suppose X naught is 1, that is the man is currently in Production, then X 1 can be 1, 2, or 3 any of the three sections he can be assigned to.
So, that means, you would want to know what the probability is. So, it means this has to be given to you, that is if he is already in, he is starting his career with X naught equal to 1; that means, he is in Production right now; and then, what is the probability that he will be again kept in Production only? So, X 1 is 1. So, we will call this as a P 1 1. And as I told you these are one-step transitions probabilities and that we are assuming stationality. So, it does not matter whether it is X n plus 1 equal to 1 given X n is 1; or X naught is 1 given that X naught is 1 then X n is 1, so the probability. So, P 1 1. And then, similarly, you would need to know if X naught is 1, then what is the probability that he will be in HR? So, that probability is P 1 2 and the probability that he will be in Sales is given by P 1 3. So, these are the first step transitional probabilities. 
If you know where he is at the beginning of the planning horizon. Again if you know X naught is 1, but if X naught is 2, then of course, again their transitional probabilities will be different - in the sense that now what is this probability of going from 2 to 1? So that means, he is in HR and then the probability that he will be assigned to production; so, that must be some probability. You see these are the transition probabilities, which are now describing to us whatever the assignment process is.
So, therefore, again these three transition probabilities P 2 1, P 2 2 and P 2 3 are given to us; and then for if X naught is equal to 3, that means if he is already in, he is currently in Sales, then his probability of going into Production will be P 3 1, probability of going into Sales will be P 3 2, and probability of remaining and Sales will be given by P 3 3. So, these we call as the… I am not all the time saying one-step transition probabilities, but that is understood. So this is transitioning from state. So here, these three numbers - these three probabilities - give you the transition probabilities of transitioning from state 3 to any of the three states. So, therefore, the process, and now, of course, we will see that this is not a complete description of the process, and we will, as we go along we will find out what more we need; but, let us first just look at this. 
So, now, the nine first step transitional probabilities can also be written as 3 by 3. See, remember, because whatever the number of states, if the number of states is capital N, then your transition probabilities will be N square, because you can go from one state to any of the N states. So, therefore, you will always have N square numbers. And so, these transition probabilities can be written in a matrix form. So, if you have N states that this system can occupy, then it will be N cross N matrix that you can you can record all these transitional probabilities in an N by N matrix. So, here since our states, 3 states are there, three sections. So, I can record all the nine transitions - first step transition - probabilities and then 3 by 3 matrix. So, P will be called transition matrix. 
Now since the man must transition from, let us say from, Production to any one of these other, either he stays in Sales, Production or he goes to HR or he goes to Sales, he must transition to one of them, because after every 6 months the assignment is announced.
(Refer Slide Time: 35:34)
 
So, therefore, these three probabilities will add up to 1. And therefore, also another way of saying that these probabilities must add up to 1 is that they are the P 1 1 and P 1 2 and P 1 3 describe the conditional P M F; remember we have talked about it while talking about, you know, conditional probabilities and conditional expectations.
So, this is the conditional P M F of X 1 given that X naught is 1. And, so therefore, since these three numbers describe the conditional P M F they must add up to 1 because of this. In the same way you can argue that the second and the third rows must also add up to 1; that means, P 2 1 plus P 2 2 plus P 2 3 is equal to 1 and P 3 1 plus P 3 2 plus P 3 3 is 1. So, now, any square matrix which has - because these are probabilities, so they have to be nonnegative numbers - so any matrix - a square matrix - which has all entries or all elements nonnegative and the rows add up to 1, can qualify to be a transition matrix; that means, we can say that there must be a stochastic process, which can be associated with such a matrix. So, all entries are nonnegative and the rows - the elements of row - add up to 1 - of every row - add up to 1. So, this will be - this will qualify to be a transition matrix.
Now, another way of looking at this process, because diagrams always help, they fix ideas, and I think they also help in the understanding of the process. So, let us see, I will describe the three states by the nodes of this graph. So first is your Production, HR and Sales. And if I am showing it arc from 1 to 2, then this is transitioning from 1 to 2; and of course, I have not entered all the probabilities, but they can be written down here. And so, the arc 2 to 1 will be the transition from - one-step transition - from your HR to Production. And this loop describes, that means, you stay in one, that means, your transition from one to one. So, you do not go anywhere, you continue with the same state.
So, this way you can look at this. And so, you can write down the probabilities. Here also P 1 1; this will be P 2 2; and this will be P 2 3 and this will be P 3 2, and finally, this will also be P 3 3, and here this will be P 3 1 and this will be P 1 3. So, this diagram also helps you to look at… and you can see that currently you can transition from for example, from 1 to 2, then you can go from 2 to 3, you can come from 3, again you can come back to 2 or you can go from 2 to 2. So, actually, you can play around and you can see lot of things you can do with the… you can see how the transition is taking place and so on. But, of course, this you can do when your number of states is small.
And if the number of states is large, then drawing a picture like this may not be a very good alternative, and so, we will have to look at other ways of handling this process; but anyway, this makes the thing look interesting; I mean the picture is there and you can just see how the process is evolving over time going from one state to another and going through these parts. So, you see we describe the first step transitional probabilities and through a diagram and so on.
(Refer Slide Time: 39:23)
 
Now, suppose we want to now look at look at X 2 - the random variable that describes the state of the system at time 2. Now, again I will try to show you through the diagram. So, if you look at this for example, you start with state one; that means, you start with Production and after two transitions you are back in Production. So, what would that mean? So, the possibilities are that you start with Production, then the next period you again transition to Production only; that means, you stay where you are; and then finally, you, in the next step you again transition to Production. So, that means, you continue through this. So, this path describes one possibility which I have written down here.
And then, it could be that you start from Production, you go to HR, and then again, you get transition back to Production. So, that would be your second path. So, I am talking now in terms of paths; because this is how you will - when you go for two-step transition probabilities - this is what you will have to do - compute the probabilities of these paths. And then finally, you will start from Production, go to Sales, and then you are back to Production and that will be your third path. So, just to give you, and of course, we will continue this discussion in next lecture also. 
So if you look at probability X 2…So, here your the arrows are in the wrong direction. So, it should be X naught to 1 and then X 1 to X 2. You start from here, then you transition to Production, and again you transition to Production from the first period to the second period. And since we have the Markovian property that tells us, that, you know, we just need one-step transition probabilities, that means, the transitioning from X naught 1 to 1 and then from in the second period, from in the first period from 1 to this; these are independent, and therefore, I can write them as the product of transition probability 1 to 1 here in the first period, and then again 1 to 1.
So, now here again the second property that we have used is the stationality. So, Markovian property and stationary transition probabilities both tell us that, you know, the probability of the first path; that means, transitioning from 1 to 1 in 2 periods along the first path, the probability is P 1 1 square. And so, we will continue with this kind of computation, and then show you very interesting results. And then, you will see that how far our analysis can go of a stochastic process which satisfies Markovian property and of course, we are talking when the stationality conditions are met.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 26
Transition and State Probabilities

(Refer Slide Time: 00:15)
 
So, I will continue the discussion about computing the transition probabilities one step transition probabilities I showed you and we have just started talking about two step transition probability. So, just consider a case in last lecture I considered the case x 2 equal to 1 x naught equal to 1 now let us look at x 2 equal to 2 and x naught equal to 1. So, in that case you see that what are the possible routes of transitioning from the initial state of 1 2, the state 2 in 2 steps. So, I want to look at it. And of course, three possible paths would be see at step 0. So, this is a time period 0, time period 1, time period 2 and these give you the states. So, therefore, at time 0 the system is in state 1 it transitions to state 1 that is a possibility, because in one step you may transition to 1 2 or 3 and then you have to come back to state 2.
So, therefore, one possible route would be from 1 to 1 and then 1 to 2 right in one step transition in one period you go from 1 to 1 and then from 1 to 2. Similarly you could go from 1 to 2; that means, you transition to, so this was our production and this is h r. So, from production to h r and then h r to again h r right, you can continue here or the third route would be from 1 to 3; that means production to sales and then sales to h r. So, these are the 3 routes and that I have written down the 3 routes. In this way these are the 3 possible ways, no other route is possible of going from 1 2 2 in 2 steps right. Now, we need to compute the probabilities of traversing these paths, because you want to compute two step transition probabilities.
Now, look at the first path. So, the first path I know the probability of transitioning from 1 to 1 when I am initially in state 1 and I am now transforming or transitioning to state 1 in the next time period then it is p 1 1, I know that now look at this path of the leg. So, this is the 2 paths of the journey from 1 to 2 for example, so this is this. So, 1 so first 1 leg, I know you already know the other 1 step transition probabilities.
Now, we use the Markovian property, because you see the probability that you want to compute is going from 1 to 2 in; that means, you are actually looking for a probability x 1 to 1 x we are in 1 at time period 1 and you wanted to transition to 2 time period 2 right. So, then you see this is independent of the first leg y, because you see this is independent the Markovian property says that from here to here the transition probabilities independent of where I was at time zero the initial state. So, its independent of value of x zero right and therefore, I can write the probability of traversing this path as product of the first leg into the probability of the second leg. So, this is the idea and this is where I am using and otherwise I would not able to write these transition probabilities two step transition probabilities if I did not have the advantage of the Markovian property ok.
So, it is clear that, because as remember, I said that the past history is not important for computing is not required for computing the transition probabilities. So, the here it is, where you are currently and where you want to transition. So, this is the only thing that we need to compute the probability I do not need to know, where what was the value of x naught right. And so therefore, the two are independent and since by our stationarity.
(Refer Slide Time: 04:06)
 
So, the stationarity property, I should say that stationarity property gives us says that probability x 1 equal to 1 and transitioning to x 2 equal to 2; that means, the conditional probability of being in 1 and transitioning 2 this is same as probability x naught equal to 1 transitioning to x 1 equal to 2 right.
So, remember because we said that this stationarity say that probability x and plus 1 equal to j given x and equal to I is a same as probability x 1 equal to j given x naught equal to I right. So, the stationarity property says that these transition one step transition probabilities remain the same no matter in which time period you are and therefore, this transition probability of going from 1 to 2 was the same as the probability x zero equal to 1 so going from here to 2 in initial stage. So, therefore, we are able to write down the probability of traversing these paths. And so I have written them down here for the all 3 paths.
(Refer Slide Time: 05:25)
 
So, this is for the first path, this is for the second one, because you are going from 1 to 2 and then 2 to 2. Why have I written it this 1 p, p 1? Ok this was to 1 to 2 and here I am using the fact that you are going from what is this path x 2 equal to 2. So, what is the path I have written here x naught equal to 1 so 1 1 and 1 2. So, this is a path right and then you have 1 2 and 2 2. 
So, that should be, so this is that one and this is this one and this is a third one, 1 to 3 and then 3 to 2. So, this is 1 1 and 1 2 and this is 1 2 and 2 2. So, that is the 1, which I have written here and this is the 1 corresponding to this and then this is 1 to 3 and 3 to 2. p 1 1 say, I do not know why am I writing this as x naught is 1 and then you are going to what is this path? This will be 1 3 and then this will be 3 2, ok sorry, all these 3, I am sorry, these 3 paths together give you this probability right of x naught equal to 1 and x 2 equal to 2 yes this is. So, these are the 3 possible ways of going from 1 to 2 in 2 steps right 2 steps transition. So, all these 3 add up to this, I am sorry, this is the 1 right, p 1 1, p 1 2 and then p 1 2, p 2 2. So, this is p 1 1 1 2 then this is 1 2 2 2, which is this path and then it is 1 3 and 3 2 so 1 3 and 3 2. So, these are the things.
So, now similarly when you want to when your x zero is 1 and then x 2 is 1; that means, in 2 steps you want to transition 1 to 1. So, again you will have 3 possible such paths right, maybe I will just again repeat the whole things then there is no confusion. So, for example, you can go from 1 to 1 and then 1 to. So, this is here see the path corresponding to this will be this right. So, maybe I make it this thing yeah just 2 and then what are the possible way you can go from here 1 to 2 and then 2 to 1. So, 1 to 2 yes and then 2 to 1 so this is the 1 right.
And then the third path would be when you 1 to 3 and then 3 to 1 right. 1 to 3 so you would go from 1 to 3 and then 3 to 1. So, this would be 3 paths and then for the each path you would write down the probability. So, this corresponds to the three exclusive paths through which you can go from 1 to 1 in 2 steps and similarly this will be 3.
So, now you have computed all the two step transition probabilities for when x naught is 1 right and then in the in 2 steps you can be in 1 2 or 3. And so similarly you will have a six more such transition probabilities, when x naught is 2 and then you want to transition to 1 or 2 or 3 in 2 steps starting from a step 2 at time 0. And then finally, it will be x naught equal to 3. So, x naught is equal to 3. So, because you do not know you could be in any of the 3 states or the beginning of the process. And so x 2 is equal to 1 you are transitioning to 1 from 3 in 2 steps from 3 to 2 in 2 steps and from 3 to 3 in 2 steps right.
So, let p 2 denote the matrix of 2 step transition probabilities just as p we are not writing p 1. So, understood p 1 is said this is p. So, this is a transition matrix of 1 step transition probabilities now let p 2 denote the matrix of 2 step transition probabilities. Then we will just quickly notice that p 2 is actually p square, because ya here you have written the components of this, let me just write down say for example, if you want to write. So, p 2 this here will be the first one will be a p 1 1 2 you want to look at right. And so that will be going from so p 1 2 p 2 1 plus p 1 3 ok, first let it be 1 1, 1 1 then it will be 1 2 p 2 1 plus p 1 3 p 3 1. So, this will be a first element right, these are the 3 paths, which I had drawn in the last lecture ok.
So, then you see this is multiplying a p 1 1 p 1 2 p 1 3. So, first row of p and with p 1 1 p 2 1 p 3 1. So, if you multiply the first row of p is the first column of p you get the entry p 1 1 2 right. And now, you can also verify this for example, this is the first row p 1 1 p 1 2 p 1 3 you are multiplying with the second column p 1 2 p 2 2 p 3 2 right. So, to get the entry 1 2 in; that means, it here if you want to get the entry 1 2 then you are multiplying the first row of p with the second column of p. And therefore, you can just verify yourself quickly that p 2 the second step condition maybe nothing, but the product of p and p. So, that makes like very easy and we will show that this is valid for all values of for a higher powers of p also; that means, if you want to look at yeah.
So, let me just show you a systematically that we would be you are really on the path of getting a very interesting and very useful result. Because to be able to compute these transition probabilities any step transition probabilities by raising the power of p is a very convenient way of getting the transition probability right. So, here you are want to know that what is the probability that you will be in tenth steps you will be from i to j starting in state i you will be state j then the tenth the i j th entry of p ten will give you the at probability and so on. So, you will see that yeah. So, basically what we have we have shown is that your 2 step transition probabilities can be expressed in terms of 1 step transition probability right, because we are just multiplying the 1 step transition matrix with itself and we are getting computing the 2 step transition probabilities right ok.
Now, same way we can do it for any power and here again I will just want to spend time it may look like little reputation, but it does not matter, because you must get the ideas very clear. So, for example, now yeah so the whole a target is now to compute p i j k; that means, k step transition probabilities we want to compute. And so here again I will just start from x 3 equal to 1 and x naught equal to 1. So, suppose now the 3 steps, you want to transition from 1 to 1. So, this again I can break up like this x naught starting with 1 you are in 2 steps in 1, state 1 and then you will be going again transition to 1 right. So, this is your 2 step transition probabilities and then this is your 1 step.
So, again I can write down this and now these 3 paths are mutually exclusive and exhaustive right. This is not because there you can go to x 2 you can be after 2 steps after 2 transitions you can be in state 1 2 or 3 right. Starting from x naught equal to 1 and then you have to transition finally, to a state 1. So, therefore, these are the 3 paths right. And here again we are using the Markov property because this one is this then this part of the path will be independent of the probability for this, because here you have x 2 equal to 2 and x 3 equal to 1.
So, there only the current state is needed to compute the transition probability and this is not dependent on where you were earlier either at x 1 or at x naught, that is not important. So, therefore, we will write this and again using stationarity I will simply be able to write this also again as a 1 step transition probability of going from 3 to 1 right. So, therefore, you see that these 3 probabilities can be written as p 1 1 2 yes in 2 steps you are going from 1 to 1 and then again 1 step you are going from 1 to 1. So, this is p 1 1 2 and p 1 1 right. Similarly 2 step transition from 1 to 2 1 to 2 p 2 and then 2 2 1 p 2 1 plus p 1 3 2 and p 3 1 right, this is yeah right. 
So, and then I can write down x 3 equal to 2 when x naught is 1 and then of course, probability x 3 equal to 3 x naught equal to 1 right. This will also be equal to so p 1 1 p 1 3 plus p 1 2 p 2 3 plus p 1 3 p 3 3. So, this is the first row of and you can see that since this is your element of p square. So, therefore, if you write these are the entries of your p square and then you are again multiplying by p 1 1 p 2 1 p 3 1 so; that means, so essentially yeah ok.
(Refer Slide Time: 16:04)
 
So, we saw that p 3; that means, if you want the 3 step transition probabilities, this will be given by p 2 p square into p. So, again a third power p. And so in general we will should be, we can now say that if you want to n step transition probabilities then this will simply be raising the matrix p to power n. That means, multiplying p n times and the entries in p n will give us all the n step all the n steps transition probabilities that we need right.
Now, there is a another method through walks on the transition graph, but you will soon realize that it is not a very efficient method it is fine to see what is happening when your graph is small in number of states are also not too many. So, for example, when you want to look at this probability of 2 step transition probability from going from 1 to 1 right.
So, which would mean that you traverse this loop once and then again one more times, 2 times you traverse this loop and you have this then you can compute the probability, which would mean that this is a traverse of probability of traversing the loop once is p 1 1. So, when you do it twice it will become. So, the probability would be. So, the probability this would be p 1 1 square right, fine. Then if you want to for example, compute the 3 step transition probability of going from 1 to 1 then let us see what are the we will try to see all possible paths on this transition graph going from 1 to 1 right.
So, of course, I have not written the detail for example, x naught equal to 1 x 1 equal to 1 and x 2 equal to 1 and x 3 equal I am just you know made the notation simpler. So, here this tarsus the, you know 1 path which is you are traversing this loop four times right, I mean 1 to 1 sorry, 3 time. 1 to 1 then 2 and then 3, three times, because 3 to 3 transition probability so this path you would traverse 3 times; that means, the loop you will traverse 3 times. Then the probability is that you go from you traverse the loop once then you go to 2 and then from 2 go to come back to 1 right. So, you traverse this loop twice then you go to 2 and then 2 to 1. So, this is 1 path and therefore, here again you can write down the probability as p 1 1 square into p 1 2 plus p 2 1 right.
So, once you write down. So, the eight possible paths, you can see that right 3 step transition and you this 3 possible states so therefore, eight possible paths. And similarly like 1 to 2. So, you go from 1 to 2 then you traverse this loop 2 to 2 then 2 to 1. So, this will be p 1 2 into p 2 2 then p 2 1 right. So, this way, I can write down all the probabilities and then compute the. So, therefore, they are all distinct paths and you can compute the probability of each path and as I told you each leg of the path is independent. So, we are multiplying the corresponding probabilities of traversing each leg of the path. And so you can write down, but you see that this will become very conversion the moment your number of states become, you know if you had four to five states or even, you know easily any Markov process that you consider we have seven to eight or ten states.
Then you see the possible number of the number of paths were really go up right, exponentially. And then you may it is a since its very likely that you will miss out on some of paths, because you have to inomulate all the possible paths. And here in this case only you know for x 3 equal to the 3 step transition probabilities for 1 you are going from 1 to 1 you had to inomulate 8 paths.
Now, if it becomes x four it will be 16 paths. So, the number this will blow up and. So, therefore, this is for large n and for large number of states; that means, if you want to ten step transition probabilities and the number of states is also ten. Then it just not possible for you to inomulate all possible paths and then compute the probabilities, but for small cases and. In fact, to see actually what is happening this is a good way right. So, I thought I have just talked to you about it and when you are working out with small problems you can actually see this, but otherwise this is really a very efficient way of computing the higher order transition probabilities. Now, this is fine. So, therefore, we have now a method of computing any step transition probabilities provided we are giving the 1 step transition probabilities right.
(Refer Slide Time: 21:06)
 
But again we there is some more information that we need and that is see the value of x naught is not known with certainty we do not know when which a state the system has was initially or for where it started right. So, this will be normal given by a probability distribution; that means, you will be given these values. So, p I naught is a probability that x naught is an state I right. So, this at time 0; that means, that initial time the employee is in state i. So, this is there is a probability attach to it.
Now, if you want to compute the probability that the employee is in H R in human resource section division at time five. So, you know; that means, you want to compute yeah, so let us see you want to compute the probability that x 5 is equal to 2. So, the particular employee at time period five is in h r right. Now, let us see the column of p 5 remember the 5 step transition probabilities are given by p 5. So, the column would be p 1 2 5 p 2 2 5 and p 3 2 5. So, actually I should have written this let me write this instead of you know immediately jumping to this. So, we want to say that the probability x 5 is equal to 2 given that x naught is 1 right. Then you will multiply this by probability x naught equal to 1 right. So, I am writing this as a conditional probability then into the. So, then I will have to do it for all possible values of a x naught.
So, to get the probability that x 5 is equal to 2. So, this will be probability x 5 is equal to 2 given that x naught is 2. So, probability x naught is equal to 2 right, plus probability x 5 is equal to given x naught is equal to 3 into probability x 3 is equal to oh sorry, x naught equal to 3. So, I break up this. So, again you see mostly what you have seen that, you know the basic probability theory that we need for analyzing these chastic processes. So, this is a writing probability as a, you know breaking it up into conditional events and then writing them down as the some of these conditional probabilities right. And so this one gives you this is your five step transition probability from 1 to 2. So, 1 to 2 5 and then into probability x naught is equal to 1, which is given to you from here.
So, p 1 naught so this will be p 1 naught right. Similarly this will be a five step transition probability of going from 2 to 2. So, this is p 2 to 5 into probability of being in state 2 at time 0. So, which is p 2 0 and this is third. So, this is how you can write down the probability if you want to know that the in time period 5 the employee will be in H R right. And so you can now compute in general you can say that this is now p i n will be the probability at the system is in state i at time n and see here just to make the presentation simple. I am just taking all the time referring to our job assignment example, but you know that this can be made to whatever the number of states general you can have a simple k here. So, k states and everything can be argued with respect to general number of states, but here I am doing it for this particular example just show that you can fixed your ideas better ok.
So, then p i n is probability x n equal to i; that means, the system is in state i at time period n. So, these are the probabilities and I have shown you how you will compute them. So, you can write them down right here. So, this will be your, I am writing this small p naught into p n. So, when you want the probabilities of the system being in a particular state and time period n then this is a formula and these are called the state probabilities at time n. So, this is the important right.
So, now we have we do also have the see we have the transition probabilities for any time period and we also have the state probabilities at for any time period n right. And yes so I have written it here where these I am saying that p n is your row vector of probabilities. So, this is the i th component. So, then p n is ya, I should have written here so this is the i th component ya. So, in general so if this is a row vector is p 1 n p 2 n p 3 n. So that means, state probability of the system being in n being in 1 at time period n this is probability of the system being in state 2 at time n this is the probability of the system being in state 3 at time n. So, I denote this by a row vector p n and then this can be written as p naught into p n. So, this gives these state probabilities at time n right.
Now, the Markov change is completely specified when you are given the first step transition matrix p and the initial probability, initially probability was being system being in particular state. So, p naught is the vector which gives you p naught 1 p naught 2 and p naught 3. So, this will be the probability in initially when the system is in state 1 2 or 3. Then you can compute these and of course, you can compute the transition probability in step transition probability also.
(Refer Slide Time: 27:24)
 
So, let us consider an example the same example now with numbers. And so we will just go through all the concept that we have talked about the transition probabilities and state probabilities I mean higher order transition probabilities and the state probabilities. So, suppose the transition matrix is given as this. So, then the corresponding diagram you see for example, there is no arc from 2 to 1. So, therefore, this is missing here and similarly you do not have a loop from 3 to 3. So, it is missing the probability is 0 right, otherwise and you see that they add up to 1 all these probabilities or the rows must add up to 1. So, this is a valid transition matrix and these are other positive or zeros and they row entries and all add up to 1. So, this is valid and a comparing diagram is this, the transition diagram is given by this right.
Now, let us compute second order transition probabilities. So, I multiply p with p and I get these numbers. So, for example, here you can transition from 1 to 1 in 2 steps this will be 1 to 1. So, 2 steps therefore, again the same thing as I showed you that if you just want to sit on path it will be 1 by four this plus then you can go to you cannot go to 2 in 1 2 steps transition, because then you cannot come back to 1 right. So, then it will be you can go to 3 and then 3 to 1. So, this will be 3 by 4 into 1 by 4 right.
See you can either stay with 1 to 1 and then you can go from 1 to 3 and then 3 to 1 this is what you can do in 2 steps if you want to transition from 1 to 1. So, 2 possible paths and so therefore, this is 3 by 16 and this is 4 by 16 so 7 by 16 right. Similarly you can maybe look at this 1 here 5 by 16. So, this is from 1 to 2, 1 to 2 you want to transition in 2 steps. So, then the possible path is 1 to 2 then 2 to 1 right. So, that will be what 1 to 2 is 1 by 4 into you transition from 2 to 2 will be 1 by 2 plus or you can stay from 1 to 1 and then go from 1 to 2. So, that will be a 1 by 2 into 1 by 4 right. So, what how much will this be 1 by 8 plus what or what I miss something out. So, this is you are going from 1 to 2, 1 to 2 you are going in 2 steps yeah.
So, 1 by 2 yeah this is a 5 by 16 and you are computing p 1 2 right. So, you can go from p 1 1 into p 1 1. So, that was 1 by 4 and why did I multiplied by I want to go from 1 to 1 sorry, this is not correct, why should I have say 1 to this is simply 1 to 1 so this into p 1 2. So, therefore, this is half ha that is I wrote this plus 1 by 2 into 1 by 4 or I can go from 1 to 2, which is 1 by 4 and then transition 2 to 2. So, that comes out to be 2 by 8 and I am getting it as 5 by 16. So, let us multiply this; that means, you want 1 and 2. So, that will be, (()) I am missing out on the path 1 by 8 plus 1 by 8 plus 1 by 16, so 1 by if you want to go from 1 to 2. So, right I missed out on the path. So, this is 1 to 1 and then 1 to 2 then 1 to 2 and 2 to 2 and then there is a another path 1 to 3 and 3 to 2. So, plus 1 to 3 is 1 by 4 and then from into 3 to 2 is 1 by 4.
See that is what I am trying to say that you know even in such a small diagram I was missing out on a path. So, just imagine if you had these five or six states and then you had you know, that many nodes so and then you have these so many arcs. You will certainly miss out it will be very difficult to it will be very time consuming to enumerate all possible paths. So, as it is you know such a small example, I could miss out on the path 1 to 3 and 3 to 2. So, that will give you now 1 by 8 plus 1 by 8 plus 1 by 16. So, that will be 5 by 16 right, 1 by 8 plus 1 by 8 which will be 1 by 4. So, that is 4 by 16 plus 1 by 16 5 by 16.
So, anyway you can now interpret all these probabilities you know by looking at the path or by find. Now, I make further computations took powers of p. So, this is p 3 comes out to be this and if you make compute fourth power then these are the numbers. And another aspect that I want to point out here is that for example, in this particular case you are able to transition from any state to any state. Even though some of the arcs are missing, but even after that, you can go from 1 to 2, 2 to 3, 3 to 1 again and so on. So, you can transition from any state to any state maybe not in 1 step always, but in fact, here it is happening that you are able to go yeah for example, from 2 to 1 you cannot go in 1 step, but you will able to go from 2 to 3 and then 3 to 1. So, in 2 steps you will be able to transition.
So, here in fact, the moment all your entries see at p 2 yeah. So, at p 2 all your entries are positive, which shows see therefore,; that means, your p i j 2 is positive for all i j. So, this immediately makes you conclude that you have a 2 steps path from each state to from every state to every other state. So; that means, this was the word for this is communicate; that means, all states communicate with each other and maybe not in 1 step, but at least in 2. So, if all the entries of p i j 2 are positive then; that means, all states communicate with each other, I will formulate define that also, but essentially what I want to saying here is that you can go from any state to another state in 2 steps in this particular example. And in some other example, if it is you know there is some k for which this is positive then; that means, again there is a k step path from every state to another state. 
(Refer Slide Time: 34:24)
 
And ya, so now when you look at the fourth power of p these are the numbers and you can now you should carefully look at the column numbers this is 103 upon 256, 102 upon 256 and 102 upon 256 so the numbers are getting closer right. And you can say that almost conversing to 102 on 256. In fact, you might say that why not 103 or 102, but any one of these numbers. So, in other words that you know, if you want to interpret these numbers; that means, now the probability say for example, what is this number. So, 103 upon 256 is the probability of 114; that means, four steps you are from 1 to 1 right. And then 102 upon 256 this is the probability 2 1 4 right; that means, if you, so here it says that, if you are initially in state one then in four steps you will be back in state one. So, this is the probability.
Now, this says that if you are in state 2 in the beginning and you are transitioning to 1 in four steps then this is a probability. And third one is 102 upon 256, so this is p 3 1 4 so; that means, you are in state 3 and you are transitioning to 1 in four steps. So, you see that it is becoming almost immaterial to know, where you started, because these probabilities are getting closer and we will show you then later on you will also formula is all this discussion. So, essentially the state in which you were the initial time is becoming unimportant these. And similarly the same thing you can interpret for the second column because it is a 85 by 256 86 by 256 and 85. So, these numbers are also getting closer to 85 and here I have written, because here its 68 by 256 68 by 256 and 69 by 256.
So, you might say that why not 68, but then see remember the probabilities, which when you finally, say that all these are conversing to they must also add up to 1 right, because the system has to be in 1 of the states. So, the same argument we will continue using and so here I have if I say that this converges to 102 this 2 upon 256 this is 85 by 256 then this should by 69 by 256. Of course, it is possible that the, so essentially right now the probability of being in state 1 after four transitions is hovering between 102 256. So, which is a more exact statement, this is a more exact statement right. Similarly here also I can say the probability of being in state 2 after four transitions is between, is in the interval 85 upon 256 and 86 upon 256 right, which is a very small interval right.
So, difference of 1 upon 256 and similarly here it will be 68 upon 256 and 69 upon 256. So, these probabilities and if you take the fifth power then certainly you will see that the numbers are conversing and you will take about this formulae anyway yeah. And also while we are talking of this see I wanted to point out that here again these probabilities, because this is now row vector, this is a row vector remember 1 by 3 we are writing. So, this is 1 by 3 and this is 3 by 3. So, then again this is 1 by 3. So, the 3 atleast must again add up to 1, because at you know n after n transitions your system will be either in 1 2 or 3. So, therefore, these probabilities also must add up to 1 right, which you can see also that.
So, anyway these also add up to 1 and then now, suppose for this job assignment problem, if your initial probabilities are given by 1 by 4, 1 by 4, 1 by 2. That means, probability of being in production is 1 by 4, probability of being in H R is 1 by 4 and probability of being in sales is half then you want to ask the question that what are the probabilities of being in state in 1 2 or 3 after 2 transitions. So, that will be given by this right. So, 1 by 4 1 by 4 1 by 2 multiplied by p square and so these are the probabilities of being in you know. So, this gives you the probability of being in a production after 2 transitions right and this is the probability of so these are the state probabilities after 2 steps, after 2 time period. So, this is 21 by 64 and 18 by 64 and these probabilities also must add up to 1 right. So, now, we are trying to give you some more characteristics of the Markov process and we will do lot of analysis in terms of these transition probabilities and the state probabilities.
(Refer Slide Time: 39:53)
 
So, let us I just want to show you the limiting behavior of these steady state probabilities. So, let us just graphed the values of p 1 3 p 2 3 and p 3 three for different values of n. So, you see the starting vector is 1 by 4 1 by 2 and 0. So, p 1 3 for example, 1 by 4 is 0.25. So, I am just start it. So, these are time periods and these are your probabilities. So, numbers from 0.1 to 0.5. So, 0.25 see at time 1 it is in period 1 it is 0.25 then here also 4 by 16 is 0.25. So, in period 2 also this is a same then it will very slightly goes up in period 3 to 17 by 64. So, I am just showing it like this and then it comes down to 68 upon 256.
Now, 68 upon 256 is 0.26. So, therefore, it comes down to a point this is this is my value for a 0.26. So, this is the graph for p 13 as it goes to different periods. So, the values transition probabilities then, if you look at p 23. Now, p 23 is starts from half right then it immediately comes down to 0.25, because this is 1 by 4 so 0.25. So, this is where it is and then in the next 1 it goes to 18 by 64. So, actually sorry, my graph for p 1 3 is this 1, because very slightly it goes up and then again it settles to here this is the graph for p 2 3.
So p 2 3 the p 2 3 graph is this. So, this is from 0.5 to 0.25 then it goes up to 18 by 64. So, this is above more than 17 by 64 this and then it comes to 68 by 256. So, the same value as for p 1 3, p 1 3 4 and p 2 3 4 are the same. So, this is how it is and for the for p 3 3 see it is 0 in the beginning and in stage time period 1 then it jumps to 5 by 16, which is little more than 1 by 4. So, little more than 0.25 and then it comes to 16 by a 64, which is exactly 0.25, right.
So, I have try to just parallel it with this 1 here and then it will be 69.256. So, the line is the slightly above this. So, therefore, you can see that and then as you take higher powers all 3 will settle down to this number, which we have to compute and we will do it when we find out the steady state probabilities. So, you see this is the limiting behavior and so it does not matter even though the 3 had different very different starts all the three, but finally, they must to the same. So, therefore, the relevance of the starting state of the process is not at all a relevant here this is what you want to show. And of course, this will show this will not always be true and we will now then find out during the course of few next few lectures as to when this is valid on when this kind of limiting behavior is valid ok.
So, what we are going to say is that rows of p n become identical to pi 1 pi 2 pi 3 all the rows, because it does not matter the starting state of the starting state of the system. And so all the rows will be pi 1 pi 2 pi 3, but it is not necessary that the 3 probabilities are the same right so; that means, it is being. So, essentially what we are saying is this is now a long term behavior we are saying that the system will be in state one. So, that is a probability right then this is the probability of the system being in state 2 and this is the probability of the system being in state 3. So, the starting probabilities are not relevant, but the values long run values will not necessarily be the same. And so the definition for the steady state probability is that pi j is the limit of p j n, as n goes to infinity right, remember we defined this as the, you know multiply by p 0 and p n.
So, this is a limiting a value of p j n, as n goes to infinity, which is actually probability x n in j right. In the long run your system is occupying state j as n goes to infinity and what we are saying now is that this actually is equal to this conditional probability, but this part is becoming irrelevant right. So, the i c the probability finally, is going to pi j so the i part is irrelevant here this is what we want to show you. 
And so we will in the next lecture discuss the under what condition of course, that will come in the due course of time, but first of all we would want to know how we go about computing these steady state probabilities when we know that they are they exist. So, right now we will assume that they exist, and then we will find out the method of computing them. And then we will continue with the discussion as to under what conditions they always exist.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 27
State Prob First Passage and First Return Prob

(Refer Slide Time: 00:14)
 
So, through the numerical examples we saw that limit p n - p is a transition matrix - so the nth power, as n goes to infinity, if this exists - if the limit exists - then it converges to a matrix with all rows identical. Whatever two-three examples we considered, we saw that the limit existed, and then, we saw that the rows were becoming identical as we increase the value of n; that means, we continue taking higher and higher powers of p. We can easily show that in case limit p n exists, limit p n then goes to infinity - if this limit exists, this is always be the case; that means, whenever this limit exists, when this will converge to a matrix whose rows are all identical. So, let us show this immediately, very easily.
So, limit p n; suppose, n goes to infinity. So, Q 1 is a row, Q 2, Q k; suppose these are k rows. We are considering the system when it has k states, k possible states. So, then I can write limit p n as n goes to infinity as limit p n minus 1 into p, as n goes to infinity. Then as n goes to infinity, this and this have the same value. So, this same matrix; they will converge to the same matrix. So, this will be Q 1 Q 2 Q k is equal to Q 1 Q 2 Q k p. So, this reduces to the limiting case; this reduces to this system. Therefore, from here, you can say that Q i, the i th row here, would be the i th row multiplied by p, post multiplied by p. So, this is it for all i. And hence you can see that all rows of p are - I should not say of p; what I want to say is, that if it converges to… p is your transition matrix. So, all rows of p raised to n will converge to… So, all rows of limit p n, I should write here limit p n as n goes to infinity are identical.
Now, if you want to solve for this, you can see that immediately, see you know that the rows of p, the rows of p have the property, because it is a transition matrix. So, all rows add up to 1. And therefore, this is not a non-singular matrix. And so, here you will have infinite solutions, to this system you will have infinite solutions; but then, if you also require the elements of Q i to be non-negative and they add up to 1, that means, we are looking for a solution where the Q i (s) - the elements of Q i - form probabilities, then this will be a unique solution and I will denote this solution by Q i is equal to pi 1 pi 2 pi k and these will be known as the steady state probabilities. So, it means when the system has a steady state, it has gone on for a long time, it settles into a steady state, then the probability of being in state 1 is pi 1, probability of being in state 2 is pi 2, and up to pi k. So, this is the whole idea. 
(Refer Slide Time: 03:41)
 
Now we will come up with the method of obtaining these values pi 1, pi 2, pi k - the steady state probabilities. So, now let us evolve the method for computing the pi i(s) - the steady state probabilities. See, p n can be written as p n minus 1 into p, the n th power of the transition matrix. So, then, if I take limit on both sides, then this is the limit p n and n goes to infinity; and this is limit p n minus 1, n goes to infinity into p. Now, as we said since we have assumed that the pi i(s) exist; and so, each row of p n in the limiting value would be pi 1, pi 2, pi k; so, all the rows are identical. Therefore, on this side also you get the matrix pi 1 pi 2 pi k, pi 1 pi 2 pi k, and so on. Similarly, p n minus 1 will also converge to the same matrix and this times p. So, the limiting behavior, I can just break up this in this way and then do it. So, if this is going to the limit, in the limiting value to this matrix, this will also go to the same matrix, and therefore, you have these equations.
Now, this system actually, since the all rows are identical, so actually these k equations reduce to this. So far, I was talking about the three-state processes. So, now, let me just do this much in 3, for the general case, and then we will come back when we want to talk of specific values and examples, we will again revert back to the three-state example that we have been talking about. So, let us just talk about it in general, and therefore, the system reduces to k equations; that means, I can simply just equate the first row here to the first row here. So that means, pi 1 to pi k is equal to pi 1 to pi k times the matrix p. And now let us write out the equations in detail here. So, pi 1, the first component here, will be this multiplied by the first column of p.
(Refer Slide Time: 05:33)
 
So, the first column p is… so pi 1 p 1 1 1 plus pi 2 p 2 1 and so on plus pi k p k 1. Similarly equate the second, component here, element to the second element; that means, this multiplied by the second column of p; so that gives us this. And finally, the k th equation is pi k is equal to pi 1 p 1 k. So, the k, the k th column we will take when we equate pi k with this multiplied by the k th column. So, I have these k equations, but we can immediately see that these k equations are not linearly independent, since sigma p i j, j varying from 1 to k is equal to 1. So, let us just quickly check this - that is, all these equations. See essentially what I am saying is that your first k minus 1 equations will give you the k th equation. So, therefore - those of you who are familiar with the word rank - so, the rank of this matrix is k minus 1 or you want to show that.
So, let us add the first k minus 1 equations here. So, it will be pi 1 plus pi 2 plus pi k minus 1 and this is equal to... So, when you are adding the first k, so you will be adding p 1 1 plus p 1 2 up to p 1 k minus 1. So, it will be pi 1 into summation p 1 j, j varying from 1 to k minus 1. And similarly, pi k into summation j varying from 1 to k minus 1 p k j.
Now, since the rows add up to the transition matrix we have to put this. I mean we know this that these rows of the transition matrix will always add up to 1. So, therefore, sigma j varying from 1 to k minus 1 p 1 j is actually 1 minus p 1 k. Because this plus p 1 k is 1. So, therefore, this sum is equal to 1 minus p 1 k, and similarly I substitute for all of these sums by. So, this one will be 1 minus p k k.
And now you see that when you open up the bracket, so, pi 1 plus pi 2 plus pi k. So, pi 1 plus pi 2 plus pi k minus 1 cancels out, you are left with pi k, and the other things you transferred to this side. Then you immediately get pi 1 p 1 k plus pi 2 p 2 k and pi k p. So, this is your k th equation. So, because the probabilities of the rows sum up to 1, therefore, these k equations are not linearly independent. So, in fact, the first k or any k minus 1 will lead you to the k th 1 essentially, because here I just choose the first k minus 1, you can choose any k minus 1 and you will be able to obtain the remaining one by adding the k minus 1 equations you have chosen.
So, therefore, infinite solutions - because the matrix is singular; the equation matrix is singular, but when you impose a condition because since we are looking for these steady state probabilities and they must add up to 1, pi 1 plus pi 2 plus pi k has to be 1, because a system will be occupying one of the states - either one, two or k minus 1 or k. So, when you impose the condition that pi 1 plus pi 2 plus pi k is 1, then you get a unique solution. And so, so therefore, we have a very neat way of computing these steady state probabilities and we know that we have a unique solution. So, you cannot say that, you know, that the probability of - the long run probability of - being in a particular state of the system, here you know the probabilities are more than 1; that would not be reasonable solution.
So, now let us go back to your job assignment problem, and let us try to obtain, because I was trying to get you to have a look at the steady state probabilities by taking the powers of p, but now here, this seems to be a quicker way of and a neater way of solving, of trying to get the pi (s). So, because when you are taking the powers you really do not know when to stop; or in fact, you would have to go on doing it till you see that the values are really closing in. So therefore, this would be a better way to get your steady state probabilities. And so, the three equations you see, you can see from pi 1, your this thing p 1 2 is … when you are writing the equation your p 2 1 is zero. So, here you get, yes, the matrix is there in your earlier lectures. So, these are the three equations essentially for solving pi 1 pi 1 pi 2 pi 3.
So, therefore, I can from this equation I immediately get… So, the trick would be that since you know I do not get unique solution to this system, so I will solve for pi 1 and pi 2 in terms of pi 3 and then I will apply the condition that the sum is equal to 1 to get the value of pi 3 and then I will get all the values. So, from here you see - you immediately see - that half of pi 1 is 3 by 4 pi 3. So, that gives you that … where is pi 1? Yes, half of pi 1 is 3 by 4 pi 3. So, pi 1 is 3 by 2 pi 2, 3 by 2 pi 3, and then you can substitute here for pi 1 in terms of pi 3 to get your pi 2. So, pi 2 comes out to be 5 by 4 pi 3. Because this is half pi 2 and this is pi 3 minus 1 by 4 into 3 by 2 pi 3. So which makes it 3 by 8. So, 5 by 8 pi 3; therefore, pi 2 is 5 by 4 pi 3.
So, now I substitute the values pi 1 is 3 by 2 pi 3, this is 5 by… this is 5 by 4, 5 by 4 pi 3 and this is 1. So, therefore, how much is this? I suppose I will have to redo this thing or maybe this was right, I do not know. So, what is it? This will be 6 plus 5 plus 4. So, the value was ok. This was a mistake here, but the value I had computed was ok. So, this is this. So, therefore, your pi 3, pi 3 is 4 by 15. And so, this gives you pi 2 equal to 5 by 4 into 4 by 15, the value of pi 3. So, that makes it 1 by 3. And this pi 1 would be? pi 1 is 3 by 2. So, 3 by 2 into 4 by 15, which is this, and 3 by 5. So, pi 1 is 2 by 5. And now, let us compare these values with what we had obtained by taking powers of p.
(Refer Slide Time: 13:07)
 
So, our pi 1 had come out to be something because two values of 102 upon 256 and the other one was 103 upon 256. So, you see, 2 by 5, does lie between these two numbers. So, this was up to fourth power. And when you take the fifth and sixth powers, you will see that values will get closer and you will actually reach 2 by 5. Similarly, your pi 2 is 1 by 3, and this is also a number lying between 85 upon 256 and 86 upon 256. You can compare; right this is between. So, 1 by 3 lies between these two. And similarly, 4 by 15 is a number which is between 68 by 256 and 69 by 256. So, the two things matched, but certainly that is a much better, quicker, way of obtaining your steady state probabilities.
Now, these steady state probabilities have very useful interpretations and we will continue seeing through examples, through on, when we analyze the process further. So, essentially what we have said is that pi i is a probability that in distant future one will find the system in state i. So, the probability that your process will be, that means, a particular employee in the automobile manufacturing company, that particular employee, will be in lets say HR, when you know after the process has gone on for lets say for 4 years or 5 years, then we expect the person, the probability, that the employee would be in the HR division is 1 by 3 or the probability that he will be with sales is 4 by 15. So, these are the long term probabilities. And as we said that the initial, that means, the division or the section in which he started his career is irrelevant here. Then you can also interpret this as the fraction of time the system occupies state j; fraction of time the system is occupying the state j. I am writing pi i. So, it should be pi i here. Yes, this is i. So the fraction of time the system occupies state i.
Now, if you run many identical processes simultaneously, then you see, that the pi j would come out to be the fraction of processes that you would find in the state j; that means, if you suppose run hundred identical processes simultaneously, and you find out that maybe 45, 45 of the processes are that particular time, of course, you let the processes run for a long time, and then after a certain particular period of time, you just find out how many of these processes are occupying state j. So that comes out to be 45, then your pi j would be, pi j would be approximately 45 upon 100; that will be the fraction of processes that you would find in state j. And another interesting interpretation of the state pi j is, you know, it is a reciprocal of the mean number of transitions between recurrence of state j. So, this recurrence I will define formulae after some time which is also very important.
So, what we are saying is that, this is the reciprocal of the mean number of transitions. So, on the average how many transitions would be required to go from state j to j? Now recurrence means for the first time; that means, you are in state j to start off, and then for the first time when you revisit j. So that number of transitions, if you take the average of such transitions, then the reciprocal of that is your pi j. And this also we will derive in another way, and of course, this part we will prove later on. 
So, for example, what we are saying is that since pi 2 is 1 by 3 and pi 2, 2 is our HR section. So, we are saying on the average three transitions will be required for this particular employee to go from HR to HR. That means, if he starts his career with HR - Human Resource section - then he will after 3, on the average, he would be requiring 3 transitions to get back to HR. So this is the interpretation. So many interpretations that we have we can give, and then, we will see how we make use of these steady state probabilities to analyze these processes further.
(Refer Slide Time: 17:47)
 
So, let us now… I have taken this example from again Rabindra, Phillips and Solberg. So interesting physical interpretation of state probabilities. So what he saying is that, in the, you know, job assignment problem, you know, you would consider the three states as three reservoirs. So, node 1, and node 2, and node 3 - they are reservoirs, and the arcs connecting the nodes are the pipes through which liquid can flow with valves to ensure that flow goes in the direction in which the arrows are there. 
For example, there will be valve here, which will direct the flow from 1 to 3 only, and another valve which will direct the flow from 1 to 2, and then another one which will just direct the flow from 1 to 1. So, this is the idea. So, just think this as a reservoir - representing a reservoir - with these pipes connecting them. The reservoirs and then the valves to ensure that the flow goes in the direction in which the arrows are there. And then the probabilities p i j (s); that means, for example, the probability 1 4 associated 1 2 would be the fraction of the liquid that is there in 1 - in reservoir 1 - which will be sent to 2. Similarly, if you look at 2 to 3, then it is half the liquid, which is there in reservoir 2, will be send from 2 to 3 and so on.
So, these probabilities then can be interpreted as the fraction of the liquid in the reservoirs. So, p i j is the fraction of the liquid in reservoir i, that will pass to reservoir j in 1 unit time. So it will take 1 unit of time for the flow; so that means, half of the flow from here to here in 1 unit of time will go from 2 to 3, because the probability is half. 
So, if we think of the system as, you know, made like this, then what you do is, you pour 1 unit of liquid into the system according to these initial probabilities; that means, one-fourth of the liquid is put in reservoir 1; a one-fourth is put in reservoir 2; and half the liquid is put in reservoir 3. And then, the liquid is allow to flow according to this plan. Then what we are saying is that dynamic equilibrium. So what we have discussed - that the probabilities will converge and they will become irrespective of how much liquid was initial poured into the reservoirs. So, finally, dynamic equilibrium will be attained and the liquid will continue to flow, but the liquid in each reservoir will equal the steady state probabilities.
So, our steady state probabilities… I do not have the numbers here, but whatever we had computed pi 1 pi 2 pi 3 as, for example, I remember pi 2 was 1 by 3. So, pi 2 would be the… that means, reservoir 2 will have one-third of the liquid, and then pi 1 would represent the amount of the liquid that is in reservoir 1, and pi 3 will be the amount of the liquid present in reservoir 3. 
So, this is the interesting part. So what is being said is that, actually equilibrium will be attained and the liquid will continue to flow according to this plan, but each reservoir will settle down to - even though the starting amounts were this - each reservoir will settle down to the amount of the liquid according to these steady state probabilities; and what do we mean by that? So equilibrium means that for each reservoir the flow out will be equal to the flow in; then only whatever there is - the liquid is there - the steady state liquid that is there in the reservoir will be maintained, which is according to your pi 1 pi 2 pi 3.
(Refer Slide Time: 21:33)
 
So, flow out from reservoir i would be… So, the probability that you are in a reservoir i into then p i j, summation over j. So, from i it can go to reservoir 1 to 2 to 3. So this is the probability that the amount of liquid flow out from reservoir i… and the amount … This you can write, when you summing up, you are summing up with respect j; so i can, pi i can come out, and this will be sigma j p i j, but sigma j p i j is 1, all these probabilities and the i th row will add up to 1; so this is pi i. And the flow in from other reservoirs that the flow is coming in. So that will be pi k into p k i; the flow is coming from the k th reservoir to the i th reservoir, and so this is the probability of being in the k th reservoir. So this is sigma pi pi k p k; well I am talking of probabilities, but here we are saying this is the amount that is there in the k th reservoir, and so this is the fraction which is going to i.
So, yes, I should actually interpret the whole thing in terms of this particular example. So, here also I should not refer to pi i as the probability of being in i, but this is the amount of liquid that is there in the i th reservoir and the p i j fraction of this liquid is being sent to the j th reservoir. So, therefore, flow out. So, from the i th reservoir this much is the liquid, and from this, these are the fractions of this liquid which are being sent to different reservoir. So this is a flow out and this is the flow in. So, please just interpret it this way; ignore my earlier remark. So this is a sigma pi k p k i, and so, the two must be equal, and therefore, you again get these, if you do it for all i, then you will immediately get this equation pi is equal to pi p. So I thought this was interesting way of looking at these steady state probabilities and somehow these will fixd certain ideas in your mind.
Then another example from Sheldon Ross that I want to … because I really want to spend time on these steady state probabilities, so that you get the ideas, you know, understand them properly.
Now, here this is an example where it is a production system and these are the probabilities of … transition probabilities. So we have four states 1, 2 and 3, 4. Now the states 1 and 2 are considered as acceptable or you can say when the system is up, and 3, 4 are not acceptable which you have to interpret as your system is down - that means, there is a breakdown, the machines are not functioning. So there are four states and this is your transition matrix from state i to state j and questions to be answered.
Now, the question that we want to answer are - the rate at which the production process goes from up to down; that means, the rate of breakdown. So when it is up, that means, the machines are working and then there is a breakdown. So you want to know the rate at which the process - the production process - goes from up to down. 
And another question will be the average length of time the process remains down; that is also very important, because you want to know with this kind of transition matrix, you want to know for how long the process will remain. And of course, you always talk in terms of average length of time the process remains down when it goes down. So, when there is a breakdown for how long will it remain in that state before it comes up, but now the new thing is that you have two states which are describing the up situation and two states which are describing the down situation. So, therefore, I took up this example to again show you, of course, we will compute the p i(s) and then I will show you how to answer these and there are many more questions that have to be answered. 
So, the third question you want to answer is the average length of time the process remains up when it goes up. So, these are the three questions we will try to answer by computing these steady state probabilities.
(Refer Slide Time: 25:53)
 
So, we write down the equations for the finding these steady state probabilities. So, pi 1 is equal to this pi 1 pi 2 pi 3 times the first column. So, you get this number, this equation then pi 2. So, you can just by looking at the transition matrix, yes the matrix p, then you can see that these are the four equations that we will obtain.
Now, interestingly the second column here is all 1 by 4, 1 by 4, 1 by 4, 1 by 4. So, when you write this second equation, this, you immediately get the solution for pi 2 because all these add up to 1, the state steady state probabilities have to add up to 1. So this immediately comes out that pi 2 is equal to 1 by 4. So, I have used it already here and now since I have the value of pi 2, I should be able to immediately compute the values of pi 1 pi 2 and pi 3. So, what I do is here, yes… no that is not… I have to now after having got pi 2, yes I can now see from here… yes, no even here… So, I thought that it was immediate that you could compute after you have pi 2, then yes, yes, see here, yes, you see, that is why one has to be a little clever and use inspection. So, here this is pi 1 pi pi 3 and pi 4 and again the coefficients are 1 by 4. So, this I can write as 1 by 4 into 1 minus pi 2. See and I have the value of pi 2 already as 1 by 4. So, this again immediately gives me pi 1 as 1 minus 1 by 4 is 3 by 4 into 1 by 4. So, 3 by 16. So, your pi 1 is 3 by 16.
Now, I have the values of pi 1 and pi 2. So, then from here I can immediately get pi 3 because bring this here. So, this will be 3 by 4 pi 3, 3 by 4 pi 3 and I substitute the values of pi 1 and pi 2. So, this will be 1 by 2 into 3 by 16 plus 1 by 2 into 1 by 4; that gives me 7 by 32. So, pi 3 will be when you multiply by 4 by 3 gives you 7 by 24. And then, once you have, you now have pi 2 pi 3 and pi 4 is on this side, when you bring it will be half pi 4. And so, again substituting for pi 2 and pi 3 you get these values. And so, you get pi 4. So this was quick work. You know this was certainly faster than computing, you know, second, third, fourth powers of p, which is a 4 by 4 matrix. So, lot of multiplications if you start taking the different powers.
Now, let us try to answer the questions - rate of breakdown. So, rate of breakdown is a transition probability of transitioning from up to down; that means, up means when your machines are working or anyone of the machines are working and then any one breakdown will mean there is a breakdown. So, that means, you are transitioning from up 1 and 2 which are up states to their down states which are 3 and 4. So, that means, you want to say that if you are in state 1, so that is the probability into your transitioning from 1 to 3 or 1 to 4. So that is p 1 3 plus p 1 4.
And if you are in state 2, then the transitioning from up to down is 2 3 plus 2 4, p 2 3 plus p 2 4. So, we have all these numbers or the probability of a rate of breakdown will be 9 by 3 2. Because any one of the breakdowns, this means you are going from up to down. So, any one breakdown or two breakdowns, whatever it is, the probability is 9 by 32 and that is your rate of breakdown.
Now, you want to answer the second question, which is the average length of time, average length of time the process remains down when it goes down. And the other one is the average length of time it is up when it goes up. So both the things. So, let us define u bar as the average time the system is up, and d bar as the average time the system is down. Then your rate of breakdown is… now we are, you know, redefining or talking in now. So, then we will make the equations and try to find out u bar and d bar. This is the idea. So, rate of breakdown is 1 upon u bar plus d bar, because you know, see this is the average time it is up and the average time it is down. So, one breakdown at the rate of 1 upon u bar plus d bar, because this is the total time when it is up and then down, average time. So, therefore, 1 upon this will give you the rate of breakdown, because one breakdown for this time, this much period, one breakdown for this much period, and therefore, the rate is 1 upon q bar plus t bar. So, proportion of up time is then u bar upon u bar plus d bar. And similarly, you will define the proportion of a down time as d bar upon u bar plus d bar.
Now, let us try to find out. So, the definition of u bar will be pi 1 plus pi 2; this is because… this is the… your are either in the state 1 or state 2 that is where it is up. So, this is the probability of being in state 1 or state 2, and then so this is a proportion of time and this is your rate of breakdown 1 upon u bar plus d bar which we have already computed as this from here, this is your rate of breakdown; so that is this. And so this is a gives you your u bar, and then we compute d bar, and we will continue with the exercise.
(Refer Slide Time: 32:00)
 
So, therefore, we saw that u bar will turn out to be 7 by 16 which is pi 1 plus pi 2 divided by u bar plus d bar which was your rate of breakdown. So, that was 9 by 32. So, then we multiply and it will be 32 by 9. So, this is u bar comes out to be 14 by 9; that means, this is the average amount of time for which the system will be up. And since u bar plus d bar is a 32 by 9, so to get d bar we will simply say d bar plus u bar minus u bar which is 14 by 9. So, that comes out to be 18 by 9, which is 2 units of time. 
So, therefore, what we have been able to answer the three questions that were asked: the first was what is the rate of breakdown? So, this is 9 by 32 or 28 percent of time the breakdowns occur. And then, the breakdowns from the average last for 2 units of time; so, that means, once the system is down then it will remain down for 2 units of time. And the third question was the average amount of time for which it is up. So, then there is average amount of time for 14 by 9. So, 14 by 9 it is up, when the system is up. So, it will remain up for 14 by 9 times. 
Now, the thing is certainly the system is not in a very satisfactory situation because your breakdowns on the average the breakdowns have remained for 2 units of time, whereas your actual production time is only 14 by 9 which is less than a 2 units of time. So, certainly the system is not in a very healthy state. And so, this again gives a warning to the manufacturer to do something about it, because the way the transition probabilities are given, this is what your conclusions are. 
So, I hope you understand, see the way we computed this because we had to define u bar and d bar, and then of course, the other reason I took this example was that, you know, they were two states which were defining the up system and two states which were defining the down system, and therefore, we had to… these computations were not just straight forward. So, I thought that will be a good example to discuss in this course.
So, once we have talked about these state probabilities pi i(s) which we were answering as to the, you know because this, and of course, we have also computed this. So, for that means, number of transitions required to go from i to j, this was the answer, and then the pi i(s) gave you the… the pi i(s) gave you the long term probabilities of being, of the system occupying a particular state, and then all of course, we also said that this is a fraction of time that the system will be in state i. So, pi i(s). I gave you these interpretations of pi i.
Now, this other kind of questions that are needed which are now the first passage and first return probabilities. So, this is also very important, because you want to know how long it will take to reach a certain state. And so when you say how long will it take to reach a certain state… see the statement it means here that you know that will be the for the first time that you reached the state; so that means, you are starting from a state i and then you are wanting to say that how long will it take for you to reach state j. So obviously, the moment you reach state j you have answered that question. So, therefore, this will be what you mean by this is that for the first time that you reach state j from i. So, that is the understanding.
So, that means… now, for example, if n transactions occur before the state j is reached from state i. So, suppose we want to just, you know, surmise or say that n transactions have taken place before state j is reached from state i, and then we want to know the probability that n transactions will be required for going from i to j, then you might say that would p i j raised to n be the answer, for this probability? Because p i j n also tells you the probability of transitioning from i to j in step one, but see now there is a difference, because you see, when you talked about p i j n then it does not say that you may reach j before… and a number of times before you finally reach j in n steps. The various graphs that I drew for you earlier showed that you may, you know, like you had, you started from state 1 then you stay in state 1 and state 1.
(Refer Slide Time: 37:06)
 
So, this was your, you know, transition probability from 1 to 1 in two steps or in three steps you stayed in state 1. So, here that is fine. So, this was your p 1 1 3, p 1 1 3, of course, also included that you could go from here to here, remain here, and then come here, or you could stay here, then go here, and go here. So, this is fine; this particular path that you are taking, no you are not coming back to state 1 before.
So, starting from state 1, you are reaching here without going to state 1 before hand. So, therefore, this is the kind of path you are looking for; but whereas, when we were computing your p 1 1 3, we had all possible paths to reach from 1 to 1 in three steps; that is what we were doing. Say, for example, if you consider p i j 4, then p i j 4, I could go to 4 in step two also; that means, from i, I could go to j, as I said and then you could again go to j, and then j; this would also be there. Then you will have i to j, and then, you could go to k, and then to j, and this way. So, so many paths, but nobody is stopping you from…
So, when compute the probability p i j 4, remember we said it includes all possible paths of going from i to j. And so you could revisit j in between number of times because you have to, you have to enumerate all the possible paths. So, therefore, this is not the answer what we are looking for. So, we need to make some more definitions and some more terminology has to be introduced to compute these probabilities. So, the first passage and first return probabilities we want to compute.
So, essentially what we were looking for is that for the first time I reach j from i. So, in between I should not have touched state j, and when the first time it occurs I want to compute the probabilities of such. And so, so what we will do is, we will make these definitions here. So, again f i j n, I am defining as the first passage probability. And so, I need to… I have written first passage here, but I will define it here. So, first passage probability of going from state i to state j. And remember x n was the state in which this system is at time n; this is… we have been using this notation when we were describing the transition probabilities on the Markov process.
So, now what are we asking for? We are saying that f i j n is equal to the probability of x n equal to j, but x n minus 1 is not j, x n minus 2 is not j, and x 1 is not j; it is only x naught; x naught is… x naught is i. So, starting from i in between all these n minus 1 transitions that take place you do not ever touch j, but it is only in the n th transition that you reach j. So, probability of that is what we were defining by f i j n; so, that means, probability of reaching j from i in n transitions for the first time. So, if you look at f 1, f i j is 0 then f i j 0 is 0 because we cannot transition; then f i j 1 will be p i j, your … f i j 1 will be simply p i j.
So, now we want to compute f i j n; that is probability of going from i to j for the first time in n steps - n transitions - for the first time. So, we should not have visited j in between, less than n steps. And so, this we will obtain by writing p i j n which is the total probability of going from i to j in n steps - all possible paths - which may imply or revisiting j number of times, and then finally, coming back to j. So, p i j n minus in sigma k varying from 1 to n minus 1, you see, because you want to reach for the first time for y to j and n steps. So, your k can be allow to vary from 1 to n minus 1 only, and then this will be f i j k. So, for the first time you have visited from i to j in k steps, and then once you reach j, and then again you can go to many other states, come back to j or stay in j whatever it is in n minus k steps.
So, for example, if you look at p 1 1 3, then what we are saying is that you can, you know, continue staying here in state 1 for all the three transitions or you can go somewhere here, come back and then again revisit here, and whatever possible paths you can, or you can go this way, this way, this way. So, many other paths you can think of. So, we are ruling out all those paths. So, we are subtracting; so, that means, you have visited from i to j in k steps for the first time, and then, in the remaining n minus k you again from j go to other places or remain in j and then come back to j. So, we subtract all these, then we get the probability that f i j, we subtract these from p i j n. So, we get the probability that probability of visiting j from i for the first time in n steps. And then we will see lot of applications and implications of these probabilities. So, this is what we, how we write down the expression for f i j n.
So, let me… and of course, when j is equal to i, then f i i n would be the probability of going back to i from i for the first time. So, you started from state i, and then when you for the first time you reach a state i again in n steps of going. So, I should say from state in n transitions; so, in n transitions. So, this will be f i i n and that will be the probability of recurrence of i, state i, in n steps. So, f i i n and I used the word recurrence earlier and I said we will define it later on, so that is it. And we will, of course, be talking in detail about these first passage times and first return time.
So, first return probabilities is your recurrence probability, a probability of recurrence; but here, of course, we are saying in terms of n transitions and then you would want to know the probability of ever returning to state i, and so, we will compute that also.
So, now the number of transitions to go from i to j for the first time. So, transitioning from i to j for the first time is called the first passage time. So, the number of transitions required to go from i to j for the first time we will define it as a first passage time. And you can see that this is also a random variable because you do not know how many transitions you will require to go from i to j for the first time. So, first passage time is a random variable, and if i is equal to j, then the first passage time is called the first recurrence time. So, this will be when you want to come back to the same state, starting from your particular state you want to come to it for the first time, that will be your first recurrence time.
So, first passage times and first recurrence times are random variables; and therefore, you can redefine this again f i j n is a probability that first passage time from, probability of first passage time from i to j in n steps; that means, your random variables. So, f i j n is the probability of the first recurrence of the first passage time equal to n. So, f i j n will be because this is the time, first time return, for you go from i to j and when this value is equal to n you want to compute this, the probability of first passage time equal to n is your f i j n; this is how we will define.
We will go through now a very interesting journey when we want to, you know, compute these f i j n and f i i n. In fact, you would finally, want to talk about f i j; so that means, that will be when for the first time you return from i, transition from i to j, so without the n because here this is transitioning the first passage time when it is equal to n. That means the probability of the first passage time equal to n. So, now you would want to then finally, compute your f i j and f i i. So, we will continue with this discussion.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 28
First Passage and First Return Prob. Classification of States

So, we will continue our discussion with first passage and first return probabilities; how to compute them and so on.
(Refer Slide Time: 00:14)
 
So, I just recall quickly that f i j 0 will be 0, because there cannot be any transition in 0 time; then, f i j 1 that mean the first time, j is reached from i in one step, so that will simply be p i j. So, the first step transition probabilities are the first-time transition probabilities also, and then for f i j n, we wrote down this formula through which we can recursively compute the f i j’s. So, an f i j n will be p i j n minus sigma k varying from 1 to n; f i j k into p j j n minus k. And I had explained last time also that, we are… because p i j n simply gives you the probability of transitioning from i to j in n steps. And in between you could number of times have visited state j. So, all that is included here, because we were computing all possible paths from i to j. So, that may include going to j and staying over j and so on; and then, going from j to somewhere and then coming back to j and all that.
So, now, we will want to subtract those probabilities from p i j n to compute f i j n. And so, this says that, here this is the first time in k steps you transition from i to j for the first time and then from j to j in n minus k. So, this again will include… No, going from j and coming back to j, but in between also you can visit j any number times. 
So, this p j j and minus k; and here this is… You have already reached j in k steps and then all this is happening, because you are computing re-transitioning probabilities up to n. Therefore, we have to subtract. So, these particular paths we are subtracting; that means from i to j, suppose you have this; and then, you go back here; you come back to j; then, again you go back and come back to j and so on. So, n minus k steps you will be doing this; but, in k steps, you reach j for the first time from i. So, we have to subtract the possibility of traversing all such paths from this one to be able to compute the first passage probabilities. And so, that is what we are doing. So, I thought that, I will revisit this and explain it much better.
Now, we can solve these iteratively from these equations given the initial conditions here. But, then we need the p i j n’s are available for all n to compute this. So, just look at this example. Again a job assignment problem; we have p square is this; and F 1. So, here I we are using the notation that, now, just as a P is a matrix of one-step transition probabilities; P square is the matrix of two-step transition probabilities; we will also denote the first time first passage transition probabilities by the matrix F 1. Then, it will be F 2, F 3, and so on. So, if you want to compute for example, f 1 2 1; no, what am I doing here; this is f 2 1 2. So you want to compute the probability that a transition from 1 to 2 in two steps. So, this will be by the formula p 1 2 2 minus f 1 2 1 p 2 2.
See here the formula is… Therefore, you reach… that means in one step, you will go from 1 to 2 and then you have to stay with 2, because there is only 1 step here. And therefore, if you compute this, you get 3 by 16. So, now, what you see is that, you have to... Therefore, now using this formula, you can compute… you get the matrix F 2. So, you have to compute all two-step transition probabilities before you can compute other the three-step first passage transition probabilities. And for computing F 3, you would need F 1, F 2 and P 3 also; that means P, P 2, P 3, F 1, F 2 you will need to compute F 3 – elements of F 3. And so, this is lot of work. And so, I will give you now an alternative method of computing these first passage probabilities without wanting to… also, without wanting the higher powers of P; just the first transition matrix would be enough.
(Refer Slide Time: 05:02)
 
So, the alternate way. Now, the alternate way is see the way we explain; this is now, look at it as a one-step. So, f i j n – I am writing as sigma k varying from 1 to n p i k. So, one-step you transition right in the beginning; you are starting from i. So, suppose you go to k. So, that probability is p i k. And then, from k, the first-step transition probability… I mean first passage transition probability k to j in n minus 1; is it okay? that means, k is varying from 1 to n. So, for all possible states, you are starting from i and you may go to some other k; and then, from k, you want to go to j for the first time. So, here you will require n minus 1. So, if you have already computed f k j n minus 1, then you can compute f i j n by using the first-step transition probabilities. And so, this is a neater and more efficient way of computing f i j n’s recursively. So, the argument is okay because I have to move out from i to some this thing. So, k should not be j obviously, because I have to visit j for the first time; but, then in… that means I will definitely visit some other state from i to k in one-step since I want to visit j from i in n steps.
So, in the first step, I will definitely go somewhere, which is a state, which is different from j. And then, i need f k j to n minus 1. So, from k to j, I should visit j from k for the first time in n minus 1 steps. So, this is a neater way of computing the first passage probabilities. And now, here we just need the one-step transition matrix P. And of course, we are computing these f k j… – all of these before I compute f i j n. And so, here again, I am just doing the same exercise. So, if you want to compute f 2 3 2; so, then this will be simply p 2 1. So, remember the k does not have to be… So, k cannot be 3. So, k can take the value 1 and 2. Therefore, p 2 1 f 1 3 plus p 2 2 f 2 3. So, this is all. And so, by taking the values because this is only p 1 3; so, this is p 2 1 p 1 3 plus p 2 2 p 2 3. And you can looking up the values in the matrix P, you get this.
Now, look at f 3 1 2; f 3 1 2 – so, here j is 1. So, k can be 2 and 3. So, this will be p 3 2 into f 2 1 plus p 3 3 into f 3 1. And what is happening is that, what is p 3 2? p 3 2 is 1 by 4, but then what is f 2 1? f 2 1 is p 2 1. So, p 2 1 is 0. So, this is 0. Then, p 3 3 is 0 into f 3 1. So, this is 0. But, then you remember if I have not drawn the diagram here; but, if you remember, the path 3 2 1 does not exist, because you did not have the arrow from 2 to 1 in the job transition – this matrix, because this is 0. So, you do not have the arc from 2 to 1. Therefore, this path does not exist. So, anyway this is you cannot transition from 3 to 1 in two steps first time. First time, from 3 to… You cannot reach from 3 to 1 for the first time in two steps in two time periods. So, this is… So, this is definitely better way of computing f i j n.
So, now, once we know this, then let us talk about the mean first passage times. So, remember N i j we have denoted as the number of transitions that you require for going from i to j for the first time. So, then the mean first passage time will be expectation of the random variable N i j, which you will write as n varying from 1 to infinity and f i j n. And when you put i equal to j, then it will be M i i, which will be the mean recurrence time. And this we have said is equal to 1 by pi; 1 by pi i. So, the steady state probability of being in… So, this is a proportion of time being in state i over the long run. So, 1 by pi i would be the mean recurrence time. So, that will be the time required for reaching. On the average, this is a time that you will require for reaching from i to i for the first time.
Now, to compute M i j’s, you would need the first passage time distributions. So, you need to compute… You cannot apply this formula, because you have to then have all f i j n. So, again, we will look at a nicer way of computing mean recurrence time and mean first passage times.
(Refer Slide Time: 10:21)
 
So, as we said that, to compute m i j by the formula, where you need all f i j n up to infinity, this is not practical. So, let us now come out with another method for computing these first passage times. So, you see we will condition on the state at step 1. So, see what happens is if you are computing the mean first passage time, then either the transition from i to j takes in one step. So, then this is 1 into p i j; remember you are computing the expected value of f i j n. So, m i j – so, if it is one step, then probability of transitioning from i to j in one step, that is p i j. 
So, 1 into p i j. So, either we will transition from i to j in one step, and therefore, 1 into p i j or we go from i to k in the first step, since it has to be… Either we transition from i to j in one step or from i, I go to some other state. And then, from k, I will transition back to j. And so, then it will be… Once I do this, then the passage time becomes 1 plus m k j, because m k j is the mean time of going from k to j. And so, 1 plus, because one transition has already taken place. So, the mean time of transitioning from k to j for the first time will be 1 plus m k j and into the probability of transitioning from i to k, where k is not equal to j. So, this should be clear.
Now, we just rewrite this expression, because here you are summing with respect to k and k is not equal to j. So, p i j is missing, which is available from here. So, when you add up p i j plus sigma p i k, k not equal to j. So, this whole thing is the summing up the components of the i-th row of the first transition matrix. This must be equal to 1, because from i, you have to transition to one of the states. And therefore, this is 1 plus sigma m k j into p i k, k not equal to j. And we can rewrite this as summation p i k into m k j, where k is not equal to j. So, this is now again, as I said, the way we computed the formula for f i j n, this is also a simple way of computing m i j without really requiring to have the whole distribution for the first passage probabilities f i j n. So, these are n equations and n unknowns; that means, n unknowns means in the sense that, you are asking for this – m 2 j and so on, m n j. So, you are asking for a first transition passage to j from anyone of the states 1, 2 and n. So, these are n variables, because i is varying from 1 to n in n unknowns; n equations in n unknowns. Now… And similarly, we can also compute i i i; can also be obtained this way. So, the mean first recurrence times can be also obtained by solving corresponding set of equations here. And let us just work out the formula. This will be…
(Refer Slide Time: 13:54)
 
So, if you want to compute m 2 3, then m 2 3 will be 1 plus… And remember k is not equal to 3. So, k can take the value 1 and 2. So, it will be p 2 1 into m 1 3 plus p 2 2 into m 2 3. So, now, in order to compute m 2 3, I need m 1 3. So, I will write down the formula for m 1 3. So, m 1 3 will be… So, here again k is not equal to 3. So, this will be 1 plus p 1 1 m 1 3 plus p 1 2 into m 2 3; so, then two equations in two unknowns. And we can… Substituting the probabilities p 2 1, p 2 2, p 1 1 and p 1 2, I get these equations. And so, it is not difficult, because from here you immediately get like half m 2 3 is 1. So, m 2 3 is 2; immediately you get it from here. And then, once m 2 3 is 2, this is half. So, this is 3 by 2. And when you bring this to this side, let us see; m 2 3 is 2. So, this is 1 by 2. So, this is 1 by 2 and this is 3 by 2 and this you bring here. So, this will be half m 1 3 is equal to 3 by 2. Therefore, m 1 3 is 3; it is not just 3 by 2; m 1 3 is 3; yes, from here. You can again substitute and make sure. So, m 1 3 is 3; this is 3 by 2 and m 2 3 is 2. So, this is… What is the mistake? [FL] This is equal to 1 plus m 1 3 – we are saying is coming out. So, this is 3 by 2 plus [FL] and this is half. So, this is 2 plus 1 3. So, m 1 3. Therefore, that was the right solution. So, this is m 1 3 is 3. So, working out always helps you, because you can find out…
Now, similarly, let us just look at the way we compute m 1 1. So, the first mean recurrence time for going from state 1 to 1. And here again k cannot be equal to 1. So, it will be 1 plus p 1 2 m 2 1 plus p 1 3 m 3 1. And now, you need m 2 1 and m 3 1. So, three unknowns are there. Therefore, three equations: m 2 1 will be 1 plus… Again, k is not equal to 1. So, p 2 2 m 2 1 plus p 2 3 m 3 1. And then, finally, when you write it down for m 3 1, it will be 1 plus p 3 2 m 2 1 plus p 3 3 m 3. And so, substituting for probabilities, I get these equations. And again, in a very simple way, you can solve and you can check… Let us see m 1 1 comes out to be 5 by 2. And if you remember the calculations for pi 1, pi 1 was 2 by 5. So, the steady state probability of being in state 1 was 2 by 5. So, the mean of first passage time will be 5 by 2.
Now, m 2 1 comes out to be 4 and m 3 1 is 2. So, I hope this is a right calculation, because let us see if you want to do it here, just verify. See if m 2 1 is 4, then this side is 1 plus 2 and m 3 1 is 2. So, that is also 1. So, that is 4. This is coming out to be high, because remember there is no arc from 2 to 1; there is no direct arc from 2 to 1. So, you can of course, go from 2 to 3, then 3 to 1 for the first time, but… So, that is 2. But, then other paths when you go around, it will be... So, the mean first passage time is coming out to be 4 and m 3 1 is 2. So, now, we will see… Of course, see the thing is that, as I said when I have concluding the steady state probabilities and the mean first passage times, there are certain conditions under which these are valid. And so, we now have to look at the situations, where these things may not be valid. And in fact, I had said that, these may not even exist and so on. So, we will now start looking at… So, right now, under certain conditions, which we have to specify and we will do it soon. So, want to show you that, this will be true – all these ways of calculating the steady state probabilities and mean first passage time and mean recurrence times; you will be doing it under certain conditions; they are valid. And when they are not valid, then we have other quantities to define those states. So, we will talk about it.
(Refer Slide Time: 19:13)
 
So, let us just recall what has been done so far. See we said that, limit probability X n equal to j given that X naught is i is actually limit P X n equal to j. And then, we defined this as pi j. So, this was the tacit assumption that, this limit exists and that it is independent of the initial state. And therefore, we said that, you can solve these pi j’s through the system of linear equations. And that is what we did. But, this was under the assumption that, this limit exists. But, now, it is not really true that, this will always exist. And this is what we need to now talk about and find out. Therefore, that means the linear equation method of solving the pi i's depends on whether this limit exists. And we said that, this limit is also independent of the starting state. And therefore, we could write down the system of linear equations and say that, the solution exist under the condition that, sigma pi j is add up 1. Then therefore, things were simple, life was easy. Therefore, we will now look at the conditions under which this limit exists.
Second is that… And the recursive formula for f i j n that we wrote down – this formula is valid. Here we are not asking for any limits or anything, because the powers of p can be computed. And then, therefore, through that, you can recursively compute your first passage probabilities. So, that is valid. But, here… And m i j again – because remember I am saying that, the m i i will be equal to 1 upon pi i. So, there again the existence of pi i is assumed and even otherwise. So, the linear equations for solving the m i j’s also needs to examined under what conditions this method will be valid. So, let us start looking at examples and then we start talking about the conditions. So, first suppose… So, now, you again consider the job assignment problem and you see that, the matrix p 2 had got all entries positive.
(Refer Slide Time: 21:36)
 
In the first transition matrix, there were some zeros in the sense that, you were not able to go from 2 to 1 and you did not have a loop from 3 to 3. So, you had 0 entries. But, when you took the square of the matrix, then all entries became positive. And after that, P 3 was also… All entries were positive. So, this implies that, there is a path from… Remember because this is simply a transition probability in two steps from i to j. So, if it is positive; that means there is a path from each i to each j. And in such a case, when you have a path from i to j and then you have also have a path from j to i, because p i j 2 is positive and p j i 2 is also positive. 
Since all entries are positive, you have this; you have a path here again from j to i with positive probability; after such a pair of states is said to communicate with each other. So, they said to communicate. And if all states communicate with each other; and so, now, because p i j 2 is positive for all i j. So, we conclude that all states for the job assignment problem communicate with each other. And such a chain or such a Markov chain or process is called ergodic. And we will talk about this some more. But, first let me say that...
So, now, what we will say is that, we will define a closed set as a set of states, which communicate with each other. And for the job assignment problem, it turns out that, the closed set actually consists of all the states – 1, 2 and 3. But, it is possible that you may have more than two closed sets or three closed sets; whatever it is, all states may not form one closed set; that means all states may not communicate with each other. And now, let us look at this example here. See this is the transition diagram. So, you see that, 1, 2 and 3 – you can see that, they all communicate with each other; there is a path from 1 to 3, from 3 to 2, 3 to 1 and so on; and there is a path from 4 to 5 and 5 to 4. But, there is no path from 1, 2 and 3 to 4 and 5. And this you can… Of course, see the thing is that, I have drawn this diagram with five states; but, when the number of states is large, the transition diagram will be very big and it may not be again… Same problem as I was talking about earlier.
Let you know you cannot possibly enumerate all possible paths when you have a large number of states… So, the recourse is to taking higher powers of p. So, let us start. And of course, here it is evident that, these two... Therefore, the two closed sets are 1, 2 and 3 and 4 and 5. So, this chain is definitely not… All the states not form a closed set. And… So, let us see. Let us start with P – the transition matrix. So, you see there is no arc from 1 to 4 or 1 to 5. Similarly, there is no arc from 2 to 4, 2 to 5 and from 3 to this. And same way, there is no arc from 4 to 1, 4 to 2, 4 to 3 and 5 to 1, 5 to 2 and 5 to 3. There is no arc. So, this is the zeroes. And let us see when we take the second power; that means P square, then these zeroes remain intact. These probabilities change; these zeroes may… like this 0 goes away. But, this…
And then, again when you take P 3, these zeroes do not go away and here it becomes… Therefore, now, you can say that, among the states 1, 2 and 3 – the closed set 1, 2, 3, now, you have path from each node to the other two nodes, because these are all positive. So, they all communicate; that means you need at least three transition steps to see that, there is a path from each of the nodes 1 to 3 to the other two. And similarly, here this is of course, quite clear. So, this is also… All the probabilities are positive here. And therefore… And you see that, this structure will continue no matter what higher powers you take of P. You will continue to have zeroes here and zeroes here. Therefore, this is a situation, where all the states do not form a single closed set. And in fact, if you have more than one closed set, we call such a chain or a process reducible. And if all states form a closed set – one single closed set, then it will be irreducible. So, what we have been talking about so far has been irreducible chain; and irreducible means that, all states will communicate with each other. And therefore, it will also be ergodic. But, again even this classification is not enough; we need to do it further. And so, continue the discussion.
(Refer Slide Time: 26:53)
 
So, if a single state forms a class; that means there is only one state in a class. It is called absorbing, because obviously, the state is not communicating with any other states; it is just communicating with itself. So, then it is called absorbing; that is… So, once the system enters in an absorbing state, it will not come out of it. So, we will just look at the examples for all these – the kinds of states that we are talking about. Now, from the 5 by 5 matrix of the two closed sets, we just looked at this example in which you had two closed sets has formed by the states 1 2 3 and the states 4 and 5. Remember there was no communication between the states 4 and 5 and 1, 2 and 3, and vice versa. So, these were two closed sets. So, if you look at the submatrix – 3 by 3 submatrix; see because otherwise it is all zeroes; this is 3… It was 0 and 0, because there was no communication from 4 to 5.
(Refer Slide Time: 28:06)
 
So, in the submatrix, the entry 1 3 was by mistake written as 25 by 36; it should be 19 by 36, because all the rows – the elements of any row must add up for a transition matrix; must add up to 1. And so, with 19 by 36, the numbers 1 by 6 plus 11 by 36 plus 19 by 36 add up to 1. So, make that correction. And in P 3 also, the same correction has to be made, because this mistake got carried over from P 3, where it was by mistake written as 25 by 36 and not 19 by 36. So, you see that, the submatrix itself… 
Now, the case that, we were talking about that, the matrix P n in the limit will converge to where the rows are all identical – whatever these numbers states k 1. So, this was a pi 1 to pi k and so on. So, all rows were identical. Remember this is the case we had talked about. But, now, you see it has no meaning here, because the rows… These zeroes will remain forever. So, we cannot say that, the rows will become identical in the sense that… These three rows will become identical maybe you can say. But, then below here you have zeroes, because again 1, 2, 3, 4 and 5 are not communicating with 1 and 2 and 3. So, you will have zeroes here and then you will have some positive entries here. Therefore, you cannot say that, the rows will become identical.
These three rows will become identical; that is what I want to show you that, if you… This is P 3. So, P 3; this is 1 by 6, 5 by 24 and 1 by 8. So, supposedly, this number will go up a little and this number will also go up, because you need 6 by 24 is 1 by… So, you need 1 by 4. So, supposedly, you can see that, the numbers are close. Similarly, 11 by 36, 7 by 24 and 1 by 3. So, 1 by 3 is 8 by 24. Therefore, again the numbers are getting close. And similarly, here. So, you see… that means these three closed states – they themselves will satisfy the condition that, the steady state probabilities… You can compute the steady state probabilities; and here it will not matter in which the system started. But, to say that, all the rows of the 5 by 5 transition matrix will converge to the same values would not be valid.
Now, again this is a big example I have taken from Ravindran and Phillips and Solberg. And so, this is 8 by 8 transition matrix; and the diagram I have drawn on the other board. And see I have written down this matrix though I am not making use of it right now. But, it will be a good exercise for you people also to sit down and try to… If you can write it a small ((Refer Slide Time: 31:16)) I am sure from matlab and so on, if you feed this matrix, you can get a different powers of the matrix. So, it is not too much of a problem getting higher powers. And then, whatever I am saying, you can also conclude the same things by looking at higher powers of P.
(Refer Slide Time: 31:34)
 
But, in any case, if we draw the transition diagram, it will look something like this. And I am not writing down the probabilities, because they are here and anyway it will clutter up the diagram; we just need to look at the connections and whatever i am concluding from that is enough; I do not need the probabilities really, except that this P 6 6 is 1. So, fine. So, now, if you just glance at this transition diagram, then you will see that, 4, 5, 8 are connected; 3, 7 are connected; and you may say that, 2 and 6 are connected. But, then when you go further, you see that, there is no arc from 6 to 2. And when you reach 6, then the probability of coming back to 6 is 1. So, this is a certain event; so, that means once the system comes to state 6, it just stays there. And so, 6 is an absorbing state. And this is not a closed set, because closed set 2 and 6 should communicate, and 6 and 2 communicates. So, there is an arc from 2 to 6, but there is no arc from 6 to 2. So, this is not a closed set. Therefore, you have two closed sets, which are 4, 5, 8 and 3 and 7; that for sure, because you have an arc from 3 to 7 and 7 to 3.
Now, 1 and 2 do not figure. Therefore, this is not a closed set. So, states 1 and 2 do not figure in any of the closed sets. And such states we define as transient, because see what will happen is that… So, first of all, they are transient. And since you have more than one state – closed state in the system… Therefore, this is a reducible system. So, that is another thing. Now, thirdly, once the system enters a closed set. So, for example, it enters state 5 or 4, then you see it will keep hopping amongst these states only; there is no way of going out; there is no arc, which is going out of 4, 5 or 8. So, the system will then… For infinite number of times, go on hopping among the states 4, 5 and 8. And such states we will call as recurrent, because they will keep occurring again and again. So, the moment a system enters the closed set, then there is no way of going out, because if this communicated with any other states, then that will also form part of the… For example, if 4 communicated with 1, then this will become a closed set. So, that is not true. So, once you enter a closed set, you cannot get out of it.
And similarly, here if you come to 3, then you will go on going from 3 to 7 or 7 to 3; that is all. You will just go round and round. Or, because there is no loop here either, there is no loop here. So, you will continue doing it. And from here if you come to 2 and then you go to 6, then you just stay put in state 6; you do not get out of it. So, first of all, now, after defining the recurrent state from transient state and an absorbing state, you have the closed sets. What we want to say is that, each closed set if you look at, this itself behaves like now a reducible Markov chain. So, a subchain of the whole system, which is irreducible – ergodic in the sense that, if you just consider this. And similarly, if you consider the chain consisting of sets 3 and 7, then they together form a irreducible chain. And this is both of them – 3 and 7 communicate with each other. And so, talk about… Further classification is needed.
(Refer Slide Time: 35:31)
 
So, now, I will give you another classification of these states in terms of first passage probabilities. And that will also give you a good understanding. And of course, another alternate way of determining whether the state is recurrent or transient or whatever it is. So, now, let us define f i as the probability that, starting in state i, the process will sometimes return to state i for the first time, because f i i n was the probability that, it returns to state i from i for the first time in n steps – n transitions. So, now, when we add up this from 1 to infinity, this will give us the probability of the system returning to – starting from i returning to i for the first time in any number of steps. So, all possible. Therefore, this is will sometimes return to state i. So, that is important. So, this is a probability.
Now, we say that, state i is recurrent if f i is 1; so, that means there is a positive probability or it is a certain event that, the system will sometimes return to the state i from which it started. So, if f i is 1, then it is a certain event. But, if f i is less than 1, then it is a transient state. And the… So, now, you can interpret this as saying that, if f i is 1; that means the system will return. So, starting from i, it will return to itself after sometime. And then, because it is a Markov process, memory less; that means the past history is not to be considered; then, you will again… So, the whole process starts fresh; and then, you will again go to other states and so on, and then come back again to i. So, every time you come back, the system starts fresh. And since f i is 1; therefore, you will keep coming back to i infinite number of times. Therefore, the way to characterize this is recurrent state; that means is that, once you come to i, then you will keep coming back to i an infinite number of times. But, for a transient state, see what is happening is since f i is less than 1, 1 minus f i is positive. So, this is the probability that the system will not return to state i. And so, if this is a positive probability, then we will say that, this event will also occur. Therefore, how you want to interpret this saying that, a transient state will be visited only a finite number of times. And so, that will be the difference between a recurrent state and a transient state. So, let us just interpret this.
Now, you see if the system is in state i for exactly n periods; starting in i and exactly for n periods, visit the state i again for n periods – n times; then, the probability of that is f i raise to n minus 1, because f i is the probability of x returning to state i. So, that into n minus 1. And again, these are independent probabilities. So, that is why I am raising it to f i raise to n minus 1, because of the Markov process, the Markov property. And then, it does not come back to itself. So, for what… So, I am computing the probability that, exactly for n periods, it has visited state i starting from i; I mean this is I am writing down the conditional probability of starting in state i and then visiting it for exactly n times – being in state for n times. So, it has already started in state i. So, now, it needs to revisit state i n minus 1 times. So, this is the probability of revisiting state i n minus 1 – n times starting. And then, 1 minus f i is the probability that it will never come back after that.
Now, this is… And for n greater than or equal to 1, this is now… This has the probabilities from a geometric distribution if you recall. So, what we are saying is that, coming to itself is a failure and then not coming to itself is a success, remember. So, you are asking for the probability in n trials; you are asking for the… Here this is the… The best way to say it is that, this is not coming to itself. So, that happens once. And then, this is coming back to itself n minus n times. Or, coming back to itself – it is n minus 1, because it is starting in i, but it has been in state i for exactly n periods, that is… So, there are two different things I am saying. Therefore, here you are saying revisiting itself n minus 1 times. Therefore, f i raise to n minus 1. Now, when you want to compute the mean for this distribution, then it will be… that means n now varies from 1 to infinity and you compute the mean. And it will be n times 1 minus f i into f i raise to n minus 1.
(Refer Slide Time: 40:52)
 
And, here we can take 1 minus f i outside. So, sigma n f i n minus 1. And this is a geometric distribution; f i is less than 1. So, this is convergent; and this is an arithmetico-geometric series. And you should all know how to evaluate it; we have done it right in the beginning of this course. And so, the sum is 1 upon 1 minus f i whole square; and so, multiplied by 1 minus f i. So, this is this. So, there is a finite; this is the finite positive number; that means the average of a… You see if it was to visit itself, infinite number of times, the mean will not be finite. But, here it is the mean is finite; so, that means, you can again interpret this as saying that, the state will not be revisited infinite number times; only a finite number of times it will be revisited.
Now, another way of characterizing a recurrent state; so, you see that, we have been trying to talk about the same thing in different ways. And that certainly helps you to understand other things better. So, now, let us say define I n as 1 if X n is i; that means if the n-th time the system is in state i and 0 otherwise. So, this is an indicator variable. And then, if you add up sigma i n from and to infinity, this will represent the number of periods that the process was in state i. So, starting from time period 0 – the initial time, then this will count the number of times the system was occupying state i. And now, if you want to compute this conditional expectation, that is, given X naught is I; you want to compute sigma I n, n varying from 0 to infinity – the expectation. So, I will exchange this summation sign; that means if this thing is finite; that means if this exists, then obviously, I can exchange the expectation. So, this is also convergent; that is all I need to interchange. Therefore, this is expected value of I n given X naught is i, which… But, I n is equal to 1 if X n is i. Therefore, this is probability X n equal to i into 1 when you… Conditional probability of X n given, i given that X naught is i. So, 1 times; that you will write down.
And, this by our definition, is P i i raise to n. Therefore, summation n varying from 0 to infinity P i i n. So, you want to say that, sigma I n, n varying from 0 to infinity represents the number of periods that the process is in state i. So, now, if… So, once you have computed this, then a proposition immediately follows. A proposition says that, if state i is recurrent, that is, state i is recurrent if this is infinity, because this is the expected value. And if the definition is that, the recurrent state will keep revisiting itself infinite number of times; then, the expected value will also be infinite.
(Refer Slide Time: 44:18)
 
Therefore, this will be infinity. And for transient, this has to be less than infinity; so, another way of looking at it. Now, see interesting outcome from here is that, if the number of states is finite; see that is important, is finite. So, the number of states is finite; then, all states of the process cannot be transient – all states cannot be transient. And why? Because if a transient state can be visited only a finite number of times and you have finite states; let us say the number of states are 1, 2 and k; you have k states. Now, this is a… If all are transient; so, this can only be visited let us say T 1 number of times; this can be visited only T 2 number of times, and this can be revisited only T k number of times. And now, you take max of T 1, T 2 and T k; take the maximum of this; define this as capital T. And then, now, when you consider the time T plus 1, T plus 2, what happens? Because all the transient states have already been visited; you cannot revisit, the process has to go on; the process has to be in some state at time T plus 1, T plus 2. So, this is a contradiction, because if you have only finite number of states and all are transient, they will all get visited the finite number of times.
And after that, beyond that time period, the process is going on. So, where does it go? It has to transit to one of the states. Therefore, in a finite process, a finite process we mean finite number of states – all states cannot be transient. Therefore, immediately, the question is asked. If the number of states is not finite, then is this possible that, all states may be transient and yes. So, we will also look at an example. And we have already done, looked at such a process, but we did not really talk about this aspect of the process at that time. So, yes, if there are number of states are infinite, then all the states maybe transient.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 29
Random walk Periodic and Null States

So, in the last lecture I had told you that it is a number of states are finite of Markov process and then all states cannot be transient, right. We had argue rate out that if the system has to go on then because transient states will be visited only a finite number of times. If they are finite number of states, then the process must come to an end in a finite number of times, but since the process has to go on, therefore if the number of states is finite, then all states cannot be transient, but the argument does not hold when the number of states is in finite. So, I said I will give you an example. When the numbers of states are in finite, it is possible that all states of this process may be transient, right.
(Refer Slide Time: 01:04)
 
This is what we want to talk about today, so giving you an example when all the states are transient. Now, random walk is very interesting and important process and I hope that after having you know read about, now you will be able to recognize situation processes, stochastic processes which follow behavior of it random walk. So, this now a Markov chain when the states space consist of the integers i mean varying from contain the value 0 plus minus 1 plus minus 2, and so on. So, that means, I am numbering the states by minus 1 plus 1 plus 2 minus 2 0, and so on. And so this can go on for a infinite number. The number of states is not finite. This is infinite states situation and then, the transition probabilities. So, if you go forward; that means, if you transition from state i to i plus 1, the probabilities is p and if your transition from i to i minus 1, then that means, if you go backwards, the probabilities is 1 minus p, and this is i varying from 0 to plus minus 1 plus.
So, therefore, the probabilities remain the same sensually. It is going forward. The probabilities is p and if you are going backward, then the probabilities is 1 minus p for some, any p varying between 0 and 1. So, therefore, for different values of p you will get different random walks. This is the idea and diagrammatically if you look at the transition diagram, the transition diagram simply says that. So, these forward probabilities are p and the backward probabilities are 1 minus p. So, from minus 1, you can go forward and then, it will go to state and from 0 if you go backward, you will go transition to this state minus 1 and the corresponding 1 minus p and therefore, this process go on either side. So, this is your transition diagram.
So, you see that from here that all states communicate because you can go anywhere by forward movements. If you go from minus 1 to 2, you can go here and then, you can again come here. So, any possible path is there, but you can transition from any state to any state. So, all states communicate, ok. So, therefore, either all states will be recurrent or all states will be transient because remember the recurrent states will form a class. So, if they form a class, then within a class, all states must communicate with each other. Since, it is already true that all the states communicate. Therefore, all the states will either be, so they are all in one class. So, they will either be recurrent or transient, ok.
So, here again remember I had defined for you recurrent state via the probabilities of first passage, first passage probabilities and remember we had said that if f i is equal to 1, then the state is a recurrent state because then there is positive. There is the event that it will recur back to itself is a certain event, right and if f i is less than 1, then we had said that the state is a transient state. And then, using an alternate characterization of a recurrent transient state, we had also said that if from here we had said that if p i summation, this will be summation p i i n n varying from 1 to infinity. If this goes to infinity, then the state is recurrent and this is less than infinity. Then, this state i is transient. So, this was another characterization. So, that is what we will use here.
Since, all states are behaving as exactly the same way because the probabilities are the same of going forward or backward. So, it is enough if we consider sigma n varying from 1 to infinity p 0 0 n. So, let me just look at the behavior of this expression and if I can show that this will be diversion series, then that means, it will go to infinity. Then, I can conclude that state 0 is recurrent and since, they are all the states from one single class, therefore every state is recurrent and if sigma n varying from 1 to infinity p 0 0 n is less than infinity, then 0 is a transient state which implies that all states are transient.
So, let us now start looking at this expression. For example, if you look at p 0 0 n, then that means, this is wanting to know that 0, you starting from 0, you will be back in 0 in a n steps. So, since you can see from here, from the red diagram that you can return back to 0 only in even number of steps, in even number of transition, right. If I go here, then I can come back here. So, 2 if I go from here and here and then, I need another two steps backwards, right or if I go from here, then I go back here and then, in fact you can have any possible number of forwards and backwards, but they should. So, if the number of transition if my n is odd, then I cannot comeback from 0 if I start from 0, right.
So, coming back to itself requires even number of states and you can just try to draw number of paths, and you can see that you can go from here, here, then here, then you can come back here and again here and then, here. So, all possible ways are thereof, but then you will require every time even number of steps.
(Refer Slide Time: 07:13)
 
So, therefore, if you look at p 0 0 2 n minus 1, then this will always be 0, all right. You cannot transition to back to the state starting from 0. You cannot comeback to 0 if odd number of steps. So, those probabilities are 0 and for coming back, you need even number of steps. Then, you require exactly n forward transition and backward transition in any order right as I try to explain from the diagram. So, this will be equal to, therefore from 2 n you chose n forward steps, forward transition and n backward transition. So, therefore, the probabilities p 0 0 2 n will be like this, all right. Choose n from 2 n transition and then, p transition forward and 1 and 1, sorry n transition forward and n transition backward. So, probabilities of backward are 1 minus p, probabilities of forward transition is p and this is 1 minus p.
Now, let us just open up the expression here. So, this is 2 n factorial n factorial n factorial p raise to n 1 minus p raise to n. I will now use Sterling’s approximation which I have already talked about in earlier lectures. So, factorial can be approximated by Sterling’s formula and so, this will be 2 n raise to 2 n plus half e raise to minus 2 n and then, under root, we left out the part p raise to n and 1 minus p raise to n. So, this is and therefore, similarly n factorial can also be written by Sterling’s approximation formula. So, n raise to n plus half e raise to minus n and then, there will be 2 root 2 pi. So, root 2 pi for both of them. So, therefore, it will be 2 pi and raise to plus half e raise to minus n and now, we can cross out few things. This and this gets canceled out and then, you can two raise to half. We can cancel out from here and then, I will be left with root 2 pi, yeah and oh this is root [FL].
So, root 2 pi was there because this is root 2 pi and this is 2 pi. So, root 2 pi was left and then, that root 2 gets canceled by this root 2 here and then, you can just see this simplification here and this is n raise to half. So, here this is n raise to 2 n. That cancels out with this, right and then, there is n here and there is n half. So, you are left with the root n. So, this is root n root pi and then, you have 2 raise to 2 n which I bring inside here. So, this is again 4 into p 1 minus p raise to n. So, this is the simplification, right after using Sterling’s approximation for the factorials I get.
(Refer Slide Time: 10:17)
 
So, we saw that this series can be written approximated by the series and varying from 1 to infinity 4 p 1 minus p raise to n upon root pi n. Now, the terms I can breakup as sum of even terms and odd terms and here, even though I have written the index is n does not matter. So, dummy index. So, here it could have been m also, but the idea is that I am breaking up. I am writing p 0 0 n. Instead of this, I am writing the odd. I am adding up the odd terms and the even terms.
Now, the odd terms do not contribute anything to this sum. So, it is only the even part and so now, let us consider the case when p is equal to 1 by 2. So, in that case, this will become equal to 1, right. So, this series will reduce to summation and varying from 1 to infinity 1 root by n which we know is a diversion series because the power root by of course is constant. So, this will be n raise to half 1 upon n raise to half and we know that this series 1 upon n raise to p n varying from 1 to infinity is diversion for all values of p less than or equal to 1. This we already know.
So, therefore, this is a diversion series and therefore, since all the state, we will immediately conclude that all the states are recurrent because the time to return to this is infinity. So, all states are that mean sigma n varying from 1 to infinity p 0 0 n. So, this is recurrent and therefore, all other states are also recurrent, ok. Now, we have to consider the case when p is not equal to half.
(Refer Slide Time: 12:01)
 
So, for p not equal to half, your 4 p into 1 minus p will be less than 1, remember because for p equal to half this, the maximum this as the maximum value for this term for you p into 1 minus p is for p equal to half. So, for p less than half, it will be less than 1, right. So, let me call this term as alpha. Let me denote it by alpha. Then, we will show that this series converges and simple. You just apply the ratio test. So, take the n plus 1 term divided by the nth term which will be you know the n plus yth term will be 4 p into 1 minus p raise to n plus 1 under root pi into n plus 1 and here you dividing by the n th term which is this. So, you have this.
So, here you see you are left with 4 p into 1 minus p and then, this root n i bring in the denominator. So, this will be 1 plus 1 by n raise to half and therefore, the limit of this ratio of the n plus 1th term and the nth term as n goes to infinity will be you see, this will go to 1. And therefore, it will just converse to 4 p into 1 minus p which is a number equal to alpha less than 1, whatever the value of p. Since, p is not equal to half, this number is will be equal to something less than 1, all right and yeah, so in that case we will conclude that all states are transient states.
(Refer Slide Time: 13:28)
 
Now, of course, I had told you that you can look up for whenever now that you know this random process which backward forward and of course, for the transient case, the probabilities of going forward is different from going backwards and for recurrent states, it was both the probabilities are the same.
So, now just on the lighter side, we know you can say that if there is a drunken man and he is trying to walk on along a straight line, then he will takes step forward. Then, he will take two steps backwards or he may take two steps forward and one step backward or something like this. So, you know the wonderings of a drunken man. You can sort of say that the process of the walking of a drunken man can be modeled as a random walk and of course, it will depend on the p. Then, value of p will depend on how drunk he is or something like that, ok. So, that is one of the examples. Then, we may be we will come across some more in the process of this or otherwise, you can you know now be aware of such a process, ok.
Then, we will continue with the classification on the states and after the transient states, they are also states which are periodic and null states which are both of which are not of much practical use and of course, there occurrence is also not that often. So, now, you see we have talked as we said that the recurrent state, it is possible that recurrence state may have infinite mean recurrence time that is mathematically, this sum may not converge and remember for recurrence states even you wanted to find out the first passage time and so on. We did it by finding the mean recurrence time, the m i j s and m i i and so, when we did this, then we assume that this is finite; this series will converge, but it is possible mathematically that this series may not converge even though the series, this of course, this is your condition for state to be recurrent that is sigma f i i and n varying from 1 to infinity which is equal to sigma which is equal to f i. That is the recurrence time probabilities of the state coming back to itself. Then, this is equal to 1.
So, for recurrent state, these probabilities have to be 1 because coming back to a recurrence state is a certain event. So, this series converges, but this series may not converge which is your mean recurrence time and this is such a state, we will define as a null state, ok. So, not much is talked about it. So, we will also not spend much, but we must complete the presentation of the states of the classification of the various states. So, for the recurrence states where we assume that this is finite, because then we were solving for m I j s or m I i s, but there is possibility that this series may not converge, ok and this as I have already said these are a frail practical use and the probabilities of being in null state will also go to 0. So, therefore, we will not talk about such states, we will not spend much time on it, but just to complete the discussion, we have also considered the case when this may not converge. So, this may not be finite.
(Refer Slide Time: 17:19)
 
Now, let us talk about periodic states. So, consider the following transition may tricks and this is the corresponding transition diagram, and you can see immediately from here that from 1 you will either go to 3 or 2, 4 right and also from 2, you will go to 3 and to 4 and then, again from 3, you may go to 1 or you may go to 2 and from 4, you may go to 1 and from 4, you may go to 2. So, that means, there are two classes. You can immediately see because there is no communication between the states here, between among the states and states here, all right. So, it is you can just I should not say classes exactly because these two are not communicating, but they are communicating to the. So, you have communication between the states of this set and this set and vice versa, all right.
So, your system will alternate. That means at any time, either the system will be occupying states 1 and 2 or it will occupying 3 or 4, right because once if you start in 1, then you will either be in 3 or 4 and then, if you are in 3, then you will either be in 2 or back to 1, all right. So, you either communicate this way or you communicate this way. So, your system alternates between these two classes and that you can see by these probabilities also, ok.
Now, in fact, you can see from here that suppose from 1 I go to 3, then I can come back to this. So, that will be in two transitions. I can come back from 1 to itself or I can go from 1 to 3, then I can go from 3 to 2 and then, 2 to 4 and then, 4 to 1. So, that means, it will be then in case it will be four transitions that will be required to go from to start from 1 and come back to 1, right or look at the other thing. If you may go to from 1, you may go to 4 and then, again you can come back. So, again it will be two transitions, but if from 1 you go to 4 and then, you go to 2, then you will go to 2 to 3 and then, 3 to 1.
So, that means, you can recur back to state 1, either in two transitions for in four transitions and the same story true for state two. That means, from 2 you can come back to itself, either in two transitions or in four and the same again. What? It is three and four, right. From 3 you may go to 2 and then, come back, right or you may go to 2 and then, you may go to 4, then 4 to 1 and 1 to 3. So, all the states can be visited, re-visited either in two transitions or four transitions. Revisited I mean starting from that state, you will revisit either in two transitions or in or four transitions, right. So, you can see there is a periodicity. So, let us make a definition. So, we will say that a state which occur at time periods m2, m3 m and so on and m is sum integer greater than 1. This is called a periodic state of period m, right.
So, therefore, using this definition you can say that all the states of this particular chain are periodic of period 2, all right. A state for which no such m greater than 1 exist is called a periodic. So, here of course, the understanding is that it will actually the word should have been a state which can occur a times period m 2 m. So, that means, if you are starting from that particular state and then, it occurs again at period m2 m3 m, and then the period is m. So, that part is understood here, right that you are starting from a particular state and then, if you can visit it at regular intervals of periods m, m, some integer which is greater than 1, then that state will be periodic.
So, in this case of course what is happening is that all the states are periodic. So, this is one particular example, but of course you can have situation where you may have some recurrence states. So, these are also recurrent, but not in that sense. See here yeah. So, we will just see that there will be no this thing. There will be you can say that this series, in fact the periodic state you already know that you are going to visit it at a particular time. The probabilities of visiting it at regular intervals are there. It is positive probabilities.
(Refer Slide Time: 22:14)
 
So, for periodic states we said that the coming back number of transition has to be a factor of some integer greater than 1. That means m 2 m 3 m and so on. Then, we will say that it is periodic state of period m. Now, of course, on the transition diagram if you can see that all walks starting from walks or paths, whatever we have been saying starting from i and returning to i are of length m 2 m and so on, where m is greater than 1. Then, i is a periodic state and the period is m, right. So, for example that we just considered, I showed you that any state you start from either 1 or 2 or 3 or 4, you can come back to them in either two transitions or four transitions or six transitions and so, we concluded that the period for each of the state was m, right.
Now, if you can find a walk of length one, that means, if there is a loop for a state that means, you can come back to it one step or if you can find two walks which have relatively prime lengths. That means, one step one walk may be of length m 1 and the other may be of m 2, and they are relatively prime. They have nothing in common. Then, you can conclude immediately that the state is not periodic. That means, it is periodic, right because if 2 there can be in two parts of length that is starting from that state and coming back to it, either in m 1 transition or m 2 transition and these are relative. Then, certainly there cannot be anything common. So, there cannot be a period to that state, right or if there is a loop, then certainly it is not periodic state, right. That is another way.
So, we are just trying to look at various ways in which you can characterize a periodic state and then, again if it turns out that your mth power, that means, the p m transition matrix raise to power m. If this is greater than zero, that means, all components are all entries of this matrix are positive from some m, then no.
(Refer Slide Time: 24:17)
 
So, actually it is not difficult to show that if you are p m s or components of the matrix p m are positive for some m, then it can be easily shown that your matrix p m plus 1 will also be positive. That means all entries of the matrix p m plus 1 will be positive and this you can see immediately from here. See p m plus 1 can be written as p into p m. Let alpha denote the minimum of p I j m greater than 0 and then, we are saying because for every element of p m is positive. So, take the smallest and that smallest one, I am denoting by alpha and that will be positive, all right.
Now, consider the Ijth element of pm plus 1. So, that will be ith rho of p multiplied by the jth column of pm, right and so this is p i into p j m, right. Now, you see that when you multiply the ith rho with the jth column and replace each entry of the jth column by alpha because all other elements are bigger, right. So, I am writing the small as possible number for each of the entrees of the jth column. So, it will be p i 1 plus p i 2 plus p i n times alpha because since the rho’s add up to 1, so this will be equal to alpha. So, therefore, the i j th entry of p i j of the matrix p m plus 1 is greater than equal to alpha which is also positive and this holds for any element i j of p m plus 1.
So, therefore, matrix p m plus 1 is also positive. Now, since all the entries of pm are positive. So, it seems that pick up any one, then p i i m is positive. That means, there is a path of length m from state i to i and since, p m plus 1 is also positive, matrix p i i m plus 1 is also positive which implies that there is a path of length m plus 1 from i to i. Now, by a definition you see m and m plus 1 for any m integer, positive integer, there are c prime numbers. So, we have shown that there are two paths from i to i of co-prime lengths and hence, by our definition, the state I cannot be periodic. It will by a definition, it will be periodic. So, n says this is true for all i. Therefore, no state is periodic. So, the proof was simple. I asked you to do it on your own, but I realized that we can show it right here and figure it out. Think about it.
(Refer Slide Time: 27:10)
 
Now, of course, periodicity is a class property as we have shown. That means, you will have just as we defined that all states in that class would be periodic and having the same period, right. So, we can put together all states which are periodic of the same period, right.
Now, consider this example that we looked at the transition diagram for four states, and we saw that everything I did not write down. I think the probabilities or let us not so let us see given that matrix p. Then, you have p square. If you now multiply p with itself, then you get this matrix, right. So, your p was if we just wrote down in the last we said that 1 is going to 3 or 4. So, there were numbers here 1 by 3, 2 by 3 and so on and you had positive numbers and you had positive numbers here. These were zeros and then, when you take p square, the numbers, non-zero numbers shift here and the non-zero number from here shift here, right and each entry becomes half, right. Then, p 3 when you now take p 3 that is you multiply p 2 with that transition matrix p and then, you will get these entries will shift here and these entries will shift here. So, this is how.
(Refer Slide Time: 28:50)
 
So, I just want to go through powers of a transition matrix. I am just trying to show you what is happening and then finally, when you take p4, the half will again shift here, ok equal to p square which you would expect because every state of system had period two. So, therefore, after two iterations of two transitions, this will be the transition matrix will be the same. So, p 2 will be p 4 will be equal to p 6 and so on, all right.
Similarly, p 5 will be equal to p 3 and this is equal to p 3. This will not be equal to p. That is true. So, p 5 will be p 3 and then, all other powers will, all odd powers will continue to be the same because then you see p 3 tells you probabilities of going from 1 to 3 in three steps. That is what will happen, right. It will come back to itself and then, go back. So, from here it can go to 3 and 4 and again in three steps. So, either it happens you see you had 1 here and then, you have 3, right and you had 4. So, if come to 3 in one step and then, 3 you cannot go back to it. You cannot come back to from 1 to 3. You want to comeback in three steps. So, you will either go here or you will go here, right to 2, right and then, you may come back to 2, 3.
So, it will take three steps to come from 1 to 3. So, starting from 1 if I want to come back to 3, then you will have to require three steps because in two steps, you can either starting from 1, you can either come back to 1 or 2. So, therefore, you will need odd number of steps to go from 1 to 3 or to 4. So, either in one step or in three steps, five steps and so on because even transition are reserved for coming back either to these things. So, that means, within a class and that is why we said that this and this of course, they all had the same period, but here what we are saying is that you can go from 1 to 3 and then, 3 to back or 1 to 4 and 4 to 1 and so on, ok.
So, this is what is happening and so, you see that p i i n. So, if you see here the first matrix, your p i i, so 1 1 1 was 0. Now, it is half and then, again in p 3, this number is 0 and similarly, all these numbers are 0 and all these numbers here in p 2 are half, right and then, in p 4 again, they are half and in p 5 when you again look at it, all the numbers, all these p i i will be 0. So, this limit does not exist, right. So, limit p i i n n going infinity does not exist. It actually oscillates between 0 and half. So, therefore, this is for the first condition for this series will also not converge. If you want to take this summation, but anyway these are not the first step transition probabilities. So, all we are saying here is that limit p i n as n goes to infinity does not exist this limit.
So, this summation will also not exist. This is not convergence series p i i n n varying from 1 to infinity, but will not be a conversion because the necessary condition for this series to converge is that the lth term must go to 0 as n goes to infinity. So, here either limit does not exist. So, therefore, I cannot say anything about this series also, ok. So, now after having looked at all possible states of Markov process, the conclusion is that you know if the process is erotic, then of course, finite number of states, then the study state probabilities can be found by solving system of linear equations as we saw, right. By solving this matrix equations pi equal pi p and sigma pi i i varying 1 to n is 1 with this condition because otherwise the solution here is not unique. So, we saw that when you put this condition, you will be getting unique solution if your system is erotic, that is finite of number of states and all states are recurring, ok.
So, therefore, the system does not contain any transient periodic or null state. So, this was one convenient way, but then we saw that there were other states also. So, for transient and null states probabilities of being in that state is 0 and of course, periodic state also do not possess steady state probabilities, all right. So, when the state possesses as study state probabilities, then we saw we can solve it by this linear equation adding this equation to it, but otherwise periodic as we have seen do not possess steady state probabilities for transient and null states, the probabilities of being in that state goes to 0 as the process continues for a longtime. So, we have finally sort of completed this argument and said that when you know that the system is erotic and so on, then you can solve prostate, the state probabilities using system of linear equations. We have methods how to classify and how to decide that the state is periodic and it is null or transient, ok.
Now, the thing is that periodic and null states are not much of practical use and they do not or there occurrence is rare. So, we will not talk about them, but transient state you know transient processes are there. That means there are lots of practical situations where the process does not continue for a long time. So, therefore, we call them to reduce Markov processes and so, there transient in the sense that after a while the process comes to an end. So, we would look at in more detail because there are situations where your processes are not supposed to continue for forever. So, we will define them as reduces Markov processes and we will talk.
(Refer Slide Time: 35:12)
 
So, reducible Markov chains, one or more absorbing state and number of transient states, right because we are saying that the process will not go on. It will terminate after a short period of time. So, therefore, there will be either one or more absorbing states and remaining will be transient states. So, again by our discussion, we have seen that once you reach an absorbing state, you will not go out of that states. So, the process will terminate or if you are in a transient state and the numbers of states are, then the number states are finite. Then, again after a finite period of time, the process will be over.
So, this is what we are talking about. So, the interesting example and that is the gamblers ruin problem. Now, the idea is that the gambler at each play of the game has probabilities p of winning 1 rupee and probabilities q of losing 1 rupee. So, there is a game. Why I will tell you? Why it is called gamblers ruin problem? So, now, successive plays of the game, yeah it should be plays of the game are independent. So, successive plays are independent. That means, whatever the outcome of one play, the game goes on independent of what has happened and the gambler will quit playing when he wins rupees n.
So, he wants to make a fortune of rupees n. He is hoping for that. So, he will quit the moment he has earned n rupees. So, we want to find out the probabilities that starting with rupees, I suppose he has this much money with him. The gamblers fortune will reach rupees n before reaching 0, and that is what being by the ruin because if he allows the process to go on, then he will ultimately loose all the money and that will be the end of his playing gambling because then he cannot bet anymore.
So, let us look at the transition diagram. So, here what we are saying is that see with 0, he cannot play because he has no money to bet. So, he stays here, otherwise if he has rupee 1, then he can either loose that rupee and come back to state 0 or he will win and he will go to with probabilities p and then, he will go to 2. That means he will have 2 rupees. So, the state is described by the amount of money he has, and that is how we are using these integers to describe the situation, right and then of course, again if he has 2 rupees, he bets and he loses that rupee. Then, he will again revert back to having rupee 1 and so that will be the state.
So, this is the diagram and finally, at n minus 1 when he has n minus, 1 rupee, he will bet again and if he wins, he will get n rupees. He will make his fortune. So, we want to compute that and of course, what we are saying is that he will stop playing. So, there was no one going back from here because he will just quit the game, right.
So, this is the whole idea. So, this is now if you look at it, this is you know the duration of the processes is finite. And you can see that this is an absorbing state and you may call this as an absorbing state, and all other state are transient, because the moment he has some money with him, he will bet and then he will either convey, he will either go back to 0. For example, here he will whether win and he will go to transient to this transition to this state or he loses and then, he transition here. So, again this is an observing state and he loses. He just looses all the money. Therefore, the game is over. So, this is what we want to talk about and I will show the end of course. The whole idea is to compute the probabilities that starting with rupees i, the gamblers fortune will reach rupees n and you can say that here of course.
So, the process here you can immediately see that this is the Markov process because your transition and it just depends on where you are. So, your transitioning to the next state just depends on where you are and it does not matter how you reached one, or how you reached two. It just shows. We can immediately conclude that this is the Markov process and this is a short period duration. That means, it will terminate if the gambler ends up with rupees n, otherwise of course or if he just loses everything and he is back here. So, starting with rupees i, you want to find out the probabilities that the gambler will reach the fortune that we want to make.
So, the gamblers ruin problem. I have to put as an exercise. In exercise 10, which I will be discussing after some time. So, I have after explaining the problem, I have now left it to work out the details and let us hope that you enjoy doing it, and you are able to compute the probabilities, but while discussing the exercise, I will also give some hints and try to show how to go about it.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 30
Reducible Markov Chains

(Refer Slide Time: 00:17)
 
So, I will continue the discussion with the transient and absorbing probabilities. That is your reducible Markov chains. Now here for example, look at this transition diagram. So, there are four steps. And you see that from 1, you can either come back to 1 or go to 3. But then 3, once you reach 3, then probability of returning to itself is 1. So, therefore this is a certain event. So, once the process from 1 goes to 3, the process will stop there.
Similarly from 1 it can go to 2 and then from 2, if it transitions finally to 4 and 4 is the absorbing state. And so your process will again stop here. And similarly 2; so you can see that from 2 also you can go to 1 and 3 or 2 to itself and then 2 to 4. So, 1 and 2, no, I am sorry, 1 and 2. This should be 1 and 2 are transient and 3 and 4 are absorbing. That you can immediately see just by, you know looking at the transition diagram at once. 
And of course, you can see that over a short period 1 and 2 will be visited, because they are transient. And so for a while, the process may go from 1 to 1 itself or from 1 to 2, then 2 to 1. That may go on for a while or 2 to 2, but then the moment, the process transitions to either 3 or 4, it stops. So, therefore over a short period of time 1 and 2 will be visited. But ultimately the process will either enter state 3 or 4; and then stay there. So, the process will end. 
 And, so now using this, I want to talk about absorbing probabilities. So for example, the questions that arise; so I have just; I have written the first question. Even though this is plural, we will talk about other questions after this. So, which absorbing state will be entered? Of course, here again we will only talk in terms of probabilities; which absorbing state or what is the probability.
Now, just to point out the difference between the absorbing probabilities and the steady-state probabilities, you see, now just look at this example. So, what I am saying is that we will answer this question by computing absorbing probabilities. And, so before I start talking about the method for computing the absorbing probabilities, let me just give you a feeling what we are talking about. See, here if you are in state 1, then the probability of transitioning to 3 seems higher than transitioning to 4; because, well, you might say that the one. If it happens in one step, then this probability is half or then it can happen that, you know, you can go to itself and then transition. So, that will be also. Then, that will be; so this will be half plus half into 1 by 4. 
So, let us just compute this in two steps. And then if you; so transitioning, if you start in 1, then transitioning to t 3; let say in two steps. So, half plus half into 1 by 4, but if you are in 2, so computing the transitioning; so if you are transitioning from 2 to 3, then we cannot do it in one step. So, the two step transition probability will be; so the path will be from 2 to 1 and 1 to 3. And so this would be 2 to 1 is 1 by 3 and 1 to 3 is half. So, 1 by 3 into half will be 1 by 6. 
So, this is the probability. Two step transition probability of going from 2 to 3. Fine. I mean, again the example that I am trying to take is, and so half plus half into 1 by 4 would be how much? This will be 1 by 2 plus 1 by 8 which comes out to be 5 by 8. You are connected to 3 from 1 directly.
So, this is what we are trying to bring out through the computation of the absorbing probabilities. That it looks like that transitioning from 1 to 3; the probability would be higher, if you are in state 1. And if you are in state 2, then the probability should come out to be lower than that. So, in other words what we are trying to make a case for is that the absorbing probabilities are not independent of the starting probabilities; that means the starting states. Whereas, the steady-state probabilities we saw. So, unlike steady-state probabilities Ergodic process, the absorbing probabilities depend on the starting states. See, steady-states were independent of where the system started. And therefore, we would compute, you know, simply pi equal to pi P. And, it did not matter where the system was; because remember all the rows of the matrix became identical. But in the absorbing probabilities, it will depend on where you are starting and this is what we want to make sure. 
Like, this will; now we will ultimately, when we compute the probabilities, we will show that the absorbing probabilities when you are in state 1 to 3 is higher than when you are in state 2. And similarly for 4; it will be higher when you are in 2 and then when you are in 1. So, we will show because here we will have to then let us say, I take three steps, four steps, four transitions, then I can show you that the numbers. Here when you are in state 1, transitioning to 3 will have a higher value than transitioning from 2 to 3. So, let us see. It will come out.
(Refer Slide Time: 06:26)
  
So, let me make these definitions. a i j is the probability of reaching the absorbing state j from state i; where i is a transient state. You want to compute this. Now, of course one way is that you can use the first passage probability. So, f i j; that means, over the first time you are transitioning from i to j in n steps and then you sum it this up from n equal to 1 to infinity. Now, this is not computationally efficient. Right; because we will have to compute all the higher powers of the transition matrix and then we want to compute the f i j n s. So, an alternate method. And, this should look familiar because we have already used this kind of argument.
So, now what we are saying is that if you want to compute a i j, then the transition either takes place in one step. That means, in that case the probability is p i j. So, this is the probability of transitioning from the transient state i to the absorbing state j. So, then this is p i j plus or i transition from i to another transient state k. So, that probability will be p i k. And then a k j will be ultimately transitioning from the transient state k to the absorbing state j. So, this will be; this number with this probability and this is the probability of transitioning in one step from i to j. So, this is the argument. 
Now, a complete set of linearly independent equations will be obtained, if the same argument will be applied to each transient state. So that means, here I have done it for i. So, whatever the number of transient states, from each of them I will try to find out this probability of transitioning to the absorbing state j. And then I will have a complete set of linearly independent equations and we will then solve for the a i j s and then we will get the... So, we will be able to answer the question that which absorbing state will be entered. In the sense that you will say that a particular absorbing state will be entered with this much probability starting from the states. This is the way we will be able to answer that question. 
So, now let us just take the transition diagram. So, we are considering this process. And, if you write out the equations, when you see from one transition state 1, you want to go to absorbing state 3. Then, if you write out these equations, it will be p 1 3. Either, you do it in one step or you go to the transient state two; p 1 2 and then a 2 3. Or, you come back and follow the loop p 1 1 into a 1 3. So, this is your equation when you want to write down for a 1 3. Similarly, you can write it down for a 2 3. So, this will be p 2 3 plus p 2 2 a 2 3. From 2, you can either transition to 3 in one step. p 2 3; p 2 3 in our case will be 0. Or, then you will have to go from 2 to 2 loop and again a 2 3. There will be a 2 3. So, you come back to itself and then a 2 3; the probability of transition from 2 to 3. Then or you go from 2 to 1 and then you go to from 1 to 3. So, these are the two equations.
Now if you substitute for the p i j s, we obtain these two equations. And, you can see that here the variables are a 1 3 and a 2 3, right, because this is 0 as I said. p 2 3, there is no arc from 2 to 3. So, you have two unknowns and two equations. So, we should be able to solve for a 1 3 and a 2 3 here. So, see if you look at these equations from here, if you bring a 1 3, here it will be 3 by 4 a 1 3 equal to half plus 1 by 4 a 2 3. And here because this is zero, so you bring a 2 3 here. So, this will be 2 by 3 a 2 3 which is equal to 1 by 3 a 1 3.
(Refer Slide Time: 10:46)
 
So, that immediately gives you 2 by 3 a 2 3 equal to 1 by 3 a 1 3 gives you a 2 3 is half a 1 3. And, now if I substitute for a 2 3 in terms of a 1 3 in the second equation, which is 3 by 4 a 1 3 is equal to half plus 1 by 4 into 1 by 2 a 1 3. So, then I get the equation for the value of a 1 3, which is 3 by 4 minus 1 by 8 a 1 3 is half; that is 5 by 8 a 1 3 is half. So, therefore I get the value of a 1 3 as 4 by 5. So, once my a 1 3 is known as 4 by 5, I can compute a 2 3.
So, you know, even from here only one could have concluded. What I was trying to show you, but of course, it what I needed at least 2 to 3. You know computations of three, four paths to get you to this. That a 2 3 would be half less than a 1 3. The probability of reaching the absorbing state 3 from 2 is smaller than the probability of reaching 3 from 1. And, you know, maybe you can say that the intuitive feeling looking at the diagram because you have a direct connection here. And here, you will need at least two transitions to come here. So, therefore this was the feeling which you get now sort of validate by doing these computations. So, therefore a 2 3 comes out to be 2 by 5; which is less than 4 by 5. And therefore, it is less than a 1 3.
Now, certainly a 1 3 plus a 2 3 will not be equal to 1; because we are not sure whether we will be; yes, so a 1 3 plus a 2 3. Yes. Because we do not know whether we will, from 1, we will definitely reach the absorbing state 3. You may also reach the absorbing state 4. 
So, therefore these two probabilities will not add up to 1, not necessarily. But if you fix the initial state, then the system will enter one of the absorbing states. If you fix the initial state, that means, if I simply say that my system is in state one, then of course a 1 3 plus a 1 4 will have to be 1. Or, if my system is known to be in a state 2, then I must transition to either 3 or 4 ultimately. So, therefore a 2 3 plus a 2 4 will have to be 1. 
So if you know this, then I can immediately compute because I have already computed a 1 3 and a 2 3. So, then a 1 4 will be 1 by 5 and a 2 4 will be 3 by 5. And, so here again the same thing gets validated that your a 1 4 is less than a 2 4. So, the probability of transitioning from 2 to 4 is higher than transitioning to 4 from 1. Now, let me just make this 1. This is the whole idea. 
Now a 1 4 and a 2 4, I could have also obtained just as I wrote down the equations for a 1 3 and a 2 3. So, the same way I would write down the equations for a 1 4 and a 2 4 and I would compute them. So, this is what now; this is the method for computing the absorbing probabilities. And, as we have seen that these probabilities will depend on where the system is and unlike these steady-state probabilities, which are independent of the starting state. 





(Refer Slide Time: 14:30)
 
Now, let us just generalize this process. If I now call the A as a matrix of these transition probabilities, then here your i will vary. I mean, transition probabilities from transient states to absorbing states. Then i will be the rows of the matrix. You know, these vary over the transient states. And, j varies over the absorbing states. So, the columns correspond to the absorbing states. And this, so for example, in this case it is two by two. 
So, in this case your matrix will be two by two. And, you can see that if I wrote down the equations for a 1 4 and a 2 4 also, then I will have the matrix here corresponding to all these absorbing probabilities that I want to compute. So, then in that case the system you would have been written as the matrix A and this will consist of, remember the R is the matrix consisting of transitioning from a transient state to absorbing state in one step. You are writing so. p i j s; so therefore, R is a sub matrix of your transition matrix p, which has the same dimension as A. And the rows, of course correspond to the transient state and the columns correspond to j because you are transitioning transient state to absorbing state in one step. So, therefore R is exactly the sub matrix of p of the same dimension as A. Then, we wrote down Q A.
So, remember this will consist of the transition probabilities from a transient state to another transient state; because we were writing. So, either from i to j you did in one step. Then, those probabilities are here or you go went from i to k another transient state and then from k, you went to j finally. So i to k, this is transitioning from a transient state i to a transient state j k. So, Q will be that matrix. And, since the columns here are transient states, so and the rows are transient states, so this matches. So, this is compatible and this will be your system of a linear equations written in a matrix form when you want to compute the absorbing state probabilities. So, let us see. So here for example, if you bring to this side, it will be I minus Q times A equal to R. So, we continue with the computation. Through this matrix, we will look at the entries of what do we mean by. So, in other words it will be I minus Q A is R. So, A will be I minus Q inverse R. And, I minus q inverse will exist. 
(Refer Slide Time: 17:30)
 
So, I minus Q A is R. So, this implies that A is I minus Q inverse R. So, you see, here A represents the probabilities of reaching an absorbing state from a transient state. And, so when we setup the equation a valid one, then there must be a solution to this system. So, that is what we are saying. So, therefore I minus Q; and, it is a unique solution. So, therefore I minus Q inverse exist. That is what we are trying to say.
So, I am giving the argument in this way. Normally, you try to first show analytically that the matrix is a non-singular. And, hence the solution is exist. But, here we know that the system will ultimately settle down into one of the absorbing states. So, these probabilities are finite and therefore the solution exists. And hence, I minus Q must be invertible. So, this is the whole idea. 
So, the stars equation has a unique solution. So, I minus Q inverse must exist. And, now we have interesting interpretations of the elements of I minus Q inverse also. And as I said, the question that keep arising; we will go now answering them. And then in between we will also look at the interpretation of the elements of I minus Q inverse.
So, the second question that arises is how many times a transient state will be occupied before absorption occurs. So, now the second question is how many times a transient state will be occupied before absorption occurs; because obviously, this is, you are talking of a reducible Markov chain. And, so you want to know how many transitions on the average will go continue before absorption occurs and the system stops. So, this is the question mark. And, so for each particular transient state, we want to answer the; answer this question. So then and surely this is the random variable depending on the starting state. How many times transient state will be occupied? Again, it is a random variable and it will depend on what is the starting state. 
So, let us define e i j as a mean number to times that transient state j is occupied, given that initial state is i. So, remember when computing your m i j, is which was your mean time for a transition from i to j in the Ergodic case, then we also talked about the same thing while computing your f i j s. And now and then the absorbing states, the probabilities of going from a transient to an absorbing state a i j s. We were using the same argument which we will use here again to compute to right side. Write down your, you know the equations relating these various e i j s, which are mean number of times that the transient state j is occupied; given that the initial state is i. So here, this is of course a transient state. i is a transient state again; so i to j.
So, when i is not equal to j, then of course you will go to i to k and then k to j. So, this will be the mean number of transitions that you need for transition from k to j and this is a probability of transitioning in one step to i to k, when i is not j and this summation will be over all transient k s. So, this is one set of equations. The other would be if i is equal to j, then you are computing e i i. So, it will be one step. You can go from i to I; you transition from in one transition from i to i. So, therefore the number of transitions is 1 plus, you would again transition from i to k, e k is transient and then from k to j; so the mean number of times. 
So, the same argument continues. And, so in a matrix form these equations because now we have these relations for all i to j and this is from i to i. So, the same dimension as Q. So, the relationship is that E is equal to I plus Q E. And so here now your E is actually nothing but I minus q inverse. And, this is what I want to say that, you know, you can relate the elements of I minus Q inverse and give them the meaning. 
(Refer Slide Time: 22:04)
 
And, let us just look at the entries of I minus Q inverse for the example that we have; we would discussing just with four states; where two were transient and two were absorbing. So, in that case your R was half and 0 and 0, 1 by 3. This was, you know, going from one to one and this was going from three to three, sorry, two to two. One and two were transient and three and four were absorbing. And then Q was the matrix of transitioning from transient state to a absorbing state. So, the diagram; you can just refer back to the diagram. And, so this will be 1 by 4 and 1 by 4; that means from one transient state, you could go to 3; if the probability is 1 by 4 or you could go to; sorry I will just repeat this. Q is basically from transient. So, this is 1 and 2 and this is 1 and 2. I am sorry. So, 3 and 4.
Maybe, I will just again draw the figure. So, this was 3 and this is 4. Yeah. And, so you had this. You had a loop here, then you could come here and you could go there. This was your diagram. Sorry. So, I should you have been careful. Yes. So, our Q is a just the matrix consisting of whether rows and columns both correspond to a transient states. And so in this case, this loop had probability 1 by 4 and then you could go from 1 to 2 also with probability 1 by 4. And from 2, you could go to itself with 1 by 3 and this was also and then you could go from 2 to 1, probability 1 by 3. So, you can just verify these numbers. Ok.
Now, so I minus Q will be this matrix. And therefore, I minus Q inverse will be 8 by 5, 3 by 5, 4 by 5 and 1 by 5. We can; and then we also computed. We made these computations. So, you have matrix A, which is I minus Q inverse times R is this matrix. And, this agrees with our calculations that we had done. 4 by 5 and 2 by 5; so we said that this is higher than this and then this is higher than this and these computations are all there. So that is there, but now let us look at the elements of I minus Q inverse. So, look at e 2 1 for example; because this is our matrix E. So, e 2 1 is this; 4 by 5.
Now, this is the mean number of times that state 1 will be occupied before absorption occurs, given that the initial state of the system was 2. So starting from 2, you want to find out the probability that you would be going on; finally, going to an absorbing state. And, but in the meantime the mean number of times that state 1 will be visited before absorption occurs. So, that is 4 by 5. 
So now, you know it will be interesting. You can just take up any physical process; that, you know, can be modeled as this reducible Markov chain, which has only transient states and absorbing states. And then you can try to give meaning to these numbers. And then if you add up now; for example, e 1 j where, yes, this is mean number of total transitions before absorption occurs, given that the system was initially occupying state 1.
So, now you want to compute these mean number of times, total transitions before because remember you computed 2 1 here. Then I could have also computed e 2 2. e 2 1 or for example, here if your starting state is 1, then you go to 3 or to 4. So, this is… So, we said that e 2 1 is 4 by 5; which is the mean number of times that state 1 will be occupied before absorption occurs, given that the initial state of the system was 2. So starting from 2, then I will occupy 1; on the average, 4 by 5 times before absorption occurs. And similarly, now if you add up e i j s, sorry, e 1 j over j which is again transient. So, this will give you the; that means, starting from state 1, and then both the transient states will be occupied before absorption occurs. So, this will give you; yes, so therefore, for example when this is 1, then in this example it will be e 1 1 plus e 1 2. So, mean number of times.
So, state 1 is occupied or state 2 is occupied, both are transient. So, this total will give you the total transitions before mean number of total transitions before absorption occurs, given that the system was initially occupying state 1. So starting from state 1, how many mean number of transitions can occur before absorption occurs? So, here this was a particular element which is 2 1. That means starting from 2, how many times will mean number of times 1 will be occupied before absorption occurs.
Now, you are saying starting from 1, what is the total number of a mean number of a transactions or transitions which will occur before absorption occurs. So, it will be e 1 1 plus e 1 2; because either 1 can be occupied or 2 can be occupied before transition, before absorption occurs. So, that will be 11 by 5. And, in the case when you are starting from 2, then 2 1 plus e 2 2; that probability is 1, sorry, the mean number. Again, it is not probability. It is a mean number of total transitions. So when starting from 2, it will be 1 and this number is 11 by 5. So, starting from 2; that means, it is faster. The absorption occurs faster; mean number on the average. That is what we are saying. right
(Refer Slide Time: 28:17)
 .
So see, the question that we have answered was that when we are starting from state 1 which is one of the transient states, how many transitions before absorption occurs? So therefore, as when we were looking at the elements of I minus Q inverse, so this is e 11 plus e 1 2 because either absorption will occur from state 1 or absorption will occur from state 2. So, therefore you add up the two elements I minus Q inverse and this comes out to be 11 by 5. Similarly, you can find out. If you started from state 2, then how many transitions occur on the average before you transition, before you go to absorbing state? So, that sum will be e 2 1 plus e 2 2. And therefore, so that was, you know, I thought I will just emphasize again the interpretations of the elements of the I minus Q inverse. ok.
Now, a different question. This is, suppose you specify an absorbing state and then you want to know how many transitions will occur before the specified absorbing state is occupied. So, this is also because that will give you ideas to how long the process will continue. And because once the absorption occurs before, once you occupy the absorbing state, then your process is over. Or, it will just continue to stay in that same situation; ok, same state. So, and of course, this question will arise if there are more than one absorbing states. Because otherwise if there was only one absorbing state, then you know that ultimately your process will reach that state and your process will stop or will come to an end.
So, if there are more than; if there is only one absorbing state, the question can be answered by a mean first passage time. So that means, you will ask the question that starting in state i in a transient state i, how many transitions on the average before you reach the state j? j maybe in any states. So, if it is there is only one absorbing state, you can find out your first mean first passage time f i j. And, that will be the answer to your question. But, if there are more than one absorbing states, then final transition will occur to only one of them. But, you do not know. It is not known to which one of them. And therefore, the mean first passage time can be infinity in this case because we do not know to which absorbing state you will go.
So, and once you reached one absorbing state, the other one will not be visited ever. And therefore, the first mean passage time will go to infinity. So, therefore here when you have more than one absorbing state, then you need to compute; make some computations to be able to answer this question that how many transitions will occur before this specified absorbing state is occupied. 
So, what we will do is, in that case we will compute the conditional mean first passage time; that means, given that you are in a particular state, then we want to know. So, mean first; given that passage has occurred to an absorbing state. So, that is what you are saying; here you are specifying the absorbing state and then you are... So, the mean conditional; the conditional mean first passage time is what we need to compute. So, given that you are going to be occupying the absorbing state, let say j, then you... 
So, here you were defining this m i j as the conditional mean passage time, mean first passage time. It should be mean first passage time from i to j. So, let m i j denote this number and this is different from of the m i j; that means number of transitions required for going from i to j, when you are considering the Ergodic process; when all states for recurrence. So, that m i j is different from this one. So, here we are saying that this is the conditional mean first passage time from i to j. So, you are occupying state i and you know that you want to transition to state j, which is an absorbing state. 
(Refer Slide Time: 32:47)
 
So, now here we will write the following equations. So a i j, remember was your matrix that we had computed to compute the absorbing probabilities. So, then a i j is the probability of transitioning from i to j. i is the transient state, j is absorbing state, then m i j as we have said is conditional mean first passage time from i to j. So, you are occupying state j, then this can occur either in one step. So, 1 into a i j, right, and then here it will be; you may not transition to j right away. So, you will transition to some k and p i k into a k j. So, k will again be a absorbing state. So, you are transitioning to p i k into a k j and k j; right, so therefore, then the transition from k to j, absorbing probability from k to j and then m k j. So, this is, you know, trying to write down the equations for m i j, so that we can have the system of equations and we can solve for these conditional mean first passage times. So, is that ok.
So, here this is i to k; that means, you may transition from i to another absorbing state, but then in that case and then no it has to be, sorry, if k is not; k cannot be in an absorbing state. Because you see, we can immediately see that the argument is not correct because if you are from i to k, then you cannot transition from k to j because once you are in absorbing state, then it is done. So, k is a transient state. So, you are transitioning from i to k. So, i is the transient state, k is a transient state and then you are finding out the absorbing probability of going to j and m k j will be the mean first passage time, right, conditional mean first passage time. That means you want to go to j when you are in k; so m k j into a k j into p i k. So, this you sum up; where k is. So, I should not say that k is not equal to i. So, we are saying that because we want to find the transition probability from i to j, where j is an absorbing state. 
And, for the first time; so first passage time, you are computing mean first passage time. So, this will be that you transition from i to another transient state, then from that transient state your absorbing probability is a k j into m k j; so the mean number of transitions that you will require or going from k to j and m k j. So, this gives you an equation for relating the m i j s with the other mean first passage times to the absorbing state j. This is 
So, if passage to state j is certain to occur, then of course, a k j will be 1. And, in fact all a i j s; where j is fixed will be 1. So, in that case you see these equations will transform to because this will be 1, this is 1 and this is 1. So, then if you recall your equations for m i j s which you wrote down for the Ergodic process, you will get the same equation; mean first passage time. That means, now you are considering that there is only one absorbing state. And, so the mean first passage time equations will be valid here. Ok.
So the whole idea is, when you have more than one absorbing state, you want to see how to compute these conditional mean first passage times. So, let us say that you; now, in a example that we have been all along following the fourth state example in which 1 and 2 are transient and 3 and 4 are absorbing. So, you consider the four state which is… And, you want to compute m 2 4; that means, you are in 2 and you want to find out the mean first passage time of going to 4; to absorbing state 4. 
So here if you look at this equation, let us just write it out. So, it will be a 2 4 m 2 4. So now, 2 cannot be equal to. So, when we will now make use of the conditional mean first passage times. So, I am defining m i j as conditional mean first passage time from i to j, and I am defining the conditional mean first passage time. This may be a general definition. But in particular, now I want to say that suppose j is an absorbing state; I want to talk about that only. 
So, in that case I can write this as a i j m i j; right because the transition probability or the absorbing probability from i to j is a i j and that into m i j, the mean; a conditional mean first passage time. Then, either this transition occurs in one step or it will occur…; that means, you will go from i to k where k i. So, I need not write. Here k, essentially I mean that k is a transient state. This is a transient state. That is all I want to say. So, then this will be; you may transition to another state or 2 itself; p i k, then a k j. So, k cannot be j. That is all because j is an absorbing state. So once I transition to j, then it is done. I do not have to. So, it will be p i k; that means, i transition to another transient state. From that transient state, I go to the absorbing state j. So, the probability of that into the mean first passage time from k to j. So, k is a transient state.
Now if passage to state j is certain, then all these absorbing probabilities are 1. Because no matter where you are, since you know that you are going go to j. So, all these probabilities will be 1. And, in that case these equations will reduce to your; you are computing the mean first passage times for an Ergodic process, which we have done already. So, same equation; I mean, this will reduce to the equation for computing the mean first passage time for an Ergodic process. 
So, now let us see how we make use of these equations to compute your m i j s. So, let us consist; say for example, I want to compute m 2 4. So, that means the question here that we asked how many transitions will occur before the specified absorbing state is occupied. So, of course I will compute m 2 4, then m 1 4 also, and the sum will tell me so that means your answer to that question. It will be m 1 4 plus m 2 4. That will tell me the mean number of transitions that are required before I occupy state four. This is what we want to compute. 
So, let us just write down the equations here. So, a 2 4 into m 2 4. This can be equal to a 2 4 which is actually 1 times a 2 4 plus, then from 2 I can transition to 1 which is the transient state, then a 1 4 into m 1 4 or I can transition from 2 to2. So p 2 2, then a 2 4 and m 2 4. So, this is clear. Similarly if I want to look at m 1 4, then it will be a 1 4 into m 1 4, then 1 into a 1 4. So, I will again transition from 1 to 4 and this will be a ... So, this will be in one step. And then I mean, the mean first passage time will be 1 plus p 1 1 p 1 4 m 1 4 plus p 1 2 a 2 4 and m 2 4. So here again, from 1 you can transition to itself or you can transition to 2. So, if you transition from 1, then again you want to compute a 1 4 and then this will be m 1 4 plus p 1 2 into a 2 4 m 2 4. So, this is the conditional mean first passage times that we are computing. That if I am in 1, and then I can transition to 4. So, what is the conditional probability? 
So, now substituting for p i j s. I should not say p i j s. Substituting for a i j s. And, so remember we had, for this thing, we had computed the matrix A. And, if you look back at the matrix A, it is, the numbers are given to you. So, a 1 4; for example, there are a 2 4 is 3 by 5, then this was 3 by 5 plus 1 by 3, your this was 1; this was 1, a 1 4 was 1 by 5, then 1 by 3 was p 2 1. Anyway, you had the matrix this and you had the matrix; the transition matrix p also the transition diagram. So, looking at those if you can just revert back to a few frames earlier, then you have all these numbers. And so by substituting there, I get these two equations and then solving them simply, easily gives me the answer that m 2 4 is 93 by 45 and m 1 4 is 153 by, it should be 45 only, by 43. 
So, as I were saying that now if you want to look at the m 1 4 plus m 2 4, then this is equal to 93 plus 153 by 45 and this will be 246 by 45. So, on the average the mean number of conditional; that means if transitioning to four, so the number of transitions that will be required; mean number would be 246 by 45. Provided, you are transitioning to the absorbing state four. So one can, you know, I have tried to look at these processes in a different ways and giving you interpretations.
And so you know given a physical process, there are lot of these kinds of questions because you want to know if one has to plan that one has to know, for example, these are reducible Markov chain; that means you know which the processes which will terminate in short time, then you want to have an idea about these numbers, so that you look at, you can plan accordingly. And, let us hope that in future after having gone through this, you will be coming across such situations or such processes, where then you can look at them in a more meaningful way. 
(Refer Slide Time: 44:23)
 
So, I will now discuss exercise. So, let us look at question one. This is, a particle moves. By the way, these questions I have taken from the book Hillier and Lieberman, reference to which will be given to you at the end of the course. So, a particle moves on a circle through points that have been marked 0, 1, 2, 3, 4 in a clockwise order. So, and the particle start at point zero; so let us see. I can just… So, here is a circle and you have 0, 1, 2, 3 and 4; so this. And, the idea is that you can either move from here to here or you can move backwards.
So at each step, the particle starts at point 0. At each step, it has probability 0.5 of moving the point clockwise. So, the clockwise would mean this way or 0.5 of moving one point counter clockwise; means either backwards or forwards. And, both the probabilities are the same. So you remember, this was your, we were looking at the random walk. You were looking at the random walk. And, when we said that probability is half, then we also showed that it will be an Ergodic process; because in that case, all these states will be recurrent. So, the same situation.
Now, let X n denote its location on the circle after step n X n is a Markov chain. So, we have already seen that this will be a Markov chain because it will just depend on where you are, so that you know the probability of transitioning to a next step will just depend on where you are. It will not depend on how you reach there. So, this will be the Markov chain. 
Now, construct the one step transition matrix. You can do it. So, it will be a five by five matrix. Then, determine the n-step transition matrix p n for n equal to 5, 10, 20, 40 and 80. No, I have given up to 80, but that is because either you must be either familiar with Matlab or by writing a small program of your own. Then, you can iteratively find out to the multiply to get the power of p raise to 5 p raise to 10 p raise to 20 and so on. So, it is just to familiarize yourself. 
Then, determine the steady-state probabilities of state of the Markov chain. Now you, so this is a little; may become tedious because you are solving your five by five; your transition matrix is five by five. So, you will have five variables and five equations. But since the values of p s are half, so therefore it should not be a difficult system to solve. You should get the answer too quickly. 
So, determine the steady-state probabilities of the state of the Markov chain. Describe how the probabilities in the n-step transition matrices obtained in part (b), compare to these steady-state probabilities as n grows large. So, want to show. You see that, you should feel the… So, once you find out the steady-state probabilities and you also have; you know p raise to 40 or 80, then you can see that. In fact, at p n equal to 80; that means, when you have p raise to 80, then they should definitely be very close to your steady-state probabilities. And in fact, you can see the pattern even when you compute the 40.
(Refer Slide Time: 48:10)
 
Now, question 2 is just to determine the period of each of the states in the Markov chain that has the… yes. So, here you have again a five by five matrix and I am asking you to determine the period of each of the states in the Markov chain that has the following transition matrix. So, this will be; all the states are periodic. Well, you just find out. So, you have to then determine the period. That means you will have to compute P square, P cube. And, here also you can make use of the same program that you wrote for P and then you can compute P square, P cube and so on to determine the periods of the periodic states. Yes.
(Refer Slide Time: 48:46)
 
Now question three; a transition matrix P is said to be doubly stochastic if the sum over each column equals 1. So, you know for the transition matrix that we have seen, the row must add up to 1. So, now I am giving you an additional condition. And that is, that the columns also add up to 1. So, therefore P i j as i varies from 0 to M is also 1. So, column sums are 1. In that case, such a chain is irreducible, aperiodic and consists of M plus 1 states. States are already M plus 1; show that your steady-state probabilities. In such a case, you do not have to do any computations. Just right away you will be able to show that your Pi j s are 1 upon M plus 1; where j varying from 0 to M. So, this is simply, you can do it or write down if you think and then make out your… So, this is now, oh, this is ok.
Now question four; a computer is inspected at the end of every hour. It is found to be either working. It means up or failed down. If the computer is found to be up, the probability of its remaining up for the next hour is 0.9; if it is down, the computer is repaired, which may require more than one hour. Whenever the computer is down, regardless of how long it has been down, the probability of its still being down one hour later is 0.35. So, that means your unit of time is one hour and then you have to write down your transition matrix. So, construct the one step transition matrix for this Markov chain. And find the mu i j, the expected first passage time from state i to state j; for all i and j. So this, you will be able to do. So, here I have asked you to; now this sort of question depends on computing the first passage times, which we have also discussed quite thoroughly. 
(Refer Slide Time: 50:50)
 
Now, question five; which I told you in the lecture. This is, you know based on the gambler's ruin problem. And, so I thought that I leave the computations to you. I just explain to you how, what the problem is.
Now, here gambler bets; there should have been a space between. So, now this is a gambler bets dollar here. It is dollar 1 on each play of a game because this is the game from Hillier and Lieberman. Each time he has a probability p of winning and probability q which is 1 minus p of losing the dollar bet. He will continue to play until he goes broke or nets a fortune of T dollars. Now, let X n denote the number of dollars possessed by the gambler after the nth play of the game. Then, you want to find out; X n plus 1 will be X n plus 1 with probability p; right, because he has 1 more rupee if he wins and that is with probability P, otherwise he will have X n minus 1 with probability q which is 1 minus p.
Now, here of course he continues playing, only if x n is less than T. And, X n plus 1 will be X n for X n 0 or T. right because if he has no money, then he cannot play. And therefore, he cannot bet. And, so he continues to be at the same state. That means, he continues to be broke. And if he has T dollars, he has earned T dollars; then again he does not play because he has earned his fortune. 
Now X n is a Markov chain. We have already discussed this. The gambler starts with X naught dollars; where X naught is a positive integer less than T because I said; we can say that X naught is i.
Construct the one-step transition matrix of the Markov chain. So this, you will have to write down. And, you could see that it will only be one step forward or one step backward. The other entries will be zeroes. Now, find the classes of the Markov chain. This, I have already told you. Let T equal to 3 and p equal to 0.3. So, if it is a question of earning up to 3 dollars, so that means, your states will be 0, 1, 2 and 3. So, then I have asked you to find out the first passage probabilities f 1 0, f 1 T, f 2 0 and f 2 T; and then again the same things, when p is 0.7. So, it will be not be difficult at all if you write down. See, again the computations, the formulae are given to you for the first passage probabilities. And, so once you write down the transition matrix, you should be able to complete the problem. 
So, in the lecture I had told you that I will be asking to you to compute the probability that the gambler will end up with a rupees T. or, in the lecture, it was I think rupees n or dollars n, whatever it is, that does not matter. That means, the gambler with what is the probability that he will earn the fortune that he is wanting to. So, that has not been asked in this question five. But you see, you should be able to set up equations. So, essentially it is just to define the probability p i p i minus one.
(Refer Slide Time: 54:08)
 
You can interpret the same way. And then it will be p i is equal to p p i plus 1 plus q p i minus 1. And then you multiply p i by p plus q; because p plus q is 1. And then from this equation you have an iterative relationship for different values of i. And then you can find out the iterative relation and then you will be able to find out the probability p i. And there, of course you will use the fact that if you have 0 dollars, then the probability of making your fortune is 0. And, if you have earned T dollars, then your p T is 1. So, using this initial at boundary conditions, you will be able to solve for p i. So, please do that; because in the problem I have not asked you to do it. But, you can certainly do it. 
(Refer Slide Time: 55:02)
 
Now, question six. Question six is which is again a simple one. A leading brewery on the West coast, labeled A, has hired an OR analyst to analyze its market position. If it is particularly concerned about its major competitor, let us say labeled B. So, another brewery which is their competitor for this brewery A and. So, they want to find out how could a competitor or how bad a competitor, this other brewery is. So, analyst believes that brand switching can be modeled as a Markov chain using three states with state A and B representing customers drinking beer produced from the aforementioned breweries and state C representing all other brands. So, you know state A will represent; so that means A to A in this transition matrix that is given below. So, see this probability of A; that means, somebody who is taking, using the, you know, beer from brewery A will continue to do that, use the brewery A only is 0.7, but may switch to B with probability 0.2 or to other brands with probability 0.1.
Similarly, you can explain the row B entries, right, and then C. for other brands, when they switch to A will be 0.1 and 0.2, 0.1 again to B and 0.8; that means, they continue with the same brand that they are already using is 0.8; so that point is missing here. Anyway, just you can make the entry; so 0.8. 
Now, what are the steady-state market shares for the two major breweries? So, we want you to find out pi 1, pi 2 and pi 3. So, the answers that they are asking for is pi 1 and pi 2. So, what are the steady-state market shares for the two major; that means, when the process has gone on for some times, you think that the choices have all stabilized. Then, you want to know the steady-state market shares for the two major breweries.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 31
Time Reversible Markov Chains

(Refer Slide Time: 00:15)
 
So, today we are going to look at interesting phenomena related with Markov chain and that is you know time reversible Markov chains. So, let us just first start looking at what we mean by all these. So, suppose you have given this transition matrix p i j and you have given the stationary state probabilities. So, this is let us assume that the ((Refer Time: 00:38)) p i s are all positive, because if this, if pi i is 0 then surely we can drop that state from the process, because it is not of any interest.
So, this is the ergodic process and the pi i s are all there stationary probabilities and the system is gone on for some time. So, we are looking at the stationary part of the thing. So now consider the sequence in the reverse order. So, this is x n, x n minus 1, x n minus 2, and so on. So, at this point of time you are looking backwards at the process right. Now, we will show that this is also a Markov process. So, this is the interesting part that is when you Markov process is going on and you at some point you want to look backwards, and then you will see the transitions and so on.
So, there also the sequence will follow will have the Markov property and so it will also be a Markov chain or a Markov process.
So now how do we show this? To show this, I have to show that, you know if suppose the current time is m plus 1 then you are occupying state i or the system is occupying state i and then you want to look at the probability that in the time period just before; that means, today and yesterday. So, it was x m is equal to j. So, you want to look at the probability, conditional probability.
So, therefore, for if you are looking at like you are today and you are looking at yesterdays situation then all these days ahead; that means, x m plus 2, x m plus 3 and so on, all these. So, the conditional probability of you know having the history future history and then x m plus 1 is i and you are wanting to know the probability of x m equal to j. So, this would be when you are at time m plus 1 and you are looking backwards. So, if you are looking at this thing then this is all past for when you looking backwards right.
So, therefore, this conditional probability should be equal to x m equal to j given x m plus 1 equal to i; that means, it will just depend on the current situation or the current state being occupied by the process. And then so this probability should be you know here all these sates occupied in the past because now we are looking backwards.
So, all the states occupied in the past do not matter it is. So, only the current state that is occupied by the system and then so this is what you want to prove. If I show this then it would imply that the backward process at any time the backward process will also be a Markov process right.
So, present time is m plus 1 and we know that we have given that x naught x 1, x 2 this is the Markov chain and as I said and the corresponding transition probabilities are p i j s and the pi i s are the stationary probabilities. Now, the conditional distribution of x m plus 2, x m plus 3 and so on given the present state that is given the present state x m plus 1 then the Markov property tells us that the conditional probabilities of x m plus 2, x m plus 3 and so on, do not depend on x m right, because the conditional probability of the whatever state is being occupied at time m plus 2 is dependent on this right. And then of course, x m plus 2 will be, x m plus 3 will be dependent on x m plus 2 and so on.
So, because this is the Markov process, we know that the present state x m plus 1 is independent of no no, so this is conditional distribution of x m plus 2 x m plus 3 and so on given the present state x m plus 1 is independent of x m the past right and all things before hand x m minus 1 x m minus 2 right.
So, the conditional distribution of x m plus 2 or x m plus 3 and so on. So, conditional distribution of x m plus 2 would depend on the present state which is x m plus 1 and will be independent of x m. Similarly, conditional distribution of x m plus 3 will depend on the state being occupied at time m plus 2 and so it will be independent of m plus 1 and x m and so on right.
Now, we know that independence is the symmetric relation you say that x i and x j are independent; that means, x j and x i are also independent. So, it is a symmetric relationship right. So, therefore, given that x m plus 1, x m given so; that means, when you given x m plus 1, x m is independent of x m plus 2, x m plus 3 and so on. So, then I can say the reverse also right. See we just now said that given x m plus 1, x m is independent of x m plus 2, x m plus 3 and so on. This is what we want to say, because x m plus 2 is independent of x m, x m plus 3 is independent of x m so therefore, the reverse, because this is the symmetric relationship. 
So, I can say that x m given x m plus 1, x m is independent of x m plus 2, x m plus 3 and so on. And therefore, this probability can be written as probability x m equal to j and x m plus 1 equal to i. And so we immediately conclude that the backward process is also a Markov process. And now, we want to look at another special case of this. So, therefore forward or backward Markov process as this property.
(Refer Slide Time: 06:29)
 
Now, let us define these backward or the reverse probabilities right. So, I will say that let q i j be equal to probability of x m is equal to j given that x m plus 1 is equal to i right. So, I am defining the backward or the reverse transition probability. So, this is present currently u r and I and so we are occupying state position j just 1 period before. And Ss, this conditional probability, I can write as by the conditional probability formula I can write this as x m equal to j comma x m plus 1 equal to I divided by the probability of x m plus 1 equal to i right. And then again this product probability, I can write conditional as a conditional probability x m plus 1 equal to i given x m equal to j into probability x m equal to j divided by probability x m plus 1 equal to i. 
And this, because we already have the transition probabilities for our forward process. And this and the stationary probabilities pi i. So, this can be written as p j i because j i right. So, p j i into pi j probability x m equal j and divided by probability i that is being state i at time m plus 1 the stationary probability.
So; that means, given the transition probabilities and the stationary probabilities, I can always compute the q i j s which are reverse transition probabilities. So, we can compute the q i j s right. And so therefore, now, I can say that this is the backward process is also a Markov process. And the conditional the transition probabilities the reverse transition probabilities are also available given the regular Markov process then the backward process. I can and once you specify the transition matrix the reverse transition probabilities the process is completely determined right ok.
Now, the special case and the special case is in case q i j is p i j incase the reverse probabilities are the same as the forward probabilities transition probabilities. So, if q i j is p i j then you see this equation q i j equal to p j i into pi j upon pi i this reduces to see you write here p i j. So, it will be p I j. So, p i j into pi i is equal to pi j into p j i right.
Now, if you look at the left hand side this says. So, you this is the probability of being state i and then this is the probability of transitioning from i to j. So, this is the rate at which the process transitions from i to j right. And in our case this is the, you know because I am assuming that currently I am in I, state i transitioning backwards to state j.
So, this is your probabilities the rate at which you transitioning from i to j in the backward way and this pi j p j i. So, this is the probability of being in state j and then you are transitioning from j to i right. So, therefore, this is your x m equal to j and then transitioning to i. So, forward probability. So, this is the rate at which the process transitions from j to i.
So therefore, now, you say that this Markov chain is said to be time reversible Markov chain with respect to time, because the forward transition rate and the backward transition rate are exactly the same. And so now, you can see that you know, it is something like saying that, if you play a tape then you will not be able to differentiate whether it is playing backwards or forwards this is the idea right.
If the tape is the you know, has captured the process of a Markov chain, which has the time reversible property then whether you play the tape forward or backwards it will exactly look like this it will look exactly the same. You will not be able to make a difference, because the rate of transitioning backwards and forwards is the same right. And this is the necessary condition for time reversibility. So, once you have; that means, if you have a set of transition probabilities and a set of probabilities state probabilities, which we will show our stationary probabilities then and they satisfy this equation for all i j then you see this system the Markov process has the property of time reversibility.
So, this is what we are trying to say right. So, and again it just maybe it is a matter of again repeating that we are saying that you are see here this is i or this we are saying is j and this is i. So, then you are going backwards or you are coming this way right when you are here you are looking backwards. So, then the transition the rate at which you transition is exactly the same as, if you are here and then you are transition to i right.
So, this is what essentially pictorially also this is what this equation says. So, this is a necessary condition and therefore, now we will show that the converse of this is also true. And then you know we look at some examples of time or how exactly. And of course, the other advantage that we will show that reversible Markov chain, time reversible Markov chains posses ok.
(Refer Slide Time: 12:37)
 
So, now suppose p i j s are given and s is vector of probabilities such that this condition is satisfied which is your necessary condition for. So, we are looking at the converse what we are saying is that suppose you have a transition matrix and you have a vector of probabilities such that this condition the time reversibility condition is satisfied; that means, the process that we have given the Markov process is the time reversible Markov process. Then so the process is reversible Markov chain then s is the vector of stationary probabilities.
So, therefore, what we are saying is that in case you have a probability vector which satisfies the reversibility equations with corresponding to the p i j s, which are your transition probabilities then the s i s can be nothing else, but the stationary probabilities, stationary state probabilities.
So, this is a convenient way of, because… So, now we know that of course, we said that the conditional; that means, we said that the, if s i s were stationary probabilities. And these were transition probabilities and these conditions were satisfied then we defined reversible Markov process. So, now we are saying talking about the converse that, if any probability vector along with this given transition probabilities for a Markov process satisfy these time reversibility equations then s has to be nothing but the state probability vector this is want to say. So, suppose I start from here and then I sum up these equations with respect to i. So, this is sigma, sigma with respect to i s i p i j is equal to summation, summation respect to i s j p j i now, since s j is independent of i.
So, I take s j outside and this will be summation p j i over i right, but then these being transition probabilities and you are summing up the probabilities of rho j right p j i s with respect i. So, you are summing up the elements of a rho and that must add up to 1, because these are elements of a transition matrix and therefore, this is equal to s j right. And so when you write down for all j this is satisfied.
So, this gives you the matrix equation that s, s is equal to s p. And therefore, s is the, because remember we said that when you do this and you have the condition that components of s add up to 1 then you have a unique solution and that unique solution is the vector of state stationary probabilities. So, therefore, we now know that any system if we can find a vector s and we have the transition probabilities for a Markov process satisfying this then s must represent the stationary probability vector.
So, knowing this now of course, the question is we will certainly want to look some examples of reversible Markov chains. And then will show you that through these examples that we know computing the state probabilities becomes very easy. And so you do not have to work out, you know apply matrix methods, iterative methods to solve for s, because given this you want to know this state probabilities. Then you have to remember we solved system of linear equations, but when the process when the number of states is very large then it will be very tedious to have to solve these equations.
So, now through examples we want to show you, but computing these state probabilities is very simple. And of course, the process we also look at these examples. So, the idea is that now here, let us look at an undirected graph with 4, 5 nodes right and the links connecting and arcs connecting them.
Now, what I am doing is that, I am writing probabilities; that means, transition from 1 to 2, 1 to 3 these are the two edges. So, I am giving them equal probabilities right. And that is it is called random walk, because you can wonder around this graph and what we are saying is that if for example 2, 2 has four edges incident on it when it can, you can traverse any of the edges with equal likely I mean traversing or picking up an edge to go along is equally likely. And therefore, I am giving probabilities like p 2 1, p 2 3, p 2 4 and p 2 5 equal to 1 by 4.
So; that means, when you are at node 2 traversing the edge to 1 2 3 or 2 4 or 2 5 is equally likely. So, therefore, these are the probabilities right. And then similarly p 3 1 is equal to p 3 2 is equal to half and p 4 2 is 1 and p 5 2 is 1. So, here from here you have no choice you have to go to 2 only and from 5 also you can go to 2.
Now, let me define d i as the degree of node i right, so that means for example, for this the degree is 2 for this the degree is 4 for this is 2 this is 1 and this is 1. And then by the definition, because of these definition you see that immediately since p i j is simply suppose you are at node 1 then your p i j is 1 by 2, because 2 nodes are incident.
So, this is equal to 1 by d i since we are saying that equally likely. So, d i into 1 by d i similarly d j into so for example, if you are looking at 1 2 then here suppose i is 1 and j is 2 then this is half and d 1 is 2. So, this becomes 1 and then when you are here d j is the degree is 4, 4 into p j i 2 1 is 1 by 4 and therefore, the product is 1 here again.
So, this holds for all i j right and so now, looking at this necessary conditions being satisfied. So; that means, it is a random walk where you know you can go from at any node you can traverse any edge and go on wondering around this graph that will be, so I mean what we are saying is that this is the Markov process and its time reversible because it does not matter the process has gone on.
So, where ever you are then again you start traversing and or you look back to your this thing to your traversals before this. So, it will be the same process there is no change right, because the I mean we interpreted this with the rate of going forward and the rate of going backwards is exactly the same right. So, once and of course, you can look at the numbers as I have written down here now, you can try to verify for all other nodes and arcs that these conditions are satisfied. So, therefore, this is an example and so now, here we would want to convert the d i s in to probabilities.
(Refer Slide Time: 20:05)
 
And so what we would do is. So, the probability of transferring an edge i j is equally likely for all edges i k incident on I right. And so now, let me generalize this discussion and we will say that. So, then I will give you process of writing down the corresponding state vector and how you define the transition probabilities.
So, take a undirected graph now with n nodes. So, just take the general case and will define the probability vector s by saying that the i th probability is state vector is component is d i upon sigma d i you take the degrees what we had defined here and now we just normalizing.
So, essentially if you want to convert these two probabilities you have to just define this by the total number of edges, which will be summation d i. So, you are adding up the degrees of each node. So, which will actually become? So, like for example, sigma i, if you do it here now, for this case it will be the degrees are 6, 7, 8 and 10 right.
So, summation d i is 10 right, which is twice the number of edges right. So, the, when you add up all the degrees, they add up to degree twice the number of edges in the graph. So, here we are normalizing. So, therefore, this is d i upon sigma d i then s i s are probabilities, because when you add up sigma s i, sigma s i this will be sigma d i divided by sigma d i, which is sorry, which is 1 right.
So, these are probability vectors and as they will satisfy this, because I am defining this is p i j as I am saying that p i j is 1 upon d i at node i whatever the degree of the node. Then I take the probability of traversing each of the edges, which are incident on i as equally likely. So, it will be 1 upon d i.
So, whatever the degree of node i and then all edges which are incident on node i, I will take the probability as so i to j. So, this will 1 upon d i and similarly p j i will be 1 upon d j right. So, there we are at node j then whatever the number of edges, which are incident on j then 1 upon d j and so p j i is 1 by d j. So, as we saw in this example and now you can easily verify that, because you have simply divided each s i by this thing. So, therefore, the equations will remain the same and so these will be satisfied.
So, these this probability state vector and these transition probabilities define satisfy your time reversibility equations. And so we will say that no wondering around this random walk on a undirected graph can be looked upon as a time reversible Markov chain right. And you see here one did not have to do any hassle with solving a system of linear equations to compute your state probabilities stationary state probabilities.
So, just simple formula gives you the way to compute them right. And this is what we really want to show that because of the property of time reversibility things become so simple right. So, this is finally, our conclusion that s i s and p i j s satisfy the reversibility equation and so s i s must be the stationary probability vector ok.
Now, you can generalize you can talk of a generalized random walk and here suppose what we are saying is that you have a weights attached to the arcs. So, there is a weight w i j, which is non negative for the arc i j and if the arc i j is not there the edge, I should say actually this should be called as edge, because in the directed case it is the nomenclature is that you call them arcs when they have direction. So, otherwise undirected links are called edges. So, this is edge i j and. So, w i j s are not negative and w i j is 0 if edge i j is not present right. So, we will discard that. Now, what we will says that again we want to generalize these concepts. So, what we will says that probability of traversing an edge i j when at node i is proportional to w i j let us say.
So, actually the weights here right, for example, edge 1 2 is 1 2 to 5 is 2 and so on. So, I am given you the weights w i j right. And now what we are saying is that the probability of traversing the edge i j is proportional to w i j. So obviously, because these are numbers, integers. So, they cannot be probability. So, I will have to normalize them.
Now so I do this, I define p i j as w i j upon yeah, one more thing I should have spelled out here that, in this case in the random walk case, you see what is happening is that your probabilities your s i s the state probabilities are being defined by this right. So, d i upon sigma d i and that means, that remember state probabilities is the stationary state probabilities also represented the fraction of time the systems spent on the particular state right.
So, here since s i is d i upon sigma d i you see the system will spent more time in state, in the state which has higher degree right. So, the higher the d i, the more the higher the value of s i, because the normalizing factor is the same. So, therefore, we magnitude of s i gets determined by the magnitude of d i. And so the system will spent more time in a state, which has higher degree which has more edges incident on it. And of course, I should have spent little more time on the analogy.
See when we said that this is a Markov process. So, here essentially the nodes or the state of the system we are saying that these are the states in which the system will occupied by the system and then the links are the gives you the transition from; that means, you can transition from 1 to 2 or you can transition from 1 to 3 and so on. So, the possibilities of transitioning to different states so this is the analogy.
So, now let us talk about generalized random walk and that is why we are saying that we will have weights attached to the edges and the weights will be 0 whenever the edge is not present right. And then we will define the probability of traversing an edge as w i j divided by the total weights of the edges, which are incident on that node right.
So, sigma w i k summation with respect to k, so you add up all the weights. So, for example, if you want to look at the probability p 1 2, so the total weights here are 5. So, p 1 2 would be the weight of the edge 1 2, which is 1, so 1 divided by 5. Similarly p 1 3 would be the weight is 2 here so 2 by 5 right. When p 1 4 is 0 right and p 1 5 there is an edge. So, p 1 5 is 2 by 5. And so and the now, we have to define the state probabilities and to show you that again you know generalized random walk; that means, now the probabilities of traversing an edge when you are at particular node will be given by this. And therefore, this will again be this is the random this is the Markov process. Where again the nodes represent the states and the legs the edges give you the states to which you can transition. And now when I defined for you state vector stationary probability vector such that the necessary conditions for reversibility are satisfied. Then this is also another example more general example of a reversible Markov process.
(Refer Slide Time: 28:31)
  
Yeah, so you see the weights attached to the edges then we see that if I define my p i j as w i j upon sigma k w i k. So, now, here the notion of you know of going to an edge is equally likely that has been replaced by. So, this is the weight of the edge i j and then divided by total weights of the edges which are incident on that node right.
So, then that is how will define p i j and you can see that if all w i j are the same then this will be the exactly the same; that means, if you just take this as, I mean the number of edges which are incident when this p i j will reduce to 1 by the number of the degree of the node right. So, this is the generalization of the random walk. And so you will define p i j as w i j this. So, now, we will if you write this as this then this will be sigma w i k summation respect to k p i j is w i j. And of course, this condition we are imposing that w i j s w j i right.
So, then in that case yes. So, again since I have been able to write this as this. So, w j i if you take the same equation w j i can be written as p j i into see the p i j represent p j i summation w j k summation over k right, because here it was w i k. So, here it will be summation w j k k, because you are at node j so from j you are transitioning to i. So, therefore, weights of all the edges, which are incident on node j which are of the kind j k.
So, you add up all the weights of the edges incident on node j and just know. So now, once you get this then you say this is your reversibility equation, because your p i j s are transition probabilities. And now, I just have to define my corresponding state probabilities and then you see this will give me a reversible, time reversible Markov process this is the idea.
So, as I we said that your s i s will be proportional to summation w i k over k and so we will normalize s i that is you let s i be take the summation of all the weights. And so sigma w i k respect to summation respect to k divided by summation respect to i and k of w i k total weight right. And so therefore, by our result that we proved earlier s i s are the stationary probabilities.
So, essentially the same concept go through and you can now, take a general case you can assign any sets of weights to the edges. And then you can define the corresponding transition probabilities and you will see that this will again be this will be a generalized random walk. So, you can and you can very easily see that it is you know reversible in the sense that the process can go on and but if you start going backwards then again it will be the same process that is repeated. So, exactly the same forward or backward does not make a difference. So, therefore, in other words we can now, get a feeling for the time reversible Markov process is and the converse will also help you to fix ideas better.
Now, what we are saying is that any reversible chain is of this form. So, given a reversible chain you want to say that you will be able to associate undirected graph and give weights to the edges such that you know and then you can define the corresponding transition probabilities and your state vector you know this is simple. So, therefore, now see; that means, if you given a reversible chain and this is the set of equations; that means, there are some s i s and p i j s which satisfy this necessary condition. So, this is given to you right. That the time reversibility equations are satisfied by the state vector s and the transition probabilities p i j.
So, some reversible chain is there. Now, we will start assigning will say that we can draw undirected graph. And of course, the nodes will be the, so we can construct a graph with nodes as states and the edges i j for which p i j is positive. So, wherever there is a positive pi j then the corresponding link will be there, otherwise it will not be their right.
Now, let me define the weights on the edges. So, w i j, I will simply define as s i p i j right. And this again by the definition because say s j p j i will be w j i. So, immediately you get that the weights are symmetric. So, w i j s w j i so by using this question right. Now, you want to compute the transition probabilities and which we will show can be done in terms of the w i j s. So, you want to compute probability x n is i given that x n minus 1 is j right. So, this because I am constructing a undirected graph and I am associating weights w i j.
So, we remember with the generalize random walk this transition probability we defined as w i j upon sigma k w i k it is here right. So, once given Markov process I am constructing a graph undirected graph where the nodes are the states and then now, I have to when the weights are well defined through this equation and w i j s w j i.
So, once you have the weights then our process of you know generalizing a random walk gives us that the probability of transitioning from, oh I am sorry, this should have been oh. So, let me write this as see it should have been I am writing w i j.
So, this should be j and this should be i sorry, right. So, from i to j you are transitioning. And so the probability would be w i j upon summation w i k summation with respect to k right. This is exactly what the way we have defined here. And now, let us substitute for w i j from here this is s i p i j and then summation if you sum up respect to j or k it is a dummy variable does not matter.
So, you are summing up this s i p i k respect to k now, since i is independent of k. So, s i comes out and sigma p i k respect to k is equal to 1, this is 1 right, remember transition matrix and you are summing up the components of a rho. So, therefore, this is equal to 1 so then s i s i cancels. And of course, as earlier said it and again repeated that s i s are not 0, because if s i is 0 then the probability of being in that state is 0. And so we can always reduce we can remove that state from the process and come talk and work with reduced process right.
So, therefore, of course, these are meaningful only when s i s are not 0. So, s i gets cancel and you are left with p i j. So, that means; once you given this then I can assign the weights by this equation. And then once, I have this weights I can now defined my transition probabilities in terms of these weights right. w i j upon sigma w i k and once I have this transition probabilities I can also define my s i s we just reverting back to the process.
(Refer Slide Time: 36:15)
 
So, here s i s was this and so similarly we can say that from here summation w i j is summation j is equal to summation j s i p i j. So, this becomes this and therefore, this is s i.
So, here your s i s are proportional to summation w i j sum respect to j and since s i s have to be probabilities I can normalize them so defined by the total sum of weights. And so this gives me a probabilities and so my, this thing is complete; that means, given any Markov process which satisfies the time reversibility equations, I can assign a random walk with it. And assign weights I can define the weights, I can define the transition probabilities and state probabilities.
So, therefore, any time reversible Markov chain can be modeled as a random walk and you can determine the weights and the, you can determine the transition probabilities and the state probabilities. And so this is very simple in the sense that now, you really want to compute your, this and this. You can do it respect to you do not have to solve system of linear equations. And so this simplifies, but of course, only a small class of process is Markov process, which would be which would satisfies time reversibility condition right ok.
So, I think this brings to an end of course, I should also just mention that the non reversible Markov chains examples, one example and this is taken from burst stains lecture you know. However, he has given lectures on Markov processed, Markov chains. So, he says that you know World Wide Web. So, you can imagine as you know each web page as a state of the system right and so web pages are states and edges. So, edges again you can picture this as a graph, but this will be a directed graph right. So, for example, just take 4 web pages or you may be you can take 5 web pages does not matter. And then you see it is like, if you are page 1 here, where you can go from here to page 2 or you can go from here to page 3.
So, these are the hyperlinks right, you are looking for some searching for some word remember you get a page you open a page. And then its links you to other pages it shows the links hyperlinks they are called to other. So, therefore, and this is very small example, because you know the millions and millions of web pages and they will be connected and it is any time you open a page it will link you to hundreds and thousands of pages. 
And of course, there is a way of ranking and so on, all that algorithm is there, but in many case. So, the whole idea is that you can picture this as a directed graph. So, each node will be a web page and the pages which are connected to a particular node will be directed by a link.
So, for example, from 1 you can go to 3, but you cannot go to 3 to 1 right. Similarly you can go from 1 to 2, but you cannot go from 2 to 1 and so on, but at 4 you can go from 1 to 4, 4 to 1 and similarly from 4 to 2, but not 2 to 4. So, you can immediately see that this will not be a time reversible process. Of course, there is algorithm to show you and then how do you compute the state probabilities and so on. Again there is a whole algorithm interesting one, which gives you method of not as actually having to solve system of equations again and you can compute the state probabilities and so on, but there is a way of computing the transition probabilities also.
So, example web pages worldwide if you look at this. Then this will be and searching on the web is not a it will be a Markov process, because it will depend on see the way you adjust the probability or where you want to go will be this probability will not be dependent on how you reached one. So, it is easy to picture that the research on the web will be a Markov process, but it will certainly not be reversible Markov chain ok. So, I think with this I would like to end the discussion on this thing on Markov process. Now, we would like to talk about continuous Markov processes and then go on to specialized continues Markov processes.
(Refer Slide Time: 41:01)
 
See after having looked at the discrete Markov time process Markovian process is to stochastic processes discrete stochastic processes with Markovian property. So, we have to spent quite of you time quite bit of time on looking at the properties and characteristics of such processes. We will be looking at because again the continuous time process is are also very important and especially the Markovian ones and I would like to now through a series of lecturers show you particular kinds of a Markovian continues time processes.
So, and so want to show you the transition from discrete time processes to continues time processes. And same and how the Markovian property also translates when you consider time as varying continuously instead of discrete time. So, we say that continuous time process we describe it has x t where x is the random variable so x t comma t greater than equal to zero.
So, this is x t varies you get different values. So, and since t is greater than or equal to zero. So, it is simply varying continuously the time is varying continuously and we say that if continuous time stochastic process taking on values in the set of non negative integers. So, these values would be positive integers, non negative can be 0 also. And the property process is Markov process if for all s and t your a non negative integers i j and x u, where u is varying between 0 and s.
So, these are all non negative integers probability that x t plus s is j given that x s is i. So, at time s the system is occupying state i let say, because these are the non negative integers know. So, the non negative integers describe the state it is occupying. So, this tells you the state the value of x t will tell you the state that is system is occupying a time t. So, here probability x t plus s is j given that x s is i and that x u is small x u again these are positive values as u varies from 0 to s.
So, given all the past history; that means, the states which the system occupied from time 0 to s then at time s it is in i and now, at time t plus it is in j. So, this probability is equal to the probability that x t plus s is j given that x s is i; that means, this past history is redundant you. So, you do not want the probability this probability will only depend on this; that means, what is your present state and then after time t it is occupying state j.
So, this probability is independent of how you reached state pi at time s so; that means, so whatever happened between 0 and s is not a material ok. Now, which I am saying in words here that is the conditional distribution of the future x t plus s given the present x s and the past depends only on the present and is independent of the past right. And this property and of course, and if this probabilities also independent of s. That means, it does not matter what time and if you remember the conditional we are saying for stationary that we was saying that probability in the discrete case we are saying that x plus 1 j given that x n is i is equal to probability x 1 is j given that x not is i.
So, the same property that is so it does not matter when you are considering this conditional probability whether at time 1 or at time n plus 1 does not matter. So, then we said that this case these the system or the process is stationary, because it is independent of the time right. So, same property is being carried over here. So, if this probability is independent of s. So, essentially you are saying that you know, but s is tenth day or fifteenth day or the zeroth day does not matter if in the zeroth day the system is occupying state I then at x t it will be j and this will be the same what time you have to takes right. So, if this probability is independent of s then we say that the continues Markov process is stationary. 
(Refer Slide Time: 46:02)
 
And now, just let us consider the finite case; that means, the system, it is a continuous process, but it can occupy finite states i varying from 0 1 to m right. And now, we associate a random variable t i which is the amount of time the process spends in state i. So, it continuous to be in state i and how do you, how do you sort of express this property or how do you describe this t i.
So, we say that suppose the system enters state i at time t prime equal to s. Then for any fixed amount of time t greater than 0, this greater than t will be possible if it has been continuously; that means, if x t prime is i for all t prime in the interval s to t plus s. So, at time s it started it entered the state i and now you want to know for how long it will continue in that state; that means, for all values of t, out of t prime between s and t plus s this value should continue to be i right.
So, this is the kind of random variable we want to. So, the amount of time the process spends in state i. So, these are the important thing and we have just now said that, and we say that this is the Markovian property with stationary probabilities implies that probability i greater than t plus s given t i is greater than s is same as probability i greater than t right.
Because I can take s to be 0 and then this will simply be that initially it is state 0 and then now, it is in continues to be state zero. So, the probability oh in that case yeah, amount of time the process spends in state i.
So, I will take the time as to be 0 sorry, that is not the state. So, s is 0 then simply you started in state i and so it will be it will be independent of when you are considering this probability. So, as long as, so that means; only that duration of occupying the state i, that is important it does not matter. So, does not matter at what point of time you are considering this. So, essentially this just means that the process has been in time in state i for time t. So, therefore, this is now, this will be; that means, t i is memory less.
So, the kind of continuous; that means, when you take the continuous process and you impose the Markovian property then it actually translates to saying that this random variable t i is memory less. And if now you remember of course, we did not prove this part when we talked of exponential distribution negative exponential distribution.
We said that exponential any random variable, which has a negative exponential distribution, is memory less. And exactly this property; that means, t i would be, because the course level was such that, I could not prove the reverse thing that any distribution having memory less property has to be negative exponential. I did not prove that part, but may be later on some time when you do an advance course we can see how that property proved.
So, in many cases since this is the Markovian process memory less. So, therefore, t i will have a negative exponential distribution. So, now, I will be describing to you talking about Poisson processes and the birth and death processes very interesting. And they also you know model lot of situations and practical life. And you know, lot of process is you can show how this property approximately of course, you cannot say that you can always model the real situation very accurately.
So, we will be talking about and so… Then see I will be referring to birth and death processes as m m 1. So, it will be that you know the arrival process is Markovian and the departure process. So, suppose you are in a situation. Suppose you are at a counter at a bank counter or at a post office counter and you want to people are coming in and then they get serviced and then they leave the system. So, you want to model that situation. So, here you describe such process by m m 1 property which means that you know the arrival process. So, you can actually show that if the arrival pattern is Poisson then the inter arrival times will be exponential. And so the interval arrival times have a Markovian property then the service times will also be shown to be under the condition of course, the condition that we will impose will be things under the service times also follow an exponential distribution. So, we will call it m m and then 1 server.
So, this is the connection and therefore, you see that why it was very important that talk about discrete Markov processes. And then continuous Markov processes which again have the same property, Markovian property in this case can again be written down as this. And this will be the memory less property which implies that the t i has a negative exponential distribution.
So, the birth and death processes that we will consider will have the same under this (( )) we will consider the birth and death processes where the arrival inter arrival times have follow Markovian have a negative exponential distribution, and the service times also have a negative exponential distribution. So, then we can very easily describe the system to be m m 1 with 1 server. And of course, you can also consider more than 1 server, and we will derive lot of interesting results for the parameters related with such distributions.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian institute of Technology, Kanpur

Lecture - 32
Poisson Process

 (Refer Slide Time: 00:14)
 
So, while talking of the Poisson process I said we have to first talk about a counting process, and so we said that there should be some norms for the, have to be followed for the counting process. And so the first one is that it should have independent increments; I should underline increment, independent increments. So, that means, that the number of event that occur in disjoint intervals are independent. 
So, that means, say for example, if you are saying that up to 8 am you are counting the time, then n 8 would be the number of events that have occurred up to time 8. And so that n 8 will be independent of say, for example, the number of events that have occurred in the between at 8 and 10 am. So, that means, n 10 minus n 8. So, both these are random variables, and so we will assume because the intervals are disjoint this is up to 8, let us say 0 to 8, and then this is from 10, 8 to 10. 
So, the 2 intervals are disjoint, and therefore we except we want that these 2, the number of events, that means the corresponding random variables must be independent. Now, for the, for example a, that I see, I gave you 3 examples of counting processes; first one was you know arrivals at a post office. And so example a, this may be a reasonable assumption because we may assume that people as long as the, for the time that the post office is open, people will come in any time. And so people coming say, between say, upto from, if it is open from 8 am, then 8 am to 10 am, the number of arrivals and the random variables indicating the number of arrivals, and say between 10 and 12 the arrival, the random variable, 2 random variables giving the number of arrivals in these disjoint intervals are independent.
Now, for b, which is the number of births in a particular town or a this number of births between time t and t plus delta t suppose we are taking, will be large if M t is large. So, that means, at, if you taking it over a long span then at a particular time when the people, population is large then the number of births will be large. So, here it will depend; that means, it does not seem reasonable that N (t) is independent of N t plus delta t minus N (t) for any t. 
(Refer Slide Time: 02:51)
 
So, it will depend, see, this will depend on the number of births that occurs if you are taking upto; or, in the sense that you are saying that the random variable N (t) and the random variable N t plus delta t minus N (t) need not be independent, if you are, ok. Now, for example, see, it would be a reasonable assumption. So, this example c, refer to the number of goals that are hit by a hockey player. 
So, here again if you take the time spent to be one season of hockey tournaments. So, during one particular season we expect the hockey player to be either to have continue to have a good form or not have a good form. See, if he has a good form then he will hit number of goals hit by him upto time t, or from t to s, t to s plus t, should be, the 2 random variables should be independent. So, the time spent is important, right. If I take the time spent to be 2 years then certainly it will matter because one cannot maintain a form for, let us say, upto 2 years or 5 years; so time spent. So, if you restrict your time spent then c would be a reasonable assumption. For c, the independent increment assumption would be reasonable. 
The other important assumption for counting process is stationary increments, right. Now, here what we are saying is that the number of increments the, that occur should depend only on the length of the interval. So, here, for example, if you having (s, s plus t) then the length of the interval is t; so it will not matter what value s takes, as long as the interval time has length t, then the number of increments that occur during this interval is just dependent on the length of the interval, right.
Now, here, we can again see whether the counting processes that we wrote down is that reasonable assumption for all those counting processes. For example, for a, it is not a reasonable assumption, why? Because, for a post office, and even, similarly you can consider a bank, there may be a rush hour. If there is a rush hour then certainly you cannot say that this and this are independents. 
If this is the rush hour then, you know, that there will be more arrivals, and so the random variables n 8 and n 10 minus n 8 would not be independent. So, if you have the concept of rush hour, but if you sort of ignore the rush hour and then you look at the counting process for a post office then this may be, assumption of stationary increments may be a reasonable assumption. 
Now, again for b, it may not be a reasonable assumption. In this case, some sort of pattern has been observed in the number of births. See, somewhat times more babies may be born then during winters, and so again, if the, some pattern has been observed in the town that you are considering, then again b may not be, because it will not follow the assumption of stationary increments. 
So, the, it will matter if your time span is during summer, so then, for the same period more babies may be born as opposed to the time span this is during winters. So, for the same length of time, the 2 may not be, the number of events in the interval has the same distribution for all s. So, it may be different distributions. 
Then again for c, it will be a reasonable. Here again, if you are saying that if the person, if the, if the player if the hockey player is involved then surely the number of goals that he hits will depend on the length of the time that he is played. And so it will have the same distribution, and will depend, only the distribution of the number of goals that he hits would be dependent on the length of the interval, and not on the, when he hits. 
If I am again restricting myself to, let us say, 1 season or may be 2 seasons, if that is considered to be reasonable that a person will continue to be in form for a player will be continue to be in form for 1 season or 2 seasons, maybe sometimes, it depends; whatever the way to look at it in that case the stationarity increment assumption would be reasonable one for c. 
And, this is what I am trying to say is that you have to, before you start applying, modeling a situation, for example, a particular counting process, you have to see that certain basic assumptions are satisfied. And in that case, you can, you know, then we will see that based on these 2 assumptions we can now talk about the Poisson process. So, these are the 2 basic assumptions under which we will now formulate our this probabilistic model for counting, for the counting process, and which is which we will define as the Poisson process. 
(Refer Slide Time: 08:25)
 
So, after having defined counting process, now I would make a definition of a Poisson process. So, what we are saying is that the counting process N (t), t greater than or equal to 0, is said to be a Poisson process if its satisfies the following conditions. So, as we said that we start the counting from time t equal to 0. So, n 0 is 0, then this has independent increments which we already said that while we define the conditions for a counting process. And then, we said additional properties were has independent increments. Then 3 is, that number of event that occur in any interval of length t has Poisson distribution; see, this is thing. 
So, therefore, we are saying that it will be a Poisson process. The counting process will be a Poisson process. If it the number of event that occur in any interval of length t has Poisson distribution with mean lambda t, where lambda is some constant, positive constant. So, that means, what we are saying is that because the interval of length is t, time interval is of length t, so therefore, probability of N s plus t minus, N s equal to n. 
Because, what we are saying is that the number of events that occur in this interval, s plus t, s, ok, we can say that the length of the interval is t equal to n will be, e rise to minus lambda t, lambda t rise to n upon n factorial, n varying from 0. So, this is your probability for any value of n, here integer value of n, right. So, now, since we are, since this probability is only dependent on the length of the time interval that is t, it is not dependent on when the counting process is started, the beginning of the interval. 
So, therefore, you can immediately conclude that the process that we have defined also has the stationery increments property, right, which we said that it does not matter, it is only the number of events that occur which depend on the length of the interval and not on when you started counting. So, therefore, this would be a Poisson process, that is what our definition is. 
So, now let us just look at this definition. And see you can, of course, condition 1 is defined that simply says, that counting begins from time t equal to 0, which we have been saying repeatedly. Then, 2 can be verified from the knowledge of the process that it has independent increments whether it is a valid assumption or not for the process that you are trying to model, then you can tell from the knowledge of the process itself, right. 
Now, 3 says, that the number of events that occur in an interval of length of t, has Poisson distribution. So, it is not clear how to verify 3. And this is the whole thing; I mean, if I am calling a process a Poisson process then I am just saying that the number of events that occur here follows a Poisson distribution. So, it is not clear; and therefore, this definition is not very implementable decision, or, you know, you cannot really verify this condition because, right. 
(Refer Slide Time: 12:00)
 
So, therefore, alternate definition is needed to determine whether a counting process is a Poisson process or not, we would be wanting to have another definition which hopefully would be a more easily implementable or verifiable, that a given counting process is Poisson or not. So, let us see. So, here we will say that can the same mean lambda t, if it satisfies the following conditions. So, counting process is said to be a Poisson with mean lambda t, if it satisfies the following conditions. 
So, this is same as for the first definition, N (0) is 0. Now, what we are saying here is that probability N (h) equal to 1; that means, in the time interval h your probability that N (h) is equal to only one arrival takes place, 1 event occurs. This should be in this form; that means, lambda h plus order h. Now, this, of course, means that your function here is of value of high order than h, when you say, this is higher order of h. So, this is linear; that means, the terms here would be square, cube powers of h. 
In other words, you can say that what this means is, that limit o (h) upon h, as h goes to 0, is 0. So, therefore, you know, this is of higher order than h, square, cube. For example, if you take o (h) to be h square, then h square upon h, limit of this as h goes to 0, is 0. So, this is the idea; that means, higher order terms here so this. And so what we are trying to say is that you can always discretize the occurrence of the event. 
That means, if you take, if you make the interval h small enough, then you know, there will be the probability of an occurrence of an event is positive in a small interval. So, therefore, you can discretize. And the second one, I suppose, ok, this is third condition. The second of course, is the same as that one, that process has stationary and independent increments. So, these 2 properties we require for the counting process to be able to say that it is Poisson process, right. So, this is has to be satisfied. 
Now, this one tells you that the probability of the occurrence of event in a small interval is dependent on lambda and that you can separate out the. So, in other words, the, you know, bunching of occurrences of events is not permitted here. That, probability N (h) greater or equal to t, is of order h. So, that means, when h is small, this probability is really very small; of 2 or more events occurring in a very small interval of time h, so that is of order h. 
And, since I have told you that this means the higher powers of h then linear; so therefore, this would be, you know, when h is very small, this also be very small. So, given lambda positive, same lambda we are saying here; when I say this, that means, it is understood that lambda is greater than 0 here. So, this is the alternate definition. 
And, let us now see that obviously, when we are saying that this also describes a Poisson process, that also describes a Poisson process, there should be, we should be able to show that the 2 definitions are equivalent, right. So, I will do it, 1, both ways. I will first show that definition 1 implies definition 2, and then show you the definition 2 implies definition 1. And this is very interesting and nice, simple. 
So, here, see we start with this. Definition 1 says that probability N (t) plus s minus, N (s) equal to n is, e rise to minus lambda t, lambda t rise to n upon n factorial, and varies like this, right. Now, put s equal to 0, t equal to h, because this is for all s, t; and n equal to 1, in this equation; then you obtain that probability N (h) equal to 1 because this is 0; t is h, s is 0. So, N (h) equal to 1 is given by e rise to minus lambda h; then lambda h rise to n is 1, and this is it, right. 
Now, just expand e rise to minus lambda h, that will be 1 minus lambda h plus, lambda h whole square by factorial 2, and so on, multiplied by lambda h. So, when you bring lambda h inside, this would be lambda h plus, all terms will be of higher order because this will be square, h square; this will be h cube, and so on. So, I can write in this way, and which satisfies, right.
So, that means, your condition 3 implies, condition 3 here, for the definition, second definition. And similarly, it is also implied from here because when you want to compute this probability N (h) greater than or equal to 2, this will be 1 minus probability N (h) equal to 0 minus, probability N (h) equal to 1. So, N (h) equal to 0, since your definition is saying that when N is o, the probability is e rise to minus lambda h, that is all, right, because your N is 0; so that is e rise to minus lambda h. And this is probability N (h) equal to 1, we have just computed is this thing. So, minus lambda h and order, minus or plus does not matter, whatever. 
And now, you see, when you expand this because this would be 1 minus, of 1 minus lambda h plus lambda h whole square by, 2 factorial minus, lambda h plus o (h) right. So, then 1, see, you have a minus sign here, so this becomes plus, right, because minus and then 1 minus lambda h; so therefore, this is, 1, 1 cancels out; lambda h minus lambda h cancels out; and you are left with something because this is order h. So, order higher than h, and this is also o (h). So, therefore, the whole thing is o (h), right. 
So, you can see that definition 1 implies definition 2. And now, we will show you that definition 2 implies definition 1. And you see that this, then we would most of the time we are working with this definition of the Poisson process. 
(Refer Slide Time: 18:27)
 
So, let us see; we will try to now show that definition 2 implies definition 1. And of course, then we will talk about inter arrival times later. But, you see here, probability n (t plus h). So, this is, I am saying is the, probability of N (t plus h) is equal to n, this is what we are saying, what we mean by this. So, this is the new notation I have started; so p n (t plus h), that means, number of arrivals are n in, upto time t plus h. 
Now, this can be thought of as, n minus 1 arrivals upto time t; and then 1 arrival at, within the interval h, right. That means, see, from t plus, upto t plus h, you want n arrivals or n occurrences. So, upto t, if there are n minus 1 occurrences, then in the interval time length of h you want 1 arrival. And according to our definition 2, this is the probability of 1 arrival in the time interval h, length of interval is h, right. 
And, since we are talking of independent increments, so this will be product, that means, I can say this; plus, there is no, that means, there are n arrivals upto time t, and there is no arrival in time length h, this is what; and, this will be probability n h equal to 0 which follows from 3 and 4. See, 3 said that probability of 1 arrival is 1 plus, is lambda h plus order h, right; and, probability n h greater than or equal to 2, was of order h, right. 
Now, when you say that there is no arrival, then that means, you want 1 minus probability n h because, right; you want this to be; so if you take the complement, so then, n h greater than or equal to 1, would that be ok? See, if you want n h equal to 0, I, in time, so that means, arrivals have 1, 2, and so on, in the interval h; so 1 minus of that will be, right. So, therefore, yes; so this would be then 1 minus lambda h because this o h and this is lambda h plus o h, so therefore, this is what you have. 
So, therefore, probability of n h equal to 0 is 1 minus lambda h minus order h. So, again independence of events, independent increments, so this will be p n t in to this, right. So, this is how you can describe n events in time upto t plus h, by breaking up the event into number of arrivals upto time t, and then n minus 1, one arrival in time h, or n arrivals upto time t, and no arrival in time n h. So, this is how we will write it down, right.
And therefore, this will be, if you simplify this expression, p n t is coming from here plus, lambda h p n minus 1 t minus, p n t, right. So, this is it plus, all terms are of higher order of h, right. Now, just rewrite this. This is p n of t plus h minus p n t, divided by h, so that will become; I have divided by h here, so lambda times p n minus 1 t minus p n t. And this is order h upon h. 
Now, when you take the limit you can immediately see that when you take the limit as h goes to 0, this will be limit as h goes to 0 of this, and here this will be lambda, this is independent of h, and this we have seen will go to 0, right; order, higher order of h means that this limit is going to 0, right. So, this is what you have. And then this is nothing but the derivative of p n t. So, this will be the derivative and this is equal to lambda p n minus 1 t minus p n t.
Now, so this is valid for n varying from 1 because you have this n minus 1. And d p 0 t upon d t is minus lambda p 0 t, because when you are looking at n equal to 0, see from here, then you do not have this; you simply have this, right, p n t because I should have n equal to 0, and right, so it will be; if you want me to write it down separately, see here becomes crowded. 
So, this will be, p 0 t plus h is p 0 t; so no arrival upto time t, and no arrival in the time intervals, so 1 minus lambda h. Remember, I can ignore that term because that will anyway go to 0. So, then this will be p 0 t plus h minus p 0 t, divided by h. So, limit of this, as h goes to 0, it is not legible, but you can, I am talking loudly, so you can hear. So, this is equal to p 0 t minus into lambda, right. 
So, this, therefore, this is derivative, d p 0 t upon d t is equal to minus lambda p 0 t, and so you, this much knowledge you have about the differential equations. So, here, from here it follows that p 0 t is e rise to minus lambda t; and so you have these 2 sets of differential equations. So, here the solution is immediate, and this is n from 1 to t. So, if you put like, for example, n equal to 1, it will be d p 1 t upon d t which will be from here, minus lambda p 1 t plus lambda e rise to minus lambda t. 
Because, I am putting, substituting for p 0 t. See, when n is 1 this is p 0 t, which is e rise to minus lambda t. So, therefore, this is it, right. Now, of course, there are methods to solve these differential equations are difficult, but what we are saying is that you, if you just try p 1 t equal to lambda t e rise to minus lambda t, it will satisfy this equation, right. Just differentiate and substitute here, the 2 sides will be equal. 
So, p 1 t is the solution here. And then, in general, the solution would be p n t you can very easily verify that you know, for all values of n this is the solution to all general differential equation that you obtained here. And this is nothing but as I have said by definition is that. p n t is nothing but probability of n t equal to n; so n arrivals upto time t. So, therefore, you see all other conditions remain the same in the definition 2 and 1 this was the only thing.
Because we were not sure how we would go about verifying in definition 1 that the number of arrivals in time interval of length t will follow Poisson distribution. So, now, using these properties, you know, probability of definition, of number of occurrences in the time interval h, by now given those, the third and fourth condition of definition 2 help us to show that the number of arrivals, probability of number of arrivals upto time t would be follow a Poisson distribution. 
So, a nice way of showing that and because, see therefore, definition 2 is easier to verify, we feel because that you know, to digitize and so on, you can sort of approximate the condition 3. Actually, that is the important 1 in definition 2, and then that is probability of 1 occurrence in time interval length h is of this order that you can supposedly easily verify, there are methods to do it. 
So, therefore, most of the time we would be, would now else we have established the equivalence of definition 1 and 2; it does not matter whichever you feel, when needed you can use it in your; you know, when you are trying to analyze certain results, and, or obtain certain probabilities, ok. 
(Refer Slide Time: 26:52)
 
Now, as I have written there, inter arrival times we would now like to look at the probability of, that means, the time. So, here, time between 2 occurrences, because again the occurrence is overall chance events are unpredictable. So, we want to now look at the, if it is possible to determine the distribution of these inter arrival times, right. We have seen that probability N (t) equal to 0 is e rise to minus lambda t. So, no arrival from 0 to time t, this is your. 
So, that means, upto, and if you define x 1 as the time of the first arrival, if the time of the first arrival, and then if I want to compute the probability that x 1 is greater than t; that means, that there has been no arrival in the intervals 0 to t. So, no arrival from 0 to t is the event that N (t) is 0. So, the 2 events are the same; that means, if the first arrival has not occurred, the time for the first arrival, see x 1 is the time of the first arrival. So, if the first arrival time is greater than t; that means, in the intervals 0 to t, no arrival has taken place which implies that N (t) is 0. 
So, the 2 events are the same, is just that here we have defined the random variable N (t), and here if the random variable x 1. So, therefore, and this probability is e raise to minus lambda t. So, if somewhere I have written that this event can be taken as x 1 greater than or equal to t then this is not correct. Because, you are saying that the time of the first arrival is greater than t, so it cannot be. 
Or, if you are saying that N (t) is 0 then this is equivalent to the event that x 1 is greater than t; it cannot be greater than or equal to t because, in the time 0 t no arrival has taken place. So, any arrival that takes place will be after t. So, this is the important thing. And therefore, 1 minus f of x 1 t; so this is 1 minus of f x 1 t, if f is the cumulative distribution function for x 1. So, then this is equal to e rise to minus lambda t; and so f x 1 t is 1 minus e rise to minus lambda t. 
So, this gives you the; and so that shows you that therefore, your f x 1 will be lambda e rise to minus lambda t. So, if you if you differentiate this equation on both sides you will get, lambda e rise to minus lambda t. Now, this is exponential distribution, exponential lambda. So, the distribution of x 1 is exponential lambda; and therefore, the expectation is expected value of x 1 is 1 upon lambda. So, this tells you what? That, you know, 1 upon lambda is the, you know, the mean, mean time of, you know, first arrival, right. 
But, actually, now if you look at x 2; x 2 is the elapsed time between the first and the second arrival; that means, here the first arrival occurred here, and the second arrival occurred here. So, I am calling this as x 2. So, that means, if this is x 1, so the time of the first arrival is x 1, then time of the second arrival will be x 1 plus x 2 because this is inter arrival time. So, x 2 is the time between the first and the second arrival. 
So, for example, so now, if you look at, that is why I have defined here. This is the elapsed time between the first and the second arrival, or second occurrence; I keep calling arrival, but which also means occurrence. Now, if you want to look at this probability t 2 greater than t, condition that t 1 is s. So, the first arrival took place, we are writing t 2, t 1, but here I have been writing x 1, x 2. So, it does not matter; you can make it x 1, and you can make this as x 2, because this is x 2, so x 2. So, therefore, this will be probability n s plus t minus n s is 0 because this second arrival is not have, has not taken place upto, I mean, this length is not is bigger than t. 
So, therefore, s plus t will be this. So, n s plus t minus n s is 0, given t 1 is s. So, therefore, probability n s plus t minus n s is 0, is e rise to minus lambda t. So, this is again, see this will also be 1 minus f x 2 (t), and therefore, you can again see that it will be exponential. So, we will continue with the, you know; so the inter arrival times are all exponential and that you can relate it with the memory less property of the exponential distribution which comes to your independent increments. So, the 2 things are related. 
(Refer Slide Time: 31:51)
 
In this exercise 8, I will be going over some problems related with the liber theorems that we had done, and also the Poisson process that we have talked about after that right. So, X 1 and X 2 are, question 1, X 1 and X 2 are independent random variables; X 1 is binomial n i, p, i 1 to 2, right. So, X 1, that means, is binomial (n 1, p), and X 2 is binomial (n 2, p). So, use m g f s to find the distribution of X 1 minus X 2 plus n 2. 
So, here, you see, all that you have to show is, yeah; so basically these 2 problems are on the, you know, m g f s joint density functions of random variables, and then add also introduce the concept of m g f for more than 1 variable. So, now, here you see, you can rewrite this X 1 minus X 2 plus n 2 as, X 1 plus n 2 minus X 2. So, since X 2 is binomial n to p, your n 2 minus X 2 will become binomial n 2, 1 minus p, right, is that clear?
Because, you see, the when you consider n 2 minus X 2, so if X 2 has r successes, then x, n 2 minus x 2 will have n 2 minus r successes. So, it will be; so therefore, the, for n 2 minus X 2, the successing of X 2 would be failures here. And therefore, your, see the, at the probability for a failure is 1 minus p. So, that is all. So, once you recognize that you can write this as, X 1 plus n 2 minus X 2, then n 2 minus X 2 is binomial n 2 n 1 minus p. 
So, once you know this then you can immediately began, and then they will be independent. So, therefore, because X 1 and X 2 are independent, so X 1 and n 2 minus X 2 are independent, and therefore, you can write down the joint m g f. So, you should be able to do it, right.
Now, question 2, X 1 and X 2 form a bivariate normal random variable; I mean, they are bivariate random normal variables with parameters new 1, new 2, sigma 1 square, sigma 2 square, and row. So, row is your co relation co efficient. Show using m g f s, that Y and Z, given by, so Y is defined as X 1 minus new 1, and Z is defined as X minus new 2 minus row into, sigma 2 upon, sigma 1 into, X 1 minus new 1. So, you have to show that these 2 random variables are independent, and that Y and Z are each random normal variables.
Here the idea is to use m g f s, but actually there is a easier way. And surely, to be able to do this problem using the m g f s, I leave it as a challenge, and maybe when I am discussing, you know, set of miscellaneous examples, we will revisit this. But, right now, way to do it is, see, because Y is X 1 minus new 1, so this will continue to be normal remember, because X minus new 1, the mean of Y will be 0. 
Variance will be the same, because by shifting the mean of a random variable the variance does not change. So, therefore, Y is again normal which means 0 and variance sigma 1. And similarly, Z is also, this should be X 2 here that is missing, so X 2 minus new 2. So, here again you have shifted the mean of X 2 by this quantity new 2 plus row into sigma 2 n; of course, this is the full idea. When you write Z like this, so X 1 minus new 1 upon sigma 1, that is the, because you are computing the; so this is the whole idea. 

(Refer Slide Time: 35:56)
 
So, here again, the mean has been shifted. And therefore, z is also normal with the same variance sigma 2, and the mean would be well; so by definition of z, we see that z is the random variable which is given by a conditioning x 2 on x 1. And we had to, while computing the conditional p d f s, we have seen that this will also turn out to be normally distributed random variable. And you can immediately see that the mean of z that is the expected value of z is 0 because expected value of x 2 is new 2 and expected value of x 1 is new 1. So, when you take the expected value of z, it will turn out to be 0, right. 
So, therefore, we need to compute the variance. And the variance will simply be expectation of z square. So, which I have done here, by writing down the expectation of the square term, and then taking expectation inside as we can do it, and therefore, it will turn out to be 1 minus row square upon sigma 2 square. So, this is the variance. Now, when you want to define the co variance then it will be y comma, co variance of y, z. So, that will be expectation of x 1 minus new 1 into, x 2 minus new 2, minus row sigma 2 upon, sigma 1 into x 1 minus new 1, right. 
And again, here we can take expectation inside. So, this will be expectation of x 1 minus new 1 into, x 2 minus new 2; and then, minus row sigma 2 upon sigma 1, expectation of x 1 minus new 1 whole square. And expectation x 1 minus new 1 into x 2 minus new 2 is the covariance the correlation coefficient row into, sigma 2, sigma 1, right. Because, expectation of x 1 minus new 1 into x 2 minus new 2 is the covariance, and, so that can be written as row into sigma 2 sigma 1. 
Then, minus row sigma 2 upon sigma 1 into expectation of x 1 minus new 1 whole square is sigma 1 square. So, therefore, when you substitute that value you turns out to be 0. So, y and z are uncorrelated. And now, we use the result that for norm, if y and z are normally distributed then being uncorrelated is equivalent to their being independent. So, therefore, y and z are independent, right. 
Question 3 is, from an urn containing 10 identical balls numbered 0, 1 to 9, n balls are drawn with replacement. So, the, draw a ball, and then put it back, you just notice the number. In the following, let us occurrence of 0 on a draw mean that the draw yields a ball with number 0. So, draw whenever the occurrence of 0 means that you draw a ball, you notice the number or you note it down somewhere, so if it is 0 then it is a draw. Means, that the draw yields a ball with number 0, and then we put the ball back, right.
Now, what is the weak law of large numbers assert about the occurrence of zeros in n drawings? So, the mean is 1 by 10 because they are identical balls. So, the probability of drawing any ball is equally likely with any of the numbers, 10 numbers is equally likely. And therefore, the weak law of large numbers will say, that if s n is the number, see we are denoting by s n the number that number of balls that showed up with number 0, right. 
So, then s n by n is the relative frequency. So, out of the n draws, you have s n balls have shown up with number 0. So, s n by n, as n goes, is becomes large, will converge to 0 in probability, will converge to 1 by 10; the mean is 1 by 10; so will converge to 1 by 10 in probability, that is your weak law of large numbers. So, s n by n will converge to 1 by10 in probability. 




(Refer Slide Time: 39:48)
 
Now, b part is, how many drawings must be made in order that with probability at least 0.95, the relative frequency of occurrence of zeros will be between 0.09 and 0.11. So, that means, you are wanting to know. So, s n by n is the relative frequency, you want to compute this probability that the relative frequency is between 0.09 and 0.11. And this probability should be atleast 0.95, right. 
So, therefore, now again I standardize the whole thing. So, this is s n by n minus 0.1, right; 0.1 is the expected value here, and so subtract 0.1 from either side, and so this finally, because the difference is 0.01. So, this is what you have. Now, establishes in the quality this number; this probability is greater than or equal to 1 minus variance of this s n by n which is because this is now binomial 1 by 10 into 9 by 10. So, 0 and nonzero that is how I am treating this is. 
So, p, q; p, q into 1 by n because s n by n, the variance, right. So, variance of s n is n p q and that divided by n square. So, this is 1 by n, fine. And so this into divided by. so in establishes the quality 0.01. So, therefore, we will compute the value of n when this is equal to 0.95; and, for higher values of n, it will be higher, right. So, therefore, now you have the equality. You can now get a equation for n, and you will get the value of n for which this probability would be between 0.09 and 0.11. So, you can do the rest of the problem.
Then, part c is, use a central limit theorem to find the probability that among n numbers thus chosen 0 will appear between n minus 3 root n by 10, and n plus 3 root n by 10, fine. So, here again you want this probability using central limit theorem, right; n minus 3 root n by 10, less than s n, less than n plus 3 root n by 10. So, then I, you see, n by 10 is the mean of s n. So, I write it here, this. And then, you see the variance; variance of s n will be n into 1 by 10 into, 9 by 10, right. Because, s n is now binomial with mean 1 by 10 and, sorry, mean n by 10 and variance n p q, right. So, this is this, and so under root of this will be 3 root n by 10; so 3 root n by 10.
So, when you divide, so now this becomes a standard normal variant, and so the central limit theorem says, that probability this less than or equal to, I mean, for n large enough, less than or equal to 1; you want to compute, approximate. So, this is the approximate probability which is 2 phi 1 minus 1, right. So, phi 1, the value is given to you at the end of the problem, and so you can compute this. So, this is good use of central limit theorem. 
(Refer Slide Time: 42:59)
 
So, now let us go to problem 4. An employee in a call center works from 8 a.m. until 5 p.m., with breaks between, 10.30 to 10.45, then from 12.30 to 11.30, and 14.45 to 15.00 hours. Assume that calls come in according to a Poisson process with expected number of calls per hour equal to 6. So, lambda probability that there are atmost 10 calls during the breaks. 
So, here the whole idea is, because you see, it does not matter for the, when the arrivals, the phone calls are coming by as a Poisson process, then the inter arrival time between the phone calls are, is exponential which is memory less. So, that is what you are using here. So, then what we can do is we can just add up the total break up, the break time which is 15, 1 hour and 15; so 1 hour 30 minutes right. So, therefore, 3 by 2 hours; and you want at most 10 calls during this 3 by 2 hours. 
So, therefore, you will have to write the probability, see you sum up; that means, the calls can be 0, 1, 2, upto 10. So, your lambda is 6 into 3 by 2; 6 by, 6 into 3 by 2 because 3 by 2 hours. So, lambda t, lambda t becomes your parameter now. And within this time, within the time 3 by 2 hours you want atmost 10 calls. So, you can write down the Poisson probability.
What is the probability that first call of the day is after 8.10 a.m. So, that means, for 10 minutes you do not want any call. So, 0 call. And therefore, again this will be; so your time would be, you have to see, since your arrival rate is given per hour, so you have to convert the 10 minutes to the, to fraction of an hour which is 1 by 6. So, therefore, it will be e rise to minus lambda t, probability that no call comes during the time 8 to 8.10 am. So, that means, 1 by 10, 1 by 6 into 6, which becomes e rise to minus 1 will be the probability, right. 
Actually, right, my idea is not to really give you all the answers, but just give you hints. What is the probability that the employee can do something else for 45 minutes without being disturbed by a call? So, here again we are repeatedly using the memory less property. So, 45 minutes can be anywhere; and therefore, you want the break; that means, now your time is 3 by 4 hour. So, you do not want any call to come in between for 3 by 4 hours, and your lambda is 6. So, you can do this now.
Now, consider a Poisson process with parameter lambda. What is the conditional probability that N (1) is n given that N (3) is n? So, here again, this is a good question in the sense that will again help you to understand the Poisson processes. Do you understand why this probability does not depend on lambda? Now, here you see, what is that you have to find? 


(Refer Slide Time: 46:14)
 
You have to find probability N (1) is n, given that N (3) is n. So, this means, probability N (1) is n. And see, actually you can interpret this as that N (1) is n, and then N (2) is 0, because N (1) is n and N (3) is also n. So, that means, for 2 prime periods, 3 minus 1, there has been no arrival, right. So, therefore, this is this, and then divided by probability N (3) equal to n. This is what you are having, right. And so and you are given, and your arrival rate is lambda, right. So, therefore, you have to write this, right. 
So, N (1) is the number of arrivals which is equal to n; n time 1 period and n time 3 period also you have given that n arrivals are there. So, that means, all the n arrivals have taken place between 0 and 1. And so there are no arrivals in the time 2, 2 units of time 0, right. And now. if you right out this, these probabilities, you see that the answer will be independent of lambda. And again I want you to work out the details. So, question 5 is over.
Question 6 is, jobs to be performed on a particular machine arrive according to a Poisson input process with the mean rate of 2 per hour. Suppose, that the machine breaks down and will require 1 hour to be repaired, what is the probability that the number of new jobs that will arrive during this time is 0 to; so that means, essentially you are asking for 1 hour gap; that means, the business of machine is takes 1 hour to be repaired. 
So, then in this 1 hour you want to know the probability of 0 arrival, 2 arrival, or 5 arrivals. And this is the Poisson process; and the mean rate is; so lambda is; so the mean rate is lambda which is equal to 2, right, 2 per hour. So, this you can, very simple problem; but again, I just want you to familiarize yourself with all these concepts, and therefore, I have done it here. 
Now, question 7, suppose you arrive at a single teller bank to find 4 other customers in the bank, 1 being served and the other 4 waiting in line, the statement is a little this thing because here it should have said 5 people, but anyway, 4 refers to the 4 people waiting in the queue, 1 is being served; and you join the end of the line, so you are the 6 person. So, if the service times are all exponential with rate new, what is the expected time you will spend in the bank?
 So, therefore, you see, this is 6 service times because 5 are already there, and because of the memory less property the person who is being served, again the probability of its completing, you know, so whatever service time is over is immaterial. So, therefore, 6 services have to be completed. And therefore, the completion time for the sixth person is a gamma distribution with mean 6 new; it will be 6, new, right; yeah, it will be gamma, 6, new, sorry.
So, it will be 6, new, and therefore, the, you know, what is the mean. The mean would be 6 by new. I think the mean should be n by new, right. If it is gamma n, new, anyway just verify that. So, you will find out the expected waiting time of the sixth person when he joins the queue in the bank. 
(Refer Slide Time: 50:20)
 
There should have been a, then this eighth one. So, cars pass a certain street location according to a Poisson process with rate lambda. So, a certain location in the, on the street, the cars are passing at the rate of lambda. And a woman who wants to cross the street at that location waits until she can see that no cars will come by in the next t time units. She has some idea that she is standing at this particular place, and then she looks at the side and sees that you know, for quite distance she cannot see any car coming then she will feel free to cross the street, right. And that time according to her is t time units, something like that. 
So, find the probability that her waiting time is 0. So, waiting time is 0 means; that means, she comes to the location, and then the probability that there is no car coming for the next t units, right. So, here again because your arrival rate is Poisson with rate lambda, so your inter arrival times are also exponential with parameter lambda. And therefore, you can find out the probability that her waiting time is 0; that means, no arrival in the time 0 to t. 
So, find out the Poisson probability that which is e rise to minus lambda capital T, right, no arrivals. And find her expected waiting time. So, now, you have this distribution, e rise to minus lambda t, as the probability that her waiting time is 0. So, you find out her expected waiting time. So, this you can now do by yourself. 
(Refer Slide Time: 51:58)
 
To answer the second part, that is what is the expected waiting time of the woman whose, who waits at the crossing for the cars to come. So, you will have to break up the, you will have to compute the expected value of the waiting time by using conditional probabilities. So, I will just write down the solution for you on the board. 
So, I hope, with all these hints, and almost the some of the problems have solved almost completely. So, anyway, I hope you will enjoy doing it. And I definitely will try to come up with the large list of interesting and challenging problems at the end of the course.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian institute of Technology, Kanpur

Lecture - 33
Inter Arrival Times Properties of Poisson Processes

(Refer Slide Time: 00:14)
 
I will just quickly again, go over through the go over the inter arrival times that we discussed in the last lecture. And then I obtained the distribution for inter arrival times. So, we already said, showed that fx1 t is lambda e rise to minus lambda t; that means, the x 1 denoted the arrival time up to the first, up to the first event that occurs. So, therefore, that is exponential, in the interval is lambda the interval for the first has exponential with distribution parameter lambda. Then, if you want to now, compute for x 2 then let us look at the probability x 2 greater than t when x 1 is equal to s.
So, here you see again the idea is that the first interval the first event occurred here. And now, so this was your x 1 now, this time is denoted b y x 2. And, we are saying that this is greater than t. So, if this time is greater than t; that means, there is no arrival in this time. And, so you are looking at probability x 2 greater than t, condition on x 1 being s. But since, we have shown already, that the inter arrival times are exponential. And, so they are memory less, and therefore it does not matter. See, this probability will remain the same whether it is here or here or anywhere. So, it does not matter, when the first event took place the probability the conditional probability is the same as the, probability x 2 greater than t.
So, this is the memory less property that we have already shown. So, therefore, this is equal to this, and here the same thing probability s comma s plus t 0 given that s 1 is s. So, therefore, this is equal to probability that there no arrivals in the time interval s comma s plus t. And, that probability is e rise to minus lambda t, is it ok? Because, here again the number that you the probability that you want to compute here, is that there is no arrival in this interval. 
And, so the conditional has no bearing on this probability also. So, therefore, this is e rise to minus lambda t, and here, this in term of your distribution function. You will write this probability as 1 minus F x 2 t and this is equal to e rise to minus lambda t. Therefore, if we differentiate both sides, you get f x 2 t is minus lambda e rise to minus lambda t.
So, this goes out and therefore, you have shown that for x 2 also the distribution is, exponential lambda. And now, repeated use of this argument because essentially we are using the memory less property. And, so the same argument can be repeated for x 3 x 4 and so on. So, we end up with this proposition, that when you take the sequence of inter arrival times these are identically, independently, distributed. Remember, we have assumed for the Poisson process independent increments, and stationary increments. 
So, therefore, these are inter arrival times are identically, independently, distributed exponential lambda random variables. That is, the process is probabilistically starts itself, which means its memory less. Every time, event occurs it starts itself again. So, there is no memory as to, when the last event occurred, it just starts fresh from after any event. So, when you start counting the inter arrival times, it rejuvenates itself again. Now, just a word about the parameter lambda. So, you see because this is exponential lambda. So, expectation of x I will be 1 upon lambda, and I mean the theory about exponential distribution does not say anything about lambda as long as lambda is greater than zero.
(Refer Slide Time: 04:26)
 
So, lambda can be any positive number. So, here before I come to that see a high lambda corresponds to a small average of waiting time. If lambda is large, then 1 upon lambda which is the expected value is small. And, so it is saying that this is the average of the inter arrival times so; that means, if the average is small, then the arrivals will be occurring in small intervals because the expected value is small.
So, when lambda is high it corresponds to a small average of waiting time between 2 consecutive occurrences. So, we were saying that when lambda has a large value the corresponding expected value will be a small number. And, so that would mean that the inter arrival times are smaller, in the small in the sense that the average is small. So, therefore, the arrivals are occurring at smaller intervals. And, in any case lambda is called the intensity of the process. 
So, there is no therefore, it simply says that lambda measures the, so if lambda is small then this will be big, so that means, the inter arrival time average is large. And, so the events are occurring at large intervals hence therefore, we are saying that lambda is called the intensity of the process also. And, lambda can be any positive number, but if we think of earth quakes in Indonesia say for example, and take 1 year as unit of time. Suppose, consider the process you know, if I am counting the number of earth quakes that have occurred, in a span of ten years say for example.
And, so if I take the unit of time as 1 year, then lambda should not be large because if lambda is large then what will it say that 1 upon lambda is small and therefore, it would mean that the earth quakes are occurring at smaller intervals of time, but we all know that the earth quakes of course, they are un predictable, but normally it does not happen that earth quakes occur very often. 
So, one has to be careful that is; why this interpretation of lambda gives you an insight into, how when you go about modeling a process? When how should your choice of lambda be made? Our also like, if you look at moments this, I mean again this is the time this 1 d when a radioactive material sends particles. Then the intensity is high, the intensity is high and therefore, this is small.
So, the particles spread radioactive particles spread very fast. And, so if you are counting at any point of this thing, how often the particle is arriving? Then the inter arrival times will be small, and therefore, this will be small. So, lambda would be high. So, just to give you an idea, and then you can look at many different examples, and see how the value of lambda will reflect the inter arrival averages. Similarly, you want to look at the parameter lambda t. So, lambda t is number of events. So, this is actually on the average the number of events in time t in time period t. So, this is your mean arrival rate.
So, now number of events in 2 disjoints time intervals are independent, just now we said that they are independent increments. So, therefore, if you look at the arrival in between 0 and 1, it is Poisson lambda. And this is Poisson lambda between 1 and 2 now; if you look at the time interval 0 2 then it will become Poisson 2 lambda. Because, again from now, by now we have by, so many different methods shown you, that if 2 random variables x 1 of course, here x 1 is Poisson lambda x 2 is Poisson lambda. 
Then x 1 plus x 2 would be again Poisson 2 lambda, the parameters get added. So, therefore, 0 2 would the number of arrivals, will be Poisson 2 lambda. So, therefore, in 0 t it will be Poisson lambda t, this is the whole idea. So, this is the important thing and therefore, in time 0 t we will say that the arrival rate is lambda t, Poisson lambda t, this is the whole idea, because t can be fractional and so on. So, 1 can again interpret in the same way now another thing is that since we are talking of stationery increments therefore, what we have to say is that; the arrivals over the time 0 t are distributed in a uniform way. 
Because, they are random 0 to t they are anyway random events such then when we are talking of number of arrivals for example, when I am counting n t this is the number of arrivals in time 0 to t, in the span time in the span of time 0 to t. So, then we have to think the way the process is being modeled, is that in this particular time period, the arrivals can occur anywhere. And, so the best way to model that is, that the arrivals are uniform in the interval 0 to t, and through an example again I will try to make you understand this concept a little better.
(Refer Slide Time: 10:11)
 
So, after computing the distribution function of the interval arrival time, let the another quantity of interest is s n, which is sigma x i, i varying from 1 to n, which means x n is the waiting time for the nth event to occur. So, because see you are adding up x 1 to x 2 to x n. So, x n is the time, when the n inter arrival time between n minus 1 and the nth event. So, therefore, s n will be the waiting time for the nth event to occur.
So, just added up all the see on the line, you have you are starting from 0 this is x one this is x 2 and so on. And finally, this is x n. So, at this point the nth event has occurred, right starting from here, this is the first event, second event and so on. So, at this point the nth event has occurred. So, this is the total time; that means, this the total time you are denoting by s n. So, which is you can say waiting time for the nth event to occur, for the nth you know the time the volcano has to erupt particular volcano or earth quake to occur, whatever process you are looking at, you can interpret s accordingly. Now, from independence of x i’s, and being identically distributed as exponential lambda. And here, again you see in the last few lectures we have been talking about, some of independent random variables, and through convolution through m g f s and so on.
We have looked at the distributions of sums of independent random variables. So, here it immediately follows, that s n is gamma and lambda. Because, here the x i’ s are identically distributed as exponential lambda, n of them you are taking some n of these random variables exponential random variables. So, the sum will be gamma, n comma lambda, and therefore, the p d f are the density function for f s n t is lambda, e rise to minus lambda t lambda t rise to n minus 1 upon, and minus 1 factorial for t non negative. So, this is the thing, but now again as I said it always helps to be able to use other tools that we have developed. And, so let us try to do it, and then of course, m g f again we has already been computed, for a gamma random variable is lambda upon lambda minus s rise to n. So, while writing m g f of s n the s got written by mistake.
So, it is actually m g f of s n, which will be lambda upon lambda minus s rise to n. So, the idea was that you were computing it at s. So, therefore, it got written there. So, this is actually lambda upon lambda minus s rise to n. Let us look at it in an alternate way, and that is also interesting. So, let us just be very clear about this n t greater than or equal to n if and only if s n is less than or equal to t, that is if the number of arrivals by time t greater than or equal to n. Then, the time s n for the nth event to occur is less than or equal to t and vice versa. That is if s n is less than or equal to t then it will imply that n t must be greater than or equal to n.
So, when you want to compute the distribution function of s n, this is probability s n less than or equal to t, which because the 2 events are the same, this is probability n t greater than or equal to n. And so since n t is Poisson distributed, a Poisson random variable with lambda t as the parameter. So, therefore, this probability can be written as sigma i varying from n to infinity e rise to minus lambda t, lambda t rise to i, upon i factorial. Now, let us differentiate this equation from both sides.
(Refer Slide Time: 14:18)
 
And, so on the left hand side this will be the p d f of s n, and now here, let us do it term by term. So, the derivative of this first. So, minus lambda e rise to minus lambda t, lambda t rise to i, upon i factorial, and then the derivative of this, which we are writing as. So, first function as it is e rise to minus lambda t in to, lambda rise to i remains as it is, t the power of t becomes, i minus 1 and then i factorial here, which you can you know cancel the i part here, then it will be i minus 1 factorial. 
So, and e rise to minus lambda t I have taken outside then this summation from n to infinity. So, I am not writing out many terms here, we just have to show you that you see, when you take n i equal to n, the term from here you will get lambda t rise to n upon n factorial. And, this will give to lambda rise to n, t rise to n minus 1, n minus 1 factorial. So, these are the 2 terms now, put i equal to n plus one. 
So, this will be minus lambda, lambda t rise to n plus 1, n plus 1 factorial, plus lambda n plus 1 t rise to n upon n factorial. So, you see this cancels with this, and then I thought, I will also write the values corresponding to i equal to n plus two. So, then that will be lambda, lambda t rise to n plus 2 upon n plus 2 factorial, plus lambda n plus 2, t rise to n plus 1, and n plus 1 factorial. So, that cancels out this. So, you can see the pattern first, and the fourth here then the third and the fifth sixth and so on. 
So, all these things will cancel out except this. Because, this is the lowest degree term after that the powers of t keep on increasing. So, this is the only 1 which is left out all these will cancel out. And, so you are left with e rise to minus lambda t into lambda, lambda t rise to n minus 1 upon n minus 1 factorial, same as 1, which is a gamma density function, gamma n comma lambda.
So, I just wanted you to sort of you know, make use of this also. And therefore, you can even do it directly. So, once when you generate, so many tools, it is always possible to prove result by more than 1 way, and it also helps gives you a better insight, if you can do that. So, then expected value of s n will be n upon lambda, and variance s n will be n upon lambda square. Now, we will further prove some more properties of the Poisson process, and then you know work out examples to show you how you make use of these all these machinery, that we have developed.
Now, for example, if you take a Poisson process n t, t greater than or equal to 0 then they can and they can be 2 sub processes. If you remember while discussing, the joint m g f I talked about Poisson process, and then I said, that if all the events that are occurring are being counted. Then they the probability of an event being counted was p, and event not being counted was 1 minus p. And then I showed you through the m g f, that each of them, each of these process again would be a Poisson. So, see while talking about the Poisson process, having 2 sub processes, which we call type 1 and type 2. And, so the probability that the type 1 would have occurrence with occur with probability p, and type 2 with occur with probability 1 minus p.
So, I have already. So, the only correction I want to make is that see here, you n t is lambda p t, because we are talking about with respect to t. So, then we are talking of arrival time arrival rate in the interval 0 to t. So, now, here similarly your n 1 t will be then Poisson, and this we showed through m g f processing of we showed that it can be both will be again Poisson. So, the sub processes n 1 t would be Poisson lambda p t, and n 2 the process type 2, which will be. So, the random variable is n 2 t will be Poisson lambda 1 minus p t. So, the we have to attach. So, what I wrote in the lecture was, without the t part everywhere here. So, this is what the correction is being made, otherwise I have explained, what we mean by these sub processes and so on.
In the lecture itself, so exactly the same thing, but here again I will do this, I will try to prove the same result by using the machinery that the definitions that we have made here. I will try to do that because the m g thing we know. So, here it is saying that the 2 types of; that means, you must be considering, let us say immigrants from another country, and the immigrants may be Hindus, Muslims whatever it is. So, therefore, the total process of immigrants coming from another country, may be a Poisson process and then the kinds of people that are arriving, you may want to separate them into 2 streams. One may be let us say Hindus, the other may be Muslims. So, there will be type 1 arrival and the probability of 1 of the arrival immigrants being Hindus is probability p, and the 1 minus p is the probability of the immigrant being Muslim.
(Refer Slide Time: 20:23)
 .
So, we will now, prove it in a different way, in an alternate way. So, as I said the proposition is that there is a Poisson process, and n t is the number of arrivals in time up to time t. Then if there is type 1 and type 2 processes, sub processes. And, so type 1 process; that means, the type 1 event occurs with probability p, and time and the type 2 event occurs with probability 1 minus p. We want to show that n 1 t is Poisson with lambda p as the parameter, and n 2, n 2 t is Poisson with parameter 1 minus p lambda. We want to show this. And as I told you, that we have already shown this result using m g f s joint m g f, but let me do it through. So, we will show that n 1 t, t greater than 0 this satisfies your definition 2, which remember we said is more easily verifiable.
And, so let us do it quickly since n 0 is 0, this implies n 1 is 0. Because your n t is n 1 t plus n 2 t. If this is 0 then both of them must be zero. So, n 1 is 0 now, the other part is that you know, independent and stationary increments. So, which can also be easily seen because if I condition this by fixing n t equal to n. Then, the arrivals here are also you know they only depend on the length of the interval, and are independent of, what is occurred before. So, that is the memory less. So, by conditioning also you do not change the independent increment, property and the stationary increment property. So, therefore, n 1 t satisfies both, now we just want to show that your probability n 1 h equal to 1. So, the property 3 should be satisfied.
So, let us just look at this event. So, if type 1 arrival in time h is 1 then ,we can write this break up this event as saying that n 1 h is 1 given that n h is one. So, total arrival is 1 and then n 1 is 1, and. so this will be condition this in to probability that n h, n h is 1. All probability n 1 is h and n h is greater than or equal to two. So, these are the 2 possibilities, because either n h 1 has is 1 or n h 2 is greater than or equal to two. So, this would be this into probability n h greater than or equal to two. 
So, I like the probe because just by basic definition of the process, we are able to show this result. So, here see n 1 h is p, and then probability n h equal to 1 is because n is anyway Poisson process. So, we already satisfy the definition. So, therefore, probability of n h equal to 1 is n h plus order h, this when given that there is 1 arrival. So, then n 1 h the probability is p plus now again here arrival n 1 h is one.
So, that probability is p and then n h greater than or equal to 2 n satisfies the condition four also. So, therefore, order h right and. So, this will be lambda p h plus order h because p see remember, when you say a function is of order like this, then constants are all allowed. Because, it is only the power of h which is important, it is higher power and. So, as h becomes smaller this goes to 0. So, therefore, that p gets absorbed here and therefore, this is it. So, this is what? 
So, therefore, this satisfies definition because lambda p is the probability now of arrival. So, therefore, this will be lambda p in to h, and this n 1 h is greater than or equal to 2 is satisfies. Because, this probability is less than or equal to probability of n h, greater than or equal to 2 right by the definition because n h is n 1 h plus n 2 h, and since, this is order h. So, this has to be also order h.
So, nice simple proof and I like it, of course, you we have already done it through the m g f method, but that was for a general situation. Now, here, we are doing it for a Poisson process. So, therefore, the type 1 and type 2 you can see if you have sub processes, and certainly if this can be extended to more than 2 sub processes. So, if you have more than 2 sub processes, each of them and of course, the some of the probabilities must add up to 1, which it will and therefore, you can say that all these sub processes will be independent. Now, how do I show that n 1 and n 2 are independent, that part is also there that n 1 and n 2 are independent. Once we have shown and similarly, by this similar by this similar argument you will show that n 2 h is also Poisson with parameter lambda into 1 minus p.
Now, you can now use the joint m g f method to show that they will be independent. So, this method I use to show that n 1 t will be Poisson with lambda p s the parameter. And, n 2 will be Poisson with parameter lambda in to 1 minus p, to show independence you can use the m g f method.
(Refer Slide Time: 25:52)
 
So, let us look at this example, suppose that people from Bangladesh migrate in to north eastern states of India at a Poisson rate of, lambda equal to five per day. So, the question asked is, what is the probability that the expected time until the 15 immigrant arrives? So, what is the probability that the expected time until of the expected time that the 15th immigrant arrives?
So; that means, you are asking for s 15. So, s 15 is gamma 15 comma 5 by the result that we arrived some time ago. Because, it will be x 1 plus, x 2 plus, x 15 and. So, that will be gamma 15 comma 5, and the expected value is 15 upon 5. Remember because this is gamma this is n upon lambda. So, this will be 15 upon 5, which is 3 days. So, the expected arrival time that the expected time until the 15 immigrant arrives. 
Now, what is the probability? That the elapsed time between the 15th and 16 arrival exceed 2 days. So, here you are asking for x 16, because x 16 is the inter arrival time between the 15th and the 16 arrival. So, you are asking for the probability that x 16 is greater than 2. And, that will be e rise to minus 2 lambda, again this is from your, this is from your exponential distribution. Because, when you have lambda e rise to minus lambda t, and if you are asking for this thing from let us say a to infinity. Then, this is, what lambda upon minus lambda e rise to minus lambda t a to infinity. And, so this is e rise to minus a lambda.
So, this is it. So, probability x 16 greater than 2 will be e rise to minus 2 lambda, which because lambda is 5. So, this is e rise to minus 10. And, I have just computed the value here, whether you can write this as e rise to minus 2 rise to 5, and e rise to minus 2. I knew the value is 0.133. So, we just rise it to 5 anyway now, if a Bangladeshi immigrant is a Hindu with probability 1 by 10 then what is the probability that no person of Hindu origin will migrate to north eastern region in the month of march. Just to show you the use of you know the, what we just discussed. So, here; that means, it is lambda p t. So, lambda is 5 p is 1 by 10 and the time is 31 days, March has 31 days.
So, therefore, the no Hindu will arrive in that period, again will be e rise to minus lambda t p, which is e rise to minus 31 by 2. And, so you can compute this number. So, this is the whole idea and then of course, we will look at some more properties of the poison process, and work out if you more examples.
(Refer Slide Time: 29:01)
 
Now, let us look at this example, where we are trying to compute the conditional distribution of n s, given that n t is n. So, given that n arrivals are there in time 0 t, and s is less than t. So, now, you want to look at the conditional distribution of n s, given that see through all these examples, I am just trying to familiarize you more with the working of the process, and the machinery that we are developing. This is the whole idea, and is the process that makes subject quite interesting. So, the solution is that and then the of course, it is been asked do you recognize this distribution, once you get once you obtain the conditional distribution, the question asked is, do you recognize this distribution?
So, you have given that n t is n, you have to find the probability, that n s is equal to k given that n t is n. So, now, that means, if up to time 0 s the arrivals are k, and up to time t the arrivals are n so; obviously, the number of arrivals in time t minus s is n minus k. That is, how it will make up the number of arrivals up to time t as n. So, time s the number of arrivals is k, and then in the interval s 2 t, which is the interval length. And, by now, we know that we just have to worry about the length of the interval, and not exactly, where that interval is occurring.
So, the number of arrivals in time t minus s is n minus k. So, when you write down this probability, probability n s equal to k given that n t is n. This you can write as probability n s is k and comma n t the joint probability of n of t minus s is n minus k. Condition on the n t equal to n, and since again from the dependent increment property for disjoint intervals, s in to minus s the probability can be written as the product of these 2 probabilities. So, therefore, this will be the product of these 2 probabilities, the numerator and the denominator will be probability n t equal to n. 
So, I suppose I hope this is clear. So, therefore, e rise to minus this probability is e rise to minus lambda s, lambda s rise to k upon k factorial, and this probability will be e rise to minus lambda t minus s. Lambda t minus s rise to n minus k upon n minus k factorial, divided by e rise to minus lambda t, lambda t rise to n upon n factorial. So, as long as this part is clear that when you see this probability of course, I can write in this way and in this I can write as the product of these 2 probabilities. 
And, so now, you see that this is e rise to minus lambda s, and here you get, e rise to plus lambda s, which cancels out. Then e rise to minus lambda t, and in the denominator you have e rise to minus lambda t. So, the e terms all cancel out, and you are left with. So, this n factorial will come in the numerator.
So, the first term that I have written is n factorial upon k factorial n minus k factorial, this all put together. And then you have lambda s rise to k, and lambda t minus s rise to n minus k, divided lambda t rise to n. So, this is what I have written here. So, this whole expression simplifies to this. 
And, now here what you can do is see again the lambda rise to k and lambda rise to n minus k is lambda rise to n, which cancels with lambda rise to n here. So, you are left with s by t rise to k now, the t rise to n, I can write this as k plus n minus k. So, the k t rise to k couples with this, which is s upon t rise to k and this here it will be 1 minus s upon t rise to n minus k.
So, see that now you can recognize this, if you treat p equal to s by t then this is a binomial probability, when we are choosing k items out of n; that means, you are asking for k successes out of n trials. And, n independent trials, and your probability of success is s by t. The more important thing is that this whole expression that the conditional distribution is independent of lambda; that means, no matter what the parameter of the poison process is these conditional this conditional probability is independent of lambda. It is only dependent on the length of the time intervals; that means, here it was n s and there it was n t. So, that s and t... So, I am sure there are many more interesting implications of this result, but again know you can get it nicely, by just using the definitions and so on.
(Refer Slide Time: 34:29)
 
Now, let me again take up this interesting optimization problem, and here again the machinery is not very complicated. Suppose that items arrive at a processing plant in accordance with a poison process with rate lambda, so that means the items are arriving at the you know, at the gate of the processing plant, and arrival process is poison with rate lambda. 
Now, at a fixed time all items are dispatched from the system. So, the items get processed and after if time t, when they all collect they are dispatched to they came. Now, the problem is to choose an intermediate time t, belonging to 0 comma t, at which all items in the system; that means, all the items which have been processed by time small t they get dispatched and then the remaining, which get processed from time t to T they will be after being processed they will be dispatched.
So; that means, they have now they are not going to wait till the end of up to time t. So, in between also they would like to dispatch the items, and the idea here is that this will this way, they want to minimize the total expected wait time of all items. So, total expected waiting time. So, this is what we have to write down the expression and then see how we minimize. So, the choice of small t; that means, the intermediate time at which you want to dispatch, whatever items have been processed, this is that has to be fixed that has to be sort of obtained by this process.
So, expected number of arrivals in 0 t is lambda t, remember because this is Poisson with parameter lambda. So, therefore, in time 0 t the expected value is lambda t. And, each arrival is uniformly distributed remember, I some time ago discussed when you are looking at the Poisson process, and it is properties and we said that because of the stationary increments, when the number of items that arrive in this time, they would be uniformly distributed, over the randomly distributed over the time interval 0. 
So, therefore, in time 0 t the expected any uniform variable distributed over 0 t has mean t by 2. So, the expected wait time is t by 2, all items which start getting processed from here till up to this. So, their expected wait time is t by 2, because we have said that the, you know, the processing is uniformly done. I mean in the sense that the processing is not uniformly done it is that is they arrival. So, is distributed the arrivals of these items is distributed uniformly in the interval 0 t.
So, their expected wait time is t by 2 because they will be dispatched by the end of this time period. Now, so total expected wait of all items arriving in 0 t is therefore, lambda t into t by 2. So, expected wait time of any item is t by 2. Because, they are uniformly distributed in this interval the items and therefore, for each of them the wait time is t by 2, and since the expected number of items that arrive in this time is lambda t. 
So, the whole thing is lambda t into t by 2, which is this. Now, the similar reasoning holds for items arriving in time t to t comma t, and therefore, for these items because they will get dispatched at time capital t. So, the total expected wait time will be therefore, lambda t square by 2 plus half lambda T minus t whole square. 
So, I hope this part is clear, and this reasoning is because expected wait time into the expected number of items that arrive. So, that gives me the total expected wait time of all items arriving in time, in the interval 0 t. So, to minimize that to find out the minimizing value of t, I differentiate this expression with respect to t, and I get lambda t minus because there is a minus here.
So, 2 is gone. So, lambda t minus lambda T minus t is 0. And, this gives me t equal to t by 2, as you would expect. Because, the arrivals are uniformly distributed over the time interval, and just to make sure that this is the minimizing value, you find out w prime t and w prime t will come out to be 2 lambda, which is positive. So, therefore, this gives you the minimizing value. So, therefore, it says that you dispatch whatever items gets processed, in the middle of the time and then wait for the others to be processed and dispatch them at t. Simple which appeals to your reasoning also, but then through this machinery also we have arrived at this result. 
(Refer Slide Time: 39:48)
 
So, before I begin, you know, talking about queuing models, I thought, I will finish off the lecture on Poisson processes with this example on exponential distribution. Because, it is somehow related and part of it. And, so and this would be the right place to talk about it, because we have talked off exponential of the Poisson process. And, we have talked of people expected number of people in the system and so on. 
And then because the inter arrival times had we have shown that each of them were identically independently distributed as exponential random variables. So, I thought this would be also this can be part of it. So, here the whole idea is that and of course, this is a simple example on the memory less property of the exponential distribution. So, consider a railway booking counter, that is run by 2 clerks suppose that mister Sharma enters the system he discovers, that mister Jain is being served by the clerk at 1 counter, and mister Varna is being served at the other counter.
So, both the counters are busy, when mister Sharma enters the system. Now, mister Sharma service will begin as soon as either mister Jain or mister Varna leave the system. That whenever as soon as 1 of them is completes service, they will, he will leave the system and then mister Sharma’s turn will come to be serviced by the clerk. 
So, if the amount of time a clerk spends with a customer is exponentially distributed, with mean 1 by mu; that means, the parameter of the exponential distribution is mu. And, therefore, the mean time that a clerk spends with a customer is 1 upon mu, what is the probability that of the 3 customers’ mister Sharma is the last to leave? So, of course, here mister Sharma will only get serviced once 1 of the customer is left.
So, the actual question is that when mister Sharma’s turn comes for being serviced there is 1 person 1 of mister Jain or mister Varna 1 of them is being serviced. And, so mister Sharma goes to the clerk for getting his job done, and then the idea is that who will leave the system first? So, suppose mister Jain is being serviced while mister Sharma goes to the clerk because mister Varna has left. So, the question being asked is, what is the probability that mister Sharma would still be in the system? When mister Jain leaves? So, essentially you are asking, who will be the first 1 to leave? Either mister Jain or mister Sharma mister Varna has already left.
So, but exponential distribution is memory less. So, therefore, how long mister Jain how long more, will mister Jain take is independent of? How long he has already been at the counter? Because we have said that it is memory less and therefore, the service gets completed is not dependent, on how long it will take for the service to be completed? It has not depend on, how long he has already been serviced and. So, therefore, its equally likely that either mister Sharma will complete his service, before mister Jain or mister Jain will complete. I am just assuming that mister Jain is still in the system mister Varna has left, but you can do it either way.
So, therefore, very simple you know use of the memory less property of exponential distribution. And, so therefore, the probability of mister Sharma leaving last is half, because it is equally likely, whether mister Jain completes his service first or mister Sharma completes his service, because of the memory less property. So, I thought this will just add to the Poisson process, and the other systems that we have been talking of birth and death process; that means, when you have people arriving at a service station, and then they are being serviced. And, so then we want to talk about, the you know number of people average number of people in the system then what is the average waiting time? And so on.
(Refer Slide Time: 44:15)
 
I would like to take this further because once we have been able to compute, you know arrivals, if we have been, we have discussed the Poisson process. One of the arrival processes is under these conditions that we have laid down. And, then now, we want to look at you know for example, you have a service center, and there you have people arriving for service.
 Then you have people providing the service, and then that process is also random. So, now, you want to combine these 2 and therefore, the whole the theory that you, when you study such processes is known as, queuing process. And, then you want to for example, know when you have a post office you want to know, because if the average number of people arriving in the post office is large, then you would want to 1 clerk may not be enough to serve everybody. And, you would and then facility how they should be and so on.
So, the very interesting question, but of course, we will study them at very basic level. So, it will be the queuing process is where you want to compute the average waiting time of a customer. You want to compute the average service time of a customer, then you want to look at the average number of people they are at any time there are in the system and so on. So, such interesting questions we would want to answer. And therefore, we will model the situation, where you have people arriving for service. Services are being rendered, and then people leave the system. So, the whole thing we would want to study, and this we will try to do in the next couple of lectures.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 34
Queuing Models M/M/I Birth & Death Process Little’s Formulae

(Refer Slide Time: 00:15)
 
So, I had to wait for this example, you know to discuss this example, because I had not worked on the when we talked of weak law of large numbers and strong law of large numbers, I have not, you know talked about the Poisson process. So, I waited till I had, you know introduce the topic of Poisson process to give you this example. In fact even when we are talking of law of large numbers I had shown you some examples. So, this is also one of them; one of interesting example. 
Now, here you see inter arrival times are exponentially distributed with mean 1 by lambda, right; because the arrival rate is lambda. So, we have shown that the inter arrival times will be exponentially distributed; and the mean time would be, that means, inter arrival time would be 1 by lambda. So, that means average waiting time between 2 occurrences is 1 by lambda; and so the number of arrival, mean arrival weight is lambda, right. 
So, hence in a time interval of length t we should expect around lambda t occurrences, right; if lambda is a mean arrival rate, so therefore per unit times. So, therefore, time interval t; you were expect on the average lambda t occurrences, lambda t arrivals, right. So, then and since our notation for the Poisson process for the number of arrivals up to time t is N (t). So, therefore, we expect that N (t) and lambda (t) should be close, and this is what the weak law of large numbers and strong law of large numbers is all about. 
So, let us just look at this, and we will show that, yes, the ratio of N (t) by, this will be N (t) by t would be close to lambda, right; because if you want lambda (t) to be close to, N (t) to be close to lambda (t) then N (t) upon t should be close to lambda; this is the whole idea.
(Refer Slide Time: 02:27)
 
So, let us look at the proof, interesting. Now here, I should have written the word proof here. Now, let t be some positive time, right; and then we want to show, I said it is the, we want to show that the limit of N (t) upon t, N (t) goes to infinity is equal to lambda. So, this probability is 1; that means, this is the certain event. So, as you take the limit and your law N (t) to grow large, then your ratio N (t) by t would be lambda. Now let us look at the proof. 
So, see, this is the thing; now for the Poisson process when we are looking at the arrival process, and so on, then my S n (t) is the movement of the N (t) th arrival upto time t. This is what we have been denoting. And later on when I discuss the death birth and death process at that time S n (t) was the, you know, time arrival, because remember I was looking at the waiting distribution for the waiting time in the q; and then I also used the symbol S n (t), but that time it was the waiting time for the n plus 1 th arrival; that means, S n (t) denoted the time at which the N (t) th service got completed, right. So, here it is S n (t) is the movement of the N (t) th arrival upto time t. 
So, I hope the reference to the context the things will be clear because here we are only talking of the, and I have not introduced the waiting time and so on, upto this point. So, therefore, it should be ok. So, S n (t) is the movement of the N (t) th arrival upto time t and therefore, S n (t plus 1) will be the movement of the N (t plus 1). 
(Refer Slide Time: 04:17)
 
So, the inequality that we are writing here, S n (t) less than or equal t less than or equal to S n (t) plus 1, should be actually replaced by S n (t) less than or equal to t and strictly less than S n (t) plus 1. Since N (t) th arrivals have occurred upto time t, and n S t is the time of the N (t) th arrival, and so therefore, when the S n (t), when the N (t) plus 1 th arrival occurs that will be the time n S (t) plus 1. So, that will have to be bigger than t. 
So, want to make that clear, and that is why this should be replaced by the strict inequality here; that is because we say that S n (t) is the time at which the N (t) th arrival is occurred, and upto time t; and so S n (t) plus 1 the time arrival for the N (t) plus 1 th arrival will take, will be more than t, right after t.
(Refer Slide Time: 05:21)
 
In that arrival; in fact, I would understanding is that, you know, N (t) is the max of n so that S n is less than or equal to t; so that means, upto time t we do not expect, there no more arrival then N (t); and therefore, this inequality is valid; that means, t is greater than are equal to S n (t), but if there is one more arrival then certainly that time will x e t; this is the whole idea, right.
So, upto time t, S N (t) is the number of, the movement of the N (t) th arrival this should be N, sorry; should write here is this is N; so that means, the time of the N (t) th arrival has to be less than or equal to t, but N (t) plus 1 th arrival will exceed the time t. So, this is the understanding, right. 
So, with this understanding you now divide the both the inequalities by N (t), and therefore, you get S n (t) by N t less than or equal to t upon N (t), this is less than or equal to S N (t) plus 1 upon N (t), right. Or, remember the x size are the inter arrival times. So, therefore, you, S n (t) will also be equal to x 1 plus, x 2 plus, x n t. So, when you add up the inter arrival times they will all add up your S n t. 
So, sigma i varying from 1 to N (t) sigma x i divided by N (t), and this is less than or equal to t upon N (t), then this is, this, here the summation will go upto N (t) plus 1. So, you will add up the inter arrival time for the N (t) plus 1 of the arrival, upto this thing. So, N (t) to N (t) plus 1 th, the arrival this will be this, right.
Now, sigma x i s are independent, remember we have shown this; we get the poisson process, Poisson arrival process; then the inter arrival times would be exponential distributed; and they are independent identically distributed, each has the mean 1 by lambda. So, then the conditions for your law of large numbers is, are satisfied. And therefore, by the strong law of large numbers, sigma x i vary from 1 to N (t) divided by N (t) will converge to 1 by lambda with probability 1. This is our strong law of large numbers. 
And since, this is also the same series, you know, N (t) plus 1, but you are allowing this go to infinity. You are allowing N (t) to go to infinity; so therefore, this and this have the same limit which is 1 by lambda, right, the mean of x i with probability 1. And so by the sandwich theorem, because here, you see this is converging to 1 by lambda, so t by N (t) has no choice, it has to converge to 1 by lambda. 
And so therefore, by the sandwich theorem, limits t upon N (t) will converge to 1 by lambda with probability 1; or N (t) upon t will, because we have taken t to be positive, so N (t) by t will converge to lambda with probability 1. So, therefore, you know, for the Poisson process; so now, again as I told you that the situation for the law of the large numbers is basically used to estimate the mean of the population. 
And so you go on making observations, and we say that the observations are independent identically distributed because they are coming from the same population. So, then the average, we expect the average to converge to the mean of the population. So, here also the same thing for the Poisson process; what we have shown is because N (t) is the number of arrivals in time t, so this ratio will converge to lambda, the mean arrival rate. 
And therefore, you can go on observing the values, number of arrivals in a particular time, and then upto time interval t, and the ratio will converge to lambda. So, if in case your lambda is large then you will have to make the observations for a longer time period because your N (t) will have to be sufficiently large; and therefore, that of course, make sense. So, therefore, this gives you a good way of wanting, trying to estimate the value of lambda. 
(Refer Slide Time: 09:40)
 
So, the Queuing model I am going to talk about today is M M 1, it is called M M 1, and I will explain in a while why we call it M M 1. So, here the whole idea is that you have a source from which your customers are coming to some service facility; there is a queue. So, these indicate the customers who are waiting in the queue for to be serviced; you have a service facility. And then again it will depend on what kind of service facility you have. And so the customer; so one by one a customer comes here, get serviced, then exists from the system after his service, his or her services is completed. 
Then the next one in the queue comes to be; so this is I am describing the situation when there is only one service facility or one clerk at a counter or something; if there are more than one, then of course, the movement one of the clerks is free the, a person waiting in the queue will go and get serviced, right. So, whatever it is, the service facility, the customers come, they get serviced; and once their service is complete we expect that they leave the system; so they are out of the system. 
Now, here, in order to discuss the model we first, so we need to specify the arrival pattern of the customers, right. So, this can be either specified by the arrival rate and the distribution of the arrivals because remember the whole situation, the thing, that the scenario is that the events are unpredictable. So, we do not know when a customer will walk in. Also we have no idea, the service times are also unpredictable. 
So, therefore, everything has to be modeled through these probability distributions. And so we will either specify the distribution of the arrivals, just as in the Poisson process we say, that the arrivals are coming at a rate whatever the rate is lambda, and then they are being modeled by the Poisson distribution; and or we give the specify the distribution of the inter arrival times which we saw that if the arrivals are following a Poisson distribution then the inter arrival times will be exponentially distributed. 
And then we had, in the last few lectures we have talked about in detail what, under what conditions we can say that the arrival pattern can be modeled by the Poisson distribution, right; so stationary increments. And then independent increments and so on; and then that the probability of arrival in a small interval would be only lambda times the length of that interval, and so on. So, there are huge lot of conditions under which we said that we can then model the arrival pattern by the Poisson distribution, right.
Then you have the service facility; and here of course, you can specify the distribution of the service times. As I said that it is not fixed operation each customer may take different amount of time, and so on. So, we have to; and then of course, you need to specify the number of servers. So, basically if you have these 3 things specified then your queuing model is there; and the M denotes the exponential distribution of inter arrival times, memory less. 
This is the property or markovean which we will again when we later discuss markov processes, we will see that Morkovean process is also have memory less property, right. So, inter arrival times are exponentially distributed; and x service is also, service times are also exponentially distributed. So, therefore; and then one server. So, first we will discuss the case when the, this is only one server at the server facility and latter on we will try to generalize the, now s is to more than one server. 
(Refer Slide Time: 13:58)
 
Now, just tells the specified the conditions under which we can model the arrival pattern by the Poisson process, we need to look at conditions under which service times can be modeled as exponential distribution, by an exponential distribution. Now, if your server is performing fixed, some fixed sequence of operations for each customer, then certainly this is not memory less. 
Because, if the customer, if these clerk has to perform 10 operations, sequence of 10 operations for every customer then he is up come up to the this thing, task, then we will know that he is going to finish after next 2. So, the sort of, one can assess the time taken for example, if a server has come up to this point, I mean this task is performed, then we know that he will finish these 2, and so the time at which this service will end depends on how far he has been already with the customer; how far he has been servicing the customer. 
So, therefore, they are certainly not a case for modeling by exponential distribution, right; because this is some sort of a fix sequence of operations. So, therefore, here also we will have to be, basically it will have to be the memory less property. If you can somehow justify that the service facility of the situation that you are modeling has this property then it will be, you know, safe to say that yes we can model the service times by the exponential distribution, and so on, right. 
So, then and the state of the system we will always specify by the number of people in the system; and then P n will be the probability that there are n people in the system. So, you can see that it is people coming for service, after being service they leave the system. So, it is, you know, our constant state of changing, because people come and go. So, P n is a probability that there are n people in the system. So, therefore, in time, (0, T); yeah, here I should I have underlined this, but I sort of missed it right now. So, the whole thing is being discussed under steady state situation. 
So, now, what we are saying is that suppose there is a new restaurant that is opened in the locality then you know, the number of arrivals would vary from day to day, and there will be no set pattern for some time till people sort of get used to that restaurant or they make it a habit of whatever it is; and there are steady number of customers who comes to the place to the restaurant. 
So, therefore, what we are saying here is that the we are discussing all this, when the system has settled down the tabulations are all over, and it is only steady state; that means, the probabilities have also settled down, and so on. So, under steady state we are discussing the modeling of this, modeling the queuing the situation, ok.
So, therefore if P n is the probability that the n people in the system, but in time (0, T). So, this total time for which the system is in; see, you can also look upon P n as the proportion of time for which the, for a unit time, proportion of a unit time in which this system is in state n; that means, the n people remember because this is the probability, and so this is the fraction, and therefore, we are saying the fraction of time that people, the n people in the system, right.
And therefore, over the time interval, (0, T), we will say that the total time for which the system is in state n, sorry, is not p n; is in state n, it is P n T, right. So, approximately we will say that proportion of time that there are, in this time interval proportion of time for which there are n people in the system is P n T. And therefore, and number of arrivals in (0, T) that find the system in state n is roughly, lambda P n T. 
So, we are talking in approximations and right, because the arrival rate is lambda. So, the number of arrivals in (0, T), that find the system in state n would be, lambda P n T because they are lambda arrivals in a unit of time. And so I mean the arrival rate is lambda. So, and this is also called a birth and death process because birth refers to a new arrival to the system and death refers to a departure of from the system. So, therefore, each the departure is treated as a death and each arrival, new arrival is treated as a birth. So, this is also called as a birth and death process. And so this birth and death process under the assumption that your arrival rate is a, process is Poisson, and the service time the exponentially distributed, there is one server. 
So, if you, diagrammatically you can describe the situation here, of the birth and death process. You begin with state 0, no people in the system, then 1 arrival takes place; should be lambda. And so you go to state 1. But from state 1, you can reward back to state 0 if the departure, and that is for this. So, we are saying that the exponential, the service time is exponentially distributed with rate mu, right. 
And then again when you are in state 1, it can go to state 2 by arrival and can reward back to state 1 because if there is a departure, and so on. So, that means, at each state, n minus 1, for example, you can go to the next state, and from this you can reward back to the old state; and so therefore, this make sense that you will, this proportion of time you will be in state n, right; because the situation keeps changing. So, let us further analyze the, you know, arrival pattern, mean arrival, average arrival time, average waiting time, and so on.
(Refer Slide Time: 20:17)
 
You see, when I made the statement that we are considering the system, the queuing system in steady state, so we actually I just remain that this limit probability of N (t) equal to n as t goes to infinity is P n. So, this is steadying down. And of course, t going to infinity is the analytical we are saying it, but essentially for a large time this system has operated and then it is settled down to steady state, that is what you mean. So, these are the limiting probabilities essentially of the system. 
So, and then for example, if you say that P 0 is 0.3, then in the long run, system will be empty of customers 30 percent of the time, right. Again, you know, because these are all probabilistic statements; what we are saying is that if your P 0 is 0.3, then long run if you observe the system then you will find that 30 percent of the time the system is empty. And that is what we meant when I said that P n T is the proportion of time. 
So, this is again in the long run when you, P n T will be, approximately we proportion of time for which the system has n people in the system, the system has n people, n customers and users whatever it is. So, this is the idea. So, and similarly if P 1 is 0.2 then the system has 1 customer, 20 percent of the time, even if you observe it for a long. And so approximately for time t, we can approximately say that this is the proportion of time that the system will have n customers, fine.
 Now, we want to start getting some more, you know, we want to get some, make some computations regarding this queuing system. And so we will use this concept of balance equations. What we mean is therefore, each n greater than 0, the rate at which the process enters the state n, equals the rate at which it leaves state n. So, this is also part of the system that, condition under which we are modeling the situation or the process. 
So, what we are saying is that the balance is maintained. In other words, what we are saying is that if you are state 1, you see, then you are leaving it here, by, because 1 more arrival has come; or you are leaving state 1 because 1 person has been serviced. So, this is how state 1 changes; either 1 more arrival, or 1 death or 1 percent leaving the system. And then again the way state 1 is reached is also from state 0 when there is a one arrival at this, so then you come to state 1.
 And here again, you come from state 2 when there is a departure here at this point. So, this is the idea. So, at each state of the system you have; so for example, when you are at state 0 then this is the rate at which lambda P 0. So, this is the rate at which the system leaves the state 0, right; because it is state 0 then lambda arrival; I mean the mean arrival this is, I should not say mean; the rate, arrival rate is lambda; therefore, lambda into P 0. This should be, this is rate at which it will leave the system. 
See, the system right now is in state 0, so it will leave, the system leaves that state at the rate, lambda P 0. And from P 1 it arrives to state 0 at the rate of mu P 1. And therefore, the 2 must balance. So, the rate at which it changes its state from 0 and arrive at 1, and the rate at which it leave state 1 and arrives at 0 is mu P 1. So, the 2 must equal.
Now, if you are in state 1 arrival describing you, then you see it is the 2 ways it can leave, either 1 more arrival or 1 departure. So, therefore, lambda plus mu into P 1 because remember that 2 processes we assumed are independent; service process and the arrival processes are both independent. So, therefore, I can add up the these rates. So, and this will be lambda plus mu into P 1. This is how it will leave the system P 1, the state P 1.
And, if it is P 2 then it can again come back to P 1 at the rate of mu P 2, and here from P 0 it can come to P 1 at the rate of lambda P 0. So, therefore, we departure from state 1, the arrival to state 1, the rate at which these 2 things happen must be the same, right. And so in general again same thing, that n for example, you are leaving it again because this arrival and you are leaving it because there is a departure. 
So, therefore, these 2, lambda plus mu; and then you are coming to state n through n minus 1 at the rate of lambda P n; and then you are, sorry, P n minus 1, lambda P n minus 1. And then here you are coming from n plus 1 at the rate of mu P n plus 1. So, therefore, in general you can write this. 
Now, here of course, if I am only considering a very simple form here because you can also have a situation where your lambdas are also dependent on the people in the system. But, we are, see, because that can happen some places where it is not a very essential service if the places crowded. For example, if a restaurant, people may not want to wait and they will leave the place because you can go elsewhere to eat, right. 
So, then you are, lambdas would be the arrival rates, would also be dependent on what state the system is in. And similarly the mu s can also depend on your, the number of people there are in, the customer they are in the system. So, these can be different for different states of the system, but I am right now considering the most basic case where all the lambdas; so these are not dependent on the number of people in the system; similarly the mu is not dependent on the number of people in the system. So, the service rate continues at the same P’s. 
So, now, if you solve these equations; see here, immediately you get the P 1 is lambda by mu P naught. So, let us get all these P’s in terms of P naught. And then similarly from here if you substitute for P 1 from here then mu P 2 would be lambda plus, mu into, lambda by, mu P naught minus, lambda P naught, this goes this here.
(Refer Slide Time: 27:45)
 
And then if you simplify you get the P 2 as lambda by mu whole square into P naught. So, in general your solution to these equations, these balance equations is P n is equal to lambda by mu raise to n times, P naught. So, all, for all n this will be the formula; that means, this just lambda by mu raise to n P naught, right. Now, we can obtain P naught by using the fact that all these probabilities must add up to 1, right. 
The system must be in one of the states from 0 to infinity. And therefore, when you add up this you get this as a geometric series; P naught is outside with common ratio lambda by mu. And so P naught is 1 minus lambda by mu, because this sums to 1 upon, this series sums to 1 upon 1 minus lambda by mu, right; so therefore, P naught for the 1 minus lambda by mu. 
Now, first this is valid only, this series converges provided your lambda by mu is less than 1 because otherwise it will explode. And you can also see, of course, mathematically you know that this series will converge only if lambda by mu is less than 1. If lambda by mu is not, is greater than 1 or even equal to 1, then this will not converge. So, the sum will explode. And so what does it mean? 
See here, when you say that lambda is less than mu, that means, lambda is less than, sorry; lambda by mu less than 1 that it implies that lambda is less than mu, right. And so this is the service rate and this is the arrival rate. So, obviously, you expect that otherwise people will go on collecting in the system if you are service is lower than the rate at which people are coming. 
Or, in other words, the better way to look at it is, that 1 by mu is less than 1 by lambda. So, mean service time is 1 by mu, remember, because it is exponential mu. So, therefore, the mean time is 1 by mu. So, mean service time is 1 by mu. Now, this should be less than; and 1 by lambda is the mean time between arrivals, remember, because if the arrival process is Poisson with rate lambda then the inter arrival times are exponential with rate with parameter lambda. 
And therefore, the mean time between 2 arrivals will be 1 by lambda. So, in general you expect that 1 by mu should be, that means the service, mean service time should be less than the mean time between 2 arrivals, right. So, therefore, then only you expect this system not to explode; that means, the queue will not explode and you will be able to process the customers faster than they come; I mean in lose way you saying that it will not happen, right. 
So, therefore, this makes senses that, and so once you get your P naught as 1 minus lambda by mu, from here you get that your P n as lambda by mu raise to n into 1 minus lambda by mu for all n. So, therefore, nice way we have been able to compute the probabilities for the different states of the system, right, under these assumptions. 
And, many more ways of explaining this, but basically the whole idea is that they should be; even otherwise from here you see, you can just see that P naught being finite must be because it is a probability of empty system then if lambda is greater than mu and this will go on becoming larger and larger. 
So, here they will be a positive probability for, you know, n being, well, this is yes, yeah, because P naught will take with P n cannot be, but what I am saying is there will be a positive probability of the system becoming, you know, number of people increasing in the system because, lambda by mu raise to n, if lambda is greater than mu, then that will be become, this start becoming a big number, fine.
Now, if you want to find out the average number of customers in the system, so therefore, you want to know that at any point of time, what is the average number of people. And mostly when you design a facility, you base it on the average number of customers in the system because you should at least be able to cater to the average number of people in the system; and then of course, there can be variations.
So, that means, L here is, we will define. So, L is the average number of people in the system; and so this will be sigma n P n vary from 0 to infinity because the probability of there being n people in the system is P n; so n into P n. The expectation of this P n, I mean of the variable denoting the, or we can say that may be L n is the, this thing random variable whose probability is n. So, or we have been, sorry; you can, we have been denoting it by, but that was N (t); so does not matter. Let us just keep it that, this way. 
So, sigma n varying from 0 to infinity n P n, will give you the average number of people in the system. So, here substitute for P n. And since this is not, this is independent of n, I will just concentrate on this. So, let me call this series, sigma n lambda by mu raise to n, 0 to infinity; let me call this s. So, I just write it out, you know, like this. 
Then I multiply this by lambda by mu s; and I just, because, see, the infinite term in the series I can start writing this from here, does not matter; this sum I can just, you know, slip 1 position, and so I start writing it from here. And again, both the thing are x turning to infinity. Now, when you subtract this from here, it will be 1 minus lambda by mu s. And here you see, this is 0; so this is lambda by mu; then this is 2 lambda by mu square; and this is lambda mu by, lambda by mu whole square. 
So, therefore, the difference is again this. And this is, you know, anyway, from those of you who are familiar, known that this is an arithmetic co geometric series, yeah. So, the terms are, the first term is changing as an arithmetic progression, and the second term is changing as a geometric progression or coming from a geometric progressions; so arithmetic co geometric series, fine. 
So, the way to sum up such a series is that you write down s and then you write down lambda by mu s, just slip to writing the terms from, you know, second position for this you write start writing from second position, and then you get, the difference comes out to be geometric series. And therefore, here the first term is lambda by mu, so I will write lambda by mu into 1 upon 1 minus lambda by mu, right. So, if your s is lambda by mu into, because this is this, so 1 minus lambda by mu whole square, right.
And so your L, because L had a, 1 minus lambda by mu here. So, then that will get canceled. Therefore, the average number of people in the system is lambda by mu upon 1 minus lambda by mu. And so here you see that even if this is large, atleast if this is close to 1; lager distance of course, because we cannot come to this expression if lambda is greater than mu; then this does not, I mean we cannot even talk about the average number of people in the system because a system would be explored it. 
So, lambda by mu less than 1; if it is close to 1 then you say this number is small; and so 1 upon this will be very large; and therefore, again the number of people in the system we will be very large. So, this definitely gives you the idea is to how, you know, the lambda by mu has to be small for efficient service. And if you try, if you not able to keep lambda by mu much much smaller than 1, it will certainly will be, there will be times there will be chaos because this is only talking about the average number of people in the system, right. 
So, therefore, this gives you an idea that if lambda by mu is reasonably small then this number will also be reasonably small; and so most of the time, I mean on the average you will expect, that there will be not too many people waiting to be serviced.
(Refer Slide Time: 37:09)
 
So, now the other characteristic of a queuing, of a good queuing model is that the amount of time a customer spends in the system should not be very high. So, therefore, we want to now estimate the average amount of time a customer spends in the system. So, again that will depend that will be a function of lambda and mu; your arrival rate and the service rates, right. So, let us find out this. 
Now, if an arrival finds n customers in the system, the arrival will have to wait through (n plus 1) exponential service times because n people are already in the system, and he or she is the (n plus 1) th arrival in the system. So, there is, then before the (n plus 1) th arrival leaves a system, that means, (n plus 1) services have been completed, right. 
Now, the thing is that there is already 1 customer being serviced because there are (n minus 1) people in the queue, and there is 1 person who is being serviced. But, because of this memorialized property we cannot say that, you know, this service, how long he has been at the counter, and therefore, how long he will takes more; we cannot say anything about it; that is as much unpredictable quantity as when he started the service. 
So, therefore, because of this memorialized property I have to count that also as 1 full service; and therefore, we have saying that they will be, (n plus 1) service is to be completed before this arrival who finds there are n customers in the system, finally leaves the system, right; so therefore, your, S n plus 1, will be T 1 plus, T 2 plus, T n plus 1, and varying from 0, 1, 2, and so on. 
So, this is the, and this is the conditional waiting time given there are n customers in the system, right; because, S n plus 1, means your conditional waiting time given there are n customers in the system, and therefore, (n plus 1), services have to be completed. Now, we know, since the service times are exponentially distributed we know that some of these (n plus 1) exponential identically independently distributed exponential random variables will be gamma (n plus 1, mu). 
So, the same parameter, but since they are n 1 of them. So, this becomes a gamma (n plus 1, mu); here s n plus is this. And so when you want to compute the probability that the average waiting time is greater than t, or that is the expected value, expected waiting time then this is sigma n varying from 0 to infinity, t n. So, conditional probability; remember, this is conditional. So, P n into S n plus 1 greater than t. 
So, you will write this as, this is probability that S n plus 1 is greater than t. So, you are services the, n plus 1, services take more than t time to be completed. And the probability that the n people in the system then only, n plus 1, services have to be completed. So, this is sigma n varying from 0 to infinity. 
So, substitute for P n, then you will get, lambda by mu raise to n, 1 minus lambda by mu into, probability S n plus 1 greater than t. So, this you can write as, 1 minus F w t because this is if I am saying that F w is the distribution function of w; and similarly, F n plus 1 t, I am denoting as the distribution function for S n plus 1. So, therefore, this is what I can write. Now, I can just differentiate both sides. So, this of course, is 0; I get the; so the minus sign, minus sign will cancel out, because so this is not a function of t.
(Refer Slide Time: 41:09)
 
So, here this will be minus and minus that will cancel out; and what you will get is that F w t is equal to this whole thing, and this is your gamma (n plus 1) mu p d f, right; mu e raise to minus mu t, then mu t raise to n upon n factorial. And now let us just simplify. So, what I will do is, this is independent of n; this is independent of n. So, the only quantity you see is mu in the denominator here, mu raise to n, and this is a mu raise to n in the numerator. 
So, the two will cancel out, and therefore, simply we left to the lambda t raise to n, upon n factorial; the other things can be all taken out. So, lambda t raise to n upon n factorial, you sum up this from n 0 to infinity. And now, this is very familiar series for us; and so this will be, e raise to lambda t. So, therefore, I can combine it with this. So, therefore, e raise to minus mu minus lambda t; remember, mu is greater than lambda. 
And so if you simplify this expression, mu minus lambda upon mu, cancels with mu. So, it is, mu minus lambda e raise to minus mu minus lambda t; and this is exponential, mu minus lambda, right. And therefore, you immediately know that the expected value of w is 1 upon mu minus lambda, right. And this if you remember the expression for L was, I will not see what was the expression for L, that was lambda mu minus lambda, right. 
So, therefore, the expected waiting time is L by lambda, or what it means is that our average. So, this was, the average number of people in the system will be, lambda times t, average waiting time that a customer spends. So, and this is known as the famous, should be t here, little’s formula. So, this is attributed to little who first, you know, get this differentiate between L and w. 
So, this is again you can, we can say out in words. so that you do not; and then if you want to find out the probability that, w is greater than t, then this is we have the p d f for w; this will be t to infinity, mu minus lambda, e raise to minus mu minus lambda t d t, which we now is this therefore, right; e raise to minus mu minus lambda t. 
So, what can you say here it has been if you want to say that, yeah; so this probability that your average waiting time would be greater than t, again you can talk about in terms of mu and lambda, right; because this is essentially equal to 1 upon e raise to mu minus lambda t. So, this, if you want to this probability to be small, then obviously, your mu should be greater than lambda, quite, you know, substantially, so that this probability then is small because e raise to mu minus lambda t would be large, and so 1 upon that would be small.
And see, all these relationships and this quantities will help you to in modeling very efficient queuing system, and depending on what parameters you consider important you can accordingly concentrate on those, and then accordingly you know design your system so that you are mu and lambda conform to that. 
So, that in the sense that if you want your L to be small, that means, you do not want its place to be crowded all the time then you concentrate on this. And if you, it is important that people should not have to wait for a long time then you will concentrate on this, right; but the 2 are related. So, L is equal to w, and therefore, you can say if you concentrate on this, you concentrate on this, depending in respect to lambda.
Now, the other quantity would be expected queue length. See, L was the expected number of people in the system which includes the person being serviced, but now here you are talking about expected queue length; and so that will be n minus 1 into P n because if there are n people in the system, 1 person is being serviced, so then the number of people in the queue are n minus 1. 
And, this summation will be from 1 to infinity because if you have n people then 1 person is said to be being serviced and therefore, n minus people, n minus 1 people are waiting in the queue. So, that will be; so you want to compute the expected value of L q of the people in the queue, right, which is L q. So, then this is n minus 1 into P n. Now, I can separated out as n P n minus, sigma n varying from 1 to infinity, P n, right.
So, this we know is L, because anyway when n is 0, the contribution is 0. So, this is also the same as L. So, that I write as L. And sigma n varying from 1 to infinity to P n is actually 1 minus P 0 because when you add P 0 then the whole thing adds up to 1; so 1 minus P 0. So, this is it. So, l upon lambda upon mu minus lambda is your value of L; then 1 minus, 1 minus lambda by mu, this is P naught. 
So, therefore, this becomes your; so that means, this is essentially lambda by mu into L, right; because lambda upon mu minus lambda is your L. And this is lambda upon mu into L. So, interesting this thing; and what you can see, in fact, the little’s formulae also say that w q should be, at lambda times w q should be L q. And we will show this also because here lambda times w is l, so lambda times w q should be L q; one can derive this results also. 
(Refer Slide Time: 47:23)
 .
See, w, I have used as a random variable, notation w for random variable that denotes the waiting time; and then I computed a expected value of w, but then again in the little’s formulae either it should be capital L, in the little’s formulae I again use the word w only. So, what I am trying to say is that because in the little’s formulae they used L capital L, capital W. So, did not want to change it. 
But then what I feel is that is not really much confusion using w, you know; using the same notation for the random variable as well as for the expected value because you see when you are computing this probabilities like this then it is clear the w is being used as a random variable because you do not associate probability, expected value of w is not a random variable. So, you will not associate probabilities with it, right.
So, therefore, probability, w greater than t, is to be computed that it is clear that w is the waiting time random variable. And when w is used for denoting the expected waiting time, it is clear of the little’s formula then it is clear that this w denote the expected value, yes; may be one could have used to different notations, but that is, ok. 
I just want to make sure that, I will make it clear that it should be possible to see from the reference to the context in what way w is being used. And the same holds for wq, because wq, I am using as a notation for denoting the random variable for the waiting time in the queue; we know just before your turn comes to be serviced.
So, before that the time you spend in the system, so this is the rate random variable denoted by w q. And again in the little’s formulae we will use the, for the expected value of w q, I am again using the notation w q only. So, the same reasoning that it should not cause any confusion. And one should be able to see from the reference to the context in what way w and w q are being used. So, please keep this in mind.
Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 35
Analysis of L Lq W and Wq M/M/S Model

(Refer Slide Time: 00:15)
 
So, I will continue my discussion about the you know the queuing system. You can say the features that are important in determining various aspects of a queuing system. So, L denoted our average number of people in the system; L q was the average number of people in the queue. And then we also had computed the average waiting time that a person will spend in that system which includes waiting in the queue plus service time. 
And then we will also talk about the waiting time in the queue which we show also important. So, anyway, so let me just continue the discussion about L and L q. And so this is as functions of rho which is your lambda by mu, that is your lambda is mean arrival rate and mu is the mean service rate. So, lambda by mu denotes your innocence utilization of the queuing system. 




 (Refer Slide Time: 01:27)
 
So, now we can see from the figure that is on the screen that as you know full utilization of the server; that means if rho is close to 1 then you see that your graph for L and L q both are going to infinity, right. So, that means, when lambda is close to mu, if rho is close to 1 that means, lambda is close to mu that is the mean arrival rate and the mean service rate are almost the same. 
In that case you see the number of people in the system and the number of people in the queue they will the expected number will go to infinity, right. You can see the vertical, the approaching, the both the curves are approaching the vertical line. So, now this what we are saying is mean values; that means L is the average number of people in the system and L q is the average number of people in the queue which are, which going to infinity. 
So, it is not, see, it is bad if once in a while your system has infinite people or very large people or the queue has becomes very large. But here it saying that it is the mean behavior that is on the average system will have infinite people, very large people, and the queue will also be very large, of course, ok. So, that is not acceptable, finely. 
But, anyway, also what we want to say here is that now in this case this does not happen in real life because if the big crowd then it turns away lot of people. So, it is not that the queue continues to grow. So, that does not really happen. And therefore, what we are saying is that in real life there will not be a balance because the queue system, you know, how many people turn away, and so on. 
So, it will not follow the same pattern; and therefore, when things become so bad we cannot apply the same rules that we started with, you know, our assumptions. And therefore, we will say that the system is not in balance. So, therefore, it cannot be, you know, measured; it cannot be analyzed by any of these models that we have written down, right. 
So, if you look at the mean length of 4 on the vertical line or then draw horizontal line from 4 then you see that it will meet the corresponding utilization is 0.8, ok. So, mean queue like that; that means, on the L q curve. So, and so L q is the first curve and then L is the second curve. And similarly, if you look at the value of L q equal to 5, the corresponding rho value is 0.85; so that means, when you allow 4 people to wait in the queue then the server will be ideal for 20 percent of the time, right; because rho is 0.8. 
So, 0.2 is the fraction of time that the server will be ideal; and so 20 percent of the time the server is ideal. And if you allow the queue size to be 5 then it will be 15 percent idealness. So, you can see that there is a definite conflict that is if you want that your server should not be ideal for very long time or even not then as we saw that the, if the system is allowed to operate freely. Then your queue and the people in the system and people in the queue will become very large. 
So, therefore, but then you do not want that to happen because then you lose out the customer, and so on; and it becomes a chois. So, there is a definite conflict between the issue, between the desire to obtain full utilization of a server and the desire to keep the mean queue length short. So, you can see that. So, where, wherever there is good will of the customer is very important. Certainly, the persons who are offering the service would want to make sure that the queues do not become too big. 
But then there it is more important, that means, the financiers are important and you are having a service where the, you cannot keep too many servers because that means, that many salaries, and so on. And then of course, you are, the servers will be ideal for a long time. So, therefore, you, one has to balance. So, the system can; of course, first of all this model has shown you that the system cannot being balance if the arrival rate is equal to the service rate, or even if the arrival rate is close to the service rate.
(Refer Slide Time: 06:03)
 
And so the ideal ratio of arrival rate to service rate is something less than 1; that is acceptable because your service rate must be more than the arrival rate, otherwise and that make sense. And so but its specific value depends on the relative cause of idealness verses congestion. So, if, for you it is very important that the system should not be congested; there should not be too many people in the system. Then you make sure that your service rate is much higher than the arrival rate.
And, if your, you have limitations; you may not to provide, you know, more than 1 server, may be let us say or is efficiency of service providing the service, then you know, we will go for; so I mean, right, so idealness verses congestion. So, if you want the, allow the server to be ideal you will not have that many people waiting in the system, right. Because, your service system will be such that your mu is much higher than the arrival rate, you will ensure that. 
And, in that case, your, L and value of L q will be small, but if your mu is close to your lambda then there will be congestion. So, one has to really strike a balance between, you know, idealness verses congestion. So, this is the whole idea I mean. So, therefore, you see we can, through these, this model we can study and decide what should be our level of service, and given what is your level of, you know, customers arriving to the system, right, ok. 
So, now, even though we, the little’s formula told us that if you, we have already computed average waiting time in the system. And now we also know that the W q can be written as rho times W; that means, the average number of people waiting in the queue is utilization factor times the average waiting time in the system. But, we will also like to compute this independently because the distribution of W q is also of importance. And besides, the W q is of importance in hospital emergency rooms. 
Because, in a hospital emergency room the time that you are waiting to be, you know, taken to the doctor is important because you want to cut that shot; it is an emergency room and therefore, people need treatment fast. So, you would, therefore, W q is of importance; and in hospital emergency rooms you would want to ensure that your W q is not very large. And so we want to look at it in a greater detail and also obtain the distribution of W q. 
So, now, of course, you can immediately write down this relationship because if there is nobody in the system when the arrival comes for emergency treatment then probability, so probability of the waiting time will be 0 because the patient will immediately be taken to a doctor for being treated. So, there in that case your waiting time will be 0. So, probability the W q is 0 is P 0; that means, there is nobody in the system which is 1 minus rho. So, now we will want to compute the distribution when person coming to the system has to wait; that means, there is 1 row more than 1 person already in the emergency room and then the person has to wait. So, this we will compute; try to obtain the distribution for W q also. 
(Refer Slide Time: 09:49)
 
So, for n greater than 0; that means, if the any customer is already present in the system then the new arrival has to wait through n exponential service times until his or her own service begins, right. So, if you want to find out the probability, the W q is greater than t, where W q is the waiting time in the queue. So, then probability W q greater than t, so I will break it up into conditional probabilities and then add up.
So, this is will be probability W q greater than t given that there are n customers, and so we add up from 1 to infinity because there has to be atleast 1 customer to being serviced then only there will be a need to wait in the queue. So, this is n to 1 to infinity probability W q greater than t given that there are n customers in the system. And this then would be written as; so now, when you write this probability then this will be P n into probability S n greater than t because if these are the n service times then S n would be t 1 plus t 2 plus t n. So, this has to be greater than t because the n people being serviced. 
See, you are in the, you are waiting in the queue, so then n services have to be completed and that takes because your waiting time is more than t; that means, these services are taking more than time t; and this into probability of there being n customers. So, then this will be; so I will substitute, I will write down for P n which is rho n into 1 minus rho, n varying from 1 to infinity, probability S n greater than t, right.
Now, if I take rho outside and then I write this as rho, so this will be a rho n minus 1 into 1 minus rho, and this is probability S n greater than t. Now, see, at n equal to 1 the value here is rho into 1 minus rho, and this is probability S 1 greater than t, so if I rewrite this as rho outside, and now at n equal to 0, your p n would be just 1 minus rho because rho n, rho raise to 0 would be 1. So, this would be 1 minus rho. So, same thing; and here it will be S 1 greater than t. So, the same event is being written here and therefore, all subsequent ones will be the same. 
So, this helps you to, because now you have the summation; probability sign is missing here. So, please write; this will be p in, probability of S n plus 1 greater than t; I will just write it; there should have been probability; so probability S n plus 1 greater than t. So, therefore, so now, you have, because the summation is from 0 to infinity, so then we can sum it up easily. 
(Refer Slide Time: 12:42)
 
And therefore, you can just expand this. And so here this is no people then the, service time of the, sorry; 1, rho into 1 minus rho actually would be the, you know, 1 person in the system; then the waiting time is the service time of the first person is of the 1 person already present in the system is more than t, and so on. So, when you take out rho then this is what, we have, you just expanding this expression like this, this series. 
And this, now we know; we recognize this because when we computed the distribution for the average time in the system. So, then this was, this is nothing but, and that is why we wanted the sum from 0 to infinity. So, this is probability W greater than t. And we already know the distribution of W greater than t; so we know this probability. So, therefore, this rho into e raise to minus mu, 1 minus rho t. So, we have computed this probability W q greater than t which is equal to this.
Now, so the rho is creating the problem because I cannot call this an exponential distribution, why? Because, if you write the p d f of W q, then this will be, you know, this you will write as 1 minus probability W q greater than t, yeah; this whole thing; so then d d t of that will give you the p d f of W q, right. So, this will be minus rho into, because this is 0; and I will write down the, yeah; so this one is rho into e raise to minus mu, 1 minus rho t; substitute for this here, then d d t of this, right; rho is outside. 
(Refer Slide Time: 14:31)
  
So, then differentiation gives me this expression which is equal to this. So, therefore, this would not be an exponential distribution because exponential distribution will be this; rho is the extra part, right. But, if you consider the conditional distribution, so now, that is important; conditional distribution of W q, given the W q is greater than 0, does have an exponential distribution because now you will write the conditional part. 
And, this will that be equal to probability W q greater than t because when you take the intersection, obviously, t is positive; so W q greater than t. So, the intersection of these 2 becomes just this event, and divided by probability W q greater than 0. See, late this you have to write as probability W q greater than t intersection, W q greater than 0; and then it will be probability W q greater than 0; this is what our formula for conditional probability is; but, this is the same as this; of course, given that t is positive. 
So, this event is equivalent to this event, given that t is positive, right; and then you divide the probability W q greater than 0. So, therefore, this becomes now, rho e raise to minus mu 1 minus rho t divided by rho, because probability W q greater than 0 is; this is what we computed here; W q is not 0, yeah. So, remember our W q, probability W q equal to 0 was 1 minus rho, right.
Because if the person does not have to wait that there is no person in the system, and so therefore, P 0; this probability is equal to P 0, which is 1 minus rho. So, if you want probability W q greater than 0 then it will be 1 minus of 1 minus rho which is equal to rho, right. So, probability W q greater than 0 is rho; so we divide this. Now, the rho cancels out; and this is e raise to minus mu 1 minus rho t. So, this now is coming from; that means, this now represents because the conditional part W q greater than t given that W q is positive. So, this is this which matches with our exponential distribution; and so the conditional distribution of W q is exponential with parameter mu into 1 minus rho t.
So, this is therefore, I again just want to repeat that this is not conditional distribution; we just removed this. So, it is just probability W q greater than t is that what you are computing; you started writing out of this; and then this is, I will just; no, we wrote this expression and just to, so that I can relate this series with this series with probability w greater than t; so that was helpful. 
And then we saw that the distribution is not matching with the exponential. So, it is only when you take the conditional probability that you will get, right. And so this already we had seen; and therefore, this is rho. So, that is it. So, therefore, and this will be useful at times you may really want to know the distribution of the; so this will be the conditional distribution of W q which you can recognize. 
Otherwise the distribution of W q is given by this; I mean the f q t, f W q t, right. Now, let us compute the expected time or the average time spent in the queue waiting for to be serviced; so that we will now compute independently because this is only the conditional part. So, you will say that the expected time in the system is equal to the expected; so the time in the system is time in the queue plus service time; so expected value of that. 
So, expected time in the system is expected value of time in the queue plus, the service time right. And so this can be rewritten as expected time of time in the queue plus, expected service time. So, this if we denote by W q. So, this is the convention way we have been following that the variable is also treated as the, S denoting the expected value of that variable. 
So, this is expected time in the queue plus, expected service time is 1 by mu, right; because your number of services is with parameter mu, exponential with parameter mu. So, 1 by mu is the expected service time. So, this is what you have; and therefore, W q is W minus 1 by mu; and you can, so we know W, expected value of W which is 1 upon mu minus lambda minus, 1 by mu. So, this becomes what we had computed, rho times W. So, W q is equal to rho times W, and which we have already seen through using the little’s formula. 
(Refer Slide Time: 17:21)
 
So, we saw that the conditional distribution of W q and W are both same exponential, and the parameter was, yeah; it means, I mean the same parameter. So, they, now also want to make an observation that the little’s formula that we obtained under special conditions, but it turns out. So, that means, the relationship between L and L q, W and W q, and L and W, so they are all; in fact, what it means is that if, you can find any one of the quantities, L, L q, W, W q, then you can find all the other 3. 
So, the all the 4 are related, and it turns out, fortunately that under very general conditions this formulae are valid. So, therefore, you know, computing any one of them would help you to get the values of the others. Now, I want to continue this discussion on these quantities L, L q; also show you how we then through these analyze these waiting systems have been queuing model. 
So, this particular example; it is the small one; but, anyway this is from Shelton laws; and what it says that machinery in a factory break down at an exponential rate of 6 per hour, ok. So, that means, the arrival of the machinery for repair is 6 per hour. And then there is single repair man who fixes machines at an exponential rate of 8 per hour. So, the arrival and the service rate as all provided to you. 
The cost incurred in lost production when machines are out of service; see the machines come for repair; they are waiting; so the repair man has to repair then. So, while the machines are out of service they incur a cost because you, the lost production. So, rupees 100 per hour per machine is lost to the organization, right. So, the cost of lost production is rupees 100 per hour per machine; this is what is given to us. Now, we want to find out what is the average cost rate incurred due to failed machines. 
So, while this is, the machines are waiting to be repaired, they are not producing, and therefore, there is a loss to the organization; and this is the rate. So, you want to find out the average cost rate. Now, the average cost rate will be dependent on the number of machines which are in the system; which are either waiting to be repaired or which are being repaired. So, that will be our number l. 
So, therefore, you see, L is lambda is 6, mu is 8. So, therefore, average cost rate we will write as 100, rupees 100 into, average number of broken machines which is either waiting to be repaired or they are waiting, or they are being repaired. So, this will be rupees 100 into L; L is the average number of broken machines which are in the system; L gives you the average number of people or customers in the system. 
So, therefore, this is rupees 100 into lambda upon mu minus lambda, which is 100 into 6 upon 8 minus 6; so rupees 300 per hour; so the loss. So, therefore, this is the very important parameter because the system would now like to evaluate whether the repair man that they have is good enough, or they need to have more repair man; because, it depends on what is the, how much the loss to the system compared to the salary of a repair man, and so on. So, that question you see will always be running through all these examples; and you want to analyze; and you know, this should hopefully help you in your decision process.
(Refer Slide Time: 23:49)
 
Let us take another example. So, you have now a pump station, a single pump station; so single pump petrol station. So, there is only 1 pump, and so cars that come for taking the petrol have to wait in the queue. So, 1 is being serviced; once the serviced car is done with then the other will come from which are waiting in the queue. 
Now, inter arrival times are exponential with mean 12 minutes; and that means, inter arrival time, the average time between 2 arrivals is 12 minutes; and the service time is exponential again with mean service time 6 minutes. So, average time it takes to fill up the car is 6 minutes; and waiting space is unlimited. So, I am not put any question here, but as we go long we will see what are the kind of questions we want to answer here. 
So, let us see; lambda therefore, that means, the arrival rate is 5 per hour because arrival time, inter arrival time with mean is 12. So, therefore, the number of arrivals per hour is 5. And similarly, the service rate mu will be 1 by 6 into 60 because this is per minute; this is only in minutes. So, you convert to hours. So, this will be 10 per hour; that means, the service rate you can, on the average you can fill up 10 cars in an hour, right.
Rho the utilization factor or the traffic intensity, we have lot of names for this. So, rho is 5 by 10, right; 5 is your arrival rate and 10 is your service; so 5 by 10. And therefore, this is 0.5. So, the traffic intensity is not very high; 0.5 is not considered to be very; that means the petrol station is not very busy right now. So, the kind of service rate and the kind of arriving rate.
Then, if you want to look at the probability that there is no car at the petrol station; so that will be 0.5 1 minus rho which is 0.5 again which is the high probability. Then, P n is the n cars at the station; so that will be 0.5 into 0.5 raise to n, right. And then the mean number of cars at the station, mean number of cars would be lambda upon mu minus lambda; or, well, this is, why I am writing this as, how, in fact, this is, sorry; this is rho upon 1 minus rho. So, the mean number of cars at the station is 0.5 upon 1 minus 0.5 which is 1; and L q, the car waiting in the queue is 0.5. So, this is the idea. 
So, now, we want to analyze the system through these quantities that we have computed. And you know, like you want to again answer the question that in case the arrival rate increases then supposedly the traffic intensity will go up, because this number will go up. And then what kind of numbers L and L q will be there; the values will also go up; and therefore, the petrol owner, the station owner may want to ask a question is, should we install a faster pump and so on.
Or, of course, more than 1 pump you will, the system that model we will discuss later on when you have more than 1 server; right. Now we are talking about only 1 server systems; and therefore, the only option that the man may have, in case the arrival rate goes up, option would be to install a pump which is filling up cars are at higher rate. So, we will just look at the analyses with the numbers.
(Refer Slide Time: 27:44)
 
So, through this examples which we are just discussing, I again want to raise the issues about validity of a model. So, it is very important that you keep recalling what are the assumptions under which we are working, and what are the; so for a example here I wrote that waiting space is unlimited, but you know that in a petrol station waiting space cannot be unlimited; and usually when you have space for 2 to 3 cars.
So, but of course, the, with the given data right now, it did not really matter because your L was 1, and your L q was quite small, right; L q was 0.5, I think; L q is 0.5. So, therefore, that, right now it is not an issue whether the space is limited or unlimited, but in case your data changes then to say that your waiting space is unlimited, it is not a very valid assumption. 
(Refer Slide Time: 28:39)
 
So, therefore, one should always keep this in mind that the better model would be when you talk of queues with limited capacity or with limited waiting time. So, that would be a better model for such an example. Then, the arrival pattern is state dependent; now, here to assume that lambda will remain the same all the time is not correct because if already 2 to 3 cars waiting, the person may want to go to the next petrol station. So, therefore, this is not. 
And, arrival process is not stationary also. So, it is state dependent and also not stationary because during the rush hour there may be, the lambda may be higher than corresponding to when it is lack hour. So, therefore, the lambda itself may change during the day. So, the lambda is not stationary; and it is also a state dependent; because people do not like to wait for too long, for because as you know you can always drive further and get another petrol station. There may be other considerations also; that is true. But sometimes if you like to wait at a particular station because they are familiar with the people know them, and there can be other, so many other reasons. 
Then also we must keep this in mind that whatever computations we are doing, remember they are not giving us accurate information about L and L q, and the remaining other parameters W and W q. But, we can certainly change the values of lambda in mu of the system; so that means, we can study the changes in the system and then correspondingly see what are the changes in these numbers L, L q, W and W q. 
So, this models certainly will help you to study the changes; whatever change is taken place in the system, then accordingly find out the changes in L and L q. So, that is what I want to; so that is what I have stated here, that the real use of the model is in evaluating the effect of changes in lambda and mu, right. 
So, for example, the station owner has the choice of, has alternative of installing a faster pump. If you done that then the mean service time is reduced to 4 minutes per car; it was earlier 6 minutes per hour on the average. So, now then the average time has gone down to 4 minutes; that means, the petrol pump can service 15 cars per hour. 
(Refer Slide Time: 31:21)
 
So, by installing a faster pump the mean service time is reduced to 4 minutes; that is the pump can fill up 15 cars per hour, right; and so your rho width now become 5 upon 15 because the arrival rate is 5 per hour. And so the intensity, traffic intensity or I use to called it the utilization of the petrol pump, and so on, so that is 5 by 15 which is 1 by 3; and this is 0.33. So, this is less than 0.5. So, the earlier one was 0.5 traffic intensity, now it has come down to 0.33. 
And, the probability that there is no car at the station, so that comes out to be 1 minus 0.33, right; because it will be 1 minus rho; and so that is 0.67 which is greater than 0.5; so that means, the petrol pump would be vacant for more time. The fraction of time would be higher than here because there it was 0.5; since rho is 0.5, so 1 minus rho is also 0.5. 
And, your L, the average number of people in the system or at the petrol pump, that means, the number of cars getting filled up or waiting to be filled up, so that will come out to be 0.33 by 0.67 which is also less than 0.5. So, therefore, this does not warrant installing a faster pump because your petrol pump is vacant longer, the intensity, traffic intensity has come down, and so on, yes. So, if you are looking at from the view point of the petrol pump owner then certainly it does not wanted installing a faster pump.
In case, the arrival rate goes up, that means, you have 6 cars per hour instead of 5 cars per hour, and with the current pump that you, the man has, then this will be, rho will be 6 by 10. So, this is the 0.6; that means your traffic intensity will go up from 0.5 to 0.6. Your probability of there being no car in the system is 0.4; and your L is 1.5; and your L q is 0.9. 
So, therefore, you see that is what I am saying that, now with the model you can play around; and for different values of lambda we can figure out what is, how these numbers are changing. And then if you can, as I said, you know, the losing the good will of the customer verses the cost of installing a faster pump and so on, what can be, the owner can study all those things through this model, right. And therefore, that the basic contribution of this model lies in being able to study the various changes that will take place in your, you know, you can call them parameters when you change your lambda and mu change.
(Refer Slide Time: 34:19)
 
So, now I will, after having discussed 1 server model we will now look at the situation when there is more than 1 server. So, this is that model would be M M S, that the same, the pattern, or arrival pattern and the service pattern are the same, right; you can say that, and therefore, and the number of servers is now more than 1. So, in that case you see as long as there are number of people is less than s, then your service rate will be. 
Because, whoever is there is in the system, if the n people in the system, all will be serviced; and therefore, your service rate will become n times mu; that is understandable because everybody is being serviced, and therefore, the n people who are being serviced simultaneously. So, the service rate you can say has gone upto n mu, right. 
And, if you have more than n s people in the system, then of course, it will be remain at s mu because only s people can be serviced, since your s servers. And therefore, then the service rate will be s mu, but I will try to explain; and therefore, diagrammatically if you look at the transition diagram here, then you see arrival rate is the same lambda, right; which is, you know; so lambda is the arrival rate, but the service rate changes. 
So, if you have 1 percent in the system then it will be mu, right; because there you serviced and therefore, you get back to 0 state. If you have 2 people then 2 are being service simultaneously and therefore, you are at the rate at which the system can transition from 2 to 1 will be 2 mu. So, this should be understood very well because so what we saying is that, that many people are being serviced and therefore, the probability of transition; that means, the rate at which you can transition from 2 to 1 will be 2 mu. 
And, similarly with 3 people, the rate of transition will be 3 mu, but the arrival pattern is the same; and therefore, the arrival rate is lambda. So, this will go on upto s minus 2 and then upto s minus 1; and when you have s people in the system if your state is, the system is occupying state s, then it will be s mu. And thereafter, the service rate will remain at s mu, right. 
The arrival pattern would be at the rate of lambda, but the service pattern, service rate would then remain at s mu. So, this is the idea. And so here this service rate depends on the number of people in the system; that is if the number of people is less than s than it is n mu, and if it is more than s then it is s mu.
(Refer Slide Time: 37:18)
 
Now, let us understand the assumptions; it is very important. And if the, what we are assuming is that all operators operate at the same mean rate. So, right now this is the simplification; because, obviously, it will get very complicated if I have different servers with different service rates. So, therefore, we are assuming that all operators operate at the same mean rate, mu. 
Therefore, I am saying that the, when there are n people in the system, the service rate will be n mu; and when there are more than n, it will be s mu. So, this is possible only if I make this assumption that all operators or all service people are operating at the same mean rate mu, right. And so this makes it; because then we do not have to keep track of which servers are busy; you know, then we will have to accordingly keep changing the service rate; and that will become quite problematic, right.
Again, if I feel that this is not very, this can be treated as a realistic assumption because, you know, person may be a little more efficient than the other, but the differences cannot be very, very large to really take care of them in the system, right, in the model. So, this is what 1 assumption. 
And then the second assumption which is important is that departures will be 1 at a time; that is probability of service of 2 or more services being completed exactly at the same time is 0. So, this probability, that means, at departures because that is the important of the, you know, when we say that we looking at M M S system, and yes I will have occasion to explain. So, then when we talk of Markov process we will discuss in detail.
 And so anyway, I am, when we talking of Poisson process, remember I had told you that there is always a small, there is a small enough interval in which we will say that the probability of 1 arrival is probability of, we know, the is something like lambda delta t, right. And then for more than 1 arrival it was of the order delta t square, a higher order right.
So, therefore, we were neglecting that; so the probability was again, that means, we assume that exactly at the same time 2 or more customers will not leave the system. So, the service will not get completed exactly at the same time for more than 1 people. So, therefore, there will be a distinct interval between 2 departures. So, therefore, we can model this as a birth, death process, because our birth and death process the assumption when we talking of M M S. 
So, then the basic assumption is that your arrivals and departures are distinct at distinct times; you cannot have more than 1 departure or 1 arrival at the same time. So, once we make that assumption; and the second assumption is that the operators are all operating at the same efficiency; so the mean rate is same. Then we can process this system as a birth, death process, right. 
And, so now, I can write down the balance equations. So, this is the first one which is easy to understand, right; because you have, you already have 1 person then the rate at which it can depart is mu. So, mu P 1 must be lambda P naught. 1 person can arrive when you have 0 when you are in the 0 state; so then this and this gives you this, right.
Similarly, when you, I want to write for, so 2 people in the system then it will be lambda P naught. You can go to P 1, sorry, to 1; and from here when you have 2 people then at the rate 2 mu you can go to again because 1 departure 1 person get serviced, and so you again to P 1. And here, it will be lambda plus mu, right, P 1; that is why the transition diagram. And even when I were discussing M M1 system, I had explained to you how you can, you know, interpret the transition diagram. So, it will be lambda plus mu. 
So, it is actually not; there is nothing new here except that you have to remember that; so I have not written down the remaining things; it is understood that upto s minus 2 you will have this thing. And then after that you will, the movement you have s people in the system as a more; then this is the balanced equation that you will get, right. 
So, once you have written down these balanced equations, immediately you can start solving. So, P 1 in terms of P naught will be lambda by mu P naught. And then if in the second one if you substitute for P 1 in terms of P naught, then you get your 2 mu P 2 as, ok.
(Refer Slide Time: 42:03)
 
So, the expression 2 mu P 2 simplifies to, equal to lambda square upon mu P naught. And therefore, P 2 is equal to lambda square upon 2 mu square P naught. So, note the correction, that 2 was missing. So, it should be lambda square upon 2 mu square P naught. So, all the probabilities can be computed in terms of P naught. 
So, important thing is that the moment you have more than 1 server things change a little and one has to understand, and what assumptions you are now modeling the situations; and so I try to explain to you how we will, under what assumptions we will treat this as a birth, death process. So, the service is, are all at the same rate; that means, all servers have the same efficiency, and that no, more than 1 departure at exactly at the same time. So, there will be just little interval of time between any 2 departures from the system. So, under this you can easily write.
And then of course, this service rate changes depending on the number of servers you have. And so and all these 3 assumptions you can write these balance equations, and then we will try to get the probabilities in general formula, and then we will again compute your quantities L, L q, W, W q to get an idea about. So, therefore, your traffic intensity also will change, right; you can see that; because your service rate is changing and therefore, your traffic intensity will also change. So, all these again open up a very interesting this thing, you know, situation; and we will like to look at them.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 36
M/M/S M/M/I/K Models

(Refer Slide Time: 00:15)
  
So, continuing with our solutions of the balanced equations for multiple servers, so M M S system; maybe, I can again write here this because we are continuing with the same system with multiple servers. So, then you may solve equations for P 1 and P 2. And now, in general, if you want to solve it for, so at the point when you have, you know, more than s people, or it just at the boundary, so this is been lambda P s minus 1 when you have s minus 1 people. 
So, in coming, the way you can reach P s would be through 1 arrival. And then here, when you have s plus 1 people, then, you know, your service rate is s mu. So, it will be, you know, again 1 person departs. So, then you will be back to P s; and here it will be 1 arrival and 1 departure. So, then again you remain at P s, right. So, therefore, this is the balanced equation at this stage.
And, we can now substitute for, because, yeah; so I had shown you that the formula for P s, upto P s minus 1 would be this. So, I just substitute for this in terms of P naught. So, this would be lambda into lambda s minus 1 upon mu into 2 mu into s minus 1 mu, right; then, plus s mu P s plus 1, and lambda plus s mu into lambda raise to s. So, upto P s the same solution will go; the same formula; so mu into 2 mu into s mu. 
So, let us just, yes, we simplify; you take this to this side and then, you know, without spending time because surely you can do this calculation yourself. So that, from here you will subtract this expression, right; and you have s minus 1 mu here. So, you will get a s mu in the denominator from you multiply, and so when you multiply by s mu. So, lambda s, s mu term will cancel out, right; and you will be left with lambda s plus 1. So, this is the simplification; you can see it right away from here, right. 
So, you will be left with only lambda s plus 1 upon, so this will be mu raise to s, and then 1 into 2 into 3 upto s, so that is s factorial. So, that gives you s mu into P s plus 1 equal to this. And therefore, P s plus 1 will be lambda by mu raise to s, and the lambda, so the s factorial, and then divided by s mu. So, 1 lambda upon, yeah, this is my lambda; you should be able to write it; yeah, this is lambda, lambda upon s. 
So, that means, when it is s plus 1, you have this term into lambda upon s mu times 1 at when your rho is lambda, utilization factor is s mu, lambda by s mu now, right, s servers; and just want to show you that the same formula will continue, and then you can generalize for n, P n. So, now if you write lambda P s, then s mu P s plus 2, because after you have more than s people then if the same service state will continue. So, s mu into p s plus 2 is equal to, lambda plus s mu into P s plus 1. 
And, this again when you substitute for p s and p s plus 1 from here, then you will get the expression that p s plus 2 is equal to lambda by mu raise to s into, lambda upon s mu raise to 2. So, this is the factor which goes on increasing; this remains the same; s factorial lambda by mu raise to s is common; and then it is lambda by s mu square. So, now, you can generalize for, you know, you can write the general formula, and that will be P n is lambda by mu raise to n, n factorial, P naught, no, that yeah, for n between 0 and s. So, this formula is ok for n between 0 and s that is what we were using here, right; and here, for P s. 
So, then, but n greater than s, you are going to have lambda mu raise to s upon s factorial. And then, see, we have, let me show me you. So, this is then this is lambda by s mu square. So, I am writing lambda by s mu, no; I do not have to write s here. So, this is lambda by mu raise to n minus 1 upon s raise to n minus s. So, either s you can include with this, and it will be lambda by mu raise to n minus s. 
So, if you are writing the formula for P n lambda by mu raise to s upon s factorial, this is the common thing, and then it will be lambda by mu s raise to n minus s, which I choose to write as lambda by mu raise to n minus s, and divided by s raise to n minus s. So, it is same thing, into p naught if n is greater than or equal to s, right. And so now, since we have the general expression you can use the convention that 0 factorial is 1, and therefore 1 can be replaced by lambda by mu because when you add up, see now you want to use the fact that summation P i, i varying from 0 to infinity is 1. 
So, when you write P 0, so therefore, n all are this are also in terms of P 0. So, the series will become 1 plus and so on, divided by the P 0. So, 1, we are replacing by 0 factorial. So, in that case, you see, this will be your this thing; and here, the later part, that means, from s onwards, s plus 1, s plus 2, to infinity, the terms set you will get, you will have this power series; and, this will be convergent if lambda upon s mu is less than 1. 
So, as we have anyway c in that, you know, if this is greater than 1 then your things will blow up; if your arrival rate is more than s mu then the q size in everything will blow up. So, we have to anyway work this under the system; and this is less than 1. 
(Refer Slide Time: 06:49)
 
So, for any feasible if you want to consider a balanced form and stationary system, so therefore; so this then can be written as s to infinity, lambda by s mu raise to n minus s, under the condition that lambda upon s mu is less than 1. So, this is the expression. And of course, we are not going to see this no other close form for this. And, when you are given the values lambda, mu, and s, you can just compute this value, right.
So, now start computing the expressions for L, L q, W, W q, and so on. So, let us just look at the expression for L q which will be n minus s. And, you can see the reason because there is a neat expression for this thing enough for the probabilities when n is s or more than s. So, I am therefore, writing L q. And since, I can get L from L q, therefore, it is enough that I compute this. And, once I get q, I will get L, and then I get W, I get W q. So, that is the thing. 
So, let L q; so we will write as n minus s P n where n is varying from s to infinity. And here, if you want to write n minus s s j, then n is s plus j, right. So, therefore, you can then say that j varies from 0 because n is varying from s; so n plus s. The j will vary from 0 to infinity, and this will be n minus s j into, P s plus j. So, we can, we have a nice way of writing the probability for this. 
So, which will be, see here, the s part is lambda by mu raise to s upon s factorial; and then this for the j this will be lambda by mu raise to j upon s raise to j, right. And, this j is there because n minus s. So, you are computing L q, right; expected number of people in the q, right; and this is P 0, fine. So, I can remove lambda by mu raise to s upon s factorial, take it outside the, and P naught outside the summation sign; then I am left with this j into lambda by mu raise to j upon s raise to j.
And, here this I can; see, lambda by s mu, one s I can take outside; then, I will be left with lambda by s mu raise to j minus 1, right; one lambda by s mu I take outside which I am writing as rho; then, it will be lambda by s mu raise to j minus 1. So, j times this which is the, you know, derivative of lambda upon s mu raise to j. So, this whole thing by taking rho outside is equivalent to the derivative of this, right.
And since, lambda upon s mu is less than 1, we know that this series is also convergence; this is the arithmetic co geometric form with common ratio is lambda upon s mu which is less than 1. So, therefore, this is the convergent series. So, I can take the, first was, I should have written the derivative outside; and then, since this is a convergent series I can bring the derivative sign inside, and this is what you have.
And therefore, now this is the geometric series which adds up to 1 upon 1 minus rho, right; this part summation, and then derivative of this, will be 1 upon 1 minus rho whole square. So, actually, no no; what I should have done is I, first I write derivative inside and then I take it outside because it is a convergent series, so you can interchange summation sign and derivative sign.
So, now I take the derivative outside; then this sums up to 1 upon 1 minus rho; and the derivative gives me 1 upon 1 minus rho whole square. So, therefore, now you have a neat expression, except the P naught is a little complex one. So, then you have this expression for L q. And then, I can get my W q which will be L q by lambda; and, because we said that these relationships are valid even in the general case. 
So, 1 upon; so therefore, this is given 1 upon s mu; when you divide this by lambda, this will be left, though 1 upon s mu, and you have this expression. Hence, then after that you will say, W, W q plus; and remember, the difference between W and W q will still be that of 1 service because your departure from service is 1 at a time. So, therefore, this we will not 1 by s mu, it will be 1 by mu, right. And similarly, here this lambda will, L will be L q plus lambda by mu. So, keeping that in mind, you have all this relationships.
Now, let us just look at some of the; no these, yes, and I want it to show; the tables that I am going to show you have been taken from this book and I will give you the proper references all at the Ravindran and Philips books. So, I have taken some tables where they have plotted the L with respect to, you know, the rho sign, rho, where s is vary for different values of s. So, rho changes; so they have plotted. 
(Refer Slide Time: 12:03)
 
So, let me show you the graph here. So, figure 2, I would just want to explain that here you see the horizontal axis is the utilization factor; that means, rho equal to lambda by s mu; so different values of rho going from 0 to 1. And, the vertical axis is the steady state probability of 0 customer in the system. So, look at the curves in the diagram, in the graph, then you see that the utilization factor is coming down drastically as s increases, ok. 
So, for; that means, for 0.8, for example, the top; we have top line shows you the utilization factor the, you know, utilization factor versus the probability steady state, probability of nobody no has customer in the system. So, these are the different lines. And, you see that the neutralization factor when s is 25 is barely, is even less than 0.3. So, that of course, we also except because more the server, the lesser the utilization factor. And, but there again as we said that it is always conflict between, you know, have it congestion or having more servers; and, that depends on what your priorities are. 
So, anyway, this, the graph actually show you what we expect; that as this will go up the utilization factor will come down. But, the other important contribution of this graph is that, you know, you can plot because, remember, the expression for the steady state probability when you had more than 1 server, the expression was lengthy one. 
So, now you can actually plot for different say; that means, if you know the utilization factor, say, for example I know the my utilization factor is 0.7, and then if I want to find out what the corresponding value of P naught will be, so then I will go along this vertical line of 0.7. And, if my number of servers are 4, then you see whereever this curve s equal to 4 cuts the vertical line 0.7, so that point, and I go horizontally then across to the vertical line, so I can then find out the corresponding value of the P naught. 
And so that will help me because then I have to make my computations for L, L q, and so on, or even for P n s, I will need the value of P naught. So, then it will help me to just plot the value, given utilization factor and the number of servers; then I can find out the corresponding value of P naught. So, this is the contribution of figure 2, and later on when I work out, when I worked out any, I will use the values.
(Refer Slide Time: 14:53)
 
Now, I will show you another graph. This is the utilization factor, the verses. So, we are plotting the utilization factor on the horizontal axis, and steady state expected number of customers; so number of customers in this system, right. So, utilization factor and therefore, it says the n for different servers as you except. So, for example, if your utilization factor is 0.3 for s equal to 25 you can see that; well, let us see; this is at utilization factor 0.4; that means, your lambda bar, lambda upon s mu is 0.4. 
And then, if you go up then you see that for s equal to 25 the number of people will be 10. So, now, total number of people; but you have this is the steady state expected number of customers which is L. So, the number L would be around 10, winning of 25 servers in the system. 
Now, if you come down, that means, if you come down to or if you go higher, then of course, these as the utilization factor increases, then we know that the number of people in the system will go to infinity, and the, because it is never advisable to have your s mu equal to lambda. So, therefore, this should never come very close to 1, the, your rho, right. 
So, that of course, is depicted by as we saw it for ones server, the same phenomena is shown, is repeated here also. But, this again gives you an idea is to the utilization factor verses the number of servers you have and the number of customers you will have in the system. So, for different values you can just plot and see, right; for what is the number of; so if for example, for 0.5 if you go again the number of people in the system will come, will be again round 11 or something; you can say that for 25. But, then if you have only s equal to 1 and 0.5, then you expect only 1 person to be in the system. 
So, this is the kind of; so therefore, this, I mean the conclusions are the ones that you except, right; but they, sort of, give you more accurate you, and you can accurately find out for number of the utilization factor, number of servers, what will be the expected number. Because computing P naught, so you can from here only just find out the different values of rho; you can find out n for number of servers; you can find out the excepted number of people in the system. So, once you can do that, then if you have computed L, then you can find out L q, you can find out W q, and you can find out your W. So, this is just to give you a feeling about the multiple servers, and how these quantities L, L q, W, W q, behave. 
(Refer Slide Time: 18:00)
 
So, you see, now interesting example from Ravindran, Phillips and Sol berg, actually there are 3 authors; so Ravindran, Phillips, and Sol berg. So, now they are trying to show you that pool verses separate servers, and what would be the conclusion. So, let us look at this example. So, the 2 business working, business men working in adjacent offices; each requires secretarial service; and they each produce an average of 4 letters a day; well, this is simplification.
But anyway, whatever the work, what we are saying is, average of 4 letters a day to be typed, and a secretary can be excepted to require an average of 1/ 5 of a day to type 1 letter; that means, the rate of typing letters by secretaries 5 letters a day, and the business men each is producing 4 letters a day to be typed. So, the question is should they get together to form a 2 person secretarial pool; the pool means that whenever anybody has a letter ready, when anyone of the 2 secretaries who are free, they will type the letter. 
So, it is not that, you know, 1 secretary to the 1 business man, and so she will only work for particular, for her boss only, and only when the letter is ready by the boss she will type it. So, by pooling, it will be possible for each of the business men to access both the secretaries; that is the idea. Or should each men have his own secretary; so this is the question and let us try to answer through this model of M M S which we have just now talked about. 
(Refer Slide Time: 19:39)
 
And you see, so let us see. So, if you take a single system then it will be just input is in 4 letters a day and their secretary is typing 5 letters a day. So, each system can be considered as a M M 1 system, right. So, and therefore, your rho will be 0.8; the utilization factor 4 by 5 is 0.8; and the mean delay which is W q will be lambda upon mu; mu delay means that the letter has to wait for sometime before it gets started to be typed by a secretary. 
So, then W q is lambda upon mu into mu minus lambda which is 0.8; so that means, on the average a letter will sit for, you know, 4 th, 5 th of the day, on the secretaries desk before it is being typed, before it starts being typed, typing begins on that letter. So, the mean delay is 4th 5th of the day, right. Now, and the same applies to the second business man also because they are identical systems M M 1 systems with the same data. 
So, therefore, the second business men also will have the same thing happening to his letters that for 4 5th of the day now the letter will be waiting on the average, and then just typing begins. Now, suppose, you pool the system then your input will be, you know, 8 letters a day, and you have 2 servers now, each them producing, typing 5 letters a day. So, then this is a M M 2 system, right. 
And, your rho will be again lambda upon 2 mu which is 8 by 10. So, therefore, this is 0.8. And your lambda by mu is 1.6, right. So, then P 0; now this is where you are, the graph that I had talked about come in handy; of course, this is the small system, and so therefore, I have shown you the calculation even otherwise; this is this, right. I have shown you the calculation, but see, you can see from, that means, for lambda by s 2 mu, s mu is 0.8; so corresponding to 0.8 and 2 servers. 
(Refer Slide Time: 21:52)
 
If you look at the graph here, figure 2. So, 0.8, and you want to go up to 2. So, you see this is little above 0.1. So, 0.11, right. You can see in the graph, lambda by s mu equal to 0.8 and 2 servers. So, this is just above 0.1; so 0.11, right; and which also by our calculation comes out be 1 by 9. So, this is 0.11. So, larger systems your graph is plotted; you can just check the value, you know, look up the value for P naught without having to do the lengthy calculation.
(Refer Slide Time: 22:13)
 
And therefore, your L q would be again by the formula and then so W q; that means, so by formula we have W q s, this number which is 0.35. So, therefore, by pooling the mean delay has come down to 0.35; earlier the mean delay was we have computed it was 4th 5th of the day, right; which was, right. And so here now it is 0.35 which is much less than 4 by 5, right. Because, if you multiply this is, mean delay here, what is it, 4 5th of the day. So, if you want to compute it in; this is 0.8; mean delay is 0.8, so which is much less than point, which is much very very high compared to 0.35.
So, by pooling definitely your mean delay will come down. So, it might not be, you know, if you put the ego side apart; you know, like having your own secretary; and of course, probably this goes against intuition also. Because you may feel that if you have 1 person to exclusively to do your job, then you should get it done faster, but certainly the data here shows that this is not the case; by pooling it will always help you to get your work done faster.
Now, mean delay we had computed that 0.8. So, therefore, this is very high compared to this number. Now, let us see, we can again play around with few numbers. Suppose you say that this data was particularly till I had, so that their difference is so much- 0.8 and 0.35. Now, suppose 1 of the business men has only 2 letters a day then the mean delay for is the letter getting type will be 2 upon; so this is the number of let mu mu upon lambda, lambda minus mu, sorry; I have said the wrong way.
2 is the number of letters that arrive per day. So, lambda is 2, mu is 5, because 5 letters get typed; the secretary can type 5 letters a day; mu is 5. So, this is, lambda is 2; so lambda upon mu into mu minus lambda. So, this will be 2 by 15 which is 0.133. So, with his own secretary the mean delay would be of the order of 0.133. 
Now, if we pool the 2 secretaries then your lambda becomes 6 because the first business men is, one of the business men is sending, getting 4 letters to be typed; and the other one has only 2. So, lambda equal to 6; and 2 mu will be 10, because each of them can type 5 letters a day. 
So, therefore, P 0 is 1 by 3. Now, this we get from the figures that I have, should, given you. So, therefore, for lambda and mu, for these values of lambda and mu, you find out p naught which it comes out to be 1 by 3 from the figure. And therefore, your W q would be 0.11; that means, the mean delay would be 0.11 which is still less than 0.133. So, you see pooling definitely is a better option with 2 letters and the secretary and the man using his own secretary, even then the delay that he encounters is more than what he would encounter if he, if the 2 secretaries service is a pooled up and then they type letters as they come. 
So, you see, even though as I said in the beginning in somewhere in the last lecture that, you know, you cannot take the values that we compute through this such models as exact, but they do definitely give you, you know, they have good guiding; they give you, provide you with good parameters to make, to help you make your decisions, right. See, even though the numbers may not be so exact like 0.35 and 0.8, but it definitely shows that the difference is there. 
And so you can, the efficiency of the system gets improved by pooling. So, your services that you have; you know, like so many banks in so many other places, in public places if you see, that sometimes even at airport cannot counters and so on, you feel that, you know, separate queues because once you, once up the customer joins a queue then he or she cannot change the queue. 
So, you see, that way you can immediately see that, I mean, this kind of model shows you that lot of time is being wasted; I mean the system is not working efficiently because you are not pooling the resources. So, somehow the feeling that separate queues will be more efficient and your work will get done faster, so that belief is not supported by this model; and it is a reasonable correct model, in the sense that it gives you ideas to what happens when you pool up the resources. 
So, this is a all about it; and we will continue with the. So, figure 2, I would just want to explain that here you see the horizontal axis is the utilization factor; that means, rho equal to lambda by s mu; so different values of rho going from 0 to 1; and the vertical axis is the steady state probability of 0 customers in the system. 
So, first of all if you look at the curves in the diagram, in the graph then you see that the utilization factor is coming down drastically as s increases. So, for, that means, for 0.8, for example, s equal to 1 you, the top, way of top line shows you the utilization factor the, you know, utilization factor verses the probability, steady state probability of nobody no has customer in the system. 
So, these are the different lines. And, you see that the neutralization factor when s is 25 is barely is even less than 0.3. So, that of course, we also expect because more the server the lesser the utilization factor, and, but their again as we said that it is always conflict between you know have a congestion or having more servers, and that depends on what your priorities are. So, any way this, the graph actually show you what we expect; that as the number of servers will go up, the utilization factor will come down.
But, the other important contribution of this graph is that, you know, you can plot because, remember the expression for the steady state probability when you had more than 1 server, the expression was lengthy one. So, now, you can actually plot for different; that means, if you know the utilization factor. So, for example, I know the, my utilization factor is 0.7, and then if I want to find out what the corresponding of P naught will be, so that I will along this vertical line of 0.7. 
And, if I number of servers are 4, then you see wherever this curve s equal to 4 cuts the vertical line 0.7, so that point; and I go horizontally then across to the vertical line, so I can then find out the, in a corresponding value of the P naught. And so that will help me because then I can make my computations for L, L q and so on, or even for P n s I will need the value of P naught. So, then it will help me to just plot the value, given my utilization factor and the number of servers then I can find out the corresponding value of P naught. So, this is the contribution of figure 2 and later on when I work out, when I worked out an example, I have used the, I will use the values of P naught from this graph. 
(Refer Slide Time: 30:42)
 
So, I will take up this, taken up this case study from the state hospital in; and this is from the book Hillier and Leeber men; again this reference will also will be given at the end of the course. And, see, the state hospitals in the US are called county hospital. So, the data was collected from the county hospital, and the emergency room is considered because that can be modeled really well. So, here emergency room and the arrivals, and we are considering the morning shift; have I written something from where here, yes. So, this data refers to the early morning shift. 
So, early morning shift and that, I do not know, for some reason this is what happens; that often the emergencies are in the early hours of the day, early hours of the morning. So, arrivals are 1 per half hour, right; so that means, your arrival rate is lambda equal to 2. And, here again, it is, it was found suitable to model the thing y Poisson arrival; and of course, the service process is exponential, negative exponential. 
So, that means, since 1 every half hours, so 2 arrivals per hour; then doctor requires an average of 20 minutes to treat a patient which means that mu is 3 patients per hour. So, your this thing also; if it is negative exponential then the inter arrival times, the services, the service times would follow negative exponential distribution. Now, there are 2 alternatives which the hospital management has to consider. 
They have 1 doctor to manage the emergency room, so either they continue with the, with 1 doctor, or to add another doctor; that means, your number of servers will go up to 2. So, these are the 2 alternatives; this for a morning shift; it is not for the whole day because for the rest of the day, your lambda may change and even your mu may change. So, for the morning shift this is the, these are 2 alternatives which are being considered. 
(Refer Slide Time: 32:55)
 
So, now let us look at the data. And so all the calculations have been made with s equal to 1 and s equal to 2. And so let us look at the data. So, this is steady state results from the M M S model. So, there should be a gap between S and model, for the M M S model, for the county hospital problem, right. Now, for s equal to 1, the rho, the traffic intensity is 2 by 3. But, when it is s equal to 2, it will become mu lambda by 2 mu. So, this will be 1 by 3. So, intensity will come down to 1 by 3.
 P naught, your probability, when there is no patient in the system, in the emergency room, this is 1 by 3, and here it is 1 by 2. Then, P 1, the computed value of P 1 also, at 1 patient it will be 2 by 9 for s equal to 1, and 1 by 3 for s equal to 2. So, again the number of patients, the probability of P 1 will be 1 by 3. Then, P n for n greater than or equal to 2 is 1 by 3 into 2 by 3 raise to n; and here it will be for s equal to 2 it will be 1 by 3 raise to n. 
So, everything, obviously, we except all these numbers to come down, but the drastic difference is seen where in L c, L q is 4 by 3. So, a patient has to wait, right; the q is 4 by 3. Whereas, for s equal to 2 it is 1 by 12; so that is really remarkable difference. Then your number of people in the system on the average would be 2; whereas, here it will be 3 by 4 for s equal to 2. Then, W q, the time, average time spent in the queue waiting for to be treated by doctor, here its 2 by 3 hour; and for s equal to 2 it becomes 1 by 24. 
And so you see in an emergency room it is very, very crucial that a patient gets treatment as fast as possible because it is a matter of life and death. So, here W q being 2 by 3 if only one doctor is attending to the patients, then it is a, then the waiting time is high; whereas, it comes down drastically to 1 by 24 hours if your s is 2. Then, W, the number of people waiting; that means, q n service is 1 hour; whereas, here it is 3 by 8 hour. So, you see these are the figures which immediately tell you that it will definitely be, to the, it will be advantages to have 2 doctors because after all in an emergency room we do not want patient, patients to die because they have not got immediate attention. 
And then, probability W q greater than 0 is 0. 667 when s is 1, but it is 0.167 when s is 2 ok. So, that means, the patient coming into the emergency room will have to wait; that is high; 0.667 when s is 1. But, the moment you have 2 doctors attending it comes down to 0.167. And similarly, probability W q greater than half would be 0.404, for s equal to 1; whereas, it will be 0.022 for s equal to 2. 
So, therefore, this is also you know damaging because they, in a hospital emergency room if you have to wait for more than 1 by 2 of an hour then this is bad, and the probability is 0.404 when s is 1. So, this is not acceptable. And, similarly, W q greater than 1 hour is 0.245 which will be less than half, right. So, that is the waiting time. So, that will be 0.245, but for s equal to 2 it will be 0. 003.
See, if you just look at the numbers the other 2 are not that important. But, anyway, so this data; so therefore, we are able to then conclude that single doctor will give you a long waiting period which is not very desirable for a emergency room, for hospital emergency room, but 2 doctors you expect from service. 
And so therefore, anybody looking at this data; and this is what this model has helped us to generate the data and see that it will compare very, you can compare the performance of the emergency room, and there is 1 doctor remain, and when there are 2 doctors. So, if financier is not a consideration. It would be very helpful to have 2 doctors.
(Refer Slide Time: 37:31)
 
And then, again I just want to make a point about pooling that what we were talking the example I gave you in the earlier. So, pooling, we saw that if the waiting time is the main consideration then pooling will always have, because we saw that even with, you know, when 2 business men having their own secretaries they had to, the letters had to wait longer, but when the after when the services of the 2 secretaries were pooled the waiting time for the letters to be typed came down, right.
And, if there is some registration or something then it is a different thing; that you cannot, you have to have separate queues, but otherwise if the main consideration is to avoid long delays, then pooling is the answer. So, there, another, we know, again the model helped us to arrive at that conclusion. 
Now, let us look at another kind of model which is limited of finite q variation of the M M S K model. So, here the ideas that you cannot allow queue, more than k people in the system. So, you could just take the example of an emergency room in hospital; you know, it may not be possible to because people come, they need beds, they are, it is an emergency, or they are on stretches. So, then you definitely need room for these patients arriving for emergency service.
(Refer Slide Time: 38:58)
 
So then, you, the space is limited; and therefore, you cannot allow for infinite q size, right. Then, you can also have many other; and as we said that, you know, a petrol station, if you may not, you could not have infinite number of cars waiting to be serviced. So, therefore, again you have limited space for the cars to be waiting and that the number usually; if you are big, even that it cannot be more than 5 to 6 cars which can be accommodated by the petrol station where they are waiting to be serviced, depending on the number of pumps the petrol station has, anyway. 
So, this is very reasonable; and this model realistic situations where your limited space; that means, your finite q; you cannot allow for infinite queue. So, the only change that you would have to make in the M M S model would be that your lambda n will be lambda, for n varying from 0, 1, to k minus, 1; and for n equal to k, it will be 0. So, that means, you will not allow people to come; even once you have k people in the system then you will not allow people to enter the system essentially, right.
And here, the q will reach a steady state even if lambda is greater than s mu. See, remember, for infinite size we had to restrict lambda less than s mu, but, because otherwise the number would have blown up, right; your L, the average number of people in the system, and so on, would blow up if lambda was greater than s mu, in case you allowed infinite q size. 
So, here, because you are not permitting your queue size to be more than k, so then lambda greater than s mu is also permissible, right. And so the q size will never exceed k minus s; and the total number of people in the system will not exceed k. See, your s servers and your k size cannot be more than k minus s. Also, so as I came with example is emergency room of a hospital; also you see there are situation the places where the customers are choosy. And they would not like to wait; they would not like to enter the system as they are more than k people already; I mean, they might consider that k number to be a crowd, and therefore, there would go away.
 Now, such phenomena is called bulking because you are losing outer customers, since you have limited space. So, you are losing customers; and you may also be losing out good will. So, we will look at this aspect. And, essentially, one would like to know what kind of business you are losing now, because your people are, your customers are being turned away because there you do not have enough room. 
And, of course, for emergency rooms in a hospital registration requires, that if you cannot accommodate a patient right away, then you have to send them to another person, another hospital. So, there the registration requires that you turn away patient if you do not have enough room for them. So, all these considerations are there. 
So, we will look at a bolking, and we will try to 3 examples try to see how you estimate the loss of revenue because you have lost customers. And then, of course, that might also encourage you to invest in increasing the waiting space, waiting room, so that to compensate for the loss in business. 
So, now of course, I will give you the expressions for M M S K also, but right now it will be easier to just write down the balance equations from M M 1 K model; and then the arguments for M M S K will also not be much be different except that you will have to take care of the s server. So, for M M 1; that means, 1 server, but you have finite q. So, the balance equations will be; of course, when there is nobody there in the system then 1 arrival comes, and then you can go from P 1 to 1 departure. So, therefore, this is the balance equation, right.
 And, so that gives you P 1 equal to lambda by mu P naught. And so here you see the transition diagram is no different from M M 1 except that there will be no state after K. And so therefore, you will have only that many balanced equations. So, that is only the difference; that is why I did not draw the transition diagram, anyway.
 And so for, when there are n people in the system, then lambda plus mu, 1 arrival, 1 departure; again you are back with n people in the system; then this will be n minus 1 people; you can reach p n, you can reach n by 1 arrival. And, when you have n plus 1 people then you can reach again state n by 1 departure. And, this will be valid for n, 1, 2, to k, minus 1, right. 
And then, the last one when you have k people, when only departure is allowed, because no arrival, right. And so from P k minus; so that means, from k minus 1, again you can reach k by 1 arrival. So, this will be the last equation, right. Surprisingly, you do not answer therefore, that is ok; this makes sense because you cannot go away from here; and you cannot have any, allow any arrival here. So, this will be the equation. 
And, the interesting thing is that we will not leave this equation actually, when you are obtaining values of P 1, P 0, P 1, P 2, because from here, see, when you put n equal to k minus 1, P k value will be available U from here. So, we do not write we needed, but just for completeness sake we want to write it down. And so now, one can solve these balanced equations to get the corresponding relevant probability. 
(Refer Slide Time: 45:10)
 
So, just as for M M 1 model, we will solve this balanced equation; and, you will get P n is equal to lambda by mu raise to n P naught, n varying from 1 to k. So, let me just show you the calculations for; as I told you that the last equation will not be needed; the last but 1 equation can, will give us the value of P k. So, the last, but one equation is lambda plus mu, P k minus 1, is equal to, lambda p k minus 2, plus mu P k, right; because when there k people in the system, no arrivals are allowed. 
So, this is your last but 1 equation; and since you have obtained the formula for P k minus 1, and P k minus 2, so I just substitute. So, therefore, your mu P k is equal to lambda plus mu, times lambda by mu raise to k minus 1, minus lambda times lambda by mu raise to k minus 2, into P 2, P naught, right. Everything is in terms of P naught. 
So, therefore, just simplify; lambda by mu raise to k minus 2, you can outside. So, then you will be left with this expression; and here you can simplify. So, mu lambda; and lambda again you can take out side. So, it will be lambda plus mu, minus mu by mu; lambda is outside here. So, this gives you lambda by mu; and therefore, this becomes lambda square by mu. 
But then, you have your mu p k here, so therefore, P k will be lambda by mu raise to 2 into lambda by mu raise to k minus 2. So, the whole thing is there. So, therefore, you, there is no problem in solving your balanced equation. And then, since all the probability is must add up to 1, so you get the expression for P naught which is the geometric series here. 
And, of course, except that rho should be not equal to 1; and otherwise you can add this and that gives you 1 minus; because when rho is equal to 1 you will have a simplification. So, that can be written down immediately. So, therefore, this is your value of P naught; and so you get first form for the P n which is lambda by mu raise to n into 1 minus rho, upon 1 minus rho raise to k plus 1. So, this is valid for n varying from 0 to k, right.
Now, you want to find out the average number of people in the system. So, this will be sigma n P n, n varying from 0 to k. And, so you just substitute for P n; that is what you get. And again, we will use the same trick that lambda, n lambda by mu raise to n. So, this can be written as derivative of lambda by mu raise to n, respect to rho; so rho raise to n. So, n rho raise to n; so that will be an summation of course, you are n varying from 0 to k. 
So, if you take a rho outside, then it will be; so this will be then rho, derivative of rho is 2 n. And then again, so finite series I can interchange. So, d by d rho outside the summation, n varying from 0 to k rho n; and that gives you again geometric series; and the summation is this. So, derivative of this d by d rho on minus rho raise to k plus 1 upon 1 minus rho. 
So, differentiate the numerator; this is minus k plus 1 rho raise to k, into 1 minus rho, minus, 1 minus rho raise to k plus 1, into derivative of this which is minus 1, right; divided by 1 minus rho whole square. And just simplify; and finally, you will get this as. So, I have just separated out the 2 terms, rho upon 1 minus rho minus, k plus 1 rho to k plus 1 divided by, 1 minus rho raise to k plus 1, ok. 
So, this 1 minus rho cancels here. So, you are left with 1 minus rho, the power 2 is gone, and then the rho part here. So, rho 1 minus rho, I have written out here; and there is a 1 here. So, then this gets coupled with this. So, minus k plus 1 rho raise to k plus 1; rho is outside here; divided by 1 minus rho k plus 1. So, this usually you can see, simplifies to this expression, fine. 
(Refer Slide Time: 49:34)
 
Now, we just want to look at the long, the behavior, if you allow k to become large, you want to look at this. So, for rho less than 1, rho k plus 1 will go to 0 as k goes to infinity. And earlier, we have shown that this series is, this converges k sigma raise to, sorry; rho raise to k, summation; the series converges to rho upon 1 minus rho whole square. We have already seen this because this arithmetic co geometric series, right. And so if a series converges then the necessary condition is that the n th term must go to 0 as s k goes to infinity, right.
So, therefore, k rho raise to k, must go to 0 which implies that k plus 1 into rho k plus 1 goes to 0, as k goes to infinity. So, now, if you look at this here, this is going to 0, so this reduces to 1; and k plus 1, rho k plus 1 goes to 0. So, therefore, your limiting value of L when rho is less than 1 and s k goes to infinity. So, the limiting value of L is rho upon 1 minus rho which is the M M 1 case. 
So, you see, you can immediately conclude that, you know, when you have the M M K s; that means, you have a limited space for people to wait; that is a k people can wait; units can wait; then we, so this model relates to that. But, if you make this space unlimited; that means, there is no restriction on how many people can wait in the system then the system reduce, that then the whole process reduce this to the M M 1 case. 
So, this validates the M M K K s; that means, whatever we have derived, the values of L and so on, they are valid in the sense that they correspond to the M M 1 case, in case your space becomes unlimited, so as many people as you want can wait for to be serviced. So, in that case, it will be M M 1 case, right. So, you can, you know, so there are many ways in which you can also try to validate the model that you have constructed. So, this is one of them.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 37
M/M/I/K and M/M/S/K Models

(Refer Slide Time: 00:14)
 
See, the last lecture we talked about m m 1 case, and I will just continue with that and the basic thing to be noted is that see the difference between m m 1 case and m m 1 k case since only the q size. That is you are restricting the number of people in the system. So, for m m 1 k the number of states only go up to k, for m m 1 the states were, it could go up to infinity.
So, therefore, the derivation as I have showed you in the last lecture, the derivation was straight forward. And then see I also showed you that as k goes to infinity, and if of course, here in this case here, we require that o is less than 1, and that I am saying is that the formulae these are all valid, when rho is not equal to 1, because otherwise you cannot divide by 0. So, a for rho less than 1, we showed that as k goes to infinity l will go to rho upon 1 minus rho, which is the k infinite case. That is which is the m m 1 case, as it should be. Because, when you allow your k to become large then it reduces to the m m 1 case, and similarly the derivation for l q. So, this is l q l minus 1 minus p0, you can see that from the formulae for l q because it will be n minus 1 raise to into p n summation. So, you get this. 
And therefore, this is the expression, and here again you will see, so I write the expression for l. And, this is for 1 minus p0 and therefore, you can simplify this. And finally as because again this portion will go to for rho less than 1, and as k goes to infinity. So, this portion will become 1. Because, rho is less than 1, so I can again divide by. So, you will be simply left with rho here, k goes to infinity. So, this portion you can show will go to 1.
And therefore, this will be rho upon 1 minus rho, minus rho, which will be equal to rho l. So, again the same as m m 1 case. See, here we can there is so many ways in which you can actually show that this quantity will go to 1, just as we worked out for the l case. The same tricks you can use here, and show that this quantity will go to 1. So, therefore, this is the 1 case. And now just let us look at the probability p k, which is a very important quantity here.
(Refer Slide Time: 03:04)
 
So, p k is rho k into 1 minus rho upon 1 minus rho raise to k plus 1, when rho is not equal to 1 and it is 1 upon k plus 1 and rho is equal to 1. So, this part of course, I have asked you to do it as an exercise. Now, p k is the probability that the system is full because, you cannot have more than k people in the system. So, p k is the probability that the system is full, which can also be interpreted as fraction of time over the long run.
See remember, we are always talking in terms of steady state probabilities. So, over the long run this also can be interpreted as the fraction of time, that an arriving customer will find the system full because, it already has k people. So, therefore, no more entries can be allowed. And, so this will be a fraction of a time of the time when an arriving customer will find the system full
So, therefore, the number of customers blocked per unit time would be the arrival rate lambda into the fraction of time the system is full. And, so p k into lambda is the is the important number that tells you, the the number of customers blocked by unit time. And, so this is your lost business, lost revenue. So, this is this number is useful in determining increase in waiting space. So, I have been talking about this, what I am saying is that; see now, you can the loss of earnings because, of lost customers can be made up by allowing for more customers to join the system.
So, therefore, now the management has a very important guiding tool, this is you know you can find out that if you are losing that many customers per unit time. Then over day or a week or over a year, whatever your planning horizon, how many customers would have been turned away. And therefore, you can compute estimate the revenue that you would have earned if those customers, who are allowed in and then you can you know, compare it with the cost of increasing your services or allowing for more waiting space and so on.
So, therefore, one can then very comfortably come up to a decision, has to if you lost customers this number is large. Then you would certainly consider increasing your waiting space, and allowing for more people to be serviced, and come to the system. So, as I have been saying that you know these are a really useful models, and they help you. And, the management or the people concern people can always use these as guidelines, not again go by exact number, but at least they can be very good guidelines.
They give very good guidelines. Now, as I said special case when rho is equal to 1 is an exercise, in the problem sheet, which we will be discussing at the end of this lecture exercise nine. So, I have put this you know just for you to compute very simple, but you can then see that the all the quantities can be computed, when rho is equal to 1. That means that is this implies that lambda is equal to mu. So, the service rate, and so here again, there is no question the system growing up because, it is a finite space or a finite space model.
So, now, the case that again I will not go in to detail, but it needs to be mentioned. And, I have written down the formulae for completion sake. So, this is m m s k model. So, now, you have s server s greater than 1, and again finite space. If I not allow more than k people in the system, and certainly your number of servers have to be less than or equal to k, otherwise; it does not make sense. If you are allowing for only ten people to be in the system, and you have 12 servers. 
So, certainly the 2 servers will always be idle. So, therefore, s is less than or equal to k and this is nothing really to spend time on arriving all these formulae. Because, the transition diagram is the same as for m m s case, just as here the things were exactly the same as for m m 1 case, except that you had. We have to stop at after state k and here, m m s case these 2 are similar, except that here again you are chopping off after the state k is reached. And, so therefore, the same transition diagram and you can write the same balance equations, and then we can obtain the value for p n. 
So, this will be lambda by mu raised n upon n factorial p0, for all values of n from 1 to s, and for values of n greater than s, s plus 1 to k this will be lambda by mu raise to n upon s factorial. Then, 1 upon s raise to n minus s and p0.So, then p0 can be written as this by summing up all the probabilities. So, this is your value for p0. Now, again we will write down the formula for l and l q. The derivation is exactly the same as for m m s, and then you know go on with the other this thing.
(Refer Slide Time: 08:40)
 
So, when the expression for l q will be derived exactly as for the m m s case, but k is infinity. And, the argument will be the same exactly, you will be summing up sigma n minus s into p n upon n varying from 0 to k, instead of 0 to infinity that is all. So, therefore, that is why this portion has come in. 
So, otherwise when k goes to infinity, and for rho less than 1, you will see that this expression will be gone, And, so you will be left with this, which is exactly equal to your l q for m m s case. So, that you can derive that and this is surely your rho is this. And, so far k becoming very large, the your rho has to be less than 1, this has to be less than 1.
And then the expression for l can be then obtained from l q, and so that is all. I mean you just write down the expressions, I am doing this for the completeness sake. So, that you can yourself if you want to derive them then you can check that the answers are ok. Now, expressions for w and w q for both m m 1 k and m m s k, are not simple. So, what we basically do is; we use the computer calculations to given the values of k, and then value of s and lambda mu. We will simply put these values in, and write a small program to compute the values of w and w q.
And of course, some people in some textbooks you may find, just as we plotted graph for a m m s m m s case. You know we could plot p naught against the values lambda and s and mu, and so on. So, you will find these values tabulated somewhere, now the interesting case out of this is the 1 in which your number of servers is equal to the number of people allowed in the system; that means, you allow only as many people in the system as you have servers. And of course, an immediate example is your telephone network with s trunk lines right.
So, if you have s trunk lines, callers get a busy signal when all routes are busy. So, therefore; obviously, they cannot make a call unless some route becomes free. So, therefore, the special case is of lot of interest, when the number severs is equal to the number of people allowed in the system. And of course, the other extreme case could be, when you know when you go to a restaurant it is self service.
So, then; that means, the number of servers is equal to the number of people in the system. So, that of course, is also there. Then, maternity ward of your hospital because there also see, the number of beds that is available only you can only entertain that many patients, that many women, who are going to deliver? And so you have to turn away other people.
(Refer Slide Time: 11:42)
 
This case is also of interest, and here, in this case p s will be the will represent the fraction of time the system is full. So, otherwise in these 2 cases it was p k, but now since s is equal to k. So, p s will represent the fraction of time the system is full, and therefore, again you can find out. So, the number of customers lost per unit time will be then given by lambda p s.
If the lambda is your arrival rate then it will be the number of people who are turned away. Now, this is also called the Erlang’s loss see, Erlang’s, A.K. Erlang was a Danish telephone engineer. And, he is considered to be the founder of queuing theory in the early 20th century. So, you see it is amazing, how as a telephone engineer? He had you know excess to these you know the queuing systems. And therefore, he sort of initiated lot of ideas you know, where these the whole theory has now been developed.
Now, I like to just look at these m m s k case, through an example, and I have just adapted. See, this is from Ravindran, Phillips and Soldberg, but I have adapted it to our system. And so I have just named it the hospital as a lady Harding medical college, which is it is not school, college.
The Lady Harding medical college, which is in New Delhi. And, this is the maternity being of the lady Harding medical college. So, suppose there are 12 deliveries per day. Now, the thing is that only the labour rooms, where the people where there were people come? When the pregnant ladies come with labour pain. So, then they have to wait and then the actual. So, the labour rooms are the bottle neck because, that is where the patient lie till, the delivery has to be has to take place.
So, delivery rooms are used for actual delivery, and do not take long, and the recovery rooms are not a problem. Because, once that a babies delivered then they can be put in a general ward. Whatever; any because there is no special medical attention is needed at that time. So, the recovery rooms are also not a problem.
On the average a labour room is occupied by a patient from 3 to 5 hours, and then half an hour is taken for rating the patient for the delivery. So, therefore, this is where the bottle neck is because, this occupy the longest by a patient. So, and therefore, the idea here is that you can say that may be 6 deliveries per day. So, the deliveries that can. So, 1 labour room can accommodate 6 deliveries, 1 labour room can accommodate 6 patients a day. And of course, your arrival rate is 12 per day.
(Refer Slide Time: 14:58)
 
So, we just now look at the parameters l q, and the number of patients, who get turned away and so on. So, since the number of labour rooms is the bottleneck. So, we will call the servers, number of servers is the number of a labour rooms. So, therefore, as we saw that system can be modelled as a m m s s.
The maternity being of the lady Harding medical college, which is also has the hospital attached to it. So, that will be treated as an m m s s case since, we are taking the arrival and the service pattern to the morkovain. So, and then the fraction of maternity patients turned away is p s into lambda. So, this is the fraction of time that the system is blocked, and then a lambda is the arrival rate. So, this is the fraction of maternity patients that will be turned away.
Rate of the maternity patient turned away, which the formula for that would be lambda by mu raise to s upon s factorial into 1 upon. So, your p0 would be just adding up to, this whole thing the formula is, we have obtained it number of times by now. So, p0 will be 1 upon this only, because you will not go beyond s. And therefore, this is lambda by mu raise to n divided by n factorial n varying from 0 to s. So, this is the formula for the number of fraction of maternity patients, that will be turned away because, your labour rooms are all occupied.
So, compute the occupancy rate of the labour rooms, we compute expected value of p n, which is for which our notation is l; that means, the average number of people in the system, and this is will be summation j varying from 0 to s j into p j, because either you do not have any patient or you have 1 2 3 up to s only. Because, you only permit as many patients as there are labour rooms. So, therefore, l q is 0 there will no waiting queue, there will be no people waiting in the queue, and summation. So, 1 minus sigma p j j varying from 0 to s minus 1 is equal to p s.
So, with these conditions we can compute this, and that will give us the occupancy rate of the labour rooms. Now, let us compare the ah situation; that means, the hospital has the college the college authorities have a choice, whether to continue with the current 2 labour rooms or to increase the labour rooms. So, that you do not call this comfort, and you do not turn away too many people because, that certainly has a reputation on the hospital if you are saying that all the time your beds are full.
Your labour rooms are busy. So, when s is 2 because your lambda is 12 and your able to the labour room can be used, occupied the number of times it can be occupied is 6. So, we will say that the service rate service rate is 6 and the arrival rate is 12. So, twelve by 6 square into p0 right your p s from here and your p0 will be...
So, this is 2 square upon 1 plus 2 plus 1 by 2 into 2 square, because your s is two. So, just apply this formula, and when you do the computations it comes out to be 4 by 5. Because, your p0 is 1 by 5 and this is 4. So, 4 by 5 is your, which is you can see is high. Four; that means, the fraction of time you turn away patients is 4 by 5. And, the number of patients turned away. So, the rate of number of patients turned away per unit time will be 4 by 5 into 12, which is 48 by 5. I mean per day you are turning away 48 by 5 patients, you are not able to accommodate them.
When you have 2 labour rooms, and these of course, see here this I do not consider this is really important. Because, this will depend on the since your only allowing as many people as there are servers, the number of labour rooms. So, therefore, this is just as you that as you are calling the occupancy rate of the labour rooms.
(Refer Slide Time: 19:31)
 
This is 6 by 5 now, for s equal to 3, when you make the computations your p0 is comes out to be 3 by 19. Because, now you will go up to 3 the summation, sigma n varying from 0 to 3. So, this is the computation and therefore, it comes out to be, which is 3 by 19. So, therefore, p0 is of course, the probability that there is no there is no patient in the labour rooms, and here your p0 was 1 by 5. 
This was 1 by 5, and this is 3 by 19. Then, p 3 comes out to be 4 by 19 and therefore, the loss of patients is 4 by 19 into 12 which is 48 by 19. So, this is definitely less than 48 by 5. In fact, much less than this number. So, therefore, the loss of patients drastically comes down, by increasing 1 labour room. So, with 3 labour rooms, the average number of patients present in the hospital in the maternity ward l, will be given by p 1 plus 2 p 2 plus 3 p 3.
And. So, that will be this number into 3 by 19, which is your p 0 and. So, this turns out to be 30 by 19, which is much higher than 6 by 5, because 150 and this is 114. So, therefore, what is being said is that; which of course, is obvious in the sense that l is higher for 3 labour rooms, then when you had 2 labour rooms. So, this was your traffic intensity or utility whatever you want to call it, for with 2 labour rooms and this is. So, why? Because, you are turning away less patients, and if good will counts then certainly it is more important to have lot of good will in the community, and so 3 labour rooms may be worthwhile, then 2 labour rooms. Know considering the expense of having another labour room.
One more doctor 1 more labour nurse and so on, but anyway. So, this is something for the organization to consider, but anyway the numbers tell you something, and this is could measure to see that your utility would be higher 3 labour rooms obviously, but important thing is that you are turning away less patients.
So, that you know the whole idea it was actually in this course, the idea was not to discuss queuing theory extensively. But, I essentially wanted to show you because, after having developed probability theory, I thought it was important if you, get insight into why this theory is. So, useful and therefore, I started talking about you know its applications in the sense that. So, you have seen that throughout your discussion of queuing theory, we have almost used all the concepts of probability theory that we developed. And, other stochastic process is also, that we have the Markova process that we have discussed already.
 There also you see that you will be using, that we have used the concepts of probability theory. So, the whole idea was that while you know seeing these applications, you get a good insight, and good understanding of the probability theory. So, that was a basic idea it is not that we would trying to really cover the Markova processes, and queuing theory extensively.
So, now I will just discuss exercise 9 where I have collected some problems, and then we will continue with some more discussions of some more applications of the probability theory we have used, may be through reliability. I want to show you the applications of probability theory to reliability which will come later. 
(Refer Slide Time: 23:36)
 
So, exercise suppose, that at fixed time instance t 0, which is positive the number x t 0 of. So, now, since I have collected these problems, from different books. So, the notation may be a little different. So, here x t0 is the number of customers in an m m 1 stationary queue, we have been refereeing to the number of customers in queue as n t 0. So, does not matter.
And is smaller than or equal to 4. So, at a fixed time the number of customers in an m m 1 stationary queue, is smaller than or equal to 4. Calculate the expected value of the random variable x t0 as well as its variance if lambda is mu by 3. So, you have given rho, rho is 1 by 3, and you are asked to compute the expected value of the random variable. So, therefore, see what are the possible values of x t 0? All you have told is that it is less than or equal to 4. So, therefore, the possible values can be 1, 0, 1, 2, 3 and 4.
So, we just have to compute the probability, conditional probability, that probability x t 0 equal to say, I given that x t 0 is less than or equal to 4. So, you can do this, whatever we have learnt enough methods to compute your conditional probabilities. So, once you have the conditional p m f of x t 0 you will be able to then find out expected value, and the variance of this random variable.
So, I have given the hint also, I have said that compute the conditional probability density function of x t 0, given that x t 0 is less than or equal to 4. Now, question 2 says that for m m 1 k model, compute the probabilities p n, and 0 1 2 k, when lambda is mu. So, I had said that in the in the lecture also, that when your rho is 1, we want to find out the probabilities, and also the values of l and l q.
So, the value for p and I have already given to you as, 1 upon they all will be the same. So, therefore, it will be 1 upon k plus 1. And now, you have to compute l and l q fine. So, that is straight forward question 3 is that x t 0 is number of customers in a birth and death process, and with t non negative. Let the state space b consisting of 3 states which are 0, 1 and 2 that is the system can have no customers, 1 customer or 2 customers.
So, birth and death rates are given by... So, the transition diagram you can see that lambda 0 will be lambda, but when lambda 1 will be 2 lambda, and mu 1 is mu, mu 2 is mu. So, here they have defined the arrival rate, and the departure rate. So, the arrival rate is the when the 1 then it is 2 lambda it becomes 2 lambda. 
(Refer Slide Time: 26:57)
 
So, set up the balance equations, and find the steady state probabilities p0, p1 and p2. So, I have deliberately given this because, this is departure from your, we have not really discussed the case when lambdas also change. But, since there are only 3 possible states you should be able to write down the balance equations and therefore, then compute your the probabilities p 0, p 1 and p two.
So, I hope you enjoy doing this, then question 4 is again a this is an m m queue in equilibrium, with lambda equal to 2 mu by 3. Find the probability that there are more than 4 customers in the system, given that there are at least two. So, again this is a computation of a this thing so; that means, you are saying that your n t if you know for a fixed time t your saying that n t is greater than or equal to 4, given that n t is... 
So, there are more than 4 customers means l t is greater than 4, and then and your given that n t is at least two. So; that means, n t is greater than or equal to two. So, conditional probability of n t more than 4 given that n t is greater than or equal to 2. So, again a simple computation of the conditional probability.
(Refer Slide Time: 28:16)
 
Now, let us come to question 5, consider a 2 server queuing system. So, they are s s 2, where all service times are independent and identically distributed, according to an exponential distribution with the mean of 10 minutes. Now, the problem 5 and 6, I have taken from hillier and lieberman’s book and. So, therefore, the statements are little different, in the sense that see the service times are independent, and identically distributed, which we have been referring to as markov process. So, with a mean of 10 minutes.
So, remember the mean is 10; that means, the parameter for the exponential distribution will be 1 by 10 when a particular customer arrives, he finds that both servers are busy, and no 1 is waiting in the queue. So, then what is the probability distribution including its mean and standard deviation of this customers waiting time in the queue?
See, you are asked to find out, what is the customer comes in to the comes to the system both the servers are busy? So, you are asked to find the probability distribution of this customers waiting time in the queue. So, w q, when 2 servers are busy, now, what will be the see since the 2 servers are busy; that means, any 1 of them can get serviced, and then his turn will come. So, his waiting time is till, 1 of the service is gets completed right ok.
And so therefore, his waiting time is over in the queue the moment 1 of the services is completed. So, now, since there are 2 servers, and each of them is you know with the mean time of 10 minutes. So, once service over; that means. So, see what we have been doing. So, our mu is 1 by 10. So, now, when there are 2 servers our, this thing mu will be 2 by mu 2 by 10. So, which is 1 by 5 and therefore, the corresponding mu will be the mean service time would be 5 minutes.
So, therefore, you can then compute the so; that means, it will again be exponential with mean as 5 minutes. And therefore, you can compute the variance. I am just giving the hints, and within time in the system. Now, you can also determine the expected value, and standard deviation of this customers waiting time in the system. So, in the system when you want to compute that it will be the waiting time plus your mu.
 Because, his own service see the mean service time is 10. So, therefore, your w is w q plus mu, and your mu is 10, the mean waiting service time. See, that is not confuse here I am calling mu as 10. So, 1 by mu will be 1 by 10, which is the parameter for the exponential distribution. So, I am calling the mean service time, whichever way you like if you if you still want to refer to mu as 1 by 10, then here it will be 1 by mu. Because, his w q has a mean of 5, and his own service time has an average of 10 minutes. So, then it will be 15 minutes.
So; that means, in the system his mean time mean time in the system would be 15. So, correspondingly you will have mean, and the variance, because for the exponential distribution if mu is if 1 by mu is the mean, then 1 by mu square is the variance. So, you can compute accordingly. So, let us go to problem 6.
(Refer Slide Time: 32:00)
 
Now, consider an m m 2 queuing system with lambda equal to 4 and mu equal to 3, determine the mean rate at which service completions occur during the periods, when no customers are waiting in the queue. Determine the mean rate at which service completions occur during the periods, when no customers are waiting in the queue. So, so here it is lambda is 4 mu is 3. And, so you will compute see here, little departure and again I thought, I will give you I have put the problem in to just to show you see you will compute p 0, p 1 and p 2.
Because there are 2 people in the system 2 servers there are 2 servers. So, therefore, either no people in the system 1 person in the system or 2 people in the system. So, mean rate, when no customer in the queue. So, the mean rate, when no customer in the queue I am writing as, the formula for that is... So, mean rate when no customer in the queue.
(Refer Slide Time: 33:09)
 
So, this I am defining as mu 0 p 0, plus mu 1 p 1 plus mu 2 p 2, which is and divided by p 0 plus p 1 plus p 2. You see, by definition mu 0 is 0 since no service is completed when no 1 is in the system. So, then your mu 1 is 3, but your mu 2 becomes 6 right twice mu mu 1 this is twice mu 1. So, mean rate when no customer in the queue, and this is how we are defining it. So, you compute p 0, p 1 and p 2. And then for an m m 2 queue and you can then write down this.
Now, 7 th is that server in an m m 1 queuing system works twice as fast, where there are at least 2 customers in the system. This means that your mu and t is mu if n t is 1. And so now, I am back to my notation because, here n t is the number of people in the system at time t up to time t. So, therefore, this mu or at time t that is better way to put it. So, mu and t is mu if n t is 1, and mu and t is 2 mu, if n t is greater than or equal to 2. So, here again, just change the system a little, and now, you can write down the balance equations for this system. 
And, then what is the condition for the existence of the limiting probabilities, and you can compute the probability. I have kept the thing. So, small and therefore, you can you know do this changes in experimental that. Question a tells, what is the average number of customers in an m m 1 queuing system? In equilibrium given that the number of customers is an odd number, which is you have to find expected value of n t, where n t is an odd number.
So, here again I have taken this problem from hillier and Lieberman, now see remember you have to just compute the expected value. So, your n t will be equal to 2 n plus 1, as n varies from 0 1 to n since we are asking for odd number of people in the system. So, to find the expected value this is the conditional expectation. So, expectation of n t given that n t is odd.
So, which you will write as 2 n plus 1 summation n varying from 0 to infinity, 2 n plus 1 into probability that there are 2 n plus 1 people in the system. And then divided by number of the probability of they are being odd people in the system, which is sigma n varying from 0 to infinity, probability 2 n plus 1.
There is a customer, who was unable to enter an m m 1 c. So, here again c means your k; that means, finite capacity queuing system at time t 0 decides to comeback at t 0 plus 2, what is the probability that the customer in question is then able to enter the system given that exactly 1 customer arrived in the interval, and was unable to enter the system. So, this I will leave for you people to you know really think about it because, this is interesting and it is challenging problem. 
So, let us see that you are able to crack it. So, the whole idea is that between t 0 and t 0 plus 2 somebody arrives the system is still full. So; that means, exactly at t 0 plus 2 there is 1 vacancy; that means, one of the services has been completed. And therefore, this person is able to so; that means, at t 0 the system was full and then exactly at t 0 plus 2 the system is empty has 1 vacancy and. So, this person can enter. So, you have to work out this problem. So, I hope you enjoyed doing this assignment sheet.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics & Statistics
Indian Institute of Technology, Kanpur

Lecture - 38
Application to Reliability Theory Failure Law

 (Refer Slide Time: 00:15)
 
So, now the last topic that I want to consider in this course is applications to reliability theory. That means, again the concepts that we have learnt during the course of probability theory, want to show you some applications of course, some, everything may not be new, but still we want to put them altogether, so that you have a good feeling about.
And of course, see the reliability theory is very, it has become very important now with systems, the systems, very complex systems, you know, coming in, and then besides that you know, you have lot of dependence on the systems’ functioning, otherwise if something fails, then lot of things connected with it also fail and you know, there is a chaos. So, so there is a very growing area and we see that the applications are really interesting and very meaningful. So, you can model situations here also through the tools, that we have learnt during the course.
Now, so first of all let us first understand what we mean by reliability of a system. Now, just for example, consider a steel beam under load. And so you have whole structure, you know, resting on a beam and there is a heavy load, then you have a fuse inserted into a circuit, so the source of stress. So, you know, there are systems and then there are some source of stress. So, here and for example, an aeroplane wing, the planes fly at high speed, there is a lot of friction and so there is some sort of stress on the aeroplane wing also. Then, electronic device you have, this is, when it is functioning again, that is, that is sort of a stress and therefore, so one can go on writing. The number list can be very, very big, you know, anything that you use as a tool and then.
So, when, when you are using it there is some stress, some kind of stress on the tool and so things will change or things will happen. So, that means, so you have source of stress, you have a system that means, a component or a whole system, and then you talk of state of failure. So, what can happen? The beam can crack, right and similarly, a fuse can burn out or the aeroplane wing can buckle because of pressure or stress and an electronic device can just fail. You suddenly find, that your PC is not working or your, you know, electric kettle is not working or whatever it is, right. So, therefore, you know you can write down your own this things. You can take a component or a system, you can talk about what kind of stress that system is facing, and then you can also define the way the system will stop functioning.
So, essentially what we are saying is, that we have this. So, now here we can and suppose we, I define, so therefore, so we need to talk about time to failure or life lengths and it can, it can, it will be a random variable and why because you see, if you take identical components under identical stress may fail at different and unpredictable times. You really have no idea, sometimes things just stop working. So, some fail early, some may fail at later stages and so on.
So, therefore, you can see, that whatever the systems we have talked here and talked about and many other, you see, that you cannot really, of course, sure say, that ok, this component or this system will work for so long. So, there is lot of unpredictability if they are not. So, these things cannot be predicted very well. And therefore, because you never know how the stress works on a particular component or a system and also the manner of failure also varies, as I told you, because the beam will crack, the fuse will burn out and so on, ok.
(Refer Slide Time: 04:45)
 
So, yeah, so the manner of failure, you can say, fuse working one moment will fail the next moment, right. Suddenly you find, that the thing is not working. You are having good output, the radio was functioning very well, broadcasting and suddenly it goes away, goes out. So, that the beam, you know, steadily over a long period, it becomes weaker and weaker and then cracks, right. So, here again and and many other situations you can talk about. So, therefore, it is, it is reasonable or it is appropriate to, to construct a probabilistic model and then treat the life time of the system or the component as a random variable. So, this seems to be very appropriate.
And now, we will, what we will do is, we will talk about different models, that we can, that we can use for predicting or for the life time of a component or a system and we will be using lot of tools that we have learnt so far. But so first of all let us define because now with the understanding, that what we mean by system failing and the manner of failure can be very different and the unpredictability of these components or systems failing under different situations. So, we can now define reliability of a component or a system at time t say by R t. So, we will define.
So, R t will be the, we will define the reliability of a system and we will say R t is equal to probability T greater than t. So, at time t we want to know the reliability of, of a system, then this is equal to probability T greater than t, where T is the life length of the component. So, suppose let us, we are talking about a component, then T is the life length and you want to know the probability, that T will be greater than t and R t is defined as the reliability function. So, this is the reliability function. And so for different values of T we can get the value of this function, which will tell us the probability that the system is functioning at that time, right.
So, essentially when we say, that R t, when we are computing this way this probability, so if T is the life length, that means, here it is saying, that life length, this more than t. So, that means, at time t when you are computing this, the system is functioning, right. So, the probability is not 0. Well, I am not saying that. I am saying, that probability, that T is greater than t, that means, the life length is greater than… So, the system is still, that is how you will interpret this because this is the life length. So, life time of the component is greater than T. So, at time t, that means, it is functioning, the system is functioning. So, this is what, right.
Now, for a particular item, suppose R t 1 is 0.95. So, at time t 1 you compute this and it turns out to be equal to 0.95. This means, that the, that approximately 95 percent of such items used under similar conditions will be functioning at time t 1, that is what we mean. So, the 95 percent of the items will still be functioning, will be functioning at time t 1. So, this is what we mean by. So, probability being 0.95. So, probability, that the life length is more than point is more than t 1. So, this here, this you will write as equal to probability, that t is greater than or equal to t 1, sorry, T greater than t 1. So, that is equal to 0.95. So, this probability is 0.95 that means, 95 percent of such items. And the similar conditions will be functioning at time t 1 and we continue with the…
(Refer Slide Time: 08:59)
 
So, you see, we saw that if f is the pdf of T, the random variable t, probability density function. So, in that case we can write the reliability function R t as t to infinity because remember, this is probability T greater than t, right. So, therefore, this will be the integral of f s from t to infinity. So, because we were saying, that this definition tells us, that the reliability gives you the probability, that the system is functioning in the interval 0 t.
So, it has not, that it is not, sorry, the way to say it is, that the reliability tells you, that the system is functioning, has not failed in the interval 0 t. That is the better way to put it, right, because the life time is greater than t that means, the system has not failed in this interval, right. So, it can fail anywhere in the interval t to infinity, that is what reliability is, right, probability T greater than t. So, that will be written as t to infinity integral of f s from t to infinity, which it is a capital F as we denote the capital F as the cdf of cumulative density function of t, then this is 1 minus F t, right. So, this is what we can express the liability function as.
Now, we will associate another function with reliability and which is with the random variable t, which is the in failure rate Z and this is also called the hazard function. Now, if you recall, while talking about exponential distribution, I had introduced this hazard function and of course, we did not talk much about it, only I simply I showed you, that if the, if the pdf of random variable t is exponential, negative exponential, then the hazard function will be a constant. And so we will see many more interesting kinds of hazard functions. And, but anyway, we had come across this at that time, but now I am using this, that is why I said, that some of the things, which I talk about here may already have been discussed, but we are putting them all together, so that it becomes a complete unit.
So, now, failure rate we are defining as Z t is equal to f t upon R t. So, the pdf divided by the reliability function, which you can write as f t upon 1 minus F t, right, from here defined. And of course, this is defined for F t less than 1 because this, remember F t is your, F t is probability, T less than or equal to t. So, if F t is equal to 1, that means, and so this will say, that the life time is less than or equal to t. So, if this is 1, then this, that means, it is a certain event, f t equal to 1. So, f t equal to 1 implies, that by time t, the system has definitely failed, is a certain event, right. So, therefore, this has meaning only when the system is still functioning. And therefore, this is reasonable condition to impose, that this is defined for F t less than 1 because F t equal to 1 would mean, that the system has or the component has failed. So, therefore, so this is a failure rate.
And why, why is this, why are we calling it is a failure rate? This is the definition, but now let us understand why this does covers the failure rate of the system. So, consider the conditional probability T, capital T lying between small t and t plus delta t, given that capital T is greater than t. So, since I am asking for, see the failure rate has to be after time t. So, here you have to consider the inequality, strict inequality. I cannot allow equality here because my conditional event is, that T must be greater than t. So, that is why, you cannot write less than or equal to here.
So, this is what we have to consider this, I mean, what I am saying is, that the event should be described properly. So, then the probability, this less than or equal to, so t lying between, so this is strict inequality and that is less than or equal to t plus delta t. So, then by our rule, because this and this when you take the intersection actually means just this event, right, because capital T is greater than t is already satisfied, which is here. So, therefore, this conditional probability can be written as probability capital T between small t and t plus delta t divided by probability T greater than t.
And this integral form, if I take f to be the pdf, then this would be my failure law. Then, this will be t to t plus delta t f s ds divided by R t, right. Now, for small delta t, you see, I can take this to the, by the mean value theorem or ok, here you do not need small delta t. So, by the mean value theorem of integral calculus, this integral can be written as delta t, the length of the interval of integration into. So, there exist a value, a point, real number psi between the interval t and t plus delta t such that this integral can be written as delta t into f psi. So, this is well known for a mean value theorem of integral calculus divided by R t.
Now, for small delta t when I can say, that this approximately Z t into d because your failure rate is f psi of f t upon 1 minus f t. So, then I can, because my delta t is small, then this interval is very small. So, I can treat this as the value at t. And therefore, this will become f t because if this interval is small, then your psi is close to t. And so approximately I can say, this is equal to Z t into delta t because your Z t is f t upon R t. And so this is what your and therefore, Z t represents the proportion of items, that will fail between t and t plus delta t, right. That means, during the time span delta t, this is the proportionate, proportion of items and that is why, we call it the failure rate. So, among those items, which have not failed till time t, remember, because we are computing this, so this is P T greater than t.
So, all items, which have not failed till time t, then the proportion of those, which continue to work in the interval t t plus delta t. So, that is represented by Z t. So, this is, you know, an interpretation of what I defined here, Z t as f t upon 1 minus f t right. So, this was the conditional probability. So, life time is more than t and therefore, this is, so therefore, Z t is the rate of failure, right. So, that make sense, right.
(Refer Slide Time: 16:28)
 
Now, we could, we could define Z t given the pdf f of T, right. So, given the pdf of T, that means, the f determined Z t, Z uniquely, the failure rate. The converse is also true, that means, if you are given the failure rate, then you can determine your T uniquely, determine your pdf f uniquely. And once you know f, then you know, the cumulative density function also, right. So, let us see that.
So, the theorem is, that if t, the time to failure is a continuous random variable with pdf f and if f 0 is 0, where f is the cdf of t, sorry, where capital F is the cdf of t, then F can be expressed in terms of the failure rate Z t as follows. So,, then F t can be written as Z t into e raise to minus integral 0 to t of Z s d s. So, that means, once I know z, then through this function I can compute my pdf. So, if, if suppose you are, you somehow know the failure rate, you know, empirically or somewhere, then you can sort of compute the pdf also of T, right. And of course, this make sense.
What, what are we saying, that f 0 0 implies, that R 0 is what, 1. So, that means, certainly the function, this is, we are not going to be, the time is 0, then your system is not going to fail. It will take some, require some time. We will start the function, the system working or the component is working, then only after little lapse of time this is a possibility, that the system may fail or something. So, the reliability will be 1 at 0 time. And so this is not< you know, this is a reasonable assumption, that F 0 is 0 because you are talking of reliability and the reliability comes only when the system starts functioning. So, some time has to lapse before you can say, that ok, the component has failed.
So, with this condition, now let us start computing f from given z from the given failure rate. So, let us see, R t is equal to 1 minus f t, differentiate both sides that will give you R prime t. So, the derivative of F t is the cumulative density function is the pdf. So, this is minus F t, right. So, R prime t is minus f t and therefore, your Z t, which is defined as F t upon R t. So, for F t you are going to write R prime t. So, this minus R prime t upon R t, right. So, f t is minus R prime t and therefore, if you integrate this from 0 to t, this is of the kind 0 to t R prime s because that is what you have here. So, this is 0 to t Z s ds and this will be.
So, now, you have this integrant of the kind where you have numerator as the derivative of the denominator. And so immediately you know, that this is the integral of this is minus ln, minus sign is here. So, ln of R s log of R s from 0 to t, right. And now, here you see this that means, this will be, yeah. So, if you write it out, this will be minus ln R t plus ln R 0, right. This, what this integral will be, but then since f 0 is 0, R 0 is 1 and log of ln of 1 is 0. So, therefore, this is, there is no contribution from here and you have minus ln R t. So, this is what, since R prime f 0 is 0, therefore r 0 is 1, right. And so from here, yeah Z t is this.
So, I should write, therefore R t. R t, I wrote down this way and this, this I just integrated 0 to t. So, R t is, so this is ln R and this is ln R t. So, you have the equation, that Z t, Z t, I am sorry, yeah. So, what about have you obtained, yeah? Now, let that that be there, yeah. So, the long, equation has become long that is why. So, what we obtained is 0 to t Z s ds is minus ln R t, right. So, from here we are, I am saying, that this implies that R t is. So, ln is. So, e raise to, remember when we write ln, it means, to the base e. So, this could be e raise to minus 0 to t Z s ds.
And now, you have it from there. See, from this equation, our original definition because you want to compute, yeah. So, I should have finished it here. So, once you have this, now your Z t is f t upon R t. So, therefore, f t is R t into z t and R t we have just computed as this. So, therefore f t is Z t into e raise to minus integral 0 to t Z s ds. This is what our result was, we wanted to show this. And so given a failure rate z, I can compute the pdf of the life length random variable t uniquely.
(Refer Slide Time: 22:17)
 
So, there is an interesting relationship between the reliability function R t and the mean time of failure. So, expected T would be the mean time to failure, right. And so why I want to show you that. So, this is the theorem, it says that. So, the t is the random variable and R is the corresponding reliability function. So, want to show you, that E T, the expected mean time, expected value of T is nothing but the integral 0 to infinity R t dt. So, in other words, if you have this, then you can integrate this function and also compute E T. There is nothing much so great about it, we, it can use the same concept that we have.
So, remember your definition of R t is, so probability T greater than t. So, integral 0 to infinity R t dt will be integral 0 to infinity probability T greater than t dt. Now, this was, so I think I gave you this as an exercise in one of the earlier exercises when we were defining expected value of a random variable. But let me now just spend time and show you why this will be true. So, T greater than t, f integrating, now this I can write as integral t to infinity of f s ds, right, probability T greater than t was per, thus what we wrote down just now. So, it is a t to infinity f s ds and then 0 to infinity.
Now, let us integrate by parts. So, I will treat, you know, this one as a first function and this as a second function. So, integral of the first function would be simply t, right. And so we want to have this t into integral t infinity f s ds from 0 to infinity, right, plus, why will it be plus? Because when you differentiate this, so integral of the first into the derivative of the first, second and the integral of the whole.
So, when you want to differentiate this, you see the lower limit is the function of t. So, it will be as it as when you do the, you know, first integral, the integral of the first function into the second function minus, it is a minus sign. But since this is the limit is the function of t, the lower limit is a function of t. So, there will be another minus sign. So, and the derivative of this will be 1. So, then f t, so plus. So, therefore, this sign will become plus and this will be 0 to infinity t f t d t.
So, if you apply integration by parts to this, treating this as the first function and this whole thing as a second function, then you can write this. Now, you can immediately see, that there is a limit at the 0 point. So, this whole thing has to be integrated, has to be computed between 0 and infinity. So, at 0, this is 0 and this will be 0 to infinity f s d s, which is equal to 1 because remember, f is the pdf and the, and that variable t varies from 0 to infinity. So, this integral is equal to 1. So, the f is 0.
And now, here this is little complicated, but we can see, that limit here as t goes to infinity. So, you see here, as t goes to infinity this part becomes 0 and this is going to infinity. So, it can be shown, that the product here, the limit of this product will go to 0. So, once that happens, then that integral reduces to simply 0 to infinity R t d t, which is, I mean, it reduces to simply this, which is t f t d t from 0 to infinity and this is your P T, right, and so you have this relationship.
So, either way you can use, I mean, if you, if you know this, when you can say, that this integral is equal to this or if you know R, then you can, by integrating this you can compute the expected value over random variable t.
(Refer Slide Time: 26:49)
 
So, now it is we want to study various failure laws. That means, we want to find out the different pdf’s, which will be suitable for different situations where we want to study. And of course, we will keep it very simple here, not going to complicated results. But just look at various distribution, some of the distributions and we will show why they are appropriate for modeling certain situations for reliability, ok.
So, after defining your reliability function and your failure rate we are going to show how important tools they are to, you know, study these failure models, that we will be discussing. So, these are the two basic tools that we need and continuously will be making use of them.
Now, the questions, that arise, the first question, of course, then we will ask what underlying failure laws are reasonable to assume there is, what should be the appropriate form of the pdf of t we want to know. And of course, people have, you know, computed data, I mean, collected data and then try to fit this various probability laws, which are, which are normal exponential and so on. So, that is what, say, at some of the tested pdf’s we are going to look at. And tested, by tested we mean, that you know, you try to, you have the data, you know system is going on and then you compile the failure times and so on, of the components and then you try to fit curve. And these, the ones test we discussed, now have been very well tested and you know, found suitable for the some particular data that is we are going to talk about, right.
So, when there is wearing effect on the components, just as we said, that you know, been under heavy load, so slowly, gradually there is a wearing effect, and then breaks down. So, for such situations where the wearing effect is the one, which is the cause of the failure, then normal failure law is considered to be appropriate; considered in the sense, that again it has been tested. And by fitting the data, by fitting, you know, having the particular kind of data, which is, you know, which is for components failing under the wearing effect, and then you know, finding out, that yes, normal failure law, the pdf, normal pdf seems to give the quite accurate results.
So, now, therefore, we want to and there are many situations where the wearing effect is the prominent reason for the failure of the, or the breakdown of the component or the system now when you look at the normal law. So, because the normal law is such, that you know, if mean is the mean expected value, so mu is, yeah. So, I am looking at the normal law, which is mu sigma square. So, mean is mu, the expected value is mu and variance is sigma square, then this has the bell shape, the normal. So, we have already studied in this course, I do not have to spend time on describing the normal curve to you, right.
And we know, that if you, if you take the area between mu minus 2 sigma and mu plus 2 sigma, then area under this, this two is 0.9572 and if you go up to 3 sigma mu minus 3 sigma mu plus 3 sigma, then of course, very little area is left out. So, almost, I think, 0.99 something the area within these two limits. And you also see, that for t is equal to mu, this point is the mean as well as the mode. That means, the maximum failure will occur at around the time t is equal to mu, right. But since our variable t takes only non-negative values, therefore we will consider the normal distribution, that is, only the portion from 0 to infinity and not from minus infinity to infinity. So, this is the.
(Refer Slide Time: 31:06)
 
So, normal failure law implies, that most of the failures occur around t is equal to mu, which is the expected value and number of failures decrease as t minus mu decreases in absolute value on either side, right. So, the number of failures will decrease and the probability goes down.
And so for example, if you take normal failures law, means, that 95.72 percent failures take place for t satisfying this mod t minus mu less than. So, that means, if your t is in this area,, then so it will be from 0 to infinity only, only this portion. So, we do not have to worry about this, yeah. So, whatever the mean, the expected value, the maximum failures will occur this time.
Now, if you look at R t, the reliability function, then the reliability function, yeah, so R t is equal to 1 minus probability capital T less than or equal to small t, right. Because this is R t is equal to probability T greater than t, which can be written as this. And now, here you can write this probability for in terms of the standardized normal variant, which we have been doing all along in this course. So, this would be equal to 1 minus probability T minus mu divided by the standard deviation. So, this is less than or equal to t minus mu by sigma, right. And so this becomes 1 minus phi t minus mu by sigma, which is equal to 0.9, that I was just considering the value. So, this is the, this is the function, functional form for your reliability function.
((Refer Time: 26:49)) And if you plotted here on the t axis, then it will be something like this. So, at, at 0, t equal to 0, your probability T less than or equal to 0 is 0, right, because t has, takes only non-negative values. So, this probability is 0, at small t is equal to 0. So, therefore, this is equal to 1. So, at 0 your value of R t is 1 and when you take R mu, then this will be t less than or equal to mu.
Now, since t is normally distributed, we know, that area, this, this area, that means, this whole area is equal to 0.5. Right half, the area is on this side and half the area, it is a symmetric curve. So, therefore, this would be 1 minus 0.5, which is 0.5. So, therefore, for mu equal to, so this is at mu t equal to mu, the value of R t is equal to 0.5. So, this is the kind of curve when, then it goes to, as t goes to infinity, this goes to 0. So, the reliability function decreases with time.
Now, yeah, so I was saying, that see what you can see from here is, this is your reliability function. If you want high value for the reliability function, then obviously, so that means, you want this whole thing to be high, which that is, what I was saying here. So, suppose this is equal to 0.9 and this implies, that this must be small and if, for this to be small you can again tell by the graph, that t must be away from mu. This is the whole idea, right. Because as we said, that maximum failures will occur around t equal to mu, and as you get away from mu, the values become smaller. So, if you want this whole thing, if you want high reliability, then your value of t must be removed from mu, right.
So, for example, if this is 0.9, then this implies, that your phi of t minus mu by sigma should be 0.1, right. This you bring here, then 1 minus 0.9 would be 0.1 and so that will make it, make t minus mu by sigma equal to minus. So, you look up the tables, right. Again I do not have to spend time on this, the standard norm because this is now standardized normal variant.
So, you look up the numbers table, among the tables corresponding to 0.1 area you look up. So, it will be somewhere here for the standard normal thing. So, it will be somewhere here point because you want only area 0.1 up from up to this point. So, it will be very small, right. So, this is minus 1.2 and so t comes out to be minus 1.2 times sigma plus mu. So, that much remove from mu, your value of t is, if you want reliability of the order of 0.9.
So, take another example. Now, here suppose the failure rate, the time, life line, life time of a component is normally distributed with mean mu and variance 100, that is, right. So, the standard deviation is 10. Suppose, this is this and you are told, that the reliability for the 100 hours is 0.99. So, R of 100 is 0.99, you have to find the value of mu, that is, the expected value of T you have to find. So, since we know the functional form for R t, that means, again 0.99 is 1 minus phi of. So, we standardize the normal this variant t, which is 100 minus mu upon 10 standard deviation, right. So, this is phi 100 minus mu by 10. So, that gives you, that phi of 100 minus mu by 10 is 0.01.
So, again we look up the standard tables corresponding to the area 0.01, this value, the value of Z is equal to minus 2.33. So, the tables. So, see this smaller, this becomes the, further away you go from the mean value, that is what we are saying. And so this implies, that mu is, see here you will multiply this with this, and then so it will become 23.3 and mu comes to this side, this gets added to 100. So, this will be then 123.3 hours. So, the mu, that means, the mean is here and so you see, this is removed from the mean, this is 123.3 hours. So, at 100 hours if you are asking for a reliability 0.99, then your mu is this.
So, this is the whole idea, that you, if you have, if you, if your data or your experience with the system that you are working with is, that the normal distribution is appropriate for studying the failure rates then. So, here of course, you should also look at what your Z t will be, right.
So, if you want to compute, which may not be very. So, for example, your Z t, we said, is f t upon R t, alright. So, which will be 1 upon root 2 pi sigma, ok. Let me just, so this will be equal to your f t is 1 upon root 2 pi sigma e raise to minus 1 by 2 sigma square x minus mu whole square divided by 1 minus phi of t minus mu by sigma. So, something like this. This is your failure rate.
So, if you want to compute Z, you will get this complicated expression, but it seems, that here your reliability function is the one, which is more useful and as a simple form because all you have to do is to, for a fixed value, for a given value of t mu and sigma given, then you just have to look up the normal tables and compute the reliability of the system at any given time t.
(Refer Slide Time: 39:11)
 
Failure law, I said, to be applicable we want this, because obviously, the time to failure cannot be less than 0 with only when this apparatus or the instruments start functioning, then you talk about its failure time and so on. So, time to failure. So, therefore, since this is less than or equal to 0 and normally, R, R, the normal distribution extend from minus infinity to infinity.
But what we saying here is, that the most of the curve should lie to the right of 0. So, that means, here is, so the curve who should be like this. So, very small area is to the left of 0. So, most of it lies to the right of 0, then the computations would be fine. So, this is very important. So, that means, this probability T less than or equal to 0 should be essentially 0, negligible, very small. That is what you want to say.
Now, another way to handle this situation could be, that I consider the truncated normal distribution that means, you truncate. When you, you may have your normal distribution, this and then you truncated this portion and so that means, then you would consider. But, then since it has to be a pdf, so then you will have to. So, that is what I am trying to say, that you know, truncated normal distribution.
So, if you consider the truncated normal distribution, truncated to the left of t 0, then the pdf would be this. But that is not defecting the actually situation because by this what we are doing is, since I want to call this a pdf, so this integral, and of course, is 0 for x less than 0. So, this is from 0 to infinity. So, what we are saying is, that this will be from 0 to infinity. This will integrate to 1, but this is not what I want because I want the normal failure law, but it should be side that the most of the curve lies to the right of 0 of t equal to 0. So, that is the meaning.
And therefore, this of course, this will complicate your computations also, but besides that it will not give you the desired results. So, therefore, the truncated normal distribution is not to be considered. It is simply, that keeping this in mind we have to make, show, that you know, most of the curve lies to the right of 0. So, therefore, well, we compute the probabilities. They would be approximately alright for as I said, that the normal failure law is for the ageing where the ageing is permanent.
So, now, we will study, we look at the other failure laws, which have again been tested for different situations and have proved very, very, have to prove to show good results. So, this would be exponential distribution and viable distribution and some others.
(Refer Slide Time: 42:08)
 
So, let us look at the exponential failure law. Now, of course, obvious way to define the exponential failure law would be by defining the pdf. So, we say, that the pdf T is alpha is e raise to minus alpha t where t is positive, takes positive values, and then alpha is also some, positive constant, right.
And, then we can obtain R t and Z t, but, but that is not really have that dramatic effect as when you say, that the law, we say, that the failure rate. That means, z t is a constant, is equal to alpha, right. So, here I have just said, that alpha is some constant, but actually when your law is exponential law failure law is exponential, then negative exponential, then your failure rate, sorry, yeah your failure rate would be a constant, right is a positive constant, is equal to alpha actually. So, alpha is your failure rate. So, this is constant, right.
And immediate consequence of this is because remember we said, that we can, given Z we can uniquely determine the pdf. And also, given the pdf, we can uniquely determine the function Z the failure rate. So, here you see, the definition was, that f t would be Z t e raise to minus integral 0 to t of Z s f s. So, here z is a constant. So, therefore, this is alpha into d s. So, integral, this leads to t. So, t alpha and here z t is alpha again. So, this is alpha e raise to minus alpha t for all t non-negatives. So, therefore, this is your, so immediately you compute the pdf of t. And the converse is also immediate because if you are given, that the f t is alpha e raise to minus alpha t, then this we have already done this computation, but anyway let us just go through it again.
So, Z t is f t upon 1 minus f t, which is R t. And so f t is alpha e raise to minus alpha t and your, you know, that 1 minus f t is e raise to minus alpha t. This is probability t greater than capital T greater than small t and so it will be e raise to minus alpha t and so comes into alpha. So, this is the constant. So, your Z t, the failure rate is constant. So, immediately we can write down this theorem that. And so if I remember correctly, we had not done this part, that means, given the failure rate when I had talked about the exponential, even we would, we had just introduced the exponential distribution, I had defined the hazard function or the failure rate.
But I did not, at that time discuss this part, that given Z t you can obtain your pdf uniquely, right. So, now, we can immediately write down this theorem because I have shown you both ways, that is, if and so for constant failure rate the only pdf that can be there is your negative exponential. And if the pdf is negative exponential, pdf of the life time random variable t, then it has to be, the failure rate has to be a constant.
So, immediately we have the theorem, that let t the time to failure be a continuous random variable assuming all non-negative values, then t has a negative exponential distribution if and only if it has constant failure rate. So, this is now neat, neat way to present the whole thing, that is, there can be no other pdf, which satisfies the condition, that the corresponding failure rate is a constant. So, constant failure rate would always mean exponential pdf’s.
(Refer Slide Time: 46:04)
 
And constant failure rate implies, that it is time independent, right. So, no matter, that is, the failure does not change with time, the failure rate does not change with sign. So, no matter. So, therefore, this will be appropriate for situations where there is no wearing effect, right. So, that means, no matter how long the component has been working, it does not matter, it has no bearing on the failure of the component, it will only be some external, may be, I will come out with in the next lecture. I will try to show you some more, you know, ways of describing the situations where these different failure laws can be appropriate.
So, essentially now try to think of this situations where the failure is not because of because of the wearing effect. That means, not because of some kind of stress or load, but it is. So, therefore, as we try to say, that if you take a fuse, then fuse can be working fine for a long time and then suddenly it fails. So, it is not because may be, because of high current or something high current is come, then the fuse burns out otherwise it may continue for a long time.
So, therefore, such situations would be very appropriately modelled by the exponential failure law and one can, you know, the now, that you read about this yourself, you know, try to think of components or systems where the failures are not because of the wearing effect or this kind of some kind of load or stress, but it is a different kind of failure and therefore, this can be model by exponential law. And you can see, that how effectively it will give you the parameters that you will require for, you know, predicting things about the model.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics and Statistics
Indian Institute of Technology, Kanpur

Lecture - 39
Exponential Failure Law Weibull Law

 (Refer Slide Time: 00:14)
 
So, I will continue discussing the exponential laws very important one and any way there are some many aspects that there may be some repetition also, but does not matter. So, we said that for example, I have been giving the example of queues, which does not show the varying out effect. And are similarly a jewelled bearing you know you have them in watches. So, there is no bearing out effect on such components and they are as good as new while they are functioning right. It does not matter how long they have been functioning they are as good as new. And you have fuse has not burnt out it is like a new one, a jewelled bearing does not wear out.
So, this is again and again I am trying to give you examples of component, which for which and therefore, for such components the exponential law is appropriate and is supported by empirical evidence; that means, when you collect the data for such components how long it takes for them to fail and so on. So, then and then fitting the curve to the data it turns out that exponential law is an appropriate one was such components. So, another way of saying that there is no wearing out effect is as follows consider the conditional probability that capital t the life time lies between t and t plus delta t, given that capital t is greater than t right. Now, the intersection of these 2 events is simply this right, because here also T is greater than t and it is less than t plus delta t. So, therefore, the intersection of these 2 events is this. So, then their conditional probability can be written as probability of the intersection of the 2 events divided by probability that t is greater than t right. 
Now, this you can see immediately is the probability T less than or equal to t plus delta t minus probability T less than or equal to t so this event right. And since this is 1 minus e rise minus alpha t plus delta t minus of 1 minus e raise to minus alpha t right. So, the 1 1 cancels out and you will be left with e raise to minus alpha t minus e raise to minus alpha of t plus delta t divided by this probability, which is e raise to minus alpha t yes, of course, I am showing you for the exponential law. So, therefore, this is 1 minus e raise to minus alpha delta t, which is nothing but the probability that t lies between 0 and delta t. So, tells you that this probability is independent. So, this conditional probability is independent of t depends only on delta that is depends only on the length of the interval that you are considering; that means, you want to consider.
So that means, the here from t to t plus delta t. So, the length of the interval is delta t. So, this probability this conditional probability is independent of t and depends only on delta t right. So, therefore, this is another way of saying that it is memory less or it the varying effect is not there. That means, is not it does not matter for how long the system is already will working, but now when you want to look at the probability that it will be working in the interval t to t; that means, it fails before t plus delta then that is dependent only on delta t. So, this is the whole idea right. And so we have seen that there are many situations where this is a very appropriate law. Now, see this want to make a note here that even though this will, this probability will all if would say t less than or equal to capital t less than or equal to t plus delta t this will also come out to be the same as this one right. 
But since, we are considering the conditional probability that t is greater than capital t. So, therefore, we have to consider this event right and not this event. So, sometimes inadvertently may be one can I may have written it like this, but the when you looking at this conditional probability then it has to be t strictly less than capital t and here it is less than or equal to t plus delta t. So, that would be the right way to write the event and the even though, because of the continuous case the 2 probabilities may come out to be the same. This is the important. So, thus as long as the component is working it is as good as new.
(Refer Slide Time: 04:47)
 
Now, in this equation suppose, I expand the right hand side so expansion for e raise to minus alpha delta t right. So, all of you should be familiar that much calculus everybody has done. So, you can write down the expansion for the e raise to minus alpha for delta t, which will be 1 minus alpha delta t plus sorry, this should have been 2 factorial and so on, powers of delta t. And then when you open up the brackets 1 cancels out and then will be have alpha delta t plus higher power terms containing powers of terms like delta t square delta t q and so on fine. Now, when delta t is small, we can just ignore these terms and therefore, for small delta t probability of failure in time delta t is proportional to alpha delta t. So, this is what again just reiterating what we have been saying. So, now, in fact, we have given it better expression from here this is more you can immediately you conclude quite a few things from here. So that means, in a small interval no matter where the time interval is length delta t is the probability of a failure in that time period is proportional to time period itself delta t.
Now, this is if you again see I am saying the same thing again which I said. So, this is nothing but your Poisson process. This is the one of the basic assumptions of a Poisson process. In fact, what you can say now here is that, suppose you have a electronic device and you have lot of components, which have the same, which follow the same exponential failure law and they have the identical distribution that is the same the same parameter lambda let us say right. And then your… And of course, the components behave independently. So, that that condition also for a Poisson process is satisfied that is the, you know arrivals are independent. And so here the components will behave independently. So, their failures will also be independent of each other. So, that assumption plus the assumption that with an in a small interval the probability of a failure is proportional to alpha delta t ok.
So, then in that case with those 2 assumptions you can then say that, if you are considering let us say time period 0 comma t then the number of failures within this time interval will follow a Poisson process. So, you can see that the arrival and the inter arrival times that will talk in detail later on. So, the inter arrival times and the arrival pattern. So, inter arrival times would be exponential and the arrival patterns would be Poisson and so on.
So, we will continue with that discussion. So, now, because again we want to say this thing now that since the for the exponential failure law, the failure behavior of an item depends only on the length of the time period being considered and not on its past history right. So, therefore, and for the non exponential just like, we have so far considered the normal failure law. So, for non exponential failure laws, we pass this matter it does matter right, when you are under we know stress then the varying out effect is there and so it depends on how long the stress has been and so on. 
So, for non exponential failure laws we pass thus matter. So, therefore, it is important to understand that when you talk of the time t, you know life length. So, for the exponential failure law t will denote the time in service up to failure right, because it does not matter when you start counting it is if the component is functioning then you start counting the time from then. So, up to failure t will denote the time it does not matter when you start counting it right, but for other for non exponential components t will denote the total life length up to failure. So, you started functioning from whatever time you count your time form that and. So, capital t will in that case the normal the random variable will be will denote the total life length up to failure.
So, total means at you whenever use start surveys or whenever you start using the item then you start counting your time from here whereas, here it does not matter you start counting from any point and then up to failure. So, the life length will denote that. So, t will denote that time period. So, it is important understand these 2 differences between you know, how you count the time for exponential failure law and for a non exponential failure law.
(Refer Slide Time: 10:09)
 
Let us look at the various graphs connected with the exponential failure law. So, this is the familiar one right, at t equal to 0 this will be 1 it will be equal to alpha right. And then it will go down this way right, as t goes to infinite this will go to 0, and then correspondingly you see z your failure law of a rate of failure z t is alpha right.
Which is the constant right and. So, it continuous to be alpha value alpha for all values of t this is your t axis this is your z t axis then f t would be of course, so 1 f t would be what 1 minus e raise to minus alpha t right, oh sorry, this function right. So, 1 minus e raise to minus alpha. So, that t equal to 0 this will be 0 and then s t goes to infinity this goes zero. So, the function finally, goes up to 1. And then your r t the failure function ho sorry, the reliability function yes, the reliability function r t, which is 1 minus f t and therefore, this is equal to e raise to minus alpha t. And so here again f t equal to 0 the value will be 1 and then it will go down s t goes to infinity. So, the reliability goes down as t goes to infinity ok.
So, this is the graph for the p d f of an exponential failure law. So, t equal to 0 t equal to alpha and then it goes down to infinity as t goes to infinity then we know that the failure rate z t the hazard function this is a constant right. And the constant value is alpha then cumulative density function which is f t equal to 1 minus e raise minus alpha t would again at t equal to 0 it will be 0, because this will be 1. So, 1 minus 1 is 0 and then it goes up to 1, the reliability function would e rise to minus alpha t so at t equal to 0 this is will be 1 and then it goes down to infinity. So, these are the 4 graphs the 4 functions relate with the exponential law and you have picture of the all 4 of them. Now, let us look at this example if the parameter alpha is given and reliability is also given; that means, r t is specified we can find t.
So; that means, given alpha; that means, your specified the failure law and then you are asking for certain level of reliability. So, you want to know what would be the time required for the equipment or the component to operate to achieve that reliability right. So, the number of hours of operation required for the specified reliability level I should say. Now, let alpha be 0.01 and reliability is 0.9. So, you want this to be obtained and your parameter is 0.01. So, if alpha is 0.01 then your mean will be what? So, for exponential distribution the mean is. So, expected t would be 1 by alpha, which is 1 upon 0.01, which is hundred hours, if you are talking if a unit of time is hours then this is hundred hours ok.
So, now, so therefore, the number of offers that are required is given by to achieve this reliability level then you are saying that e rise to minus 0.01 t, remember this is the function reliability function. So, e rise to minus 0.01 t should be equal to 0.9. So, you want that value of t, which will satisfy this equation. So, you take log of both sides and this will then give you minus 0.01 t is equal to l n of 0.9 and remember l n of number less than 1 is negative. So, therefore, this is so this is minus sign here right. And so if you, now, divide by 0.01 then you get that the t is equal to hundred into l n of 0.9.
Which comes out to be if you look up the values of l n 0.9 then multiplied by hundred that gives you 10.54 hours. So, therefore, the way you can depict this is that out of hundred components all above working simultaneously and ninety what we are saying is and if they all operate for 10.54 hours then our expectation is that ninety of them will not fail. So, after 10.54 hours ninety of them will be working. So, this is what we mean by the reliability level and so on. So, therefore, you know essentially it is question of given what and then what will you can compute. So, sometimes you may be given the time then you can compute the reliability level right. So, if you given t then you will be able to determine this number and if you are given this reliability level then you can give determine the time. Or if you given time and reliability then you can determine the parameter; that means, you can uniquely determine the exponential failure law, because you only need the parameter alpha to determine the failure law, exponentially failure law ok.
(Refer Slide Time: 15:55)
  
Let us look at another example. So, here you given the cos c interms of mu so c is 3 mu square be the cost of producing an item, where mu is the mean time to failure. So, again we talking of exponential distribution, exponential failure law and mu is the mean. So, therefore, if mu is the mean then remember the distribution the failure law would be minus 1 by mu t right, this is what you have. Now, this cost is 3 times mu square. So, which means that, if mu is small then the cost is small, if mu is large then your cost would be accordingly large right ok, which makes senses. 
So may be, because if your mean time to failure is small then you expect that the cost is also small. And if the mean time to failure is big is large number and; that means, you expect the component not to fail very early I has a long life time and then that case the cost of producing that item would be also high. So, it is reasonable to assume the cost in this way right. Now, suppose rupees d are earn for every hour, the item is in service. So, you earn a profit of d rupees per hour, when the item is functional. Now, you want so therefore, profit for item is given by the profit would be d in to t, if the life time is t hours then d into t minus the cost 3 mu square right. And t is the number of service hours right. So, find the value of mu for which the profit is maximized.
So, expected profit so certainly, because this is a random variable so we will maximize the expected profit. So, the expected profit is these right, because d of e t this is a, I mean this is not a random variable this would be some fix number. So, then d of e t minus 3 mu square and e t is mu. So therefore, d mu minus 3 mu square so exactly what ever, I saying that yeah. So, this is, so therefore, to maximize this expected profit, I would differentiate this is respect to mu is a function of mu and put it to zero. So, that gives me d minus x mu is equal to 0, which implies that mu is d by 6. And of course, only critical value and, but still you need to verify the d square by d mu square is of the function is minus 6, which is less than zero. So, therefore, the critical point is a point of maxima. So, the value that we get of mu here is value which maximizes the expected profit ok.
So, therefore, u mu is equal to d by 6 is maximizing the profit and the maximum profit is d square by 12 rupees. So, just trying to give you a feeling for the failure law, exponential failure law and the kind of problems that can be discussed and that arise corresponding to these. So, again the level is at very basic you know, the level is very basic, because this is just trying to give you a gleams of how these probability tools at we have learnt can we used for answering so many questions about day to day operations of you know systems, service systems and so on. So, this is the whole idea right. Otherwise reliability theory has become very complex and in fact, the next failure law that we will discuss is a complex one. And we just try to understand the basics of that of the Weibull failure law.
(Refer Slide Time: 19:55)
 
So, let us the talk about the Weibull failure law and you can see that. Now, the degree of complexity is going up and we have not so for discuss this distribution probability law also. So, let us look at it and the idea here is to, because the constant failure rate was only applicable to a special kind of components, which were not let us say, for which there was no wearing out effect right. So, that was a special situation and we have seen that there are so many almost electronic devices or you know behave that way and so the exponential noise appropriate for them. So, now, if you want to modify this constant rate then the Weibull failure law was thought of and this is alpha beta t raise to beta minus 1. So, now, you have introduced power of t of the time and of course, two parameters and they can more than 2 also. So, we are talking of a 2 parameter Weibull failure law. And so here alpha and beta are positive and t is greater than 0 as usual, because its 3 time lifetime wherever. So, therefore, has to be non negative.
Now, you can look at I have drawn various pictures of z t when for values of beta and different values of alpha and beta. And so may be will just look at it, let me just first compute your f t. So, remember we said that we can compute f t uniquely given the failure rate functions z t. So, then this z t e raise to minus integral of 0 to t of z s d s integral 0 to t of z s d s right, this is our formula for computing f t given z t. So, then here if you substitute for z t this is alpha beta into t raise to beta minus 1 e raise to minus integral 0 to t alpha beta s raise to beta minus 1 d s right. So, if you just look at this integral let us just compute. So, this will be s raise to beta minus 1 d s from 0 to t and the integral here is 1 by beta is raise to beta 0 to t. So, therefore, this is 1 by beta t raise to beta.
So, if I make that substitution here, I get my f t s this. So, this is the p d f connected with a Weibull failure law and the failure law is specified there. So, yeah the weight looks it is it will complicated, but just see when you put alpha equal to 1 and beta equal to 1, alpha equal to 1 beta equal to 1 then this is 1 and this will be e raise to minus t. So, e raise to minus t would be your yeah, so this would be your p d f right. The exponential with parameter 1 and that is the 1 I have drawn here right. Then if you look at the value alpha equal to 1 and beta equal to 2. So, therefore, in this case the, beta equal to 1 this will be exponential and the failure rate will be constant which will be 1. So, of course, here I have drawn it only for beta equal to 1. So, alpha is as it is, this 1 is of course, you put alpha equal to 1 also. So, anyway this is your function for the failure rate then when you put alpha equal to 1 and beta equal to 2.
Then I have drawn this one, this is the 1 for beta equal to 2, of course, not a very accurate, not very accurate figures. So, you can always Google search and then you can find nice pictures very accurately drawn graphs. So, beta equal to 2 now, you look at this thing here this is alpha 1 beta equal to 2. So, this is twice t; that means, it is a linear function of t. So, therefore, you see of different values of beta things are changing. So, if alpha equal to 1 beta equal to 1 you got constant, alpha equal to 1 beta equal to 2 you get and in fact, any value of alpha, alpha does not have to be 1. Then in that case it will be a linear function of t right, if beta is beta is 2 right. And so I have here of course, I have drawn it for alpha equal to 1 and beta equal to 2, the diagram then and the corresponding p d f will be 2 t e raise to minus t square. 
Then for beta equal to 3 for example, I have drawn the picture here also for beta equal to 3. So, then this starts taking a bet more well shape and beta equal to 3 alpha equal to 1 will be 3 times t square. So, that will be; that means, z t is quadratic function of t and correspondingly you are this thing will be. So, here when beta is 3 then of course, this is t square and then e raise to something right so quadratic into exponential function. Now, and for beta equal to 5 for example, it will become more steep like this and then as beta goes to infinity, you see, you can show that will simply be a spike no just a spike, because beta is going to infinity sorry, I mean yeah, beta is going to infinity then this will simply just spike into this thing, which will, which you call as a delta function. So, at the point yeah, so some way here it will become a spike as p term goes to infinity yeah.
So, the thing becomes narrow and narrow or as your beta goes up. So, here beta is the shape parameter therefore, you see beta is shape parameter and 1 by alpha is the scale parameter. So, why you scale the whole thing right; that means, when you drawing the thing when you. So, failure rate is proportional to power of power beta minus 1 of t. So, therefore, this is the generalization that we have made to the constant failure rate and so this is the failure rate is now proportional to t raise to beta minus 1.
(Refer Slide Time: 26:33)
 
So, you can see that yeah and then this also gives you that good feeling. Now, if an example, if your beta is less than 1, if beta is less than 1 then this will become negative. So, t will be in the denominator and so alpha beta upon t raise to 1 minus beta. And that will be for as t goes to infinity.
So, the denominator will go to 0 and therefore, this will let me show, alpha beta upon t raise to 1 minus beta right. So, as t goes to 0, this goes to infinity, the denominator t goes to 0, this goes to infinity and so no it should be the other way. I want to show that for beta less than 1 for beta less than 1 this is negative. So, when I take it here it will be positive this power is positive and so as yes, as t goes to 0, this goes to infinity, because this goes to 0 so this goes to infinity as t goes to 0 right yeah, this should be. And therefore, it is this way and then s t goes to infinity this goes to 0 and so failure rate decreases with time. Now, failure rate decreases with time let me see essentially defective items fail early and the failure rate decreases over time as the defective items have been we did out. So, all the defective items have been we did out from the population. So, that case the failure rate will decrease with time right. So, all defective items fail early and therefore, as time progress is your failure rate will decrease.
So, this is the situation that is gets small moderal when you by putting beta equal to less than 1. So, all values of beta between 0 and this thing here right. So, we should take this, then this is the situation it will suppose to moral and beta equal to 1 we have already discuss thoroughly now, here of course, since the failure rate is constant. So, as time goes on the failure rate does not change. So, this is because random external events are causing the failure that could be one of the reasons. So, random external for example, if a fuse, fuse will blow out if the high current comes suddenly in the line right. 
So, therefore, that is an external event and many others can be explained high wind and so on, for other you know ten high tension wires you can snap and so on. So, therefore, beta equal to 1, because the failure rate is constant it is understood that external events would cause the failure could be the reason for the failure. And for beta greater than 1 as we have seen failure rate is increasing with time. And therefore, this modules the situations were aging process has a role to play in the failure of the system. And that is parts are likely to fail as time goes on and this is when the stress part.
So, you see this certainly captures it is a more complex and it will more comprehensive failure law, which captures more than one situation. And you can play around by manipulating the value of beta and alpha and try to get accurate results. So, this is the whole idea and we will continue with the discussion on Weibull distributions.
(Refer Slide Time: 30:13)
 
So, let us make this have computations about the expected value and the variance of a Weibull distribution. So, e t the theorem says that e t is alpha raise to minus 1 by beta gamma of 1 by beta plus 1. So, we are know the gamma function and then v t is the variance would be alpha raise to minus 2 by beta, gamma of 2 beta plus 1 minus gamma of 1 beta plus 1 whole square right, which is we are using the formula that variance is e t square minus expected value of t square minus expected t whole square right. Now, so just apply the, because we have already computed the f t the p d f for t when t e has a Weibull failure law. Then this is t into alpha beta t raise to beta minus 1 e raise to minus alpha into t beta d t right ok.
So, yes so now, you can see that, this t beta minus 1 and t beta. So, this prompts you to make the substitution that t beta is y no so we will do this. So, again you are familiar with this part of the calculus you can do this integration. So, t raise to beta is y that will make beta t raise to beta minus 1 d t is equal to d y the limits will not change will remain from 0 to infinity, since beta is positive. So, for t equal to infinity y will also be infinity and t 0 y 0. So, now, therefore, this thing whole thing gets replaced by d y. So, you have a beta t beta minus 1 and d t. So, this we will replace by d y, when you are left with t and alpha and then e raise to minus alpha y, because t raise to beta is y. So, therefore, this, what you have, alpha e raise to minus alpha y and y raise to 1 by beta and there is a yeah, so y raise to 1 by beta, because you have a t here. So, t will be y raise to 1 by beta. So, therefore, this is what you have. Now, you see this looks familiar, because you can now relate this with the gamma function gamma p d f. So, here alpha e raise to minus alpha y then you have to have alpha y here as the variables alpha y raise to 1 by beta. 
Now, y 1 by beta is there so alpha 1 by beta m adding here. So, therefore, I will divide by alpha 1 by beta and then I need a gamma of 1 by beta plus 1. So, this integral d y to be 1, because this is the p d f of a gamma distribution with parameters alpha and 1 by beta. So, then be I am left with this and this final. So, therefore, the expected value of the random variable t where t is has a Weibull failure law is given by gamma of 1 by beta plus 1 into alpha raise to minus 1 by beta right. And then the second part should be straight forward. So, you had this. So, therefore, I need to compute expected value of t square and so that will be t square alpha beta t raise to beta minus 1. So, now, you see you are again beta t raise to beta minus 1 and e raise to t raise to beta would become this thing yeah I am sorry, I mean beta t raise to beta minus 1 d t that will be d y from here right. 
And then you have t square so that will be y raise to, I am not written the integral here. So, anyway this will that is reduce this will be equal to 0 to in, I have written t this is 0 to infinity yeah, this will be 0 to infinity. So, y raise to 2 by beta and then you have an alpha and then you have t raise to minus alpha y d y right. As so here again I will do the same trick that I did here. So, alpha e raise to minus alpha y is there, then this you need to write this 0 to infinity alpha y raise to 2 by beta alpha e raise to minus alpha y this is the same thing. And then you will divide by alpha raise to 2 by beta then you need a 2 by beta plus 1 right and you will multiply by 2 raise to beta y gamma of 2 beta plus 1 2 by beta plus 1 and so this whole thing will be and there is a d y right. So, then you will be left with gamma of 2 by beta plus 1 into alpha raise to minus 2 by beta. So, this is the expected value of t square right. And therefore, the variance will be this minus the expected t whole square.
(Refer Slide Time: 35:01)
 
So, you take out alpha raise to minus 2 by beta common and then you have so this is just for you now come. And they here again we could make use of the gamma distribution computations to compute the expected value on the variance. Now, again so we have seen that Weibull distribution represents and appropriate model all if failure law whenever the system is compose of number of components right. And the failure is primarily due to the most severe flow how many large numbers of flows in the system. So, this is what is happenings, you have lot of components and lot of parts in the device that you have using and each one of them has a flow, but then it will be govern by the most severe flow of among all the components. 
This is what the, you know you can say that this is the representation of there is a situation, but which Weibull distribution represent and your alpha beta. And of course, you have seen that you know by changing the values of beta you can either have a increasing failure rate or a constant failure rate or a decreasing failure rate. So, this we have already seen right and yeah, so here you know I have just being able to give you, you know, short glames into the how what these distribution can do and one needs to really work at lot of examples to understand the implications or the importance or the importance of this distribution.
Now, let us just look at this example. So, each of the 6 cubes of a radio set has a life length e years. So, our time unit is year which may be considered a random variable. So, the lifetime of a radio tube in a radio set in number of years should we consider as a random variable suppose these tubes function independently of each other. So, that is important where working independently of each other what is the probability that note you will have to be replaced during the first 2 months of surveys. So, will after you know translate this to years, because the, our unit of time is and years. Now, the p d f of the failure time to failure is given by this 50 to t e raise to minus 25 t square so immediately you can recognize that, this is Weibull distribution and since t has power 1. So, your beta is to 2 right, this is beta is equal to 2, because t raise to beta minus 1. So, therefore, if beta is 2 then alpha is an of course, from here alpha is 25.
So, this is alpha beta, alpha beta into t raise to beta minus 1 e raise to minus 25 t square, because this is beta. So, this is the Weibull distribution right. Now, of course, we have not made this computation for the Weibull distribution, but certainly you can do it and may be you can use in my recover method. So, essentially yeah, it is a Weibull distribution with these are the parameters then you since the tubes of functioning independent of each other and you do not want and of course, let me say that your t is 1 by this is 2 months so 1 by 6, which I have written it here right. So, t is 1 by 6 you want to, you have capital t right.
So, yeah, so we want their 6 tubes there working independently of each other we do not want anyone of them to fail so therefore, in the first 2 months. So, the probability of let us say the first tube not failing in the first 2 months is t 1 greater than or equal to 1 by 6. So, time unit is 1 by 6. And then since all of them are independent of each other we do not want any of them to fail. So, then this would be probability t 1 greater than or equal to 1 by 6 raise to 6 so that is we will, you know this is not a difficult integral again you know, because see you have seen my computations here for e t and variance t. So, you can just use those you can use the gamma distribution computations to do the computations here. And then you can find out this probability raise it to 6. So, the answer is approximately 0.5 raise to 6. So, this integral you can handle now, since I have given you the method out computing e t was so exactly it just twice on to that. So, different per values of t and so on right ok.
So, now, this does not exhaust the failure loss, I have only as I told you and I have been repeating it that we have only considering very basic failure laws here and my of course, aim was to since we have discussed the probability theory and so the various tools you have learnt about. So, I just thought that I would like to show you the various applications also of these tools that we have learnt in the course. So, that has been the whole you know, whole idea the theme across the course that you learnt the theory and then you learnt to muse it also. And so Markov process is discrete Markov processes then we will we have talked about continuous Markov processes and the process special case is which are Poisson and exponential distributions and then birth and death process.
Since and finally, applications to reliability theory and here also the basic concepts have been given to you, but as I said it is a very growing large growing area very important and a lot of applications of. Of course, probability theory and the many more people have come up with failure laws, which probably supplement the theory that has been discussed.

Introduction to Probability Theory and its Applications
Prof. Prabha Sharma
Department of Mathematics & Statistics
Indian Institute of Technology Kanpur

Lecture - 40
Reliability of Systems

Now, having discuss the reliability of a component or a device, where we are assuming that a single piece, single component let me now talk about reliability of systems, where there are more than 1 component. So, here again the treatment will be simple. So, that is why I have stated in the beginning only, the simple cases will be consider, but once you learn the basic technique.
(Refer Slide Time: 00:40)
 
Then, you can always divide you know break up, complex device into smaller systems. And then you can try to compute the reliability of the whole system. So, let us see we can now, here I have adjusted beginning with this simple case. That 2 components are hooked up in series. So, this how they are right c 1, c 2 there are 2 components.
And there in series, and so for the in order for the system to work, both components must be functioning there in series, may be performing different tasks for the whole device. And, so they both have to function if any of them fails, then the system will fail. So, this is the whole idea they working in series. Now, we also make the assumption, and of course, this is important otherwise; things will get complicated, and we have to learn to methods for handling dependence also. But, right now, we just assume the independents to show you the, how to develop? How to compute the reliability of the system? So, if they are functioning independently then the reliability r t of the system can be obtained, in terms of the reliability r 1 t and r 2 t of the 2 components. So, I am just denoting the reliability of the first component by r 1 and the reliability of the second component.
I should probably write just this small t, into value of the... So, therefore, I can compute the reliability of the system in terms of the reliabilities r 1 t and r 2 t of the 2 components. When this is a simple computation we have already done it, so many times. So, here your asking for probability greater than t, and this would be this can what it means says that your t one; that means, t 1 is the life time of the first component, and t 2 is the life time of the second component.
Then we are asking for probability t 1 greater than t, and probability t 2 greater than t. Both must be functioning up to time t if you are saying that the system for the system, the functioning time are the is you know greater than or equal to t. So, now, because of independents this joint probability can be written as, probability t 1 greater than t into probability t 2 greater than t.
This is because, we have assume that the 2 components of function independently. And, so this is r 1 t into r 2 t now, because these are probabilities. So, they are each of the numbers is less than 1. So, therefore, this product would be less than the smaller of the 2. Because, if r 2 t is less than r 1 t then I am multiplying r 2 t by number less than 1. So, the whole product is still less than r 2 t. similarly, if r 1 t is the minimum of the 2 then I am multiplying r 1 t by number which is less than 1, and therefore, the product is again less than r 1 t. So, essentially what we are saying is that the reliability that the function r t, here again, I should use small t. So, r t is less than or equal to minimum of this.
So; that means, the reliability goes down. If you have components hooked up in series, then the reliability the system goes down, because this is less than or equal to minimum of the 2. So, whatever the numbers the 2 numbers here, this will be r t will be smaller than the minimum of the 2 numbers at any time t. 
(Refer Slide Time: 04:41)
 
Now, one can now generalize this result, and to say that if n components functioning independently are connected is series, and if the I th component has reliability r I t. Then, the reliability r t, I have this habit of writing capital t I do not know then reliability r t of the system is given by the product of the individual reliabilities. Because, we are assuming that the components are functioning independent of independently of the other components.
So, therefore, you have this general formula, and you see the movement you have the components hooked up in series, is many components they lower the reliability, because you require all of them to be functioning for the system to function. Now, consider a case when n is equal to 2 and the failure law of the I th component is an exponential. So, then your reliability for the system, when 2 components will be e raise to minus alpha 1 t into e raise to minus alpha 2 t, which is this is e raise to minus alpha 1 plus alpha 2 t. And, your therefore, the p d f for the system for the failure time of the system, would be minus r prime t which is alpha 1 plus alpha 2 e raise to minus alpha 1 plus alpha 2 t. So, this is negative exponential with parameter alpha 1 plus alpha two.
So, again we just repeating, what we have already learn that; if you have 2 two exponentials distributions, their corresponding random variables are independent. Then the some would be, I mean no, here we are asking for I over taking the… So, the p d f becomes negative exponential where the parameters get added up. So, this is exponential essentially this is. So, I will written it down here, alpha 1 plus alpha 2 into e raise to minus alpha 1 plus alpha 2 t. So this, what happens if you 2 components and both are exponential both have the failure law exponential failure law, and they functioning independently then for the system, if you want to make the computation for the reliability. 
Then it will be parameter added up. So, it will be alpha 1 plus alpha 2 t and e raise to minus this, and the p d f for the time to failure for the system would be exponential negative exponential distribution, with parameters alpha 1 plus alpha 2, this is it. So, now, we can look at some more examples, and then we will look at some more another kind of system, which is when you have components a raised in parallel. I have taken this example, you know from a book which got published in 1961.
So, this is Beznesky reliability theory and practice prenties hall may be the book is not available now, but I have basically chosen the example. Because, you know these figures, I am not easily available we know we failure wait for a silicon transistor composition transistor and so on. So, just for that reason and I wanted to show you the numbers because you see, what we are saying here is… So, let me read out the problem first. So, you consider an electronic circuit consisting of own silicon transistors 10 silicon diodes, 20 composition position resistors, and 10 ceramic capacitors in continuous series operation. So, they are all hooked up in series, and under certain stress conditions that is prescribed voltage current and temperature. Each of the items has the following constant failure rate so; that means, the failure law is exponential. So, for silicon diodes, it is in hours. So, the your parameters 0.000002; that means, if you convert this into; that means, the mean failure time, mean failure time will be how much? 1 2 3 4 5 6. So, you will you will have to write 1 0.000002.
So, it is a very fairly large number. So, this exactly. So, I thought that since Bezensky has some where got this data from and. So, we can use it and actually the example appears in minus book, which for which the reference I will give you at the end of the lecture. So, any ways. So, the mean failure time is you know, millions of hours will be there right 2 4 6 yes. So, thousands of hours you can see.
Similarly, these are the various numbers. So, the parameters; that means, each has a exponential failure law follows the exponential failure law, and we are assuming that they are hooked up they are they are failure I mean they are functioning independent of each other. So, therefore, just now as we saw that we just add up the parameters to get the distribution for the parameter for the failure law of for the whole system, and that will also be exponential. We just saw, it can be easily shown that of course, I showed it to you for two, but the same thing will easily can be shown for any number of…
So, if you have lot of components many components hooked up in series, each is following an exponential failure law. Then, the when you look up failure law for the whole system then that will be simply again exponential with the parameters added up. So, you have, how many you have, 10 silicon diodes and. So, the parameter is this. So, therefore, 10 times the parameter for a silicon diodes then silicon transistors they are 4 of them 4 silicon transistors of 4 times this parameter, which is 0.00001 plus 20 times we have 20 composition transistors. So, this is 20 times this plus 10 ceramic capacitors 10 times this.
(Refer Slide Time: 11:15)
 
So, the parameter for the exponentially distributed see the time to failure for the entire circuit is exponentially distributed, and the parameter will be equal to since they are 4 of them. So, 10 into would see the numbers are given to you. So, this adds up to 0.001. So, earlier in the computation I had written 4 zero’s, but actually, when you do the addition multiplication and addition it will come out to be 0.001. So, that is your mu and thus for a 10 our period of operation. The probability that the circuit will not fail will be e raise to minus mu in to 10, so mu ten.
So, the time period whatever the time period the parameter gets multiplied by that for the corresponding parameter during that period. So, e raise to minus 0.0001 into ten, which is e raise to minus 0.001. So, the final answer was given correctly, which is 0.999, and therefore, your e t will be 10000 hours. So, therefore, probability is very higher; obviously, because these diodes and capacitors have life time mean life time in thousands of hours so; obviously, for 10 our period you do not expect another system to fail. So, the probability is very high. So, therefore, we would expect the system to will be the high probability the system will continue to function for 10 hour without any failure this is the idea.
(Refer Slide Time: 12:53)
 
So, again you may say simple examples, but just to drive from the point that this kind of thinks you consider. Now, other system that we would like to there is a parallel system. So, here the system fails to function only if the of all the components fail. So, you knows the diagrammatically, you can repeat this for 2 component, if you have the component arrange in parallel.
When you it is like this. So, the input comes and then you have either it can go this way or it can go this. So, the system will fail to function only if both of them fail, because this long as 1 them is functioning, they will the things can be the input can the input can be go this if this fails when this will go this way and it will go out this way. So, this still operation will be performing, and if this fail and it will go this way. So, the operation will be still be performed. So, therefore, for the system to fail both of them have to fail. So, that is what to mean; when we say that all the components have to fail, and again and independence.
So, if we are saying that function independent of each other, and that what is expected if you have in parallel then the each component to functions parallels independently of the other. So, then if you want compute the… I do not why I keep writing capital t here. So, this is if you want to compute reliability for the system, when this is probability t greater than t which is 1 minus probability t less than or equal to t. So, there in that case this is what you want that 1 minus probability t 1 less than or equal to t and t 2 less than or equal less than or equal to t. Both of them should not be functioning by 10 t.
So, therefore, because of independence you would write this as the product. And therefore, this becomes, so probability t 1 less than or equal to t is 1 minus r 1 t, because r 1 t is probability t 1 greater than t. So, this will be 1 minus r 1 t into 1 minus r 2 t. Now, when open out multiplied the 2 terms and then you get this. So, this call reduces to r 1 t because, 1 minus 1 cancels out r 1 t plus r 2 t minus r 1 t into r 2 t. So, this is expression for the and of course. So, once we get this expression, which I can because 1 cancels with the minus 1. So, you will be left with r 1 t plus r 2 t minus r 1 t r 2 t.
Now, you see that this is this is the reliability for the 2 systems. Because, this is r 1 t into r 2 t n where assuming that 2 two systems function independently. So, therefore, you see that this is a number, which is less than r 1 t and r 1 t both. So, considered see for example, r 1 t is larger than r 2 t then this whole number is bigger than r 1 t. So, if r 1 t is maximum of r 2 and r 1 then this number this whole number because, r 2 minus r 1 t r 2 t something non negative and therefore, r 1 t plus something non negative.
This is going to come out to be and hence I can immediately conclude. So, that is what I have written that since r 1 t r 2 t is less than or equal to both r 1 t and comma r 2 t. Therefore, it follows that your reliability, when you have you know 2 components working in parallel. See, I have shown you that the 2 system have working in parallel. So, in that case the reliability of system because is greater than or equal to max of the reliability of the 2 components. So, that immediately shows that systems compose of component functioning independently, in parallel that reliability will be higher than the reliability of the of each of that components, that are in parallel. So, parallel components often used to increase reliability.
If you want to now, generalized to n components, which are functioning in parallel then this will be r t into 1 minus of 1 minus r 1 t into 1 minus r 2 t into 1 minus r n t. So, the same principle will be used, and you can show that. So, this is the important thing that when 2 so; that means, here we are considering the case when 2 components are working in parallel, and system has to fail only when both of them fail. Because, all components have to fail, in that case the reliability of the system will be greater than or equal to reliability of both the components. So, therefore working in parallel having in components in parallel and having components in series. So, this is the basic the way you make up the devices, and then I can say you can decompose them, and you know into smaller this thing.
Where you can consider component arrange in parallel, when components arrange in series, then put them together. So, I will try to show you some more examples of you know system, you know system, of components arrange in different orders 
(Refer Slide Time: 18:29)
 
So, let see take the consider the example, where 2 component are in parallel, and each of whose failure law is exponential distribution. And of course, we are assuming that first component has parameter alpha 1 the other 1 is alpha 2 then the reliability of the system when since they are in parallel. So, reliability is given by formula.
We just obtained r 1 t plus r 2 t minus r 1 t into r 2 t because they have functioning independent of each other and therefore, this will be your reliability function. And then the e t the expected time to failure for the system would be because, you know when you take the expectation will be integrating each of them separately, this t into d t this t into d t integral of 0 to infinity t into this, each them is exponential distribution. So, it will be 1 upon alpha 1 plus 1 upon alpha 2 minus 1 upon alpha 1 plus alpha 2. And you can now, since you have the old machinery with, you do all any competition that you want to do once you know the functional form of the, you know of the reliability function. You can make these computations.
(Refer Slide Time: 19:44)
 
Now, again just to drive of the point that, parallel arrangements of components definitely increases the reliability of the system. And I have take this example from Meyer’s book which again is very old one, but very good 1 and. So, the thing is that yes. So, any way I have just given reference I will give you reference, but the book may not be easily available does not matter. Suppose, 3 unit are operated in parallel, assume that each has the same constant failure rate alpha equal to 0.01. So, there are identical components. So, all have the exponential failure law, follow the exponential failure law with parameter 0.01.
Hence reliability of each unit for a period of 10 hours is, e raise to minus 0.01 into 10, which e raise to minus 0.1, which is 0.905 or about 90 percent. So, if each component is functioning by itself then the reliability is in 10 hour period that it will not fail is, you know 90 percent. Now, how much of an improvement can be achieved, in terms of increasing reliability of the system by operating 3 such unit in parallel. So, by our formula this is of course, I am not looking at the expanded form.
This is 1 minus 1, 1 minus p probability of t less than t raise to 3. So, that is what will it will be. This is what you see that I got after opening up the brackets, but if you do not do it see this whole thing you wrote as, 1 minus 1 minus 1 minus r 1 t into 1 minus r 2 to t. So, this was the formula which by which then we opened up into 1 1 got cancelled and so on. So, I am just and since they are identical. So, it will be the same function. So, it will be 1 minus r 1 t square in our case it will be q. And, so this is 1 minus 0.905 it because argue of this came out to be 0.905. So, 1 minus of that raise to 3, and that cancel to be this. 
Therefore this is equal to 0.99914 and therefore, reliability has g 1 up to 99.9 percent. So, the numbers drive on the point, and that is why it is important, that you individually if you just had 1 component in the system. Then, for the probability its operating for 10 hours would be only 90 percent, you expect 90 percent of the time it will be function still at the end of the 10 hours period. But, if you have 3 in parallel then you will almost be showed that the device with 3 parallel components, will still be functioning at the end of 10 hour period right.
So, this is the idea when therefore, the reliability can improved upon,, but I had said that it has to be verses reliability verses cost reliability verses volume of the device and so on. So, you cannot just go on having components in parallel now, see the thing is that as our saying that I discuss the very basic arrangements for you, basic systems. And then you can have things like you know series parallel. So, you have these 3 components here in series, these 3 components in series, and then parallel. So, there is no problem because, you can complete the reliability for this, and for this, and then you know how to compute the reliability for the parallel because, when they 2 are parallel.
So, we just have to you know iteratively do this arrangement we compute this we shall be the product, and this will be the product, and then it will be you know 1 minus of. So, what we have been doing, so for n. Similarly, if you have arrangement paralle,l and series then these are parallel. So, you can compute the reliability of this you can compute the reliability of this. So, this will be form your r 1, and this form you r 2, and then you are doing it in series. So, that is what I meant that all complex devices can be broken up into you, whether either they are series parallel, parallel series and so on. And then you want to put them together.
So, most of time you should come up whether reasonable functional form for the reliability of the of the whole device. And, you thing just and of course, I will discussing if you problem like this in the exercise, which will follow. So, that exercise on problem related to whatever we have discussed about reliability theory.
(Refer Slide Time: 24:45)
 
So, let me give you the reference that I have the books that I have been referring to all along in this course, and yes I agree that. So, of them are out of print,, but in any case the idea is that even though like this is a 76 edition and that 1 is 71 edition of course, ((Refer Time: 25:05)) 8 th edition have just come, and I think even the 9 th 1 may be ready.
(Refer Slide Time: 25:11)
 
So, any way the thing is to get the basic material I have to refer to these old books, but certainly substitute will be there and now lot of materials is available on the net. So, you just have to type the word that you would want, whatever subject matter you want and lot of thing come out. So, therefore,,, but in any case I just want to refer to this books, because I have use material from these books. So, the first 1 is the introduction to probability models 10th edition by Sheldon Ross this is Elserser academic press.
This I think is that 2010 addition, and may be this 1 will keep coming with new addition. So, therefore, no problem getting a copy of this book, operation we search principle and practice Don t Phillips, A Ravindren and James Solberg this is 76 th book, but some treatment or some topic have been treated very well. So, I have use a lot of example are fall from here and I have whenever I use figures, I have refer to that part also. 
So, this is 76 th book then introduction to operation search by hillier and lei berman eighth edition McGraw hill. I do not remember the for this particular year, this is being come out with new addition. So, therefore, no problem this is McGraw hill. So, cheap edition I should be available easily, and 4 th 1 that I have used is introductory probability and statistical applications, second addition pl Meyer this is classical book, and very neatly and simply, the material has been presented. 
So, reliability theory portion, I have use this book and this is the addition Wesley 1971 book. So, in any case this is, what I of my source is, where and now, you can as I told you Google search for any subject matter that you need, and that I hope you get interested enough topic to read more.
(Refer Slide Time: 27:17)
 
Now, let me just discuss the last exercise 11 with you, which is on based on probability theory. Let us just look at question 1, suppose; that t the time to failure of an item is normally distributed with e t as 90 that is mu hour and standard deviation 5 hours. In order to achieve reliability of 0.9, 0.95 and 0.99, how many hours operations may be considered? 
(Refer Slide Time: 27:55)
 
So, now you know the reliability function this is 1 minus 5 t minus mu upon sigma. So, this would be if for example, you put it equal to 0.9 and you know you do not mu is it mu is given to you sigma is also given to you now, perform the normal tables you are looking for pi t minus mu, I have d 1 problem will give like this is equal to 0.01. 0.1,1 minus 0.9 is 0.1. So, then give mu 1 sigma you will look up the tables and for corresponding 0.1 what is the value here and they corresponding value of t will be available.
So, similarly when you put 0.95, 0.99 you can accordingly get the value of t. So, how many hour of operation may be considered? So, you can answer for all the 3 value of the reliability level. Question 2, suppose, that the life length of an electronic device is exponentially distributed, it known that the reliability of the device for a 100 hour period of operation is 0.9, how many hours of operation may be considered to achieve a reliability of 0.95? So, first the first data that is given to you.
You will compute the parameter for the exponentially for the exponential failure law of and then once you get the alpha then you can compute the time. We have corresponding to the reliability level of 0.95. Question 3, suppose, that the life length of a device has constant failure rate c0 for 0 less than t less than t 0, and a different constant failure rate c 1 for t greater than or equal to t 0. Obtain the p d f of t the time to failure, and sketch it. This is sketching part I will level to you, but see here all that is saying is that you have. So, up to t 0 you have 1 failure law, and then after t 0 you have another failure law. So, therefore, but at the point t 0 the 2 you must meet right. So, therefore, you what you will say is that c 0. So, you see the required density will be c e raise to minus c 0 c as long as t is between 0, and t 0because, this is the failure law. So, the rate of failure is c 0 and is exponential failure law. So, therefore, for t less than or equal to t 0; that means, laying between 0 and t 0 you will write this. And, for t greater than t 0 it will be c 1 e raise to minus c 0 t 0 plus.
(Refer Slide Time: 30:09)
 
So, this is e raise to I should, and then you see c 1 t 0 minus t. So, since t is greater than t 0, when you write it as t minus t 0 then it will be minus here anyway. So, this is now this will be the probability density function. So, to show that f t is a p d f, we have to show that integral from 0 to infinity, would be equal to 1 and then particular. So, the first part we will integrate from 0 to t 0 and the second part of the function f t we will integrate from t 0 to infinity.
And therefore, the calculation shows, that the integral comes out to be equal to 1. So, this is the required p d f and for question 3. And then you can try to sketch it. Suppose, failure rate z is given by. So, now, 4 is special case of 3. So, here your time between 0 and a the failure rate is 0 and for t greater than a it is c. So, it is constant. So, again it is the same thing as 3 except that now, c 0 is 0 and for c 1 is c fine and . So, therefore, you can because, we have obtain the form for the failure law in 3’s now just substituting this special values you can compute you can compute the…
(Refer Slide Time: 32:07)
 
Let me just see. So, here you have to find the p d f associated with t the time to failure. So, that you can find out because, I have already obtained for you. And now, put in the value of c 0 c and of course, your t 0 is a, and evaluate e t. So, then you also a evaluate by actual integration. Now, let us look at question 5, suppose, that the failure law of a component has the following p d f. So, this is f t is r plus 1 into a r plus 1 divided by a plus t raise r plus 2 t greater than 0. So, for what values of a and r is the above a p d f we can look at it I can look at it…
Suppose, that the failure law of component has the following question 5, suppose that failure law of a component has the following p d f, f t is r plus 1 into e raise to r plus 1 divided by a plus t raise to r plus 2 t greater than 0. So, it should not be difficult because, all we have to do is hence we have to say that for what value of a and r is the above a p d f and I think if my this thing is right. Then it really does not matter it is a p d f for all a and r. Because, you see simply we write the integral as a plus t raise to minus r minus 2 and then integrate, from 0 to infinity. And then you just have I think the value of a will cancel out and r. So, you will get the integral as equal to one without specifying any values for a and r anyway.
So, now you can do this and then you can obtain and expression for the reliability function and hazard function. And show that the hazard function is decreasing in t. So, I let you do this problem. 
(Refer Slide Time: 34:09)
 
Now, question 6 suppose, that the failure law of a component is a linear combination of k exponential failure laws, that is the p d f of the failure time is given by f t is equal to sigma j varying from 1 to k c j beta j e raise to minus beta t, t n beta j from all j is positive. So, for what values of c j is the above p d f. So, now, when you integrate because, this is finite sum.
So, I can take the integral inside. And, so when you integrate beta j integration integral of 0 to infinity beta e raise to minus beta, it should be there is missing, let me write it down I think you f t should be...
(Refer Slide Time: 34:58)
 
This happen the typing errors take tripping. So, this is j being from 1 to k and this is c j beta j, e raise to minus beta j t. This is for t greater than 0 and beta j greater than 0 for all j. So, this is beta j make the correction. So, when you integrate this from 0 to infinity d t will be integrating all separate 1 this is 0 to t d t. So, therefore, now this is equal to 1.
So, therefore, this whole thing will add up to sigma c j, j going from 1 to k. So, this is the condition that all and of course, c j have to be non negative, and then you say that sigma c j while, actually it say linear combination. So, I will just to be on safe side say that c j be non negative and they add up 1. So, this becomes convex combination in that case, of all these different exponential law, and so this is also again and p d f this will be a p d f. Then, obtain and expression for reliability function and hazard function, obtain a function expression for mean time to failure.
See here again because it the summation. So, you will have to integrate if you have to compute this integral, the same principle you will use for the reliability thing you will have to show r t, when you do t to infinity. So, you again then integrate separately and. So, it will be a convex combination of all the separate reliability functions, r 1, r 2, r 3. So, it will c 1 r 1 plus c 2 r 2 plus c k r k. So, straight forward this is not right and then answers b and c beta j equal to beta for all j. And of course, obtain an expression for the mean time to failure. So, the mean to failure would be, see for each of them 1 by beta j. So, it will be summation. So, mean the failure; that means, your e t will be summation c j beta j, j going from 1 to k.
Now, let us go to next problem, then the question 7 expected life time this 3 by 2 years. So, which means that lambda is 2 by 3 again, exponential failure law. And, probability that it is still functioning after 2 years will be e raise to minus. So, it will be e raise lambda t, which is minus 4 by 3 after 2 years. So, this will be e raise minus 4 by 3 now, you want to probability the 2 still functioning after 2 years. So, 2 still functioning after 2 years at least so; that means, you may have after 2 years either 2 of them are functioning or 3 them.
So, when 2 of them are functioning it will be 3 c 2 e raise to minus 4 by 3 into 2. Because, 2 of them are functioning, and 1 of them is not functioning. So, it will be 1 minus e raise to minus 4 by 3 and all you have all 3 of them functioning. So, it will be e raise minus 4 by 3 into 3; that means, here this is. So, actually it will be e raise to minus 12 by 3. So, this will be required probability.
(Refer Slide Time: 38:42)
 
Now, this figure refers to problem 8, I think 3 independently functioning components are connected into a single system, as indicated in figure above. So, 2 are parallel and then 1 series, suppose that reliability for each of the components for an operational period of t hours is given by, e raise minus 0.03 t.
So, now by now, we have discussed all this. So, therefore, you have 3 these 2 has parallel. So, then you compute the reliability of these component, and then this together with this component c 3 in series. So, now, you do it, and they all identically distributed the failure law for the 3 components. So, therefore, you first compute these 2 in parallel, and then it will be, so which will be… I will give you the formula for this and then that into c 3. So, that will be you know multiplication.
(Refer Slide Time: 39:41)
 
So, you can do that and let us say what are else is ask. So, if t is the time to failure of the entire system, what is the p d f of t? That you can find out well, you will first find out the reliability function or you can try to find the p d f directly, what is the reliability of the system? How it compares with e raise to 0.03 t? So; obviously, I think your guess should be that it will definitely improve the reliability because, they are 2 components in parallel. So, definite even though see, the thing is that the reliability of this component consisting of c 1 and c 2 will go up, but c 3 will have the same.
And since when the take the combination in series, when you hope then up in series then your reliability is the minimum of the 2. So, therefore, you cannot say much it will almost with the same. In fact, it will not be the better e raise to 0 or minus 0.03 t. In fact, it will not be better than e raise minus 0.03 t.
(Refer Slide Time: 40:53)
 
Now, I have given you a big system here. So, this is suppose, that n component are hooked up in a series arrangement. Then k such series connections are hooked up in parallel to form an entire system. So, the figure below is given, if each component has the same reliability say r, for a certain period of operation, find an expression for the reliability of the entire system for that same period of operation. So, you should enjoy doing a just sit down patiently write down the first for these series connection, you write the reliability function for this and these it will be the same. And then you do the parallel thing. So, their k in parallel, and you have how many n in series. So, just patiently sit down, and you can write down expression for the reliability function for the whole system, should be able to do it.
(Refer Slide Time: 41:40)
 
Now, I am saying the suppose, that each of the above component obey an exponential failure law, with failure rate 0.05. Suppose, further more that the time of operation is 10 hours and that n is 5. So, now, I have give the numbers and determine the value of k in order that the reliability of the entire system equals 0.99. So, you will enjoy do this problem because, case not give to you, but then when you write down the reliability function, it will be a function of k.
And then you put value for 10 hours. Your t 10 hours then you substitute that in the expression, and put the whole thing equal to 0.99 then you will get the value of k. So, interesting problem, I am sure you will enjoy by doing it now a component has reliability 0.9 when use for a particular purpose, component B which may be used in place of component A has a reliability of only 0.75. So, A has reliability of 0.9 in for a certain period, and component B which may be used in place of component A has reliability only 0.75. So, what is the minimum number of component type b that would have be hooked up in parallel? So, now, you can write down the reliability function suppose, k you can take k number of B component and then hook then up in parallel. 
You know the reliability function, and then you want say that its reliability should be equal to 0.9. So, that also again you can use in the formulas that have give you for computing the reliability, when they are hooked up in parallel. Then when you 0.75 reliability of 1 component, then how many should be there. So, that reliability goes up to 0.9. So, these are the kind of question which I am sure you will, that is it.
So, I think this is the last lecture, and effort has been made to equinity with probability theory, basic probability theory. I would say, and then its applications and I have try to trough exercises, try give you good in site into the subject, and I hope you enjoy doing these exercises.
