COMPUTER NETWORKS
Prof.Sujoy Ghosh
Department of Computer Science and Engineering
IIT, Kharagpur
Lecture - 36
 (Refer slide time:00:47)

Our topic for today is QOSQOS and multimedia, that is quality of service and multimedia. (Refer slide time : 00:57:00:58)

We will just look at these one by one. (Refer slide time : 01:07 - 01:37)

Quality of service: What is quality of service? QOS refers to traffic control mechanisms that seek to either differentiate performance based on application or network operator requirements or provide predictable or guaranteed performance to applications, sessions or traffic aggregates. It talks about lot of things, the basic notion is that there are some applications which require one kind of quality of service. By the way the quality of service may mean so many different things but the most important of them are the network delay and the packet loss. These 2 parameters may sort of come in various ways, they affect differently when you talk about different applications. And by multimedia we mean audio, video, etc going through the net which has got a different kind of QOS characteristics, a different set of requirements than a file transfer. We will see how we can handle QOS and how multimedia traffic is handled in the network. Sometimes it may so happen that some applications are more important than others, so they need a better guarantee of performance. Such things also come under quality of service. (Refer slide time : 02:46 - 04:24)

 Take examples: Video and audio conference requires bounded delay and loss rate. That means the delay has to be bounded and also the variability of the delay should also be within the bounds and the loss rate of packets should again be bounded. As you can see, this is quiet different from a file transfer where the loss of some packets cannot be tolerated at all. It is somewhat tolerant of losses, but more sensitive about delays. When you are downloading a file, they are usually not that sensitive to trace. Video and audio streaming means maybe from video server or some internet radio, etc; audio or video is being streamed to different clients so this again requires a bounded packet loss rate. It may not be so sensitive to delay. There might be some time critical applications like real time control. Here again, bounded delay is important. There are some valuable called premium applications. Maybe those who run these premium applications are ready to pay more for this and they expect better guaranteed service than a low premium or less valuable applications. (Refer slide time : 04:25 - 04:47)

QOS requirements can be specified as delay, delay variation (jitter), throughput which is the rate at which you can send data and error rate. Error rate is something where some packets get lost. (Refer slide time : 04:48 - 08:10)
 
There are two approaches to this, stateless and stateful QOS solutions. Stateless solution: Router maintains no fine grained state about traffic. This has got a positive point that this is very scalable. Actually the kind of thing we have talked about till now is that routers do not maintain any states. It is simply the raw packet forwarding capacity that comes to this. In this way it is very scalable, this is also quite robust but it has weak services because there is no guarantee about the kind of delay or performance a particular application you will have to encounter. On the other hand, we have stateful solutions. Routers maintain per-flow state. This flow is very important while guaranteeing quality of service. Suppose there is some audio conferencing going on between some people, the audio signal nature is digitized and packetized and then these packets are going on. This is a packet switched network, essentially at the heart of it this is a packet switched network. but at the same time we not only talk about a single packet in entity in itself which is how we have dealt with packets so far but the end users are interested in the flow, that means the flow of packet. All these streams of packets that are flowing which contain these audio signals constitute a flow and the users are actually interested in the flow. Suppose somebody wants some guarantee on this service, he wants a guarantee on this service of this flow. Merely looking at packets is not enough; you have to go from a purely stateless situation to a stateful situation. Actually you have to make out that this is a part of particular flow. Naturally if you are stateful, if you go into the packet and look at what kind of packet it is and maintain a state about it in the router then you can give powerful services like guaranteed services plus high resource utilization, fine grain differentiation between different flows, protection where here there is a problem that this is much less scalable that means when the number of flows through a router starts increasing, and that is what will happen in any of the core routers, then the core router will not be able to handle this. So it is much less scalable and much less robust. (Refer slide time : 08:11 - 10:25)

Let us look at the Integrated Services. This is a fully stateful system and is also known as intserv. This is an intserv architecture or isa. It is the architecture for providing QOS guarantees in IP networks for individual application sessions. We are talking about an entire session and the flow that has gone on during that session of flow consisting of so many packets. It relies on resource reservation and routers need to maintain state information of allocated resources (for example g) and respond to new call setup requests. The point is, in this situation how will you guarantee that this particular flow which is starting will get the requested kind of guarantee of service that means its delay would be bounded etc? For this we have to specially reserve resources like buffers, resources like CPU time and so on at the intermediate points. So, you have to reserve these resources for this particular flow so long as this flow continues. That is how you give better service to this particular flow than to any other ordinary packet. It will have to maintain the state in the form of these reservations and respond to new call setup request. For example, as soon as you take out some resources, then naturally it goes out of the available resource pool and if a new call setup request comes for another session some intermediate router may not be able to handle that so it will not be admitted. Network decides whether to admit or deny a new call setup request. (Refer slide time : 10:26 - 10:55)

This is the basic idea of intserv. Therefore in this case since you have to reserve resources there is a call setup phase. This is almost like a virtual circuit which is being setup. There is a call setup request which goes from the source to the destination and back and on the way it reserves resources at each of the intermediate nodes. And if each of the intermediate nodes, that is, each of the intermediate routers are ready to provide these resources then the call will be admitted. (Refer slide time : 10:54 - 12:20) 

For resource reservation there is a particular protocol called reservation protocol or RSVP. RSVP constitutes of call setup and signaling. Then there is a traffic QOS declaration and per element admission control which means whether the call could be admitted or not. Then there will be QOS sensitive scheduling. That means, when a packet arrives first it may go into the buffer of a router and there maybe various buffers. Each of these packets will have to be scheduled for processing and then forwarding. This processing may not be done in a uniform manner but it may be done in a QOS sensitive manner. Similarly routing algorithm may also be QOS sensitive, packet discard strategies etc come under the intserv QOS components. We have talked about scheduling and some of the other things. Now let us discuss about RSVP. (Refer slide time : 12:21 - 13:44)

RSVP is internet signaling. It creates and maintains distributed reservation state. This is decoupled from routing. One thing is to use routing for setting up paths but then this has to reserved resources therefore it is decoupled from routing. It uses multiple trees setup by routing protocols, not RSVP. Multicast tree is setup by routing protocols. RSVP is for reserving protocols there unlike ATM or telephony signaling. While doing the call setup you actually assign the virtual setup. This is initiated by the receiver, this scales for a multicast and it may use soft state. That means reservation times out unless refreshed. so you have to refresh reservation from time to time, otherwise one particular flow may be reserved and never be used so that part will go away. That is why reservation will be timed-out. And latest paths discovered through path messages (forward direction) and used by reservation messages in the reverse direction. (Refer slide time : 13:45 - 14:08)

Signaling Semantics: In signaling semantics you have a setup acknowledgement, setup response, admission control, tentative resource reservation and confirmation. This can be done from both directions, simplex and duplex setup and with no multicast support. These are the signaling semantics in brief. (Refer slide time : 14:09 - 15:02)

 Suppose this is the source, the source would initiate the setup. It will send a setup call to the first switch controller, router to another one and finally to the destination. Each of the intermediate nodes send a setup ACK so that the source knows that this is the way it is going to go and the path is being setup. And then a setup response will come and the acknowledgement will go to the destination and another setup response and acknowledgement will keep coming in. What we will have to see is that, in this fashion, after this, the resource has to be reserved at each of the node for whatever service that is being asked for. (Refer slide time : 15:03 - 16:19) 

Session must first declare its QOS requirements and characterize the traffic it will send through the network. There are two specifications r spec and t spec: The r spec defines the QOS being requested, what kind of bound we want on the delay, what kind of bound we want on the jitter, what kind of packet loss is acceptable to me and depending on this the resource is going to be reserved. That means maybe a special queue or buffer will be setup just for this flow or something will be done with scheduling. There will be some weight given to it for processor time and so on in the intermediate nodes. And then there is a t spec that is, traffic characteristics like what kind of traffic, what is the burstiness of the traffic etc? Such traffic characteristic will also have to be sent. Therefore depending on the t spec and the r spec the intermediate nodes will compute what kind of resource is visibly required. So signaling protocol is needed to carry the r spec and t spec to the routers where reservation is required. RSVP is a leading candidate for such signaling protocol. (Refer slide time : 16:20 - 17:00)

As far as call admission is concerned, routers will admit calls based on their r spec and t spec that whether they can handle or they can manage to give so much resources for this. There is the financial side also, that whoever has initiated whether he has an agreement to pay for such premium service and based on current resources allocated at the routers to other calls. If other senders have already reserved most of the resources in the intermediate routers then a new call may not be admitted. (Refer slide time : 17:01 - 17:30)

This is the router, the request specifies the traffic the t spec and the guarantees of service which is required which is the r spec. Now this reply to the element considers unreserved resources and the required resources for this new request. If it can handle that then it replies whether or not request can be satisfied. (Refer slide time : 17:31 - 17:46)

 This achieves per-flow bandwidth and delay guarantees. For example, suppose we want a guarantee 1 MB/sec and < 100 ms delay to a flow and if we have a network like this, (Refer slide time : 17:47 - 18:06)

first the receiver will just allocate resources, that means perform per-flow admission control. First the path has to be setup, that has not been shown and this is in the response path, so perform per-flow admission control. (Refer slide time : 18:07 - 18:14) 

Install per-flow state, so this flow has to be recognized, for that the router has to have a per-flow state. (Refer slide time : 18:15 - 18:25)
 
 Challenge: maintain per-flow state in a consistent manner right up to the sender. If all the routers agree then only you can give it. (Refer slide time : 18:26 - 18:36)

When sender starts sending first of all it has to be classified that this is the integral part of this flow, so per-flow classification is necessary. (Refer slide time : 18:37 - 18:48)

Depending on how it has been classified, it will be put in the appropriate buffer and the corresponding buffer has to be managed, so per-flow buffer management is also necessary. (Refer slide time : 18:49 - 19:03)

And this way it will go through all the routers, and per flow scheduling is necessary for CPU resources and the flow will go through. (Refer slide time : 19:04 - 19:56)

In the data path, we have per-flow classification, per-flow buffer management, per-flow scheduling whereas in the control path we have the installed and maintained per-flow state for data and control paths. For each of the flow the router has to do a lot of work so this does not scale unfortunately. This is very good at giving services but if you are trying to maintain a per-flow kind of classification and management at each of the nodes, this would not scale because if the number of flows goes beyond a certain level then it will be very difficult to maintain. It will be very difficult to properly give it buffers and queues etc in the intermediate nodes so that is why it does not scale so well. (Refer slide time : 19:57 - 21:00)

Stateless solutions are more scalable and they are more robust. Stateful solutions provide more powerful and flexible services. It gives guaranteed services plus high resource utilization. It can make fine grained differentiation between different flows and it also receives protection on the way since we are short of demarcating each of the flows. Demarcating the flow is somewhat similar, either to setting up ATM virtual circuits, when you do that, you also reserve request but that is done while call setup itself, that is not done by a separate reservation protocol. Hence it is similar to that or it maybe similar to MPLS where a particular flow can be differentiated from other flows and it maybe treated specially. (Refer slide time : 21:01 - 22:56)   

Then on one hand you have, the raw internet just takes a packet by itself and tries to route it and if it cannot route, it is the best effort and it goes off. That means it is discarded, that is one end of the spectrum. The other end of the spectrum is that you have a full power flow classification and management for each of the flows where you can have a very good control etc but it does not scale. So there is a question, can we do something in between and that is well the next model comes which is known as a diff-serv, differentiated service. This is also stateful but here each distinct flow does not necessarily mean a distinct state. These are sort of soft states which can accommodate a number of flows together so that the pressure on the routers in the intermediate nodes or in the backbone of the network becomes less..
Scalability: Maintaining states by routers in high speed networks is difficult due to a very large number of flows. So diffserv provides reduced state services, that is maintain state only for large granular flows rather than end to end flows, tries to achieve best of both worlds. So diffserv intends to address the following difficulties with intserv and RSVP. Flexible service models: intserv has only two classes, wants to provide more qualitative service classes, wants to provide relative service distinction like platinum, gold, silver etc and simpler signaling than RSVP. Many applications and users may only want to specify a more qualitative notion of service rather than a quantitative notion of service. (Refer slide time: 22:57 - 24:00)


This is a diffserv model, you have an ingress edge router and you have the interior routers, it goes to the egress edge router. 
Edge routers: Traffic conditioning that means, policing, marking, dropping etc are done at the edge. The reason we want to do them at the edge of the network is that, there the number of flows etc is much lower and you can handle it over there and when you come to the core the core routers are very busy so we do not want to do that over there. Therefore set values in DS-byte in IP header based on negotiated services and observed traffic.
Interior routers: Traffic classification looking at this byte and forwarding near stateless core. This is almost like MPLS or ATM. Use DS-byte as index into a forwarding table. (Refer slide time : 24:01 - 24:45)

Edge router: It does per-flow traffic management, marks packets as in profile and out profile. 
Core router: It does per class TM, buffering and scheduling based on marking at edge. Preference is given to in-profile packets. In-profile means some traffic shape has been negotiated or is expected and then something comes which is out of the shape. That means somebody is sending more packets per unit time than that was negotiated, so those are out of profile packets. 
Assured forwarding: This is what the core router does. (Refer slide time : 24:46 - 25:34)  

Marking and power flow classification etc is done at the edge but in between the scheduling is done. The packet is marked in the type of service in IPv4 and traffic class in IPv6 renamed as DS. Then 6 bits used for differentiated service code point DSCP and determine the PHB or Per Hop Behavior that the packet will receive, 2 bits are currently unused. And this service code will dictate how this particular packet will be treated. (Refer slide time : 25:35 - 26:47)   

For forwarding Per Hop Behavior or PHB carried out in the interior routers is simplified process based on class and resources specified when SLA was created. PHB has been defined in a certain RFC. For example for premium service, it should have low loss, low delay, low jitter, assigned bandwidth is equivalent to point to point leased line etc is the kind of service we want, although this is not leased, this is the plain packet switch network. It is guaranteed through policing and shaping in order to stay within the departure rate of leaky bucket and WFQ. Since all the intermediate nodes guarantee that it will get premium service. Traffic conditioning: It maybe desirable to limit traffic injection rate of some class, users declare traffic profile, example rate and burst size, traffic is metered and shaped if non-conformed. We have seen this already when we discussed congestion control. (Refer slide time : 26:48 - 30:34)

The packets are classified and then they are marked. When they are classified and marked naturally for the session, some kind of t spec that is traffic spec has been already negotiated so it meters to see whether it conforms or not and then the traffic maybe shaped. If by chance some burst comes and if the system can handle it then it will keep it for some time and then forward it only at an appropriate rate. But if it goes too much then it drops it here itself.
This QOI is absolutely important especially for multimedia traffic as was explained. for ordinary data traffic like web traffic or FTP, file download etc, those usually are not very sensitive to delay and variation in the delay that means you may get a lot of packets in one bunch then packets maybe slowing and coming extra and these things really do not matter much if it is within some bounds. But in multimedia, these things are very important. For example, when we talk, if the delay is beyond a certain level then we feel very odd.  For example, few years back if you had made an international call which is routed in a very peculiar way, you would find a lot of delay if you are speaking to somebody in USA, which is quiet annoying. Additionally what is annoying is that if the delay remains constant, some other people can manage it. But if the delay keeps varying a lot, that is, if there is a lot of jitter then that is very irritating for people. On the other hand unlike data, maybe a few bits are dropped here and there; it will not matter too much. Maybe if you analyze it using machines you will find some difference in quality but as such to human perception most of the time it does not matter too much. The multimedia traffic is quite different from ordinary data traffic. And as network is spreading and the way it is going, people find it cheaper and most convenient to use this internet or use this computer network for what was traditionally telecoms domain in the sense for audio or video conferencing. We have discussed about inserv, diffserv, RSVP etc, but the trouble is, many of the routers on the way are not going to support this because you need a consistent support throughout the path. So people still try to use the raw internet which is just handling it at the packet level not really taking note of the flows and still try to handle multimedia and for that a set of protocols has evolved. Let us just look at those protocols now. (Refer slide time : 30:35 - 31:17)

Principles: Classify multimedia applications; identify the network services that the applications need. Making the best of best effort service, you already have a best effort service and how can you make the best of it is what we will see in RTP, etc and there are some mechanisms for providing QOS. These are specific protocols for best effort and architecture for QOS. At the network level if you have supported QOS these would have gone through much better. (Refer slide time : 31:18 - 33:24)

There are various classes of MM applications and not all are the same. There is streaming of stored audio and video, that is one kind of application, for example, you download a song, movie that is a streaming, the stored audio and video is being streamed. Then there is streaming of live audio and video, then there are real time interactive audio and video and by this way you can generally classify. By multimedia application you mostly need audio and video so by this way they can be classified. 
Fundamental characteristics: They are typically delay sensitive. They are also sensitive to delay jitter which is a variation in delay. 
Loss tolerant: Infrequent losses cause minor glitches, so this is the antithesis of data which are loss intolerant but delay tolerant. Sometimes we like VCR like functionality. suppose we are seeing a video, so we try to equate it with the kind of functionality like in a VCR so client can pause, rewind, fast forward, push slider bar etc. And at the same time when a multimedia session starts maybe an initial delay of 5, 10 seconds is acceptable, 1 to 10 seconds until command effect is also acceptable but we need a separate control protocol because we really have no other way of getting any kind of control, feedback, etc on these streams as we will see. Timing constraint for still?to-be transmitted data: In time for play out.  (Refer slide time : 33:25 - 34:42)   

Suppose we have, streaming of stored multimedia. Suppose this is the recorded video which is being sent, this is the cumulative data that has been sent, this is like a staircase because they have been sent as packets so chunks of data is going together so they are being sent. First of all you record the video and the video is sent and in the third position the video is received and played at the client. This is streaming of stored multimedia. There is a network delay in between when the video is sent and the video is received. As soon as you send it, you cannot start seeing it, 
Streaming: At this time the client is playing a part of the video while the server is still sending the later part of the video. Maybe in this particular diagram the client has already started seeing something although some of the data has still not been sent. (Refer slide time : 34:43 - 38:05)

Therefore the streaming of stored multimedia is different from streaming of live multimedia. For example, internet radio talk show is a live multimedia, a live sporting event which is being web cast. Streaming has a playback buffer, so playback can lag 10?s of seconds after transmission but it still has some timing constraint. The interactivity is limited, for example, obviously if it is live you cannot fast forward it but rewind and pause maybe possible. It solely depends on how you handle it. So this is unlike a stored multimedia where fast forward would also be possible. 
Interactive real time multimedia: Is one of the most important applications like IP telephony, video conference of the web, distributed interactive worlds etc are the applications of interactive real time multimedia which has the most stringent QOS requirements.
End-to-end delay requirements: Different applications have different kinds of requirements. for example if it is audio, if the end-to-end delay is less than 150ms it is good and less than 400ms is acceptable but beyond that people seem to be bothered a lot. It includes application level that is packetization and the application level delay and the network delays. Higher delays are noticeable and they impair the interactivity. 
Session initialization: How does callee advertise its IP address port number, encoding algorithms etc because like in an IP telephony call all these issues are there. If you are using a standard TCP or UDP IP this is what you would have to do actually but there are no guarantees on delay or loss. But multimedia application requires some QOS and level of performance to be effective.
Today?s internet multimedia applications use application level techniques to mitigate as best as possible. This is what we mean by best efforts, this means we cannot do anything, maybe at the network layer etc it would implement an inserv or diffserv, but in most of the places that is not practical at the moment so we try to do something at the end points i.e. at the application level. The application level necessarily means the end point because it is the intermediate, it will not go right up to the application layer but maybe it will penetrate a little deeper. This is mostly done from end to end. (Refer slide time : 38:06 - 40:18)

In this pseudo protocol, the number of protocols, first we look at real time protocols RTP that is RFC 1889. RTP specifies a packet for packets carrying audio and video data. So RTP packet provides payload type identification such as what type of payload it is carrying, packet sequence numbering, time stamping that is important for giving some feedback. RTP runs in the end systems. RTP packets are encapsulated in UDP segments.
Interoperability: If two internet phone applications run RTP then they maybe able to work together and may communicate to each other through the network. RTP runs on top of UDP. We have seen in both TCP and UDP, the UDP is a very lightweight protocol so it is also expected to be much more efficient than TCP. TCP is a heavy weight protocol so it has a lot of overhead and all these ACKs keep on flowing. RTP libraries provide some kind of support over an above the transport layer library, that is how a RTP runs on UDP so this is a provider transport layer interface that extend a UDP. So port numbers, IP addresses are there in UDP itself and then payload type identification, packet sequence numbering and time stamping is what RTP adds to UDP. And then, the application is here, it moves a little bit into the application domain. Maybe just look at the RTP header to do some what better service. (Refer slide time : 40:19 - 41:43) 

RTP by itself does not provide any mechanism to ensure timely delivery of data or provide other quality of service guarantees, because that really depends upon what is happening on the way. An RTP is running just between the two end points. So RTP encapsulation is only seen at the end system which is not seen by intermediate routers. So routers providing best effort service do not make any special effort to ensure that RTP packets arrive at the destination in a timely manner. The services in between is still a best effort. Since we look at it at the end points there we can effect on some kind of control. If you have noted, this RTP header goes in front of the payload for the data. For example, it is the voice which is traveling then the voice signal is digitized and packetized before each packet produced by your application layer, the RTP header will come which is available in the data. There is a separate protocol control called Real Time Control Protocol or RTCP. (Refer slide time : 41:44 - 43:25)

This is used in conjunction with RTP for multicast transmissions. Each participants in RTP session periodically transmits RTCP control packets to all the other participants. Each RTCP packet contains sender and receiver reports. So reports statistics etc are useful to applications and this is what you might use to improve the performance of your session. Inside the network, inside the backbone nobody really knows about your session so it is only the end points. But they exchange this kind of a statistics through the RTCP packets and then the application can control the rate at which things can be done, etc. Therefore some kind of feedback mechanism is present. The statistics include number of packets sent, number of packets lost, inter arrival jitter etc. Feedback can be used to control performance, sender may modify its transmissions based on feedback. This is the main point, you get some kind of feed back as this is running on UDP. There is no ACKs, packets coming on which you can send these statistics. Therefore what is done is that, this RTCP is actually in band control so a part of the bandwidth is kept for RTCP and through this bandwidth they exchange this kind of information and the time stamp, so you know that how much delay is being experienced at the other end. And after having all these  statistics you may do what you can at the application layer to modify the way you are transmitting in order to get better service. (Refer slide time: 43:26 - 44:14)

There are receiver reports, fraction of packets lost, last sequence number, average inter arrival jitter, etc are a part of the receiver report. Sender report: SSRC of the RTP stream, the current time, the number of packets sent, and the number of bytes sent. Source Description: E-mail address of sender, sender?s name, SSRC of associated RTP stream etc. Provide mapping between SSRC and the user or host name. (Refer slide time : 44:15 - 45:46)

Another use of RTCP is for synchronization. RTCP can synchronize different media streams within a RTP session. So consider video conferencing applications for which each sender generates one RTP stream for video and one for audio. The point is, you have got two streams of packets for the video streams and then the audio has to be synchronized with it. The lips are moving in some other way and sound is coming in some other way so that will not help in anyway hence they have to be synchronized. In order to synchronize this, RTCP uses the time stamp which I referred to earlier and tries to synchronize the two different streams. This is another important use of RTCP. So time stamps in the RTCP packets are tied to the video and audio sampling clocks. They are not tied to the wall clock time. The wall clock times are also exchanged and this is to get an idea about the delay. Each RTCP sender report packet contains for the most recently generated packet in the associated RTP stream, timestamp of the RTP packet and wall clock time for when packet was created. This gives you an idea about the delay. Receivers can use this association to synchronize the play out of audio and video. (Refer slide time : 45:47 - 48:02)

RTCP Bandwidth Scaling: RTCP attempts to limit its traffic to 5% of the session bandwidth. Remember, that this is in band control that means whatever bandwidth is given for the session it is within that only. So whatever the RTP actual data packets are using, maybe 5% of that, the RTCP tries to use and in this 5% it is kind of divided, like 25% for the sender, and 75% for the receiver because there may be many receivers and this 75% will again be distributed amongst the receivers. Suppose one sender sending video at a rate of 2 mbps then RTCP attempts to limit its traffic. That means to the RTCP traffic to 100 kbps. RTCP gives 75% percent of this rate to the receivers, remaining 25% to the sender. We come to another protocol called RTSP known as the Real Time Streaming Protocol. Earlier we were talking about interactive live audio or video conferencing, but now let us talk about streaming. User interactive control is provided, for example, the real time streaming protocol where a helper application displays content which is typically requested via a web browser, for example a real player, then we have the typical functions namely decompression if it is compressed in audio or video, jitter removal which means you play them back at a constant rate, error correction: use redundant packets to be used for reconstruction of original stream, some kind of Graphical User Interface for user controls like rewind, fast forward, etc are given by RTSP. What it does not do is, it does not define how audio and video is encapsulated for streaming over network, it does not restrict how streamed media is transported, whether TCP or UDP does not specify how the media player buffers audio and video so these are more at the application layer. (Refer slide time : 48:03 - 49:08)

This is the simple approach for steaming audio or video. Audio or video is stored in file. Files are transferred as http object that is received in entirety at client then pass to player. So audio or video are not streamed and so no pipelining, long delays until play out. Here the problem is that if it is some kind of a movie and if it is downloaded then the entire file is downloaded, so downloading that entire file will take a lot of time, this is a very simple approach and then there is no problem, you can download the entire file and then play it use options like fast forward or reverse or speed up etc. But streaming in the media means, as it starts streaming the audio or video file then after some delay the play back also starts. (Refer slide time : 49:09 - 50:43)   

Simple situation is, we have a web browser, web server with audio files and a media player and that is how we do it. The ACTP request, so browser gets a meta file then the browser launches a player passing the metafile to the player and the player contacts the server and the meta file contain all the necessary information, this is called progressive download. Let us look at the streaming multimedia client buffering. Suppose as before this is the constant bit rate video that is being transmitted and now because of the network delay and the availability of the network delay this is what the profile looks like of how it is received. But if you do this after some sufficient delay and you buffer it, the main point is, these two lines are never crossing. So now you can play it at a constant rate so all these delay variation etc that will sort of go and you would get a nice streaming audio or video. This is the basic idea of streaming multimedia. In this part, the difference between these two where this is the buffered part, so the client side buffering play out delay compensate for network added delay or delay jitter etc. (Refer slide time : 50:44 - 51:29)

Streaming multimedia: Is where UDP is usually preferred. We will also look at how TCP is done. The server sends at rate appropriate for client oblivious to network congestion. So, often sent rate is equal to encoding rate that is constant rate, then there is a fill rate for constant rate minus packet loss. Short play out delay 2-5 seconds compensate for the network delay jitter. Somebody does not really mind so much, that if the play back starts after 5 seconds but in this 5 seconds the entire thing will be buffered and that will take care of the jitter. Error recovery takes place if time permits. (Refer slide time : 51:30 - 52:07)

TCP: it sends at maximum possible rate under TCP and fill rate fluctuates due to TCP congestion control because in TCP congestion control the windows size can keep on varying so larger play out delay is smooth TCP delivery rate. If you start playing it after quite some time so that you can handle this TCP variation in rates etc then you can get a smooth rating. Then http TCP passes more easily through firewalls rather than UDP. (Refer slide time : 52:08 - 52:24)

RTSP example: Meta file is created and communicated to the web browser. Browser launches player as we have seen and player sets up an RTSP control connection data connection to streaming server. (Refer slide time : 52:25 - 52 - 47)

Web browser gets an http GET and web server presentation description. Then the media player is setup a connection with the media server and it starts getting it, buffers it and starts playing. The media stream comes, then you may pause, you may teardown, etc.  (Refer slide time : 52:48 - 53:09)

Finally I will just mention about two protocols namely: H.323 which is an ITU standard which is the old protocol for setting up telephone calls. H.323 is aging a little bit and there is a (Refer slide time : 53:10 - 53:28)

newer protocol namely session initiation protocol. All telephone calls and video conferencing calls take place over the internet. That is the vision, you can reach the callee no matter where the callee roams, no matter what IP devices the callee is currently using. Therefore (Refer slide time : 53:29 - 53:58)

for setting up calls there is a large protocol. 
Setting up a call: Provides mechanisms for caller to let callee know she wants to establish a call. And provides mechanism so that caller and callee can agree on media type and encoding because that has to agree and it provides a mechanism to end the call. The first one is called an invite and there are all kinds of  (Refer slide time : 53:59 - 54:29)

commands for this. It also has the facility to determine the current IP address of callee, maps mnemonic identifier to current IP address. There are other components of chip like, chip register and so on. Then it has something for call management, that means add new media streams during call, change encoding during calls, invite others for a conference, transfer and hold calls etc. (Refer slide time : 54:30 - 54:38)

 There are all kinds of details about codec negotiation etc. (Refer slide time : 54:39 - 56:15)

And then you may reject a call also. The audio, video and multimedia over the internet is going very strongly. At one point of time network performance was so poor that there was no question of accommodating this. But as the network performance has increased exponentially over the past years now it is becoming much possible to handle lot of multimedia traffic through network. This is getting more popular.. We talked about inserv, gifserv but the actual strategy that people actually deploy is when they feel this is not sufficient then they put in more bandwidth so put another fiber  and take up your multiplexer weight etc so that you solve the problem because the demand for multimedia is so great. 

Good day, today we will talk about network management. As the network becomes very large we need support for managing these networks, we need support for keeping track of these networks and so, we are going to discuss on how that is done.  (Refer slide time :56.16 - 56.18)

Today?s topic is network management. (Refer slide time :56.19 - 56.42)

Network management is the process of controlling a complex data network to maximize its efficiency and productivity. The overall goal of network management is to help with the complexity of a data network and to ensure that data can go across it with maximum efficiency and transparency to the users.  (Refer slide time :56.43 - 57.18)

The ISO, that is the International Organization for Standards in network management forum divided network management into five functional areas: Fault management, configuration management, security management, performance management and accounting management. Out of this, actually it is quite often you find that there are two systems which was deployed. (Refer slide time :57.19 - 57.41)

In that case the trap will never come. The only thing is that when the network management station polls that particular device so it will fail to respond. That way you will find out that something is wrong. So you should use a mixture of trap and polling to do your management.  (Refer slide time :57.42 - 58:30)

Let us quickly go through the types of SNMP packets: One is the get request, it retrieves the value of a variable or a set of variables, and get next request used to retrieve values of entries in a table, so the next entry. Get bulk request retrieves a large amount of data used instead of multiple get request and get next request so that in one go you can get a lot of information as far as the bandwidth is concerned. Set request: set or store a value in a variable.
Response: response to get request or get next request contains values and or variables requested.
Trap: sent from agent to manager to report an event.  (Refer slide time :58:31 - 58:48)

Inform request: sent from one manager to another remote manager to get a value of some value from agents under the control of the remote manager. 
Report: designed to report some types of errors between managers but not very widely used. (Refer slide time : 58:49 - 58.58)


Now we come to the SNMP data types.




	

COMPUTER NETWORKS
Prof : Sujoy Ghosh
Department of Computer Science and Engineering
IIT, Kharagpur
Lecture#37
Network management
(Refer slide time:00-57 min)



Good day, so today we will talk about network management. You know that as the network becomes very large we need support for managing these networks, we need support for keeping track of these networks and how these are done is what we are going to discuss. 

 (Refer slide time-1:13- 1:16min)

So the topic for today is network management. (Refer slide time: 1:17- 1:40 min)

Network management is the process of controlling a complex data network to maximize its efficiency and productivity. The overall goal of network management is to help with the complexity of a data network and to ensure that data can go across it with maximum efficiency and transparency to the users. (Refer slide time: 1:41- 2:54 min)

The ISO that is the International Organization for Standards in network management forum divided network management into five functional areas: Fault management, configuration management, security management, performance management, and accounting management. Out of these often you find that there are two systems which has deployed in large network. One is the Network Management System and another is the Enterprise Management System. Enterprise Management System usually takes care of the configurations of individual machines etc, and the Network Management does the fault management and performance management. These are two aspects which network management always has to take place and it can do some configuration management for some network devices also. So we will just quickly run through each one of these. (Refer slide time: 2:56- 5:48 min)

Fault management is the process of locating problems or faults on the data networks. It involves the following steps: Discover the problem, isolate the problem, and fix the problem (if possible). Sometimes it is possible to fix the problem remotely and sometimes it is not possible. First of all discovering the problem is important because usually in a large network there are so many hundreds of components which have been deployed over a considerable area. You need to have a good support for discovering the fault. A fault in one part of a network can lead to impairment of services in another part of a network. For example, suppose some switch has become faulty and it is generating a lot of spurious traffic, now the first thing is to locate where all these traffic is coming from, and then you have to isolate it, and then fix it. Sometimes you need to physically go there and fix it but sometimes you can do it remotely. But before you can fix it, you have to discover that there is a problem and this is where the problem lies, this is the central part of fault management. Another thing to note is that, the network devices may come up first and be switched off. Therefore the topology of the entire network is not fixed, some of them may be off, some may be switched on but it is not working. So anyway the topology of the network is not fixed therefore for fault management, first you have to discover which are the areas or which are the elements that are currently on the network and are put on and are working correctly and then which others are not working. That is, they are switched off, or may be they are faulty etc. Continuously you have to be in a mode of discovering the topology of the network, as to find out which of these are switched on and which is doing what. Then we need to locate the faults as it occurs. This is fault management. Then you have configuration management. (Refer slide time: 5:45- 6:02 min)

The configuration of certain data network devices controls the behavior of the data network. Configuration management is the process of finding and setting up that is (configuring) these critical devices. (Refer slide time: 6:03- 6:36 min)

Security management: it is the process of controlling access to information on the data network. It provides a way to monitor access points, and records information on a periodic basis, and provides audit trails, and sounds alarms for security breaches. We will be talking more about security in the next lecture which is a very big topic by itself but we will devote only one lecture to it. There we will talk little bit more about the security management and securities in network. (Refer slide time: 6:39- 7:48 min)

Performance management: Involves measuring the performance of the network, hardware, software and media. Examples of measured activities are: Overall throughput percentage utilization, error rates, response time. Quite often a fault in a network does not always be faulty but there may be degradation in performance. For example, in one particular network node you may find that a lot of packets getting dropped. So you have to find out periodically that, who is doing what, and how, in a sense that at what percentage? How many packets it has handled? How many it has handled successfully? How many it has dropped and so on. And from such statistics you have to come to a conclusion about whether this is really malfunctioning or not. Error rates are important, response time, percentage and utilization. Once again there are ways to find out these things and we will talk about them. (Refer slide time: 7:51- 8:11min)

Accounting Management: It involves tracking individual?s utilization and grouping of network resources to ensure that users have sufficient resources. This involves granting or removing permission for access to the network etc so this is also important in many cases. (Refer slide time: 8:13 - 10:50 min)

Now the protocol that is used for network management is known as SNMP Simple Network Management Protocol. Objectives are following: It is a framework for management devices in an internet using TCP/IP. It provides a set of fundamental operations for monitoring and maintaining an internet, and an application level protocol allows it to monitor devices made by different manufacturers installed on different physical networks. In a particular network all the network devices will not come from the same vendor. You may have procured some of the devices at some point of time from some vendors and some other devices from some other vendor and all of them form a part of the same network. When you are talking about network management in that place, you have to talk about all these heterogeneous platforms. There has to be a standard protocol by which the network manager can talk to each of these devices. When you look at the network devices which are available in the market, you find that there are broadly two types of devices: managed device and unmanaged device. For example, for a switch there is a managed switch and an unmanaged switch. Obviously the switch which is unmanaged does not support this SNMP and do not have the so called management agent in it. In order to manage and get the information about it from a central place the devices have to be managed. Therefore at the very edge of the network for cost consideration you may put some unmanaged devices but then management of fault etc, for those devices have to be handled separately. You cannot monitor them centrally. For monitoring them centrally you need to have managed devices. Managed devices would contain some kind of software and some hardware support inside each of the device to talk to this network management station wherever it is broke. Usually this costs money but for a large network this is important. (Refer slide time: 10:51 - 11:12 min)

This is a very simplified picture, we have the network manager here and through the TCP/IP protocol it talks to an agent. This agent resides in a managed device and these agents will have some agent variables which should be available to this manager for monitoring. That is the basic idea. (Refer slide time: 11:14 - 11:48 min)

Agent: is a router or host that runs the SNMP server program. By the way, apart from managing network devices you can also have management agents in software etc to instrument it in some fashion. The agent keeps performance information in a database, can send a trap to the manager if something unusual occurs. So, trap is a sort of alert to the manager. (Refer slide time: 11:50 - 11:56 min)

Manager is a host that runs the SNMP client program and has access to values in the agent?s database. (Refer slide time: 11:57 - 12:28 min)

Based on three basic ideas, a manager checks an agent by requesting information that reflects the behavior of the agent. A manager forces an agent to perform a task by resetting values in the agent database. An agent contributes to the management process by warning the manager of an unusual situation. These are the three basic approaches and we have specific commands for doing all these. (Refer slide time: 12:29 - 12:46 min)

SNMP uses two other protocols: SMI: Structure of Management Information, and MIB: Management Information Base. So, one is used for naming objects and the other is the basic management information base accessed by the manager. (Refer slide time: 12:47 - 12:57 min)

SNMP defines the format of packets exchanged between a manager and an agent. It reads and changes the status that is the values of objects, variables in SNMP packets. (Refer slide time: 12:58 - 13:52 min)


SMI defines the general rules for naming objects, defining object types including range and length and showing how to encode objects and values. SMI defines neither the number of objects an entity should manage nor the names the objects to be managed nor defines the association between the objects and their values. Instead, what SMI does is to have some scheme for giving names to the object. The names are not human friendly but they look as a series of integers, but there is a way of encoding the names of objects so that we are very precise and distinct about what we are talking taking into consideration we can have a heterogeneous network. (Refer slide time: 13:54 - 14:04 min)

The role of MIB: MIB creates a collection of named objects, their types, and 
their relationships to each other in an entity to be managed. (Refer slide 
time: 14:06 - 14:30 min)

SNMP: A group was formed and their efforts were completed in early 1993. There are 12 documents describing SNMP version 2, there is an SNMP version 3 also. There are three basic commands that are used with SNMP: get, set, get next. These are the basic operations then you can have a bulk, get, etc. (Refer slide time : 14:31 - 15:35 min)

This is the general situation we have. Network management station: There may be more than one network management station. In a very critical network you may have two network management stations, etc. Therefore we have some network management station which runs some network management application, NMA. This software talks in SNMP which manage devices. These are network elements which are managed. This NMA Network Management Application uses the SNMP protocol to talk to the management agent which resides in every managed object. This managed object maintains the MIB Management Information Base and from this the information passes back and forth. Hence this is the general scheme. (Refer slide time: 15:36 - 15:40 min)

There are two approaches for the management system to obtain information from SNMP: One is the traps and other is polling. (Refer slide time: 15:41 - 16:14 min)

First let us talk about traps. Traps are basically the information which is being pushed from the managed device to the network management station. Traps are un-requested event reports that are sent to a management system by an SNMP agent process A. A trap will contain the network device name, time the event happened, and the type of event. (Refer slide time: 16:15 - 16:51 min)

When a trappable event occurs, a trap message is generated by the agent and is send to a trap destination - a specific configured network address which is the network address for the management station. Many events can be configured to signal a trap like a network, cable fault, failing NIC, or hardware, a general protection fault, or a power supply failure. Although many events can be configured to signal a trap but there are pros and cons of what event is being configured a trap, there are trade offs. (Refer slide time: 16:52 - 18:15 min)

Traps can also be throttled. You can limit the number of traps sent per second from the agent, this is important. For example, a faulty node may keep on generating a very large number of traps. So that it will overwhelm the network and it will not carry any extra information in helping to set right the fault. You may have to constrain the number of traps that can be generated per minute time or something. So traps have a priority associated with them. Critical, major, minor, warning, marginal, informational, normal, unknown etc. Actually it may not be a good idea to generate traps. For low clarity may be you should not be generating any trap at all because if you do that, remember that a network may consist something of the order of a few hundred or a few thousand network devices and if all of them generate routine reports and keep on sending traps then that may not be a very effective way of managing a network. (Refer slide time: 18:16 - 18:43 min)

Resources are required on the network devices to generate a trap. When a lot of events occur the network bandwidth may be tied up with traps. So, thresholds can be used to help because the network device has a limited view. It is possible that the management system has already received the information and the trap is redundant. If something has happened somewhere else and somebody else has detected it and generated a trap then that is not generating any extra or relevant information.  (Refer slide time: 18:49 - 19:26 min)

The network management system periodically queries the network device for information. So this is the other mode which is SNMP polling. From time-to-time the network management agent will request for some information from the management agent and this might do in a round robin fashion, in a periodic fashion using some period which is configurable. The advantage is, the network management system is in control and knows the big picture. So this is the other way; one is trap, the other is polling. (Refer slide time: 19:27 - 20:25 min)

The disadvantage is the amount of delay from when an event occurs to when it is noticed. For short interval the network bandwidth is wasted and for long interval the response to events is too slow. The point is that, if you are depending only on polling and if you are polling at a very low frequency then after your last poll immediately some fault may have occurred but you will discover that only when you poll next. So, in a long interval the response to events is quite slow. On the other hand if you poll very fast then most of the network bandwidth and network resources are used for this network management so that is not very efficient and bandwidth is wasted. So you have to come to some kind of trade-off between the two. (Refer slide time: 20:26 - 21:23 min)

One good way to approach this is to use both traps and polling. When an event occurs the network device generates a simple trap. The management system then polls the network device to get the necessary information. The management system also does the low frequency polling as a backup to the trap. What might have happened is, you cannot depend purely on trap for one reason that is, the network device may have gone down in such a way that it is not even able to generate the trap. In that case the trap will never come, only thing is that, when the network management station polls that particular device it will fail to respond and that way it will find out that something is wrong. So you should use a mixture of trap and polling to do your management. (Refer slide time: 21:24 - 21:26 min)

Let us quickly go through the types of SNMP packets: GetRequest - It retrieves the value of a variable or a set of variables; GetNextRequest ? Is used to retrieve values of entries in a table; GetBulkRequest- Retrieves a large amount of data used instead of multiple get request and get next request so that in one go you can get a lot of information as far as bandwidth is concerned. (Refer slide time: 21:57 - 2:11 min)

SetRequest - Set or store a value in a variable; Response ? Response to get request or get next request contains values of variables requested; Trap - Sent from agent to manager to report an event. (Refer slide time: 22:15 - 22:31 min)

Inform Request - Sent from one manager to another remote manager to get some value from agents under control of the remote manager; Report - designed to report some types of errors between managers but is not very widely used. (Refer slide time: 22:32 - 24:01 min)

Now we come to the SNMP data types, These data types have to be, since network may contain devices from different vendors, each vendor of course will design his own agent so he has to agree to some kind of standard about what will be there. But at the same time we do not want to standardize things in such a way so that people cannot innovate and come up with new kinds of devices. What is defined are the different data types, different types of variables, one is the integer - it is a signed 32-bit integer, Octet string that is the byte string, Object identifier - is one of the most important data types and we will look into the detailed of object identifier when we talk about SMI; NULL: Is not actually a data type but a data value, IP address is a special data type, it is an octet string of size 4 bytes. We are using 4 byte of addresses in network byte order. (Refer slide time: 24:00 - 25:02 min)

Then you have a counter: It is an unsigned 32 bit integer which rolls over. The 32 bit will count to about 4 trillion. After the end of the counter the value is rescheduled which means it will go back to zero and start counting from zero again. This counter is more important because that is what will give you the statistics about the network. For example, you want to know that in the last may be ten minutes or so how many packets this has been sent, and how many packets has been dropped, and how many packets has been successfully processed etc. So the management station may want to know such information. So these are the kind of statistics you collect. Therefore you need to have these counters for these different values. Now a counter is going to go back to zero after sometime so you need to take care of that. (Refer slide time: 25:02 - 26:05 min)

If this going back to zero then after a poll, when you have got a value and when you see that the counter value is sufficiently high, you may like to set it to zero deliberately so that you get the right count next time. Gauge: unsigned 32 bit integer, once again it is the same as counter but it will top out and stay there. That means, it is going to top out and the next time you come it will not show a very low value but it will show a high value. And if you see that the gauge has topped out may be you can reset it after that but you get some estimate of what has happened rather than a rolled over value. Time ticks: Unsigned 32 bit integer so 32 bit integer rolls over after 497 days. But 497 days is very long in this network world. (Refer slide time: 26:06 - 26:36 min)

Opaque: Used to create new data type not in SNMPv1. And then there are some other data types for specific purpose like date and time, display string, MAC address, physical address, time interval, time stamp, truth value, variable pointer, textual conventions used as types. These are the different SNMP data types. (Refer slide time: 26:37 - 27:43 min)

Let us just have a look at the SNMP MIBS. Management Information Base is a collection of related managed objects used to define what information you can get back from the network device. These are standard and enterprise specific MIBS. The point is that, some things may be standard, and there are some information about the device. For example, if we have a device designed by CISCO then that may have its own specialty which is not found in other vendors. Therefore that specialty will require some information which is specific to the particular vendor. Hence we have vendor specific information also, and we have general information also. There are standard and enterprise specific MIBS. And, if you later on mix up between the two, that means, something that is specific to vendor 1 and something specific to vendor 2 it will not work out and so these two need to be separated. So naming of objects is very important. Thus there is standard and enterprise specific MIBS. (Refer slide time: 27:45 - 27:55 min)

Types of MIB modules: Standard: These are the standard MIBS currently designed to capture the core aspects of the particular technology. (Refer slide time: 27:56 - 28:10 min)

Experimental: Temporary and if achieves standardization then it is placed in the standard module. Then Enterprise-specific: Vendor specific MIBS that provide additional management capabilities for those features that require it.  (Refer slide time: 28:11 - 28:56min)

If you are using the MIB you also require the MIB tools, you require a MIB compiler, you require a MIB browser, a MIB alias tool, a MIB query tool, etc. A MIB browser allows you to browse through the management information base in a particular device directly. And MIB alias is required because, as we see the naming is very complex. So once you have given a name you do not have to repeat that name in every query so you have an aliasing tool and a MIB query tool. (Refer slide time: 28:57 - 29:10min)

SMI: Structure and identification of management information. The SMI defines the rules for how managed objects are described and how management protocols may access these objects. (Refer slide time: 29:11 - 29:24 min)

Functions: Are to name objects, to define the type of data that can be stored in an object, to show how to encode data for transmission over the network. (Refer slide time: 29:25 - 29:52 min)

Name: SMI requires each managed object that is router, variable in a router, etc. which have a unique name. So router will have a name, a variable in a router will also have a name, and a specific router coming from location should also have some way of describing that. (Refer slide time: 29:53 - 32:24min)

The naming convention really starts from a high level and it uses the integer.representation. There is a name.notation. Actually ISO has defined a very global naming tree. It starts from ISO itself, and under ISO there are so many things and under each of these there are so many things. For example, ISO.org.dod.internet.Management.MIB 2 and when I say this much, actually this ISO has got the number 1 and under ISO there are so many entities, one of them is called organization and this is an entity, a number 3 and there is a department of defense of US, that is an entity with a value 6. ISO is a European organization and all these are decided by ISO. Therefore the Department of Defense did not take a note of it. But when the internet started on the Department of Defense they saw that nobody has used anything of the naming convention and they decided to take one. And then management.2, then MIB is .2 and up to this much we have not even come anywhere close to the particular device that we are trying to manage. All objects managed by SNMP are given an object identifier. The object identifier always starts with 1.3.6.1.2.1 because we are talking about network management, and in network management naturally it has to do with network, then may be it has to do with MIB.2 and then internet and since it is the internet it has to do with DODN and all the way up to ISO. So that 1.3.6.1.2.1 etc is always the prefix of any name and there are many other integers with many more DODs in them. (Refer slide time: 32:25 - 32:52 min)

Apart from this an object in SMI has a textual name which is there in SMI termed as the object descriptor for the object type along with its corresponding object identifier which is defined. Syntax: the abstract syntax for the object type. It can be a choice of simple syntax that is integer, octet string, etc or application syntax. (Refer slide time: 32:54 - 33:08 min)

Definition is a textual description of the semantics of the object type. What type of object it is? Access: one of the read only, read write, write only, or not accessible kind of access is defined. And status: One of mandatory, optional, or obsolete. (Refer slide time: 33:10 - 33:30 min)

This object identifier is also a part of that, it is like a telephone number and it always starts with 1.3.6.1.2 and SMI uses it as the base for defining new objects. (Refer slide time: 33:31 - 34:25 min)

In the first group, ISO was 1, CCITT was 2, and for the joint ISO ? CCITT there was a number 3. Since this is under ISO that is how the first one comes. The second group for the ISO Node administrator defines 3 for use by other organizations. So in 1.3 the 3 is the other organization. Actually there are a large number of things in that particular level, we are having a global naming tree for naming anything under the sun. So there is a thing called other organization and that other organization is 3 and the third group defines 6 for the use of U.S. Department of Defense, so it is 1.3.6. (Refer slide time: 34:26 - 34:45 min)

In the fourth group the DOD has not indicated how it will manage so internet is 1. The fifth group was approved by IAB to be 1 for the use of OSI directory, 2 for object identification for management purpose. So this is the one that we are interested in. (Refer slide time: 34:46 - 36:22min)

Therefore we have 1.3.6.1.2.1.1.1 and since it is a global naming tree we have to come quite deep down to any particular level. Finally it is possible that not only you have some network devices etc somewhere down in the tree but you also have some sub trees for specific vendors. So this naming can go down that sub tree to talk about something specific to a particular vendor. Or even if we have come down to the tree somewhere and now you have got into a router, now in the router also we want to talk about interfaces and about other things so the tree also goes down from that point. So the point is, through this naming procedure we can exactly specify anything that is being talked about in this whole management scenario. Only trouble is, it is almost impossible for human beings to remember any of these names or any of these things. But the network management application makes this query to MIBS etc., so you are usually spared the trouble of looking into this. But if you look into this you will find such object identifiers in the MIB. (Refer slide time: 36:23 - 36:53 min)

The MIB-2 group: This was divided into ten groups: One for system, one for interfaces, one for address translation, one for internet protocol and so on. And the number of objects in each of these groups is given over here. (Refer slide time: 36:54 - 37:32 min)

We have a system group which has a system descriptor system, object ID system up time, system contact. The system up time is the time since last re initialization, and system object ID is vendor object identification and so on. This makes the scheme very general so that even devices from heterogeneous vendors can also be accommodated and you can talk about very standard things and that is why it was done this way. (Refer slide time: 37:33 - 38:03min)

Now let us look at the network management platform. Historically, network management revolved around multiple systems each managing one specific set of components on the data network. Restrictions of money, physical space, and technical expertise led to the desire to have the components managed by a single system that would show their inter connections on a network map. (Refer slide time: 38:04 - 39:20 min)

This is how a network management platform evolved. It is a software package that provides the basic functionality of network management for different network components. So, a network management platform has to be a general kind of software. For example, on one side you have specific vendors for managing a specific set of devices, you may have some network management application etc which is there. Hence you have this particular application from this vendor for managing his devices, and then you have some other network management application for some other devices from some other vendor etc. But then finally you would like to sit in one place and have the big picture. So there has to be a platform which can couple with these different network management applications known as the network management platform, i.e. the general software which is running which can integrate all these different components.  (Refer slide time: 39:21 - 39:57 min)

The goal of the platform is to provide generic functionality for managing a variety of network devices. There are some functionality and some requirements for network management which is very general. Those are collected in the network management platform and if there are specific things you have to talk about for a particular type of device may be from that particular vendor then that is out of the platform although that software can integrate with this network management platform. That is the idea of having a network management platform. (Refer slide time: 39:58 - 41:11min)

Basic features for any platform to include are Graphical User Interface GUI and network map. The first thing that a network management platform should do or is expected to do is to go on discovering the different network devices which are right now on, which are accessible etc, and those which are not accessible that means which were supposed to be previously there. And it would be nice if you can show it graphically on a screen like showing different colors for different types, and different icons for different types of nodes, and different colors showing whether it is working, not working, switched off etc, and if you can see that picture then you get the big picture in one go. Therefore this network map is important. A DBMS naturally wants to keep this management data and then query etc so it needs some DBMS. You need a standard method to query devices and a customizable menu system, event log, etc. These are the basic features for any platform. (Refer slide time: 41:12 - 42:19 min)

Additional features for a platform using graphing tools which graphically shows with some kind of plots that how each device is performing. This should be able to show you the plot very easily. So this graphing tool is also an integral part. Then the application programming interface API is important because after you have finished talking about the generic network management aspects then you also have these special aspects for which the different vendors are going to give you special tools. These special tools now have to integrate with this network management platform. Therefore the API Application Programming Interface has to be very clearly defined. Finally it is the system security which is always present. (Refer slide time: 42:16 - 42:33min)

Here are some examples of network management platforms: Sun?s SunNet Manager, IBM Netview, HP?s OpenView by the way is a very widely used network management platform in this category. (Refer slide time: 42:34 - 43:02 min)

If you remember, one diagram in which we showed two network management stations etc which has to do with the network management architecture and the network management platform can use various architectures to provide functionality. The three most common are: Centralized, Hierarchical and Distributed. (Refer slide time: 43:04 - 44:22 min)

In the centralized architecture as the name suggest you have one central network management station or network management platform besides on a single computer system that is a centralized system. In that case that particular station becomes absolutely critical because in a large network network management software is used all the time. Hence if you have them centrally it becomes a single point of failure. So what you may do is that, you may duplicate the same thing on another machine. If one of them fails, it will not want to have single point of failure in a network if you want to at least make the critical components of it; and network management is a critical component of a large network. So you may like to have a fall back mechanism where in the primary one fails the other one can immediately take over. Although we have put two network management stations this is a centralized architecture. Therefore for full redundancy the computer system is backed up by another system, can allow access and forward events to other consoles on network. So this is a centralized architecture. (Refer slide time: 44:23 - 44:38 min)

This is used for all network alerts and events, all network information, access all management applications etc. Hence one central architecture is used. (refer slide time: 44:38 - 45:20min)

And the pros are the following: A single location to view events and alerts, a single place to access network management applications and information, security is easier to maintain. This is an advantage, so in one place you get all that you want to view and it is easier to make it secure, and a single place to access the NMI because using the NMI, set etc you can also do things to the network, and you do not want any unauthorized person to have access to the network management station. (Refer slide time: 45:21 - 47:08 min)

In the cons of the centralized architecture it has disadvantages. Single system is not redundant or fault tolerant, but you can make it somewhat fault tolerant by keeping another machine but if the connection to this room is somehow cut then the entire network becomes a black box. As network elements are added, may be it is difficult or expensive to scale the system to handle the load, having to query all devices from a single location. As a matter of fact think of an enterprise of today. An enterprise of today that may be across various locations, it may be over a WAN, and many of these locations may be quite big hence a network that an enterprise may want to control centrally may become too big. So there is a question of whether a central server can scale it to that extent. Actually there are problems, for example, if WAN bandwidth server or some part of it is out of WAN and WAN bandwidth is also a problem because if all the network management traffic is also coming over a WAN then that becomes quite an expensive scenario. But at the same time you have this advantage of this centralized architecture that in one place you can view all the things. These are the pros and cons, and so having to query all devices from a single location will not be good. (Refer slide time: 47:09 - 49:14 min)

Therefore we go to the next step which is the hierarchical architecture. It uses multiple computer systems where one system acting as a central server and other systems working as clients. Central server requires backups for redundancy, this is the situation. Once again think of the same enterprise which is distributed geographically which may be five different locations and in each of these locations you have a big local area network to manage. So what you might do is, for each of these locations you may put its own management station who will manage the local network. You can even put a central server and all these management stations in different locations would be the client to the central server so only the important information or only the condensed and summarized information is coming to the central location via the WAN. Therefore by this you conserve WAN bandwidth and at the same time you have a central location where you can get the entire picture and if you want you can talk to one of the clients and drill down and look at the specifics if there are problems somewhere, so this has all kinds of other advantages. For example, you can keep very good and expensive network experts in the central location as he can detect a problem over there and then over the network itself he can actually look into the issue and offer a genuine advice as to what needs to be done at that juncture. This is an advantage and this is a hierarchical architecture. The central server can also be backed up for redundancy. (Refer slide time: 49:15 - 49:36 min)

Key features: Not dependent on a single system. So, even if a single system or a single link is cut still some of the network is being managed. Distribution of network management tasks is distributed now. Network monitoring distributed throughout the network, and centralized information storage is also there. These are the advantages of hierarchical architecture. (Refer slide time: 49:38 - 50:02 min)

Pros: Multiple systems to manage the network.
Cons, the disadvantages: Information gathering is more difficult and time consuming because it is coming through two layers. And the list of managed devices managed by each client needs to be predetermined and manually configured. (Refer slide time: 50:03 - 50:56 min)

Then we have a distributed architecture. It combines the centralized and hierarchical architecture. It uses multiple peer network management systems. Each peer can have a complete database. Each peer can perform various tasks and report back to a central system. Previously there was only one station that was central and the others were in a sort of master-slave kind of situation but now there are all peers so each of them can keep an entire database if it wants to. Therefore each of them can work as a central management network station and they are distributed. (Refer slide time: 50:57 - 51:18 min)

It contains advantages from central and hierarchical architectures, single location for all network information alerts and events, single location to access all management applications, not dependent on a single system, distribution of network management tasks, distribution of network monitoring throughout the network. (Refer slide time: 51:19 - 52:03 min)

We already discussed about the network management platform. Now let us talk about specific network management applications. The goals of specific network management applications are to effectively manage a specific set of devices, avoid functionality overlap with the platform which means the network management platform, integrate with a platform through the API and menu system, and reside on multiple platforms. These are the goals. So, applications do not share information because these two applications may have come from two different vendors. (Refer slide time: 52:04 - 52:09 min)

Some examples are; Cisco works or 3com?s Transcend etc. (Refer slide time: 52:10 - 52:30 min)

Choosing a Network Management System: It is built from two major components: the platform and applications. A practical approach follows these steps: Perform device inventory, prioritize the functional areas of network management, survey network management applications choose the network management platform. (Refer slide time: 52:31 - 54:45 min)

We will just mention about another term which comes quite often. RMON: Remote Monitoring MIB. These have agents and probes. So this is actually used for monitoring MIB remotely and there are specific groups for this RMON, that is statistics group, history group, alarm group, host group, host top N, etc. These are standardized to operate on Ethernet segments so that apart from network management stations you can monitor it from other places also. I think I am going to stop here, as you can see what I have tried is, to give you a broad overview of this network management system and as it is growing it. Network management is something which in today?s world you cannot do meaningful network management without machine support, i.e. you cannot do it manually and those days are actually gone. And in large network the number of events that are happening is really tremendous and it is not also possible to keep a log, the machine of course keeps a log and after a month or so the log has become so big, may be you have to delete it from your machine and then the log starts accumulating at a very high rate because the network traffic is flowing back and forth at a tremendous pace and you have to somehow keep track of those and at the same time keep a balance. That is a major part in designing a network management system, keep a balance among trap and polling, keep a balance about what information you will take and what information you will not take, keep a balance about how much you are going to manage. 

Good day, the topic for today is network security. As the network is becoming ubiquitous, in the sense that it is becoming widely available to people, many people have started giving services through network. These services are crucially dependent on security. For example, you want to do a bank transaction through the network so that anywhere you can log onto the network and do your banking. Now this banking service is of course very sensitive so that if security is breached then the whole thing falls down. Therefore security once again is a very big topic, so let us discuss about the overview of security features in network. 
 So what is network security? What is the purpose of a network? It moves bit from A to B. And we want this movement to take place securely. And what exactly we mean by securely? Of course, the bits from A must reach B but we also want confidentiality in the sense that only A and B see the bits. That means, if there is somebody in between then he cannot find out the content of the communication from A to B because A may be a client and B may be a bank. Therefore this has to be secured. 
Integrity: The message must reach from A to B intact. You have the original document; you use the one way function or a hash function and the hashed result is now encrypted with the secret key the private key of the assigner which gives the digital signature. Now the receiver should get the original document plus the digital signature. Now if you want to ensure that the original document also should not be seen by anybody then this entire thing i.e. the original document plus the digital signature you can encrypt using the public key of the receiver. Therefore what the receiver will do is that the receiver will decrypt it using his own private key so that he gets back this. Now using the public key anybody could have sent this document. Now how do I know that this actually came from whomever it purports to be? This is where the digital signature plays its role. Now the receiver can verify by applying one way hash function to the received document. Therefore he will apply the same hash function to this document so he is supposed to get back whatever was here. Now he will decrypt the signature using the sender?s public key. He has the sender?s public key with him and since it was encrypted with the sender?s private key now he can use the private key of the sender to get back the same message. Now, comparing the two results equality means document is unmodified.  
COMPUTER NETWORKS
Prof. S.Ghosh
Dept. of Computer Science & Engineering
I I T, Kharagpur
Lecture#38: Security
(Refer Start Time: 00.28)
Good day, so the topic for today is network security. As the network is becoming ubiquitous, many people have started giving services through network. These services are crucially dependent on security. For example, if you want to do a bank transaction through the network so that from anywhere you can log on to the network and do your banking. This banking service of course is very sensitive so that if security is breached then the whole thing falls down.  Therefore security once again is a very big topic, so let us discuss about the overview of security features in network. 
 (Refer slide time: 01.31 - 01.32)

So what is network security? What is the purpose of a network? It moves bit from A to B. And we want this movement to take place securely. (Refer slide time: 01.33 - 01.50)

(Refer slide time: 01.51 - 03.32)

And what exactly we mean by securely? Of course, the bits from A must reach B but we also want confidentiality in the sense that only A and B see the bits. That means, if there is somebody in between then he cannot find out the content of the communication from A to B because A may be a client and B may be a bank. Therefore this has to be secured. 
 Integrity: The message must reach from A to B intact which means without any modification on the way. This is again very important for many kinds of services. Of course sitting at B you are getting some message down the network but may be you want to make sure that this is really from A and whether the messages are coming in order. These are integrity issues and then finally the availability that B gets it in time. When B wants something from A it is able to get it. Even if all other lower layers are working perfectly B may not get the service from A or vice versa if network security is breached. So these are the three main issues: Confidentiality, integrity and availability. Let us look into these and how they are handled. (Refer slide time: 03.33 - 04.56)

Network security: There is a lot of work on security and it is a very active research area at present. People have come up with lots of solutions but as solutions come up new problems also get generated as we will see. The confidentiality can be handled through encryption. Instead of sending the message as it is, you encrypt it in some fashion so that even if somebody intercepts this message and gets a copy of that he will not be able to decrypt it. We will see various encryption techniques. Encryption basically is the fundamental way in which we handle confidentiality. Integrity may be handled through what is known as the digital signatures. And retransmission and getting the messages in order is a part of the TCP protocol. Then comes availability which is something to do with the quality of service. (Refer slide time: 04.57 - 05.57)

Security environment: this is closely linked not only with the network nodes but also with the operating systems of the systems. Mostly in the application layer although security has become more important that nowadays there are some network nodes also like routers which can encrypt messages almost at a good speed. But a lot of these security issues are handled near the application layer where the operating systems have a role to play. 
Goals: Someone attempts to subvert the goals, it may be for fun, it may be for commercial gain, it may be with some malicious intent so (Refer slide time : 05.58 - 06.27)

It is the exposure of data. If you just make a matrix of Goals vs. Threats then for goals it is the data confidentiality and for threats it is the exposure of data. For data integrity in goals it is the tampering with data as the threat. For System availability there may be a denial of service kind of an attack by some malicious people or either for fun that serves as a threat to the systems availability. (Refer slide time: 06.27 - 08.24)

Now what kinds of intruders are there? There may be casual prying by non technical users out of curiosity. There may be snooping by insiders often motivated by curiosity or money. As a matter of fact it has been estimated that for most of the serious security breaches some insider is involved in majority of the cases. And when that happens it becomes more difficult to handle it. Determined attempt to make money may not even be an insider; it could be an insider or someone who wants to just make money. Then there is the commercial and military espionage. This of course is a very big business. Military communication of course traditionally has been confidential so they were encrypted. So encryption basically derives its history for the military purpose. And now-a-days in the age of information the information technology is a very core part of the military machine of any country. So, security breach in these cases is of course a very serious issue and since most of the large commercial houses are now networked and as they have networked on one hand of course you deal with your business process in a much more efficient manner but at the same time you expose yourself to this kind of new threats which needs to be handled. (Refer slide time: 08.25 - 10.07)

As I mentioned, for confidentiality cryptography is a time honored technique. Now it has become more and more sophisticated. Now-a-days with the help of computers if you are using the older techniques it is possible to crack those encrypted messages so now people have come up with better encryption algorithms and better encryption techniques. The goal is to keep information away from those who are not supposed to see it.  You can do it by scrambling the data and use a well known algorithm to scramble data. The algorithm usually has two inputs; the data and key. Key is known only to authorized users. Now, relying upon the secrecy of the algorithm is a very bad idea. If you just have an algorithm and if you think that it is a secret algorithm then it becomes very vulnerable because all your communication is going to use that same algorithm so it becomes very difficult to ensure that the algorithm will indeed remain secret. So the modern cryptography depends on the secrecy of the key as its mainstay. Cracking codes is very difficult, with the modern encryption techniques as we will see. (Refer slide time: 10.08 - 12.53)

First let us see some basics of cryptography. Actually we have two algorithms in general. You have two algorithms E and D.  We will assume that E and D are known. This means they are not only known to the sender and the receiver but whoever wants to hack into it or whoever wants to intercept it may also know E and D. Let us assume that E and D are known to everybody. There are two keys ke and kd, these are kept secret. So keeping these keys a secret is a very important part of any crypto system and so how to distribute the keys by themselves is the topic for our discussion, Let us assume that these keys ke and kd, ke is for encrypting the message and kd is used for decrypting the message. In general ke and kd may be different. In some cases they are same but in some cases they are different. For this to be effective the cipher text should be the only information that is available to the world and the plain text is known only to the people with keys. In an ideal world, this is what happens. For example, we have got some plain text here which we want to send in a very secret fashion over the network.  What we do is, first with the encryption key ke and the encryption algorithm E we encrypt this. So, as we encrypt the plain text we get what is known as the cipher text c, so c = E(p, ke) that is the encryption algorithm and then the cipher text is sent. The idea is that, even if somebody intercepts the cipher text since he would not be having ke it will not be possible for him to produce P or it will be very difficult for him to produce P. And on the other side there is a decryption key kd and using the algorithm D and kd we decrypt the cipher text to get the plain text back.. (Refer slide time: 12.54 - 13.05)

Therefore this is the encryption part and this is the decryption part. It should be very hard or impossible to find out the message without knowing the key and it should be very easy and fast to find out the message knowing the key. It is also difficult to find out the message even if you know the key or if it takes long time then it becomes very inefficient. So, in order to handle efficiency this should be fast if the key is known. (refer slide time: 13.23 - 13.58)

Before looking at modern encryption techniques let us look at some classical encryption techniques. There are actually two approaches; one is the substitution techniques. The letters of the message are replaced by other letters or by numbers or symbols. And transposition techniques that performs some sort of permutation on the message letters. These two of course are very basic techniques and they are still used today but in a much more sophisticated fashion. You may have come across (Refer slide time: 13.59 - 15.09)

this kind of encryption in some detective stories, at least in some of the classical detective stories where a message may have been encrypted in this fashion. One of the earliest known uses of the substitution cipher was by Julius Caesar; this is known as Caesar cipher. Suppose the message is ?meet me after the party? and your c = m+3 mod 26 in this particular case then m becomes m n o p, e becomes h so ?meet me after the party? becomes phhw ph diwhu etc which looks absolutely gibberish to anybody. But of course with the help of modern computers trying out various possibilities it is very easy to crack this code. This is of course no longer used so it is just a kind of history. (Refer slide time: 15.10 - 17.44)

The other is, use any permutation of the 26 alphabetic characters. Caesar?s cipher all of them are being displaced by the same amount by three letters. In mono alphabetic cipher this may not be so but you have basically a b c d e f g h etc and it may be any permutation of the same set of letters. Now, for encryption as well as decryption you must have this mapping from a to q b to e c to r and etc. Now under attack u becomes c, n becomes w, d becomes y so c w y u l q etc becomes something like this. You may have noted that we have not considered the blank over here and all of them and that is why it has come as just one string. If you get the reverse mapping then using a dictionary breaking up with these blanks is not difficult. This is mono alphabetic cipher. Once again it is not difficult to break this, for example, if you have done something like this and if you have got a fairly long text there is a statistical table which is available on the internet also about the frequency of occurrences of different letters, for example, e, a, etc, there are some letters like this which occur many times more than letters like j, q, etc so this is available. So using this kind of a table you may even have a mono alphabetic cipher like this. Using this distribution it is quite possible especially with the help of computers, in those detective stories it was done by detectives but now-a-days a computer will do it. It is possible to guess some of the letters and as you guess more and more it becomes faster and finally you crack the message. This is also not such a great way of encrypting things. Once again we will look at this (Refer slide time: 17.45 - 18.33) 

 for historical purpose. The other approach to encryption is transposition. It is performing a sort of permutation on the message letters.  For example, if the message says ?meet me after the yoga party?, then let us say the algorithm is simply this M e then et M e e t, the point is that alternately you write them in one line or in the other line and then you read the top line first M e M a t r etc and then followed by the bottom line e t e f etc. Once again this is quite easy to decipher. (Refer slide time: 18.34 - 19.23)

 Apart from this there are certain practical problems which you have to consider. One is, generating a fully random key is practically very hard, sometimes impossible. And more over to ensure the security of the system the key size should not be less than the message size. And sending a not repeated key in the same size of the message through a secured channel to the receiver is impossible, things like how to distribute this key amongst the potential senders and receivers needs to be understood. The previous one?s possibly if we have a very long key with a length which is comparable to the length of the message then you can have more and more secured communication but having such long key which is almost equal to the size of the message then distributing is a problem. (Refer slide time: 19.43 - 20.34)

Today let us see what we mean by computational security. An encryption scheme is secure if it takes very long time to break the cipher text. If you are using brute force may be you can break all text but then breaking the cipher text takes a very long time then it becomes infeasible. Lifetime is defined in each application. For example, military orders may be one hour to three years, check transaction may be it is for only one year, business agreement 10 to 15 years. So, if decrypting a cipher text takes longer than this kind of time then may be you are doing fine. (Refer slide time : 20.35 - 21.00)

So the bottom line is that if somebody does not know anything about the key it must take more than several years to decrypt a message. With enough number of substitution and transposition modules we can make a strong encryption scheme and this is an algorithm (Refer slide time: 21.01 - 22.11)

called DES or Data Encryption Standard. The basic DES module uses a 56 bit keys. The same key is used to encrypt and decrypt. Keys used to be difficult to guess, needed to try 255 on average, so modern computers can try millions of keys per second with special hardware. Actually you can make a very special machine which can break DES. But it is not easy as you can see that you have to make a very special hardware for trying out millions or even billions keys per second and then it is possible to break this and put a number of machines working in parallel etc. It is possible to break it in some time frame but even then DES is a very good encryption technique and the modern and much more difficult encryption techniques are based on DES. (Refer slide time: 22.12 - 22.56)

Let us just take a quick look on DES. the current algorithm is Advanced Encryption Standard AES which uses 128 bit keys. Adding one bit to the key makes it twice as hard to guess so must try 2127 keys on an average to find the right one. At 1015 keys per second this would require 1021 seconds or may be thousand billion years. This of course is very good and modern encryption technique. It is not usually broken by brute force so what people try to do is they try to get more information. We will not get into attack crypt analysis but discuss just a part of it because we do not have time. (Refer slide time: 22.57 - 23.44)

This is a basic DES scheme suppose, the input is 2w bits, you divide it into two parts, these w bits you do an xor with the output of this function and this function takes other w bits and a key for this round and these two feed into a non linear function which produces an output. And this output is xor with the first w bits. Now this xor is transposed to the second half and this part comes to the first half. So this is one round of DES. (Refer slide time: 23.45 - 24.29)

Actually DES goes in various rounds so for each round there are keys. Actually this is generated from 156 bit am not going into the details and each time you go through this kind of operation with that particular round key from k1 to k16 in 16rounds then in 16 rounds you get the final  encrypted text. The decryption also uses the same set of keys only in the reverse order and if you do that you will finally get the plain text. So the original key size is 56 bits from which all these keys are generated. (Refer slide time: 24.30 - 25.13)

Now-a-days as I mentioned, since DES can be broken sometimes these days people use triple DES. Triple DES is a modern encryption standard which is very difficult to break so you require three keys or sometimes only two keys are used; ka, kb and ka once again. So you take the message, make it go through the first DES block ka then this encrypted message you encrypt again using kb and this encrypted message you encrypt again using ka and this gives you the cipher text. So like AES this is also very difficult to break. (Refer slide time: 25.14 - 27.42) 

Another very important kind of cryptographic technique is the public key cryptography, this is asymmetric key. Till now we have been talking about the symmetric key cryptography. In symmetric key for the encryption and decryption you use the same key. so if you use the same key, if you are doing the same something like a mono alphabetic substitution that table is available to both the parties, it is the same table so that is the same key basically. Similarly in DES or triple DES you use the same key or sets of keys in both the cases for both encryption purposes as well as for decryption purpose. Now, in the public key cryptography, this is another class of algorithms where the key that is used for encryption is not the key which is used for decryption. And knowing the key for decryption it is impossible to guess the key which was used for encryption. So this is the so called asymmetric key or public key cryptography. It uses two keys; one is known as the public key mainly for encryption and private key which is for decryption. Now these keys come in pairs.  Suppose A wants to send some message to B, now what will be available to A will be the public key of B. So what it is going to do is that it will encrypt it or and of course it will have his own private key. So you can do it either way. You can encrypt using your own private key and then send it. But then that can be decrypted with your public key. If somebody else sends it using your public key then I can decipher it using my private key. And since my private key is not known to anybody then nobody else can decipher it, and this is the basic idea. Another kind of function which is used is a trap door or the one way function. 
 (Refer slide time: 27.43 - 29.17)

Let us look at public key cryptography quickly. 
Public-key cryptography: instead of using a single shared secret, keys come in pairs. One key of each pair distributed widely which is called the public key and one key of each pair kept secret, i.e. private or secret. Two keys are inverses of one another but not identical. Encryption and decryption are the same algorithm. If you encrypt a message M using the secret key then using the public key if you run the same algorithm then you will get the deciphered message M. Similarly if you encrypt using the public key and then decipher it that means run the same algorithm again with the secret key then once again you get M. So, currently the most popular method involves primes and exponentiation. This basically is based on the fact that this is difficult to crack the encryption unless large numbers can be factored easily and there is no known method for factoring very large numbers. Large number means numbers or integers with large number of places. The difficultly with public key cryptography is that it is very slow for large messages. (Refer slide time: 29.18 - 30.00)

 Trap door one-way functions: It is computationally impossible to find out what are K and M when knowing the Ek (M). So knowing M you can of course use the trap door function with this ke to give Eke(M). Therefore you can go in only one direction but from this side it is impossible to come on the other side. This is also sometimes used for authentication in digital signature as we will see. (Refer slide time: 30.01 - 30.41)

 So one way functions are functions which given a formula for f(x) it is easy to evaluate y = f(x). Given y computationally infeasible to find any x such that y = f(x). Often operate similar to encryption algorithms; it produces fixed length output rather than variable length output. It is similar to xor in blocks of cipher text together. Common algorithms include MD5, so 128 bit result or SHA 1 which gives you a 160 bit result from a text. (Refer slide time: 30.42 - 32.11)

 Now let us see one important application of all these; public key and one-way functions etc which is in digital signatures. A hand written signature is a function of the signer only and not the message. That means suppose I sign some document I can sign any number of documents, my signature will remain the same and it is very characteristic of my way of signing, my handwriting etc so it is difficult for ordinary people to replicate that although there are good forgers who can replicate many signatures. Now, the digital equivalent of handwritten signatures would be useless in ecommerce. So we must be able to compare it with the real signature and must be sure it is not copied or forged. Now how can A prove his identity over the internet that is the basic idea? When I sign a document I am basically saying that it is me alone who has sort of written this so that is why I signed the document or agreed to do this. Now how can I do this over a network? (Refer slide time: 32.12 - 33.09)

This is the basic scheme of a digital signature. Digital signature is a function of both the signer and the message. A digital signature is a digest of the message encrypted with the signer?s private key. So, we have a message M and it may be a very long message so use some secure hash algorithm to produce hash that is the message digest. That means you make it run through some hashing function which produces an output of its length which is a product of this particular message.  Now you encrypt this hash using the signer?s private key and this produces the digital signature. Now this is the digital signature of Mr. A on message M. (Refer slide time: 33.10 - 35.16)

You have the original document, you use a one-way function or a hash function and the has result is encrypted with a secret key or the private key of the signer and this gives the digital signature, Now the receiver should get the original document plus the digital signature. Of course, if you want to ensure that the original document also should not be seen by anybody then this entire thing that is the original document plus the digital signature you can now encrypt using the public key of the receiver. What the receiver will do is that the receiver will decrypt it using his own private key so that he gets back this. Since public key may be public so anybody could have sent this document, how do I know that this actually came from whomever it purports to be and this is where the digital signature part come in. So the receiver can verify by applying one way hash function to the received document so he will apply the same hash function to this document therefore he is supposed to get back whatever was here. Now he will decrypt the signature using the sender?s public key. He has the sender?s public key with him and since it was encrypted with the sender?s private key now I can use the private key of the sender to get back the same message. So comparing the two results equality means document is unmodified because this digital signature could not have been produced by somebody else because this is a product of this document as well as the secret key of the sender and it is visually known only to him. (Refer slide time: 35.17 - 35.25)

Therefore if the two hashes are equal then the message is authentic. (Refer slide time: 35.26 - 36.42)

This does not solve the entire problem because sometimes you require some identity documents. What is an identity document? Identity documents are passport, birth certificate, driver?s license, etc. This is basically a piece of paper issued by a trusted third party with information verifying the identity of the holder. Now, this has to do with the following: For example, even if you have a digital signature, the digital signature will only tell you that it will verify that this message has been sent by somebody who has this particular secret key. That means secret key corresponding to the public key that the receiver is holding. Now how do you absolutely guarantee that the secret key is held by the right person? That is where the identification comes in. So, a challenge is a protocol for holder to prove he is the person named in the document. In the non electronic world we do it with photograph, signature, fingerprint, etc. (Refer slide time: 36.43 - 37.15)

 A digital certificate is a digital identity document binding a public private key pair to a specific person or organization. Verifying a digital signature only proves that the signer had the private key corresponding to the public key used to decrypt the signature. It does not prove that the public private key pair belonged to the claimed individual. We need an independent third party to verify the person?s identity through non-electronic means and issue a digital certificate. (Refer slide time: 37.16 - 38.54)

 And a digital certificate contains all these things; the serial number, name of the holder etc. This has the public key of the holder, name of the trusted third party, then the digital signature of a certificate authority. Data on which hash and public key algorithms have been used and other business or personal information. The point is that, the digital signature of the certificate authority since the certificate authority is the third party who is trusted. This means, if his digital signature is there, because since the public key of certificate authority is known then his digital signature can be verified. And in this particular case this authority is trusted. That means we know that something bearing the digital signature is indeed coming from that physical trusted authority. And now this trusted authority is basically certifying that the name of the holder is the holder of this particular public key. Of course the holder has his own private key. This private key would not be known to anybody else but then he is the holder of this public key. (Refer slide time: 38.55 - 39.29) 

We have a version of certificate standard. So these digital certificates can be checked by a machine that is the whole idea. You have a hash algorithm and then the message digest, issuer?s private key and then put the signature of the issuer. The subject?s public key is what is being certified. So, it is this algorithm plus the public key value. Then there is period of validity for this. (Refer slide time: 39.30 - 40.26)

This public key cryptography is quite an elegant system. The only trouble is that, this is rather a computationally expensive process, it is quite slow. Pretty good privacy: It uses both public and private key to chart a middle course. It uses public key encryption to facilitate key distribution. It allows messages to be sent encrypted to a person that is encrypting with persons public key. It allows person to send message that must have come from her. That is, encrypt with persons private key.  (Refer slide time: 40.27 - 41.31)

The problem is, public key encryption is very slow. The solution is to use public key encryption to exchange a shared key. A shared key is relatively short which is about 128 bits or so. Therefore message is encrypted using the symmetric key encryption. Now what you do is that in the first phase you use the public key cryptography system to exchange just the shared key. This key may be shared just for this very session and then it may go. This is shared for particular session. Since this is 128 bit you can do it once even though it is expensive or this is a bit inefficient. And then, once both the parties are sharing the same key, this is the symmetric key, so this works much faster and the message is encrypted using symmetric key encryption.  PGP can also be used to authenticate sender, use digital signature and send message as plaintext. There are various ways in which PGP can be used. (Refer slide time: 41.32 - 43.32)

With this we come to the end of our discussion about some security issues which are very general and with which most of the service organizations are very much concerned. Security is the foundation on which all these so called e activities dependant upon. Now we will focus more on the network technology part of it that what we mean by the security of a network. This is security of messages in the network and now I am talking about security of the network itself. Some terms are quite commonly used here and one such device commonly used is the firewall. It solves poor internal security measures using the network. Now all these have to do with securing the functioning of the network. The other is an intrusion detection system. Sometimes an intrusion detection or intrusion prevention system is integrated with a firewall and sometimes they are two different boxes. So intrusion detection is that, I want to detect whether any unwanted or unauthorized person has some how intruded into my secured zone and once he intrudes into my zone he will have access to data and messages from my network which I do not want. It detects non network security breaches accomplished via the network. Therefore firewalls and intrusion detection, stock prevention are all very important and most of the network vendors have got separate boxes for doing this. (Refer slide time: 43.33 - 43.58)

Therefore here let us see how they are being used. By the way there is also a question of authentication of users and what is used. Sometimes you may use distributed authentication, a centralized authentication, LDAP or AAA server for that authentication and you can do a distributed co-operation also. (Refer slide time: 43.59 - 48.23)

 This is a typical corporate network. A typical corporate network is meant to be very secure. We start from the left hand corner. Suppose these are the user machines and then we have an internal domain name server or internal mail server, internal web server, internal file server, etc. This is the private network of the corporation, i.e. the intranet of the corporation. This term intranet really means that we use the same technology which we use in internet and which you use in your internal network also. So you are using things like web browser, DNS, mail server, etc which work in the internet, the technology being deployed only for private purpose. So, this left hand part is only for the private purpose and only these authentic users should be able to use this intranet. This is connected to the internet as you can see here on the right hand corner. Although this is connected to the internet other people will generally not have access to this part. So what we do is, we try to make this internal network secure using a firewall and this is an internal firewall. And then we have another machines also belonging to the same corporation like this web server which is used for helping people by providing servicing in the internet, we have mail forwarding and DNS etc. These are put in a zone which is known as demilitarized zone. Then this connects to the external firewall and then the external firewall finally connects to the internet. Actually what happens is that, what a firewall will do is that, a firewall basically inspects the packets and decides on whether these packets are ok and secured or not. It follows a set of rules.. Depending on how you configure it is possible to have different levels of security at various ports of the firewall. A firewall may have 2 3 4 5 ports.   Suppose it has got 4 ports, it is possible to port-wise configure the security level of each of the port. Now what you want to do is that, you want to make your internal network absolutely secure. So somebody who wants to access through this firewall into something which is staying in the highly secured zone, that is absolutely the internal code network then he has to go through lot of checks, so that is a high security zone. But again what may happen is that you also have some machine like web server which you want to be open to the public. Similarly your DNS or your mail machine etc have to have a public dealing, a public face. So we want to keep some kind of medium level security for these kinds of machines. So they are put in a network area which is known as the demilitarized zone DMZ and then a firewall may connect directly to the internet also so that leg of the firewall would be of very low security termed as the low security zone. This may be one way of using two firewalls. Sometimes people will use only one firewall but this is a deployment using two firewalls such as one internal firewall and one external firewall. (Refer slide time: 48.24 - 48.59)

Network regions are these internet that is not secure at all, intranet which is highly secure and DMZ which is the middle level security. And the network boundaries for all these different regions are at the firewall. So there may be filtering firewall based on packet headers, there may be audit mechanisms. A proxy may also be used as some kind of a security device. (Refer slide time: 49.00 - 51.42)

For example, you can use IP addresses for some low level of security. The network address translation came up as the IPv4 addresses have virtually disappeared and only some class C addresses are available. So, in order to obviate that what we did was that in a internal network we used some private IP addresses and when we use a private IP address in my network, and in order to communicate we have to go through a proxy and the proxy will remember that a machine with this private address is wanting to communicate with the outside world, so it puts a valid IP address from a pool in place of the private address which is not really valid outside and then sends out the request gets the message and then sends it to this private IP. It is conventional to number the private IP addresses starting with 10 which is 10.x.x.x so that is one full class A address which is a huge address space for one organization. And the point is, the routers outside, are usually not going to route any address which starts with 10. because it knows that 10. is used for private IP. So if you use private IP addresses it is difficult for outsiders from the internet to log on to your machine unless he/she is going through some proxy and getting into your network in the first place. Therefore network address translation protocol maps internal to assigned address. 
Mail forwarding: Hide internal addresses, map incoming mail to real server, and additional incoming and outgoing checks may be performed. Therefore all these are different things you can do to enhance the security of your network. It is not possible to make your network hundred percent safe but you can increase the level of safety through various measures, this is one kind of such measure apart from any firewall that you might have put. (Refer slide time: 51.43 - 53.24)

For firewall configuration, in the external firewall, what you can configure is, find out what traffic is allowed. External source: You may put IP restriction so external source may only be from this or from these IP addresses, we will specify that. What type of traffic: Ports for example SMTP for mail or http for web etc, what kind of traffic I will allow and what kind of traffic I will not allow. May be I will not allow telnet in the secured zone at all from the outside. 
Proxy between DMZ servers and internet and proxy between inner and outer firewall are the things which you can configure in an external firewall. the network has become such a burning issue these days, so more and more development is taking place in this region and especially in firewall design etc so in modern firewall it not only works very fast but it can look at lots of things. It can counter peer to peer messages and all kind of things it can handle.. For internal firewall you can put traffic restrictions on ports from or to IP address and you can proxy between intranet and outside. These are the things which do with the firewall.  (Refer slide time: 53.25 - 54.00)

For DMZ administration whether a direct console access is required? If a direct console access is required then naturally this is another place, this is somewhat troublesome. Or you can use special access using SSH Secured Shell Connections allowed from internal to DMZ administration connections or only from some specific internal IPs or only through internal firewall etc you can administer the DMZ. This reduces the security risk to only one or a few machines. (Refer slide time: 54.01 - 54.23)

You can authenticate in various ways. One question always comes up is that whether your authentication will scale? You can repeat the authentication, have multiple administration, but if you have distributed authentication scheme then that is always good. (Refer slide time: 54.25 - 54.26)

(Refer slide time: 54.27 - 54.40)

Let us look at some attacks and defenses. One kind of attack which is common is denial of service attack, routing attack, spoofing attack and may be there are other kinds of attacks people are thinking about. (Refer slide time: 54.41 - 55.10)

As people are thinking in a more secured way, the hackers and all other peoples are also thinking of many ways of compromising security. Confidentiality on the network is manageable such as encryption to protect transmission, public key cryptography, key management, etc. Integrity is reducible to single system: digital signatures verify source and commit protocols handle network failure. What about availability? This is where the attacks on the network come into picture. (Refer slide time: 55.11 - 55.40)

 One is flooding: this is a denial of service kind of attack. That means overwhelm TCP stack on target machine which prevents legitimate connections. Routing attack is misdirecting traffic. Spoofing: when somebody is entering your network claiming to be a false identity then spoofing imitates a legitimate source. (Refer slide time: 55.41 - 56.02)

What is a flood attack? Limit the availability by overwhelming service by following service?s protocol to an extent. Example is a SYN flood; it overwhelms the TCP stack or may be a large number of emails being generated by a script. (Refer slide time: 56.03 - 56.39)

Let us look at SYN flood. In TCP protocol when a client initiates a SYN then it waits and then the server will acknowledge it and send a sequence number. The server will also send the SYN and then it will wait for an acknowledgement from the client. This is a multi-step process. Sequence numbers are incremented for a future message. It ensures message order and retransmits if lost. (Refer slide time: 56.40 - 57.35)

What some malicious person might do is that receive the SYN, the server receives the SYN, allocates connection, acknowledges and waits for response from the other side, waits for this response. So what this is doing is that it is sending one SYN after the other in rapid succession. So, on the server side you will be opening so many connections and you will send acknowledgements and wait. Therefore what will happen is that the entire space for connections becomes allocated. And this is of course is done by a malicious user but a legitimate user can no longer get any access to this server because the server has become absolutely overwhelmed. Hence this is a denial of service. (Refer slide time: 57.36 - 58.04)

So you can limit connections from one source, ignore connections from illegitimate sources, drop oldest connection attempts etc. What the firewall will do is, the intrusion detection system will also try to detect that and block all the flood of SYNs etc which is coming from one source. But that does not solve the distributed denial of service attack which is coming from many sources. (Refer slide time: 58.05 - 58.29)

Network solutions: TCP intercept: Router establishes connection to client, when connected establishes with server. So router comes in between server and the client. 
SYNkill: Monitor machine as a firewall, good addresses: allows history of successful connections otherwise kills it. These are the intrusion prevention kind of situation. You can try to encrypt your SYN (Refer slide time: 58.40 - 58.47)

or make changes in protocol also but that is usually more difficult and cumbersome to implement unless absolutely it is your own and private network. (Refer slide time: 58.48 - 59.12)

 Service-Level Flooding: Overload the server: Looks into its processing, storage, etc. Typically garbage requests using legitimate protocol: Large emails to victim, many http connections, Heavy use of scripts. These overwhelm the server in some other way so that it cannot give legitimate service. (Refer slide time: 59.13 - 59.15)

(Refer slide time: 59.16 - 59.18)


IP Spoofing: What somebody can do is that, instead of overwhelming server he can overwhelm the client and then take on the role of the client. So, there are various ways in which these network attacks are coming and there are ways to handle this. This is a developing and important field. We have just given a overview today, thank you.
Computer Networks
Prof.S.Ghosh
Dept of Computer Science and Engineering
I.I.T kharagpur
Lecture # 39
FTP-SMTP
Good day, so today we are going to take up two important application layer protocols namely FTP and SMTP. So, first (Refer slide time: 01:00 - 01:01)

let us look at FTP.  (Refer slide time: 01:07 - 01:33)

This is called File Transfer Protocol and it is a very widely used protocol for reliable transfer of files. It uses TCP as transport for reliability, it uses out of band control and this is stateful. So we will go into these one by one. First thing is that, we want this file transfer to be very reliable, in the sense that even missing one bit in between may actually corrupt the entire file. So we want a good degree of reliability and as we have seen in our discussion on TCP that one way to achieve this reliability is to use TCP. You use FTP for downloading files, now, as soon as you start an FTP to download a file it should start immediately unlike mail which may be delivered after sometime i.e. 10 or 15 minutes or so. That is one requirement of FTP. The other requirement is that the speed is not constant. The speed should remain constant but that is not a crucial requirement for FTP. A file may be transferred fast in the beginning, then if the network gets congested it may slowdown but then that is alright, in all these respects TCP is a very ideal transport protocol for running FTP. Let us look into the (Refer slide time: 02:56 - 04:35) 

general scheme. First of all, suppose this is an FTP client trying to contact an FTP server there is a TCP control connection at port 21. On the above we have mentioned the control connection and below we have mentioned a data connection. These two connections are different, that is why it says that its control is out of band. Actually, out of band control means, whenever two nodes are communicating this is a general term that if there is some control information going between the two, for example, in a telephone the connection setup there is control information, ringing etc there is a control information and when this control information and the actual data occupy two distinct channels then it is called out of band communication. That means the control is out of band. For control connection TCP uses different port and for data connection it uses a different port. One is a port number 21, the other is a port number 20 and these are basically well known ports. The request comes from the client through this port number 21. So the server opens a port number 20 with the client and starts communicating. (Refer slide time: 04:35 - 06:37)

Now, FTP client contacts FTP server at port 21 specifying TCP as transport protocol. Client obtains authorization over control connection. Now this is important, when you want to download a file it is important to check whether whoever wants to download has a proper authorization or not because not all files and all information should be available to everybody in the world. There are questions of privacy and security etc so that is why some authorization is necessary. Of course in this case what FTP does is, the authorization is rather at a rudimentary level in the sense that it is through users and passwords only but anyway that much of authorization is there and this authorization process goes through the control channel. Therefore client obtains authorization over control connection. A client browses remote directory by sending commands over control connection which means that, if the authorization phase goes through without any trouble then the current directory at the server end can be seen by the client from the other end by giving some commands. Now, in raw FTP, the commands are a little bit cryptic whereas there are FTP clients with good graphical user interface where you can actually graphically see the directory etc, this is the remote directory we are talking about it. Therefore he can look into the remote directory and select whatever file he wants to download. (Refer slide time: 06:38 - 07:27)

When server receives a command for a file transfer the server opens a TCP data connection to client and this is again done on a well known port 20 on the client so a new data connection is setup. After transferring one file server closes the connection. Now, what might happen is, a person may want to transfer a number of files from the server, so if again there is a request for another connection the server will open another connection again on the same port and the second TCP data connection is setup to transfer another file, so this is how it goes. (Refer slide time: 07:27 - 08:41) 

So control connection is out of band and FTP server maintains state. And what is the meaning of state here? It is the current directory and earlier authentication. That means that once a client connects to a server and gives his authorization then for that entire session till such time he does not log out that authorization is kept valid. That means he can go on accessing whatever is available on the other side, then the current directory  means the directory which he is browsing at the moment, the directory from which he is downloading the present file etc. The current directory for this particular client is also maintained at the FTP server. Therefore it is called a stateful protocol in the sense that it maintains the state. Even if one file transfer is over and it closes but the authorization in the current directory remains, hence this is a stateful protocol. (Refer slide time: 08:42 - 09:57) 

FTP Sample Commands: These commands are sent as ASCII text over a control channel. This is a simple ASCII text going over the control channel. It expects the user?s username and the password. These are commands you can give and these commands go to from the client to the server through the control channel. So, you can do a return list of file in current directory. This is the basic FTP command. You may also have the user interface which shows it very attractively in a graphical fashion. RETR is a file name, it retrieves or gets a file, you can use it to get and retrieve a filename. STOR filename stores or puts file onto the remote host. You can both get a file from the remote host as well as you can upload a file on the host and for doing that you have to give the particular filename. These are some sample commands for FTP which you can use. (Refer slide time: 09:58 - 11:07) 

And then once again we are talking about the control channel only. The FTP sample responses give a status code and phase as in HTTP. These are basically codes 331 user name OK, password required. When you have just entered the user name and if that user name is in his list he will sent an ok for the user name but then you still have to give the password. And 125 data connection already open transfer starting, so, in the control channel these are the kinds of responses from the server side that may come. And 425 cannot open the data connection, 452 error writing file. So, all these errors and other kinds of responses come through the control channel. These are some of the FTP sample responses. (Refer slide time: 11:08 - 13:23)

 And that is all about FTP as far as it is concerned. It is a very simple protocol but at the same time it is an extremely important protocol. People always want to download files and these files could be of any kind, there is no restriction on the kind of file. If it is a binary file you have to set the mode that way. But the file could be a text file, it could be a binary file, it could be images, multimedia or anything. If it is a binary file you have to set a mode.. And the next important application we are going to discuss today is SMTP which is at the route of all the emails or the so called electronic mails. Electronic mail has been a very important application of the network. As a matter of fact these two things taken together that one is the web which is the HTTP protocol which we are going to discuss in the next lecture. HTTP and email i.e. web and email have been the killer applications so as to say for computer networks which made computer network immensely popular, contributed a lot to the growth of a network in general. As you grow you get all the economies of scale so naturally money is invested and a lot of money comes in which sparse further growth and further innovation etc. HTTP and SMTP have been the so called killer apps of computer network. Let us now look at the details of SMTP. SMTP stands for (Refer slide time: 13:24 - 14:17)

Simple Mail Transfer Protocol. It is a simple protocol. Like FTP it is quite simple. But for sending mails etc there are some more intricacies which we will see. This is one of the most popular network services, email, is supported by TCP IP protocol SMTP. System for sending message to other computer users and provides a mail exchange between users. Actually, many of you must have used emails and you know that you can send a mail to a number of people and there are lots of advantages of this email. The chief advantage is being the speed at which your mail reaches the other end. Actually once email came into vogue the classical mail which goes into the post office have been renamed as snail mail that it goes at a snail space whereas email goes extremely fast. It may not be instantaneous depending on how your mail servers etc are configured but it goes very fast and it may be almost instantaneous. So, in a few minutes the mail reaches the other side. And the other thing is that it is so cheap and you can attach any kind file to it. Therefore all these make the email very attractive and the volume of email has grown tremendously dwarfing the number of ordinary mails that had been going on before that by orders of magnitude. (Refer slide time: 15:15 - 15:19)

So that is what SMTP (Refer slide time: 15:20 - 17:08)

does. It supports sending a single message to one or more recipients. Sending messages include text, voice, video or graphics. Actually as the SMTP was originally envisaged it can carry only text messages but then people found a way around for encoding other kinds of a data because as soon as text messages become per say people wanted to send pictures, voice, video and all kinds of graphics etc through the email so there was a way of encoding it. So we can send messages to users on networks outside the internet which is also possible. Actually this is becoming less important by the day because what is happening is that internet is swamping all other types of network but when SMTP came into existence not only the TCP IP networks but other types of networks were also in vogue and so a way had to be found to exchange mails to users who were on different networks. It was in the heterogeneous kind of network and that has actually introduced a lot of complexity into the SMTP gateways. This is also possible although this is becoming less important now because everybody seems to almost switch over to this internet and TCP IP protocol. (Refer slide time: 17:09 - 17:59)

An electronic mail system has three major components: One is the user agents. Here are some examples of user agents like Eudora, Outlook, Pine, Netscape messenger. So all kinds of user agents are there which provides the user with a graphical interface and it makes it sort of simpler even for late people to use this mail system. And then there are mail servers which handles the incoming and outgoing messages and they use the simple mail transfer protocol between the mail transfer to reach the mail from one end of the network to another. (Refer slide time: 18:00 - 19:21) 

This is just a diagram. We have these user agents who are connected to mail servers. The mail server maintains an outgoing message queue so any of the user messages may keep on sending mails so they are in the outgoing message queue. Similarly, whatever incoming messages are coming they also come into this mail server and by looking at the users address they go into the individual users mail boxes. So, if these yellow boxes represent the users mail boxes then the user agent will connect to these mail boxes. Mail boxes are basically directories where all your mails are kept and it can access its own mail i.e. the mails which are incoming so they go into these mail boxes and mails which are outgoing they go into a queue and from this the mail server sends it to different other mail servers and these different mail servers talk to each other via this SMTP protocol so it may reach another mail server to the mail box to a particular user agent. That is how the system works. (Refer slide time: 19:22 - 21:11) 

One important component of the system is the user agent. It prepares the message and creates an envelope. This envelope is nothing but, the term obviously has been brought in from classical mail just as you write a letter and then put it in an envelope similarly you put your message into an envelope which has got a certain format. It is the job of the user agent to create the message, the user has to type in the message or upload it from somewhere and then it is put in the envelope in the proper format. This would be the job of the user agent. Then he puts the message in the envelope and sends it over to the mail transfer agent, which is one job of user agent. The other job is that, for the incoming mails it has to show the incoming mails and then depending on what kind of user agent you have you may be able to create directories for classifying the mails. You may have mails from friends in some directory and mails for business purposes in other directory and some user agents also allow you to define rules so that whenever an incoming mail has come to the user agent it will automatically examine the mail and put it in its proper directory. All these are done by the user agent and then there is this mail transfer agent. So from the user agent the envelope goes to the mail transfer agent who transfers the mail across the internet. (Refer slide time: 21:12 - 22:04)

You have these different machines who uses the user agent to create the envelope which are then sent to the message transfer agent or mail transfer agent. Now it travels through the internet, for the time being let us consider only internet as a homogenous kind of a networking system and then the envelope is delivered to the proper user agent and then the user accesses his mail through the user agent into his own machine. So this is the overall email architecture. We will look at another overall architecture a little later. (Refer slide time: 22:05 - 22:32)

There is some relay MTAs. So mail may be relayed through a number of MTAs, allows systems not using TCP IP to send email to users on other sites, is accomplished through a mail gateway. A relay MTA that can receive and send a mail prepared by a protocol other than SMTP. So this relay MTAs are very important. First of all, by looking at the address remotely it may not be possible to disambiguate the address of the final mail server who is going to give directly to the user agent, it may not be possible to disambiguate it. So maybe there are mail relays before that are bigger entities who are known and the mail can be sent to him and he will send it to the proper mail server who will directly give it to the user agent, that is one job of mail relay. The other job of mail relay is that, suppose it is possible to transfer mails between heterogeneous networks, so you have one kind of network here and another kind of network here, so in between there has to be a mail gateway. This mail gateway is also some kind of relay MTA so the message will first come to this relay MTA who will then actually store it and then the format etc of the envelope and other things may not be the same in the two networks. So he will make those proper changes and then send it over to the second type of network. This is the job of a mail gateway. (Refer slide time: 24:08 - 24:47)

Here is an example, suppose a user agent has sent a mail through its own MTA via the internet, now this MTA is actually working as a mail gateway and this mail gateway then can push it to another kind of network which is a private network to the corresponding mail system. So this way it makes it possible for user A and user B to communicate, exchange mails although they are on different kinds of networks. This is becoming less important by the day because other kind of network is giving way to TCP IP networks. (Refer slide time: 24:48 - 26:47)

Now, for delivering mails of course you need the addresses so there is a unique addressing system. It consists of two parts; one is the local part followed by ACK followed by a domain name. You must have come across mail addresses and seen ACK something dot something dot something. So this is what it looks like. Now the part before the ACK is the local part and this local part is supposed to specify the mail box within that local network where this mail is finally to be deposited. Suppose that is the address of the person to whom you are sending the mail, the destination of that particular mail box to which this mail is to be deposited is given by the local part, whereas the domain name is what allows him to send a mail to the proper destination. By looking at the domain name he knows the destination so he will send it to the corresponding mail server in that domain. Sometimes this may not be done in a single hop so it may go through a few mail relays.. So this is the address part. Once the domain name reaches its destination then by looking at the local part finding out the address of the mail box is easy. (Refer slide time: 26:48 - 26:59) 

The local part defines the user mailbox where mail is stored for the user and domain name is the name of the host used as the mail exchanger. .(Refer slide time: 27:00 - 28:28)


Unlike FTP or HTTP for mails messages do not necessarily have to be delivered immediately. It can be delayed at the sender site or receiver site or intermediate servers. During this time what happens to the mail is that it is waiting in some queue and the mail servers may be configured to pole the different machines connected to it for outgoing mail from time to time. That is the time when it delivers the mail so it sends and receives messages during that time and that time may be set, that time may be a few minutes or may be more than that. And then it goes and waits in the outgoing message queue before it is processed etc. Therefore the delivery is not instantaneous it may be delayed. But usually nowadays mail is so important so people put powerful machines for doing these jobs and the mail goes really fast compared to snail mail but then compared to other protocols like FTTP or HTTP this SMTP, the messages may have to wait in some queues in some servers either on the sending site or receiving site or intermediate servers. (Refer slide time: 28:29 - 29:34) 

Aliases mean different names for the same person. SMTP allows one name an alias to represent several email addresses. This is one-to-many alias expansion. A single user can be defined by several email addresses so this is many-to-one email expansion, so both are possible. For example, you know that it is possible to send mails to a group of people. Suppose you regularly communicate to a group and when you send a message you want that message to reach to every member of the group, something like multicasting, so what you can do is that, you can define the group giving the email addresses of all the members in the group and then when you actually compose the mail you can simply send it to the group so the machine will automatically send one copy to each member of the group. That is one-to-many alias expansion. Similarly many-to-one is also possible. (Refer slide time: 29:35 - 30:11) 

this is a general kind of picture, you have the user who goes through the user interface to the user agent which puts it in this spoon for the outgoing mails and it collects the mails from the mail boxes from the corresponding mail boxes. User A will have one mail box here and then there will be alias expansion. Then it will go through the MT?s through the internet to other MT?s to reach its destination. (Refer slide time: 30:13 ? 30:57)

Now, looking at the mail message format, this is the SMTP protocol for exchanging email messages and RFC 822 gives the standard for text message format. The header lines contain two things namely to whom it is addressed from, i.e. where the mail is coming from and then there is a subject line. So these are members of the header. Then there is one single blank line and then there is the body that is the message and the message as you know is the ASCII characters only. (Refer slide time: 30:59 - 31:12)


Between the MTA client and MTA servers SMTP uses commands and responses to transfer mail between an MTP client and MTP server. Therefore this is the command and response mode like other (Refer slide time: 31:14 - 31:29)


application protocols. Mail transfer has the following phases: The process of transferring a mail message occurs in three phases: connection establishment, mail transfer, connection termination. (Refer slide time: 31:30 - 32:12)

So, for connection establishment client makes a TCP connection to the well known port 25. The well known port 25 is used for SMTP. The SMTP server starts the connection phase. So the server will reply with the 220 service ready. As soon as MTA client sends a request to this port 25 if the sever is ready or 220 service ready will come back automatically then there will be a hello message from client to the server side and server side will respond with a 250 OK. These are the commands and responses which are going on. We will (Refer slide time: 32:13 - 32:33)

look into more details of an actual SMTP session later. When the connection is ready a single message between the sender and one or more recipient can be exchanged, this is the message transfer phase. (Refer slide time: 32:34 - 32:42)

And finally there is a connection termination when the client sends the quit and the server responds saying that the 221 service is closed. (Refer slide time: 3:45 - 33:17)

Actually, this protocol is so simple. You can just try it out yourself to send mails by directly doing a telnet on a particular port suppose you know the server name. So you just telnet the sever name 25 and you will get a 220 reply from server, then you enter your commands hello, mail, from, receipt, etc and then finally you quit. The above lets you send mail without using email client or a reader. (Refer slide time: 33:18 - 34:50)

This is of course also used by people who do not want to be identified that who is sending the mail etc, so all other misapplications and misuse of these facilities are also there. Here is one sample SMTP interaction, after you have telneted it the server comes with a response that 220 iitkgp ernet.in if suppose that is the name of the server. Then the client sends a hello cse iitkgp ernet.in, so you receive a helo from this client. Then the server will say helo cse iitkgp ernet.in pleased to meet you, then it will say mail from then maybe you will give an address, then 250 so the sender,OK. So, this is the client and server, the client is sending one command and the server is responding saying they are giving the feedback all the time that it is ok. Then you have receipt TO, this mail is to be sent to such and such, so he will say that recipient ok. Then he will say data, meaning that, what follows would be the data which is the body of the message that is to be sent. (Refer slide time: 34:52 - 35:45)

In response to this data command what the server will say is, give 354 enter mail, end with dot, there is a full stop on a line by itself. So, suppose this is the body of the mail, this is a test mail checking protocol etc then you end the mail with a dot by itself. So carries return nine feeds, CRLF followed by dot followed by CRLF that is the SMTPs way of checking that the mail body is ended. So the message 250 means message accepted for delivery. Now, when the message has been accepted you can quit and then it quits. (Refer slide time: 35:47 - 38:06)

Here are some final words about SMTP. First of all it uses persistent connections. That means, so as long as you do not quit you can go on sending mails one after the other. Actually that is what the machines will do. The session I showed you is just an example, usually you would not send mail by directly using SMTP. as a matter of fact there is no point doing that unless you have some other intention. So what you will do is that you will use a standard mail agent for doing that. When the machine opens an SMTP connection this is going to be persistent till such time you quit. So, a number of messages can be sent in the same session. I should also mention that, apart from these standard mail agents like using SMTP etc, one service which is becoming quite popular now-a-days are the web mails. Actually for the web mail you connect to the web mail server i.e. whoever gives you that service through HTTP. From that point onwards it works the same way. So SMTP uses persistent connections. SMTP requires message that is header and body to be in 7-bit ASCII. SMTP server uses CRLF. CRLF that means carriage return line feed. carriage return line to determine end of message. And as we have seen that SMTP is a chatty protocol in the sense that you say something immediately it tells you something back so this back and forth command and then the response goes on for this CRLF. CRLF sometimes some flexibility is also given when some part of it is missing. (Refer slide time: 38:08 - 38:53)

And comparing it with HTTP one thing is that HTTP is a pull kind of a protocol that means the user rather makes a request and pulls the content whereas here the content is pushed from the sender to the receiver. Both have ASCII command response interaction and status codes. In HTTP each object is encapsulated in its own response message. SMTP multiple objects sent in multipart message. Actually you can send a multipart message, this is where all the attachments etc to a mail come in. (Refer slide time: 38:55 - 39:59)

Now, of course as we know that now-a-days we can send not just text messages but other kinds of things namely pictures, graphics, voice recording etc we can send through the mail. This means it is possible to send binary files through the mail. And the way it is done is by encoding this binary file into a textual form. There are various ways to do this encoding. SMTP is the Simple Mail Transfer Protocol, it can send in NVT 7-bit ASCII format only. It cannot directly send binary files, for example, video or audio or images.
MIME: Is a Multipurpose Internet Mail Extension. So MIME is an extension to SMTP which allows non ASCII data to be sent through SMTP. This is so important and useful and very common now-a-days. (Refer slide time: 40:01 - 40:15)

It transforms non ASCII data into NVT ASCII at the sending end which can be transformed back at the other end. What it does is that it adds additional lines in message header to declare MIME content type. (Refer slide time: 40:17 - 42:05)

This is an example of some message which actually contains a binary file. The initial part of the header from sujoy etc to etc etc, subject: picture of car where maybe we are sending a picture through the message. So the from to subject is like a standard message. Then since this is using MIME it says MIME version 1.0 so MIME version has to be mentioned. This is important because whatever you are sending has to be decoded on that. Then content: The method used to encode data, content transfer encoding is base 64. So base 64 is one way of encoding a binary file into a text file but you have to mention that. There are different ways of encoding binary file into text and base 64 is just one of them. So the sender has to mention or sender has to clearly specify that this is the standard encoding scheme that he has used for encoding the file so that the receiver on the other end can actually decode it. So you have to mention the method used to encode data. Then you say the content type which is image or JPEG and then you give the base 64 encoded data. (Refer slide time: 42:06 - 43:42)

Base 64 encoding is actually quite simple. Suppose you have a binary file, you take 6-bits from a binary file at a time from groups of 24. So you take 3 bytes and make four 6-bit sequences from this so 3 ? 8 = 24 and 4 ? 6 = 24 so from three bytes you can get four groups of 6. So you interpret these 6-bit binary strings as a binary number and then depending on that number you encode it into a textual form. So 6-bit will give you 26 which is 64 different numbers which is 0 to 63 and the encoding is the following: Encoding is A B for 0, 1 etc followed by 26 lower case letters so that makes 26 upper case plus 26 lower case that is 52 letters followed by ten digits (0 - 9) so that makes it 62 followed by ?+? and ?/? for number 62 and 63. This way from (0 - 63) you get A to B upper case, a to b lower case, digits, and ?+?and ?/? that gives you an encoding so that is a text and you encode it as a text and then send it as a text. (Refer slide time: 43:43 - 45:00)

Now, we will come to the user end so this is POP3 which is the Post Office Protocol. POP3 is a very simple protocol for interacting with your mail box which is in the server. This is very widely used. What this is used for is that, actually your incoming mails will be deposited in your mail box, now POP3 is a protocol for getting that content of your mail box or downloading it on to your desktop machine. that has advantages for example, the server gets less loaded because with people getting so many mails now-a-days, very soon if you have a departmental server giving the mail services to all the members of the department and if all the mails get accumulated there then it will load the mail server variable, it is good practice to download it to your machine and POP3 is a protocol for doing this download. (Refer slide time: 45:01 ? 45:42)

Mail Access Protocols: there are other protocols apart from POP3. SMTP is a push protocol. Now, if somebody has pushed a message for you how will you access that email. So, this Mail Access Protocol is retrieval from the server, it allows mail stored in mail boxes to be accessed by the recipient. (Refer slide time: 45:45 ? 46:36)


POP is the Post Office Protocol where 3 is the version 3 RFC 1939. Users can not create folders on mail server usually. POP is a protocol for doing this mail access. Another one is IMAP which is a Internet Mail Access Protocol. This has more features and you can manipulate messages on the server. There are web mail services also which uses HTTP that means it may be hot mail, yahoo mail etc., these are web mail services which are accessed through HTTP. These are three major protocols which people use for accessing mails. (Refer slide time: 46:37 ? 48:29)

Post Office Protocol version three is simple and limited in functionality. It consists of client software and server software. The server performs password authentication, the server software allows the client software to access the recipients mail box. So what the POP3 client will do is, it will connect to the POP3 server on the main mail server of a work group or department or organization. So, the POP3 server would do a user authentication once again through user and password as this is simply a password check. And when the user is authenticated he is given access to his particular mail box. And what POP3 would usually do is, download all the mails from the mail server to the desktop machine. For example, it is possible to configure it so that only a copy comes to your desktop and another copy remains in the mail server. But such practice leads to overloading of the mail server and very soon its buffer starts getting full, its memory space starts getting used up. To POP3 you are not supposed to do much here and simply get the machine on your desktop. You can organize your local mail folders in anyway you like by creating directories, subdirectories, etc. (Refer slide time: 48:31 ? 53:06)

POP3 has a problem for some users in the sense that, if all the mails are actually downloaded onto your desktop machine then when you are away from your desktop, if it is a desktop and not a laptop, so if all the mails have been downloaded on your desktop then when you are away from office you have no access to the email folders. Now-a-days, the mail has become a common mode of not only exchanging information as well as storing old information etc., so people need access to pass mails almost all the time. One way to do it, instead of downloading it using POP3 onto your desktop you can download it onto your laptop and carry that laptop around wherever you go. The other alternative way is to keep it in the server. If you can keep it in the server what would happen is that, naturally you can get access to the server from other places and you can see your mails. But the same advantage is there for web mail also. If you are using a web mail service your mail is stored in the server whoever is giving you the service. Both web mail and IMAP4 has this facility of storing the mail in your server. What facility you require? They are in the server, mail box, and anywhere. You can have access to it and if you directly access the mail box the interface is not so good so these access protocols gives you somewhat better interface. Specifically, IMAP4 is more complicated than POP3 and has got more features. IMAP4 means Internet Mail Access Protocol version 4. It stores user?s mail in the server so that it can be access from multiple locations. It is able to address mails not just by arrival numbers but by attributes. So you can define attributes on mails and you can say something like give me the last mail from Steve so it is going to do a search on your directory and access that particular mail. But if you have it on your desktop you can organize it anyway you like. here of course you are not taking it to your desktop it is in the server so this protocol has got more features so that you can access your mails in a more flexible manner and that is important because now-a-days it is all the old mails you have, there are many people who have thousands of mails and many of them are useful of course it keeps accumulating junk also somehow we fail to delete. So, anyway some kind of organization and some kind of searching this is necessary in order to operate with mails in an easy manner. So it is able to address mails not just by arrival numbers but by attributes also. It has more features than POP3 as I mentioned. Can check email header prior to downloading which is another feature. What POP3 would do is, download all mails that are in your mail box in a blind fashion. For accessing through IMAP4, before accessing you can do some kind of filtering by checking the email header. It can search contents of email prior to download so contents can also be searched before you download. (Refer slide time: 53:07 ? 53:26) 

It can partially download email, it can create delete or rename mail boxes on the mail server and can create a hierarchy of mailboxes in a folder for email storage. This is like creating a hierarchy of directories for sorting the mail into its proper category. These are the references. (Refer slide time: 53:43 ? 53:56)

For example, RFC:821 for mail transfer protocol, RFC:2821 once again for SMTP, RFC:2045 for MIME and there are other RFC?s associated with mail. RFC?s contain all the information that is necessary for these protocols. With this we come to the end of our discussion about these two important protocols namely FTP and mails that means file download upload and mail exchange. Another protocol we have to talk about is naturally the HTTP or the web which we will take up in the next class, thank you. 
Preview of the next lecture 
Lecture ? 40
HTTP 
We will discuss about HTTP which is the most widely used application layer protocol today. This is of course at the base of your world wide web, this (Refer slide time: 55:02)

HTTP stands for (Refer slide time: 55:04 ? 56:47)

Hypertext Transfer Protocol. It is the network protocol used to deliver virtually all files and other data collectively called resources on the World Wide Web whether they are HTML files, image files, query results or anything else. Usually HTTP takes place through TCP IP sockets which means it uses TCP. World Wide means majority of them are some files which are usually HTML files, there may be images, but also increasing the we have a lot of multimedia content on the web may be audio files, video files which are again termed as files and large number of applications are also being developed based on web because the spread of web has been so fast that many of the service providers are beginning to give their services through the web so that the service becomes available may be 24 hours a day anywhere in the world. So, apart from files there may be outputs of other programs like hyper text transfer protocol which are also passed through this protocol. In hypertext, the word text actually came from the original content which was most probably textually based with hyperlinks. But then, this cache has to be updated regularly. Last-Modified: This means if there is a modification on the other side that means if the lastly modified value has changed then you should get a new copy of that so you should refresh the current page. (Refer slide time: 57:11 ? 57:17)

Now, the request line consists of the request type, URL and version. (Refer slide time: 57:19 ? 57:22)

Request type: Categorize request message into several methods. (Refer slide time: 57:23 ? 57:40)

URL: Uniform Resource Locator which is the web page or document address. It indicates a method, the host, the port number and the path. (Refer slide time: 57:41 ? 58:06)

Let us look at this figure. First is the method used and it could be something like HTTP or even FTP etc, :// then the host. We usually prefer naming the hosts with domain names because it is much easier for us to remember the domain name that is one thing, Secondly, in some cases the domain name remains the same but the underlying IP addresses may have changed. So, if you give the domain name what will happen is that, first it will go through the resolver and get the IP address. 
COMPUTER NETWORKS
Prof. Sujoy Ghosh
Department of Computer Science and Engineering
IIT, Kharagpur
Lecture No. # 40
HTTP
Good day! This is the last lecture and here we will discuss about the most widely used application layer protocol HTTP. This protocol is at the base of your world wide web. (Refer Slide time: 01:04 - 01:07)

HTTP stands for (Refer Slide time: 01:08 - 02:55)

Hypertext Transfer Protocol. It is the network protocol used to deliver virtually all files and other data (collectively called resources) on the world wide web whether they are HTML files, image files, query results or anything else. Usually HTTP takes place through TCP/IP sockets. So the first thing is that the majority of resources available today on world wide web is of course some files which are usually HTML files. There may be images also. But also increasingly we have a lot of multimedia content on the web which may be audio files, video files etc. And a large number of applications are also being developed based on web because the web is vastly spread and many service providers are beginning to give their services through the web so that the service becomes available 24 hours a day anywhere in the world. So, apart from files there may also be an output of other programs which are also passed through this protocol namely the hyper text transfer protocol. So in this hypertext the word text actually came from the original content which was mostly textually based with hyperlinks but now-a-days a lot of it has changed. So, this is the HTTP (Refer Slide time: 02:55 - 03:29 )

hyper text transfer protocol. The HTTP client is our browser therefore this internet explorer, netscape, Mozilla are all HTTP clients. It sends a request to an HTTP server also known as web server which then sends responses back to the client, the standard and default port for HTTP server to listen on is 80 though they can use any port. So, the well known port for HTTP is 80. So the first request which the client is requesting for in any HTTP server or any web server goes to the port number 80. Later on they may negotiate another port number. (Refer Slide time: 03:46 - 04:47)

HTTP is used to transmit resources not just files, that is another point because require we are talking about resources. A resource is some chunk of information that can be identified by a URL. This is R in URL and URL is Universal Resource Locator, it is some kind of an address for these resources which is universally valid. Any resource which has an URL can be accessed through the web and of course it has to be served by the web server. The most common kind of resource is a file. But a resource may also be a dynamically generated query result, the output of a CGI script, a document that is available in several languages or something else. Now-a-days we have dynamic web pages or a web page may change and somehow they are sort of outputs of some programs and they are also resources or rather static files. (Refer slide time: 04:48 - 05:11)

While learning HTTP it may help to think of a resource similar to a file, but more general. As a practical matter, almost all HTTP resources are currently either files or sever side script output that means some script running on the server. What you get to see when you surfing web, sometimes some of the effects may also be the output of programs which have been downloaded along with the page which is running on your machine that means which is running on the client machine through a java, applets etc.. But anyway that program actually is coming from the server. (Refer Slide time: 05:36 - 06:42)

Used to access data on the www plain text, hyper text, and hyper text means text with hyperlinks that means links to other pages embedded in them. Actually these hyperlinks are so called links to other pages, as soon as you click on a link what happens is that a request is automatically sent to a particular page which the URL is pointing. Therefore it may be a text, it may be an image which can be clicked and whatever be the manifestation of this hyper link there is a URL embedded in it and when you click on it a request is automatically generated. When such hyperlinks are embedded in a text it is called a hypertext. Apart from plain text and hyper text we have audio, video or other things. (Refer slide time: 06:43 - 07:32 )

HTTP functions like a combination of FTP and SMTP in some way. FTP as it transfers files and uses the services of TCP. Just like FTP this is also using TCP and has only one TCP connection unlike FTP which uses two connections; one for control and one for data but here only one connection is used. And it is like SMTP. As data transfers between client and server it looks like SMTP messages. So they have format of message controlled by MIME like headers. HTTP messages are delivered immediately unlike mail, unlike SMTP. Like FTP, in HTTP the messages are also delivered immediately. (Refer slide time: 07:32 - 07:49)

HTTP is actually very simple. Client sends a request and server sends a response, similar to mail request and reply, data in the form of a letter with MIME like format. Refer slide time: 07:50 - 08:06)

Like most network protocols HTTP uses the client server model. An HTTP client opens a connection and sends a request message to an HTTP server. The server then returns a response message usually containing the resource that was requested. (Refer slide time: 08:07 - 08:25)

After delivering the response, the server closes the connection making HTTP a stateless protocol. That is not maintaining any connection information between transactions. This is one important point to remember that basic HTTP is a stateless protocol. A request has come, it responds and forgets and closes the connection and it forgets everything about it immediately. Sometimes some web servers would really like to keep some information and there are various things like access logs etc which may be maintain on the server side. Another common way in which some state information is kept are through cookies. So, cookies are a simple text file kind of a thing which is stored at the client?s machine. What the server does is, it writes something about this clients request in a text file in the client machine itself so that next time if the that same client connects again then the HTTP server can leave that file and can find out what is the last visit or some information about it. Cookies too sometimes breaks down the privacy in some sense and somebody else is writing things in my machine so that may be a source of breach of privacy or security so some people would like to block the cookies also. It is also possible to block the cookies. But anyway the point is, basic HTTP protocol is stateless. that means when one a request comes and once it is serviced the machine forgets about it. (Refer slide time: 10:19 - 11:06)

Now, let us look more into the details of the structure of HTTP transactions. The formats of the request and response messages are similar and English oriented. Both kinds of messages consist of an initial line, zero or more header lines, a blank line that is a CRLF Carriage Return and Line feed by itself and an optional message body for example, a file or query data or query output etc so this is the structure. We will see what each of these areas really contains. The blank line is just to delineate between the header and the message body. (Refer slide time: 11:07 - 11:28)

Put another way, the format of an HTTP message is initial line, different for request versus response, then header1: value1, header2: value2 so the header name: value of that header, and that is how the headers go. (Refer Slide time: 11:28 - 11:35)

Then you have the blank line and then the body. So you have initial line, headers, blank line and the body. (Refer slide time: 11:36 - 12:52)

Initial Request Line: This is different for the request than for the response. A request line has three parts separated by spaces: a method name, the local path of the requested resource and the version of HTTP being used. A typical request line is Get /path/to/file/index.html. So this is an example, this is the path name, path name to this index dot HTML file. So, starting from the route it goes down the directory and subdirectory etc to finally locate the resource which is now here in index. HTML so this is really a request line. So GET is a method, we will come to that later on. And finally it mentions the version of HTTP that is being used, HTTP 1.0. This is what is going to go from the client to the server. (Refer slide time: 12:53 - 13:36) 

GET is the most common HTTP method. It says ?give me this resource?. We will go into little bit more into the details of GET and other methods like, POST and HEAD etc later on. So method names are always upper case. The path is the part of the URL after the host name also called the request URI. So a URI is like a URL but more general. And HTTP version always takes the form HTTP/x.x a 1.0 etc. What we are trying to get is some file located in some site that is in some web server. Some how you should be able to contact that particular machine, some how we have to indicate the machine then we have to say what is it we are doing, what kind of protocol we are using. And finally in that machine we have to give a path name to that file. That path name is necessary because there may be files with the same name in different parts of the directory so always the path name is necessary. Therefore all these together constitute the URL. (Refer slide time: 14:27 - 15:42) 

Initial Response line (Status Line): Initial response line, we have seen initial request line now, we see the initial response line. The initial response line called the status line also has three parts separated by spaces; the HTTP version, a response status code that gives the result of the request and an English reason phrase describing the status code. Typical status lines are HTTP/1.0 200 OK that means a request has been received and its response is that it is OK, 200 is the code for it and it is OK. That means whatever has been requested would also be forthcoming or HTTP/1.0 404 Not found. This means, the particular file we were looking for in the request may not be available and therefore it says file not found. Now, what your client or browser would do is that it will read this and then display it may be in a separate window or a separate page that the file has not been found or the source has not been found. (Refer slide time: 15:43 - 16:03) 

The HTTP version is in the same format as in the request line that HTTP/x.x. The status code is meant to be computer readable. The reason phrase is meant to be human readable and may vary. The status code is a three-digit integer and the first digit identifies the general category of response. (Refer Slide time: 16:04 - 17:06) 

1xx indicates an information message only, 2xx indicates success of some kind, 3xx redirects the client to another URL. Sometimes somebody may have moved from his old site to some new site may be to some new URL, so what he would do is that, he would leave a redirection message in the old site, so those clients who have the old URL land up there unknowingly they are automatically redirected to the new URL. So 3xx redirects the client to another URL, 4xx indicates an error on the clients part and 5xx indicates an error on the server?s part. So, whatever resource name it has given it does not exist so that is 404. therefore this is the status line. (Refer slide time: 17:06 - 17:29)

The most common status codes are of course 200 OK and 404 not found. OK means the request is succeeded and the resulting resource is returned in the message body. And 404 means not found, 301 that it has moved permanently, 302 means it has moved temporarily and so on. (Refer Slide time: 17:30 - 18:00)

So 303 means the other the resources moved to another URL given by the location response header and should be automatically retrieved by the client. This is often used by a CGI script to redirect the browser to an existing file. The 500 is the server error. It is an unexpected server error, the most common cause is a server side script that has a bad syntax or fails or otherwise cannot run correctly. (Refer slide time: 18:01 - 18:14)

Now, after the initial line there are the header lines. 
Header Lines: Header lines provide information about the request or response or about the object sent in the message body. (Refer slide time: 18:15 - 18:32)

The header lines are in the usual text header format which is one line per header, of the form ?Header - Name: value?, ending with a CRLF. It is the same format used for email and news postings. (Refer slide time: 18:33 - 18:53) 

As noted above they should end in CRLF. The header name is not case sensitive though the value may be. Any number of spaces or tabs may be between the colon and the value. Header lines beginning with space or tab are actually part of the previous header line folded into multiple lines for easy reading. (Refer slide time: 18:54 - 19:14) 

The following two header lines are actually equivalent. You may say header 1: some-long-value-1a some-long-value-1b or header1: some-long-value-1a, then some-long-value-1b, this is just folded. (Refer slide time: 19:14 - 19:44) 

And for net-politeness when you send in a request the from part should be included. That means header gives the email address of whoever is making the request. You may or may not because this might lead to a lot of unsolicited mails coming to you also or running the program doing so. This must be user configurable for privacy concerns. (Refer slide time: 19:45 - 20:16) 

The User Agent: header identifies the program that is making the request in the form program name/x.xx where x.xx is the mostly alphanumeric version of the program. For example, Netscape 3.0 send the header ?User-agent: Mozilla/3.0 Gold?. So that is the program version. (Refer slide time: 20:16 - 20:37) 

If you are writing servers consider including these headers in your responses. 
The server: the header is analogous to the user agent header; it identifies the server software in the form of program name. For example, one beta version of apache is server returns server apache such and such. (Refer Slide time: 20:38 - 22:05) 

The last modified: the header gives the modification date of the resource that is being returned. it is used in caching and other bandwidth-saving activities. Used GMT in the format last modified such as day, date and time and this last modified is important. The point is that, sometimes there are some web pages which are seen by a lot of people and if they are seen by a lot of people in the same organization one way to conserve bandwidth is through the user proxies. Once the page is brought in, that means it is put in that proxies cache automatically so that the next person who is under that same proxy makes the request and he gets it straight away from the cache without having to go to the distant location. But then this cache has to be updated regularly. If there is a modification on the other side, if the last modified value has changed then you should get a new copy of that, then you should refresh that page. (Refer Slide time: 22:06 - 22:13) 

 Request Line consists of the request type, URL and version. (Refer slide time: 22:14 - 22:17) 

Categorize request message into several methods. (Refer slide time: 22:17 - 22:34) 

URL: This is the uniform resource locator which is the webpage or document address. it indicates the method, the host, the port number and the path. (Refer slide time: 22:35 - 25:24) 

First is the method that is used and this method could be something like HTTP or even FTP etc, :// then the host and for this host we usually like to give the domain name because it is much easier for us to remember the domain name. Secondly, domain name remaining the same, its underlying IP address may have changed. If you give the domain name what will happen is that first it will go through the resolver and get the IP address. The domain name can be given over here. Alternatively an IP address can also be given over here. If IP address is given then straight away the IP address is followed by a : followed by the port so that immediately becomes the socket. The IP address and the port number together form the socket so we give the method and the socket and when you have done up to this much the port for the initial request is port number 80. If you give the host IP address and the port number, you have given the socket which means that we have indicated or we have specified where to go, first to the domain name and subsequently to the IP address of the host. By the way this host must be on a public IP naturally and they cannot have any private IP if they have to be accessed over the internet, so the entire socket. Now we have reached the machine and we also know the method to use and then in that machine we have to locate the resource which is the path, slash means you start at the root then you go right down to the subdirectory where that particular file is present and then you give the name of the file, this is the entire URL. This way all the resources located in any of these machines connected to the internet having a public proper IP address can be uniquely specified. This is basically the addressing scheme for HTTP. (Refer slide time: 25:25 - 25:40) 

Protocol used to retrieve the document, as I said HTTP is the most common, you can also use FTP or Gopher or news or telnet. These could be the different methods used in the method part. (Refer slide time: 25:41 - 25:57) 

Host part is the computer where the information is located given by the domain name or may be the IP address directly. Port number is separated by the colon and as I said the default port is 80 and path is path name of the file on the server. (Refer slide time: 25:58 ? 26:04) 

Version: current version 1.1 and 1.0, 0.9 are still in use. (Refer slide time: 26:05 - 26:20) 

Now let us look into the methods in more detail. HTTP is an important protocol and moreover many applications based on web use these methods directly so that you can give some program output or can interact with your client through the web. Originally HTTP was not envisioned or envisaged just for locating some resource download it and see text and later on may be hypertext and some multimedia content. But increasingly the web had become so popular and so many people are hooked onto the web that people started giving services through the web. Naturally all these services go through java script and a browser client etc so actually it is somehow communicating in HTTP at some level. (Refer slide time: 27:28-27:49)

Methods: The actual command or request that a client issues to the server. One is GET: client wants to retrieve the document, server responds with the contents of the document. HEAD: client wants information about the document but not the actual document so just the header part of it is what is needed. (Refer slide time: 27:50 - 28:07)

POST: client provides some information to the server. PUT: client provides a new or replacement document to be stored on the server. PATCH: it is similar to PUT but only a list of differences to be made rather than the actual new document. (Refer slide time: 28:08 - 28:20)

COPY: copy a file to another location. MOVE: moves a file to another location. DELETE: remove a document on the server. (Refer slide time: 28:21- 28:37)

LINK: creates a link from a document to another location. UNLINK: delete links created with LINK. OPTION: used by client to ask server about available options. These are all the different methods. (Refer slide time: 28:38 - 29:20) 

The Message Body: An HTTP message may have a body of data sent after the header lines. In a response this is where the requested resource is returned to the client, the most common use of the message body. That means you have asked for a web page and that page is here, that content of that page is here or perhaps explanatory text if there is an error. In a request this is where user entered data or uploaded files are sent to the server. So this is the message body, the main content which is coming in the message. (Refer slide time: 29:20 - 30:25)

If an HTTP message includes a body there are usually header lines in the message that describes the body. In particular the content type, header gives the MIME type of the data in the body such as text/or HTML or image/gif. Suppose some image is being sent on request then on other side the client would know that what kind of resource it is, it is being told that this is an image and a gif type of image, so that on the client side that particular application or program to display gif files would be activated. The content length: header gives the number of bytes in the body. (Refer slide time: 30:26 ? 31:07)

To retrieve the file at the URL we write something like http: //www.somehost.com this is the domain name path /. And of course since over here we will see that in this request the port number has been left out so by default it is port number 80/path/file.html. First open a socket to the host www.somehost.com at port 80 and then get that file. (Refer slide time: 31:08 ? 31:52)

Then, send something like the following through the socket: GET/path/file.html HTTP/1.0, this is a request. You see the sequence; first you open a socket to the host which is the web server which is in this case some host. com at port 80, then you put another request the get request with the file name and the HTTP version. From some user from somewhere and user agent you mention and then you put the blank line, this is the header part. (Refer slide time: 31:53 ? 32:16)

The server should respond with something like the following: sent back through the same socket: HTTP / 1.0 200 OK that means the request is granted and then request is OK. Then the date that means when it was last modified, content type is text/HTML and content length is something. (Refer slide time: 32:17 ? 34:41)

And HTTP in the body the body will contain may be in this particular case a text document which is in HTML. HTML stands for hypertext mark up language. Once again we will not have time to go into HTML what you can do is that you can open any web page and look at the source you will find that in your browser if you look at the top menu then there is a way of rather than looking at the final made up version you can look at the original source and there you can see the HTML file. 

The HTML file has a number of tags and these tags help in specifying the format in which the text is to be displayed. Essentially there are other things but the major part of it is the format. There may be format, there may be tags like header sort of shown in bold, there may be tags to show the back ground color, the foreground color, the font colors, shape, size etc. All kinds of formatting information are there in HTML documents. Apart from that it is also possible to embed links. This is one example of what an HTML document might look like. First of all it is the tag HTML, whenever you have the tag you must have the beginning of the tag you must have the corresponding ending of the tag so HTML here and HTML here. Similarly body, then it says something happy new millennium or something which is the header, it says h1 which is a header then there may be more file contents and etc. After sending the response the server closes the socket. This is a stateless protocol and the server forgets about it. This is an example of what a simple text HTML document looks like. (Refer slide time: 34:42 - 35:41)

Now let us look a bit more deeply into the methods. The Head Method: A HEAD request is just like a GET request except it asks the server to return the response headers only and not the actual resource, that is no message body. So this will work very fast. If you just want to know the header and then take some decision whether or not you want to look at it then you can ask just for the header and not the rest of it so it will come down very fast. This is useful to check characteristics of a resource without actually downloading it thus saving bandwidth and also a lot of time. Use head when you do not actually need files content. The response to a head request must never contain a message body, just the status line and header. That is the head method, just get the header. (Refer slide time: 35:42- 36:23)

The POST Method: A POST request is used to send data to the server to be processed in some way like by a CGI script. A POST request is different from a GET request in the following ways: there is a block of data sent with the request in the message body, there are usually extra headers to describe this message body like content type, content length etc., The request URI is not resource to retrieve, it is usually a program to handle the data you are sending. The HTTP response is normally program output, not a static file. This is quite important, for example, now-a-days for your electric utility or for your telephone, suppose the bill has not reached what you can do is that you can see your bill on the net. So what happens is, suppose you are a BSNL subscriber, the first thing you would like to do is to go to the BSNL?s home page. If you know the address then it is very fine or otherwise you can use any searching in like Google or something to get the address of BSNL and then click on that address which is usually a link to the web page. A link to the web page meaning that usually any website would contain an initial or main page or index page as it is called and if you simply make an HTTP request to the correct server the main page or the first page or the index page would be displayed first. Actuall, that is an important point because while surfing we are accessing so many pages in so many machines. In the URL as we have seen, in that last part the located part you have to give the entire path name as well as the file name. Unless you are very well aware and very conversant with one particular sight or may be a few sites other than that you will not know either the path name or the file name, so how do you locate it and that is not how people serve. What they do is that may be they know that in this particular example we were giving so we are trying to find our own telephone bill which is missing so I want to see my bill. So I will connect to BSNL and I will somehow find the main address of BSNL which may be BSNL.co.in or something and that is where I will go. Now, I have just mentioned the domain name and nothing else which actually means a server, which actually means this domain name would stand for some web server. The domain name of course can be translated via the DNS system into the proper IP address. And since it is an HTTP protocol that is under default port is 80 so up to that much that means up to the socket part it is fixed. Now what about the rest? The rest is taken for granted that if you have not specified something you will definitely be given only that first page or index page or main page of that site. That comes as a response in the message body in the form of an HTML document and that gets displayed in that nice format usually by the browser on your stream. Now of course, that is a main page it may contain several things amongst all that I find out that if I am looking for a duplicate bill or something where do I go? Therefore something would be written over there like duplicate bill where if you take your cursor on that you will see that the cursor has changed showing that the color has changed or something has got underlined someway to indicate that this is actually a link when you click on that link. Now what does that contain? It says duplicate bill and that is how it is communicating to the user but underline this text, there is a hyperlink and this hyperlink contains the path name and the file name which will take you to the page where you can get information about duplicate bills. Let us say, I click it, as soon as I click it, actually I generate a fresh request where the server socket etc is already known. And now this new path name is added on to it so this is a new request. HTTP of course being a stateless protocol has shown you the first page and has forgotten that you actually exist. But then now you have made another request which now brings a second page into zero. Now in that page may be you will find that there is a form over there. Who would process the form on the other side, may be some CGI script or some other program you are not going into that part in the server, but before that whatever information you have may be your name, may be your telephone number, something you have to enter, there will be a form you enter that and then you submit. Actually submit sounds very nice and user-friendly but then your machine which was the client so long now has to upload some information, the information which you have just typed in it has to upload that information on to the server. This uploading of information (Refer slide time: 42:02- 42:11)

 may be done via this post, this is the opposite of that. (Refer slide time: 42:12 - 44:16)

The most common use of post by far is to submit HTML form data to CGI script. CGI stands for Common Gateway Interface so when you send something, this goes in some format and the CGI is a language where it is easy to pass whatever you have sent and then get the appropriate values. Therefore what CGI script will do is that, with all these information, it will form some kind of query may be a data base query to some database, in our example we were talking about telephone bills, so in that BSNL server where all the bills or may be at least the current bills are stored. So it will go with the current request information, form a query, get that kept your bill and then your bill was of course in a data base. So now that information has come, that has to be put together in the form of a dynamically generated web page and sent back. This is a very common way of using post. In this case, the content type: header is usually application/x-www-form-URL encoded. And content length header gives the length of the URL encoded form data, the CGI script receives the message body through STDIN and decodes it. CGI is specially designed so that such data which is coming in can be easily passed and all the values retrieved. This is how post method is used. So this is how applications over the internet are generally implemented. (Refer slide time: 44:17 ? 44:23)

    Here is a typical form submission using post, let say POST /path/script.cgi HTTP/1.0. So, basically we are actually invoking some CGI script and we have given that address of the URL of the script and we have mentioned the method and the HTTP version. From: is of course somewhere. User Agent: HTTP tool/1.0, Content-Type may be application/x www form URLencoded, Content Length: 32, Home: = something. So, this is a typical form submission, so, on the other side this will be taken and processed. And finally a dynamic web page would be generated and shown. (Refer slide time: 45:24 ? 46:57)

HTTP proxies: Are important for various reasons. One reason we have already discussed is that, suppose you are in an organization where a large number of people access the web outside, now-a-days almost everybody wants to access the web and sometimes the same page. Of course the WAN bandwidth is always costly and WAN bandwidth is always much lower than the internal band width. If some page is already been brought in and that page is fresh enough then you can cache it in the proxy, this is one major use of HTTP proxy, there are also other uses of HTTP proxy. An HTTP proxy is a program that acts as an intermediary between a client and a server. Instead of a client directly calling the server or directly sending a request to the server it may only send it to the HTTP proxy. It receives request from clients and forwards those requests to the intended servers. The responses passes back through it in the same way. Thus a proxy has functions of both a client and the server. It comes in between the client and the server. (Refer slide time: 46:58 - 51:24) 

When a client uses a proxy it typically sends all requests to the proxy instead of to the servers in the URLs. Requests to a proxy differ from normal requests in one way. In the first line they use the complete URL of the resource being requested instead of just the path, this is of course important. Actually if you are sending a request to the original server then the server has got the request that means you have reached up to that server. Now, you need to simply give the path from the root to the actual file name. Now, instead of sending the request directly to the web server, the client, it sends its request to the local proximation. Therefore in the proximation it has to supply not only the path but also the domain name or IP address of the server that it is sending its request to. Apart from caching and bandwidth conservation there is another use sometimes that a proxy is a put to. You may do it in proxy, you may do it in some other places also like fire walls etc.. In many organizations now-a-days what is happening is that the network is becoming so big but the IP address space is small. You cannot give a proper public IP address to all the machines in the network, may be the organization does not have such a big network For example, class B addresses have become very few or almost non existent these days. Therefore many organizations will not have a class B address. If that is so you cannot give proper IP address. Now, if you cannot give the proper IP address to the client, may be you can still send the request to the server but how will the servers respond back? For responding back the server has to communicate with you, it has to open the TCP connection. For that on the other end there must be a machine with the valid IP address. One way to solve this problem is to do network address translation and although network address translation may be done at the fire wall, may be done at the router, it may be also be done at the proxy. that means what we do is that, if it is a big organization may be 5000 machines or something and has got just one class C address may be 1250 addresses. What it might do is that, it might allot some number say 50 valid IP addresses to the proxy so that whenever there is a request which is being sent by the client. Now the client need not be given a public IP. If the client may be given a private IP which is just private to that network that does not work outside the boundary of the organization, from that it sends a request to the proxy, the proxy takes up this request and proxies that means it sends the request out to the world through the intended web server giving one of the valid IP addresses and when it gets the response, it changes the IP back again to the actual private IP of the machine and gives it back. That is another way, proxy may be used. Proxy may also be used to keep track of what kind of data or what kind of sites people in the organization are generally looking at, they may feel that this site may be good, this may be bad but anyway the point is that this may be done if you are routing all your HTTP requests through the proxies. Naturally it has to give the entire URL when it is sends a request through a proxy. (Refer slide time: 51:25 - 51:55)

For example, GET HTTP then you give the domain name, then the path, then you give the path name, then the HTTP and its version number. That way the proxy knows which server to forward the request to though the proxy itself may use another proxy. There may be hierarchy of proxies etc, you are not bothered about that. (Refer slide time: 51:56 ? 52:15)

As the saying goes in network programming anyway be strict in what you send and tolerant in what you receive. Other clients and servers you interact with may have minor flaws in their message but you should try to work gracefully with them. (Refer slide time: 52:16 -52:51 )

HTTP specification suggests the following: Even though header lines should end with CRLF that is a carriage return and line feed someone might use a single line feed instead, accept either CRLF or LF. The three fields in the initial message line should be separated by a single space but might instead use several spaces or tabs, accept any number of spaces or tabs between these fields etc. Usually on the other side is tolerant of these. With this we come to the end of this lecture. Actually, HTTP and this entire gamut of web services have been developed in such a manner that these demands codes by itself. Actually this whole field of networking has grown at a tremendous rate. people usually talk about Moore?s law for computing power and memory capacity etc. But if you look at the network traffic and the speed at which network has been growing, you will find that this is actually much steeper than the Moore?s law. Moore?s law by itself is exponential so being steeper than Moore?s law means that you have a higher base, steeper rate or growth which is a very phenomenal rate of growth. And this phenomenon rate of growth has to respond to a large number of technologies, a large number of protocols etc., and it is expanding all the time. Actually we have tried to encompass the basic technologies, first of all the lower layers and just we have touched upon core ideas in all the seven layers. We talked about web today and you can have an entire course on the way web services are given and all web applications can be developed etc. We have given only one lecture on a network security, you can have an entire course and networks security. It has become so important these days because transactions are being done over the network. What we expect is that as time goes on, this ubiquitous-ness of network is only going to grow and now-a-days we are not always care full to may be carry a pen because may be wherever we go we will find a pen. Similarly the expectation now would be that wherever you go may be you can find the network outlet where you may be having a laptop or palm top or whatever and through the DICP get yourself configured and be on the network. And of course people are thinking of advertising intelligent machines like your microwave oven or your heater or other things also on the network. So this is going to be a universally networked world. So with this we come to the conclusion of this lecture. Thank you. 
 

