COMPUTER NETWORKS
PROF .SUJOY GHOSH
INDIAN INSTITUTE OF TECHNOLOGY
I.I.T. KHARAGPUR
Lecture No. # 3
 Physical Medium - I
Good day. In this third lecture we will be looking at Physical Medium. In the last lecture we have seen two protocol stacks, we have seen OSI protocol stack in detail and we had a look at its CPI pre reference stack. But whatever be the model, at the bottom-most layer you have the physical medium because, after all, if two computers have to communicate, there has to be some physical medium between them. So we will just look at some general characteristics of physical medium and how data can travel along them, today. In the next lecture we are going to look at some specific media which are used in networks. (Refer slide time: 01:36 - 2:26) 


As we talk about the Physical Medium, we have to talk about two different modes of communication, so to say. One is Analog and the other is Digital, so you have before you that top one is the analog signal; you can see that it can take any shape, and the digital signal is some kind of signal, which represents a series of ones and zeros ? stream of bits, but analog signals of course can take any value in them. (Refer slide time: 2:27 - 3:20)


And one important consideration for any medium is its bandwidth. Bandwidth is the capacity of a media to carry information. Now, the total capacity may be divided into channels ? I mean there is one total capacity you can sort of divide it into channels ? and  give different channels to different users; specific portion of the channel may not be used for direct communication but for control purpose and other specific purpose. But whatever it is, any particular medium and technology will have a certain capacity and this is really important because, after all, your speed of communication will depend on the capacity of the medium. (Refer slide time: 3:21 - 5:19 ) 


This inherent capacity of the medium is of course intermittently linked with the kind of signal one particular channel can carry. For example, on the left-hand side, you see some digital signal and just on its right you have something that looks like a bargraph ? actually this is a representation of the same signal in a different way, what this right-hand side says is basically if you have a series of
a Sin x + b sin 2x + c sin 3x + d sin 4x and so on 
 where a, b, c, d represent the values shown by the graph on the right-hand side, if you sum all that sin values up, you will get the signal on the left-hand side. So the channel, if it has to carry the digital signal, has to be able to carry all these harmonics ? harmonics means the sin x constant, sin 2x constant, sin 3 etc. So all these harmonics it should be able to carry; whereas if you look at the second figure b, it is a pure sin wave. So this just has one harmonic, a sin x or something like that. This third figure has two harmonics, say a sin x + b sin 2 x; so depending on the complexity of the wave form that you want to carry, you want more and more bandwidth for the channel. (Refer slide time: 5:20 - 6:24)


Now for this we make a comparison of analog verses digital signals. Digital signals have some basic advantages the most basic advantages is that it is that less error prone that means if there is some kind of distortion in the signal between the source and destination that can be rectified very easily and to limited extent errors can be corrected. Whereas if you are talking about analog signal there is little control over signal distortion of course this also old technology and this has got some limitations in technology in the sense that how many people can use, etc. There are some limitations over here. So digital signals are of course in general preferred, although analog signal still rules in some niche areas (Refer slide time: 6:25 - 07:30)



So let us see what we mean by the statement that digital signals are less error-prone. In this figure we see in the left-hand side have some analog signal and then some noise has  come; that means, some distortion has come and the signal looks like the one below.   When noise affects an analog signal, it is hard to deduce the original signal from this whereas the same kind of noise or a similar kind of noise if it is gets superimposed on the  digital signal as we see on the right, the signal gets distorted, but since we know that the original signal was sort of square shaped, we can deduce the original signal from the distorted signal. So, despite the noise, noise can be eliminated easily in digital communication. That is the greatest advantage of the digital communication. (Refer slide time: 07:31 -8:51 )


And so far as the bandwidth of a channel is concerned, suppose we know the bandwidth (H) of the channel and the number of signal levels (V) being used, what is the maximum number of bits that we could transmit? Suppose we are trying to transmit bits in terms of digital signal; so there is a Nyquist limit. It says that 
maximum bits per second = 2 * H * log2 V
for example if the bandwidth is 3100 Hz and we are using 16 level modulation then the maximum number of bits per second is log2 (16) is four so 4 ? 2 ? 3100, that is 24800 bps 24.8 kbps. So this is the maximum number of bits that we can send through the channel of this particular bandwidth. So the higher the bandwidth of the channel, the higher the number of bits that we can send through it, but depending on the bandwidth, there is always a hard limit on how fast we can communicate. (Refer slide time: 8:52-10:42)


Let us look at this regeneration of the digital signals once more. We say that it is reliable because it can regenerate slightly damaged signals. Since there are only two states, for example, this is the original signal, which is a square, and it is grossly distorted as it is received. This becomes weaker in strength and the shape has also been deformed but we can regenerate it since we know that the original shape of the signal must have been a square one. So we regenerate it as a square one. If there are two states of a voltage, let us say, + 10 volts ? 10 volts and the signal is + 8 volts, let us say, then it is quite possible that this that this + 8 volts is a result of noise, which is superimposed on + 10 volts rather than a result of noise superimposed on ?10 volts. So whenever you get +8 volts, simply make it 10 volts with some electronics and the original signal will be restored. Of course I mean if the noise is very high, there is a limit to how much you can restore. If the noise is very high then it will not be possible then we will know because ? 10 volts also becomes 8 volts in the case of a spike, and then whatever restoration we do will be a wrong one. So we lose some information; there will be some distortion and some loss of information will be there. So there is always a limit but in the case of digital signals it is more fault-tolerant or resistant to noise, more resilient compared to analog signals. (Refer slide time: 10:42 - 12:34)

So we can correct errors in transmission ? that is another advantage of digital signals. So what we do is that we add a few bytes of error-checking information and can ask for retransmission if an error is detected. I will give you a simple example: suppose we are sending groups of 8 bits called bytes; now what we can do is that associated with each byte, we can add an extra byte and this extra byte would make let us say the number of 1s in the whole 9 bits to be odd, this is an example of an odd parity. Now, if at the receiver?s end, we find that the number of 1s have become even, we know that some bit must have flipped. That means, some bit must have flipped; instead of a 0, we got 1 and instead of a 1, we got a 0. It must have happened. Otherwise, because the number of bits was supposed to be odd ? and of course by adding 1, we can always dictate the number of bits in the original that the sending station was odd ? in that case the receiver may request the sender to retransmit that whole bunch once again; hopefully there will not be an error next time. This is of course a very primitive kind of error-checking; there are more sophisticated error-checking methods employed in networks and communication. So this  error-checking and correction of error at the receiver?s end is possible if you have adopted a very sophisticated coding technique. So that is possible in case of digital transmission; this is not possible in analog transmission.  (Refer slide time:  12:36-14:04) 
      
Another advantage is that a digital signal can be encrypted, which makes it possible to carry sensitive information on the network. For example, e-banking is coming in vogue ? that means, somebody does a bank transaction on the network. Similarly e-commerce ? that means you want to buy something online and then pay through your credit card, etc. online. Now how does the transaction take place? The point is that you are sending some information, may be your credit card number, may be some password, etc. Somebody can snoop on you in-between, so they will know your secrets and use the same set of numbers  to may be buy something else, and the money will go from your bank account; that is obviously not acceptable. In this case when we send it down the network, we encrypt it in a way that even if somebody snoops and finds out the stream of bits that is going, he will not be able to make out the original numbers from this current stream. So this is encryption and this is a very important application these days. (Refer slide time: 14:05 - 15:54)  
      
So encryption is another advantage of digital transmission. Compression is another; that means, we can compress a message before transmission and decompress it at the other end. So the overall load on the circuit and the network is lighter; since the load is lighter it is less expensive. Sometimes when you compress information there may be some loss of information; there are lossy compression techniques and they are non-lossy compression techniques. Lossy compression technique is where you may lose some information, but it may not matter. For example, let us say you want to send a digital photograph. A digital photograph may have a very high resolution; if you compress it and decompress on the other end, you may lose a few bits but the image that you get on the other end would still look almost as good as the original one. Of course, trained persons can look at it and find out there is something missing but it will almost serve the purpose.  Sometimes loss compression is acceptable and of course there is loss-less compression also. When you compress it and send it, it is a less expensive way of sending. I mean you are sending the same information but only your are taking less amount of space; of course you have to do the compression and decompression at the two ends, so that is some kind of overhead on the two sides. (Refer slide time: 15:55 - 17:07)

Suppose we have some data; how do we encode this digitally? Well, the simplest way, of course, is by the presence or absence of a signal. Let us say a positive voltage might represent a binary zero or a binary one or vice versa. Maybe if you have high voltage, you say that is I will interpret that is as one being sent and if I have a low voltage I interpret this as a zero being sent. Of course, when I am saying voltage, I am assuming that we are having some kind of electrical signal traveling; that is not always the case. For example, if you are using light for communication the presence of light may indicate one and the absence of light may indicate zero. So whatever we code it, whatever be the medium, this is the simplest wave to encode data into a digital form. The current state indicates the value of the data. (Refer slide time: 17:08 - 18:31)

If your signal is digital, sometimes you are forced to send some digital signal by analog transmission, but this is usually not preferred. Analog signal will transmit whatever signal comes regardless of whether it represents digital or analog data. So it uses amplifiers. Other than the kind of regeneration that is possible in digital voice, the trouble with amplifiers is that it also boosts noise, whereas in the digital case we could take out the noise and regenerate the original shape of the signal. Here we can amplify it, so that if a signal becomes weak we can make it stronger; but whatever noise is coming with the signal that also gets amplified. This is okay for voice, but for digital data using analog transmission usually is not done because we have so little control over the correctness of whatever we are sending. (Refer slide time: 18:32-19:58)


Digital transmission is concerned with the content of the signal; it uses repeaters which recover the pattern of zeros and ones and then retransmits. This can be used with analog signal if it carries digital data. You know sometimes analog signal carries digital data; it recovers the digital data from the analog signal, generates new clean analog signal. This is becoming more standard; for example, when you are connecting to the network, to the internet, from your home computer you may have use the modem and the telephone connection. Now what is happening over here is that the telephone line is essentially an analog medium; so an analog signal will go over there on that, but whatever is coming out of your computer is digital. So what you do is that you make this digital data ride on some analog signals to this modem pairs so that it reaches the telephone exchange. At the telephone exchange it is converted back to digital data and the backbone and the core of the telephony system is purely digital. (Refer slide time: 19:59 - 22:26)

So there are various ways in which you can encode digital information in the analog domain. One is the amplitude shift keying, which means the two binary numbers 0 and 1 are represented by two different amplitudes of carrier waves. This is not very efficient; uses up to 1.2 kbps on voice grade lines; and is used to transmit digital data over optical fiber. In the amplitude shift keying, although the signal is analog we know that there are only two levels, which this signal is supposed to take, i.e., two amplitudes: low amplitude and high amplitude. It may be 0 and some amplitude. If a 1 is to be transmitted may be we give this high amplitude and if a 0 is to be transmitted, we may use a low amplitude analog signal. You may say this is the kind of thing which is done in the optical domain; but in the electrical domain this is not very efficient. More common is the so-called frequency shift keying. In frequency shift keying, we use the two binaries; that means we use two different frequencies for the two binary digits, 0 and 1. So this is less susceptible to error than amplitude shift keying, and again, it sends up to 1.2 kbps on voice grade lines and is commonly used for high-frequency radio. Another way of encoding is the so-called phase shift keying. Two binary numbers may be represented by phase shift of carrier wave; so this is more efficient and noise resistant than FSK; this is PSK. It can be raised up to 9.6 kbps (kilo bits per second) on a voice grade line. This is for a simple phase shift keying; of course, we use more complex phase shift keying with other techniques in order to achieve even higher data rates nowadays. (Refer slide time: 22:27 - 24:01)

These techniques can be combined. So it is common to combine phase shift and amplitude shift keying so we can get about 56 kbps on a voice grade line. The modems that we buy usually are all 56 kbps, connected with some technique called multilevel signaling. Each signal represents more then one bit. So this is also possible. One is the signal, which indicates the level of the voltage or whatever it is, the phase or frequency, the level of the signal; the other is the bit or bits that it may represent. So, for example, if you have a simple technique, it will represent a 0 or a 1 by the current level of the signal, which is the simplest kind of technique, these two are the same. One is the bit rate, that is, the number of bits of information that you are sending; the other is the baud rate, that is, the number of times the signal will change per second ? the maximum number of times the signal will change per second. So in the simplest case, baud rate and bit rate may be the same but that is not always the case. (Refer slide time: 24:02 - 29:29)

So we look at the other side of the coin, which is the digital encoding of analog information. And a very common case is the telephones. For example, as I just now told you, the heart of the telephone exchanges and the telephone switches and the trunk exchanges and the core network of the telephone system are nowadays entirely digital. Whereas our voice, of course, is analog. By the way, the real world, in which we move around, is mostly analog. Now this digital is something that we adopt in-between in order to get these advantages of robustness, resiliency, error correction, etc. Our voice is analog, but the core telephone system is digital. So at some point, our voice, an analog signal, has to be converted into a digital signal. Of course, our handsets also are mostly analog. So they are going to be carried may be in this analog fashion right up to the nearest exchange; but there, there will be a set of codecs, coders and decoders, which will convert this analog voice signal to a digital signal. Now, what kind of digital signal will a voice give? The calculation is something like this: the voice data in a telephone system is limited to a maximum of 4 KHz. This telephone is a very good quality, the first so-called gold quality but this is not high fidelity kind of sound. It is less than high fidelity, but very very clear, for all practical purposes for the telephone at least. If I limit the bandwidth to 4 KHz, we get some distortion, but nothing very noticeable. So voice is still very clear. We have to send this 4 KHz of analog signal, whatever information is there, within 4 KHz bandwidth. We have to send this analog signal to the other side in a digital form; that is, we have to digitize it. There is a Nyquist rate, which is like the Nyquist limit that we have seen some time back. Nyquist rate, which says that if we sample any analog signal at double the maximum frequency that the particular analog signal has, then essentially we will have all the information that is needed to fully reconstruct the original analog signal from this sample. So if you have 4 KHz of signal, 4 KHz of bandwidth, we require 8000 samples per second. Let us say you have this analog voice; so per second we will take 8000 samples, sample values at different points. So, of course, at some points my voice may be low so I may have a small amplitude; at some point my voice may be very high so I can have a large amplitude. Now that we break up each of these into a code of 8 bits, the point is that with the 8 bits, you can really distinguish between 256 levels. And our assumption is that from the 0 level to the highest level that is admissible, we take it; whatever it is, if you break it up in to 256 parts, that is good enough for capturing how high or low the volume is. So a level of 256 is really quite a lot. We require 8 bits for each of the sample and we require 8000 samples. That makes it 8 ? 8, that is, 64 kilo bits per second, 64 Kbps. Please remember this rate ? 64 kilo bits per second ? it is the fundamental unit on which a whole lot of all other technology, etc. has been built. And basically, it has come especially from telephony, because the telephone people had the first network and 64 kbps happened to be the rate which was set for a voice. So naturally, of course, if you want to carry 1 voice channel, we will have a 64 kbps. If you want to carry 1000 voice channels, you will require 64 kbps ? 1000, that is, 64 mbps capacity. So they planned their network depending on how many voice channels they want to carry where; but 64 kbps is the basic unit in most places in telecommunications. (Refer slide time: 29:31 - 32:53)

Now let us take a quick look at how data is encoded. The simplest one is of course using the level of the voltage; for example, over here this is the non return to zero level, the so-called NRZ encoding. It uses two different voltage levels to represent 0s and 1s; typically negative voltage equals 1 and positive voltage equals 0 and the signal never returns to 0 voltage. So it flip flops between a negative voltage and a positive voltage. The value during bit time is a level voltage; that means, during the duration of a bit 0 or 1 the voltage really remains the same. So there is a transition at the boundaries of bit and of course, if there are two 1s then there will be no transition as we can see; if there are two 0s consecutively, then there will be no transition. So the number of transition is much less and it is a very simple kind of scheme. This has some problem. We will come to that later on; but let us look at another variant of this non return to zero, which is NRZI. That means non return to zero and invert on 1s. That means once again we keep constant voltage during bit time ? no transition represents 0 and transition from low to high or from high to low is a 1. So the same bit pattern, 0 0 1 1 0 1 is represented by a different voltage pattern over here. There is no transition 0 0 and then there is a 1, so there is a transition; there is another 1, there is a transition; 0 no transition; then again the 1, then another transition. So this is another way of encoding. Now the trouble with these encodings is that suppose you have a large number of 0s, a large train of 0s, there is no transition really. By the way, there is one point ? the reason they use the positive voltage and negative voltage rather than a positive voltage and zero voltage or zero voltage and negative voltage is that you want to distinguish between a 0 being sent and no signal being sent. So that is one point and the other point is that as I was saying if there is a constant train of 0s in the original data then we will have a constant level signal in the system. Now if that be so, the synchronization of the clocks between the sender and the receiver tends to drift off and then the receiver, I mean in the worst case, the signal may go one off or it may interpret the signal in a very wrong fashion. So this is the problem of this NRZ and NRZI, which is taken care of (Refer slide time: 32:54 - 33:46)


by some other kind of encoding; we will come to that later on. So this is a just a quick look at the disadvantages of NRZ code ? hard to tell where one bit ends or starts; with long string of 0s or 1s, any drift between timing of transmitter and receiver results in errors. So there is a bit phase encoding, which uses the least transition per bit time. So if you use at least one transition per bit time, what would happen is that the sender and the receiver clocks can remain in very close synchronization with each other ? that is a nice property ? and there is predictable bit transition during each bit time. So an absence of a transition indicates an error. So two examples are Manchester and differential Manchesters (Refer slide time: 33:47-34:29)

So this is Manchester encoding. You see that at the middle of each bit 0 or 1, 
there is a transition. Now, low to high transition means 1 and high to low transition means 0. So the same pattern ? 0 0 1 1 0 1 ? is there for each bit; you will see there is a transition in-between, and low to high transition is 1 and high to low transition is a 0. So this is the encoding, which is used in Ethernets and many LANS (Refer slide time: 30- 35:42)

There is another variant of this called differential Manchester; in this, the midbit transmission is really for clock synchronization purposes. They do not represent either 0 or 1. So what it does is that transition at the beginning of a bit period is equal to 0 and the absence of a transition is bit period 1. So 0 0 ? when this 0 starts, there is a transition. Transition at the beginning of the bit period is a 0; but when the 1 starts, there is no transition. There is a transition in the middle anyway; that is for clocking purpose. Then at the next level, once again if there is no transition if there is a second one coming, there is no transition and so on. This was used in token ring networks; of course token ring networks are becoming less popular these days but anyway, this is another one. There are other kinds of encoding techniques, but these are the common ones. So you see that there are different ways of encoding the digital data into these different signal levels. (Refer slide time: 35:43 - 38:29)

Signal levels and bit rates are different. The rate at which the signals change is the baud rate, and the rate at which bits are sent is the bit rate. The other thing we can consider is the analog encoding of analog information. Of course, this does not come too much in computer networks, but this is an important area in communications in general. So of course, if you have an analog signal, it can directly be sent. Sometimes it is sent in the raw form; sometimes that is not very practical, so we have to convert this to an analog signal maybe at higher frequency, and the most common example of this is the radio. For example, a radio is carrying voice or may be some sound, etc. The voice, as you know, is only 4 KHz, but if you take a 4 KHz signal and try to send it over the atmosphere, it will not reach any where, excepting in its close vicinity. So, in order to reach out to all these different locations, you have to send your radio signal at a very high frequency; but the information that is it carrying is still at that 4 KHz bandwidth. So this 4 KHz bandwidth is sort of translated; so there is a very high-frequency so-called carrier wave, which is carrying this 4 KHz of signal if it is only voice. Of course if it is music, etc., you may like to have a somewhat higher bandwidth also; but anyway, that is also analog signal and this is also analog signal. So one analog signal is carrying the other analog signal and there are various ways of doing this so-called modulation. The three most common ones are amplitude modulation, frequency modulation, and phase modulation. So we will not talk much about this because in amplitude modulation as you can understand, the amplitude of the carrier wave is changed according to the signal; similarly, in frequency modulation the frequency of the carrier wave is changed according to the signal; and then in PM the phase is changed according to the signal. (Refer slide time: 38:30 -39:58)

So this is another picture of digital signaling so called current state; that means zero represents the low voltage one is represented by the high voltage and digital signaling and state transition; so if there is no transition that is zero if there is a transition that is the one so these are all different examples of encoding. (Refer slide time: 38:59 - 39:35)	










As I was telling, the bit rate and the baud rate are different. The maximum number of times a signal can change in a second is called the baud rate and the number of bits, 1s and 0s transmitted in a second is called the bit rate. In the examples we have seen so far, the bit rate and baud rate are the same; this is not always the case. The bit rate can be higher than the baud rate if we use more then two signal levels; and the other one is also possible: the bit rate may be lower than the baud rate. (Refer slide time: 39:36 - 41:15)

Now let us look at some of the inherent trouble with all these physical media. That means, when we are throwing some signal, when we are trying to send some signal down some transmission medium ? it may be a piece of wire it may be this whole atmosphere or it may be a fiber optic cable ? there will be some kind of distortion, some kind of change in the original signal, that will inevitably come into play. So we will look at some of these; we have to really take care of all these. These signals and these kinds of effects cannot be eliminated. I mean the world is not perfect and they are basic properties of the medium so we will have to design our systems in such a way that in spite of all these efforts the whole communication will still go on very correctly. As a signal propagates, the signal changes as it travels; so the receiver may not be able to recognize it as such. For example, this shows an example of an original signal and the final signal. This kind of change and distortion etc. may be attributed to the following effects: (Refer slide time: 41:16 - 42:51)

the first one, the very first one, is attenuation. A signal get weaker as it propagates; attenuation becomes greater with distance naturally, and of course, finally, the signal will become too weak to recognize. So the original signal strength is something but as the distance grows signals become weaker and weaker. For example, let us say this kind of weakening is dependent on the property of the medium; it also depends on the kind of frequency you are using for sending. For example, let us say an AM signal will not be received at a very large distance, whereas a short wave signal may travel some other way and come over here. Similarly, if you take a local area network or a cable, then if you make the cable very long ? there are other technical problems for making cable very long ? but even from the signal propagation point of view, the signal will get weaker and weaker. Because there will be leakage currents in the cable, current will leak out, etc. Finally, the signal that we will get will be very weak. So this is a very fundamental property of any medium. Similarly, if you take an optical medium and if you send a light pulse through it, as it travels, the light pulse will get weaker ? that is one of the effects. There are other effects, but this is one of the major effects. (Refer slide time: 42:51 - 44:27)

Apart from attenuation, there is distortion. That means, the signal changes shapes as it propagates. Now if it changes shapes in this way, the adjacent bits may overlap, may make recognition impossible for the receiver, so what might happen if the signal changes shape? Why does it change the shape? If you remember in the very beginning I had shown you one slide of a square wave kind and we talked about some harmonics. So the square wave may be looked upon as a sum of all these harmonics, a sum of all these sign waves. Now all the harmonics or sign waves are of different frequencies ? we had talked about the sin x sin 2 x and sin 3 x and so on ? so they are of different frequencies. Now signals of different frequencies change or get affected by the medium differently. So a signal of a particular frequency may be attenuated less; the signal at a much higher frequency may be attenuated much more or vice versa. The point is that signals at different frequencies will get affected by the medium in different ways. So finally, the relative strengths of the different frequencies will be different when you go to the far end; that means, when you go to the receiving end, when you add that all up, you will get a different shape. You will not get the old square shape or whatever shape you have sent; you will not get that back. So this is called distortion. (Refer slide time: 44:27 - 45:31)

Then, of course, it is going to pick up noise. There is thermal energy in wire, which is everywhere. So this energy is some kind of inherent noise that will always come; then there will be random signals. So spikes may sometimes occur; say, some car is starting somewhere so there will be some static discharge; the lightning strikes somewhere, there is somebody running a motor, somebody is running a washing machine, all these things add to the general noise in our atmosphere and this medium, which is carrying a signal, will also catch some of this noise. Sometimes of course, the noise is so sharp that it may  change the transmission in such a manner that you will not get the original signal back. So sometimes such a thing may happen. (Refer slide time: 45:31 - 46:47)

What we want is a high signal-to-noise ratio in order to distinguish between the signal and the noise. If the noise is very low and the signal is high, we can still distinguish at the receiving end between what is a signal and what is a noise and take the signal out, take out the noise. But for this we want a high signal-to-noise ratio. Signal strength divided by the average noise strength is the SNR and as SNR falls, error will increase. So in this figure, you can see that as the signal becomes weaker and weaker and touches the noise floor may be goes below it. When it goes below it, the noise becomes more than the signal; then no meaningful communication can be carried out. So in general, we want a strong signal-to-noise ratio. So one thing we might do quite often is that suppose we do have to send a signal to a very long distance, the signal will naturally get weak. So in-between, we will put some amplifiers or repeaters or regenerators, which will take the signal, try to filter out the noises as much as possible, then amplify the signal and make it stronger, and then push it for the next span. So after some distance, again another repeater will take it up and regenerate the signals. We have to go on doing that so that I maintain an acceptable signal-to-noise ratio even at the receiving end. (Refer slide time: 47:26 - 47:38)

Then of course, as I said that, there is interference. That means energy from outside the wire adds to signal, like noise, which is often intermittent, and is very hard to control or diagnose. (Refer slide time: 47:38 - 48:49)

One important point is that a very strong interference can occur at cable termination. So there are two things: first of all, if two cables are running in parallel, what might happen is the signal in one may affect the signal in the other. So there is some kind of linkage between the two the so-called cross talk ? that is one thing. This is more pronounced at the termination end; at the termination end, if you do not terminate the thing properly, if you just leave it like this, the kind of distortion and the kind of noise that will be introduced will be much more. So whenever we are putting some wired kind of network infrastructure, we have to be very careful about the termination, because that is where a lot of noise can come in. So often there will be multiple wires in a bundle; each radiates some of its signal, causes interference in nearby wires and this is especially bad at terminations where wires are unwound and are parallel. (Refer slide time: 48:49 - 49:36)

Finally I just mentioned this, that when carrying digital data over analog lines, we require modems. Modem stands for modulation and demodulation. This is used to connect a digital computer to an analog phone system usually, but modems can also be used elsewhere. It can be installed internally or a card inserted into the motherboard or can be connected to the serial port, etc. So now we understand why modems are required because essentially, digital data will have to be carried on the analog system. The field of communication, as you know, is a very interesting field and we could not go too much into the details of communications. But we have just talked about the very basics of communications used in computer networks, because remember computer network or some computers or some network nodes are connected via some communication lines. So communication is absolutely important; it is all-important in this; so we have talked about this.In the next lecture, we will look at some of the medium that is actually used or deployed in common networks. Thank you. 


Preview of next Lecture
Lecture No. #4
Physical Medium - II

Today we will ] have the second lecture on the physical media in the last lecture we have seen the different ways  the digital signals and analog signals, etc how they can be used for communication how digital data or analog data can be encoded and some of the general  impairments of physical medium. in this lecture we are going to look at specific media which are used in networking (Refer slide time: 51:18 - 51:20)


 (Refer slide time: 51:21 ? 52:30)


so there are basically two types of  mediawhich are used for communication one is cable i mean they are two different classes are together so one is a cable  now this cable  could be some  copper cable they could be coaxial cable or twisted pair or shielded twisted pair so the twisted pair I mean we sometimes there actually unshielded twisted pair or UTP sometimes we simply called them twisted pairs since they are more common there are shielded twisted pairs also and then  of course the one of the most important cables these days is the fiber optic these are the different types of cables that we use in networks. similarly we can also communicate without the use of any cables by simple electromagnetic radiation and these radiation could be in different ranges of the frequencies like they could be infrared or microwave or radio or satellite. etc So we will look at all these  one by one (Refer slide time: 52:31 - 55:25)



first let us look at the kind of  media that we use in a LAN. LAN as you remember is a local area network and a local area network could vary from let us say one meter to one kilometer so its is local strictly by some means of size in some way so one meter means two computer connected siding on the same table connected side by side it could be all the  computer in one building and all the  computers in several buildings and so on so that is the kind of range that we have for LAN . and the medium that we use for LAN they could be coaxial cables, UTP, fibers, wireless so you would note that basically most of the types of cables that we talk about find their way  in some ways or other  in local area networks. and of course UTP or unshielded twisted pairs are of different varieties or categories so that cat is for categories so we could have cat3 cable cat 5cable, cat 5e cable, cat 6 cable, cat 7 cable and so on .You must have seen cat 3 cable if you looked all your telephones that is the landline phones they are connected by unshielded twisted pair cables of categories three.  for computer networking I mean cat three cables could also be used for LAN although we usually prefer cat five onwards.  the kind of things  that are on the network that could be PBX, PBX is your local telephone exchange that could also have some digital ports etc. Ethernet is one technology which is used in LAN ATM is also used, FDDI is sometimes used FDDI if you remember is fiber distributed  that is the FDDI ring kind of structure. so  there are some networks even smaller than LAN. they have called personal area networks some networks so i may have be varying three or four computers and they or connected in a network on my body. o we will come to pan later on but  going on the other side of the spectrum that means from LAN to a bigger network this is man that is a metropolitan area network. typically one campus or one city may be several small towns which are closed together they would come under the preview of the MAN, so MAN by ballpark figure man would be extent of about ten kilometers, so it could be 5 kilometers or it could be twenty kilometers so something in that range (Refer slide time: 55:26 ? 57:48)

and the kind of medium that we use for a metropolitan area networks coaxial cables both base band and broadband, we will come to this what they are. sometime UTP are used but that is not very preferred way of  connecting although UTP are  used one way UTP is definitely used are when you try to network to telephone lines. That is I mean telephone linesi  told you they use UTP. it could be a hybrid kind of system, some part of it could be coaxial some part of it could be UTP and some part of it could be fiber. fiber means , fiber optic cables. and kind of things of course that kind of technology that goes into a MAN would be PBX different kinds of modems for example if you are using a broad band coaxial cable you might use something what is known as a cable modem . then you have this long  Ethernet that means on the Ethernet on the over may be some lines cable tv DSL digital subscriber lines or it could be wireless. one issue which is important in MAN is the issue of access alright that means how do you reach to each individual users.I mean  think of a town or a city so you  really have to in order to network the entire town you have to reach to each individual residence and reaching to each individual residence involves cost ok, if it is a small building like in a LAN you can take very  good say UTP cable to his room . now there are problems of taking UTP cable to each individual house I mean  there could be i mean electromagnetic disturbance and things like that  but apart from that there is a question of cost. Ok if you are trying to build so much copper into that is quite costly. so how to access to users who are distributed over somewhat wide area in the sense of several kilometers that is an issue in metropolitan area networks (Refer slide time: 57:49 - 58:41)

Finally at the extreme of the spectrum we have WAN that is wide area network so they may stretch from ten kilometers to may be 10000 kilometers, so 10000 kilometers almost to the other side of the globe.  so they can involve very very long distance . medium is usually fiber or satellite and the kind of technology that is used in WAN are SONET or SDH that the almost similar technology ATM IP that is the internet protocol, DWDM dense wavelength division multiplexing, Geo and Leo Geo stands for Geostationary satellite is a short form of Geostationary satellite and Leo is low art orbiting satellite. 
