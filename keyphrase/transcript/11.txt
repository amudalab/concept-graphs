COMPUTER NETWORKS
Prof. Sujoy Ghosh
Dept of Computer Science& engineering
IIT Kharagpur
Lecture 11
Routing and Wavelength Assignment
In WDM all optical networks
(Refer slide time: 00:48 min)

Good day. In this lecture we are going to continue our discussion on wavelength deviation multiplexing. Specifically we are going to talk about routing and wavelength assignment ?  (Refer slide time: 01:02 -01:04)

routing and wavelength assignment to what? Well, routing and wavelength assignment means that we have some stream of packets or whatever data or whatever communication is going from one source to one destination. Now these sources and destination, first of all, if there is point-to-point connection they directly send it through the fiber. That is   simple; but in general, they will not be directly connected. They will go through a network; they go through some intermediate notes to reach the destination. So for this stream we have to route this; that is one problem and the other thing is that may be the stream rides on some particular wavelength for the time being. Let us assume that it is continued on the same wavelength; we have to assign one wavelength, so we have this problem of routing and wavelength assignment (Refer slide time: 02:09-02:19 min)

in WDM and all optical networks. Of course we can do routing etc. very easily in the electronic domain ? that is known ? but we have not yet discussed routing in the electronic domain, how it is done etc. We will discuss it later on in this series of lectures. But in routing, we are talking about simple kinds of routing problem here. So we will talk about routing and wavelength assignment. (Refer slide time: 02:39- 03:11 min)

The optical WDM networks are future backbone for wide area networks. The reason we want it is because the bandwidth demand from the users is going up at a very fast rate;   of course, we have to go for fiber, we have to go for higher speed and then we have to pack in a lot of these channels over the same fiber. So we require an optical WDM network. (Refer slide time: 03:18 ? 03:57 min)

The speed of electronics compared to optics is a major constraint at the backbone. So it is always preferable to handle the traffic at the optical layer, where we can achieve much higher speed and the whole thing is transferred. The physical topology that we will consider at the optical wavelength routers is connected by some fiber links. So these are the same kind of topology we had talked about; that means there are some nodes, which are connected by some communication links. In this particular case, the communication links happen to be optical fibers. (Refer slide time: 03:58-
05:10 min)

Most of the node pairs in the backbones are not physically connected. So we have 30 or 40, let?s say 40 nodes. Now for 40 nodes,  there are 780 possible pairs, that is, 40 C2, that is, 40 ? 39/2, that is,  780 pairs, which is a very large number. Of course, only few nodes are connected actually through physical fibers. So they can reach each other only through other intermediate nodes. A light path or connection: this is the concept that we will be talking about most in this part of the lecture. This is the path between two end nodes and a wavelength on that path, so we want to route, that means, we want to find this path between two end nodes and we want to select the wavelength on which to send all our communication from the source node to the destination node. (Refer slide time: 05:11-05:21 min)

The intermediate nodes can cross connect that particular wavelength from the incoming fiber to the outgoing fiber. Do you remember our discussion on digital cross connect? May be through MEMS, that means, a particular wavelength is coming through one particular fiber, we direct it through some mirror to another fiber on that same wavelength. It is as simple as that. Thus  with programmable optical switches, the traffic can be routed entirely in the optical plane.  (Refer slide time: 05:51-06:14 min)

So no wavelength conversion for the present, and any light path uses the same wavelength on all the links its path spans. So 16 or 32 wavelengths in each fiber are common these days and hundreds of ?s are being talked about. A single fiber could theoretically accommodate as many light paths. (Refer slide time: 06:13-06:39 min)

What are the basic concepts of the light path? End users use light paths to communicate, each light path passing along the same fiber occupies different wavelengths; that means on the same fiber there may be different light paths going through the same fiber, each of them would be writing on a different wavelength or different lambda two ?s. Two light paths with the same wavelength cannot share a fiber, that means two different light paths who are on the same wavelength they cannot have any fiber in common because then their signals will get mixed up with each other. Of course, we can have (Refer slide time: 06:52-07:36 min)

WDM with wavelength conversion also. As I mentioned in the previous lecture that wave length conversions are possible although they are quiet costly. So it is possible in different extents, for example none that means no wavelength conversion or we can have a partial wavelength conversion that means some of the nodes have WC capabilities while others do not have or it may be full. If you have wavelength conversion we get some kind of flexibility in routing and wavelength assignment. We will not concentrate on that but you can understand that if we could convert the wavelength midway that means, as the signal is going, we can convert the signal midway, then maybe we can have better possibility of accommodating many more light paths. For our purpose, we will be concentrating only without wavelength conversion. (Refer slide time: 08:00-08:21 min)

So how to establish light paths? Two parameters to be decided: path from source to destination ? this is the routing part ? and wavelength along the path, which is the wavelength assignment part. Traffic types subjected to optical networks may be static or dynamic; that means you know the specific source destination pairs, which have to be connected in advance and that is quiet stable. So now you may run some centralized algorithm kind of things and find the best way to assign the light paths. The other situation could be dynamic; dynamically there is a request from some node for a connection to some other node and you want to set up the light path on the fly and take it down. That is a slightly more complex situation. (Refer slide time: 08:59-
09:52 min)


So two versions of RWA are realized depending on the characteristics of the traffic applied: static light path establishment or dynamic light path establishment. Now routing and wavelength assignment. Several, signals can share a single fiber. All signals must have different wavelengths, so these are the constraints. Of course, technology sets the upper limit to the number of wavelengths. You cannot have  unlimited number of wavelengths, you can have a large number these days but even then this is not unlimited. So these are the constraints, which you will have to respect while doing the routing and wavelength assignment. The problem is how to choose a route and a wavelength to each connection, so that signals won?t block each other. How can signals block each other? Well, the signals can block each other in this way. For example, suppose you have routed two particular source destination pairs in a certain manner using a certain wavelength, let us say ? 1. Another pair of source destinations was, let us say, N1N2; then we want to put a connection between N3 N4,  for which the route happens to share some of the links. In these links now you cannot use ?1 for this, because ?1 on those links is already occupied by the link from N1 N2. So if N3 N4 share even one link, you cannot use the same ?1; you will have to use ?2, but then ?2 has to be blocked because of some other links and so on. (Refer slide time: 10:52-11:23 min)


So the objective of SLE, that is, static light path establishment, is to minimize the total number of used wavelengths connecting the maximum number of nodes. They are the same; if you can connect some particular set of nodes using the minimum number of wavelengths, using the number of wavelengths, which are given to you, you may connect the maximum number of nodes. Other objective functions we may also consider are the load in the most loaded link, the total number of optical switches, etc. (Refer slide time: 11:24-13:48 min)

So this is an example of light path establishment. Suppose you have these A B C D E connected. So in the first part the left half of the figure what we have is the physical connection from A to B there is a connection and B to D and so on. In this, I show some  RW routing and wavelength assignment has already been done and some of the wavelengths and some of the links have been used. So here only two wavelengths are used. Let us say A to B are not connected; say a 
light path has been established via B for A to C. At B, there will be a switch, which will switch this dashed line, which is ?1. So ?1 coming through this fiber from A to B is switched to ?1, using the same wavelength to the outgoing fiber from B to C. So we have light path established between B to C.  

Similarly, from C to D there is a light path;  there is a light path from B to D; there is a light path from D to E; there is a light path from E to F; there is a light path from D to F and so on, using the same ?1. Then I want to connect E to C. Now I cannot go from E to C. After say ?1 has been assigned, I cannot go from E by ?1 to anywhere because all the outgoing fibers of the ?1s have been used up this side for A, this side for B, and this side for F. So, in order to connect from E to C, I use another wavelength, say ?2, which connects me via D and the D cross connect will connect this particular ? from this fiber to this fiber. So we will get a direct light path from E to C. Similarly, we will get a light path from B to F using ?2, A to D using ?2 and this way they are all connected. As you can see, a large number of light paths have been established using just two ?s. (Refer slide time: 13:49-14:35 min)

Dynamic light path establishment, on the other hand, is appropriate for network having dynamic traffic, where the traffic pattern changes very dynamically and a communication request may arrive at any time. The goal is to maximize the number of the incoming communication requests accepted. Well, if it so happens that you have already made some  kind of reservation and some kind of allocation to an earlier request and when a new request comes, you find that there are no paths on which a ? is consistently free throughout. So in that case, you have to block that request or regret that request. So we want to minimize such regrets and maximize the number of incoming communication requests that can be accepted. That is the goal of DLE. (Refer slide time: 14:36-14:57 min) 


 In order to solve this problem, let us see what the complexity of the problem is. The RWA problem is difficult; it can be divided into two sub-problems ? routing and wavelength assignment. Both of these sub-problems are NP complete and tightly linked together. If you remember, by NP complete we mean that class of problems for which no  polynomial time algorithm is known and so, if you can solve any one of them in  polynomial time, all others can be solved in polynomial time. It is not known whether  any polynomial time algorithm exists, but since the number of such problems is so large  and people have thought about these problems in so many different guises, it is very unlikely that you would suddenly come up with a polynomial time solution to any of these. And of course, when an algorithm has an exponential complexity, it takes a lot of time. So that is a difficult problem in that sense; both its parts are NP complete. So there is no exact solution. So we cannot expect to get the so-called ideal solution or the optimal solution in all cases, but we can try good heuristics. (Refer slide time: 16:00- 16:31 min)

Now what we want from a good algorithm ? maximize the number of connections; use the shortest routes; and minimize the number of wavelengths. If you can maximize the number of connections, this is of course our basic requirement. If you use the shortest routes or the number of hops should be minimum, delays and all kinds of things should be minimum. So that is another good thing to have, and if you minimize the number of wavelengths that have been used, future requests can also be possibly accommodated.  (Refer slide time: 16:32- 17:06 min)


So for routing, there are different techniques like fixed routing; that means the path that is predefined is used; that means the for all pairs we have some fixed paths and fixed alternate routing, meaning multiple predefined paths are there and one of them is selected. So the criteria could be shortest path, least loaded path, least congested path, and so on. (Refer slide time: 17:07-17:27 min)

There could be adaptive routing techniques; the path is found on the fly. That means as the network is in operation dynamically, you find the least congested path or the most suitable path depending on the current situation in the network, and once again we may try to find the shortest path or least loaded path. (Refer slide time: 17:28-18:03 min)

Now how do the wavelengths affect routing? There cannot be two signals with same wavelength per fiber for two different light paths; that is not possible. So the shortest route may be blocked by other signal and in the worst case all the routes are blocked. Then, of course, either you have to reassign the wavelengths of other earlier assignments or you have to block this request. If the wavelength conversion is possible, the signal can use other free wavelengths but the conversion is not always supported. (Refer slide time: 18:04-18:15 min)

Wavelength assignment problem arises under the wavelength continuity constraint; that means the wavelength has to be continuously available in all the links down the line and there are various algorithms for that. One of the most commonly used one is the first fit,  which means, you have decided on the path by some means; that is the routing path. Once you have decided on the path you have a list of these wavelengths, ?1 to ?N, and you try them in order. The first wavelength, which is free on all the links in the route is the one which is assigned to this particular light path request. That is called first fit, and it has some good points in the sense that since you are always trying from the same end, you tend to use up these earlier ?s more and more, giving you very good utilization of the ?s. So you may be having a lot of other ?s in the network. You have them on reserve to accommodate the request. So that is a first fit algorithm. But then again you must remember this is just a heuristic, in the sense that there is no way you can prove ? as matter of fact you can disprove it. In some cases, this would not give you an optimal algorithm. In some cases it may give you an optimal algorithm. In many of the cases, it has been found that this gives good results, but in some cases, it may give very bad results. It may be random. You may want to distribute the load all over, so it may  be random or people have used the least used; that means the least used ?, which is most free, is the one that is picked up. When you try all the ?s one by one, you reach the ? that can fit this particular route. So this will have the opposite effect, in the sense that this will try to distribute the load evenly across all the ?s or the most used ones; it need not be the first fit or the least loaded, etc. So these are the different algorithms or different heuristics, which you might use for assigning your ?. Of course, what you could do also is that at some point you could go back and instead of asking about your routing path you can ask, give me the next alternative path. So from the shortest path, which it might have given in the first instance, it might give you the second shortest path on which you may try the same kind of wavelength assignments using that. So all kind of combinations of routing and the wavelengths, all these strategies are possible. (Refer the slide time: 21:18-21:34 min)

What are all the good points about wavelength routing? Setting up a light path is like setting up a circuit. You remember we have talked about circuit switch network and packet switch networks? So in circuit switch networks, specifically the telephone circuits, even today may be majority of their networks are circuit switches; that means, a call from one node to another, one caller to one callee, a continuous circuit is set up. All those things have become more complicated as we have seen because of the TDM and all kinds of packets and all these things are coming in between. Anyway, the essential circuit switching is that the circuit is switched. Just in the same manner, when we are assigning a particular light path to two nodes, which have to be connected, it is just like setting up a circuit. And once the light path is set up, the route is fixed and the wavelength is assigned and the light path is set up. Then these two nodes can communicate, pumping as many packets as they like through this, of course limited by the technology constraints. But this is quiet a high constraint. So the inherent advantages of setting up this circuit switching is that in this particular approach to the problem specifically the quality of service is good. What we mean by the quality of service is smooth traffic and QOS guarantee can be given due to fixed bandwidth reservation and SLE is easy to manage, that means static light path establishment is easy to manage. That is the advantage of wavelength routing. (Refer slide time: 23:22-23:39 min)   

The disadvantages are the following: long circuit set-up time. This circuit time will be in the order of tens of milliseconds. Actually the circuits are set up in such a way that the source sends some request and the request goes down all the nodes on the way. The local switches have to be set up in that particular fashion and then they will acknowledge and say that ok the light path has been set up. So all this communication takes the order of tens of milliseconds. Now tens of milliseconds may be a lot of time depending on  the situation. When a very high-speed communication is going on, then tens of milliseconds is a lot of time. But if you are going to set up a light path and then use it for one month or one year, then tens of milliseconds may not be much. So it depends on the situation; but if your traffic is changing dynamically then you want to adopt what light paths you want to assign etc., in a dynamic fashion, then tens of milliseconds may be a lot of time. The other problem is that the huge capacity of 1? can carry how much traffic, let us say of the order of 2.5 gbps or something like that or may be even more these days. Its capacity is very huge. The point is that for just two nodes communicating, it may be a gross underutilization if proper traffic grooming is not done at the edge. What you mean by traffic grooming? You remember that at the edge, first of all, when we are talking about the edge, we are talking about the backbone network, which is where usually all your WDM systems will be deployed. So we have this backbone network and these backbone networks have been fed by all different networks, are routed from different networks etc., so number of streams are coming into this backbone network. They are converging and then traveling to the backbone, and then going out on the other side. So, the routers which communicate with this backbone are the edge routers and the light path you have got from N1 to N2, as we have seen is the granularity is quite coarse; that means a quite high amount of traffic can be handled. So if the edge router get together a number of streams from different sources and then uses it, it?s good traffic roaming; it loads it quite well then that is good. So we are achieving high efficiency if it is two single users and the two end then it is a gross under utilization of this ?. Unfortunately in this circuit inherently you cannot have less than 1? for a circuit, if you are setting up a circuit. You have that capacity but you are underutilizing it. This is the same problem that we had seen in circuit switching versus packet switching, and as a matter of fact there is a development as we will see for the packet switching part also, which we will see in the next half of this lecture. (Refer slide time: 27:03-27:13 min)

So bandwidth is inefficient for bursty traffic. This is another term that you should know, if you remember I told you while discussing about the telephone traffic that the Bell telephones people had done a lot of study about what kind of traffic is there, and how long the people talk and how frequently they talk at different times of the day, etc. We know that this is the some kind of Poisson distribution with exponential inter arrival time etc., so  those are very well-behaved kind of systems. Unfortunately, in recent years first of all the voice traffic has shrunk to may be less than 5% of the overall traffic in the network, 95% of it is data traffic and this data traffic has seen to be very bursty. They also follow some kind of statistics, but it is a complicated kind of statistics, the whole thing is that the data traffic seems to come in bunch. When they come lot of packets are coming and then for a long time there is no traffic. It is also self similar, and it is complex kinds of statistics but in anyway the point is, for long time for which when it is not sending anything, the circuit is remaining unutilized; so this is a gross under utilization of the circuit. The busy time versus the lean time may be of the ratio of 1:500 or something like that. So that is why this becomes an inefficient way. Another disadvantage is wasted bandwidth during either off or low traffic periods for SLE or too much overhead, that is, delay, due to frequent set up or release in dynamic light path establishment. That means if you want to put it down and then set it up again, in that time frame this becomes too much of an overhead because, if you remember, for setting up a light path we require may be tens of milliseconds. So you cannot do it very fast. (Refer slide time: 29:16-30:05 min)   

Particular ? path specific pros and cons are that, they have very coarse granularity, as we have discussed i.e., OC 48 and above. OC 48 if you remember is 2.5 gbps or above that. They have limited number of wavelengths and number of light paths; no aggregation, that is, merging of the light paths inside the core. So inside the core, there cannot be any aggregation etc. Traffic grooming can only be done at the edge so this may be complex or inflexible. That OXC has a millisecond kind of switching time. So these are the pros and cons of ? paths. (Refer slide time: 30:06-30:10 min) 

So this takes us to the next half of our lecture, where we will have a look at the other way and other approach to this whole problem, namely, optical burst switching. Just as the previous one was circuit switching, where we were doing circuit switching; we were setting up light paths. Here we will try to take the packet route; that means we will send them packet by packet. How that can be done? Originally, the packets may have originated from some say TCP/IP or Ethernet or some computers as small kinds of packets. Doing it at that particular level becomes difficult at the optical level. So we have some technology for that; we will look at this now. We will discuss the next topic, which is optical burst switching. (Refer slide time: 31:13-32:19 min)

First of all, let us do one quick comparison between electronic versus optical switching. Data is transmitted optically in WANs, MANs and even some LANs. Electronic switch uses digital switching fabrics; converts data from optical to electronic for switching and then from electrical to optical for transmission. That means what we are doing is that, we are trying to do the switching in the electronic domain. As mentioned a number of times before, the electronic switching always has problem; at high speeds it is very costly and this is not very easily upgradeable, scalable, etc. So that is a problem; but if you have done the switching in the electronic domain, there will be no problem. The kind of switching and kind of logic, kind of algorithm that we use in the other parts of the network could be put over there but we want to avoid electronic switching and do optical switching as much as possible. So let us see how that can be done. (Refer slide time: 32:20-32:33 min)

The cost of electronic switching goes up steeply as the speed requirement increases and optical or photonic switching uses optical switching fabrics, keeps data in the optical domain. (Refer slide time: 32:35-32:51 min)

So, why not we keep the status quo; that means that do the switching in the electronic  domain only? Well, the trouble is that the data traffic growth is still doubling every year and this is different from what we have in the computing domain. In the computing domain or Moor?s law, it doubles may be in one and a half years and this is doubling every year. Actually if you see over the long range, although the computational speed has  increased many fold, the communication speed has grown even more, by an order of magnitude more maybe. So the point is that electronics is unable to move and that is not possible for developing at that particular rate of development. So pure electronic processing and switching can hardly keep up. Electronic MUX, DEMUX, space power consumption, heat dissipation, etc., are always a problem because heat dissipation is more, it requires most space etc. There is no transparency, meaning, it depends on the kind of system and the kind of the modulation system, the kind of multiplexing system that you are using, which you have to use in the electronic components. So when the technology moves on, these intermediate nodes will also have to be changed, whereas, the optical switching, since it is transparent, does not matter if you change what you are sending through that pipe. (Refer slide time: 34:33-34:51 min) 

The cost factor, of course, weighs the heaviest. Though the cost of OEO at 0C-48 is going down, the overall cost including WDM system at 0C-48, is still a dominant factor. OEO at 0C-192 and higher in the future will still be a dominant cost factor. (Refer slide time: 34:52-35:18 min)

So we want to go to optical switching, whose advantage is that, low cost and high capacity, transparency; that means it is independent of bit rate, format, protocol, etc. It is synergetic to optical transmission and future proof; that means when we upgrade, all these things might change but my intermediate node will not change in the optical switch. (Refer slide time: 35:19-35:41 min)

Opaque, that is OEO switches, are more mature and reliable, of course. So still they need some electronic processing and control; that means, when we are doing in the optical domain, we still require some electronic processing and control. What we do is, we try to minimize this, and optical 3R and performance monitoring are hard. You remember that we can amplify a signal quite easily but if you want to do all the 3Rs that means Regenerate, Reshape and Retime, then we prefer to take it to the electronic domain.   (Refer slide time: 35:58-36:30 min)

Packet switching: a packet contains a header; that means addresses and the payload. It is a variable or fixed length. The advantage of packet switching is that it has some kind of statistical multiplexing; it can be sent without circuit set-up delay ? if the line is there just simply send it. It also enables statistical sharing of link bandwidth among packets with different sources and destinations. So that makes it more efficient; bandwidth usage is more efficient. (Refer slide time: 36:31-37:04 min)

So packet switching is done usually this way. Store and forward at each node: it buffers the packet, processes its header, and sends it to the next hop. This is how usually it is done in the electronic domain; we will look at the details of this later on. But usually what would happen is that, when we are using a circuit switching, the circuit is set up from N to N and then we can send whatever we like. But when it comes to packet switching, since it is coming packet by packet, each packet has to be processed independently. We have to look at this packet, look at this header, see what the destination is, decide on which next link to take, etc., and send it. So you have to store this packet in a buffer and then examine, do some processing and then forward it ? this is the store and forward paradigm. This is usually done in packet switching. (Refer slide time: 37:37 ? 37:43 min) 


We have some problems with that optical domain, as we will see. It is statistical multiplexing and is inherently bandwidth efficient. (Refer slide time: 37:43 ? 38:25 min) 

Now if you have a packet core, well, we have the access or metro networks, optical buses, passive star couplers, etc. SONET WDM rings or token rings are used. We will talk about token rings later. It uses switched networks or gigabit Ethernet. So these are the kind of technologies that are deployed in the LAN/MAN side, whereas in the WAN side, we have the ? routed virtual topology, i.e., circuits or leased lines. We have dynamic ? provisioning; that means circuits on demand and optical burst switching, which we are talking about now. (Refer slide time: 38:27 ? 38:54 min)

The technology drivers for this are the explosive traffic growth, as I already mentioned, bursty traffic pattern, and to increase bandwidth efficiency. To make the core more flexible, naturally a packet?s system would be more flexible than those fixed light path kind of system to simplify network control and management and making the core more intelligent. (Refer slide time: 38:54 ? 40:05 min)

How important is this bandwidth efficiency? We are always talking about the bandwidth efficiency. Well there are two views to it ? one is the user?s point of view. Well, user wants some bandwidth today and if the bandwidth becomes cheaper and as it becomes available, he immediately thinks of another application and his bandwidth demand will grow. Previously, people were very happy to send some simple text. Now, they are downloading, then they want to download songs, files, they want to download entire videos, then they will try to do video conferencing with each other. So these are very bandwidth intensive applications and they require a lot of bandwidth. So from the users? point of view, the more the bandwidth you give, I will bring lot more applications and I will just use it up. So with more available bandwidth, new bandwidth intensive applications will be introduced. High bandwidth is like an addictive drug, cannot have too much of bandwidth from the users? point of view. (Refer slide time: 40:05 ? 40:38 min)

From the carriers? and vendors? point of view expenditure rate is higher than revenue growth sometimes; so longer-term equipment investment cannot keep up with the traffic explosion. So, you have to see that whatever I invest today, how long in future I can take so that my investment is lower. We need bandwidth efficient solutions on the infrastructure existing today that will be competitive. So these are the different issues which (Refer slide time: 40:39 ? 42:07 min)

brought us to optical packet switching or optical burst switching. I will come to that later on. But this is our goal; there are two problems; and one of them is the lack of optical buffer. In the optical domain, if some packet is coming, means some light pulse is coming now, how do you store them in the optical domain? There is no good buffer for optical domain; there is a thing called fiber delay lines. This is really a very bulky and not very good stuff, you can put it in the fiber delay line. As it comes, it goes to that fiber delay line and comes out of the other, the whole thing would be delayed a little bit; that is something akin to buffer in it. But there are severe limitations on how much you can delay, that is one thing. Secondly, it is bulky, expensive and not very good. So fiber delay lines are bulky and provide only limited and deterministic delays. Store and forward with feedback FDLs lead to fixed packet length and synchronous switching. So we cannot use because of this simple store and forward, and the other thing is that tight coupling of header and payload requires stringent synchronization and fast processing and switching. So these things are difficult. (Refer slide time: 42:07 ? 43:49 min)

So we go to this optical burst switching or OBS; a burst has a long and variable length payload. So first of all, variable length payload means we want to keep it as flexible as possible; that is one good aspect of it. That means we want to keep it as flexible as possible. The other thing that we want it to be is it is long, why is it long ? because we have to do some processing, some setting up, etc., for these burst of packets to travel. So what we do is, we will do some grooming in the electronic domain. We  collect a number of packets together forming a burst, which has the same source?destination pair and then we set up the path and send this burst along all in the optical domain. So that is the essential approach to optical burst switching. A burst has a long and variable length payload, if it is long and has low amortized overhead and no fragmentation. A control packet is sent out of band, that means using some other ? control and reserves bandwidth ? that is ? data reserves a particular bandwidth along a particular path ? and configures the switches. So it is like setting up a temporary light path from the source to the destination. A burst is sent after an offset time; it arrives at a switch after it has been configured. So no buffering is needed. Our original problem is of not having optical buffer, so buffers in the optical domain are avoided in this fashion. (Refer slide time: 43:49 - 44:51 min)

We have to do a burst assembly and disassembly at the edge at the source side. That means the client data may be the IP packets, which are the most dominant ones. They are assembled together into bursts; and burst switching or reservation protocol is done, that means, we send the control packet, an offset time t ahead of burst. So within this offset time, all the switches down the line will do their programming. That means they will set up all their mirrors or whatever it is their cross connects, etc. So that later on, when the burst does arrive, we do not have to do any processing on that and if you are do not doing any processing on them we do not need to store them either. They can go straight away in the optical domain. There is a dedicated control channel, which is out of band signaling for the control packets. (Refer slide time: 44:52 -45:25 min) 

The advantage is no fiber delay lines nor OEO conversions for burst at any intermediate nodes, photonic burst switching fabric inside the core. That means it leverages best of optics for burst switching and electronics for control packet processing and fabric control. So just for the control part, we do this OEO and for the bulk of it, the burst, we do not have to go to the electronic domain at all. (Refer slide time: 45:25 - 45:55 min)

This is a diagram, say assembly queues for different egress nodes; these are going to different channels. This is an ATM cell IP packet or SONET, and we have an IP packet over here. We have a SONET frame over there because if you are sending things in the purely optical plane, you do not really care what the payload contains. It may be an IP packet, it may be a SONET frame, it may be some cell, it may be anything else we do not care. Intermediate optics is transparent to all that. So what happens is that (Refer slide time: 45:16 ? 47:18 min )

we use the ATM cell for the control packet purpose. So we make a control packet, which assembles a burst, and as it assembles a burst, it knows what the time or length threshold reached is. The length of the burst may be variable, as we said the burst could be long and of variable length. But when all these different IP packets frames, SONET frames etc., are put together, what happens is that a control packet is generated and sent out. The control packet now knows the source, it knows the destination, it knows the length of the burst, so it sends through a separate control channel, so this control channel goes through the control plane as we will see. (Refer slid time: 47:18 -47:44 min)

So we have the assembly queues for different egress nodes; that means the destinations, for different destinations, all these packet frames etc., are getting queued up and forming into bursts. (Refer slide time: 47:44 -  48:04 min)

Now we see fiber delay line ? as I just mentioned it fiber delay line, feed forward or feed backward. So there is no optical RAM for store and forward; every FDL provides only limited delay and cannot perform most of useful buffer functions. So FDL units are bulky, affect signal quality etc. (Refer slide time: 48:04 ? 48:24 min)  

Now going back to this OBS, we have various schemes still involving in an active area of research. I will just present a simple scheme called just enough time or JET. There is an offset time between CP and burst. So what is done is that the control packet is sent and after the control packet is sent,  there is a delay. We give a delay and then we send a burst;  this delay is to cover all the programming time on the intervening nodes. (Refer slide time: 48:43 ? 49:05 min)

So an offset time between CP and burst: no fiber delay line required to delay the burst, when CP is processed and switch fabric is configured. CP carries the burst length info, facilitates delayed reservation for intelligent efficient allocation of bandwidth and FDL if any, including look ahead scheduling. We need not go into the details. (Refer slide time: 49:10-49:53 min)

We have the control packet here, which is moving in the control plane, and we have a burst over here and there is offset time T and we have just enough offset, JET, which we require for programming these intervening optical  nodes. So CP arrives at OEO node at time, let us say, T1. But the control packet is being taken to the electronic domain for processing, because this will have to be processed etc. So it is better done in the electronic domain. (Refer slide time: 49:54 ?50:05 min) 

Then CP goes through the optical to electrical conversion and configure the switch fabric and then it will move on. (Refer slide time: 50:06-50:12 min)

CP goes through EO conversion and leaves the OEO node at time t1 + ?. (Refer slide time: 50:13-50:53 min)

So what will happen is that, this will now move towards the other end, to the next node, and here this will again go through the O to E and then do the switch configuration and then again E to O and go to the next hop. And this delay is calculated in such a fashion that when the burst arrives, what happens is that at the intermediate node, the switch fabric is already configured. So you do not have to store it; you simply pass through in the optical domain. (Refer slide time: 50:54-51:16 min)

Offset of course is now T ? ?  because it spent delta amount of time over here. So without any delay, the burst goes through the optical switch fabric.  Depending on how many intervening nodes are there, you have to have this original T so that finally when T is exhausted, offset is exhausted but you have also reached your destination. (Refer slide time: 51:17-51:37 min)

That is just enough time. And finally to conclude, OBS is a programming switching   paradigm that offers many advantages over the existing technologies, but is not likely to be the end-all kind of solution. OBS has several variations and adopting OBS will be an evolutionary process. This is another problem ? when you have a new scheme and there are different researches, they will try to do research and come up with different suggestions and then at different places some different things may be adopted. But then, in order for the entire network to work in a very smooth fashion, you have to come to some standard, so OBS has not come to that standard yet, but it is a quite a promising approach. Now, we have talked about the two approaches in WDM, namely, this circuit switching path, that is the light path routing and wavelength assignment and setting up of light path, and we have talked about optical burst switching. In the next lecture, we will talk about SONET infrastructure. The SONET, which we have talked about, a lot of it is also in fiber optics. Then we have all these fiber optics; that means packet oriented fiber optic infrastructures are also coming in. That means large routers, etc., are coming into this picture, one thing we did not discuss although we mentioned it a while discussing about SONET was that this has an inherent capacity of fault recovery, recovering from fault. So that is one thing that we would like to discuss in the next lecture ? not only in SONET, in optical network, but in general, how do you handle faults. That is very important, because this optical network is at the core of the network and if the core of the network fails, its repercussion is tremendous, both economic and other repercussion may be tremendous. So we like to put in lot of reliability into all this fiber infrastructure that we have, and how exactly that is done, we will discuss in the next lecture. Thank you.
Preview
COMPUTER NETWORKS
Prof: Sujoy Ghosh
Dept of Computer science& engineering
IIT Kharagpur
Lecture 12 
Protection and Restoration 


(Refer slide time:53:37-53:41)

Good day. In  this lecturer, we are going to discuss the various protection and restoration  mechanisms, which are usually employed in  optical  networks 
(Refer slide time: 53:54-53:57 min)	

We will be talking about protection and restoration, now of course we have to discuss, what is protection and restoration.    Why we need them? (Refer slide time :54:05-54:16 min)

What is protection and restoration, comparison between the two and the different schemes of rotation? This could be   our general outline   of presentation. (Refer slide time:54:19-54:25 min)

Network is unreliable somehow , so many failures can occur,  node may fail a link, may get cut, some fiber optic line may cut in between because  somebody cut it , while digging a whole or something or node might fail there may power failures at nodes and so many things.   So there are failures in the network but if you remember  that  one of the most important places where we deploy optical networks is in the core of the network  and the core of the network connects so many people, to so many other people. It is so very vital  that we cannot allow the services to be a severely desalted because that would have very grave consequences. Anyway the service provider attempts to give a very high level of service.   So although failures are   unavoidable in real life, we have to find a some way of combating this, that means  if there is a failure, we want to recover from it as soon or as fast as possible so that, is what protection and restoration is all about. Another thing is that when we want to give some reliability, protection, restoration etc we always in some form, always have to bring in some redundancy. Without any redundancy a system  cannot be  protected, it cannot be restored without any replacement etc., so there has to be some redundant capacity in some form in the network, in order to achieve protection and restoration. How this is done that is what we will discuss. (Refer slide time: 56:14-56:25 min)

So   first let us talk about  path protection, it uses more than one path to guarantee that data is sent successfully.   so if you  look at this graph,  it will be having a six node graph, where 1 and 6 are communicating on the top  through the dash line.   We show the primary path, which is the primary connection between 1 and 6. What might happen is that the link between 2 and 3 might snap due to some reason. So we have already got a backup route which is calculated going through 1 4 5 & 6 . We will channel our communication through the backup link and please note that this  backup or secondary path from the source of the destination is link. This channel does not share any link with the primary path, so that is the requirement. If any link in the primary path fails,  I am assuming only one failure which means that the backup link is all intact and you can switch to the backup path for this particular communication. (Refer slide time:57:24-57:47 min)

Dedicated link protection is not always practical, sometimes it may have it shared link protection is practical, it is quiet often and it is implemented and   it may fail, when this link protection may cause failure here you are only provisioning for the failure of the link,   but if a node fails, then it may lead  to some complications as we will see. (Refer slide time:57:48-58:07 min)

So to compare between path switching and line switching path, switching of course is a coarse scheme and line switching is a finer scheme and line switching is can again be span protection, span would may be a several links together and that may be a span or  a line protection (Refer slide time:58:08-58:37 min)        

In mesh networks, of course the restoration is possible only if the graph is 2 edge connected that is by connected which means that there are 2 edge connected disjoint paths between any pair of nodes so that no single edge failure can disconnect the network. So this is a  necessity and usually  try to keep that way, unless it will be difficult or it is not a cost,   effective etc., (Refer slide time: 58:37-59:21 min)

Protection in a mesh networks of course more complicated, then a ring   simple minded scheme would be 2 edge node, no disjoint paths for each connection 1 +1 not as is  mentioned here, this not very efficient. There may be many paths and provisioning double the number of paths, which are pair wise mutually node are edge disjoint that may be very difficult. Provisioning in the network better approach would be line protection which of course have the problem of coordination.   I will show the later on are protection cycles in mesh net, again I will show this.
