COMPUTER NETWORKS
Prof. Sujoy Ghosh
Department of Computer Science and Engineering
IIT, Kharagpur
Lecture-26
Introduction to Routing (Refer slide time: 00:39)

Today we will start our discussion on routing. We have already talked about routing a little bit in different context, specifically in the context of ATM of how the ATM virtual path etc are set up. Today we will start our discussion on the major area of routing and specially with reference to the TCP/IP stack. That is how packets are routed in an IP network. (Refer slide time: 01:22 - 01:33 min)

Today we will start the introduction with routing and then we will take up the discussion about different routing protocols in the next set of lectures. (Refer slide time: 01:34 - 03:46 min)

Let us just recollect, what is the job of the network layer or what is routing? The job of the network layer is to carry data from end-to-end. That is, from the source to destination perhaps through a number of intermediate subnets. Now depending on whether connection-oriented or connectionless services are used other functionalities may be incorporated at this layer. We will talk about this later on. Right now we are talking about routing of IP packets and later on we will discuss on how you can have a virtually connection oriented system on that. unlike data link layer, if you remember, is just the next hop, just the link which is immediately adjacent. So that has some advantages in the sense that whatever information you require about it are locally available. Unlike the data link layer, the major problem with routing is that it happens over multiple networks and towards a very remote system and the packet might have to take many hops, may be 10, 20 or even 30 hops to reach the end point. When you take 20 hops the area you are serving becomes so large with so many machines connected to it. And then how do you keep track and then switch so many machines with so many links? The problem is some of the links may go down, some of the machines may go down, some of the machines may come up And when I may refer it actually says PCs, servers, etc, they may also refer to network boxes like other routers.  So the job of the router is to know which link it should take so that globally the packet will arrive nearer to its destination.  (Refer slide time: 03:47 - 04:12 min)


This is the basic routing problem. At a particular subnet node given a packet with a particular final destination determine the next subnet node or the outgoing link which is appropriate. In the datagram network this is determined for individual packets but in VC networks this is determined only for setup packet for each session. Now we will concentrate on the datagram network.  (Refer slide time: 04:13 - 08:20 min)


Consider a router X. X may not know the topology of the entire internetwork. These days everybody wants to be connected to the internet so we have a giant network of networks. So there is this big network of networks spanning the entire globe and then a particular network once again may be divided into so many sub networks. There are billions of machines connected to this network so some user somewhere wants to connect to another user on the other part of the globe. This is a huge problem that must be solved in a systematic manner. But this is the objective of routing or the network layer. So X needs to determine the next?hop router for every other network in the internet. We are trying to reach some particular machine, some particular server. If you want to keep track of all the machines in the world it becomes really impractical. We somewhat reduce the problem where all these different machines are grouped into different networks or even sub networks. They are grouped into different networks so that a remote router needs to keep track of only the remote network rather than a particular server in that network. Of course, the idea is that, once you reach your destination network finding a particular server within that network will be very easy. Either through ARP or some such protocol you can reach the particular server once you have reached the correct destination network. The entire information that is required is structured as a routing table of router X to keep track of all the other networks. What is a routing table? Given the address of a particular network in a remote location we should be able to find from the routing table that which local hop I must take next. Even that is not easy even if you reduce the scope of the problem from servers or PCs to networks because there are millions of networks in the world. So theoretically if you do it in a very naive fashion you have to keep millions of entries so that you can match and know that this is what the mistake is. Of course, even this is not possible because at the same time you want to go to the correct destination for this particular packet and at the same time you want to process the packets as fast as possible. People want more and more speed so the network traffic and the number of packets are increasing day by day so you have to process the packets very fast. If you have a very large table then it demands time even just to look up to it and you require a lot of memory. Additionally it consumes lot of processing power which will thereby drive up the cost of the router. So, even keeping millions of entries for most routers this is not a feasible option therefore we have to do something about it.  (Refer slide time: 08:21 - 10:04 min).


The other issues in routing are: One is, the topology changes affect convergence, delay and stability. Topology of the network changes all the time because the links may go down or come up, nodes may go down or come up so the topology is changing. Therefore this may the change the path that a particular packet takes and the path the next packet takes in the same stream.  This may affect the delay and the stability. The other problem is scalability to a large number of interconnected networks or routers or links. And even when you come down from nodes to networks this is still a very large problem. Then there are other issues like what is the best path from X to Y. It may be that five different routes are possible from X to Y. Now all these five routes are not equal. First of all they may not be equal in the number of hops, they may not be equal in length, they may not be equal in cost, they may not be equal in the quality, some of the routes may be very unreliable that the packet has a larger probability of getting dropped and so on and so forth. So we would like to have the minimum number of hops or the minimum delay or the maximum capacity.  Therefore if possible we would also like to incorporate the quality of the path when deciding on a route for a particular packet from X to Y.  (Refer slide time:10:05- 11:30 min).


So routing consists of deciding the route for each packet. And in order to do that the router has to have knowledge of the entire network and this knowledge has to be dynamic because the network topology keeps on changing so we have to update the knowledge of the network from time to time. Suppose you have a host or LANs connected to some routers say A, B, C, D, E and then through the links 1, 2, 3, 4, 5 and 6 respectively then for example when the router A gets a packet from a local network which is connected to it which may be destined for the LAN which is connected to router C. So it has to decide whether to take link 1 or link 3. Obviously it does not take this link because this is where it is coming from and obviously it is destined to some other sort of remote so it has to decide. Although in this particular example you may theoretically reach C both by taking link 1 and link 3 but then these links may be of different quality, May be something like A, D, B,C, E is a bit of choice. (Refer slide time: 11:31- 12:12 min)


As mentioned earlier these are the routing tables. We have the routing tables in routers. They look somewhat like this. For example, let us look at the routing from A and this may be just one form of it. It may not be exactly used in this form but let us look at it. Suppose you want to route to the router A which is again local because we are sitting on router A, for B you take link 1, for router C link 1, for router D link 3 and for router E link 1. (Refer slide time:12:13- 12:24 min).

From A to B is link 1, may be C is also link 1 and D is link 3 and E is again link 1 and so on.  .  (Refer slide time:12:25 - 12:59).


Similarly, B will have a routing table and C will have a routing table and so on.  Suppose you take any destination A, (Refer slide time: 13:00 - 15:41).

now for A let us consider a tree with a root at A. Now B connects to A through link 1 and C connects to A through link 2.  Obviously link 2 is not taking C directly to A but link 2 is only taking C to B but that is the preferred path for connection from C to A.  If you think about it this way, for each destination we have got some kind of a tree if the network was very bigger. Here the network is very small so the tree is only two levels deep. But the tree could be very deep may be 10 or 15 levels deep. So for each destination we actually have a tree which is implicit in these routing tables which are distributed. At each node we try to see the local link to be taken for that particular destination. As I said, the local link may not take you directly to the ultimate destination. But the local link will take you somewhere and that particular node will again have a link for the same destination. This way, if everything is working fine, after some hops you will reach the final destination. This means that some of the other nodes may be directly connected, some may be 2 hops away, some may be 3 hops away etc. But overall there is an implicit tree for each destination. And for one movable link of this tree is in one particular link of this routing table just according to the destination. In other words, if there are n nodes and there are n implicit trees and these n implicit trees are distributed over n nodes. So it is one link from each tree in the routing table of a particular node. In that way you have a routing table of size n including the root which is the local link.  And somehow you need to maintain this tree and that is the job of a routing protocol. Later on we will see different routing protocols and also see how these implicit trees may be maintained or rather how these routing tables have to be maintained. (Refer slide time: 15:42- 16:44 min).


When there is a routing table there is a question of forwarding. Routing is the process of building routing tables at each router. Forwarding is the process of looking at the destination address of a packet and sending it to appropriate next hop interface of a router. This means, once through a routing protocol you have a routing table then a packet actually arrives and you have to forward it to the correct interface of that router. So, you look up to this table and the interface to which the packet must be sent and forward it. So this routing or forwarding are two different and distinct parts of the router. Actually sometimes these two are diverged even more. For the time being we assume that routing and forwarding happen at the same place and the routing table itself is being used for forwarding although that may not always be the case. Forwarding requires access to local routing table. Sometimes forwarding table is structured in a different manner than routing tables.  (Refer slide time: 16:45 - 18:05 min).


So forwarding table is optimized for packet look ups. Routing table is optimized for routing changes, topology changes etc. A routing table may look like this: say, for net number 10 the next hop would be this IP number because the routing table is working in the IP address. This IP address is version four addresses and it contains four numbers all less than 256 so it is 171.69.245.10. The link cost may be there. In forwarding, we really do not care what the IP address or the next hop is. We do not even care about the link cost because all these are a part of setting up the routing table. In the forwarding table we just wanted to know the interface as to what is the local interface to which this packet has to be sent and what is the MAC address at the next hop. This is what we are more interested in. Basically you can just add your data-link headers and just send it over to the physical layer. This is a slightly higher level and the abstract view of processing an IP datagram.  (Refer slide time:18:06- 21:09 min).


In this IP module there is a routing table which is the central thing. There is a routing protocol which makes this table. Sometimes we also use static routing, for the time being let us consider that it has been manually configured.  Some of the entries may have come through a routing protocol while some of the entries may have been manually configured. Now, when a packet comes from an upper layer it will come from some transmission layer protocol. Two of the most common transmission layer protocols are TCP and UDP. We will see what they are later on. But let us assume that some packet has come through UDP with some destination IP address in it. You look up at the routing table, The next hop and send the datagram. Or the same thing must have come through TCP also.  When we are discussing the processing of the IP datagram in the IP layer the IP layer is present in two different places. In one place it is the regular host the PC and in the other place it is a router. The jobs of the two places are a little different. If a packet comes from outside to a PC, and is not meant for the PC, the PC is simply going to drop that packet. In the case of a router, if a packet comes from outside, it looks up the destination and then actually forward it. So in a PC the forwarding table may be disabled whereas in a router the forwarding table will be enabled. If the packet originates from machine PC itself then it has to go out on its way. It will send the packet to the router. The IP datagram it is sent to the network layer. This is a high level view of what is happening in the IP datagram processing. (Refer slide time: 21:10 - 21:21 min)


The processing of IP datagrams is very similar on an IP router and a host.  The main difference is IP forwarding is enabled on router and disabled on host.  (Refer slide time: 21:22 - 21:45 min)


Now when the IP forwarding is enabled, if a datagram is received but it is not for the local system, the datagram will be sent to a different system. When IP forwarding is disabled, if a datagram is received it is not for the local system and the datagram will usually be ignored.  (Refer slide time: 21:46 - 22:03 min)


The view at the data link layer is somewhat different. Internetwork is a collection of LANs or point-to-point links or switched networks that are connected by routers. So this is the data link layer view of the IP datagram.  (Refer slide time: 22:04 - 23:02 min)


In this diagram there may be some point-to-point links or some LANs, etc. and they are all connected by some routers R1, R2, R3, R4 etc. A particular host places an IP datagram on the local ethernet that is destined for outside it will eventually reach the local router and the router will decide whether to give it to another network such as the network of Ethernet switches, token ring etc. Through different networks the packet proceeds through the routers to this. When you look at it from a data link layer point of view all these switches become visible whereas at the IP layer only the routers and the networks will be of main concern. (Refer slide time: 23:03 -23:26min)




A view att the IP layer: An IP network is a logical entity with a network number.  We represent an IP network as a cloud. The IP delivery service takes the view of clouds and ignores the data link layer view. That means the details of these actual switches etc are in the data link layer view whereas in the IP layer view it will simply be a cloud.  (Refer slide time: 23:27 - 23:26 min)



In this picture there are routers R1, R2, R3, R4, etc and the connecting networks are shown as clouds.  Each network has some number. (Refer slide time: 23:47 -27:13min)


The following conditions must hold so that an IP datagram can be successfully delivered. The network prefix of an IP destination address must correspond to a unique data link layer network which is equal to LAN or point-to-point link or switched network. The reverse need not be true. This is quite fundamental. You have already seen examples of IP addresses. They are basically four numbers each less than 255 that is something like 144.16.192.53. This may be the IP address of a particular machine. In the network layer it is not possible to handle all the machines individually because that will make the problem really big. So as our first step in our reduction or scaling it, actually in the remote routers we do not usually keep track of the specific IP addresses of specific machines. We just keep track of how to go to that network which contains this IP address. So the IP address usually has two parts: the leading part that is the first few bits or bytes is a address of the network whereas the last few bits or bytes may be reserved for a particular machine within that network. This is how a global IP addressing scheme is. This is not as neat as in telephone numbering which exactly tells you the particular state, area, LECA and the particular exchange finally so it is not that neat. But at least the first few bits or bytes will be associated with all the IP addresses in a particular network. If you just take that prefix part you know that it precisely means that particular network and no other network will have the same exact prefix. The network addresses have to be globally unique because now-a-days our network is really span the entire globe. Therefore this is called as the  network prefix of an IP destination address and this must correspond to a unique data link layer network. But the reverse need not be true which means one data link layer network may have two different network prefixes.  (Refer slide time: 27:14 - 27:37 min)


So routers and hosts that have a common network prefix must be able to exchange IP datagrams using a data link layer protocol such as Ethernet, PPP etc. Every data link layer network must be connected to at least one other data link layer network via a router.  (Refer slide time: 27:38 -28:08 min)



Each router and host keeps a routing table which tells the router how to process an outgoing packet. The main columns as we have already seen are (1) the destination addresses, i.e. where is the IP data gram going to, (2) next hop, or how to send the IP datagram and (3) interface or what is the output port. Next hop and interface columns can often be summarized as one column and routing tables are set so that the datagram gets closer to it is destination.  (Refer slide time: 28:09 -29:39 min)






This is another example of a routing table. IP datagrams can be directly delivered which means these are in the local network. Therefore they go through the interface called Ethernet zero whereas these addresses are outside so this one had to go through a router or to a point-to-point link. Or this can be some other network altogether. Now the prefix has distinctly changed. For example, 10.1.0.0/24 means any number from 0 to 24 can be there. So, for all these IP addresses, you just deliver the datagrams directly. Similarly 10.1.0.2 is also connected directly which means they are all in the same network. And then there is a point-to-point connection through a serial link on this router which is also may be very closely connected to the same set of networks. There may be other networks out in the WAN which really starts from 20. So, for those networks you again have to go to the router and go out through some port of that router.  (Refer slide time: 29:40 -30:22 min)



If you take a more global view these different routers will be having routing tables. We know the details of these routing tables and what they contain and this is how one particular IP packet which originates here will go to a router then to a next router and then to another router and so on.  (Refer slide time: 30:23 -33:41 min)



Processing of an IP datagram at the router: 
First we have to receive an IP datagram then IP header validation. The IP protocol is a network layer protocol. Previously we discussed about a lot of data link layer protocols but now we are talking about IP protocols. And for these IP protocols once again you require some information to be exchanged between peers. This information will be in the header called the IP header because in the network layer we are mainly concerned with IP so it is the IP header. In any case the IP header has to be validated. If there are some options in the IP header they have to be processed. The destination IP address is parsed from this header. Then we do a routing table look up and we decrement TTL i.e. we decrement time to leave. Here is a common example. In this distributed fashion we are trying to capture a good and consistent and correct picture of the entire global connectivity which gives you the best connection. But in practice this may not always be possible because the global picture may change from time to time. So, to get the entire global picture in a very correct fashion is not possible sometimes. You may have inconsistent routing table entries and that may lead to various things such that it may lead to a loop in the routing table. The loop may not be in one routing table but if you take several routing tables together then you can see that the packet will go in a loop. Once a packet starts going in a loop it will continue in that loop because each time it comes to the router the router will see its own routing table locally and send it to the next one which was hopefully in a correct path. But actually now it is in the vicious ring so this packet will just go on circulating ad infinitum. To stop this we put some kind of restriction on the number of hops a packet will take may be 30. Each time an intermediate router forwards a packet it will decrement this time to leave that is from 30 to 29 and from 29 to 28 and so on.  After 30 hops whichever router finds a packet with a TTL zero will simply drop the packet either that packet is going in a loop or the packets have gone very astray because of mistaken entries in the routing table and so on.  (Refer slide time: 33:42 -35:18 min)



Then perform fragmentation if necessary. We will see the details of fragmentation later on. Fragmentation here is, what you are doing is that you are going from one network to another network to another network and so on.  All these different networks are on different administrative controls and different domains and they may even have different data link layer technologies. Some token ring may be connected to some Ethernet and there can be all different kinds of networks in between. Now suppose the source had sent an IP packet which was quite large but inside one particular network it is not possible to handle such a large packet.  It would be unfortunate if you drop the packet all the time because it will never go through. Therefore what is done is that this big packet is broken up into small fragments and the fragments are sent. Later on when you are in a sort of wider area the fragments are again reassembled into a big packet and sent along when it reaches the destination. Then you calculate the check sum which is of error in connection as we note and transmit to the next hop and send an ICMP packet if necessary. ICMP stands for Internet Control Message Protocol. The routers may use ICMP packets for communicating between each other and sending various messages if necessary. We will see one example list now and the rest later.  (Refer slide time: 35:19 -35:41 min)




When a router or host needs to transmit an IP datagram it performs a routing table lookup. So, use the IP destination address as a key to search the routing table. The result of the lookup is the IP address of the next hop of the router and/or the name of the network interface.  (Refer slide time: 35:42 - 37:09 min)


So we have seen that. Therefore either you take the network prefix or host IP address or loopback address or the default route.  Loopback address means this is meant for local consumption so it will go back to the same machine. So it is coming down from a machine and it contains a loopback address then it goes back to the same machine. Why would somebody want to send the packet like this? One process of the packet of the host is sending some packet to another process in the same host and it is using this network operating system part for sending that message.  Default route is very important because you cannot keep the network prefix for all possible networks in the world in this table then this table will then become very large. So you will have fewer entries for the network prefixes and if your network is something else may be there is a bigger router somewhere that knows about all these networks. So there is a router which is likely to know about this particular network prefix which has come so you send it to a default route. And on this side you have the IP address or the name of the network interface.  (Refer slide time: 37:10 - 37:26 min)


So the destination address is a network address, most entries are network routes. For the host route the destination address is an interface address which is used to specify a separate route for certain hosts.  (Refer slide time: 37:27 - 38:09 min)

The default route is used when no network or host route matches. The router that is listed as the next hop of the default route is the default gateway. We are calling it gateway because this is not a packet for a network which is close by. This is a packet for some arbitrary distant destination, this is a smaller router that is connected which will send it to the gateway and the gateway will in turn send it to a bigger router to find its final destination.  (Refer slide time: 38:10 - 38:27 min)


Loopback address:
Routing table for the loopback address is the particular loopback address which is used in IP which is 127.0.0.1 and this is meant for local consumption. The next hop lists and loopback interface as outgoing interface.  (Refer slide time: 38:28 - 40:04 min)


To minimize the size of the routing table we use the longest prefix match, i.e. we search for the routing table entry that has the longest match with the prefix of the destination IP address. It means search for a match on all 32 bits. The IP address contains four integers less than 256 i.e. four bytes which is actually 32 bits. So an IP address in IPv4 address is 32 bit long. So first you try to match all the 32 bits with some entry in the table. If the 32 bit does not match then you take only 31 bits and check whether they match and you keep on doing it and keep on reducing till you get a match so you have identified the first entry that matches with the longest prefix where such a match is possible. The host route loopback entry is a 32 bit prefix match. The default route is represented as all zeros which is a zero bit prefix match. That means there is a zero entry which will give you the next hop as the gateway because now it has not matched with anything. Finally this is a zero bit prefix match. (Refer slide time: 40:05 - 41:14 min)


Suppose the destination address that has come in is 128.143.71.21 then of course the 128 and 143 parts have matched with this but then here this is zero and this is 71 so this is a much better match here with the one shown in red. Similarly 128.143.71 is also matching here but the next number is 21 which will match better with this rather than with this range. This is where the match will take place and you will send to router R4. The default router at the gateway is shown as R5. So the longest prefix match for this is for 24 bits with entry. You can find this out if you actually break up 21 into its binary form and see how many bits are matching but this is matching with the 24 bits etc, so data gram will be sent to R4.  (Refer slide time: 41:15 - 41:32 min)


The longest prefix match algorithm permits to aggregate prefixes with identical next hop address to a single entry. This contributes to significantly reducing the size of the routing tables for internet routers.  (Refer slide time: 41:33 - 42:31 min)


Suppose for 20.2.0.0 to 16 I would have gone to router R2 and for 30.1.1.0 to 28 I would have gone to R2 once again. Now we see that the next hop is the same and what we can do is, instead of 20 and 30 if we make the entry as 20.0.0.0/8 and put it as R2 then because of longest prefix match then whenever something also comes in this range it will have a longest prefix match with this rather than with this because this is taken over here and 30 is naturally closer to 20. So instead of two entries we keep only one entry in the routing table which helps in reducing the size of the routing table.  (Refer slide time: 42:32 - 42:56 min)


 How do routing tables get updated? One way is to add an interface and then configure the same so it adds a routing table entry. This is manual configuration.  We can also add a default gateway that means for the destination that is the default route we can add a gateway. This is once again a manual updating.  (Refer slide time: 42:57 - 43:32 min)


So it is the static configuration of network routes or host routes. If some particular route is forced then I might put in a static configuration of what they are. Routing tables also get updated through routing protocols. There may be ICMP messages from some router which may update the routing tables. So these are the different ways in which a routing table may get updated.  (Refer slide time: 43:33 - 44:31 min)


For example, for this ICMP when a router detects that an IP datagram should have gone to a different router the router (here R2) forwards the IP datagram to the correct router and sends an ICMP redirect message to the host. The host uses the ICMP message to update its routing table. What is happening is that one particular host had sent the IP datagram to one router.  Now this router sees that it need not get it from this host and that host should have sent it to that router. This router will now send it to the that router anyway and send an ICMP message to this host saying that from next time onwards when you have got this destination please send it to that particular router rather than sending it to this destination. This is one example of how ICMP may be used. These are the different kinds of ICMP messages.  (Refer slide time: 44:32 - 45:46 min)


 The other thing is, ICMP router solicitation and ICMP router advertisement. When a router is switched on for the first time how will other routers know that this router has come up? Since the other routers do not know about the existence of the new router which has come up it is was not sending any message to it. So, after bootstrapping a router broadcasts an ICMP router solicitation. It sends an ICMP and advertises itself and solicits ICMP messages from the neighboring routers. In response the router sends an ICMP router advertisement message. Also, routers periodically broadcast ICMP router advertisement. This is sometimes called Router Discovery Protocol. This has to be done periodically because some router may have gone dead in the meanwhile. Therefore by doing things periodically you try to keep it as current as possible.  (Refer slide time: 45:47 - 46:28 min)


We can look at routing as some kind of a graph theory problem where (a) the nodes are the routers of a single administrative domain or different networks, (b) the edges are interconnection links, (c) link costs are related to physical distance, capacity, delay, etc and (d) the objective is to determine minimum cost path. You can formulate it as a graph theory problem and this particular graph theory problem can be handled in different ways. We will see two different ways later on.  (Refer slide time: 46:29 - 46:41 min)


The problem has some constraints, one is to solve the minimum cost path problem in a distributed manner rather than centralized manner and constraint two is to react quickly and robustly to topology changes.  (Refer slide time: 46:42 - 47:26 min)


There are routing protocol requirements. One is to minimize routing table space, i.e. with all these millions of networks working at the same time minimizing the routing table space is always very important. This makes the routers smaller or cheaper or faster, minimizing or controlling messages is also important. Routers should be robust and not misroute packets.  Loops and oscillations must also be avoided. Finally optimal paths must be used. All these are different routing requirements. It is not that we can get 100% of the requirements all the time but we try to do it as best as we can.  (Refer slide time: 47:27 - 48:40 min) 


Now we will quickly go through the different approaches to routing. One is the centralized versus distributed approach. In centralized routing one central processor collects information about the status of each link, computes the routing table for each node and distributes it. This is possible only in a small number of cases and not all the time. And obviously it is not possible over the entire internet because there is no such centralized routing that would handle the scale. In distributed routing, routers cooperate to run a distributed protocol to create mutually consistent routing tables. In distributed routing also there may be two approaches. One is that you distribute the local information only and then globally try to come to a solution. The other is that you distribute the information globally and then locally you simply route some kind of a centralized algorithm to know because you have now got the global picture in each of the places.  (Refer slide time: 48:41 - 49:53 min)


Routing may be source based or versus hop by hop. In source based routing the packet header contains the entire route. If a link or a router along the path goes down a source routed packet will not reach the destination because the route has been fixed by the source. The intermediate routers do not do anything. If the next hop is available it will send the packet otherwise it will drop it. In hop by hop routing the packet contains only the destination address and each router will consult its own routing table and find out what is the next hop and then choose that next hop. But in the source routing the route is fixed from the beginning. Loose source route is something in between, it is an intermediate solution. In loose source route what is done is that instead of specifying the entire path you specify some sort of islands in between. That means you go from one router to the next through several hops then again several hops and so on. So this is something intermediate between strict source routing and pure hop by hop routing.  (Refer slide time: 49:54 - 52:47 min)

Routing may be stochastic or deterministic. In stochastic routing each router maintains more than one next hop for each possible destination. One of these is randomly chosen. So the idea is to distribute the load evenly along the links. On the other hand packets may get out of order because of this. It is because the packets from the same source travels to the same destination and the first packet may be stochastically chosen to go through this path and another may be stochastically chosen to go through this path.  The probability of choosing either this path or that path can be based on some metric like the delay. But in the end the packets may reach out of order.  Please remember, the service the network layer is providing is just to send the packet from one end to the other part of the network. Here this part has been said explicitly but it is also important to understand what has not been said. It has not been said that this service is going to be very reliable which means that in the interim some router may drop a packet so your packet may not reach the destination at all. So reliability is not guaranteed. Another thing that has not been said is that all the packets you sent from destination A to B will reach the other end in the same order in which they were sent. The first packet may reach later than the second packet because may be it came through two different paths or may be due to some other reason. Once again there is no explicit guarantee regarding the ordering of the packets. Obviously towards the end application this may not work at all in many cases. So in such cases where this is very important you have to take precaution against this or you have to put in some corrections for this at some other layer and the network layer is not doing this. This was the idea for breaking it up into layers in the first place. In the physical layer it is the physical sending and in the data link layer sending is from one to one hop only and makes it as reliable as possible through checksum etc. In the network layer it is just reaching the other end of the network layer through several hops. Now if you want to do it reliably you have to go up one level more and then try to do something there. We will see how it is done.  (Refer slide time: 52:48 - 53:16 min)

Single versus multiple paths: Each router maintains one primary and some alternate paths. Single path routing is used in internet to reduce routing table size. Multiple paths such as stochastic etc are not usually used in these routers in the internet because the routing table size is at a premium. Multiple paths are used by telephone networks as routes can easily be deciphered from the address such as telephone numbers.  (Refer slide time: 53:17 - 53:33 min)



Next is state dependent versus state independent routing. State independent or static routing pre-computes the routes ignoring the network state and state dependent or dynamic routing uses the current measured network state (like loading or health of a link) to determine the current route which may change as the packet is proceeding. It requires more overhead but can usually find better routes.  (Refer slide time: 53:34 - 53:42 min)



 In static routing, the next state entry does not change in response to changes in network traffic or topology. In dynamic routing it does change.  (Refer slide time: 53:43 - 54:08 min) 



Routing in the telephone exchange of course is very simple as we have already seen. Under the same exchange there is no routing and under the same Short Distance Charging Area (SDCA) a central switch sets up the connection with the destination exchange. For trunk calls the central switch forwards the setup request to the trunk exchange (TAX) and maintains a primary and alternate path to a Long Distance Charging Area (LDCA). (Refer slide time: 54:09 - 54:20 min)


The possible goals of routing algorithm may be to minimize average end-to-end packet delay (which is desirable from the viewpoint of network user), to maximize throughput (which is desirable from viewpoint of network operator) and to minimize average number of hops (which tends to give both low delay and high throughput.  (Refer slide time: 54:21 - 55:49 min)



Another way we do routing route is by flooding. This is some kind of broadcast, so if a router wants to flood something it will send the same message to all the routers which are connected. That may be a very nice and fast way of reaching somewhere because when you are flooding very soon this message will get replicated at each node and everything is running perfectly and in a synchronous manner it will reach the destination using the shortest possible route. The only problem is that not one copy will reach but multiple copies will reach using different paths. And then other copies will never get anywhere but they will sort of choke other parts of the networks so these overheads are there. Still flooding is used in some special cases. This is one reason we use flooding and the other reason is that when we actually want to broadcast this to everybody then one good thing to do is to flood it. Every incoming packet is sent out through every outgoing line except the one it arrived on. A hop count or keeping track of previously flooded packets may be used to avoid generating infinite number of packets. Flooding gives the shortest route and is very robust but hardly practical otherwise. But in many situations they are also practical.  (Refer slide time: 55:50  - 56:06 min) 

Flow based routing is a static algorithm that uses both topology and load for routing. The traffic matrix and the line capacity matrix and a routing algorithm is assumed to be given. The mean delay time for the entire network is calculated from this. Different routes from different algorithms (or all possible routes) can be evaluated.  (Refer slide time: 56:07  - 56:20 min)


We will come to that later on when we do MPLS. Given a particular set of routing entries, the net average traffic in each link is calculated. So you can try to do some traffic optimization through this.  (Refer slide time: 56:21 - 56:33 min)

Then we have multi path routing.  At the router, for a given packet with particular final destination several choices for next router are enumerated, and then the actual path is chosen in some fashion.  (Refer slide time: 56:34 - 56:42 min)

Multi path routing may yield more stable traffic.  (Refer slide time: 56:43 - 56:46 min)

Alternative routes are also similarly determined.  (Refer slide time: 56:47 - 56:53 min)

We have already talked about dynamic routing versus centralized routing.  (Refer slide time: 56:54 - 56:58 min)

 It has its own disadvantages meaning it lacks some fault tolerance if routing computer goes down.  (Refer slide time: 56:59 - 57:23 min)

Distributed routing is the most usually used. It may use some distributed algorithm like distributed Bellman-Ford or it may use some centralized algorithm with distributed global data. We will look at distributed routing in more detail in the next couple of lectures.   


COMPUTER NETWORKS
PROF. Sujay Ghosh
Department Of Computer Science and Engineering
IIT Kharagpur
Lecture Name #22
Cellular Networks
(Refer slide time - 0:55)

Good day. So, now we will start our discussion on terrestrial wireless networks. We have already seen one kind of wireless communication, which is through satellites. So it is microwave repeater and we know that. But there are two very important and rapidly expanding field in networking, which is terrestrial wireless networking. We will have two lectures on this. In the first lecture, we will discuss cellular networks. The cell phone, which has become ubiquitous nowadays and in the next lecture, we will talk about Wireless LANs: Wireless LANs are may be little bit of Wireless MANs also. So, today we will discuss about cellular networks. (Refer slide time: 01 :49-04 :29)

So just right away, let us learn some jargons. What is a cell? The cellular network is organized in the form of some cells and it covers a geographical region. It has base station analogous to 802.11 AP. AP is for access point. 802.11 is the wireless LAN technology. We will discuss about this in the next lecture. Anyway, the point is that there is a base station and it will have an antenna, some transmitters and receivers. It will be connected to the backbone through a line. May be this could also be a wireless line, but usually this could be a fibre optic line. In a circluar geographical location around this base station, mobiles will communicate with this base station and through this base station to the rest of the network. So mobile users attach to network through BS. And air interface is the physical and link layer protocol between mobile and BS. That is called air interface between the mobile and base station. Now all these base stations are connected to the mobile switching center (MSC). The switching is essentially done over here. The MSC connects cells to Wide Area Network. The mobile switching center will be referred to as MSC, Base station as BS ,mobile switching center as MSC, MS, by the way, is a mobile station. MSC connects cells to Wide Area Network and manages call setup. More about that later and these MSCs will be connected to each other for a particular service provider. They will also connect to public telephone network and the internet etc. So one service provider, their network would be  connected to another service provider?s network. So somebody from this network can call the other network and so on. So we have the cells; we have the base stations; we have the mobile stations or MSs. We have the mobile switching center, MSC, and of course the PSTN at the back of it all. This part is usually wired.(Refer slide time: 04:30- 06:20)

The first hop ? we are now talking about the air interface between the mobile station and the base station. There are two techniques for sharing mobile to BS radio spectrum. There is certain radio spectrum, which is allocated to the base station and to the particular region that it has to be shared. Now, this is a question of multiple access and two techniques that we talked about earlier are FDMA, if you remember this is frequency division multiple access, and TDMA, time division multiple access. In cellular technology, what we usually do is that we combine FDMA and TDMA. So divide the spectrum in frequency channels and divide each channel into time slots. If you say that these are the different frequency channels and each channel may be divided into number of time slots. We will do FDMA as well as TDMA on this. That is one kind of scheme ? the so-called GSM utilizes this. We will be talking about how FDMA and TDMA are combined. The other technology is CDMA, which was designed by a company called VOLCOM in USA, which uses code division multiple access. We have already seen what code division multiple access is. So we will not get into the details of CDMA systems here. CDMA is another popular way of transporting data to the mobile devices. Both GSM and CDMA are used in many countries. For example, in our country also some service providers provide CDMA services, and few offer GSM services, some provide both, and so on. (Refer slide time: 06:24-07:19)

We will now discuss cellular standards as they stand today. Historically, we had only the cellular system that came from some amps in USA. Previously, there was only one cell from the analog system. From analog system, it came down to digital system in deamps and then we have these two systems of the 2G system ? one is the GSM system and the other is the CDMA version. 2G systems are voice channels: IS-136 is TDMA, combined with FDMA, which is used in North America. GSM, which is more popular of these schemes, is the global system for mobile communications. It has combined FDMA/TDMA, which is most widely deployed. IS -95 is the code for CDMA systems, which use code division multiple access. So these are the 2G or second generation systems. (Refer slide time: 07:20-08:23)

There are 2.5G systems. These were introduced because the 3G was promised quite some time back but the service providers really could not deliver it or crank it up to that extent. But, there was lot of demand for it. Voice was alright with 2G, but then the demand for data and other kind of multimedia services etc., was increasing. So people had to be given some data services. Instead of going all the way to 3G, people went to 2.5G. 2.5G systems have both voice and data channels. So, for those who cannot wait for 3G services, there are 2G extensions. One is GPRS. This is General Packet Radio Services evolved from GSM and the data is sent on multiple channels if available. It has an enhanced data rate for global evolution edge; also evolved from GSM using enhanced modulation data rates up to 384k.(Refer slide time:08 :24-09 :11)

CDMA has its own version called CDMA 2000, that was phase 1; then there was phase 2 also. So data rates up to 144k evolved from IS-95, which is the CDMA system. 3G system includes both voice and data: one service it provides is UMTS. This is the name of the Standard Universal Mobile Telecommunications Service (UMTS). GSM is the next step, but using CDMA 2000. So, all these merge into the 3G systems. How exactly this merging will take place and how it will actually be deployed and become popular remains to be seen; but today you can get these data services on your cell phones, etc. (Refer slide time: 09:12-09:46)

The protocol layering for cells is a little different. We will not go too much in to this. One is of course, the physical layer, which has to do with the physical channels. Then there is MAC, medium access control. We will talk about it, at least for GSM. So, there are these logical channels, transport channels, and then there is Radio Resource Control layer. That is the layer 3 particularly. This you might say is a protocol, but this does not go all the way that the OSI 7 layer. This is just for the cellular systems. (Refer slide time: 09:47-12:04)

 Our idea is that we have some base stations and each base station will cover some geographical area like it has been shown here. Different BS would be connected through a backbone network or through MSCs. We are trying to get the basic idea of the cell. The point is that, nowadays cell phones have become very popular. Its rate of penetration is much faster than the original telephones, and it is much faster than PCs also. So, cellular phones have become very popular, which means a lot of people want to use it and lot of people have cell phones. Many of them would want to talk at the same time. But how do you accommodate all these people talking at the same time? We do multiple access. But then, there is a limit to what you can do using same frequency spectrum. The idea was to do some kind of space division multiple access. In the sense that within one particular geographical area, we use a particular frequency band and then in another geographical area, which is far removed from there, so that these two do not interfere with each other, we use the same set of frequency band at the same time for a different set of users. The point is that these powers have to be controlled because, if they are very powerful, they will start interfering with each other. But if this power is controlled, then within that cell, that power is enough. But, it is not enough to interfere with each other. So, two different groups of users can use the same frequency band at the same time. This is the basic idea of breaking up a region into cells so that you can increase the number of people, who would be using this system. That is the basic concept of a cell. (Refer slide time: 12:06-13:03)

In practice, cells are may be of arbitrary shape. But they will be close to a circle because usually the kind of antenna used in base stations is omni directional antenna, in the sense that it gives the same power on all sides. It has the same sensitivity on all sides. If that is so, the area of influence would be a circle. But when many circles are put together they are pulling and they will intersect with each other. To solve this problem, we can use a tessellation. There are only three types of tessellations, which are possible ? equilateral triangles, squares or regular hexagons. Out of these three, the regular hexagon is the closest to a circle. That is why usually the regular hexagons are used to represent a cellular structure. A hexagonal cell, the closest approximation to a circle, is used traditionally for system design. (Refer slide time: 13: 04-14:27)

This is how a big geographical area may have been divided into a large number of cells ? it looks like a beehive. If you notice carefully some of the cells are dark and these cells are marked as A B C D E F G. So, these are seven. There are seven hexagons like this and these are actually different frequency ranges. These frequencies are again reused. For example, you have another A B C D E F G  over here. This B and this B ? although they use the same frequency ranges ? are far apart. So, different groups of people can use it at the same. Once it gets into the base station, we usually take it to the fiber optic domain, where a large number of calls, simultaneous calls can be handled. This really shows you the frequency reuse. A, the set of frequency bands, which are associated with A, will also be reused here, here, and there and so on. That is how a hexagonal cellular structure is constructed and we do this frequency reuse. (Refer slide time: 14:28-14:54)

Co-channel reuse ratio is given by DL/RL = ?3N, where DL is the distance between co-channel cells, that means those who share the same channel. RL is cell radius; N is the cluster size. The number of cells in a cluster N determines the amount of co-channel interference and the number of frequency channels available per cell. This really comes from geometry. (Refer slide time: 14:55-16:29)

When the number of subscribers in a given area increases, allocation of more channels covered by that cell is necessary. What happens is that in one area, say a small town, one base station could satisfy people, who had these cellular phones or mobile phones. Now what happens is that, the number of people who wanted to use mobile phones kept on increasing and now we cannot serve them any longer. The number of requests, which are denied, keeps on increasing. How can we increase? May be break it up into two cells and then break it up into four cells and break it up into many more cells, depending on the clusters of users and the cells. Now, the same area has been divided into smaller cells. May be in the BS, you decrease the transmitter power so that they do not interfere with each other. So when the number of subscribers in a given area increases, allocation of more channels covered by that cell is necessary. This is done by cell splitting. A single small cell midway between two co-channel cells may be introduced. (Refer slide time: 16:30-16:53)

These are the small adhoc solutions to the problem. For example over here, you had a large number of  cells. We created a small cell over here using A, which uses the same frequency bands as the already existing ones. You cannot use E, F, C, or B. But you can use A with other cells. So that is called cell splitting. These are ad hoc solutions, when a particular area has more number of users. (Refer slide time: 16:54-17:14)

We  now have a cellular hierarchy, the needs of which are: extending the coverage to the areas that are difficult to cover by a large cell; increasing the capacity of the network for those areas that have a high density of users; increasing the number of wireless devices and the communication between them. (Refer slide time: 17:15- 18:04)

So, you have a large number of cellular hierarchies. One set of them are called Femto cells. These are the smallest unit in the hierarchy. So these cells need to cover only a few meters, where all devices are in the physical range of the users. This is also called Personal Area Networking. So I have something in my left pocket, something in my right pocket and something in my hand. These might communicate with each other. So, that is Personal Area Networking. Femtocells are small cells. Then we have Picocells, the size of their network is in the range of a few tens of meters. So, you can think of a small building as Picocell. For example, WLAN (Wireless LAN). (Refer slide time: 18:05-18:34)

Micro cells cover a range of hundreds of meters; for example, in urban areas to support PCS or other technologies. PCS is another kind of mobile technology. Macro cells cover areas in the order of several kilometers, for example, a metropolitan area, or may be a small town. Mega cells cover nationwide areas. So, mega cells possibly are being serviced by a satellite. (Refer slide time: 18:35-19:04)

This is the picture of satellite, which may service a mega cell. Then, we have macro cell from this tower. Then we have pico cells, which have some access points etc inside a building and so on. Microcells for covering communication. So these ways of different kinds of technologies may be deployed for these different ranges of cells. (Refer slide time: 19:05-19:32)

Frequency reuse: We have already talked about this. Radio spectrum is one of the scarcest resources available; because, there is so much demand for it for so many applications. So, employ architectures that can support as many uses as possible (theoretically) with the available spectrum. Same spectrum can support multiple users separated by a distance and thus efficiently be using the spectrum. (Refer slide time: 19:33-20:46)

Frequency reuse has its foundations in the attenuation of the signal strength of EM waves with distance. So, if two points are at a distance from each other, this signal gets attenuated and does not interfere significantly with this one, although they are using the same frequency band. Usually, what will happen is that the service provider will be given some band of frequencies.  Now, he has to use that and cannot stray from there, as that is the license agreement. So, what he will do is that, is depending on where his users are, and what the distribution is, what the density is like, he has to develop or plan a cellular infrastructure in this fashion using and reusing this frequency, the same frequency band, here and there to give the maximum amount of service. The distance separating the transmitters of this frequency reuse should be sufficiently large. Of course, this has to do with a transmitter?s power. Transmit power should be reasonably small. The cellular concept is an intelligent means of employing frequency reuse. (Refer slide time: 20:41-21:21)

So what we have been talking about is something like a fixed channel allocation. That means for a particular cell, the channels, that means, the frequency band associated with the cell is fixed. So, total number of channels is Nc = W/B, where W is the bandwidth of the available for spectrum. B is the bandwidth needed by each channel. The total number of channels per cell is Cc = Nc/N, where N is the cluster size. (Refer slide time: 21:22-21:53)

Adjacent radio frequency bands are assigned to different cells as shown. In analog each channel corresponds to one user while in digital each RF channel carries several time slots or codes. So, you are doing either TDMA or CDMA. So, if you are doing this, the naturally FDMA TDMA combine or CDMA uses spread spectrum technology. So, it?s simple to implement. So, fixed channel allocation is simple to implement if traffic is uniform. (Refer slide time: 21:54-23:24)

But then, sometimes traffics are not uniform ? there may be two cells, which are side by side. So, this has been given one band. one has been given another band of frequencies. They do not interfere with each other. But, we find for each cell.  Let us say, to start with, we are given with equal bandwidth to each of the cells. Now,  I find that in one particular cell, the user density is much higher, whereas in adjacent cell, the user density is lower. So, I could use some more bandwidth in this cell and I could do with a little less bandwidth here. So, what could do is that, a part of this frequency band  can borrow from the adjacent cell. So, that is called Channel Borrowing technique.  High traffic cells borrows channel frequencies from low traffic cells. Temporary channel borrowing and static channel borrowing. This could be a permanent feature or this could be the feature of a day. For example, in the central business district, It might become very busy during the day time. So, it may borrow channels from the side, whereas after the evening the use may fall drastically. In that case, one cell can give out channels to others. Not only sort of giving channels to other people. So, this could be static as well as it could be temporary. (Refer slide time: 23:25-26:26)

This is suitably complex picture of GSM, i.e. the Global System for Mobile communications. So, this just to show you how these TDMA and FDMA are combined. So, you see there are 124 simplex channels in the GSM system. Now, each of the simplex channels actually carries a series of TDMA frames and each of the frames is divided into 8 parts, that is how a large number of channels can be given. There are two parts: one is the uplinking and another is the downlinking, that means, from BS to MS ? Base Station to the Mobile Station or from the Mobile Station to the Base Station. So you have two different frequency bands for these ? one band for this BS to MS communication and another band for MS to BS communication. In each band, there are a number of frequency channels and each frequency channel is again divided into so many slots: eight slots for simultaneous communication. So this one and this one are same channels, but this and this are two different channels for a particular mobile station. So from base station, it may be using this particular time slot in this particular channel, that is, from the base station to the mobile station. The same one, from the mobile station to the base station, will be using another channel and actually another time slot, because there is some technical problem in giving the same time slot in this channel as well as the other channel. So, you give it a different time slot over here. So, in this particular time slot of this particular channel, the mobile station is communicating with its base station. So, that is how it goes. GSM uses 124 frequency channels, each of which uses an 8-slot TDM system. And there is a frequency band at which it operates; this is also fixed. This is in the 959.8 MHZ range. You need not remember these figures, but this is the general scheme of the way TDMA and FDMA are combined together. (Refer slide time: 26:27-27:15)

Suppose this is S1(t) and  this is the signal which comes from source 1 and this is the signal from source n, Sn(t). This is some other source. What is happening is that in the Tm slots, the first slot ? S1 ? gets the first slot and Sn gets the nth slot. So, they are pushed into this in the same frequency band, and as time progresses, they function just like in a TDMA system. So, this is the TDMA part. So, GSM = FDMA 200 KHZ; that is the GSM system (Refer slide time: 27:16- 27:46)

This is a portion of the GSM framing structure. So, how they are framed? Actually, this is a somewhat complicated scheme. Some of these frames are used for control purpose and others for communication: one group for base to mobile and other from mobile to base, etc. So, there is a scheme for this. We will not go into the details of this. (Refer slide time: 27:47-28:17)


A GSM system has 124 pairs of simplex channels. They are in pairs because one goes from BS to MS and the other from BS to MS. Each of these is 200 kilo hertz wide and supports 8 separate connections on it, using TDM. So, each active station is assigned to one time slot on one channel pair. 992 channels can be supported in each cell, but many of them are not available to avoid frequency conflicts with neighboring cells. (Refer slide time: 28:18-30:16)

Transmitting and receiving does not happen in the same time slot because the GSM radios cannot transmit and receive at the same time and it takes time to switch from one to another. That is why different time slots are given. A data frame is transmitted in 547 microseconds, but a transmitter is only allowed to send one data frame every 4.615 milliseconds, since it is sharing the channel with seven other stations. The gross rate of each channel is about 270 or about 271 kbps divided among eight users. This gives about 33 or 34 kbps gross. CC i.e., control channels are used to manage the system if somebody is getting only 33 or 34 kbps. Previously, we have been talking about voice channel requiring 64 kbps. Now, the 64 kbps happens to be if you are doing a plain vanilla PCM. That means we have explained, how it is encoded by sampling it at eight samples and eight levels for each sample ? that gives us 64 kbps. The point is that, it is not the only coding scheme. Actually, there are more advanced coding schemes. We did not find time to discuss those coding schemes. Using those coding schemes, good quality voice transmission can be achieved, using a much lower bandwidth. This 33.854 kbps is actually enough, if you are doing your coding in a smart fashion. (Refer slide time: 30:17-32:19)


As I said, apart from the user channels, there are some control channels. CC is used to manage the system. The Broadcast Control Channel (BCC) is a continuous stream of output from the base station containing the BS?s identity and the channel status. All mobile stations monitor their signal strength to see when they moved into a new cell. The point is that the mobile station, when it gets these broadcasts from BS, by just sensing how much transmitter power it is getting, it can identify whether it is near this particular BCC, what this particular BS is, or what its identity is, or whether it is near some other BS. In some systems like CDMA, this power is very crucial even for decoding purposes. That is one thing which is being broadcast and to listened by all the MS. The dedicated control channel is used for location updating, registration, and call setup; in particular, each BS maintains a database of mobile stations, which are in its area. So, information needed to maintain this database is sent on the dedicated control channel. So, the point is that these mobile stations are moving. They move from one cell to another, from the vicinity of one base station to the vicinity of another base station. So, the set of MS, which are now currently under this, that information in some schemes is collected on the side from time to time and there is a database, which is associated with the BS. This is centrally communicated. That is important for locating a person. We come to that later on. (Refer slide time: 32:20-33:33)

And then there is a common control channel which has got three logical sub channels. That is the paging sub channel, paging channel, in which the BS uses to announce incoming calls. Each MS monitors it continuously to watch for the call it should answer. The point is that, if there is a call,  and MS is in the area of some BS and then somebody wants to call to this MS, that one particular MS has to be alerted. So, there is a paging for that MS from the BS and the MS is always listening to it. So, whenever it hears the page for itself, it gets alerted. So, the other is the  random access channel. This allows users to request a slot on the dedicated control channel. If two requests collide, they are garbled and have to be retried later on. So, this is the part of the call set-up. So, it is the first part of call set-up. It tries to put a request in the random access channel for a slot in the dedicated control channel. When it gets a slot in the dedicated control channel, it can go away with the further steps of call set-up. Next is the access grant channel. (Refer slide time: 33:34-33:51)
 
In GSM the channel multiplexing is FDM + with eight TDM slots. Uplink is this much and channel bandwidth is200 KHz. So, DCS has certain frequency range etc. (Refer slide time: 33:52-34:03)

Channels are broadcast and the channel rate is 13 kbps.  (Refer slide time: 34:04-34:42)

We have already seen what CDMA is ? it is based on DS spread spectrum, that is, the Direct Sequence Spread Spectrum. It has two frequency bands, one for forward channel and one for reverse channel and one frequency band, a wide band actually that is shared. That means it uses orthogonal codes by a number of handsets or number of mobile stations. So, CDMA allows use of same spectrum over all cells. It also gives net capacity improvement. Although which system is better ? CDMA or GSM ? is still not clear. (Refer slide time: 34:43-35:40)

There are certain issues in the cellular infrastructure, which have to be handled.  We will quickly discuss each of them. The most important one is handoff. Because you may be talking on your mobile phone while moving, may be moving in a car. So, what will happen is that, the car eventually will pass out of the range of one base station and move in to the range of another base station. So, you have to hand off. That means previously all communication from this mobile station was being handled by this particular base station, as it moves in to the area of another base station, this call has to be handed off from one BS to the other BS. Handoff changes of radio connection from one base station to another will happen. But this not such a simple scheme and we will see why. There are two types of handoff: hard handoff and soft handoff. (Refer slide time: 35:41-36:33)

This handoff has to be managed. In order to manage the handoff, we have to detect that handoff requirement has arisen because the mobile station has moved and then you have to execute the handoff, in the sense that you have to do the channel assignment and you may have to do some path rerouting and there may be problems in this section also. For example, when you move into a new cell, all the channels over there may be busy and so you may not have any extra channel, which has to be given to this ongoing call. So, there are various schemes for handling ? may be you drop this. That is the simplest thing to do, that you do not allow it or maybe you keep some guard channels specifically for these kinds of cases. But this detection of handoff requirement is a troublesome affair. (Refer slide time: 36:34-37:04)

As I said, there are two types of handoff: hard handoff and soft handoff. Hard handoff is break before make. This is used in GSM system ? that means you break this connection and set up the new connection with the BS in whose area you are moving. MS connects to base station 2 after link with base station 1 breaks, and this is the region where the handoff will take place. (Refer slide time: 37:05-37:57)

The difficulties in handoff detection are the following. The signal strength fluctuates. This is a very challenging area of mobile system design ? the signal area fluctuates due to various reasons: scattering, reflection and diffraction results in fading. There are fast fading and slow fading of the receiving signal. There are false handoff requirements at the boundary; there is a ping pong effect at the boundary. That means what might happen is that it may hand off from BS 1 to BS 2, then again from BS 2 to BS 1, again from BS 1to BS 2. This kind of ping pong might be going on. So, the number of unnecessary handoffs must be reduced because handoffs have a price paid, actually, keeping both channels busy on both sides. There are other kinds of overheads to this. (Refer slide time: 37:59-38:41)

Let us look at a very simple model. Actually the situation is much more complex because, there are number of base stations ? maybe three base stations and you may be equidistant from all the three at a particular point. So, you may have an even more difficult problem. But let us look at a simple problem. Suppose D is the distance between two base stations. So, ideally we would like that the signal strength from BS1 is following like this and the signal strength from BS2 is going like this. As you move from BS1 to BS2, as the MS is moving at the cell boundary, it just switches from BS1 to BS2. But the actual picture is something like this. (Refer slide time: 38:42-39:44)

This is the point is that the signal strength from BS1 is varying, very fast. Why does it vary? I will just tell you. I had just mentioned it, but I will tell it again. This is varying like this. The signal strength from BS2 is also varying like this. So this has been plotted from, let us say,  800 to 1200 region. So, there is a solid region at least from 950 to 1050. There is a region of 100 m, where you really do not know who is stronger. So the signal is varying all the time. What might happen is that you might now decide to move from BS1 to BS2, and then you find that BS1 has become much stronger and BS2 has become much weaker. So, it might switch from BS2 to BS1 and this might go on as a ping pong effect. So, this is a very difficult problem. (Refer slide time: 39:45 -41:03)

And as I said, why is it that it varies in this fashion? There are various reasons for this: one is that you are moving. This mobile station is actually moving.  Now whatever signal it gets, it may get some direct signal, it may get some reflected signal, it may get some scattered signal and all these signals may start interfering with each other. So, actually what might happen is what is called multipath fading. That means, the same signal may have arrived from source to destination through two different paths ? may be through two reflections ? and they may be out of phase because of the different distances, which may be allowed. If they are precisely out of say, 180? out of phase, then you are going to have distractive interference or they may be in phase; they may strengthen each other. So, in a very short span of time, as the mobile is moving, you may find a very largely fluctuating signal. There are other reasons for this fading etc. We will not go into the detail of this. (Refer slide time:41:04-42:21)

So, there is a problem of handoff. So, for the handoff decision there is various algorithms which have been  proposed. I will just mention them. One is relative signal strength, which is the simplest first thing. You will think that whichever is weaker, we leave that, and whichever is stronger it will chose that one. So, choose BS2 if signal from BS2 is greater than the signal from BS 1. But as we saw, with just this, there may be lot of ping pong effect and lot of unnecessary handoffs. You can use this same RSS, that is, received signal strength, and some threshold base. That means we choose BS2 if the signal from BS2 is greater than the signal from BS1 and the signal from BS1 is less than a threshold, which means that although BS2 is stronger, if BS1 is above the threshold, which is still working, then we do not do a handoff. Another thing is RSS plus hysteresis, that is, received signal strength. Just being greater is not enough; it has to be greater by a certain amount of hysteresis. The hysteresis means base1 persists as the BS2 is becoming stronger in base 1 and then there are other kinds of other combinations. People have tried for getting a good handoff decision. (Refer slide time: 42:22-42:50)


As I said, this hard handoff is used in GSM, whereas in CDMA system, they use soft handoff. This is ?make before break? ? that means you make a connection to that coming in the next base station, before you release the connection with the previous base station. So, MS connects to BS2 before connection to BS1 breaks. This is called soft handoff. (Refer slide time: 42:51-43:14)

We will now discuss the merits and demerits of soft handoff. Merits are: mobile station does not loose contact during handoff; the effects of ping pong are reduced; and it is easy to implement for CDMA systems. The demerits are: it is a complex process. So, hardware requirement is more and that means your hardware cost may also go up; and it utilizes extra resource during handoff. (Refer slide time: 43:16-44:22)

[43:16]Now, we come to the question of mobility management.  How do you manage mobility in a local in a MS?  That is because, one of the very fascinating thing about mobile connection.  I have called somebody on the mobile, who I assumed is just local. That is who is in the same area as i am. It just so happens, that he is in a place far away. He is visiting some place.  May be Rajasthan or something. ,as he is very far away. Now  I will expect that the system would somehow locate him in Rajasthan and then allow me to talk to him. So, that is again a non- trivial problem. There are various approaches to this problem. We will just once again touch on this.   So, this is called mobility management. One is location management access point of a mobile station changes as it moves around the network coverage area and important for effective delivery of incoming cells and other is handoff management. We have already talked about it. (Refer slide time: 44:23-45:21)

Now, for location management, one approach through location updates. That means messages are sent by MS that is a mobile station regarding its changing points of access to the fixed network. So, that is to the fixed network, that is sort of time of time it tells that. Ok.  This is where some central database is updated. Each time the MS makes an update to its location a database in the fixed part of the network has to be updated to reflect the new location information. So, that for a particular MS, if you go to the data base and find out what is the last point, where he said, that he was. Of course what he might have done is that he might have switched off his   mobile and then moved to somewhere else and then put it on or something. .  So, put it on again. So,   that is not still solved all the problem 100%.  But this is one approach to solve it. (Refer slide time:45:22-46:26)

The other this thing is the paging. You know what is paging? Paging means that  sort of broadcast it. Well broadcast means broadcast it everywhere. We do not want to broadcast it everywhere. So, you broadcast it only to certain places. So what we do is that, we broadcast that there is a call for such. So, that is what we page and if that paging is being done in a cell, where the MS is actually present and that the MS  will respond, that is what will happen. So, that is another scheme  required to deliver an incoming message to the MS.  Response from the paged terminal enables the network to locate the MS. The other thing about location management is location information dissemination. Procedures to store and distribute the location information related to MS are serviced by the network. that is the issues over. That I am not going detail in any of these, as no time.(Refer slide time:46:27-48:03)

And for the location update, you may do static location update. That means initiation of location update is decided by the topology of the network and location area based location updates which is commonly used.  what a location area is and distance based, which performs location update after crossing certain number of cells or timer- based, performs location update after a certain time has elapsed. So, the question is that how frequently do you update this? Because, if collecting all the data all the time and just updating it all the time, that will consume an enormous amount of resources. You have to optimize somehow.  That this is the point is that if we not doing frequently enough, your data in the database going to stay and then when you want to actually search for somebody, then you might have to search around a large area. Ideally what would you liked is that when a call is there for somebody, we know that exactly in that particular cell that mobile station is there. So, we go and page over there. He responds ok.  That is the idea. But this idea will never work.  Because, you cannot keep it updated on all the time and you cannot collect and keep all the information. So, you have to do some kind of optimization over there, which means that you actually looking for one particular mobile. You have to search not in just one cell, but may be in several cells. So, that is where location area comes in that location. Area is collection of cells, we will come to that. (Refer slide time: 48:04- 49:02)

The other is dynamic location update. It uses mobility of the user and call pattern for location update. So, if you know the mobility of the user and some call pattern etc, you may be able to predict that where this particular user may be. It is more likely that he will be there.  So, it state-based: performs location update, based on the current state information such as distance  travelled, the number of LAs crossed, etc or user profile based, which is more difficult,   not exactly used at the moment maintains. A list of LAs that is location areas that the MS located in at different points of that time usually.  So, usually during office hours I will be found in my office.   In that particular area. So, that may be known and that may be a guess.  But then gathering this information and keeping this information for all users, this is not a mean task. (Refer slide time:49:03-49:58)

So,this is the location area based  location update. So, as you see that a bunch of cells together form a location area.  So, this is the location area 1 containing 1 2 3 4 5 cells. This location area 2 containing 7 cells and so on. So, assign a location area identifier to a group of cells LA 1, LA2.  BS broadcasts periodically LA identifier. So, it is enough to trying to fill a particular cell. You are trying to fill it down to a location area. So, BS broadcast it, whichever location it is in MS is required to listen for LA identifier and make an update to the location if necessary. Drawback is once again,  there may be ping pong effect.  This fellow is moving like this.  So, it going from location area 1 to 2,1 to 2 etc.  That is always the thing. You cannot eliminate this completely. (Refer slide time: 49:59-50:22)

 Location update in GSM. LA identity, that is it takes the location based approach. Identity is used for location updates. LA consists of a group of cells controlled by BSC and MS performs location update under 3 (1).circumstances upon power up, compares previous LA identity with the one currently being broadcast- if different, performs update. (Refer slide time: 50:22-50:52)

(2)When MS crosses LA boundary, performs update. (3)After a predetermined period of time, performs update to ensure MS is available. So that you do all the three things simultaneously. So that would make sort of judgment about, what is this time interval, after which it will go automatically or of course, other two are simple. (Refer slide time: 50:53-51:21))

And then in for paging schemes, you can do blanket paging, that means when you know  the location you just page everything.  All the cells paging in all cells within an LA simultaneously. If the LA update is current, MS responds immediately. Advantage is minimum delay in getting paging response and disadvantage is    it needs paging in all the cells within LA equidistant from the current cells. A timer is used to declare the MS is unreachable. (Refer slide time: 51:22-51:39)

All it could be that closest cells approach. First page the cell where MS was last seen. If not successful, page subsequent rings of cells that are. So, this is all trying to reduce the overhead and give the maximum response time etc.  So,all these different schemes are there. (Refer slide time:51:40-52:52)

And finally we will not go in to the details of these. as i said that, now everybody  want news on their handsets. Not only news they want to access, to the internet through the handsets, which means we will have to give some data service and that is why service providers also move from [Noise]  2G to 2.5G systems wherein from the GSM family.  It,the general packet radio system GPRS and  CDMA to CDMA2000.  So, GPRS is a really ?packet overlay? network that means on the same network, there  is a  packet service, which is going on available frequency bands.  Network on top of the existing GSM digital circuit switched voice based network. So, it is TCP/ IP based. The protocol based  is same as the TCP IP which we will learn later. It allows data packets to be conveyed across the mobile network using packet switching and it is ?Always on?. ? Always connected? type of thing and after initial ?log-on?, user is permanently connected to the IP services, that is the GPRS.   (Refer slide time: 52:54-53:22)

Instant access, no further log on and usually the rates also gives a flat rate. User perceived performance: fluctuates (as GPRS users defer to voice users). So, voice users have a preference. So, because data may delay that is may be acceptable to a maximum of [Noise] 50kbps. Network resources only used when information ready to be exchanged bandwidth on demand.  So, more utilization of air time that is the GPRS. (Refer slide time: 53:23-53:52)

So, this provides high speed frequency.. So, uplink is on the particular frequency band and downlink is on particular frequency band and these are all packet services which provide high speed packet data access. This uses modified GSM hardware (different phones or cards) are required. That is you have particular kind of set that handle GPRS. Several time slots can be dynamically allocated to transmit a block of data. So, if the packet is large, so several time slots may be used for that. (Refer slide time: 53:53-54:25)

The uplink channel is shared by a number of mobiles, and its use is allocated by a BSC, base station stream. The downlink is of course fully controlled by the serving BSC and random access is not needed in the uplink. Of course multiple access will still because, so many people want to send the request for data. The MS requests use of the channel in ?a packet random access message?. The BSC allocates an unused channel to the mobile and sends a ?packet access grant message? etc. (Refer slide time: 54:26-54:49)

CDMA 2000 is once again is the CDMA version of it. Increasing voice capacity. Once again this is always on peak packet data rate of 153 kbps which is quite high. Connectivity to ANSI -41and GSM-MAP, which we need not to bother. Various bands and bandwidths of operation in support of different operator needs. (Refer slide time: 54:50- 55:58)

It is expected that actually that, this  CDMA 2000 1X RTT is backward compatible with CDMA1 system, which was the previous original CDMA system. Improved service multiplexing and QOS management and variable transmission rates and it is expected that in future what is going to happen is that, as data demand is definitely going to grow, so these will sort of move from these interim 2.5G system to the 3G systems. I. CDMA is already being employed.  This is part of our big network architecture.  This converged network architecture, which is slowly emerging and in the next lecture, what we are going to do is that we are going to discuss Wireless networking in the LAN setup.   In the sense purely in this, we are talking about voice and voice added to data. Next, we are going to talk about data and may be data plus wires that is a separate issue. Thank you. 

COMPUTER NETWORKS
Prof. S. Ghosh
Dept. of Computer Science and Engineering
I.I.T., Kharagpur
Lecture Number ? 28
IP Version 4
(Refer slide time: 00:46)
Good day, we will talk about IP version 4 that is the internet protocol version 4. This internet protocol is really the network protocol of the entire stack and actually is at the heart of data communication. As it turned out that it became so successful that also other kinds of communication like voice, video, etc were also coming over to IP in a big way in many segments. So today (Refer slide time: 01:23 - 01:26)

 we will talk about the IP version 4 and (Refer time slide: 01:26 - 02:50)

 just a quick review of the stack that IP or the so called Internet Protocol is designed to connect networks that are possibly managed by multiple organizations or people. The internet we see today is a connection of network of networks. So it is of various networks and various networks are naturally owned by different organizations of people, managed by different people. But if they have to communicate they somehow have to come together and agree to one central network layer protocol and IP is that protocol, it may have different physical connections. Naturally if there are different networks having different connections it may be connected via sequence of arbitrary intermediaries. Arbitrary intermediaries mean that when you are communicating from one computer to another these two networks also may not be directly connected they may go through other intermediate networks. So there may be number of hops before your communication reaches its destination. In the beginning we discussed about layered approach which is used to simplify the application. (Refer slide time: 02:50 - 03:35 min) 

This is just an example. Let us say we have HTTP which is the protocol used in the application layer, it may use a TCP connection. TCP is another layer that is called the transport layer. TCP communicates with the IP which then may communicate with Ethernet. But please note that below the IP there may be a multiplicity of different data link layer protocols like Ethernet and token ring that communicates because of this Integrating Protocol IP which is common to both. (Refer slide time: 03:35 - 03:44)

So it is a single protocol at network level that insures packets will get from source to destination while allowing for flexibility. (Refer slide time: 03:44 - 04:18)
We have the hourglass design like FTP, HTTP, TFTP etc, are different application layer protocols at the top. Then we have the transport layer and their two common protocols namely TCP and UDP. Both integrate to one single network layer protocol namely IP and this IP may connect to naturally different networks running different data link layer protocols. (Refer slide time: 04:18 - 06:30)

 Just to look at the how the encapsulation goes once again, we had discussed this earlier. Suppose we have the user data being fed to some application then that particular application will have its own header. This header information is what is used for protocol between peers at the same layers. The application layer of this host will communicate with the application layer of the other host through this application header information and is passed to the transport layer TCP the transport layer protocol which is being used. Here the TCP header gets added and then it is passed to the network layer when it is coming down and when something is being sent where the IP header gets added at the network layer.  As far as this IP protocol is concerned this entire thing containing the TCP header, application header, user data etc is the payload. Similarly, for TCP the application header and user data together is the payload. So, whatever is inside the TCP does not really consider this. Similarly IP considers this entire thing as the payload and then it sends to the next layer which may be Ethernet as an example. Ethernet adds a header as well as the trailer. Some of the overhead we incur in this, for example, this TCP header is 20 bytes, IP header is 20 bytes, Ethernet header is 14 bytes and it has got a 4 byte trailer and then this entire thing is payload for the Ethernet which has a minimum of 46 bytes - 1500 bytes etc. This is how it comes when data is being sent and when data is being received it is in the other way, the first layer will take out these two headers and trailers, then the IP layer will take out the IP header, look at it and pass it up the TCP header and that will get stripped and finally the user data will reach the application layer. (Refer slide time: 06:31 - 07:38)

By looking at it the other way, suppose we have the Ethernet driver, this is really the lowest level in the tree that has been shown upwards. When something comes to Ethernet it has so many protocols in the next layer but these ARP is the address resolution protocol which is that given an IP address then finding the MAC address, this is the reverse of that as given the MAC address finding the IP address. IP addresses are used for communication within a same network but otherwise most of the traffic comes to IP. Above the IP layer this is TCP, UDP, IGMP used for multicasting and ICMP internet control protocol. Mostly the applications are for control and multicasting functions but the major part of the communication comes through this TCP and UDP and they connect to the various applications which may be running at the application layer and this how it is de-multiplexed. (Refer slide time: 07:38 - 09:51)

Just to summarize this IPv4 protocol IP is the best effort connectionless protocol. that means that the intermediate nodes will try to get your packet to the proper destination as best as possible but if it is not possible it will drop the packet. This does not give you any guarantee about the delivery of the packet at the other end but it is understood that all the nodes in between will make its best effort. Suppose you consider a router which is somewhere in the network now it is receiving packets from so many sources and they are destined to many other different networks. It may so happen that because of the pattern of communication the router may get congested. So if it is congested as there are so many packets coming in then it cannot hold them in its buffer any longer so it is force to drop some packets. Although it will make the best effort but then this is not a guarantee. And then secondly this is connectionless. You remember about connection oriented and connectionless protocols? For example, our telephone network was a connection oriented protocol but here this is connectionless. That means from the source to the destination there is no guaranteed physical or virtual connection between the two. And if you are sending a stream of packets from one source to the other some of the packets may take one route and then some take another route where all of them will reach their destination but they may get out of order. These are all part of the connectionless protocol. With a datagram or packet oriented protocol you can get an IP packet from anyone without any setup or connection establishment. Packets are normally routed using destination routing that means the destination is known and how to get to the destination is what is stored in the routing tables. You specify where the packet is to go now and not how it gets there. (Refer slide time: 09:51 - 10:46)

There are some more parts. You can optionally specify source routing. In Internet Protocol there is a provision that in the source itself you specify that this is the route through which it should reach the destination. For example, if you remember our BGP uses source routing. But in general for internet packets it is possible to do the source routing but this is somewhat limited because the number of hops you can specify becomes restricted because of some limitations of IP version 4 protocol structure. Each packet is routed independently. That means they can be delivered out of order or might not be delivered at all. (Refer slide time: 10:46 - 11:19)

Now we come to this important topic of IP addresses. The IP address is a 32 bit address that is 4 bytes which identifies the network and the host on a given network.  It is divided into two parts, first part identifies the network and the second part identifies the host in the network. The form is not the same if the format is not the same for each address. So this is an important point to understand that when you are given an IP address it is a 32 bit address, these 32 bits are actually divided into 4bytes and each byte is usually read out in decimal separately. You can get a IP address like 144.16.19.23 where this 144 is the decimal equivalent of the binary string which is in the first byte of the address. Then we have 145.16 where 16 is the next byte and next byte contains the decimal binary equivalent of 16. So, if you convert this 144161923 separately into  bytes which are the binary strings and put them together that gives you the 32 bit address.  Or in other words the 32 bit address is usually read out this way. Now in this 4 bytes there is some part which specifies which network you are in and there is some part which specifies which is the host in that particular network. This is the same concept when you think of a postal system where you give the name of the town and then the name of the street or the house. But the people outside will not really know about the streets in a distant town. They will just look at the town name or the pin code and just simply send it there. Then those people will figure out as to where is that particular house or street in that particular town. So we have a network part which is usually important for people who are outside who are trying to route into this network, and then there is a host part which is important within the network. So once the packet has reached this particular network then it has to reach a particular host so this is where the host part comes. (Refer slide time: 13:42 - 14:26)

 There are three types of addresses in one sense. There are other classifications also. But one is that, it is for unicast communication. Unicast means it is destined for a single host, So, it is originating somewhere and is destined for a particular host. Otherwise there is broadcast communication which is destined for all hosts on a network. In a particular network if you want to send some message to everybody then you can use this broadcast communication. Or there may be multicast communication which is destined for a set of hosts. This is a subset of hosts which are in that particular network which belong to a particular multicast group. So, that is called multicast communication. (Refer slide time: 14:26 - 15:18)

As we have already seen, the 32 bit number is represented in the following format. It is actually something. something. something. something where xxx is the decimal representation of the binary bit string. For example, 144.16.7.4 so if you see the first byte it has got a place value of 128 + 16 which makes it 144. This is the binary equivalent of 144 or 144 is the decimal equivalent of this. So this is the IP address 4 bytes of it and the corresponding decimal equivalent of each of the bytes is given 144.16.7.4. So this looks like a valid IP address. (Refer slide time: 15:19 to 20:51)

 As for another classification of IP addresses, IP version 4 has five classes A B C D E where all class A addresses start with 0 so it has a prefix of 0, class B has a prefix of 10, class C has a prefix of 110, class D has a prefix of 1110 and class E has a prefix of 1111. So you can see that they all have unique prefixes and by looking at it you can make out what it is. Irrespective of what values are here you can make out which class it is.  An IP address contains two parts, the first part is the network ID and the rest of it is the host ID. Now just consider the class A address, the first byte is given to the network ID and of course of the first byte the first bit is 0 indicating that this is a class A address and then you have 7 bits left for network ID. So you can have at most 127 or 126 networks as a class A because we only have 7 bits to represent it. And in each of this network the host ID has 24 bits for specifying the address of the host in that network. So for 24 you have actually 224 which is about 16 million. If your organization has a class A address which is very unlikely but if your organization does have a class A address, then this is one big network of that 127 networks world wide which has as many hosts as there in the network and how many hosts can be there? For the host address we have kept 24 bits which means that there can be a possibility of 224 or about 16 million hosts so there could be a network with 16 million computers in it. Nobody has such a big network and this is very unlikely to happen. This is how a class A address is specified. Next we go to class B which is in the same way but here instead of 1 byte for specifying the network we have 2 bytes for specifying the network. Out of these 2 bytes the first 2 bits are 10 so that is already gone and the rest 14 bits are for the network ID. So 214 is about 16,000, you can have 16,000 different class B networks. And each network can contain 216 hosts which is about 64,000 hosts so these are also fairly big networks. There are networks which are of that order but you have only 214 or 16,000 such networks but you cannot have more. For class C 3 bytes are given for the network part and only 1 byte. So a class C network can have only 28 that is 256 hosts that is a real small network but you can have a large number of them namely you can have about 2 million such networks 221. Class D is for multicast group and class E is really experimental so they start with 1110. So after 1110 the entire 28 bits is for specifying which group. But this does not work very well so we will come to that later on. So if class A ranges dotted quad so A is 000.0.0.0 of course all 0s is not a valid particular address but anyway we are giving the outer limits of it to 127.255 etc. So by looking at the first decimal number which corresponds to the first byte we can immediately make out whether this is a class A, class B, class C or class D etc address because class A address cannot be more than 127 and if the first digit or the first decimal number is less than 127 then you know that this must be a class A address. If it is from 128 to 191 then you know that this is a class B address and so on. So, by looking at the first decimal number which is the equivalent for the first the first byte is being dictated this way depending on the class of the address. That is how they come to a particular range of numbers. So, by looking at the first number we can know which class of address it is. (Refer slide time: 20:52 - 21:21)

So this class A is obviously used for very small number of networks and large number of hosts.  First byte represents the network address and the last three bytes represent the host address. Class A address have a first bit of 0 and class A network addresses range from 0 to 126 and 127 is actually reserved for something else. (Refer slide time: 21:21 - 21:49)

 Class B provides an equal number of networks and hosts. First 2 bytes are network address and last two bytes are host addresses. First 2 bits of a class B addresses are 1 and 0 so you can only have 16,000 such class B networks and network addresses range from 128 to 191 that is the first decimal number for the first byte. (Refer slide time: 21:29 - 22:03) 

Class C is a greater number of network addresses, fewer host addresses, the first 3 bits are 110. So network addresses range from 192 - 223. (Refer slide time: 22:04 - 22:11)

 Class D is used for special multicast addresses. The first 4 bits of Class D are 1110. (Refer slide time: 22:12 - 22:21)

Class E is used for experimental purposes. The first 4 bits of Class E are 1111. (Refer slide time: 22:21 - 25:42)

There are some special source addresses as part of an initialization procedure for example bootp. This host on this network, the net part is 0 and host ID part is 0. That means when the net part is 0 depending on which class of address it is and suppose it is the class C address then the first 3 bytes are really the network part so it will be 0.0.0 and the host part is 0. So if you say 0000.0.0.0 it means that it is itself. So this is sometimes required for example in bootp protocol you require referring to yourself. Specified host on this particular network: So you keep the network part 0 and the host ID for this particular host that you want to specify, suppose this is a class C address, the host part is given only by the last byte. Suppose the last byte has a decimal value of whatever maybe 130 or something. So if you say 0.0.0.130 that means whatever the network I may be in, in this particular network get me the host number 130. It is a specified host on this particular network wherever it is. Loop back address: The loop back address allows applications on the same host to communicate using TCP IP.  Here the net ID is given as 127 and host ID could be anything which means the first byte is all 1 that is the loop back which is referring to this particular host. Why do you require this? Suppose two different applications are running on the same host and they want to communicate with each other using TCP IP. But why do they require TCP IP if they are on the same host and when they could communicate directly? The point is that these two applications could have been hosted in two different hosts also. If this was the case then they would have to use TCP IP. So instead of writing two different versions, one for the case where both of them are in the same host and the other in two different hosts you write the same program and use the same TCP IP stack. The only thing is that you want to refer to the same host. If you are trying to refer to the same host using the same TCP IP how would you know the network address and so you would not be interested to include a hardware into that particular application. Therefore there is a way to refer to the same host which is by using 127 that is all 1s in the first byte. (Refer slide time: 25:43 - 28:41)

Then we were talking about three different types of addresses for unicast, broadcast and multicast. We have seen about unicast communication that is the network part and the host part, both you indicate and then you are talking to that particular host. We have seen multicast in class C addresses and mostly in class D so that was a multicast group. And then now you talk about broadcast. But here there is a caveat. In the sense that you are not allowed to broadcast to the whole wide world because if everybody or even a very limited fraction of people start broadcasting some message to everybody in the world then the entire network will be swarmed with broadcast because now in this age of internet millions and may billions of people are getting connected to the internet, So if only a small fraction of them want to broadcast things to everybody that cannot be allowed because then the entire network will go down. So broadcasts are always limited and how they are limited and how the broadcast addresses are specified will be discussed now. Limited broadcast typically used for initialization only appears on local cable or collision domain with net ID is ? 1 that is all 1s and host ID is all 1s. This means that if you give an address which is all 1s it means that you want something to be broadcast in the local network wherever you are in. The net directed broadcast means you want to broadcast to a particular network. So this is forwarded via router. Now that particular network has to be mentioned so the network address part is to be specified giving the net ID, the host ID is all 1s so all 1s means to every body. But if you put all 1s in network part as well as all 1s in the host part it cannot mean that all networks and all hosts in all networks, that is not allowed. All 1s in the network part as well as all 1s in the host part means that it is for all the hosts in this particular network. And then there could be subnet directed broadcast. We have not talked about subnet as yet which we will do. There will be a subnet ID which is really carved out of the host part of the address and then host ID part will be all 1s. (Refer slide time: 28:41 - 29:14)

 So all 0s means this host and all 0s in the network part and the host part is something specific which is like a particular host on this particular network. All 1s mean broadcast on the local networks. If the networks part is specified and if host part is all 1s it means that broadcast is on a distant network. If it is 127 then it is all 1s on the first byte and anything in the rest of it is a loop back. (Refer slide time: 29:15 - 34:10)

Now we come to a problem. A few companies got class A like Xerox and some other companies got a class A address when they were actually very closely involved with designing internet in the Arpanet days so people really did not know who designed this network and had no idea that their project is finally going to blossom so wildly and become greatly successful. They had no idea that they had to be careful with all these addresses that they were doling out so the companies which came in got some class A addresses. These class A addresses can have 16 million hosts which is really much bigger than anything that a company might want. Many institutions got class B networks such as 12 institutions. For 14 bits you can have only 16,000 so it is not such a big number when you are talking about in the global scale so 16,000 institutions and may be 126 companies over there is really a small number. But now-a-days there are millions of companies and ripped hundreds of thousands of companies who want to have their own network etc. They are now reduced to accepting only class C address. Class C address is too big because you cannot have 16 million hosts but a class C address can accommodate only 256 hosts but 256 is a very small number. Any institution or many institutions now-a-days have got thousands of computers in their network so this too small for them. For the first one let us think of another problem. Suppose you have a class B network where you have 10,000 nodes now if all these 10,000 nodes is one network, the network in our parlance at this particular moment is one particular broadcast domain, so you can always broadcast in this network. If you are sitting in one particular network and you communicate to some other node in that particular network then you need to know his MAC address which you do not know but you know his IP address so what you will do is you will broadcast the IP address asking for the MAC address. Now whichever machine has got that particular IP address you will get it and answer with his MAC address and that is how the ARP protocol works.  So whenever you try to communicate if you do not know the MAC address of the other side naturally you will send a broadcast to the entire network. Now if all these 10,000 hosts start sending broadcast messages from time to time then the broadcast traffic would be too much. Since the network is so big we have to break it up into smaller parts so that broadcasts are limited to smaller sub networks for which you need some more bits. Previously we were talking about the two parts of the address, one is saying this network and then we are saying this host in this network. Now we have to say three things; it is this network, this particular sub network in that network and then this particular host in that sub network. It is just like instead of a town if you have a city then in a city there will be a large number of post offices in the same city. From outside may be from another country they will send it to that particular city and in the city you will decide this is that particular post office in that city and that particular post office would know that it is for this particular house on this street in this region. So we have a network, a sub network which is the breaking of a big network into smaller sub networks and then we have a host in that particular sub network. So, as we have said that broadcast would enter a network obviously it is impractical for class A networks and even for class B networks. (Refer slide time: 34:10 - 34:29)


So subnets are used to divide a large network into smaller networks. Each address allows for one network address and many hosts that is, all hosts are on the same network. Subnet masks are used to create many subnets within the same network address. (Refer slide time: 34:30 - 35:32)

 So we will look at subnet masks. This is a bit string applied to an address. If the bit is 1 the corresponding bit in the address is considered to be a network bit. The network mask is known only locally. If we have one part which is the network part and the next part which is the host part then we take some bits from the host part and use them for specifying the sub network.  The number of bits of the network which you take for the sub network is given by the subnet mask by placing those particular bits to be 1 and this subnet mask is known only locally. (Refer slide time: 35:32 - 36:55)

 So this is an example. Suppose we have a class B network, in a class B network you know that the first two bytes is the network part and the other two bytes is the host part. Now in this host part these 6 bits will show my sub network address. So you make the corresponding bits in the network mask to be 1 and the rest are all 0s. The host part are all 0s, Now, looking at the address we will know whether it is a class A, B, C just by looking at the first number and we know how much is the network part. If we know the subnet mask we know how much is the network and sub network part. If we take out the network part from that we get the subnet address here. Actually this not the address, the masks only tells you that these are the bits which are used for the subnet address and the rest of it is for the host address. We will see examples of this. (Refer slide time: 36:55 - 39:07)

 Let us say we have an IP address 144.97.16.132 that is the IP address of a particular host. And we are also told that we have a subnet mask of 255.255.255.192,1 etc. These are all for only human communication but of course these are all individual bytes which are to be converted to the corresponding bit strings. The 255 are all 1s in the byte so all 1s and 192 is 128 + 64 which means the first two bits are 1 and the rest is 0 so this is subnet mask. Since this is the class B address we know that if you convert 144.97.16.132 then this is the string you get 144. So the first two bytes is for the network part. Now we also know that the 8 + 10 bits are for the sub network part. So this is the sub network address 0001000010 and the host is 100 part. So the network part is the first two and then the sub network part 000100 so this is the entire network part wherever we have a 1. And beyond that the point where we have a 1 we put all 0s for the network address. So network address is 144.97.16.128, the 144.97 is telling me which particular network it is and 16.128 is telling which particular sub network is within that network. And the host is this 100 so the host is 4. Let us just see another example. (Refer slide time: 39:08 - 39:57)

 So we have this IP address which is 144.97.17.132 and the subnet mask is this. So we see that the first seven bits so the network has been broken down into 127 different networks and then we have 9 bits for hosts so we can have may be 512 hosts in each network.  This is the network part up to this one so we take all the 1s there and the rest are put as 0. So network is 144.97.16 and host is 1.132. (Refer slide time: 39:58 - 40:53)

So how do packets get to the other end? Select router based on the IP address. That is, for class B use the upper 16 bits as a network specification, for class C use the upper 24 bits as network specification and so on and naturally for class A just look at the first 8 bits. Route to that network using the routing tables as we have seen. So depending on whether it is a class A, class B or class C you use 1 byte, 2 bytes or 3 bytes as the network address. Route to that network using routing tables. If your routers, RIP or OSPF etc is working properly then it will reach that particular network. The point is, what happens after that? (Refer slide time: 40:53 - 41:36)

Then the router uses the pre-specified subnet mask to select a subnet because looking at the subnet mask and at the IP address it knows how many bits are there for specifying the subnet. So it finds the subnet mask and it just takes out the subnet part of the address which is looked up in a subnet routing table. A subnet routing table is consulted and traffic is directed to that particular subnet. So this gives you a more hierarchical structure and ARP broadcasts are contained within the subnet. If you reach that particular subnet then the host number is given and you can go to that particular host. (Refer slide time: 41:37 - 46:14)

Now, we come to the other part of the problem. As I mentioned class A is of course huge, class B is also very large so we have to break them up into the subnet. The other side of the problem is that, the class C address is very small. The other thing to note is that the network has grown so much. There is a tremendous demand for IP addresses. This IP addresses have to a global standard. You cannot have your local standard because other people would be looking at your address may be at a different corner of the globe and try to route packets to you. So these addresses have to follow a global knob and that was used to be controlled by one central body. Now, if you have to give the address to somebody then you have to give internetwork address for his particular network usually. And now this creates a problem in the sense that when the demand for these addresses becomes too high you run out of addresses. As a matter of fact we have come to a stage today where for all practical purposes we have run out of addresses. Now you only have a few class C addresses left. If we had been much more careful, if we could have envisaged how the networks would grow and if we had been much more careful earlier in assigning addresses and not waste big addresses like that may be we could have stretched this for by a few more years. But anyway this cannot be helped now. So people are working on various types of solutions to overcome the shortage of IP addresses. And the other side was that quite a number of years back people worked on a new protocol, you must have noticed that this lecture is titled IP version 4 possibly implying that there are other versions available and actually there is IP version 6 which was finalized quite a few years back. Anyway in the IP version 4 we have this problem, what are the various kinds of workarounds? One thing could be, if you take a big address chunk let us say class B address and give it to different organizations may be some parts of it, the one problem is that, first of all you are breaking down these classes class A, B, C at the byte boundary. So the point was that do not have them at the byte boundary so they no longer belong to one particular class, they are called classless. And classless interdomain routing that is the CIDR is the protocol which is there where you specify your starting address and then specify how many hosts you have in your particular network, so this is an example. Suppose some British Universities like Cambridge, suppose the first address is this and the last address is this that means how many nodes they can have? You can have from 0 to 7 so that is 8 over here and of course 256 on the last byte so 8 ? 256 that is about  2048 hosts. So it gives the starting address 194240.0/21. This 21 is a code which really shows that there are 2048 hosts. Now various such numbers are possible, 22 means 1024 hosts, 20 means 4096 hosts. This way it goes down on one side and on the other side you can even have less than 1024 hosts so various numbers are there and there is a table here. Similarly 19 would mean 8000 hosts and so on. (Refer slide time: 46:15 - 50:57)

There is another workaround people have done and actually many organizations are now doing it and in common parlance it is called NATing that is Network Address Translation.  As I said earlier your IP address has to be known globally, it has to be a global standard, globally assigned. Now, if we make an observation that this is true only when we are communicating with somebody or only when somebody else is trying to communicate with me that is when it needs to be global. So you have an entirely private address and if it is a private why not it be a class A address? So whatever be the size of your organization may be you use a class A address inside. This class A address that you have just to use it without permission means that this address is not recognized globally. Assuming that you are in a big organization you do all your internal communication using this private address. The point is that only when you are going out to communicate with somebody you will mask your private address, keep a temporary table and tat table will be dynamic one, for the time being you want to communicate, dynamically there will be your local address which is actually a private address and not a globally legal private address and you will put it and then you will have a pool of legal addresses. And you will use one of them whichever is free and then start communicating. To the outside world it will be as if you are communicating with this particular legal address which you have assumed for a temporary point of time while you are communicating. So that is called Network Address Translation. Suppose we have this company LAN that is the company router etc and then a packet arrives and suppose this has an address 10.0.0.1 then the first number is 10 which immediately tell you that this is a class A address but really this company does not have A class A address but is using it. And there is a convention that when we use private address some how we use 10. But whenever somebody looks at an address that starts with 10 he knows that this is a private IP address. Therefore this is a private address he is using and this is going through may be a NAT box or firewall. Now this NATing could be done at a firewall. The NATing can be done in the router also and so all these boxes usually come with that capability. So, in the NAT box over here or this firewall maintains a table of this IP address it is trying to communicate, it assigns the pool of IP addresses and out of those IP addresses may be this particular IP address 198604212 is free at the moment. So he will take out this particular address, put in this particular address and send it to the outside world. So the outside world will know the source to be this particular address. When the outside world replies back it will come back here to this particular address, it will go through the same box, the box will know this is really an address which is temporarily assigned to him so he will now take this out, put 10.0.0.1 and send the packet to the particular host in that particular network. So the outside world will know that he is communicating with this fellow whereas this is not really a fellow this is just one of a pool of address which is shared by a large number of hosts and the translation is done here. So that is an example of how NATing is done. (Refer slide time: 50:57 - 52:13)

This is not entirely satisfactory but this is used quite often for example in my organization IIT we have got more than 10,000 machines and we do not have a class B address. You cannot help, so we just have a bunch of class C address. So we assign these class C addresses to all these boxes, we do the NATing and that is how we communicate. One problem is that if the NAT box fails all the connections are lost. It violates the OSI layer independency because this is a workaround and we do not have so many addresses that people demand. Some applications insert IP addresses as a part of the message then of course that application will fail because if the IP address is some how hard coated inside the application message somewhere that is not going to work. And NAT changes the content of the IP datagram, this is incompatible with secured data communication. If you want to do the entire thing secured including your IP addresses where you are communicating this NAT will not work or wherever you are doing NATing you can not encrypt that part. (Refer slide time: 52:14 - 52:30)

IP data is laid out in big Endian order. That means byte transmission order is 0, 1, 2, 3. You know big Endian or little Endian or which way you go 0, 1, 2, 3 1 or 3, 2, 1, 0. So, in networks this is the network byte transition. (Refer slide time: 52:31 - 53:23)

 In this IP header we have version, header length etc and the IP header is 20 bytes or more, it is minimum 20 bytes so this is 4 bytes each so that is 32 bits each. The source IP address is given as 4 bytes, the destination IP address is given so that is another 4 bytes so that is 8 bytes gone. These three batches of 4 bytes each which amounts to 12 bytes are used for various things. Later on there may be some options. (Refer slide time: 53:23 - 54:36)

 This is version 4, then version 6 would be there, bit filled specifying the IP version currently 4. Header length specified in 32 bit words and range is from 5 to 15 words or 20 to 60 bytes. So what is the length of the header? Why do we need the length of the header? If you look at the previous one there could be options, so how do you know whether just after destination IP address the data starts or the header goes some more and more options are exercised? The header length has to be given. The type of service: Some kind of quality in service was expected but this did not work out very well and is mostly ignored now. Then the message length is in bytes. The datagram identification field must be unique. So there is a datagram identification field, 16 bit packet identification. We will talk about it when we talk about Fragmentation. (Refer slide time: 54:37 - 56:49)

Time to live field: Upper limit on the number of hops that a message can go before being dropped. Although this is called Time to live, actually this is given by the number of hops and why do you require that? Sometimes the routers work in a distributed fashion as we have seen in this RIP and other protocols that they work in a distributed fashion and there may be some problem somewhere. Now because of that problem you may get a routing loop. That means virtually since this loop is stored in a distributed fashion nobody really detects that there is a loop but actually one particular packet finds that this has gone in a loop. Now this packet if it does not die out naturally it will keep on circulating at infinitum and such packets will get accumulated and it will bring down the whole network. So there is a mechanism and there are other reasons for this of course. But there is a mechanism that if a packet has gone very much astray or if it is just circulating after some number of hops the router will see that it has already crossed so many hops and this is the time to live and the time to live has come down to 0 so drop it. Otherwise you just reduce the time to live by 1 and send it to the next hop. Now there is a protocol which identifies TCP, UDP or ICMP. You remember that this is on the network layer. Now above the network layer there is a transport layer. IP is a hourglass design which sort of concentrates on the IP from the various different types of networks like Ethernet, token ring etc. It also comes to IP, from IP it goes to various different protocols like TCP, UDP and so on.  Now in the network layer how does it decide where to go to, whether to send it to TCP in transport layer or whether to send it to UDP in the transport layer, so that must also be mentioned. So this protocol identifier is there whether it is TCP, UDP, ICMP, IGMP etc. Header checksum: Checksum of just the TCP, IP header that is this IP header and source address which is 4 bytes, 32 bits destination address another IP address this is again 32 bits and options. (Refer slide time: 56:48 - 57:45)

Data starts at total length that is the header length etc and maximum IP datagram size is 64 kilo bytes. Hosts are not required to receive packets greater than 576 bytes. That means at least 576 bytes they have to accepted. Ethernet, MTU is only 1540 bytes. So most implementation allowed is about 8000 bytes for IP datagrams. The point is that when a particular packet has come to a network the packet may be too large for that particular network to handle, so then something has to be done. One thing is of course to drop it but if you drop it then every time he wants to send the packet the packet will get dropped. So what is done Is, this packet is broken down into smaller parts called fragments and these fragments are then sent through the network. In the next lecture we will talk about the IP version 6 and mobile IP.   
PROOF
COMPUTER NETWORKS
Prof. Sujay Ghosh
Department of Computer Science & Engineering
I.I.T Kharagpur
Lecture No: 29
IP Version 6 & Mobile IP
(Refer slide time: 00:00 - 00:40)
Good day, in the last lecture we discussed about IP version - 4 [IPV4]. That is the version of Internet Protocol that is now ubiquitous in the sense almost everywhere it is used. But as this particular version became more popular than its originated thought then some problems about IPV4 came into focus and people started discussing about what is the next generation of Internet Protocol that would be there and after a lot of discussion etc people came up with this IP Version 6 [IPV6]. (Refer slide time: 01:30 ? 01:37)

We will be doing a little discussion on IPV6 today. In the later part of the lecture we will be talking about mobile IP. (Refer slide time: 01:38 ? 01:37)

What was the design goal? As I mentioned, IPV4 was very successful, but the limited addresses posed problems. This was discussed earlier as how people are trying to fight with this problem using NATingnetting etc because so many machines are coming into the network these days and not only machines but in certain cases people are actually deploying all kinds of gadgets which should be connected to the network. If something is connected to the network and accessed from anywhere on the internet then it has to have an IP address. The pool of IP addresses we have in IPV4 is very limited and this is one of the major problems. (Refer slide time: 02:34 ? 02:47)

 And the second problem is, as mentioned earlier, the routing information were not inherent in addresses. For example, in a postal address, we have the Pin Code and in the pin code if the first digit is 7 then immediately we know that it is towards the East. If the first digit is 1 immediately we know that it is towards the North. So just by looking at that you can simply send the material to that direction. But that has not been so because these IP addresses although they were based on networks which are larger chunks than hosts they were distributed but then this could not be maintained at that time. If you could have some means of geographical information inbuilt into it then routing becomes easier and the routing table becomes smaller. Therefore, if the routing table is smaller routing speed becomes faster and so there are many advantages. (Refer slide time: 03:43 ? 04:07)

Thirdly, experience had shown that some aspects of IPv4 were problematic like Option headers and fragments etc were problematic then some type of service [TOS] which people never never used, options also have a very limited utility because of its limited size and fragments was a problem. These were the basic issues. (Refer slide time: 04:08 ? 04:21)

The simplification for IPV6 as mentioned was that to move to a 128-bit address. From 32-bits if you remember that IPV4 has as an address size of 32-bits whereas this is 128-bits. So in IPv4 in a theoretical maximum it is 232 (of course it is less than that but anyway the theoretical maximum is 232) addresses. Whereas here it is 2128 addresses which is a very huge number. Even, if all the devices and computers you can think of are connected and given individual address space then also you will have a huge number of addresses to spare. This was done with the idea that we are not going to run into this problem of limited address space ever. The other point is, if you have so many bits, as I said that even after assigning numbers to all the devices and computers you will be left with some to spare so that can be used more intelligently. (Refer slide time: 05:15 - 05:25)

Second point was to assign a fixed format to all headers. In IPv4 also, the essential part of it, the initial part of it, the compulsory part of it is fixed. But there are options and these options could be of various sizes so that is also removed. (Refer slide time 05:37 ? 06:01)

Remove the header checksum which was not doing much anyway. Use extension header rather than options. Options were removed and we came to the concept of extension header that means headers followed by other headers, we will come to this later on. Remove hop-by-hop segmentation procedure. That means you do not segment it somewhere in between a packet that is traveling and then somewhere in between you try to fragment it. However, that was not a good idea, and because of this fragmentation you have to keep the fragmentation number, the packet identification etc so all these are removed although fragmentation can be handled in some way. We will talk about that later. (Refer slide time: 06:23 ? 06:44)
  
This was the original IPv4 header which we have already discussed like version header, length, type of service etc. This Type Of Service [TOS] was not very useful. Fragments etc came in because we allowed fragmentation which is not done here. Header checksum may go out but the source and destination IP addresses would be there. Let us come to the IPv6 Header. (Refer slide time: 06:45 ? 07:09)

IPv6 Header is actually much simpler than the IPv4 Headers. We have a few fields and then the source address. Assuming that this is 32, previously IPv4 address was only one line but now you have four lines i.e. 128-bits for source address and 128-bits for destination address. Let us look at the fields. (Refer slide time 07:10 ? 07:27)

One is the version number. Previously it was 4 but now it is 6. Class: This is used to assign service class for real time networking. If you are doing some real time networking that can be indicated here. Then, there is a field called Flow: If you  quickly look at it we have version, class, flow level. (Refer slide time: 07:28 ? 07:32)

Flow: Flow means given one particular source and another destination then for this particular source and destination pair there is a flow level. Flow means these two are likely to send large number of packets and all of them would belong to the same flow. This is not a virtual circuit identifier like ATM because in ATM the virtual circuit identifier and intermediate switch would just look at the virtual circuit identifier and switch it that way.  This is not for that purpose at all rather this is for treating the packets with a particular flow level from a particular source and destination in the same way where all packets belonging to the same flow level in the intermediate router. For example, there may be class of service or all kinds of quality of service requirements for one particular flow that may require bandwidth reservation in between. Therefore such things can be handled using the flow level. (Refer slide time: 08:45 ? 09:31)

Payload Length: Only include the payload and not the 20-byte Header. This is 16-bits for that so packets are once again less than or equal to 64 k. Next Header; This gives rise to the possibility that there may be more than one header. If there are not any more IPv6 Headers then, at least the higher layer headers like TCP or UDP Headers could be there. There is a field called Hop Limit. This is really the TTL (Time to Live) which was present earlier in IPv4 but was used to just keep the count of the Hop and this is just renamed as Hop Limit. (Refer slide time: 09:32 ? 10:12)

 Fragments: One of the lessons we  learnt in IPv4 was that the unit of transmission should be the unit of control so no fragments created en-route in IPv6. If message is greater than MTU the Maximum Transferable Unit then you get ICMP message which is an Internet Control Message Protocol. We will talk a little bit more about ICMP later on. But this is some kind of control message which may be sent by a router to host etc. So, an ICMP message should use the path MTU. Let us see what is meant by this MTU and path MTU and how do you avoid transmission, Suppose you are the source and you want to transmit a particular packet it so happens that en route it encountered a link where such a big packet cannot be accommodated. In IPv6 what this router will do is that it will drop the packet and send back an ICMP message saying that this MTU is so much which is for the next link. Now you will reduce your packet size at the source itself and try to send it again. But now it will definitely cross that particular link, it may get struck again in another link so again an ICMP message will come back but finally you will come to size of packet which will go through all the links. Now this is your path MTU.  Now you can go on sending all your communication using this particular packet length and it will not be fragmented in between. (Refer slide time: 11:17 ? 11:36)

This is a way to fragment a datagram but it is done in an end-to-end fashion. It may so happen that for some particular application all these smaller packets we have made should actually be made into bigger packets. So this is fragmentation in some sense so far as the application layer is concerned so there is a way to indicate that, there is a header for that. (Refer slide time: 11:46 ? 12:29)

Finally we have removed the options from the IPv4 Header and we have come to this Extension Header. That means there may be more than one header. We could have this situation that IPv6 Header and next Header is said to be TCP. The Payload is the TCP Header and Payload itself. It could be that IPv6 Header, the Next Header is a Routing Header, which again is an extension header for IPv6 Routing Header and the Next Header is TCP so the TCP header and payload comes here. So there may be more than one IPv6 Headers and Headers are of different types. (Refer slide time: 12:29 ? 13:01)
   
Intermediate routers do not need to look at the Headers unless we tell them to. Specifically it has to look at some Headers but can ignore few other headers. It does not need to process all the information it should be fast. Extension Headers and Protocols, for example, TCP shares the same 256-entry name space i.e. 256-entry name space for the Headers. Hence there are limited number of extensions but this number is a big enough. (Refer slide time: 13:02 ? 13:33)

There is a certain order suggested that these Headers should occur in one particular order. One is, IPv6 Header the main header we talked about, An And the Extension Header called hop-by-hop Header, Destination Options Header, Routing Header, Fragment Header, Authentication Header, Destination Options Header, Upper-layer Headers if any that means TCP or UDP. Let us quickly discuss a few of them. (Refer slide time: 13:34 ? 14:21)

Payload may be encapsulated,payload followed by the Transport layer Header. Then there is a TCP, then a Routing Header, Authentication Header, another two Routing Headers, then IP header and so on. What you do is that you peel them one by one so that one Routing Header is peeled of because the Routing Header gives you information about how to route the packet something like source routing so that is peeled of may be in the next hop and this goes out. The IP Header remains and the routing header authentication header etc remains. You peel out one Header after another and finally you get to the TCP and the payload. (Refer slide time: 14:22 ? 14:38)

Naming: A large part of the address space is unassigned. This means, at this point of time people thought it prudent to keep provision for some future requirement which we cannot envisage at this moment. So a large part of the name space is simply been kept unassigned. (Refer slide time: 14:55 -15:08)
 
There is a way now to move away from provider based routing, based ID?s  the two routing based ID?s although both are possible. Previously what would happen is that the service provider would take a chunk of IP addresses and it is for his network. Now this could be distributed in various places. So, provider wise this loses the destination information. Whereas if you had done it geographically the routing would have been much easier, the routing table will also be smaller. IPv6 keeps the option of both. So you can have provider based addresses and also geographic based addresses. There are various levels of aggregation like top-level aggregation which is essentially a hierarchical organization reflecting the current internet architecture. (Refer slide time: 15:56 ? 16:09)

Then the Next Level Aggregator, then Site Level Aggregator allocated to a link or a link level or site level aggregator that is local. This means, at the link of the site level the rest of it may be common. It does not matter because it is strictly for local use that is something similar to a private IP and not for communication with others. (Refer slide time: 16:15 - 16:20)

The interface ID is based on EUI ID, the extension of the Ethernet MAC address and even that can be embedded. (Refer slide time: 16:29- 16:59)
 
There are some unspecified addresses. We need not bother about all this because IPv6 as of yet is not been deployed much. Only thing I would like to mention is about any cast. We have talked about Unicast, Broadcast and Multicast. Any cast is a concept something similar to multicast but in multicast there is a group where you can send some message to all the members of the group. In any cast you can send any message to any member of the group.  (Refer slide time: 17:15 ? 17:41)

Let us look at some of the Routing Extension Headers. It has the next header. a Header length, a routing type etc. Now we have some address 1 to address n. There are some IP addresses, IPv6 addresses may be listed over here. (Refer slide time: 17:42 ? 17:55)

It plays the same role as source Routing Header. You remember that, in IPv4 options there is a way to give the routing from the source. That means you determine the routing from the source itself.. Such a facility is very important for protocols like BGP because BGP wants to dictate the route through which the packet should be routed. But the problem with IPv4 was that the Header length was very limited so you can go only up to a dozen or so may be 12 to 15 hops in the source routing. If it is beyond 12 to 15 hops you would run out of space in the header so you would not be able to specify that. Here you can have a routing header then you can have more than one routing header and this particular difficulty is obviated. (Refer slide time: 18:42 ? 18:54)

Basic idea is, when a datagram reaches a destination, the destination checks for a Routing Header. If there is at least one segment left, that address is copied from the routing header and the packet is forwarded to that address. (Refer slide time: 18:55 ? 19:17)

Otherwise, the routing header is removed and the next routing header is processed. You can have multiple routing headers if the 8-bit header length causes a problem. There is a Header length of 8-bits so you can go up to a length of 256 but then you can have multiple Routing Headers. You can specify other source routing nodes using type. (Refer slide time: 19:18 ? 19:46)

Fragment Header: Each Fragment routed independently. Identification identifies the original packet that was fragmented. The offset is the offset within the fragment. The M field is a more fragments bit and is set to one for all but last fragment. This is exactly similar to the way fragmentation was handled in IPv4. The difference over here is that the source sends it using the path MTU that means in the in between it is not fragmented and whatever fragmentation is done is done at the source and that information is carried in one header called Fragment Header. And those would need not fragment anything they will not use this header. So, all these extension headers are optional. You have to have the first IPv6 Header but all the extension headers are optional. Therefore, if you are not fragmenting then you will not use this header. (Refer slide time: 20:23 ? 20:39)

There is a Destination Options Header: When a packet reaches its final destination (or at least when all prior routing extensions have been processed), the destination options header is processed. So as an option the unknown options are discarded. (Refer slide time: 20:40 ? 21:23)



Hop-by-Hop Options Header: This is another one. The Destination Extension Header is looked at just at the end at the destination. In the hop-by-hop all these at intermediate hops you need to look at this hop-by-hop options header. They are processed at each hop, For example, the Jumbo payload header. The IP header length is 0 and the jumbo option encodes the true length as a 32-bit value. This is an option that you can have a very big packet traveling down. It is also used to mark spanning trees for multicast and real time protocols etc. There may be things that you need to do at every hop. (Refer slide time: 21:25 -21:56)

Security is another area that was in focus. Security Association: We will talk about network security etc at length later on. There is a way to put authentication and encryption requires that senders and receivers agree on a key for encryption and decryption. And authentication or encryption algorithm, and set of ancillary parameters such as the lifetime etc. This is called security association. (Refer slide time: 21:57 ? 22:17)

Now, you have an Authentication Header where the security parameters may be mentioned namely the sequence number field, next Header, length and reserved. The SPI is selected by the receiver and is used to describe the security association where everything is normally negotiated during the key exchange. (Refer slide time: 22:18 ? 22:53)

There is Encrypted Security Payload. Headers entirely cannot be encrypted because then the intermediate routers will not be able to handle it. The last unencrypted header in the chain, this is an Encrypted Security so there would be encrypted data and authentication data, Also the ESP (Encrypted Security Payload) Header ESP header will be there. ESP Header also includes authentication to prevent tampering with encrypted data. We will talk in details about security in a later lecture. (Refer slide time: 22:54 ? 22:58)

To conclude this discussion about IPv6 this is really one scheme where people will not be running out of IP addresses. Then a funny thing happened in the sense that many of the hardware vendors like routers etc rather modified their design in order handle IPv6. However, actually what happened was that everybody is waiting for all others to switch from IPv4 to IPv6. When you switch you may have problems with some of your software or a lot of your software. If you only switch over to the other version that would not do because the rest of the world will still go with IPv4. You can still operate it through some bridge, through an IPv4, IPv6 etc but then nobody wants to do it unless other people are doing it. That is how everybody is held back for quite a few years. But one thing is that if there are ubiquitous kind of networking, in the sense that, not only your computers but all your devices like refrigerator, TV and Air Conditioner and everything in the house is networked then we will require a huge number of network addresses. Then people will not have any option but to actually make the move. Right now everybody is sort of waiting for other people to make the move. Next, we will come to the topic of mobile IP. What is mobile IP? Mobile IP means, now there are many network attachable devices.  It is not only the laptop computers people are carrying everywhere. Even apart from laptop computers there can be all kinds of devices including hand held devices which can be connected to a network. Now what is the problem if all these mobile devices are connected to the network? There is no problem as such, whenever you go there have to be some way in which a physical connection is made. That connection may be wireless in the case of mobile. The wireless connection is very attractive but otherwise you may go to some other place and actually connect a wire over there, it may be wired also, Although wireless is more dominant but the trouble is what happens to the IP address?. Your device has a particular IP address and that would have worked fine when you were at your home base. But you have moved from your home base to some other place. Now, if somebody wants to talk to you he will be using your IP address and that is what he is familiar with. For example, all the name servers etc will have the IP address corresponding to the URL if you have a URL and that is not going to change. They are going to try to use your old IP address but by using your old IP address they will land in your  home network where you are no longer available. This is the problem of mobile IP. When a particular network attached device moves from one network or one sub network to another network then how would you keep communicating? That is the problem of mobile IP. (Refer slide time: 25:36 ? 26:59)

These are the problems as I just now discussed. Nodes in the Internet are identified by specified IP address. Routing is performed using that same IP address. When a node?s location or attachment changes then routing will not work with the same IP address. That is a simple point (Refer slide time: 27:00 ? 27:18)

What are the alternatives? One is that, the node must change its IP address whenever it changes its point of attachment. It requires upper level protocols to handle address changes, that is one problem. This means, if it is to be made automatic then it has to be automated by a higher-level protocol which really sort of violates this layered architecture, that is one point. More importantly, what would happen is that the others who want to communicate with you know your IP address. They do not know that it has changed in the meanwhile so they would still try to communicate with the old IP address. (Refer slide time: 27:43 ? 28:54)

The other thing was that, Host specific routes must be propagated through the network. This is another possibility because from your IP address if somebody is trying to contact you from outside he first looks at the network part of the address and allows them into your network, then within the network, you have this ARP and other protocols to help you to get the MAC address and reach you directly. So the routing table essentially keeps track of all the networks as many as they can depending on what size the router is. The big routers keep track of many networks, the small routers keep track of only a few network addresses. If these entries were against Host then the routers might dynamically change their entry etc and route it directly to that host. However, even handling so many millions of networks is becoming a problem so handling billions of hosts in the routers is simply out of question. The solution to this is to use another level of indirection, that is what we do in mobile IP as I have just now shown. (Refer slide time: 28:55 ? 29:00)

Mobile IP Design Goals: A mobile node must be able to communicate with other nodes after changing its link layer attachment. Changing its link layer attachment is changing the attachment to the network or sub network to which it was originally attached yet without changing its IP address where its IP address remains the same. This is the problem. A mobile node must be able to communicate with other nodes that do not implement mobile IP. This is the other requirement. It means, you may do something very sophisticated and special in your hand held device but the point is that still it should be able to communicate with millions of other hosts who do not have any special arrangement for communicating with mobile IP. Therefore, you cannot do anything on the other end. (Refer slide time: 29:49 - 31:39)
      
Another point is that, this is a sort of security concerned that mobile IP must use authentication to offer security against Redirectment Attacks. The point is, when you are in your own network you can try to authenticate it apart from any other security arrangement that is present like your password may be at a higher layer. But the point is that it is also possible that you allow communication with that particular host which is in that network, So you will set up your firewall or router policy in such a way that, that particular communication will be allowed, may be communication from others will not be allowed. But the point is, if this fellow has moved to another network then you will not be able to do it using the network address, that is one aspect. The other point is, other people may fake from other places. For example, suppose I want to communicate with Mr X, then Mr Y from some other place may rather try to spoof; in the sense, they may try to show that he is actually Mr X. So I will think that I am communicating with Mr X but actually I am communicating with Mr Y. Therefore, anything might happen and security concern is also an issue. The number of administrative messages should be small to save bandwidth and power. You cannot have a huge overhead for doing this, Mobile IP must impose no additional constraints on the assignment of IP addresses, this is another important issue. (Refer slide time: 29:49 - 32:09)
      
Before describing how this mobile IP is implemented, let us discuss about some Terminology. One is the Mobile node that is a host or router that changes its point of attachment from one network or sub network to another. A mobile node may change its location without changing its IP address. It may continue to communicate with other internet nodes at any location using its own constant IP address. (Refer slide time: 32:09 - 32:42)
			
Home Agent: This is required in order to support mobile IP. Home Agent is a router on a mobile nodes home network that tunnels datagrams to the mobile node when it is away from home. You can immediately get the idea of how it is done. The point is that, this particular mobile device has a home network and that home network has a router and that supports mobile IP. What that home network router would do is, whatever communication is supposed to be received by this particular mobile device will come to its home network. The router will accept that communication on behalf of this mobile host that may now be away somewhere else. Then it would be the job of the router to send that communication back to that particular mobile host. Not only you require a home agent, That means, some router helping you and your home network, then you require a foreign agent. A router on a mobile nodes visited network means the network to which it is currently physically connected provides routing services to the mobile node while it is registered. For getting this service you must register with this foreign agent. (Refer slide time: 32:43 - 34:13)


The mobile node is assigned a care of address. This is a new address. One is the mobile nodes own IP address which is remaining constant that actually belongs to the network in its home base. It also has a care of address on the foreign network. This address is used to deliver the datagrams for the mobile node. This address can either be the foreign agent where the Foreign Agents address may be this care of address or it can be co-located with the mobile node.(Refer slide time: 34:13 to 34:50)


This is the idea you have, this is the home network of the device of A. Now A has moved to another network so this is the visited network of A. In the home network A has a home agent which will help you in this mobile communication. In the visited network it looks for and finds a foreign agent that will help you for this communication. This foreign agent will give that care of address and then both of them will be connected to the internet. (Refer slide time: 34:51 - 35:00)  

Suppose some source wants to send something to A, naturally it will use A?s original IP address so it will be routed to the home network of A. (Refer slide time: 35:01 - 35:15)






What will happen is that then the home network will send it to the home agent. The home agent knows that A is no longer here but it is somewhere else and the home agent also knows the care of address given by the foreign agent. (Refer slide time: 35:16 - 35:25)

He tunnels the communication to the foreign agent using the care of address. (Refer slide time: 35:26 - 35:33)

Then the foreign agent will deliver the message to A because foreign agent knows the A?s current location, MAC address etc where it can communicate. (Refer slide time: 35:34 - 35:52)

Now A replies to C but this can go straight. This need not go in the circuitous manner because he is using the IP address of the source of the original communication so A can send this reply directly back to the source. Hence, this need not go through the entire process. (Refer slide time: 35:52 - 36:05)
      
This is the solution in a nutshell, From the source, it goes to the home agent, to the foreign agent, to the node and from the node it directly goes back to the source for the return communication. (Refer slide time: 36:05 - 37:06)
      
A small overview of the Protocol, you have advertisement. That means the mobile agents the so-called foreign agents and home agents should advertise their services. That means the mobile node comes to know that this foreign agent or home agent is available, that this service is available. Otherwise, a mobile node can also solicit for mobility agents and that is possible. Registration: When a mobile node is away from home it must register its care of address with its home agent. So, not only it must set up some arrangement with the foreign agent to give it an address but also that address has to be sent to the home agent so that, whatever the home agent tunnels it will tunnel it straight to that care of address. (Refer slide time: 37:06 - 37:23)
      
Delivering Datagrams: Datagrams must be forwarded by the home agent to the foreign agent for delivery to the care-of address. The delivery mechanism must handle all packets including broadcast and multicast. A tunnel is used for this analogy. In a little while, let us see what a tunnel means. (Refer slide time: 37:23 - 38:05)
			
Advertisement and Solicitation: The router discovery ICMP protocol was adapted for advertisement and solicitation so not much of a change was required. We will look at the details of ICMP protocol later. The routers broadcast or multicast every few seconds. So it uses limited broadcast or all systems on this link, multicast kind of an address for giving this because they cannot use the IP address directly because it is an advertisement. Mobile nodes also send out solicitation messages that will cause a router to broadcast or multicast their advertisement. (Refer slide time: 38:05 - 38:39)
      
Registration: Request forwarding services when visiting a foreign network. This allocates a local foreign node address. That means a care of address is required. Inform home agent of their current care of address. This creates a binding of the foreign node address to the home address in the home agent. If anything comes destined for the original home address then this can be tunneled to the care of address. (Refer slide time: 38:05 - 39:16)
      
This is one small but important point that this binding has to be renewed from time to time. Bindings have lifetimes. This is important because mobile node may be rude and just go away without informing anybody and that registration will rather last forever, it cannot last forever. It is best that it dies down after sometime. If the mobile agent continues in the same location for more time, it is going to renew this binding from time to time. And of course you have to deregister when they return home. (Refer slide time: 39:16 - 39:26)
			
Tunneling: There are various methods of tunneling. We will just discuss this IP-in-IP encapsulation and minimal encapsulation. (Refer slide time: 39:16 - 39:26)
			
This is IP-in-IP: This was the original message sent from the source and this is what landed in the home network of the destination. If you remember, in the diagram the destination was marked as A. This IP header will contain the actual address of A and this is the datagram. What it does is, when it lands into the home agent the home agent knows that this has to be sent somewhere else. It keeps the inner IP header and datagram intact. This whole thing is considered now as a payload and then you add another IP header with some options if necessary. This IP header will have as its destination the tunnel endpoints, the tunnel destinations which is supposed to be the care of address. In the packet the original packet is still there, this inner IP header and the datagram etc and this whole thing is encapsulated as if this is a payload and sent to the foreign network in the care of address. It will reach the foreign agent and the foreign agent will then send this part to the mobile node who is currently connected and its MAC address is known to the foreign agent. The mobile agent or the mobile node will receive a whole packet including this inner IP header. So you do not require any kind of change in the software which handles it just like a normal packet. It is as if he was in the home network and got this is original packet. (Refer slide time: 41:15 - 41:50)

The outer IP header source and destination address identify the tunnel endpoints. The source would be the home agent and the destination would be the foreign agent. The outer protocol is 4 that is the IP protocol. The inner IP header, the source address and destination address identify the original sender and recipient, this is not changed by the encapsulator except to change the time to live. So for time to live you have to look at the TTL and then make the necessary changes. This whole thing is put in the payload. (Refer slide time: 41:51 - 42:16)

Other headers for authentication might be added to the outer header in order to handle all these security concerns. Some outer IP header fields are copied from the inner IP fields. For example, type of service etc most are recomputed like checksum length etc may change based on the new datagram. (Refer slide time: 42:17 - 43:09)

The other option is the minimal encapsulation. Minimal encapsulation means that you do not keep the entire IP header intact here. So, what you want to do is that, you want to retain the minimal information in the minimal header and then construct an outer IP header. For the outer IP header the tunnel endpoints as the source and destination address would still be there and some of the stuff from the IP header will also come here. The destination address will be there in the minimal header. You have to make some deconstruction and reconstruction at both places. The size is a bit smaller so the overhead may be a bit smaller but it may not be such a big deal. (Refer slide time: 43:10 - 43:30)

In Minimal Encapsulation, we copy inner header. Modify protocol field to be 55 for the minimal encapsulation protocol because on the other side it must know which protocol it is following. If it is following minimal encapsulation then it has to do something. Destination address is replaced by the tunnel exit. (Refer slide time: 43:31 - 43:50)

If encapsulator is not the originator of message, replace source address with address of encapsulator. Then increment total length by the size of the additional header by 12 or 8 octets and then re-compute the checksum. This is called mobile IP in one way in which mobility can be handled and your IP address can be recomputed. There are other possibilities and other ways of handling mobility. For example, this has an overhead that any communication from the source to the intended host that has moved, now has to go through this triangular path. Will it continue to do so or whether after first communication there would be some protocol to exchange their new IP addresses etc? Then, they can communicate directly, that would avoid this triangular path. The other problems with triangular path may be apart from higher overhead. It may exceed the hop limit, as networks are growing it may increase the hop limit and you may never reach whereas if it had gone directly then it would have reached. Other options could be just like you do handoffs in cellular from one base station to another. In the case of cellular networks what is happening is that, you are always in connection with some base station, may be even more than one base station. If you are moving away from one base station when the signal strength drops then it goes to the realm of another base station, and the other base station automatically picks up and does some kind of registration. When this is done, the communication remains direct. But, if you want to change the IP address in such a dynamic fashion then there has to be an integrated system running everywhere which is using this protocol. Mobile IP is a way of handling mobility with minimal change to others and the problem is that this has a significant overhead. In the next class we will be moving into the next higher layer which is the Transport Layer the TCP and UDP, thank you.

LECTURE 30 UDP AND CLIENT SERVER

GoodGood day, today we will start our discussion on Transport Layer Protocols and there are actually two dominant protocols UDP and TCP. We will take them up one by one. Let us look at UDP in this lecture and TCP in the next one. (Refer slide time: 46:56 ? 47:02) 

UDP stands for User Datagram Protocol, (Refer slide time: 47:03 - 47:15)

This is a Transport Layer Protocol and this has got the following responsibilities. First of all It creates a process-to-process communication path. Till now we have talked about the network layer and the job of the network layer is to connect a distant machine to another distant machine. it?s a machine to machine communication. Whereas now we are talking about, process to process communication. In this particular source machine, some application process is running which is trying to connect the other distant machine for some job. This process has to connect to the corresponding process there which may be a particular application server on one side and the application client on the other side, whatever that application may be. So this is a process to process communication path..(Refer slide time: 47:56  - 48:06) 

This also has to provide control mechanisms at the transport level. This control mechanism in the case of UDP is very minimal, as we will presently see. (Refer slide time: 48:07 - 48:19)

UDP is a connectionless, Unreliable Transport Protocol. Immediately, the question that would come in your mind is that, why would we try to have an unreliable protocol? This is not unreliable per say, the point is, it does not do anything extra for reliability making it a very lightweight protocol, the overhead cost is very low. In many cases, this may be a very reasonable thing to have where you do not expect lot of errors or you do not really care if some error occurs from time to time and in such cases, you may use a UDP. (Refer slide time: 48:58 - 49:12)


This is a connectionless protocol. It only adds process-to-process communications to IP. It performs very limited error checking as we have mentioned. It is a very simple protocol having minimal overhead. This is the main point. It forms the payload for the next layer that is the IP layer and the checksum is computed over this entire body. So there is some amount of error checking and error detection  done by UDP and that is the extent to which it will go for providing reliability. Beyond this if the entire packet is lost somewhere the UDP can not do anything about it. (Refer slide time: 49:43 - 49:50)

These are the four fields of the Header, Source Port Number, Destination Port Number, Total Length and the Checksum. (Refer slide time: 49:53 - 50:16)

And regarding the UDP operation this is a connectionless service. This has minimal flow and error control as given by the checksum. It does the Encapsulation and Decapsulation, forming of packets, it uses some queuing and does the multiplexing and demultiplexing. Let us look at the operations one by one. (Refer slide time: 50:17 - 52:12)  

This is a connectionless service. That means each user datagram sent is an independent datagram. It means that, suppose some particular application has sent one UDP and is going to send another one, now the layers below this application may be coming from the same source application process destined for the same destination application process which are the two datagrams. They are going to be treated independently by the rest of the network layers. This means a number of things. First of all It may so happen that these two packets may go in two different directions, may be route differently because there is no connection. This is a completely a Datagram Oriented Service, Connectionless Service so these two datagrams may travel in different paths. Secondly, one of them may get lost. Thirdly, what might happen is, they may go out of order, the datagram that was sent earlier may reach later. The point is that, for all mishaps UDP is not going to take any responsibility. It is taken for granted that whatever application takes place using this UDP is resilient to such events. There is no relationship between different user datagrams. The user datagrams are not numbered, meaning that, the datagram which was sent later if it arises earlier and vice versa then there is no way of knowing unless you have taken some care to identify that in the application layer itself.  (Refer slide time: 52:13 - 52:46)

No connection establishment, since it is completely a connectionless service there is no question of any connection establishment. And since there is no connection establishment there is no connection termination either. These are unregulated which means that up to port number1023 these are reserved and that is also again divided into two parts. One part is for public applications and the other for some vendor specific applications but they are all well-known port numbers. Now, think of the other direction, apart from well-known port numbers you also need a whole lot of other port numbers. Take the previous example that we have made an HTTP request to a web server, now the web server will send you back something. May be it will send you with the content of the first page of its website. This is going to be sent to the requester but to which port? For this, another port number is temporarily assigned. This is assigned from a number range from 1024-65,000. The number is randomly chosen so this is an ephemeral port and not a fixed port. For the duration of this communication this port number is going to be held constant and then it will be released for use by some other process. (Refer slide time: 53:58 - 54:12)  

Source port numbers are dynamically assigned by the originating host, and are usually a number larger than 1023. Port numbers in the range of 0 -1023 are controlled by IANA. (Refer slide time: 54:13 - 55:46)

these are some examples of some well known port numbers. There are a quite a good number of them but I have just mentioned some important protocols. For example, FTP, a File Transfer Protocol uses port number 21. TELNET, a Terminal Connection uses port number 23. There are hundreds of applications that has come up. We cannot talk about all of them but we will talk about a few of them towards the last part of our course. .For the time being, let me just mention them. TELNET is the Terminal Connection which uses the well known port number 23. SMTP is a Simple Mail Transfer Protocol that uses port number 25. TFTP Trivial File Transfer is used when you just have to send a short message that uses 69. HTTP is the Hyper Text Transfer Protocol used for web services that uses the well-known port number 80. POP 3 is a Post Office Protocol that uses a port number 110. What POP 3 does is that, suppose you got some mail in your mailbox in the local mail server then on your desktop you can download all the mails from the local server to your machine through the Post Service Protocol. This is the POP3 Protocol. This type of server is called concurrent. Just to elaborate on the server part a little bit more then what I have already discussed, the client request for a connection has come to the server. Now what is the server in this case? When I mention the term server I mean that software process which is running there and not the hardware box. A hardware box is also called a server in a different context. In our context by server I mean the process which is giving the service, So this is some kind of process which is running in a particular machine. Now, in the non-concurrent case what will happen is that all the user requests will come and they are sort of put in a queue. And now what the server process will do is that, it will take up one from the queue, process the service, then give it back and send the result. Then it will take the next one out of the queue. So there is a queue where all the client requests are waiting. And the server, that means the service process which is giving the service is taking one request at a time out of the queue. This is called a non-concurrent server. Non-Concurrent in the sense that when you are using sock D?gram that is a UDP kind of service, it is one of its kind where you get a request, send a message and may be that is the end of the service. In that case this non-concurrent servers, also called iterative servers are more efficient. But it may also happen that, in a particular service the client server communication is for an extended period of time in which case one particular request may block all other requests for an unnecessarily long time. In that case the concurrent server may be preferred. In concurrent server what happens is, as soon as the server gets a request at the well-known port it immediately spawns or forks.

NOTE: REGARDING VIDEO CONTENT
IN THIS VIDEO AFTER 45 MINIT THE NEXT LECTURE IS STATED AFTER THAT THERE IS A SWITCHING OF SOME OTHER TOPICS WHICH IS NOT RELATED TO EACH OTHER



COMPUTER NETWORKS
Prof. S. Ghosh
Dept. of Computer Science and Engineering
I.I.T. Kharagpur
Lecturer#30
UDP and Client Server

Good day, today we will start our discussion about transport layer protocols. There are two dominant protocols the UDP and TCP. We will take them up one by one. Let us look at UDP in this lecture and TCP in the next one. 


Slide 1
UDP stands for User Datagram Protocol. 

Slide 2

This is a transport layer protocol and has got the following responsibilities: 
First of all, it creates a process to process communication path. Till now we have talked about the network layer and the job of the network layer is to connect a distant machine to another distant machine. So it is a machine to machine communication whereas now we are talking about process to process communication. So in this particular source machine may be some application process is running which is trying to connect to the other distant machine for some job. So this process has to connect to a corresponding process there which may be a particular application server on one side and application client on the other side whatever the applications may be. This is a process to process communication path. 
This also provides control mechanisms at the transport level. The control mechanism in the case of UDP is very minimal. 


Slide 3
UDP is a connectionless unreliable transport protocol. But why would we try to have an unreliable protocol? This protocol is not exactly unreliable but it does not do anything extra for reliability making it a very light weight protocol. So its overhead cost is very low. In many cases it may be a very reasonable thing to have where you do not expect lot of errors or you do not really care if some error occurs from time to time. In such cases you may use UDP. Functions of UDP:
- It only adds process to process communications to IP. 
- Performs very limited error checking. 
- Very simple protocol and has minimal overhead. This is the main advantage. It has very minimal overhead. 


Slide 4
When you are talking about the IP protocol you are talking about the connection from one machine to another. But in this particular machine a number of application programs or processes may be running. This UDP protocol connects one process to another process, so does TCP and that is the job of the transport layer. Although UDP is a connectionless protocol the job of the transport layer is to make some virtual connection or some virtual communication channel available to the corresponding processes. 


Slide 5

So to summarize: 
- IP is responsible for host to host communication. 
- Message still needs to be handed to the correct process. 
- UDP is responsible for delivery of the message to the appropriate process. Actually, not only you need to understand that there is some kind of multiplexing and de-multiplexing going on. In the same server a number of processes may be running and out of all those processes a good number of them may be using the same UDP protocol. So, when sending out a packet it is alright but when receiving a packet the UDP protocol has to determine as to which process it will go to and that is one of its jobs and the other job is to make connections.  
There is a point over here and this is a common task between TCP and the UDP. Our computer network is mostly a packet switched network whereas as far as applications are concerned mostly they do not really bother about packets. They may produce a chunk of data to be communicated to the other side. They may even produce a stream of data to be communicated to the other side so it does not work with packets. So somebody has to take this stream of data from the application layer and chop them into small packets and that is a job of the transport layer. So, both the TCP and UDP do that. 


Slide 6
- UDP is a transport layer protocol within the TCP/IP protocol suite. 
- It is simpler than TCP. TCP has higher overhead, it is more reliable than UDP. If you want to have reliability and still want to use UDP then you have to take care of reliability in some other layer may be application layer or something. 
- UDP lies between the application layer and the IP layer and like TCP serves as the intermediary between the application programs and the network operations. 


Slide 7
If this is your IP datagram, the IP datagram will have an IP header and the payload for the IP would be the entire UDP datagram. The UDP datagram would have the UDP data which it derives from the application and the UDP header. 


Slide 8
When a particular application wants to communicate to another application or when a process is trying to communicate to another process which is in a remote machine, in that case it will want to talk to some particular machine. Up to whatever we have seen, a particular machine means a particular IP address. Now this IP address is handled by the IP layer that means by the network layer on both the machines. Then how does the network layer get this IP address? As such it is supposed to get the IP address, the destination source and destination IP address from the top but there is a transport layer between the IP layer and the application layer. We are talking mostly about the TCP/IP protocol stack so we are not considering talking about OSI protocol stack and presentation layer for the time being. The destination IP address is known to the application but it has to be communicated to the network layer. The transport layer has got nothing to do with the IP addresses therefore the application layer does communicate the source and destination IP addresses to the transport layer and the transport layer passes it on to the network layer and does not do anything with it except considering it for the check sum. So this is known as IP pseudo header because this is not a real header for the UDP protocol or TCP. 


Slide 9
This IP pseudo header contains the 32-bit source IP address, 32-bit destination IP address and then this 16-bit UDP length etc. So this is the header which is passed on to the IP layer and this is in the same stack in the same machine. These headers are actually meant for communication between peers that means the transport layer, the UDP on this machine and the UDP on that machine will communicate via this UDP header so this is the proper header. And the pseudo header just takes that information about IP addresses etc from above and passes it below. 
What the real UDP header uses to communicate with its peer on the other machine contains a 16-bit source port number and 16-bit destination port number. Remember, these were 32-bit source IP address and here these are 32-bit destination IP address. There is also the port number here which we will see later. We have 16-bit source port number, 16-bit destination port number, 16-bit UDP length, optional 16-bit UDP checksum which may be optional and data if any, possible odd bytes and a pad. 


Slide 10
So this is the length of the header and data. Therefore we have the source and destination port numbers, total length and checksum.


Slide 11
Let us go through this in detail. The source port number has 
- 16-bits. 
- Range from 0 to 65,535. 
- Port number used by the process running on the source host. 
Recall the multiplexing and de-multiplexing we discussed earlier. In the same machine number of processes may be communicating and out of all these processes a good number of them may be using the same transport protocol namely UDP while others could be using the transfer protocol TCP. 
When a particular packet comes, you can see whether it is a TCP packet or UDP packet. Once you make it out, you have to decide that out of all the processes using UDP for which process is this packet meant for. All these different processes are associated with different port numbers and looking at the port number the UDP decides the process for which it is meant for and this is the de-multiplexing part. But the multiplexing part comes with the source port number. Hence there is a source port number and the destination port number used by UDP for multiplexing and de-multiplexing at its own level. This is a number which is 16-bits long which will give you from 0 to 65,535. These are the port numbers and port number is used by the process running on the source host. Later on let us see in detail on how this port number is obtained.


Slide 12
Similarly, there is a destination port number: 
- It has got 16-bits. 
- Port number used by the process running on the destination host. 
- In most cases, it is a well known port number. We will what is meant by well known port number.


Slide 13
- The length is 16-bits. 
o It defines the total length of the user datagram, header plus data. 
o Note: Maximum size of data is 65,507 after subtracting 20 bytes for IP header and 8 bytes for UDP header as this is the overhead. 


Slide 14
- Checksum is 16 bits
o Used to detect errors over the entire user datagram. 


Slide 15
- Checksum includes three sections: 
o Pseudoheader UDP header and the data. 
* Part of the header of the IP packet. 
* Ensures that if the IP header is corrupted the user datagram is not delivered to the wrong host. Since the pseudoheader contains the destination IP address, even if the IP header gets corrupted this does not get delivered to the wrong host. The pseudoheader, UDP header and the data taken together forms the payload for the next layer that is the IP layer and the checksum is computed over this entire body. So there is some amount of error checking and error detection done. This is done by UDP and this is the extent to which it will go for providing reliability. Beyond this if the entire packet is lost somewhere, UDP cannot do anything about it. 
o UDP Header - There are the four fields in the header, source port number, destination port number, total length and the checksum.


Slide 16
 UDP operation: 
- It is a connectionless service. 
- Has very minimal flow and error control as given by the checksum. 
- Performs encapsulation and decapsulation and forming of packets. 
- Queuing. 
- Multiplexing and De-multiplexing. 
Let us look at these operations one by one.  


Slide 17
Connectionless service: 
- Each user datagram sent is an independent datagram. If an application sends one UDP and is going to send another then they are handled independently in the layers below this application. These two datagrams may be coming from the same source application process meant for the same destination application process, but they are going to be treated independently by the rest of the network layers. First of all, it may so happen that these two packets may go in two different directions, may be routed differently because there is no connection. This is completely a datagram oriented connectionless service. Therefore these two datagrams may travel in different paths. One of them may get lost or they may get out of order which means the datagram that was sent earlier may reach the destination quite later. UDP is not going to take any responsibility for all these mishaps and it is taken for granted that whatever application takes place using this UDP is resilient to such things.
- There is no relationship between different user datagrams. 
- User datagrams are not numbered. Meaning that if the datagram which was sent later arrives much earlier and the vice versa then there is no way of knowing unless in the application layer itself we have taken some care to identify that. 


Slide 18
- There is no connection establishment. Since this is completely a connectionless service there is no question of any connection establishment, and since there is no connection establishment there is no connection termination either. 
- Each user datagram can travel on a different path. 
Only processes sending short messages should use UDP. Usually UDP is used in a case where you send one packet and that is the end of it. When you are trying to the send a stream of packets or stream of bytes etc usually you do not use UDP.- 

Slide 19
As far as flow and error control is concerned which may be another job of the transport layer the UDP does very little. 
- It is very simple and an unreliable transport protocol. 
- There is no flow control. 
- The receiver may overflow with incoming messages. 
- There is no error control except for the checksum. 
What happens is that, suppose the receiver is getting a large number of UDP packets, and if it wants to just stop or slow down to the senders it cannot do that. If it overflows some of the packets will get lost. And then there is no error control except for the checksum. 


Slide 20
- Sender does not know if a message has been lost or if it has been duplicated. 
- An error in the checksum causes a user datagram to be silently discarded. This is a very simple protocol and this is very efficient and has a very low overhead.


Slide 21
UDP does encapsulation and de-capsulation which is a fundamental job of any protocol in the transport layer. It has to form the packets, the packets form from the streams of data supplied by the application layer. The data is chopped into pieces, a header is added to each piece and then is passed on. To send a message from one process to another the UDP protocol encapsulates and decapsulates messages.   


Slide 22
This is just a standard way as it goes down the stack, the message from the process, so this is the UDP data, this is the UDP header, then the IP header frame header etc and it is decapsulated in a similar fashion.


Slide 23
- Queuing: 
- Each port has an associated incoming queue or incoming and outgoing queue depending on which way the communication is taking place. A port is not just a number. Along with the particular number, inside the OS there will be a queue of data being communicated in the machine. There will be an incoming queue and an outgoing queue. 
- UDP removes message from the outgoing queue one by one. 
- Adds the UDP header. 
- Delivers them to the IP. 


Slide 24
Incoming queue: 
- UDP checks to see if an incoming queue exists. The first thing UDP does is to check whether the incoming queue exists. 
- If there is, UDP sends the user datagram to the end of the queue. The particular application process is going to consume from this incoming queue. The process will consume from this incoming queue which is being fed from the UDP. For the outgoing queue, the application process is going to put things in the queue and UDP will take out the message to be communicated from the queue. 
- If there is no such port then UDP discards the user datagram and asks ICMP to send a port unreachable message. This means that a particular packet has come meant for a particular port and that port does not exist in this machine so it will send them an error message saying that the port is unreachable. In order to generate this ICMP message sometimes a packet is sent to an improvable port number. So, when you get back you know that you have reached the destination but of course there is no application over there. 


Slide 25
It does multiplexing and demultiplexing.
- Several processes may want to use the services of UDP. 
- UDP multiplexes and demultiplexes to handle this. 


Slide 26
Use of UDP:
- This is suitable for processes that require simple request-response communication. Suppose there is a simple request which may be sent by UDP and there is just one message as response to this request then that may also be sent back as an UDP. This also depends on the kind of network you have. Suppose you are communicating only inside the LAN, in that case you may not like to have an overhead since this is not going over the WAN. Therefore this is expected to be much more reliable and you may not like to incur any extra cost for providing reliability etc because you know that the underlying network is quite reliable. And secondly if your process is such that there is a simple message coming and there is a simple response, in that case a simple UDP protocol may be sufficient. 
- This may also be suitable for processes which include internal flow and error control mechanisms. That means, if the application process itself is handling some flow and error control, that means if it is handled at an upper layer then you do not want to duplicate it in the transport layer, in which case you use of simple protocol like UDP which is more efficient because reliability is being handled by somebody else anyway. So that is another case where UDP is a very suitable protocol. 
- UDP may also be suitable for multicasting and broadcasting. Going to some specific examples: 


Slide 27
- This is used for management processes such as SNMP. SNMP is a Simple Network Management Protocol used for managing network. For managing network we have this central network management software which from time to time may probe different network boxes to see if their health is alright, collect all kinds of statistics etc. So this is a simple message response kind of system. It asks for queries, manages a particular device in the network by sending a message and that device responds with some statistics or some alarm or whatever it is. So that is a case where UDP protocol may be quite suitable. 
- This is used for some route updating protocols such as RIP. We have already discussed RIP. For updating the routes the routers have to communicate with each other and that uses UDP. These are just two examples. There are many other examples and user applications which may also use UDP. 


Slide 28
Now let us discuss about port numbers and then I will talk about client server.  Port Numbers:
- Local host and remote host are defined by IP addresses. Here the host refers to the machine. 
- A second identifier called port number is required to identify processes because many processes may be running on the same host. So just identifying the host is not enough but we have to identify the process in this host. Or more specifically you have to talk about this process and this host. So you have to have a port number as well as an IP address. 
- In TCP/IP port numbers are integers between 0 and 65,535. 


Slide 29
- The server process requires a well known port number. 
- The client process defines a port number chosen randomly by UDP which is known as an ephemeral port number. 
We will discuss this in more detail when we discuss more about client server. This is one of the ways you write applications in a network environment by using the client server paradigm. There will be different servers giving different services like you may have a web server giving you web services or mail server etc. Different clients could be using these services. So they use different sets of port numbers. This will be clear when we talk about the client server paradigm in more detail. 


Slide 30
Once again, if you think about the IP address, this selects the host and then the port number selects the process. When you give the destination IP address etc it reaches a particular host and in that host it looks at the port number and then selects that process using that particular port number.


Slide 31
- Port numbers work as source and destination addresses for TCP/UDP segments.
- Ports ensure packets reach appropriate service on the server. 
- The destination port field determines which service the source is requesting. 
- TCP/IP associate ports at the transport layer with certain applications.


Slide 32
- Software developers have agreed on well known ports, for example: 
o A packet bound for an FTP server would use port 21. Just think of some network service, a web service. When you are surfing the net you will use a browser and you may click on a particular URL or network address and you immediately get the opening page of that particular site displayed by your browser. If you think about how did this happen? A particular site is hosted in some remote machine somewhere. You may know only its IP address. Now, by knowing its IP address you have to make a request to that IP address, like requesting it to show the opening page. Now the IP address will help you through this mace of routers who may be running some routing protocol like RIP, OSPF so that your request reaches the destination machine. But in the destination machine how does it know the port number? You do not know about the destination machine, number of processes running etc. Suppose if it is a HTTP request that means it is a request for a web page to a web server then this request has to reach the web server. Now there may be ten or fifty other processes running on that same machine, it should not go to any of these other servers. So, for very standard applications like FTP (File Transfer Protocol), SMTP (Simple Mail Transfer Protocol), HTTP (Hyper Text Transfer Protocol) and so on are all applications. So, for all these protocols the port numbers are fixed. So, if I make an FTP request, as it says FTP server use a well known port 21. That means if I make an FTP request to any machine anywhere in the world I am going to use a port number 21 knowing that this is a well known port number and if it is reaches the destination machine port number 21 would mean the FTP server. 
- Conversations that do not involve applications with well known ports are assigned ports randomly selected from a specific range. 



					Slide 33
There is an organization IANA which handles these port numbers. So port numbers have the following assigned ranges: 
- Below 255 (0 to 255) are reserved for public applications like FTP, SMTP, HTTP etc. 
- From 255 to 1023 these are assigned to companies for marketable applications.
- Above 1023 these are unregulated which means that up to 1024 these are reserved. This is again divided into two parts, one part for the public applications and the other for some vendor specific applications. Apart from well known port numbers you also need a whole lot of other port numbers. Take the previous example where we made an HTTP request to a web server. Now the web server will send you back something, may be the contents of the first page of its website. And that is going to be sent to the requester. For this another port number is temporarily assigned and this is assigned from a number range from 1024 to 65,535 and the number is randomly chosen. This is an ephemeral port, it is not a fixed port and it will be held constant for the duration of this communication and then it will be released for use by some other process.   


Slide 34
- Source port numbers are dynamically assigned by the originating host and are usually a number larger than 1023. 
- Port numbers in the range of 0 to 1023 are controlled by IANA. 


Slide 35
These are some examples of well-known port numbers. There are quite a good number of them but I have just mentioned some important protocols. 
- FTP is a file transfer protocol uses port number 21. 
- TELNET, a terminal connection uses port number 23. I will be talking more about some of these application layer protocols in a later lecture. There are hundreds of applications which have come up and we cannot talk about all of them but we will talk about few of them towards the last part of our course. 
- SMTP is a Simple Mail Transfer Protocol that uses port number 25. 
- TFTP is a Trivial File Transfer, when you just have to send a short message it uses port number 69. 
- HTTP is the Hyper Text Transfer Protocol which is the one used for web services that uses well-known port number 80. 
- POP3 is a Post Office Protocol that uses the port number 110. What POP3 does is that, suppose you got mail in your mail box in the local mail server then on your desktop you can download all the mails from the local server to your machine through the Post Office Protocol. 
- SNMP is used for network management that uses port 161. 
There are a whole lot of others but I have mentioned only a few which are important.  


Slide 36
Now moving on to the full description of client server programming it uses what is known as a socket address. 
Socket Address:
- Socket address is a combination of an IP address and a port number. 
- This uniquely defines each client and server process. So, this process is in this machine. Therefore this process is given by the port number and this machine is given by the IP number. 


Slide 37
These are some of the references for the different RFCS and the UDP is described in RFC 768. Then there is RFC 1122 and IANA port numbers can be seen in the websites mentioned here.


Slide 38
Let us see some more about client-server paradigm which is sort of universally used for network based application. 
- Server application is listener 
o Waits for incoming message 
o Performs service 
o Returns results 
- Client application establishes connection: 
It sends the message to the server and then ito  waits for a return message. 
In this client-server paradigm usually what happens is that, the client would initiate the request. It initiates the request for some service. It has to know the address of the service and if it is a well-known service then it will use the well-known port number. So in that particular machine in that particular port number it will make the request. And the server will accede to the request, in the sense that it will give the service and then return the result to the client and then it goes back to listening. So, the server is always in the listening mode that means it is waiting for a particular request to come in. 
 

Slide 39
- Clients and servers exchange messages through the transport protocols e.g. TCP or UDP. 
- Both client and server must have the same protocol stack and interact with the transport layer. So you may have a client server using both TCP and UDP. 


Slide 40
- Protocols specify general operations and the API specifies exactly how it is done. For using the socket there is a socket API. API stands for Application Program Interface. 
- So the socket API is the de facto standard. 
- Origin is in the BSD UNIX from University of California at Berkeley as part of one of the first versions of TCP/IP. 
- 

Slide 41
Let us see a little bit about the sockets and socket libraries: 
- This is a vendor supplied library of procedures. 
- They have the same name and arguments as one of the socket functions. 
It promotes independent source code and it is - usually easier to use than original sockets. 
The vendors also provide socket libraries with some bells and whistles. 


Slide 42
- Socket software interface is designed to communicate between the user program and TCP/IP protocol stack. Internally that is the socket. All TCP/IP stacks that we talked about right from the bottom one to right up to the transport layer is already in the system. Now you want to develop an application which should be run over the network. In such a case you have to write your application program for any service you would like to give. Now this user program has to communicate with this TCP/IP protocol stack which is already in the machine and the intervening layer is the API for sockets so you go to this TCP/IP layer stack through the sockets. 
- Therefore socket is a data structure inside the program. 
- Both client and server programs communicate via pair of sockets. 


Slide 43
There are several significant socket domain families: 
- Internet domain sockets implemented via IP addresses and port numbers. 
- UNIX domain sockets implemented via filenames. 
- Novell IPX Apple Talk etc. 
All these other vendor specific socket domains are also there. But the first two are the most important. 


Slide 44
There are three types of sockets: 
- Stream: It uses a TCP protocol. Stream socket is a connection oriented service. So, naturally you cannot use stream socket with UDP. Hence the transport layer protocol to use with this stream socket is TCP. 
- Datagram: In the datagram socket there is sock datagram that uses UDP protocol. The type of socket determines the type of protocol it is going to use TCP or UDP. But this uses the UDP protocol. 
- There are the raw sockets which may be used for testing anything internally. 


Slide 45
For creating a socket you have to have a library and for accessing the functions in the library which is specifically that socket you have to include that <sys/types.h> and <sys/socket.h> assuming that you are writing in c language. So you may have a function called something like this:
int socket (int domain, int type, int protocol). 
When you give this socket call, you have to mention its domain, its type and its protocol. 
- Domain is one of the protocol families like PF_INET, PF_UNIX etc so these are the socket domain families we talked about.  


Slide 46
- Type defines the communication protocol semantics. usually it defines either: 
o SOCK_STREAM that means connection oriented stream like TCP or 
o SOCK_DGRAM which is a connectionless unreliable UDP. 
- Protocol specifies a particular protocol, just set this to 0 to accept the default.  


Slide 47
What happens in the client-server is, when the client is initiating a request for a standard kind of a service it knows the destination IP address and the well-known port number And this message has reached the destination machine. And in the destination machine the server program always listens to that particular well-known port number. So the server program is actually in a loop listening whether any request is coming in through that port number. In the case of a UDP server this may be simple. It gets some request, it immediately gives a very short response and goes back to listening. 
But in such a case when the interaction with the user may be prolonged, for example, the user makes an FTP request and then downloading the file is going to take quite a bit of time. Similarly, the user may have made an HTTP request which means it may have asked for a particular webpage. Now, sending that webpage is also going to take some time. Of course it is always with respect to the kind of speed people are accustomed to. 
If the communication is always through that well-known port then during the currency of this particular session between this particular client and the server that well-known port number is going to be blocked and others will not be able to get the service which is not acceptable. 
So usually in the client-server there is a handshake. So the request comes to the well-known port number and of course there is a port address which has been sent by the client. From the server side the response goes back with another ephemeral port number which is not a standard port number. Now, on both sides you have two ephemeral port numbers that means the port number more than 1024 and they can then communicate through these two port numbers with source and destination respectively depending on from which side it is being sent. So these two different port numbers are used. This is happening on one side and on the other side the original server goes back to listening to that same well-known port number ready to service the next incoming request. 


Slide 48
Although we have not discussed TCP as yet but so far as this client-server part is concerned both of them are very similar. 
TCP Server:
- Sock_init() - creates the socket 
- Register port with the system 
- Establish the client connection 
- Accept the client connection 
- Read/write data 
- Close() is for shutting down 
When you establish the client connection and when you accept the client connection in this part all these two ephemeral port numbers are exchanged. This is on the server side. On the client side it creates the socket and tries to setup a connection. Usually in a client-server, the initiation of the connection is always from the client side. Then the write/read goes on and then there is a shut down. 


Slide 49
UDP clients and servers are similar except that it uses SOCK_DGRAM instead of SOCK_STREAM. 
- Connectionless clients and servers create sockets using SOCK_DGRAM. 
- Connectionless servers do not call listen() or accept() and usually do not call connect(). 
This means you may not require any specific handshake and you may not require a special ephemeral port for prolonged communication between the client and the server because in this case usually the service is to just send only one message and ending the service. 


Slide 50
- Since connectionless communications lack a sustained connection several methods are available that allow you to specify a destination address with every call: 
o sendto ( sock, buffer, buflen, flags, to_addr, tolen); 
o recvfrom (sock, buffer, buflen, flags, from_addr, fromlen); 
- There is a way to specify a destination address with every call. 


Slide 51
For UDP server the sequence of calls is the following: 
- Create a socket. 
- Register the port using the bind command. 
- Receive or send data. 
- Shutdown. 
This is somewhat simpler than the TCP server. And then there is the UDP client that you create, send or receive and then you shutdown. 


Slide 52
There are two types of servers. Several clients can request service of the server in the same time. In this case a server can: 
- Service one client at one time. Other client requests must wait. This type of server is called non-concurrent. The second type is,
- Services all client requests are handled simultaneously. This type of server is called concurrent. 
This is what happens, the client?s request for a connection has come to the server. By the term server, we mean that software process which is running there and not the hardware box. The hardware is also called a server but in a different sense. In our context by server we mean the process which is giving the service and which is running in a particular machine. 
If this server is non-concurrent all the user requests come and are sort of put in a queue. Then the server process will take one from the queue, process the service and then send the result and take the next one out of the queue. So there is a queue where all the client requests are waiting and the server process takes one request at a time out of the queue. This is called a non-concurrent server. 
When you are using UDP and when using SOCK_DGRAM that means you get a request, send a message and may be that is the end of the service. In that case this non-concurrent server also called as iterative server is more efficient. But it may also happen that, in a particular service the client server communication is for an extended period of time. In this case, one particular request may block all other requests for an unnecessarily long time. In that case concurrent server may be preferred. 
In concurrent server, as soon as the server gets the request at the well-known port it immediately spawns a new process. When you execute a fork, in say unique, what you get is an exactly similar piece of code to which you make some changes. What you do is that you give them a new port number and let this new process communicate with this particular client?s request and the original process goes back to listening to the well-known port. 
Another request may come from some other client somewhere else so it will again spawn another process and the original process will go back listening to the well-known port. All these child server processes use different ephemeral port numbers to communicate with different clients. In the strictest sense if you have only one particular processor in the server machine then only one program can run, things cannot be concurrent but have to be sequential. But then, that sequentiality is imposed by the way processors are scheduled by the scheduler inside the ?. So it will give some milliseconds for one process and then it gives few more milliseconds for some other process etc so it will look as if all the clients are getting the service simultaneously. So that is what is meant when we say client requests are serviced simultaneously.  


Slide 53
These are the non-concurrent server sequence of calls. The only thing to note is that, there is a while loop and this loop will service each request sequentially.  


Slide 54
The concurrent server uses the fork and in the fork it creates a child process which will now communicate with the client. With this we come to the end of this lecture. In the next lecture we will discuss the TCP protocol. 


Slide 55


Slide 56


Slide 57
Our topic today is TCP, the second most important transport protocol. It is very widely used in many applications. This is a little more complex than UDP but it also has some advantages. We will see what they are and look into the transport layer responsibilities.  


Slide 58
If you remember the transport layer responsibilities, they
- Create packets from byte stream received from the application layer. 
- In order to multiplex and demultiplex amongst various applications it uses port numbers to create process to process communications. 
- Uses a sliding window protocol to achieve flow control. 
- Uses acknowledgement packet, time-out and retransmission to achieve error control. 
So unlike UDP which is unreliable, TCP seeks to provide a reliable communication so that it is error free. It is a connection oriented protocol and it also has some kind of congestion control mechanism. And of course it does the basic thing of making connection between processors amongst two distant nodes possible. Full duplex communication: This means A is communicating to B and B is communicating to A at the same time. Even if predominantly only one side is sending data to the other side the acknowledgement is coming from the other side anyway. 


Slide 59
- The connection can be terminated from both sides but then somebody has to initiate the termination. 
- If connection is terminated in one direction data can continue to be sent in the other direction. 


Slide 60
Four actions are required to close the connection in both directions. Let us assume a bi-directional connection that has to be closed. 
- First host A sends a segment announcing connection termination which means it sends the segment contains FIN. You remember all the SYN, FIN etc, are the flag segments in the TCP segment header. 
- Host B sends a segment acknowledging the request from A. After this the connection is closed in one direction.   


Slide 61
- When host B has finished sending data it sends a segment indicating connection closure. 
- Host A acknowledges the request from B.
- Second and third steps cannot be combined together because although we are sort of allowing the termination of connection from one side but from the other side he may have acknowledgements or other things to send to this side so he will not terminate the connection. So these two cannot be combined together. The third step can be taken only when host B has finished sending data from its side and it sends a segment indicating connection closure.
- Called Four-Way Handshaking.


