computer networking computer networking  a top-down approach featuring the internet instructor and student resources for this book are available at http  //www.awlonline.com/kurose-ross ! file  ///d | /downloads/livros/computa ? ? o/computer % 20network...op-down % 20approach % 20featuring % 20the % 20internet/index.htm20/11/2004 15  51  33 table of contents computer networking a top-down approach featuring the internet james f kurose and keith w ross preface link to the addison-wesley www site for this book link to overheads for this book online forum discussion about this book  with voice ! 1 computer networks and the internet 1 what is the internet ? 2 what is a protocol ? 3 the network edge 4 the network core n interactive programs for tracing routes in the internet n java applet  message switching and packet switching 5 access networks and physical media 6 delay and loss in packet-switched networks 7 protocol layers and their service models 8 internet backbones  naps and isps 9 a brief history of computer networking and the internet 10 atm 11 summary 12 homework problems and discussion questions 2 application layer 1 principles of application-layer protocols 2 the world wide web  http 3 file transfer  ftp 4 electronic mail in the internet file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/contents-1.htm  1 of 4  20/11/2004 15  51  32 table of contents 5 the internet 's directory service  dns n interactive programs for exploring dns 6 socket programming with tcp 7 socket programming with udp 8 building a simple web server 9 summary 10 homework problems and discussion questions 3 transport layer 1 transport-layer services and principles 2 multiplexing and demultiplexing applications 3 connectionless transport  udp 4 principles of reliable of data transfer n java applet  flow control in action 5 connection-oriented transport  tcp 6 principles of congestion control 7 tcp congestion control 8 summary 9 homework problems and discussion questions 4 network layer and routing 1 introduction and network service model 2 routing principles 3 hierarchical routing 4 internet protocol n java applet  ip fragmentation 5 routing in the internet 6 what is inside a router ? 7 ipv6 8 multicast routing 9 summary 10 homework problems and discussion questions 5 link layer and local area networks 1 the data link layer  introduction  services 2 error detection and correction 3 multiple acces protocols and lans 4 lan addresses and arp 5 ethernet n csma/cd applet 6 hubs  bridges and switches 7 wireless lans  ieee 802.11 8 the point-to-point protocol 9 atm 10 x.25 and frame relay 11 summary 12 homework problems and discussion questions file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/contents-1.htm  2 of 4  20/11/2004 15  51  32 table of contents 6 multimedia networking 1 multimedia networking applications 2 streaming stored audio and video 3 making the best of the best-effort service  an internet phone example 4 rtp 5 beyond best effort 6 scheduling and policing mechanisms for providing qos guarantees 7 integrated services 8 rsvp 9 differentiated services 10 summary 11 homework problems and discussion questions 7 security in computer networks 1 what is network security ? 2 principles of cryptography 3 authentication  who are you ? 4 integrity 5 key distribution and certification 6 secure e-mail 7 internet commerce 8 network-layer security  ipsec n 1999 panel discussion on internet security 9 summary 10 homework problems and discussion questions 8 network management 1 what is network managmenet ? 2 the infrastructure for network management 3 the internet network management framework 4 asn.1 5 firewalls 6 summary 7 homework problems and discussion questions appendix l lab  building a multi-threaded web server in java l lab  building a mail user agent in java l lab  implementing a reliable transport protocol l lab  implementing a distributed  asynchronous distance vector routing algorithm file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/contents-1.htm  3 of 4  20/11/2004 15  51  32 table of contents some relevant online audio material  unix network programming  jim kurose introduction to computer networks  jim kurose internet protocols  keith ross distribution of stored information in the web  keith ross asynchronous learning links  the web of asynchronous learning networks copyright 1996-2000 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/contents-1.htm  4 of 4  20/11/2004 15  51  32 preface preface and acknowledgments welcome to our online textbook  computer networking  a top-down approach we  jim kurose  keith ross  and addison-wesley-longman  think you will find this textbook to be very different than the other computer networking books that are currently available perhaps the most unique and innovative feature of this textbook is that it is online and accessible through a web browser we believe that our online format has several things going for it first  an online text can be accessed from any browser in the world  so a student  or any other reader  can gain access to the book at anytime from anyplace second  as all of us internet enthusiasts know  much of the best material describing the intricacies of the internet is in the internet itself our hyperlinks  embedded in a coherent context  provide the reader direct access to some of the best sites relating to computer networks and internet protocols the links do not only point to rfcs but also to sites that are more pedagogic in nature  including home-brewed pages on particular aspects of internet technology and articles appearing in online trade magazines being online also allows us to include many interactive features  including direct access to the traceroute program  direct access to search engines for internet drafts  java applets that animate difficult concepts  and  in the near future  direct access to streaming audio being online enables us to use more fonts and colors  both within the text and in diagrams   making the text both perky and cheerful finally  an online format will allow us to frequently release new editions  say  every year   which will enable the text to keep pace with this rapidly changing field another unusual feature of the text is its internet focus most of the existing textbooks begin with a broader perspective and address the internet as just as one of many computer network technologies we instead put internet protocols in the spotlight  and use the internet protocols as motivation for studying some of the more fundamental computer networking concepts but why put the internet in the spotlight  why not some other networking technology such as atm ? most computer networking students have had already significant " hands on " experience with the internet  e.g  surfing the web and sending e-mail at the very least  before taking a course on computer networks we have found that modern-day students in computer science and electrical engineering  being intensive users of the internet  are enormously curious about what is under the hood of the internet thus  it is easy to get students excited about computer networking when using the internet as your guiding vehicle a second reason for the internet focus is that in recent years computer networking has become synonymous with the internet this was n't the case five-to-ten years ago  when there was a lot of talk about atm lans and applications direclty interfacing with atm  without passing through tcp/ip   but we have now reached the point where just about all data traffic is carried over the internet or intranets furthermore  streaming audio and video have recently become commonplace in the internet  and someday telephony may be too because our book has an internet focus  it is organized around a five-layer internet architecture rather than around the more traditional seven-layer osi architecture another unique feature of this book is that it is also top-down in how the content is organized as we mentioned above  this text  as almost all computer networks textbooks  uses a layered architectural model to organize the content however  unlike other texts  this text begins at the application-layer and file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/preface.htm  1 of 4  20/11/2004 15  51  35 preface works its way down the protocol stack the rationale behind this top-down organization is that once one understands the applications  one can then understand the network services needed to support these applications one can then  in turn  examine the various ways in which such services might be provided/ implemented by a network architecture covering applications early thus provides motivation for the remainder of the text an early emphasis on application-layer issues differs from the approaches taken in most other texts  which have only a small  or nonexistent  amount of material on network applications  their requirements  application-layer paradigms  e.g  client/server   and the application programming interfaces  e.g  sockets   studying application-layer protocols first allows students to develop an intuitive feel for what protocols are  the role of message exchange and the actions taken on events  in the context of network applications  e.g  the web  ftp and e-mail  which they use daily furthermore  the inclusion of a significant amount of material at the application layer reflects our own belief that there has been  and will continue to be  a significant growth in emphasis  in the research community  and in industry  in the higher levels of network architecture these higher layers  as exemplified by the web as an application layer protocol  is the true ` ` growth area' ' in computer networking this textbook also contains material on application programming development  material not covered in depth by any introductory computer networks textbook  while there are books devoted to network programming  e.g  the texts by stevens  they are not introductory networking textbooks  there are several compelling reasons for including this material first  anyone wanting to write a network application must know about socket programming  the material is thus of great practical interest second  early exposure to socket programming is valuable for pedagogical reasons as well  it allows students to write actual network application-level programs and gain first-hand experience with many of this issues involved in having multiple geographically distributed processes communicate we present the material on application programming in a java context rather than a c context  because socket programming in java is simpler  and allows students to quickly see the forest through the trees it has been said that computer networking textbooks are even more boring than accounting texts certainly  one seed of truth in the statement is that many books are simply a compendium of facts about a myriad of computer networking technologies and protocols  such as packet formats or service interfaces  and given the wealth of protocol standards  there is no shortage of such facts !   what is missing in such accounting-like textbooks is an identification of the important  underlying issues that must be solved by a network architecture  and a methodical study of the various approaches taken towards addressing these issues many texts focus on what a network does  rather than why addressing the principles  rather than just the dry standards material  can make a textbook more interesting and accessible  a sense of humor  use of analogies  and real-world examples also help  the field of networking is now mature enough that a number of fundamentally important issues can be identified for example  in the transport layer  the fundamental issues include reliable communication over an unreliable channel  connection establishment/teardown and handshaking  congestion and flow control  and multiplexing in the routing layer  two fundamentally important issues are how to find ` ` good' ' paths between two routers  and how to deal with large  heterogeneous systems in the data link file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/preface.htm  2 of 4  20/11/2004 15  51  35 preface layer  a fundamental problem is how to share a multiple access channel this text identifies fundamental networking issues as well as approaches towards addressing these issues we believe that the combination of using the internet to get the student 's foot in door and then emphasizing the issues and solution approaches will allow the student to quickly understand just about any networking technology for example  reliable data transfer is a fundamental issue in both the transport and data link layer various mechanisms  e.g  error detection  use of timeouts and retransmit  positive and negative acknowledgments  and forward error correction  have been designed to provide reliable data transfer service once one understands these approaches  the data transfer aspects of protocols like tcp and various reliable multicast protocols can been seen as case studies illustrating these mechanisms how an instructor can use this online book this online book can be used as the textbook for a course on computer networking just like any other textbook the instructor can assign readings and homework problems  and base lectures on the material within the text however  the textbook is also ideally suited for asynchronous online courses such courses are particularly appealing to students who commute to school or have difficulty scheduling classes due to course time conflicts the authors already have significant experience in leading asynchronous online courses  using an earlier draft of this online text they have found that one successful asynchronous format is to have students do weekly asynchronous readings  and listenings !  and to have students participate in weekly newsgroup discussions about the readings students can have a virtual presence by sharing the urls of the their personal web pages with the rest of the class students can even collaborative on joint projects  such as research papers and network application development  asynchronously over the internet readers are encouraged to visit the following sites which are devoted to asynchronous online education  the web of asynchronous learning networks journal of asynchronous learning networks asynchronous learning networks magazine acknowledgments lot 's of people have given us invaluable help on this project since it began in 1996 for now  we simply say " thanks ! " and list some of the names alphabetically paul amer daniel brushteyn john daigle wu-chi feng file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/preface.htm  3 of 4  20/11/2004 15  51  35 preface albert huang jussi kangasharju hyojin kim roberta lewis william liang willis marti deep medhi george polyzos martin reisslein despina saparilla subin shrestra david turner ellen zegura shuchun zhang and all the upenn  umass and eurecom students that have suffered through earlier drafts !  list is incomplete will be adding names shortly  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/preface.htm  4 of 4  20/11/2004 15  51  35 instructor overheads  computer networking  a top down approach featuring the internet computer networking a top-down approach featuring the internet james f kurose and keith w ross instructor overheads you 'll find links below to overheads  powerpoint files  compressed postscript and pdf format  for the textbook  computer networking  a top-down approach featuring the internet  by jim kurose and keith ross  published by addison wesley longman if you want to find out more about the book  you can check out the on-line version of the text at http  //gaia.cs.umass.edu/kurose/contents.htm or at http  //www.seas.upenn.edu/ ~ ross/book/contents.htm the publisher 's www site for the book is http  //www.awlonline.com/kurose/ note that the overheads below are being made available in powerpoint format  as well as postscript and pdf  shortly  so that instructors can modify the overheads to suit their own teaching needs while we hope that many instructors will make use of the overheads  regardless of whether or not our text is used for the course   we ask that you use the overheads for educational purposes only please respect the intellectual property represented in the overheads and do not use them for your own direct commercial benefit questions or comments to jim kurose or keith ross chapter 1  computer networks and the internet l chapter1a.ppt  part 1  powerpoint format  1.178m  last update  21-dec-99   l chapter1b.ppt  part 2  powerpoint format  215k  last update  21-dec-99  chapter 2  the application layer l chapter2a.ppt  part 1  powerpoint format  568k  last update  21-dec-99  l chapter2b.ppt  part 2  powerpoint format  276k  last update  21-dec-99  file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/text_overheads.htm  1 of 2  20/11/2004 15  51  36 instructor overheads  computer networking  a top down approach featuring the internet chapter 3  the transport layer l chapter3a.ppt  part 1  powerpoint format  1.201m  last update  28-dec-99  l chapter3b.ppt  part 2  powerpoint format  640k  last update  2-jan-00  chapter 4  the network layer and routing l chapter4a.ppt  part 1  powerpoint format  951k  last update  25-feb-00  l chapter4b.ppt  part 2  up though section 4.4  last update  25-feb-00  the following slides  and those for chapters 5 and 6  are courtesy of mario gerla and medy sanadidi  ucla they taught a networking course based on our text last fall and developed the overheads below they were kind enough to allow us to post their overheads here a big " thanks " to both of them ! l chapter4c_ucla.ppt  powerpoint.250k  l chapter4d_ucla.ppt  powerpoint,258k  chapter 5  the link layer and local area networks l chapter5a_ucla.ppt  powerpoint  641k  l chapter5b_ucla.ppt  powerpoint  256k  l chapter5c_ucla.ppt  powerpoint 653k  l chapter5d_ucla.ppt  powerpoint  777k  chapter 6  multimedia networking l chapter6a_ucla.ppt  powerpoint  410k  l chapter6b_ucla.ppt  powerpoint  704k  chapter 7  security in computer networks chapter 8  network management more overheads are being added daily  copyright 1996-2000 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/text_overheads.htm  2 of 2  20/11/2004 15  51  36 what is the internet ? 1.1 what is the internet ? in this book we use the public internet  a specific computer network  and one which probably most readers have used   as our principle vehicle for discussing computer networking protocols but what is the internet ? we would like to give you a one-sentence definition of the internet  a definition that you can take home and share with your family and friends alas  the internet is very complex  both in terms of its hardware and software components  as well as the services it provides a nuts and bolts description instead of giving a one-sentence definition  let 's try a more descriptive approach there are a couple of ways to do this one way is to describe the nuts and bolts of the internet  that is  the basic hardware and software components that make up the internet another way is to describe the internet in terms of a networking infrastructure that provides services to distributed applications let 's begin with the nuts-and-bolts description  using figure 1.1-1 to illustrate our discussion figure 1.1-1  some " pieces " of the internet l the public internet is a world-wide computer network  i.e  a network that interconnects millions of computing devices throughout the world most of these computing devices are traditional desktop pcs  unix-based workstations  and so called " servers " that store and transmit information such as www pages and e-mail messages increasingly  non-traditional file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...h % 20featuring % 20the % 20internet/what_is_the_internet.htm  1 of 4  20/11/2004 15  51  37 what is the internet ? computing devices such as web tvs  mobile computers  pagers and toasters are being connected to the internet  toasters are not the only rather unusual devices to have been hooked up to the internet ; see the the future of the living room  in the internet jargon  all of these devices are called hosts or end systems the internet applications with which many of us are familiar  such as the www and e-mail  are network application programs that run on such end systems we will look into internet end systems in more detail in section 1.3 and then delve deeply into the study of network applications in chapter 2 l end systems  as well as most other " pieces " of the internet  run protocols that control the sending and receiving of information within the internet tcp  the transmission control protocol  and ip  the internet protocol  are two of the most important protocols in the internet the internet 's principle protocols are collectively known as tcp/ip protocols we begin looking into protocols in section 1.2 but that 's just a start --much of this entire book is concerned with computer network protocols ! l end systems are connected together by communication links we 'll see in section 1.5 that there are many types of communication links links are made up of different types of physical media  coaxial cable  copper wire  fiber optics  and radio spectrum different links can transmit data at different rates the link transmission rate is often called the link bandwidth  and is typically measured in bits/second l usually  end systems are not directly attached to each other via a single communication link instead  they are indirectly connected to each other through intermediate switching devices known as routers a router takes information arriving on one of its incoming communication links and then forwards that information on one of its outgoing communication links the ip protocol specifies the format of the information that is sent and received among routers and end systems the path that transmitted information takes from the sending end system  through a series of communications links and routers  to the receiving end system is known as a route or path through the network we introduce routing in more detail in section 1.4  and study the algorithms used to determine routes  as well as the internal structure of a router itself  in chapter 4 l rather than provide a dedicated path between communicating end systems  the internet uses a technique known as packet switching that allows multiple communicating end systems to share a path  or parts of a path  at the same time we will see that packet switching can often use a link more " efficiently " than circuit switching  where each pair of communicating end systems gets a dedicated path   the earliest ancestors of the internet were the first packet-switched networks ; today 's public internet is the grande dame of all existing packet-switched networks l the internet is really a network of networks that is  the internet is an interconnected set of privately and publicly owned and managed networks any network connected to the internet must run the ip protocol and conform to certain naming and addressing conventions other than these few constraints  however  a network operator can configure and run its network  i e  its little " piece " of the internet  however it chooses because of the universal use of the ip protocol in the internet  the ip protocol is sometimes referred to as the internet dail tone l the topology of the internet  i.e  the structure of the interconnection among the various pieces of the internet  is loosely hierarchical roughly speaking  from bottom-to-top  the hierarchy consists of end systems connected to local internet service providers  isps  though access networks an access network may be a so-called local area network within a company or university  a dial telephone line with a modem  or a high-speed cable-based or phone-based access network local isp 's are in turn connected to regional isps  which are in turn connected to national and international isps the national and international isps are connected together at the highest tier in the hierarchy new tiers and branches  i.e  new networks  and new networks of networks  can be added just as a new piece of lego can be attached to an existing lego construction in the first half of 1996  approximately 40,000 new network addresses were added to the internet  network 1996   an astounding growth rate l at the technical and developmental level  the internet is made possible through creation  testing and implementation of internet standards these standards are developed by the internet engineering task force  ietf   the ietf standards documents are called rfcs  request for comments   rfcs started out as general request for comments  hence the name  to resolve architecture problems which faced the precursor to the internet rfcs  though not formally standards  have evolved to the point where they are cited as such rfcs tend to be quite technical and detailed they define protocols such as tcp  file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...h % 20featuring % 20the % 20internet/what_is_the_internet.htm  2 of 4  20/11/2004 15  51  37 what is the internet ? ip  http  for the web  and smtp  for open-standards e-mail   there are more than 2000 different rfc 's the public internet  i.e  the global network of networks discussed above  is the network that one typically refers to as the internet there are also many private networks  such as certain corporate and government networks  whose hosts are not accessible from  i e  they can not exchange messages with  hosts outside of that private network these private networks are often referred to as intranets  as they often use the same " internet technology "  e.g  the same types of host  routers  links  protocols  and standards  as the public internet a service description the discussion above has identified many of the pieces that make up the internet let 's now leave the nuts and bolts description and take a more abstract  service-oriented  view  l the internet allows distributed applications running on its end systems to exchange data with each other these applications include remote login  file transfer  electronic mail  audio and video streaming  real-time audio and video conferencing  distributed games  the world wide web  and much much more  at&t 1998   it is worth emphasizing that the web is not a separate network but rather just one of many distributed applications that use the communication services provided by the internet the web could also run over a network besides the internet one reason that the internet is the communication medium of choice for the web  however  is that no other existing packet-switched network connects more than 43 million  network 1999  computers together and has 100 million or so users  almanac    by the way  determining the number of computers hooked up to the internet is a very difficult task  as no one is responsible for maintaining a list of who 's connected when a new network is added to the internet  its administrators do not need to report which end systems are connected to that network similarly  an exiting network does not report its changes in connected end systems to any central authority  l the internet provides two services to its distributed applications  a connection-oriented service and a connectionless service loosely speaking  connection-oriented service guarantees that data transmitted from a sender to a receiver will eventually be delivered to the receiver in-order and in its entirety connectionless service does not make any guarantees about eventual delivery typically  a distributed application makes use of one or the other of these two services and not both we examine these two different services in section 1..3 and in great detail in chapter 3 l currently the internet does not provide a service that makes promises about how long it will take to deliver the data from sender to receiver and except for increasing your access bit rate to your internet service provider  isp   you currently can not obtain better service  e.g  shorter delays  by paying more  a state of affairs that some  particularly americans !  find odd we 'll take a look at state-of-the art internet research that is aimed at changing this situation in chapter 6 our second description of the internet  in terms of the services it provides to distributed applications  is a non-traditional  but important  one increasingly  advances in the " nuts and bolts " components of the internet are being driven by the needs of new applications so it 's important to keep in mind that the internet is an infrastructure in which new applications are being constantly invented and deployed we have given two descriptions of the internet  one in terms of the hardware and software components that make up the internet  the other in terms of the services it provides to distributed applications but perhaps you are even more confused as to what the internet is what is packet switching  tcp/ip and connection-oriented service ? what are routers ? what kinds of communication links are present in the internet ? what is a distributed application ? what does the internet have to do with children 's toys ? if you feel a bit overwhelmed by all of this now  do n't worry  the purpose of this book is to introduce you to both the nuts and bolts of the internet  as well as the principles that govern how and why it works we will explain these important terms and questions in the subsequent sections and chapters some good hyperlinks file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...h % 20featuring % 20the % 20internet/what_is_the_internet.htm  3 of 4  20/11/2004 15  51  37 what is the internet ? as every internet researcher knows  some of the best and most accurate information about the internet and its protocols is not in hard copy books  journals  or magazines the best stuff about the internet is in the internet itself ! of course  there 's really too much material to sift through  and sometimes the gems are few and far between below  we list a few generally excellent www sites for network and internet-related material throughout the book  we will also present links to relevant  high quality url 's that provide background  original  i.e  a citation   or advanced material related to the particular topic under study here is a set of key links that you will want to consult while you proceed through this book  internet engineering task force  ietf   the ietf is an open international community concerned with the development and operation of the internet and its architecture the ietf was formally established by the internet architecture board  iab  in 1986 the ietf meets three times a year ; much of its ongoing work is conducted via mailing lists by working groups typically  based upon previous ietf proceedings  working groups will convene at meetings of the ietf to discuss the work of the ietf working groups the ietf is administered by the internet society  whose www site contains lots of high-quality  internet-related material the world wide web consortium  w3c   the w3c was founded in 1994 to develop common protocols for the evolution of the world wide web this an outstanding site with fascinating information on emerging web technologies  protocols and standards the association for computing machinery  acm  and the institute of electrical and electronics engineers  ieee   these are the two main international professional societies that have technical conferences  magazines  and journals in the networking area the acm special interest group in data communications  sigcomm   the ieee communications society  and the ieee computer society are the groups within these bodies whose efforts are most closely related to networking connected  an internet encyclopedia  an attempt to take the internet tradition of open  free protocol specifications  merge it with a 1990s web presentation  and produce a readable and useful reference to the technical operation of the internet the site contains material on over 100 internet topics data communications tutorials from the online magazine data communications  one of the better magazines for data communications technology the site includes many excellent tutorials media history project  you may be wondering how the internet got started or you may wonder how electrical communications got started in the first place and you may even wonder about what preceded electrical communications ! fortunately  the web contains an abundance of excellent resources available on these subjects this site promotes the study of media history from petroglyths to pixels it covers the history of digital media  mass media  electrical media  print media  and even oral and scribal culture references  almanac 1998  computer industry almanac  december 1998  http  //www.c-i-a.com/  at&t 1998  " killer apps  " at&t www page http  //www.att.com/attlabs/brainspin/networks/killerapps.html  network 1996  network wizards  internet domain survey  july 1996  http  //www.nw.com/zone/www-9607/report.html  network 1999  network wizards  internet domain survey  january 1999  http  //www.nw.com/zone/www/top.html return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...h % 20featuring % 20the % 20internet/what_is_the_internet.htm  4 of 4  20/11/2004 15  51  37 what is a protocol ? 1.2.what is a protocol ? now that we 've got a bit of a feel for what the " internet " is  let 's consider another important word is the title of this book  " protocol " what is a protocol ? what does a protocol do ? how would you recognize a protocol if you met one ? a human analogy it is probably easiest to understand the notion of a computer network protocol by first considering some human analogies  since we humans execute protocols all of the time consider what you do when you want to ask someone for the time of day a typical exchange is shown in figure 1.2-1 human protocol  or good manners  at least  dictates that one first offers a greeting  the first " hi " in figure 1.2-1  to initiate communication with someone else the typical response to a " hi " message  at least outside of new york city  is a returned " hi " message implicitly  one then takes a cordial " hi " response as an indication that one can proceed ahead and ask for the time of day a different response to the initial " hi "  such as " do n't bother me ! "  or " i do n't speak english  " or an unprintable reply that one might receive in new york city  might indicate an unwillingness or inability to communicate in this case  the human protocol would be to not ask for the time of day sometimes one gets no reponse at all to a question  in which case one typically gives up asking that person for the time note that in our human protocol  there are specific messages we send  and specific actions we take in response to the received reply messages or other events  such as no reply within some given amount of time   clearly  transmitted and received messages  and actions taken when these message are sent or received or other events occur  play a central role in a human protocol if people run different protocols  e.g  if one person has manners but the other does not  or if one understands the concept of time and the other does not  the protocols do not interoperate and no useful work can be accomplished the same is true in networking  it takes two  or more  communicating entities running the same protocol in order to accomplish a task let 's consider a second human analogy suppose you 're in a college class  a computer networking class  for example !   the teacher is droning on about protocols and you 're confused the teacher stops to ask  " are there any questions ? "  a message that is transmitted to  and received by  all students who are not sleeping   you raise your hand  transmitting an implicit message to the teacher   your teacher acknowledges you with a smile  saying " yes  "  a transmitted message encouraging you to ask your question  teachers love to be asked questions  and you then ask your question  i.e  transmit your message to your teacher   your teacher hears your question  receives your question message  and answers  transmits a reply to you   once again  we see that the transmission and receipt of messages  and a set of conventional actions taken when these mesages are sent and received  are at the heart of this question-and-answer protocol network protocols file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/protocol.htm  1 of 3  20/11/2004 15  51  38 what is a protocol ? a network protocol is similar to a human protocol  except that the entities exchanging messages and taking actions are hardware or software components of a computer network  components that we will study shortly in the following sections all activity in the internet that involves two or more communicating remote entities is governed by a protocol protocols in routers determine a packet 's path from source to destination ; hardware-implemented protocols in the network interface cards of two physically connected computers control the flow of bits on the " wire " between the two computers ; a congestion control protocol controls the rate at which packets are transmitted between sender and receiver protocols are running everywhere in the internet  and consequently much of this book is about computer network protocols figure 1.2-1  a human protocol and a computer network protocol as an example of a computer network protocol with which you are probably familiar  consider what happens when you make a request to a www server  i.e  when you type in the url of a www page into your web browser the scenario is illustrated in the right half of figure 1.2-1 first  your computer will send a so-called " connection request " message to the www server and wait for a reply the www server will eventually receive your connection request message and return a " connection reply " message knowing that it is now ok to request the www document  your computer then sends the name of the www page it wants to fetch from that www server in a " get " message finally  the www server returns the contents of the www document to your computer given the human and networking examples above  the exchange of messages and the actions taken when these messages are sent and received are the key defining elements of a protocol  a protocol defines the format and the order of messages exchanged between two or more communicating entities  as well as the actions taken on the transmission and/or receipt of a message file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/protocol.htm  2 of 3  20/11/2004 15  51  38 what is a protocol ? the internet  and computer networks in general  make extensive use of protocols different protocols are used to accomplish different communication tasks as you read through this book  you will learn that some protocols are simple and straightforward  while others are complex and intellectually deep mastering the field of computer networking is equivalent to understanding the what  why and how of networking protocols return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/protocol.htm  3 of 3  20/11/2004 15  51  38 end systems  protocols  and end-to-end service models 1.3 the network edge in the previous sections we presented a high-level description of the internet and networking protocols we are now going to delve a bit more deeply into the components of the internet we begin in this section at the edge of network and look at the components with which we are most familiar  the computers  e.g  pcs and workstations  that we use on a daily basis in the next section we will move from the network edge to the network core and examine switching and routing in computer networks then in section 1.5 we will discuss the actual physical links that carry the signals sent between the computers and the switches 1.3.1 end systems  clients and servers in computer networking jargon  the computers that we use on a daily basis are often referred to as or hosts or end systems they are referred to as " hosts " because they host  run  application-level programs such as a web browser or server program  or an e-mail program they are also referred to as " end systems " because they sit at the " edge " of the internet  as shown in figure 1.3-1 throughout this book we will use the terms hosts and end systems interchangeably  that is  host = end system hosts are sometimes further divided into two categories  clients and servers informally  clients often tend to be desktop pc 's or workstations  while servers are more powerful machines but there is a more precise meaning of a client and a server in computer networking in the so-called client-server model  a client program running on one end system requests and receives information from a server running on another end system this client-server model is undoubtedly the most prevalent structure for internet applications we will study the client-server model in detail in chapter 2 the web  e-mail  file transfer  remote login  e.g  telnet   newgroups and many other popular applications adopt the client-server model since a client typically runs on one computer and the server runs on another computer  clientserver internet applications are  by definition  distributed applications the client and the server interact with each other by communicating  i.e  sending each other messages  over the internet at this level of abstraction  the routers  links and other " pieces " of the internet serve as a " black box " that transfers messages between the distributed  communicating components of an internet application this is the level of abstraction depicted in figure 1.3-1 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/end_sys.htm  1 of 5  20/11/2004 15  51  38 end systems  protocols  and end-to-end service models figure 1.3-1  end system interaction computers  e.g  a pc or a workstation   operating as clients and servers  are the most prevalent type of end system however  an increasing number of alternative devices  such as so-called network computers and thin clients  thinworld 1998   web tv 's and set top boxes  mills 1998   digital cameras  and other devices are being attached to the internet as end systems an interesting discussion of the continuing evolution of internet applications is  at&t 1998   1.3.2 connectionless and connection-oriented services we have seen that end systems exchange messages with each other according to an application-level protocol in order to accomplish some task the links  routers and other pieces of the internet provide the means to transport these messages between the end system applications but what are the characteristics of this communication service that is provided ? the internet  and more generally tcp/ip networks  provide two types of services to its applications  connectionless service and connection-oriented service a developer creating an internet application  e.g  an email application  a file transfer application  a web application or an internet phone application  must program the application to use one of these two services here  we only briefly describe these two services ; we shall discuss them in much more detail in chapter 3  which covers transport layer protocols file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/end_sys.htm  2 of 5  20/11/2004 15  51  38 end systems  protocols  and end-to-end service models connection-oriented service when an application uses the connection-oriented service  the client and the server  residing in different end systems  send control packets to each other before sending packets with real data  such as e-mail messages   this so-called handshaking procedure alerts the client and server  allowing them to prepare for an onslaught of packets it is interesting to note that this initial hand-shaking procedure is similar to the protocol used in human interaction the exchange of " hi 's " we saw in figure 1.2-1 is an example of a human " handshaking protocol "  even though handshaking is not literally taking place between the two people   the two tcp messages that are exchanged as part of the www interaction shown in figure 1.2-1 are two of the three messages exchanged when tcp sets up a connection between a sender and receiver the third tcp message  not shown  that forms the final part of the tcp three-way handshake  see section 3.7  is contained in the get message shown in figure 1.2-1 once the handshaking procedure is finished  a " connection " is said to be established between the two end systems but the two end systems are connected in a very loose manner  hence the terminology " connection-oriented "  in particular  only the end systems themselves are aware of this connection ; the packet switches  i.e  routers  within the internet are completely oblivious to the connection this is because a tcp connection is nothing more than allocated resources  buffers  and state variables in the end systems the packet switches do not maintain any connection state information the internet 's connection oriented service comes bundled with several other services  including reliable data transfer  flow control and congestion control by reliable data transfer  we mean that an application can rely on the connection to deliver all of its data without error and in the proper order reliability in the internet is achieved through the use of acknowledgments and retransmissions to get a preliminary idea about how the internet implements the reliable transport service  consider an application that has established a connection between end systems a and b when end system b receives a packet from a  it sends an acknowledgment ; when end system a receives the acknowledgment  it knows that the corresponding packet has definitely been received when end system a does n't receive an acknowledgment  it assumes that the packet it sent was not received by b ; it therefore retransmits the packet.flow control makes sure that neither side of a connection overwhelms the other side by sending too many packets too fast indeed  the application at one one side of the connection may not be able to process information as quickly as it receives the information therefore  there is a risk of overwhelming either side of an application the flow-control service forces the sending end system to reduce its rate whenever there is such a risk we shall see in chapter 3 that the internet implements the flow control service by using sender and receiver buffers in the communicating end systems the internet 's congestion control service helps prevent the internet from entering a state of grid lock when a router becomes congested  its buffers can overflow and packet loss can occur in such circumstances  if every pair of communicating end systems continues to pump packets into the network as fast as they can  gridlock sets in and few packets are delivered to their destinations the internet avoids this problem by forcing end systems to diminish the rate at which they send packets into the network during periods of congestion end systems are alerted to the existence of severe congestion when they stop receiving acknowledgments for the packets they have sent file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/end_sys.htm  3 of 5  20/11/2004 15  51  38 end systems  protocols  and end-to-end service models we emphasize here that although the internet 's connection-oriented service comes bundled with reliable data transfer  flow control and congestion control  these three features are by no means essential components of a connection-oriented service a different type of computer network may provide a connection-oriented service to its applications without bundling in one or more of these features indeed  any protocol that performs handshaking between the communicating entities before transferring data is a connection-orieinted service  iren   the internet 's connection-oriented service has a name  tcp  transmission control protocol  ; the initial version of the tcp protocol is defined in the internet request for comments rfc 793  rfc 793   the services that tcp provides to an application include reliable transport  flow control and congestion control it is important to note that an application need only care about the services that are provided ; it need not to worry about how tcp actually implements reliability  flow control  or congestion control we  of course  are very interested in how tcp implements these services and we shall cover these topics in detail in chapter 3 connectionless service there is no handshaking with the internet 's connectionless service when one side of an application wants to send packets to another side of an application  the sending application simply sends the packets since there is no handshaking procedure prior to the transmission of the packets  data can be delivered faster but there are no acknowledgments either  so a source never knows for sure which packets arrive at the destination moreover  the service makes no provision for flow control or congestion control the internet 's connectionless service is provided by udp  user datagram protocol  ; udp is defined in the internet request for comments rfc 768  rfc 768   most of the more familiar internet applications use tcp  the internet 's connection-oriented service these applications include telnet  remote login   smtp  for electronic mail   ftp  for file transfer   and http  for the web   nevertheless  udp  the internet 's connectionless service  is used by many applications  including many of the emerging multimedia applications  such as internet phone  audio-ondemand  and video conferencing references  at&t 1998  " killer apps  " at&t www page http  //www.att.com/attlabs/brainspin/networks/ killerapps.html  iren  s.iren  p.amer  p.conrad  " the transport layer  tutorial and survey  " acm computing surveys  june 1999  thinworld 1998  thinworld homepage  http  //www.thinworld.com/  mills 1998  s mills  " tv set-tops set to take off "  cnet news.com  oct 1998  rfc 768  j postel  " datagram protocol  " rfc 768  aug 1980 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/end_sys.htm  4 of 5  20/11/2004 15  51  38 end systems  protocols  and end-to-end service models  rfc 793  j postel  " transmission control protocol  " rfc 793  september 1981 return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/end_sys.htm  5 of 5  20/11/2004 15  51  38 the network core 1.4 the network core having examined the endsystems and end-end transport service model of the internet in section 1.3  let us now delve more deeply into the " inside " of the network in this section we study the network core  the mesh of routers that interconnect the internet 's endsystems figure 1.4-1 highlights the network core in red figure 1.4-1  the network core 1.4.1 circuit switching  packet switching and message switching there are two fundamental approaches towards building a network core  circuit switching and packet switching in circuit-switched networks  the resources needed along a path  buffers  link bandwidth  to provide for communication between the endsystems are reserved for the duration of the session in packet-switched networks  these resources are not reserved ; a session 's messages use the resource on demand  and as a consequence  may have to wait  i.e  queue  for access to a communication link as a simple analogy  consider two restaurants  one which requires reservations and another which neither requires reservations nor accepts them for the restaurant that requires reservations  we have to go file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  1 of 17  20/11/2004 15  51  40 the network core through the hassle of first calling  or sending an e-mail !  before we leave home but when we arrive at the restaurant we can  in principle  immediately communicate with the waiter and order our meal for the restaurant that does not require reservations  we do n't need to bother to reserve a table but when we arrive at the restaurant  we may have to wait for a table before we can communicate with the waiter the ubiquitous telephone networks are examples of circuit-switched networks consider what happens when one person wants to send information  voice or facsimile  to another over a telephone network before the sender can send the information  the network must first establish a connection between the sender and the receiver in contrast with the tcp connection that we discussed in the previous section  this is a bona fide connection for which the switches on the path between the sender and receiver maintain connection state for that connection in the jargon of telephony  this connection is called a circuit when the network establishes the circuit  it also reserves a constant transmission rate in the network 's links for the duration of the connection this reservation allows the sender to transfer the data to the receiver at the guaranteed constant rate today 's internet is a quintessential packet-switched network consider what happens when one host wants to send a packet to another host over a packet-switched network as with circuit-switching  the packet is transmitted over a series of communication links but with packet-switching  the packet is sent into the network without reserving any bandwidth whatsoever if one of the links is congested because other packets need to be transmitted over the link at the same time  then our packet will have to wait in a buffer at the sending side of the transmission line  and suffer a delay the internet makes its best effort to deliver the data in a timely manner but it does not make any guarantees not all telecommunication networks can be neatly classified as pure circuit-switched networks or pure packet-switched networks for example  for networks based on the atm technology  a connection can make a reservation and yet its messages may still wait for congested resources ! nevertheless  this fundamental classification into packet and circuit-switched networks is an excellent starting point in understanding telecommunication network technology circuit switching this book is about computer networks  the internet and packet switching  not about telephone networks and circuit switching nevertheless  it is important to understand why the internet and other computer networks use packet switching rather than the more traditional circuit-switching technology used in the telephone networks for this reason  we now give a brief overview of circuit switching figure 1.4-2 illustrates a circuit-switched network in this network the three circuit switches are interconnected by two links ; each of these links has n circuits  so that each link can support n simultaneous connections the endsystems  e.g  pcs and workstations  are each directly connected to one of the switches  ordinary telephones are also connected to the switches  but they are not shown in the diagram  notice that some of the hosts have analog access to the switches  whereas others have direct digital access for analog access  a modem is required when two hosts desire to communicate  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  2 of 17  20/11/2004 15  51  40 the network core the network establishes a dedicated end-to-end circuit between two hosts  conference calls between more than two devices are  of course  also possible but to keep things simple  let 's suppose for now that there are only two hosts for each connection  thus in order for host a to send messages to host b  the network must first reserve one circuit on each of two links figure 1.4-2  a simple circuit-switched network consisting of three circuit switches interconnected with two links each link has n circuits ; each end-to-end circuit over a link gets the fraction 1/n of the link 's bandwidth for the duration of the circuit the ncircuits in a link can be either tdm or fdm circuits a circuit in a link is implemented with either frequency division multiplexing  fdm  or time-division multiplexing  tdm   with fdm  the frequency spectrum of a link is shared among the connections established across the link specifically  the link dedicates a frequency band to each connection for the duration of the connection in telephone networks  this frequency band typically has a width of 4 khz the width of the band is called  not surprisingly  the bandwidth fm radio stations also use fdm to share microwave frequency spectrum file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  3 of 17  20/11/2004 15  51  40 the network core the trend in modern telephony is to replace fdm with tdm the majority of the links in most telephone systems in the united states and in other developed countries currently employ tdm for a tdm link  time is divided into frames of fixed duration and each frame is divided into a fixed number of time slots when the network establish a connection across a link  the network dedicates one time slot in every frame to the connection these slots are dedicated for the sole use of that connection  with a time slot available for use  in every frame  to transmit the connection 's data figure 1.4.3 illustrates fdm and tdm for a specific network link for fdm  the frequency domain is segmented into a number of circuits  each of bandwidth 4 khz  i.e  4,000 hertz or 4,000 cycles per second   for tdm  the time domain is segmented into four circuits ; each circuit is assigned the same dedicated slot in the revolving tdm frames the transmission rate of the frame is equal to the frame rate multiplied by the number of bits in a slot for example  if the link transmits 8,000 frames per second and each slot consists of 8 bits  then the transmission rate is 64 kbps figure 1.4-3  with fdm  each circuit continuously gets a fraction of the bandwidth with tdm  each circuit gets all of the bandwidth periodically during brief intervals of time  i.e  during slots   proponents of packet switching have always argued that circuit switching is wasteful because the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  4 of 17  20/11/2004 15  51  40 the network core dedicated circuits are idle during silent periods for example  when one of the conversants in a telephone call stops talking  the idle network resources  frequency bands or slots in the links along the connection 's route  can not be used by other ongoing connections as another example of how these resources can be underutilized  consider a radiologist who uses a circuit-switched network to remotely access a series of x-rays the radiologist sets up a connection  requests an image  contemplates the image  and then requests a new image network resources are wasted during the radiologist 's contemplation periods proponents of packet switching also enjoy pointing out that establishing end-toend circuits and reserving end-to-end bandwidth is complicated and requires complex signaling software to coordinate the operation of the switches along the end-to-end path before we finish our discussion of circuit switching  let 's work through a numerical example that should shed further insight on the matter let us consider how long it takes to send a file of 640 kbits from host a to host b over a circuit-switched network suppose that all links in the network use tdm with 24 slots and have bit rate 1.536 mbps also suppose that it takes 500 msec to establish an end-to-end circuit before a can begin to transmit the file how long does it take to send the file ? each circuit has a transmission rate of  1.536 mbps  /24 = 64 kbps  so it takes  640 kbits  /  64 kbps  = 10 seconds to transmit the file to this 10 seconds we add the the circuit establishment time  giving 10.5 seconds to send the file note that the transmission time is independent of the number links  the transmission time would be 10 seconds if the end-to-end circuit passes through one link or one-hundred links at&t labs provides an interactive site  at&t 1998  to explore transmission delay for various file types and transmission technologies packet switching we saw in sections 1.2 and 1.3 that application-level protocols exchange messages in accomplishing their task messages can contain anything the protocol designer desires messages may perform a control function  e.g  the " hi " messages in our handshaking example  or can contain data  such as an ascii file  a postscript file  a web page  a digital audio file in modern packet-switched networks  the source breaks long messages into smaller packets between source and destination  each of these packets traverse communication links and packet switches  also known as routers   packets are transmitted over each communication link at a rate equal to the full transmission rate of the link most packet switches use store and forward transmission at the inputs to the links store-and-forward transmission means that the switch must receive the entire packet before it can begin to transmit the first bit of the packet onto the outbound link thus store-and-forward packet-switches introduce a store-andforward delay at the input to each link along the packet 's route this delay is proportional to the packet 's length in bits in particular  if a packet consists of l bits  and the packet is to be forwarded onto an outbound link of r bps  then the store-and-forward delay at the switch is l/r seconds within each router there are multiple buffers  also called queues   with each link having an input buffer  to store packets that have just arrived to that link  and an output buffer the output buffers play a key role in packet switching if an arriving packet needs to be transmitted across a link but finds the link busy with the transmission of another packet  the arriving packet must wait in the output buffer thus  in file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  5 of 17  20/11/2004 15  51  40 the network core addition to the store-and-forward delays  packets suffer output buffer queueing delays these delays are variable and depend on the level of congestion in the network since the amount of buffer space is finite  an arriving packet may find that the buffer is completely filled with other packets waiting for transmission in this case  packet loss will occur  either the arriving packet or one of the alreadyqueued packets will be dropped returning to our restaurant analogy from earlier in this section  the queueing delay is analogous to the amount of time one spends waiting for a table packet loss is analogous to being told by the waiter that you must leave the premises because there are already too many other people waiting at the bar for a table figure 1.4-4 illustrates a simple packet-switched network suppose hosts a and b are sending packets to host e hosts a and b first send their packets along 28.8 kbps links to the first packet switch the packet switch directs these packets to the 1.544 mbps link if there is congestion at this link  the packets queue in the link 's output buffer before they can be transmitted onto the link consider now how host a and host b packets are transmitted onto this link as shown in figure 1.4-4  the sequence of a and b packets does not follow any periodic ordering ; the ordering is random or statistical  packets are sent whenever they happen to be present at the link for this reason  we often say that packet switching employs statistical multiplexing statistical multiplexing sharply contrasts with time-division multiplexing  tdm   for which each host gets the same slot in a revolving tdm frame file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  6 of 17  20/11/2004 15  51  40 the network core figure 1.4-4  packet switching let us now consider how long it takes to send a packet of l bits from host a to another host across a packet-switched network let us suppose that there are q links between a and e  each of rate r bps assume that queueing delays and end-to-end propagation delays are negligible and that there is no connection establishment the packet must first be transmitted onto the first link emanating from host a ; this takes l/r seconds it must then be transmitted on each of the q-1 remaining links  that is  it must be stored-and-forwarded q-1 times thus the total delay is ql/r packet switching versus circuit switching having described circuit switching and packet switching  let us compare the two opponents of packet switching have often argued that the packet switching is not suitable for real-time services  e.g  telephone calls and video conference calls  due to its variable and unpredictable delays proponents of packet switching argue that  1  it offers better sharing of bandwidth than circuit switching and  2  it is simpler  more efficient  and less costly to implement than circuit-switching generally speaking  people who do not like to hassle with restaurant reservations prefer packet switching to circuit switching file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  7 of 17  20/11/2004 15  51  40 the network core why is packet-switching more efficient ? let us look at a simple example suppose users share a 1 mbps link also suppose that each user alternates between periods of activity  when it generates data at a constant rate of 100kbits/sec  and periods of inactivity  when it generates no data   suppose further that a user is active only 10 % of the time  and is idle drinking coffee during the remaining 90 % of the time   with circuit-switching  100 kbps must be reserved for each user at all times thus  the link can support only ten simultaneous users with packet switching  if there are 35 users  the probability that there are 10 or more simultaneously active users is less than .0004 if there are 10 or less simultaneously active users  which happens with probability .9996   the aggregate arrival rate of data is less than 1mbps  the output rate of the link   thus  users ' packets flow through the link essentially without delay  as is the case with circuit switching when there are more than 10 simultaneously active users  then the aggregate arrival rate of packets will exceed the output capacity of the link  and the output queue will begin to grow  until the aggregate input rate falls back below 1mbps  at which point the queue will begin to diminish in length   because the probability of having ten or more simultaneously active users is very very small  packet-switching almost always has the same delay performance as circuit switching  but does so while allowing for more than three times the number of users although packet switching and circuit switching are both very prevalent in today 's telecommunication networks  the trend is certainly in the direction of packet switching even many of today 's circuitswitched telephone networks are slowly migrating towards packet switching in particular  telephone networks often convert to packet switching for the expensive overseas portion of a telephone call message switching in a modern packet-switched network  the source host segments long messages into smaller packets and sends the smaller packets into the network ; the receiver reassembles the packets back into the original message but why bother to segment the messages into packets in the first place  only to have to reassemble packets into messages ? does n't this place an additional and unnecessary burden on the source and destination ? although the segmentation and reassembly do complicate the design of the source and receiver  researchers and network designers concluded in the early days of packet switching that the advantages of segmentation greatly compensate for its complexity before discussing some of these advantages  we need to introduce some terminology we say that a packet-switched network performs message switching if the sources do not segment messages  i.e  they send a message into the network as a whole thus message switching is a specific kind of packet switching  whereby the packets traversing the network are themselves entire messages figure 1.4-5 illustrates message switching in a route consisting of two packet switches  pss  and three links with message switching  the message stays in tact as it traverses the network because the switches are store-and-forward packet switches  a packet switch must receive the entire message before it can begin to forward the message on an outbound link file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  8 of 17  20/11/2004 15  51  40 the network core figure 1.4-5  a simple message-switched network figure 1.4-6 illustrates packet switching for the same network in this example the original message has been divided into five distinct packets in figure 1.4-6  the first packet has arrived at the destination  the second and third packets are in transit in the network  and the last two packets are still in the source again  because the switches are store-and-forward packet switches  a packet switch must receive an entire packet before it can begin to forward the packet on an outbound link figure 1.4-6  a simple packet-switched network one major advantage of packet switching  with segmented messages  is that it achieves end-to-end delays that are typically much smaller than the delays associated with message-switching we illustrate this point with the following simple example consider a message that is 7.5 mbits long suppose that between source and destination there are two packet switches and three links  and that each link has a transmission rate of 1.5mbps assuming there is no congestion in the network  how much time is required to move the message from source to destination with message switching ? it takes the source 5 seconds to move the message from the source to the first switch because the switches use store-andforward  the first switch can not begin to transmit any bits in the message onto the link until this first switch has received the entire message once the first switch has received the entire message  it takes 5 seconds to move the message from the first switch to the second switch thus it takes ten seconds to move the message from the source to the second switch following this logic we see that a total of 15 seconds is needed to move the message from source to destination these delays are illustrated in figure 1.4-7 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  9 of 17  20/11/2004 15  51  40 the network core figure 1.4-7  timing of message transfer of a 7.5 mbit message in a message-switched network continuing with the same example  now suppose that the source breaks the message into 5000 packets  with each packet being 1.5 kbits long again assuming that there is no congestion in the network  how long does it take to move the 5000 packets from source to destination ? it takes the source 1 msec to move the first packet from the source to the first switch and it takes the first switch 1 msec to move this first packet from the first to the second switch but while the first packet is being moved from the first switch to the second switch  the second packet is simultaneously moved from the source to the first switch thus the second packet reaches the first switch at time = 2 msec following this logic we see that the last packet is completely received at the first switch at time = 5000 msec = 5 seconds since this last packet has to be transmitted on two more links  the last packet is received by the destination at 5.002 seconds   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  10 of 17  20/11/2004 15  51  40 the network core figure 1.4-8  timing of packet transfer of a 7.5 mbit message  divided into 5000 packets  in a packetswitched network amazingly enough  packet-switching has reduced the message-switching delay by a factor of three ! but why is this so ? what is packet-switching doing that is different from message switching ? the key difference is that message switching is performing sequential transmission whereas packet switching is performing parallel transmission observe that with message switching  while one node  the source or one of the switches  is transmitting  the remaining nodes are idle with packet switching  once the first packet reaches the last switch  three nodes transmit at the same time packet switching has yet another important advantage over message switching as we will discuss later file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  11 of 17  20/11/2004 15  51  40 the network core in this book  bit errors can be introduced into packets as they transit the network when a switch detects an error in a packet  it typically discards the entire packet so  if the entire message is a packet and one bit in the message gets corrupted  the entire message is discarded if  on the other hand  the message is segmented into many packets and one bit in one of the packets is corrupted  then only that one packet is discarded packet switching is not without its disadvantages  however  with respect to message switching we will see that each packet or message must carry  in addition to the data being sent from the sending application to the receiving application  an amount of control information this information  which is carried in the packet or message header  might include the identity of the sender and receiver and a packet or message identifier  e.g  number   since the amount of header information would be approximately the same for a message or a packet  the amount of header overhead per byte of data is higher for packet switching than for message switching before moving on to the next subsection  you are highly encouraged to explore the message switching java applet this applet will allow you to experiment with different message and packet sizes  and will allow you to examine the effect of additional propagation delays 1.4.2 routing in data networks there are two broad classes of packet-switched networks  datagram networks and virtual-circuit networks they differ according to whether they route packets according to host destination addresses or according to virtual circuit numbers we shall call any network that routes packets according to host destination addresses a datagram network the ip protocol of the internet routes packets according to the destination addresses ; hence the internet is a datagram network we shall call any network that routes packets according to virtual-circuit numbers a virtual-circuit network examples of packetswitching technologies that use virtual circuits include x.25  frame relay  and atm virtual circuit networks a virtual circuit  vc  consists of  1  a path  i.e  a series of links and packet switches  between the source and destination hosts   2  virtual circuit numbers  one number for each link along the path  and  3  entries in vc-number translation tables in each packet switch along the path once a vc is established between source and destination  packets can be sent with the appropriate vc numbers because a vc has a different vc number on each link  an intermediate packet switch must replace the vc number of each traversing packet with a new one the new vc number is obtained from the vcnumber translation table to illustrate the concept  consider the network shown in figure 1.4-9 suppose host a requests that the network establish a vc between itself and host b suppose that the network chooses the patha  ps1  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  12 of 17  20/11/2004 15  51  40 the network core ps2  b and assigns vc numbers 12  22  32 to the three links in this path then  when a packet as part of this vc leaves host a  the value in the vc number field is 12 ; when it leaves ps1  the value is 22 ; and when it leaves ps2  the value is 32 the numbers next to the links of ps1 are the interface numbers figure 1.4-9  a simple virtual circuit network how does the switch determine the replacement vc number for a packet traversing the switch ? each switch has a vc number translation table ; for example  the vc number translation table in ps 1 might look something like this  incoming interface incoming vc # outgoing interface outgoing vc # 1 12 3 22 2 63 1 18 3 7 2 17 1 97 3 87     whenever a new vc is established across a switch  an entry is added to the vc number table similarly  whenever a vc terminates  the entries in each table along its path are removed file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  13 of 17  20/11/2004 15  51  40 the network core you might be wondering why a packet does n't just keep the same vc number on each of the links along its route ? the answer to this question is twofold first  by replacing the number from link to link  the length of the vc field is reduced second  and more importantly  by permitting a different vc number for each link along the path of the vc  a network management function is simplified specifically  with the multiple vc numbers  each link in the path can choose a vc number independently of what the other links in the path chose if a common number were required for all links along the path  the switches would have to exchange and process a substantial number of messages to agree on the vc number to be used for a connection if a network employs virtual circuits  then the network 's switches must maintain state information for the ongoing connections specifically  each time a new connection is established across a switch  a new connection entry must be added to the switch 's vc-number translation table ; and each time a connection is released  an entry must be removed from the table note that even if there is no vc number translation  it is still necessary to maintain state information that associates vc numbers to interface numbers the issue of whether or not a switch or router maintains state information for each ongoing connection is a crucial one  one which we return to shortly below datagram networks datagam networks are analogous in many respects to the postal services  when a sender sends a letter to a destination  the sender wraps the letter in an envelope and writes the destination address on the envelope this destination address has a hierarchical structure for example  letters sent to a location in the united states include the country  the usa   the state  e.g  pennsylvania   the city  e.g  philadelphia   the street  e.g  walnut street  and the number of the house on the street  e.g  421   the postal services use the address on the envelope to route the letter to its destination for example  if the letter is sent from france  then a postal office in france will first direct the letter to a postal center in the usa this postal center in the usa will then send the letter to a postal center in philadelphia finally a mail person working in philadelphia will deliver the letter to its ultimate destination in a datagram network  each packet that traverses the network contains in its header the address of the destination as with postal addresses  this address has a hierarchical structure when a packet arrives at a packet switch in the network  the packet switch examines a portion of the packet 's destination address and forwards the packet to an adjacent switch more specifically  each packet switch has a routing table which maps destination addresses  or portions of the destination addresses  to an outbound link when a packet arrives at switch  the switch examines the address and indexes its table with this address to find the appropriate outbound link the switch then sends the packet into this outbound link the whole routing process is also analogous to the car driver who does not use maps but instead prefers to ask for directions for example  suppose joe is driving from philadelphia to 156 lakeside drive in orlando  florida joe first drives to his neighborhood gas station and asks how to get to 156 lakeside drive in orlando  florida the gas station attendant extracts the florida portion of the address and tells joe that he needs to get onto the interstate highway i-95 south  which has an entrance just next to the gas file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  14 of 17  20/11/2004 15  51  40 the network core station he also tells joe that once he enters florida he should ask someone else there joe then takes i 95 south until he gets to jacksonville  florida  at which point he asks another gas station attendant for directions the attendant extracts the orlando portion of the address and tells joe that he should continue on i-95 to daytona beach and then ask someone else in daytona beach another gas station attendant also extracts the orlando portion of the address and tells joe that he should take i-4 directly to orlando joe takes i-4 and gets off at the orlando exit joe goes to another gas station attendant  and this time the attendant extracts the lakeside drive portion of the address  and tells joe the road he must follow to get to lakeside drive once joe reaches lakeside drive he asks a kid on a bicycle how to get to his destination the kid extracts the 156 portion of the address and points to the house joe finally reaches his ultimate destination we will be discussing routing in datagram networks in great detail in this book but for now we mention that  in contrast with vc networks  datagram networks do not maintain connection state information in their switches in fact  a switch in a pure datagram network is completely oblivious to any flows of traffic that may be passing through it  it makes routing decisions for each individual packet because vc networks must maintain connection state information in their switches  opponents of vc networks argue that vc networks are overly complex these opponents include most researchers and engineers in the internet community proponents of vc networks feel that vcs can offer applications a wider variety of networking services many researchers and engineers in the atm community are outspoken advocates for vcs how would you like to actually see the route packets take in the internet ? we now invite you to get your hands dirty by interacting with the traceroute program network taxonomy we have now introduced several important networking concepts  circuit switching  packet switching  message switching  virtual circuits  connectionless service  and connection oriented service how does it all fit together ? first  in our simple view of the world  a telecommunications network either employs circuit-switching or packet-switching  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  15 of 17  20/11/2004 15  51  40 the network core figure 1.4-10  highest-level distinction among telecommunication networks  circuit-switched or packetswitched ? a link in a circuit-switched network can employ either fdm or tdm  figure 1.4-11  circuit switching implementation  fdm or tdm ? packet switch networks are either virtual-circuit networks or datagram networks switches in virtualcircuit networks route packets according to the packets ' vc numbers and maintain connection state switches in datagram networks route packets according to the packets ' destination addresses and do not maintain connection state  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  16 of 17  20/11/2004 15  51  40 the network core figure 1.4-12  packet switching implementation  virtual circuits or datagrams ? examples of packet-switched networks which use vcs include x.25  frame relay  and atm a packetswitched network either  1  uses vcs for all of its message routing  or  2  uses destination addresses for all of its message routing it does n't employ both routing techniques  this last statement is a bit of a white lie  as there are networks that use datagram routing " on top of " vc routing this is the case for " ip over atm  " as we shall cover later in the book  a datagram network is not  however  either a connectionless or a connection-oriented network indeed  a datagram network can provide the connectionless service to some of its applications and the connectionoriented service to other applications for example  the internet  which is a datagram network  is a datagram network that provides both connectionless and connection-oriented service to its applications we saw in section 1.3 that these services are provided in the internet by the udp and tcp protocols  respectively networks with vcs  such as x.25  frame relay  and atm  are always  however  connection-oriented return to table of contents copyright keith w ross and jim kurose 1996-2000 | /downloads/livros/computa ? ? o/computer % 20net...pproach % 20featuring % 20the % 20internet/network_core.htm  17 of 17  20/11/204 15  51  40 message switching interactive java applet  message switching & packet switching this interactive applet enables you to actually see why packet switching can have much smaller delays than message switching when packets pass through store-and-forward switches in this applet there are four nodes  a source  node a   a destination  node b   and two store-and-forward switches each packet sent from the source must be transmitted over three links before it reaches the destination each of these links has a transmission rate of 4 kbps and an optional propagation delay of one second each small rectangle represents 1 kbit of data when you press start  the rectangles are grouped into one packet in the transmit buffer of the source the packet is transmitted to the first switch  where it must be stored before it is forwarded the packet then continues towards the destination to simulate message switching  set the packet size equal to the message size to simulate packet switching  set the packet size to less than the message size to examine the effect of link propagation delays  check the appropriate boxes for optional propagation delays for a variety of scenarios  it is highly recommended that you calculate the end-to-end delay analytically and then verify your calculation with the applet 15  51  40 tracing routes in the internet traceoute is a popular program for tracing a packet 's route from any source host to any destination host in the internet before we explain what traceroute does and how it works  first try running the traceroute program in the box below  enter the name of any host  such as surf.eurecomf.fr or www.mit edu the host name that you enter will be sent to a server located at ibm israel in tel-aviv  israel the host in tel-aviv will respond with the route taken from tel-aviv to the host you have listed in the box below after running the program  return to this page for a discussion of the traceroute program host address or name leave empty to find the route to your browser after having traced the route from tel-aviv to your favorite host  try it again with a new starting place  dana point in sunny southern california host address or name what traceroute does and how it works the main packet switches in the internet are called routers  and routers use datagram routing specifically  when a source constructs a packet  it appends the destination address onto the packet when the packet arrives at a router  the switch determines the appropriate outgoing link for the packet by examining the packet 's destination address traceroute is a little program that can run in any internet host when the user specifies a destination host name  the program sends multiple packets towards that destination as these packets work their way towards the destinations  they pass through a series of routers when a router receives one of these packets  it sends a little message back to the source this message contains the name and address of the router more specifically  suppose there are n-1 routers between the soruce and the destination then the source will send n packets into the network  with each packet addressed to the ultimate destination these packets are also marked 1 through n  with the first of the n packets marked 1 and the last of the n packets marked n when the nth router receives the nth packet marked n  the router destroys the packet and sends a message to the source and when the destination host receives the nth packet  the file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/traceroute.htm  1 of 4  20/11/2004 15  51  41 windows \ desktop \ keith \ book \ overview \ traceroute destination destoys it as well  but again returns a message back to the source the source records the time that elapses from when it sends a packet until when it receives the corresponding return message ; it also records the name and address of the router  or the destination host  that returns the message in this manner  the source can reconstruct the route taken by packets flowing from source to destination  and the source can determine the round-trip delays to all the intervening routers traceroute actually repeats the experiment just described three times  so the source actually sends 3 * n packets to the destination the  rfc 1393  describes traceout in detail the internet encyclopedia as also gives an overview of how traceroute works here is an example of the output of the traceroute program  where the route is being traced from the source host eniac.seas.upenn.edu  at the university of pennsylvania  to diane.ibp.fr  at the university of paris vi   the output has six columns  the first column is the n value described above  i.e  the number of the router along the route ; the second column is the name of the router ; the third column is the address of the router  of the form xxx.xxx.xxx.xxx  ; the last three columns are the round-trip delays for three experiments if the source receives less than three messages from any given router  because of packet loss in the network  traceroute places an asterisk just after the router number and reports less than three round-trip times for that router 1 gw.cis.upenn.edu  130.91.6.254  3 ms 2 ms 1 ms 2 default7-gw.upenn.edu  165.123.247.8  3 ms 1 ms 2 ms 3 192.204.183.1  192.204.183.1  3 ms 4 ms 3 ms 4 border2-hssi1-0.westorange.mci.net  204.70.66.5  6 ms 6 ms 6 ms 5 core1-fddi-1.westorange.mci.net  204.70.64.33  7 ms 6 ms 6 ms 6 somerouter.sprintlink.net  206.157.77.106  16 ms 305 ms 192 ms 7 somerouter.sprintlink.net  206.157.77.106  20 ms 196 ms 18 ms 8 sl-dc-6-h2/0-t3.sprintlink.net  144.228.10.33  19 ms 18 ms 24 ms 9 198.67.0.1  198.67.0.1  19 ms 24 ms 18 ms 10 gsl-dc-3-fddi0/0.gsl.net  204.59.144.197  19 ms 18 ms 20 ms 11 * raspail-ip.eurogate.net  194.206.207.6  133 ms 94 ms file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/traceroute.htm  2 of 4  20/11/2004 15  51  41 windows \ desktop \ keith \ book \ overview \ traceroute 12 raspail-ip2.eurogate.net  194.206.207.57  93 ms 95 ms 97 ms 13 194.206.207.17  194.206.207.17  200 ms 94 ms 209 ms 14 stamand1.renater.ft.net  192.93.43.185  105 ms 101 ms 105 ms 15 stlambert.rerif.ft.net  192.93.43.117  108 ms 102 ms 95 ms 16 danton1.rerif.ft.net  193.48.53.50  110 ms 97 ms 91 ms 17 u-jussieu-paris.rerif.ft.net  193.48.58.122  94 ms 96 ms 100 ms 18 r-jusren.reseau.jussieu.fr  192.44.54.126  100 ms 94 ms 100 ms 19 r-ibp.reseau.jussieu.fr  134.157.254.250  96 ms 100 ms 94 ms 20 masi.ibp.fr  132.227.60.23  121 ms 100 ms 97 ms 21 * diane.ibp.fr  132.227.64.48  105 ms 102 ms in the above trace there are no routers between the source and the destination most of these routers have a name  and all of them have addresses for example  the name of router 8 is sl-dc-6-h2/0-t3.sprintlink net and its address is 144.228.10.33 looking at the data provided for this same router  we see that in the first of the three trials the roundtrip delay between the source and the router 8 was 19 msec the roundtrip delays for the subsequent two trials were 18 and 24 msec these roundtrip delays include packet propagation delays  router processing delays  and queueing delays due to congestion in the internet because the congestion is varying with time  the roundtrip delay to a router n can actually be longer than the roundtrip delay to router n + 1 note in the above example that there is a big jump in the round-trip delay when going from router 10 to router 11 this is because the link between routers 10 and 11 is a transatlantic link want to try out traceroute from some other starting points besides tel-aviv and dana point ? then visit yahoo 's list of sites offering route tracing references  rfc 1393  g malkin  " traceroute using an ip option  " rfc 1393  january 1993 return to table of contents file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/traceroute.htm  3 of 4  20/11/2004 15  51  41 windows \ desktop \ keith \ book \ overview \ traceroute copyright keith w ross and jim kurose 1996-1998 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/traceroute.htm  4 of 4  20/11/2004 15  51  41 access networks and physical media 1.5 access networks and physical media in sections 1.3 and 1.4 we have examined the roles of end systems and routers in a network architecture in this section we consider the access network  the physical link  s  that connect an end system to its edge router  i.e  the first router on a path from the end system to any other distant end system since access network technology is closely tied to physical media technology  fiber  coaxial pair  twisted pair telephone wire  radio spectrum   we consider these two topics together in this section 1.5.1 access networks figure 1.5-1 shows the access networks ' links highlighted in red figure 1.5-1  access networks access networks can be loosely divided into three categories  l residential access networks  connecting a home end system into the network ; l institutional access networks  connecting an end system in a business or educational institution into the network ; l mobile access networks  connecting a mobile end system into the network these categories are not hard and fast ; some corporate end systems may well use the access network technology that we ascribe to residential access networks  and vice versa our descriptions below are meant to hold for the common  if not every  case residential access networks a residential access network connects a home end system  typically a pc  but perhaps a web tv or other residential system  to an edge router probably the most common form of home access is using a modem over a pots  plain old telephone system  dialup line to an internet service provider  isp   the home modem converts the digital output of the pc into analog format for transmission over the analog phone line a modem in the isp converts the analog signal back into digital form for input to the isp router in this case  the " access network " is simply a point-to-point dialup link into an edge router the point-to-point link file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  1 of 7  20/11/2004 15  51  42 access networks and physical media is your ordinary twisted-pair phone line  we will discuss twisted pair later in this section  today 's modem speeds allow dialup access at rates up to 56 kbps however  due to the poor quality of twisted-pair line between many homes and isps  many users get an effective rate significantly less than 56 kbps for an in depth discussion of the practical aspects of modems see the institute for global communications  igc  web page on modems and data communications while dialup modems require conversion of the end system 's digital data into analog form for transmission  so-called narrowband isdn technology  integrated services digital network   pacific bell 1998  allows for all-digital transmission of data from a home end system over isdn " telephone " lines to a phone company central office although isdn was originally conceived as a way to carry digital data from one end of the phone system to another  it is also an important network access technology that provides higher speed access  e.g  128 kbps  from the home into a data network such as the internet in this case  isdn can be thought of simply as a " better modem "  nas 1995   a good source for additional www information on isdn is dan kegel 's isdn page dialup modems and narrowband isdn are already widely deployed technologies two new technologies  asymmetric digital subscriber line  adsl   adsl 1998  and hybrid fiber coaxial cable  hfc   cable 1998  are currently being deployed adsl is conceptually similar to dialup modems  it is a new modem technology again running over existing twisted pair telephone lines  but can transmit at rates of up to about 8 mbps from the isp router to a home end system the data rate in the reverse direction  from the home end system to the central office router  is less than 1 mbps the asymmetry in the access speeds gives rise to the term " asymmetric " in adsl the asymmetry in the data rates reflects the belief that home users are more likely to be a consumer of information  bringing data into their homes  than a producer of information adsl uses frequency division multiplexing  as described in the previous section in particular  adsl divides the communication link between the home the isp into three non-overlapping frequency bands  m a high-speed downstream channel  in the 50 khz to 1 mhz band ; m a medium-speed upstream channel  in the 4 khz to 50 khz band ; m and an ordinary pots two-way telephone channel  in the 0 to 4 khz band one of the features of adsl is that the service allows the user to make an ordinary telephone call  using the pots channel  while simultaneously surfing the web this feature is not available with standard dailup modems the actually amount of downstream and upstream bandwidth available to the user is a function of the distance between the home modem and the isp modem  the gauge of the twisted pair line  and the degree of electrical interference for a high-quality line with negligible electrical interference  an 8 mbps downstream transmission rate is possible if the distance between the home and the isp is less than 3,000 meters ; the downstream transmission rate drops to about 2 mbps for a distance of 6,000 meters the upstream rate ranges from 16 kbps to 1 mbps while adsl  isdn and dailup modems all use ordinary phone lines  hfc access networks are extensions of the current cable network used for broadcasting cable television in a traditional cable system  a cable head end station broadcasts through a distribution of coaxial cable and amplifiers to residences  we discuss coaxial cable later in this chapter  as illustrated in figure 1.5-2  fiber optics  also to be discussed soon  connect the cable head end to neighborhood-level junctions  from which traditional coaxial cable is then used to reach individual houses and apartments each neighborhood juncture typically supports 500 to 5000 homes file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  2 of 7  20/11/2004 15  51  42 access networks and physical media figure 1.5-2  a hybrid fiber-coax access network as with adsl  hfc requires special modems  called cable modems companies that provide cable internet access require their customers to either purchase or lease a modem one such company is cybercable  which uses motorola 's cybersurfer cable modem and provides high-speed internet access to most of the neighborhoods in paris typically  the cable modem is an external device and connects to the home pc through a 10-baset ethernet port  we will discuss ethernet in great detail in chapter 5  cable modems divide the hfc network into two channels  a downstream and an upstream channel as with adsl  the downstream channel is typically allocated more bandwidth and hence a larger transmission rate for example  the downstream rate of the cybercable system is 10 mbps and the upstream rate is 768 kbps however  with hfc  and not with adsl   these rates are shared among the homes  as we discuss below one important characteristic of the hfc is that it is a shared broadcast medium in particular  every packet sent by the headend travels downstream on every link to every home ; and every packet sent by a home travels on the upstream channel to the headend for this reason  if several users are receiving different internet videos on the downstream channel  actual rate at which each user receives its video will be significantly less than downstream rate on the other hand  if all the active users are web surfing  then each of the users may actually receive web pages at the full downstream rate  as a small collection of users will rarely receive a web page at exactly the same time because the upstream channel is also shared  packets sent by two different homes at the same time will collide  which further decreases the effective upstream bandwidth  we will discuss this collision issue in some detail when we discuss ethernet in chapter 5  advocates of adsl are quick to point out that adsl is a pointto point connection between the home and isp  and therefore all the adsl bandwidth is dedicated rather than shared cable advocates  however  argue that a reasonably dimensioned hfc network provides higher bandwidths than adsl  @ home file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  3 of 7  20/11/2004 15  51  42 access networks and physical media 1998   the battle between adsl and hfc for high speed residential access has clearly begun  e.g   @ home 1998   enterprise access networks in enterprise access networks  a local area network  lan  is used to connect an end system to an edge router as we will see in chapter 5  there are many different types of lan technology however  ethernet technology is currently by far the most prevalent access technology in enterprise networks ethernet operates 10 mbps or 100mbps  and now even at 1 gbps   it uses either twisted-pair copper wire are coaxial cable to connect a number of end systems with each other and with an edge router the edge router is responsible for routing packets that have destinations outside of that lan like hfc  ethernet uses a shared medium  so that end users share the the transmission rate of the lan more recently  shared ethernet technology has been migrating towards switched ethernet technology switched ethernet uses multiple coaxial cable or twisted pair ethernet segments connected at a " switch " to allow the full bandwidth an ethernet to be delivered to different users on the same lan simultaneously  cisco 1998   we will explore shared and switched ethernet in some detail in chapter 5 mobile access networks mobile access networks use the radio spectrum to connect a mobile end system  e.g  a laptop pc or a pda with a wireless modem  to a base station  as shown in figure 1.5-1 this base station  in turn  is connected to an edge router of a data network an emerging standard for wireless data networking is cellular digital packet data  cdpd   wireless 1998   as the name suggests  a cdpd network operates as an overlay network  i.e  as a separate  smaller " virtual " network  as a piece of the larger network  within the cellular telephone network a cdpd network thus uses the same radio spectrum as the cellular phone system  and operates at speeds in the 10 's of kbits per second as with cable-based access networks and shared ethernet  cdpd end systems must share the transmission media with other cdpd end systems within the cell covered by a base station a media access control  mac  protocol is used to arbitrate channel sharing among the cdpd end systems ; we will cover mac protocols in detail in chapter 5 the cdpd system supports the ip protocol  and thus allows an ip end system to exchange ip packets over the wireless channel with an ip base station a cdpd network can actually support multiple network layer protocols ; in addition to ip  the iso cnlp protocol is also supported cdpd does not provide for any protocols above the network layer from an internet perspective  cdpd can be viewed as extending the internet dialtone  i.e  the ability to transfer ip packets  across a wireless link between a mobile end system and an internet router an excellent introduction to cdpd is  waung 98   1.5.2 physical media in the previous subsection we gave an overview of some of the most important access network technologies in the internet while describing these technologies  we also indicated the physical media used for example  we said that hfc uses a combination of fiber cable and coaxial cable we said that ordinary modems  isdn  and adsl use twisted-pair copper wire and we said that mobile access network use the radio spectrum in this subsection we provide a brief overview of these and other transmission media that are commonly employed in the internet in order to define what is meant by a " physical medium  "  let us reflect on the brief life of a bit consider a bit traveling from one end system  through a series of links and routers  to another end system this poor bit gets transmitted many  many times ! the source end-system first transmits the bit and shortly thereafter the first router in the series receives the bit ; the first router then transmits the bit and shortly afterwards the second router receives the bit  etc thus our bit  when traveling from source to destination  passes through a series of transmitter-receiver pairs for each transmitter-receiver pair  the bit is sent by propagating electromagnetic waves across a physical medium the physical medium can take many shapes and forms  and does not have to be of the same type for each transmitter-receiver pair along the path examples of physical media include file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  4 of 7  20/11/2004 15  51  42 access networks and physical media twisted-pair copper wire  coaxial cable  multimode fiber optic cable  terrestrial radio spectrum and satellite radio spectrum physical media fall into two categories  guided media and unguided media with guided media  the waves are guided along a solid medium  such as a fiber-optic cable  a twisted-pair cooper wire or a coaxial cable with unguided media  the waves propagate in the atmosphere and in outer space  such as in a digital satellite channel or in a cdpd system some popular physical media suppose you want to wire a building to allow computers to access the internet or an intranet  should you use twisted-pair copper wire  coaxial cable  or fiber optics ? which of these media gives the highest bit rates over the longest distances ? we shall address these questions below but before we get into the characteristics of the various guided medium types  let us say a few words about their costs the actual cost of the physical link  copper wire  fiber optic cable  etc  is often relatively minor compared with the other networking costs in particular  the labor cost associated with the installation of the physical link can be orders of magnitude higher than the cost of the material for this reason  many builders install twisted pair  optical fiber  and coaxial cable to every room in a building even if only one medium is initially used  there is a good chance that another medium could be used in the near future  and so money is saved but not having to lay additional wires twisted-pair copper wire the least-expensive and most commonly-used transmission medium is twisted-pair copper wire for over one-hundred years it has been used by telephone networks in fact  more than 99 % of the wired connections from the telephone handset to the local telephone switch use twisted-pair copper wire most of us have seen twisted pair in our homes and work environments twisted pair consists of two insulated copper wires  each about 1 mm thick  arranged in a regular spiral pattern ; see figure 1.5-3 the wires are twisted together to reduce the electrical interference from similar pairs close by typically  a number of pairs are bundled together in a cable by wrapping the pairs in a protective shield a wire pair constitutes a single communication link figure 1.5-3  twisted pair unshielded twisted pair  utp  is commonly used for computer networks within a building  that is  for local area networks  lans   data rates for lans using twisted pair today range from 10 mbps to 100 mbps the data rates that can be achieved depend on the thickness of the wire and the distance between transmitter and receiver two types of utp are common in lans  category 3 and category 5 category 3 corresponds to voice-grade twisted pair  commonly found in office buildings office buildings are often prewired with two or more parallel pairs of category 3 twisted pair ; one pair is used for telephone communication  and the additional pairs can be used for additional telephone lines or for lan networking 10 mbps ethernet  one of the most prevalent lan types  can use category 3 utp category 5  with its more twists per centimeter and teflon insulation  can handle higher bit rates 100 mbps ethernet running on category 5 utp has become very popular in recent years in recent years  category 5 utp has become common for preinstallation in new office buildings when fiber-optic technology emerged in the 1980s  many people disparaged twisted-pair because of its relatively low bit rates some people even felt that fiber optic technology would completely replace twisted pair but twisted pair did not give up so easily modern twisted-pair technology  such as category 5 utp  can achieve data rates of 100 mbps for distances up to a few hundred meters even higher rates are possible over shorter distances in the end  twisted-pair has emerged as the dominant solution for high-speed lan networking as discussed in section 1.5.1  twisted-pair is also commonly used for residential internet access we saw that dial-up modem technology enables access at rates of up to 56 kbps over twisted pair we also saw that isdn is available in many file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  5 of 7  20/11/2004 15  51  42 access networks and physical media communities  providing access rates of about 128 kbps over twisted pair we also saw that adsl  asymmetric digital subscriber loop  technology has enabled residential users to access the web at rates in excess of 6 mbps over twisted pair coaxial-cable like twisted pair  coaxial cable consists of two copper conductors  but the two conductors are concentric rather than parallel with this construction and a special insulation and shielding  coaxial cable can have higher bit rates than twisted pair coaxial cable comes in two varieties  baseband coaxial cable and broadband coaxial cable baseband coaxial cable  also called 50-ohm cable  is about a centimeter thick  lightweight  and easy to bend it is commonly used in lans ; in fact  the computer you use at work or at school is probably connected to a lan with either baseband coaxial cable or with utp take a look at the the connection to your computer 's interface card if you see a telephone-like jack and some wire that resembles telephone wire  you are using utp ; if you see a t-connector and a cable running out of both sides of the t-connector  you are using baseband coaxial cable the terminology " baseband " comes from the fact that the stream of bits is dumped directly into the cable  without shifting the signal to a different frequency band 10 mbps ethernets can use either utp or baseband coaxial cable as we will discuss in the chapter 5  it is a little more expensive to use utp for 10 mbps ethernet  as utp requires an additional networking device  called a hub broadband coaxial cable  also called 75-ohm cable  is quite a bit thicker  heavier  and stiffer than the baseband variety it was once commonly used in lans and can still be found in some older installations for lans  baseband cable is now preferable  since it is less expensive  easier to physically handle  and does not require attachment cables broadband cable  however  is quite common in cable television systems as we saw in section 1.5.1  cable television systems have been recently been coupled with cable modems to provide residential users with web access at rates of 10 mbps or higher with broadband coaxial cable  the transmitter shifts the digital signal to a specific frequency band  and the resulting analog signal is sent from the transmitter to one or more receivers both baseband and broadband coaxial cable can be used as a guided shared medium specifically  a number of end systems can be connected directly to the cable  and all the end systems receive whatever any one of the computers transmits we will look at this issue in more detail in chapter 5 fiber optics an optical fiber is a thin  flexible medium that conducts pulses of light  with each pulse representing a bit a single optical fiber can support tremendous bit rates  up to tens or even hundreds of gigabits per second they are immune to electromagnetic interference  have very low signal attenuation up to 100 kilometers  and are very hard to tap these characteristics have made fiber optics the preferred long-haul guided transmission media  particularly for overseas links many of the long-distance telephone networks in the united states and elsewhere now use fiber optics exclusively fiber optics is also prevalent in the backbone of the internet however  the high cost of optical devices  such as transmitters  receivers  and switches  has hindered their deployment for short-haul transport  such as in a lan or into the home in a residential access network at&t labs provides an excellent site on fiber optics  including several nice animations terrestrial and satellite radio channels radio channels carry signals in the electromagnetic spectrum they are an attractive media because require no physical " wire " to be installed  can penetrate walls  provide connectivity to a mobile user  and can potentially carry a signal for long distances the characteristics a radio channel depend significantly on the propagation environment and the distance over which a signal is to be carried environmental considerations determine path loss and shadow fading  which decrease in signal strength as it travels over a distance and around/through obstructing objects   multipath fading  due to signal reflection off of interfering objects   and interference  due to other radio channels or electromagnetic signals   terrestrial radio channels can be broadly classified into two groups  those that operate as local area networks  typically spanning 10 's to a few hundred meters  and wide-area radio channels that are used for mobile data services  typically operating within a metropolitan region   a number of wireless lan products are on the market  operating in the 1 to 10 's of mbps range file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  6 of 7  20/11/2004 15  51  42 access networks and physical media mobile data services  such as the cdpd standard we touched on in section 1.3   typically provide channels that operate at 10 's of kbps see  goodman 97  for a survey and discussion of the technology and products a communication satellite links two or more earth-based microwave transmitter/receivers  known as ground stations the satellite receives transmissions on one frequency band  regenerates the signal using a repeater  discussed below   and transmits the signal on another frequency satellites can provide bandwidths in the gigabit per second range two types of satellites are used in communications  geostationary satellites and low-altitude satellites geostationary satellites permanently remain above the same spot on the earth this stationary presence is achieved by placing the satellite in orbit at 36,000 kilometers above the earth 's surface this huge distance between from ground station though satellite back to ground station introduces a substantial signal propagation delay of 250 milliseconds nevertheless  satellites links are often used in telephone networks and in the backbone of the internet low-altitude satellites are placed much closer to the earth and do not remain permanently above one spot on the earth they rotate around the earth just as the moon rotates around the earth to provide continuous coverage to an area  many satellites to be placed in orbit there are currently many low-altitude communication systems in development the iridium system  for example  consists of 66 low-altitude satellites lloyd 's satellite constellations provides and collects information on iridium as well as other satellite constellation systems the low-altitude satellite technology may be used for internet access sometime in the future return to table of contents references  @ home 1998  @ home  " xdsl vs @ home ? 's hybrid-fiber-coaxial  hfc  cable modem network  the facts  " 1998  adsl 1998  adsl forum  adsl tutorial  1998  cable 1998  cable data news  " overview of cable modem technology and services  " 1998  cisco 1998  cisco  " designing switched lan internetworks  " 1998  goodman 1997  d goodman  chair   " the evolution of untethered communications  " national academy press  december 1997  nas 1995  national academy of sciences  " the unpredictable certainty  information infrastructure through 2000  " 1995  pacific bell 1998  pacific bell  " isdn users guide  " http  //www.pacbell.com/products/business/fastrak/networking/isdn/info/ isdn-guide/index.html  waung 1998  w waung  " wireless mobile data networking the cdpd approach  " wireless data forum  1998  wireless 1998  wireless data forum  " cdpd system specification release 1.1  " 1998 copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/physical.htm  7 of 7  20/11/2004 15  51  42 delay and loss in packet-switched networks 1.6 delay and loss in packet-switched networks having now briefly considered the major " pieces " of the internet architecture  the applications  end systems  end-to-end transport protocols  routers  and links  let us now consider what can happen to a packet as it travels from its source to its destination recall that a packet starts in a host  the source   passes through a series of routers  and ends its journey in another host  the destination   as a packet travels from one node  host or router  to the subsequent node  host or router  along this path  the packet suffers from several different types of delays at each node along the path the most important of these delays are the nodal processing delay  queuing delay  transmission delay and propagation delay ; together  these delays accumulate to give a total nodal delay in order to acquire a deep understanding of packet switching and computer networks  we must understand the nature and importance of these delays figure 1.6-1  the delay through router a let us explore these delays in the context of figure 1.6-1 as part of its end-to-end route between source and destination  a packet is sent from the upstream node through router  a  to router b our goal is to characterize the nodal delay at router a note that router a has three outbound links  one leading to file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  1 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks router b  another leading to router c  and yet another leading to router d each link is preceded a queue  also known as a buffer   when the packet arrives at router a  from the upstream node   router a examines the packet 's header to determine the appropriate outbound link for the packet  and then directs the packet to the link in this example  the outbound link for the packet is the one that leads to router b a packet can only be transmitted on a link if there is no other packet currently being transmitted on the link and if there are no other packets preceding it in the queue ; if the link is currently busy or if there are other packets already queued for the link  the newly arriving packet will then join the queue the time required to examine the packet 's header and determine where to direct the packet is part of the processing delay the processing delay can also include other factors  such as the time needed to check for bit-level errors in the packet that occurred in transmitting the packet 's bits from the upstream router to router a after this nodal processing  the router directs the packet to the queue that precedes the link to router b  in section 4.7 we will study the details of how a router operates  at the queue  the packet experiences a queuing delay as it waits to be transmitted onto the link the queuing delay of a specific packet will depend on the number of other  earlier-arriving packets that are queued and waiting for transmission across the link ; the delay of a given packet can vary significantly from packet to packet if the queue is empty and no other packet is currently being transmitted  then our packet 's queuing delay is zero on the other hand  if the traffic is heavy and many other packets are also waiting to be transmitted  the queuing delay will be long we will see shortly that the number of packets that an arriving packet might expect to find on arrival  informally  the average number of queued packets  which is proportional to the average delay experienced by packets  is a function of the intensity and nature of the traffic arriving to the queue assuming that packets are transmitted in first-come-first-serve manner  as is common in the internet  our packet can be transmitted once all the packets that have arrived before it have been transmitted denote the length of the packet by l bits and denote the transmission rate of the link  from router a to router b  by r bits/sec the rate r is determined by transmission rate of the link to router b for example  for a 10 mbps ethernet link  the rate is r = 10 mbps ; for a 100 mbps ethernet link  the rate is r = 100 mbps the transmission delay  also called the store-and-forward delay  as discussed in section 1.4  is l/r this is the amount of time required to transmit all of the packet 's bits into the link once a bit is pushed onto the link  it needs to propagate to router b the time required to propagate from the beginning of the link to router b is the propagation delay the bit propagates at the propagation speed of the link the propagation speed depends on the physical medium of the link  i.e  multimode fiber  twisted-pair copper wire  etc  and is in the range of 2 * 108 meters/sec to 3 * 108 meters/sec  equal to  or a little less than  the speed of light the propagation delay is the distance between two routers divided by the propagation speed that is  the propagation delay is d/s  where d is the distance between router a and router b and s is the propagation speed of the link once the last bit of the packet propagates to node b  it and all the preceding bits of the packet are stored in router b the whole file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  2 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks process then continues with router b now performing the forwarding newcomers to the field of computer networking sometimes have difficulty understanding the difference between transmission delay and propagation delay the difference is subtle but important the transmission delay is the amount of time required for the router to push out the packet ; it is a function of the packet 's length and the transmission rate of the link  but has nothing to do with the distance between the two routers the propagation delay  on the other hand  is the time it takes a bit to propagate from one router to the next ; it is a function of the distance between the two routers  but has nothing to do with the packet 's length or the transmission rate of the link an analogy might clarify the notions of transmission and propagation delay consider a highway which has a toll booth every 100 kilometers you can think of the highway segments between toll booths as links and the toll booths as routers suppose that cars travel  i.e  propagate  on the highway at a rate of 100 km/hour  i.e  when a car leaves a toll booth it instantaneously accelerates to 100 km/hour and maintains that speed between toll booths   suppose that there is a caravan of 10 cars that are traveling together  and that these ten cars follow each other in a fixed order you can think of each car as a bit and the caravan as a packet also suppose that each toll booth services  i.e  transmits  a car at a rate of one car per 12 seconds  and that it is late at night so that the caravan 's cars are only cars on the highway finally  suppose that whenever the first car of the caravan arrives at a toll booth  it waits at the entrance until the nine other cars have arrived and lined up behind it  thus the entire caravan must be " stored " at the toll booth before it can begin to be " forwarded "   the time required for the toll booth to push the entire caravan onto the highway is 10/  5 cars/minute  = 2 minutes this time is analogous to the transmission delay in a router the time required for a car to travel from the exit of one toll booth to the next toll booth is 100 km/  100 km/hour  = 1 hour this time is analogous to propagation delay therefore the time from when the caravan is " stored " in front of a toll booth until the caravan is " stored " in front of the next toll booth is the sum of " transmission delay " and " the propagation delay "  in this example  62 minutes let 's explore this analogy a bit more what would happen if the toll-booth service time for a caravan were greater than the time for a car to travel between toll booths ? for example  suppose cars travel at rate 1000 km/hr and the toll booth services cars at rate one car per minute then the traveling delay between toll booths is 6 minutes and the time to serve a caravan is 10 minutes in this case  the first few cars in the caravan will arrive at the second toll booth before the last cars in caravan leave the first toll booth this situation also arises in packet-switched networks  the first bits in a packet can arrive at a router while many of the remaining bits in the packet are still waiting to be transmitted by the preceding router if we let dproc  dqueue  dtrans and dprop denote the processing  queuing  transmission and propagation delays  then the total nodal delay is given by dnodal = dproc + dqueue + dtrans + dprop  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  3 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks the contribution of these delay components can vary significantly for example  dprop can be negligible  e.g  a couple of microseconds  for a link connecting two routers on the same university campus ; however  dprop is hundreds of milliseconds for two routers interconnected by a geostationary satellite link  and can be the dominant term in dnodal similarly  dtrans can be range from negligible to significant its contribution is typically negligible for transmission rates of 10 mbps and higher  e.g  for lans  ; however  it can be hundreds of milliseconds for large internet packets sent over 28.8 kbps modem links the processing delay  dproc  is often negligible ; however  it strongly influences a router 's maximum throughput  which is the maximum rate at which a router can forward packets queuing delay the most complicated and interesting component of nodal delay is the queuing delay dqueue in fact  queuing delay is so important and interesting in computer networking that thousands of papers and numerous of books have been written about it  bertsekas 1992   daigle 1991   kleinrock 1975   kleinrock 1976   ross 1995  ! we only give a high-level  intuitive discussion of queuing delay here ; the more curious reader may want to browse through some of the books  or even eventually write a ph.d thesis on the subject !   unlike the other three delays  namely  dproc  dtrans and dprop   the queuing delay can vary from packet to packet for example  if ten packets arrive to an empty queue at the same time  the first packet transmitted will suffer no queuing delay  while the last packet transmitted will suffer a relatively large queuing delay  while it waits for the other nine packets to be transmitted   therefore  when characterizing queuing delay  one typically uses statistical measures  such as average queuing delay  variance of queuing delay and the probability that the queuing delay exceeds some specified value when is the queuing delay big and when is it insignificant ? the answer to this question depends largely on the rate at which traffic arrives to the queue  the transmission rate of the link  and the nature of the arriving traffic  i.e  whether the traffic arrives periodically or whether it arrives in bursts to gain some insight here  let a denote the average rate at which packets arrive to the queue  a is units of packets/sec   recall that r is the transmission rate  i.e  it is the rate  in bits/sec  at which bits are pushed out of the queue also suppose  for simplicity  that all packets consist of l bits then the average rate at which bits arrive to the queue is la bits/sec finally  assume that the queue is very big  so that it can hold essentially an infinite number of bits the ratio la/r  called the traffic intensity  often plays an important role in estimating the extent of the queuing delay if la/r > 1  then the average rate at which bits arrive to the queue exceeds the rate at which the bits can be transmitted from the queue in this unfortunate situation  the queue will tend to increase without bound and the queuing delay will approach infinity ! therefore  one of the golden rules in traffic engineering is  design your system so that the traffic intensity is no greater than one now consider the case la/r = < 1 here  the nature of the arriving traffic impacts the queuing delay for example  if packets arrive periodically  i.e  one packet arrives every l/r seconds  then every packet will arrive to an empty queue and there will be no queuing delay on the other hand  if packets arrive in file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  4 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks bursts but periodically  there can be a significant average queuing delay for example  suppose n packets arrive at the same time every  l/r  n seconds then the first packet transmitted has no queuing delay ; the second packet transmitted has a queuing delay of l/r seconds ; and more generally  the nth packet transmitted has a queuing delay of  n-1  l/r seconds we leave it as an exercise for the reader to calculate the average queuing delay in this example the two examples described above of periodic arrivals are a bit academic typically the arrival process to a queue is random  i.e  the arrivals do not follow any pattern ; packets are spaced apart by random amounts of time in this more realistic case  the quantity la/r is not usually sufficient to fully characterize the delay statistics nonetheless  it is useful in gaining an intuitive understanding of the extent of the queuing delay in particular  if traffic intensity is close to zero  then packets are pushed out at a rate much higher than the packet arrival rate ; therefore  the average queuing delay will be close to zero on the other hand  when the traffic intensity is close to 1  there will be intervals of time when the arrival rate exceeds the transmission capacity  due to the burstiness of arrivals   and a queue will form as the traffic intensity approaches 1  the average queue length gets larger and larger the qualitative dependence of average queuing delay on the traffic intensity is shown in figure 1.6-2 below one important aspect of figure 1.6-2 is the fact that as the traffic intensity approaches 1  the average queueing delay increases rapidly a small percentage increase in the intensity will result in a much larger percentage-wise increase in delay perhaps you have experienced this phenomenon on the highway if you regularly drive on a road that is typically congested  the fact that the road is typically congested means that its traffic intensity is close to 1 if some event causes an even slightly-larger-thanusual amount of traffic  the delays you experience can be huge figure 1.6-2  dependence of average queuing delay on traffic intensity packet loss file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  5 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks in our discussions above  we have assumed that the queue is capable of holding an infinite number of packets in reality a queue preceding a link has finite capacity  although the queuing capacity greatly depends on the switch design and cost because the queue capacity is a finite  packet delays do not really approach infinity as the traffic intensity approaches one instead  a packet can arrive to find a full queue with no place to store such a packet  a router will drop that packet ; that is  the packet will be lost from an end-system viewpoint  this will look like a packet having been transmitted into the network core  but never emerging from the network at the destination the fraction of lost packets increases as the traffic intensity increases therefore  performance at a node is often measured not only in terms of delay  but also in terms of the probability of packet loss as we shall discuss in the subsequent chapters  a lost packet may be retransmitted on an end-to-end basis  by either the application or by the transport layer protocol end-to-end delay our discussion up to this point has been focused on the nodal delay  i.e  the delay at a single router let us conclude our discussion by briefly considering the delay from source to destination to get a handle on this concept  suppose there are q-1 routers between the source host and the destination host let us also suppose that the network is uncongested  so that queuing delays are negligible   the processing delay at each router and at the source host is dproc  the transmission rate out of each router and out of the source host is r bits/sec  and the propagation delay between each pair or routers and between the source host and the first router is dprop the nodal delays accumulate and give an end-to-end delay  dendend = q  dproc + dtrans + dprop   where once again dtrans = l/r  where l is the packet size we leave it to the reader to generalize this formula to the case of heterogeneous delays at the nodes and to the presence of an average queuing delay at each node return to table of contents references  bertsekas 1992  d bertsekas and r gallager  data networks  2nd edition  prentice hall  englewood cliffs  n.j  1992  daigle 1991  j.n daigle  queuing theory for telecommunications  addision-wesley  reading massachusetts  1991  kleinrock 1975  l kleinrock  queuing systems  volume 1  john wiley  new york  1975  kleinrock 1976  l kleinrock  queuing systems  volume 2  john wiley  new york  1976 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  6 of 7  20/11/2004 15  51  43 delay and loss in packet-switched networks  ross 1995  k.w ross  multiservice loss models for broadband telecommunication networks  springer  berlin  1995 copyright keith w ross and james f kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/delay.htm  7 of 7  20/11/2004 15  51  43 protocol layers and their service models 1.7 protocol layers and their service models from our discussion thus far  it is apparent that the internet is an extremely complicated system we have seen that there are many " pieces " to the internet  numerous applications and protocols  various types of end systems and connections between end systems  routers  and various types of link-level media given this enormous complexity  is there any hope of organizing network architecture  or at least our discussion of network architecture ? fortunately  the answers to both questions is " yes " before attempting to organize our thoughts on internet architecture  let 's look for a human analogy actually  we deal with complex systems all the time in our every day life imagine if someone asked you to describe  for example  the airline system how would you find the structure to describe this complex system that has ticketing agents  baggage checkers  gate personnel  pilots and airplanes  air traffic control  and a worldwide system for routing airplanes ? one way to describe this system might be to describe the series of actions you take  or others take for you  when you fly on an airline you purchase your ticket  check your bags  go to the gate and eventually get loaded onto the plane the plane takes off and is routed to its destination after your plane lands  you de-plane at the gate and claim your bags if the trip was bad  you complain about the flight to the ticket agent  getting nothing for your effort   this scenario is shown in figure 1.7-1 figure 1.7-1  taking an airplane trip  actions already  we can see some analogies here with computer networking  you are being shipped from source to destination by the airline ; a packet is shipped from source host to destination host in the internet but this is not quite the analogy we are after we are looking for some structure in figure 1.7-1 looking at figure 1.7-1  we note that there is a ticketing function at each end ; there is also a baggage function for already ticketed passengers  and a gate function for already-ticketed and alreadybaggage checked passengers for passengers who have made it through the gate  i.e  passengers who are already ticketed  baggage-checked  and through the gate   there is a takeoff and landing function  and while in flight  there is an airplane routing function this suggests that we can look at the functionality in figure 1.7-1 in a horizontal manner  as shown in figure 1.7-2 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  1 of 7  20/11/2004 15  51  44 protocol layers and their service models figure 1.7-2  horizontal " layering " of airline functionality figure 1.7-2 has divided the airline functionality into layers  providing a framework in which we can discuss airline travel now  when we want to describe a part of airline travel we can talk about a specific  well-defined component of airline travel for example  when we discuss gate functionality  we know we are discussing functionality that sits " below " baggage handling  and " above " takeoff and landing we note that each layer  combined with the layers below it  implement some functionality  some service at the ticketing layer and below  airline-counter-to-airline-counter transfer of a person is accomplished at the baggage layer and below  baggage-check-to-baggage-claim transfer of a person and their bags in accomplished note that the baggage layer provides this service only to an already ticketed person at the gate layer  departure-gate-to-arrival-gate transfer of a person and their bags is accomplished at the takeoff/landing layer  runway-to-runway transfer of a person  actually  many people  and their bags  is accomplished each layer provides its functionality  service  by  i  performing certain actions within that layer  e.g  at the gate layer  loading and unloading people from an airplane  and by  ii  using the services of the layer directly below it  e.g  in the gate layer  using the runway-to-runway passenger transfer service of the takeoff/landing layer   as noted above  a layered architecture allows us to discuss a well-defined  specific part of a large and complex system this itself is of considerable value when a system has a layered structure it is also much easier to change the implementation of the service provided by the layer as long as the layer provides the same service to the layer above it  and uses the same services from the layer below it  the remainder of the system remains unchanged when a layer 's implementation is changed  note that changing the implementation of a service is very different from changing the service itself !  for example  if the gate functions were changed  e.g  to have people board and disembark by height   the remainder of the airline system would remain unchanged since the gate layer still provides the same function  loading and unloading people  ; it simply implements that function in a different manner after the change for large and complex systems that are constantly being updated  the ability to change the implementation of a service without affecting other components of the system is another important advantage of layering but enough with airlines let 's now turn our attention to network protocols to reduce design complexity  network designers organize protocols  and the network hardware and software that implements the protocols  in layers with a layered protocol architecture  each protocol belongs to one of the layers it 's important to realize that a protocol in layer n is distributed among the network entities  including end systems and packet switches  that implement that protocol  just as the functions in our layered airline architecture were distributed between the departing and arriving airports in other words  there 's a " piece " of file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  2 of 7  20/11/2004 15  51  44 protocol layers and their service models layer n in each of the network entities these " pieces " communicate with each other by exchanging layer-n messages these messages are called layer-n protocol data units  or more commonly n-pdus the contents and format of an n-pdu  as well as the manner in which the n-pdus are exchanged among the network elements  are defined by a layer-n protocol when taken together  the protocols of the various layers are called the protocol stack when layer n of host a sends an n-pdu to layer n of host b  layer n of host a passes the n-pdu to layer n-1 and then lets layer n-1 deliver the n-pdu to layer n of b ; thus layer n is said to rely on layer n-1 to deliver its n-pdu to the destination a key concept is that of the service model of a layer layer n-1 is said to offer services to layer n for example  layer n-1 might guarantee that the n-pdu will arrive without error at layer n in the destination within one second  or it might only guarantee that the n-pdu will eventually arrive at the destination without any assurances about error the concept of protocol layering is a fairly abstract and is sometimes difficult to grasp at first this concept will become clear as we study the internet layers and their constituent protocols in greater detail but let use now try to shed some insight on protocol layering and protocol stacks with an example consider a network which organizes its communication protocols in four layers because there are four layers  there are four types of pdus  1-pdus  2-pdus  3-pdus and 4-pdus as shown in figure 1.7-3  the application  operating at the highest layer  layer 4  creates a message  m any message created at this highest layer is a 4-pdu the message m itself may consist of many different fields  in much the same way as a structure or record in a programming language may contain different fields  ; it is up to the application to define and interpret the fields in the message the fields might contain the name of the sender  a code indicating the type of the message  and some additional data within the source host  the contents of the entire message m is then " passed " down the protocol stack to layer 3 in the example in figure 1.7-3  layer 3 in the source host divides a 4-pdu  m  into two parts  m1 and m2 the layer 3 in the source host then adds to m1 and m2  so-called headers  to create two layer 3 pdus headers contain the additional information needed by the sending and receiving sides of layer 3 to implement the service that layer 3 provides to layer 4 the procedure continues in the source  adding more header at each layer  until the 1-pdus are created the 1-pdus are sent out of the source host onto a physical link at the other end  the destination host receives 1-pdus and directs them up the protocol stack at each layer  the corresponding header is removed finally  m is reassembled from m1 and m2 and then passed on to the application figure 1.7-3  different pdu 's at different layers in the protocol architecture note that in figure 1.7-3  layer n uses the services of layer n-1 for example  once layer 4 creates the message m  it passes the message down to layer 3 and relies on layer 3 to deliver the message to layer 4 at the destination interesting enough  this notion of relying on lower layer services is prevalent in many other forms of communication for file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  3 of 7  20/11/2004 15  51  44 protocol layers and their service models example  consider ordinary postal mail when you write a letter  you include envelope information such as the destination address and the return address with the letter the letter along with the address information can be considered a pdu at the highest layer of the protocol stack you then drop the pdu in a mailbox at this point  the letter is out of your hands the postal service may then add some of its own internal information onto your letter  essentially adding a header to your letter for example  in the united states a barcode is often printed on your letter once you drop your envelope into a mailbox  you rely on the services of the postal service to deliver the letter to the correct destination in a timely manner for example  you do n't worry about whether a postal truck will break down while carrying the letter instead the postal service takes care of this  presumably with well-defined plans to recover from such failures furthermore  within the postal service itself there are layers  and the protocols at one layer rely on and use the services of the layer below in order for one layer to interoperate with the layer below it  the interfaces between the two layers must be precisely defined standards bodies define precisely the interfaces between adjacent layers  e.g  the format of the pdus passed between the layers  and permit the developers of networking software and hardware to implement the interior of the layers as they please therefore  if a new and improved implementation of a layer is released  the new implementation can replace the old implementation and  in theory  the layers will continue to interoperate in a computer network  each layer may perform one or more of the following generic set of tasks  l error control  which makes the logical channel between the layers in two peer network elements more reliable l flow control  which avoids overwhelming a slower peer with pdus l segmentation and reassembly  which at the transmitting side divides large data chunks into smaller pieces ; and at the receiving side reassembles the smaller pieces into the original large chunk l multiplexing  which allows several higher-level sessions to share a single lower-level connection l connection setup  which provides the handshaking with a peer protocol layering has conceptual and structural advantages we mention  however  that some researchers and networking engineers are vehemently opposed to layering  wakeman 1992   one potential drawback of layering is that one layer may duplicate lower-layer functionality for example  many protocol stacks provide error recovery on both a link basis and an endto end basis a second potential drawback is that functionality at one layer may need information  e.g  a timestamp value  that is present only in another layer ; this violates the goal of separation of layers 1.7.1 the internet protocol stack the internet stack consists of five layers  the physical  data link  network  transport and application layers rather than use the cumbersome terminology pdu-n for each of the five layers  we instead give special names to the pdus in four of the five layers  frame  datagram  segment  and message we avoid naming a data unit for the physical layer  as no name is commonly used at this layer the internet stack and the corresponding pdu names are illustrated in figure 1.7-4 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  4 of 7  20/11/2004 15  51  44 protocol layers and their service models figure 1.7-4  the protocol stack  and protocol data units a protocol layer can be implemented in software  in hardware  or using a combination of the two application-layer protocols  such as http and smtp  are almost always implemented in software in the end systems ; so are transport layer protocols because the physical layer and data link layers are responsible for handling communication over a specific link  they are typically implemented in a network interface card  e.g  ethernet or atm interface cards  associated with a given link the network layer is often a mixed implementation of hardware and software we now summarize the internet layers and the services they provide  l application layer  the application layer is responsible for supporting network applications the application layer includes many protocols  including http to support the web  smtp to support electronic mail  and ftp to support file transfer we shall see in chapter 2 that it is very easy to create our own new application-layer protocols l transport layer  the transport layer is responsible for transporting application-layer messages between the client and server sides of an application in the internet there are two transport protocols  tcp and udp  either of which can transport application-layer messages tcp provides a connection-oriented service to its applications this service includes guaranteed delivery of application-layer messages to the destination and flow control  i.e  sender/receiver speed matching   tcp also segments long messages into shorter segments and provides a congestion control mechanism  so that a source throttles its transmission rate when the network is congested the udp protocol provides its applications a connnectionless service  which  as we saw in section 1.3  is very much a no-frills service l network layer  the network layer is responsible for routing datagrams from one host to another the internet 's network layer has two principle components first it has a protocol that defines the fields in the ip datagram as well as how the end systems and routers act on these fields this protocol is the celebrated ip protocol there is only one ip protocol  and all internet components that have a network layer must run the ip protocol the internet 's network layer also contains routing protocols that determine the routes that datagrams take between sources and destinations the internet has many routing protocols as we saw in section 1.4  the internet is network of networks and within a network  the file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  5 of 7  20/11/2004 15  51  44 protocol layers and their service models network administrator can run any routing protocol desired although the network layer contains both the ip protocol and numerous routing protocols  it is often simply referred to as the ip layer  reflecting that fact that ip is the glue that binds the internet together the internet transport layer protocols  tcp and udp  in a source host passes a transport layer segment and a destination address to the ip layer  just as you give the postal service a letter with a destination address the ip layer then provides the service of routing the segment to its destination when the packet arrives at the destination  ip passes the segment to the transport layer within the destination l link layer  the network layer routes a packet through a series of packet switches  i.e  routers  between the source and destination to move a packet from one node  host or packet switch  to the next node in the route  the network layer must rely on the services of the link layer in particular  at each node ip passes the datagram to the link layer  which delivers the datagram to the next node along the route at this next node  the link layer passes the ip datagram to the network layer the process is analogous to the postal worker at a mailing center who puts a letter into a plane  which will deliver the letter to the next postal center along the route the services provided at the link layer depend on the specific link-layer protocol that is employed over the link for example  some protocols provide reliable delivery on a link basis  i.e  from transmitting node  over one link  to receiving node note that this reliable delivery service is different from the reliable delivery service of tcp  which provides reliable delivery from one end system to another examples of link layers include ethernet and ppp ; in some contexts  atm and frame relay can be considered link layers as datagrams typically need to traverse several links to travel from source to destination  a datagram may be handled by different link-layer protocols at different links along its route for example  a datagram may be handled by ethernet on one link and then ppp on the next link ip will receive a different service from each of the different linklayer protocols l physical layer  while the job of the link layer is to move entire frames from one network element to an adjacent network element  the job of the physical layer is to move the individual bits within the frame from one node to the next the protocols in this layer are again link dependent  and further depend on the actual transmission medium of the link  e g  twisted-pair copper wire  single mode fiber optics   for example  ethernet has many physical layer protocols  one for twisted-pair copper wire  another for coaxial cable  another for fiber  etc in each case  a bit is moved across the link in a different way if you examine the table of contents  you will see that we have roughly organized this book using the layers of the internet protocol stack we take a top-down approach  first covering the application layer and then preceding downwards 1.7.2 network entities and layers the most important network entities are end systems and packet switches as we shall discuss later in this book  there are two two types of packet switches  routers and bridges we presented an overview of routers in the earlier sections bridges will be discussed in detail in chapter 5 whereas routers will be covered in more detail in chapter 4 similar to end systems  routers and bridges organize the networking hardware and software into layers but routers and bridges do not implement all of the layers in the protocol stack ; they typically only implement the bottom layers as shown in figure 1.7-5  bridges implement layers 1 and 2 ; routers implement layers 1 through 3 this means  for example  that internet routers are capable of implementing the ip protocol  a layer 3 protocol   while bridges are not we will see later that while bridges do not recognize ip addresses  they are capable of recognizing layer 2 addresses  such as ethernet addresses note that hosts implement all five layers ; this is consistent with the view that the internet architecture puts much of its complexity at the " edges " of the network repeaters  yet another kind of network entity to be discussed in chapter 5  implement only layer 1 functionality file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  6 of 7  20/11/2004 15  51  44 protocol layers and their service models figure 1.7-5  hosts  routers and bridges  each contain a different set of layers  reflecting their differences in functionality references  wakeman 1992  ian wakeman  jon crowcroft  zheng wang  and dejan sirovica  " layering considered harmful  " ieee network  january 1992  p 7 return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/protocol_stacks.htm  7 of 7  20/11/2004 15  51  44 internet structure  backbones  nap 's and isp 's 1.8 internet backbones  naps and isps our discussion of layering in the previous section has perhaps given the impression that the internet is a carefully organized and highly intertwined structure this is certainly true in the sense that all of the network entities  end systems  routers and bridges  use a common set of protocols  enabling the entities to communicate with each other if one wanted to change  remove  or add a protocol  one would have to follow a long and arduous procedure to get approval from the ietf  which will  among other things  make sure that the changes are consistent with the highly intertwined structure however  from a topological perspective  to many people the internet seems to be growing in a chaotic manner  with new sections  branches and wings popping up in random places on a daily basis indeed  unlike the protocols  the internet 's topology can grow and evolve without approval from a central authority let us now try to a grip on the seemingly nebulous internet topology as we mentioned at the beginning of this chapter  the topology of the internet is loosely hierarchical roughly speaking  from bottom-to-top the hierarchy consists of end systems  pcs  workstations  etc  connected to local internet service providers  isps   the local isps are in turn connected to regional isps  which are in turn connected to national and international isps the national and international isps are connected together at the highest tier in the hierarchy new tiers and branches can be added just as a new piece of lego can be attached to an existing lego construction in this section we describe the topology of the internet in the united states as of 1999 let 's begin at the top of the hierarchy and work our way down residing at the very top of the hierarchy are the national isps  which are called national backbone provider  nbps   the nbps form independent backbone networks that span north america  and typically abroad as well   just as there are multiple long-distance telephone companies in the usa  there are multiple nbps that compete with each other for traffic and customers the existing nbps include internetmci  sprintlink  psinet  uunet technologies  and agis the nbps typically have high-bandwidth transmission links  with bandwidths ranging from 1.5 mbps to 622 mbps and higher each nbp also has numerous hubs which interconnect its links and at which regional isps can tap into the nbp the nbps themselves must be interconnected to each other to see this  suppose one regional isp  say midwestnet  is connected to the mci nbp and another regional isp  say eastcoastnet  is connected to sprint 's nbp how can traffic be sent from midwestnet to eastcoastnet ? the solution is to introduce switching centers  called network access points  naps   which interconnect the nbps  thereby allowing each regional isp to pass traffic to any other regional isp to keep us all confused  some of the naps are not referred to as naps but instead as maes  metropolitan area exchanges   in the united states  many of the naps are run by rbocs  regional bell operating companies  ; for example  pacbell has a nap in san francisco and ameritech has a nap in chicago for a list of major nbp 's  those connected into at least three maps/mae 's   see  haynal 99   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/topology.htm  1 of 4  20/11/2004 15  51  45 internet structure  backbones  nap 's and isp 's because the naps relay and switch tremendous volumes of internet traffic  they are typically in themselves complex high-speed switching networks concentrated in a small geographical area  for example  a single building   often the naps use high-speed atm switching technology in the heart of the nap  with ip riding on top of atm  we provide a brief introduction to atm at the end of this chapter  and discuss ip-over-atm in chapter 5  figure 1.8-1 illustrates pacbell 's san francisco nap  the details of figure 1.8-1 are unimportant for us now ; it is worthwhile to note  however  that the nbp hubs can themselves be complex data networks figure 1.8-1  the pacbell nap architecture  courtesy of the pacific bell web site   the astute reader may have noticed that atm technology  which uses virtual circuits  can be found at certain places within the internet but earlier we said that the " internet is a datagram network and does not use virtual circuits "  we admit now that this statement stretches the truth a little bit  we made this file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/topology.htm  2 of 4  20/11/2004 15  51  45 internet structure  backbones  nap 's and isp 's statement because it helps the reader to see the forest through the trees by not having the main issues obscured the truth is that there are virtual circuits in the internet  but they are in localized pockets of the internet and they are buried deep down in the protocol stack  typically at layer 2 if you find this confusing  just pretend for now that the internet does not employ any technology that uses virtual circuits this is not too far from the truth running an nbp is not cheap in june 1996  the cost of leasing 45 mbps fiber optics from coast-tocoast  as well as the additional hardware required  was approximately $ 150,000 per month and the fees that an nbp pays the naps to connect to the naps can exceed $ 300,000 annually nbps and naps also have significant capital costs in equipment for high-speed networking an nbp earns money by charging a monthly fee to the regional isps that connect to it the fee that an nbp charges to a regional isp typically depends on the bandwidth of the connection between the regional isp and the nbp ; clearly a 1.5 mbps connection would be charged less than a 45 mbps connection once the fixed-bandwidth connection is in place  the regional isp can pump and receive as much data as it pleases  up to the bandwidth of the connection  at no additional cost if an nbp has significant revenues from the regional isps that connect to it  it may be able to cover the high capital and monthly costs of setting up and maintaining an nbp a regional isp is also a complex network  consisting of routers and transmission links with rates ranging from 64 kbps upward a regional isp typically taps into an nbp  at an nbp hub   but it can also tap directly into an nap  in which case the regional nbp pays a monthly fee to a nap instead of to a nbp a regional isp can also tap into the internet backbone at two or more distinct points  for example  at an nbp hub or at a nap   how does a regional isp cover its costs ? to answer this question  let 's jump to the bottom of the hierarchy end systems gain access to the internet by connecting to a local isp universities and corporations can act as local isps  but backbone service providers can also serve as a local isp many local isps are small " mom and pop " companies  however a popular www site known simple as " the list " contains link to nearly 8000 local  regional  and backbone isps  list 1999   the local isps tap into one of the regional isps in its region analogous to the fee structure between the regional isp and the nbp  the local isp pays a monthly fee to its regional isp which depends on the bandwidth of the connection finally  the local isp charges its customers  typically  a flat  monthly fee for internet access  the higher the transmission rate of the connection  the higher the monthly fee we conclude this section by mentioning that anyone of us can become a local isp as soon as we have an internet connection all we need to do is purchase the necessary equipment  for example  router and modem pool  that is needed to allow other users to connect to our so-called " point of presence " thus  new tiers and branches can be added to the internet topology just as a new piece of lego can be attached to an existing lego construction return to table of contents file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/topology.htm  3 of 4  20/11/2004 15  51  45 internet structure  backbones  nap 's and isp 's references  haynal 99  r haynal  " internet backbones  " http  //navigators.com/isp.html  list 1999  " the list  the definitive isp buyer 's guide  " http  //thelist.internet.com/ copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/topology.htm  4 of 4  20/11/2004 15  51  45 a brief history of computer networking and the internet 1.9 a brief history of computer networking and the internet sections 1.1-1.8 presented an overview of technology of computer networking and the internet you should know enough now to impress your family and friends however  if you really want to be a big hit at the next cocktail party  you should sprinkle your discourse with tidbits about the fascinating history of the internet 1961-1972  development and demonstration of early packet switching principles the field of computer networking and today 's internet trace their beginnings back to the early 1960s  a time at which the telephone network was the world 's dominant communication network recall from section 1.3  that the telephone network uses circuit switching to transmit information from a sender to receiver  an appropriate choice given that voice is transmitted at a constant rate between sender and receiver given the increasing importance  and great expense  of computers in the early 1960 's and the advent of timeshared computers  it was perhaps natural  at least with perfect hindsight !  to consider the question of how to hook computers together so that they could be shared among geographically distributed users the traffic generated by such users was likely to be " bursty "  intervals of activity  e g  the sending of a command to a remote computer  followed by periods of inactivity  while waiting for a reply or while contemplating the received response three research groups around the world  all unaware of the others ' work  leiner 98   began inventing the notion of packet switching as an efficient and robust alternative to circuit switching the first published work on packet-switching techniques was the work by leonard kleinrock  kleinrock 1961  kleinrock 1964   at that time a graduate student at mit using queuing theory  kleinrock 's work elegantly demonstrated the effectiveness of the packet-switching approach for bursty traffic sources at the same time  paul baran at the rand institute had begun investigating the use of packet switching for secure voice over military networks  baran 1964   while at the national physical laboratory in england  donald davies and roger scantlebury were also developing their ideas on packet switching the work at mit  rand  and npl laid the foundations for today 's internet but the internet also has a long history of a " let 's build it and demonstrate it " attitude that also dates back to the early 1960 's j.c r licklider  dec 1990  and lawrence roberts  both colleagues of kleinrock 's at mit  both went on to lead the computer science program at the advanced projects research agency  arpa  in the united states roberts  roberts 67  published an overall plan for the so-called arpanet  roberts 1967   the first packet-switched computer network and a direct ancestor of today 's public internet the early packet switches were known as interface message processors  imp 's  and the contract to build these file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  1 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet switches was awarded to bbn on labor day in 1969  the first imp was installed at ucla  with three additional imp being installed shortly thereafter at the stanford research institute  uc santa barbara  and the university of utah the fledgling precursor to the internet was four nodes large by the end of 1969 kleinrock recalls the very first use of the network to perform a remote login from ucla to sri crashing the system  kleinrock 1998   figure 1.9-1  the first internet message processor  imp   with l kleinrock by 1972  arpanet had grown to approximately 15 nodes  and was given its first public demonstration by robert kahn at the 1972 international conference on computer communications the first host-tohost protocol between arpanet end systems known as the network control protocol  ncp  was completed  rfc 001   with an end-to-end protocol available  applications could now be written the first e-mail program was written by ray tomlinson at bbn in 1972 1972  1980  internetworking  and new and proprietary networks the initial arpanet was a single  closed network in order to communicate with an arpanet host  one had to actually be attached to another arpanet imp in the early to mid 1970 's  additional packetswitching networks besides arpanet came into being ; alohanet  a satellite network linking together universities on the hawaiian islands  abramson 1972  ; telenet  a bbn commercial packet-switching file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  2 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet network based on arpanet technology ; tymnet ; and transpac  a french packet-switching network the number of networks was beginning to grow in 1973  robert metcalfe 's phd thesis laid out the principle of ethernet  which would later lead to a huge growth in so-called local area networks  lans  that operated over a small distance based on the ethernet protocol once again  with perfect hindsight one might now see that the time was ripe for developing an encompassing architecture for connecting networks together pioneering work on interconnecting networks  once again under the sponsorship of darpa   in essence creating a network of networks  was done by vinton cerf and robert kahn  cerf 1974  ; the term " internetting " was coined to describe this work the architectural principles that kahn ' articulated for creating a so-called " open network architecture " are the foundation on which today 's internet is built  leiner 98   l minimalism  autonomy  a network should be able to operate on its own  with no internal changes required for it to be internetworked with other networks ; l best effort service  internetworked networks would provide best effort  end-to-end service if reliable communication was required  this could accomplished by retransmitting lost messages from the sending host ; l stateless routers  the routers in the internetworked networks would not maintain any per-flow state about any ongoing connection l decentralized control  there would be no global control over the internetworked networks these principles continue to serve as the architectural foundation for today 's internet  even 25 years later  a testament to insight of the early internet designers these architectural principles were embodied in the tcp protocol the early versions of tcp  however  were quite different from today 's tcp the early versions of tcp combined a reliable in-sequence delivery of data via end system retransmission  still part of today 's tcp  with forwarding functions  which today are performed by ip   early experimentation with tcp  combined with the recognition of the importance of an unreliable  non-flow-controlled end-end transport service for application such as packetized voice  led to the separation of ip out of tcp and the development of the udp protocol the three key internet protocols that we see today  tcp  udp and ip  were conceptually in place by the end of the 1970 's in addition to the darpa internet-related research  many other important networking activities were underway in hawaii  norman abramson was developing alohanet  a packet-based radio network that allowed multiple remote sites on the hawaiian islands to communicate with each other the aloha protocol  abramson 1970  was the first so-called multiple access protocol  allowing geographically distributed users to share a single broadcast communication medium  a radio frequency   abramson 's work on multiple access protocols was built upon by robert metcalfe in the development of the ethernet protocol  metcalfe 1976  for wire-based shared broadcast networks interestingly  metcalfe 's ethernet protocol was motivated by the need to connect multiple pcs  printers  and shared disks together  perkins 1994   twenty-five years ago  well before the pc revolution and the explosion file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  3 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet of networks  metcalfe and his colleagues were laying the foundation for today 's pc lans ethernet technology represented an important step for internetworking as well each ethernet local area network was itself a network  and as the number of lans proliferated  the need to internetwork these lans together became all the more important an excellent source for information on ethernet is spurgeon 's ethernet web site  which includes metcalfe 's drawing of his ethernet concept  as shown below in figure 1.9-2 we discuss ethernet  aloha  and other lan technologies in detail in chapter 5 ; figure 1.9-2  a 1976 drawing by r metcalfe of the ethernet concept  from charles spurgeon 's ethernet web site  in addition to the darpa internetworking efforts and the aloha/ethernet multiple access networks  a number of companies were developing their own proprietary network architectures digital equipment corporation  digital  released the first version of the decnet in 1975  allowing two pdp-11 minicomputers to communicate with each other decnet has continued to evolve since then  with significant portions of the osi protocol suite being based on ideas pioneered in decnet other important players during the 1970 's were xerox  with the xns architecture  and ibm  with the sna architecture   each of these early networking efforts would contribute to the knowledge base that would drive networking in the 80 's and 90 's it is also worth noting here that in the 1980 's  and even before   researchers  see  e.g   fraser 1983  turner 1986  fraser 1993   were also developing a " competitor " technology to the internet architecture these efforts have contributed to the development of the atm  asynchronous transfer mode  architecture  a connection-oriented approach based on the use of fixed size packets  known as cells we will examine portions of the atm architecture throughout this book 1980  1990  a proliferation of networks file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  4 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet by the end of the 1970 's approximately 200 hosts were connected to the arpanet by the end of the 1980 's the number of host connected to the public internet  a confederation of networks looking much like today 's internet would reach 100,000 the 1980 's would be a time of tremendous growth much of the growth in the early 1980 's resulted from several distinct efforts to create computer networks linking universities together bitnet  because it 's there network  provided email and file transfers among several universities in the northeast csnet  computer science network  was formed to link together university researchers without access to arpanet in 1986  nsfnet was created to provide access to nsf-sponsored supercomputing centers starting with an initial backbone speed of 56kbps  nsfnet 's backbone would be running at 1.5 mbps by the end of the decade  and would be serving as a primary backbone linking together regional networks in the arpanet community  many of the final pieces of today 's internet architecture were falling into place january 1  1983 saw the official deployment of tcp/ip as the new standard host protocol for arpanet  replacing the ncp protocol   the transition  postel 1981  from ncp to tcp/ip was a " flag day " type event  all host were required to transfer over to tcp/ip as of that day in the late 1980 's  important extensions were made to tcp to implement host-based congestion control  jacobson 1988   the domain name system  used to map between a human-readable internet name  e.g  gaia.cs.umass edu  and its 32-bit ip address  was also developed  mockapetris 1983  mockapetris 1987   paralleling this development of the arpanet  which was for the most part a us effort   in the early 1980s the french launched the minitel project  an ambitious plan to bring data networking into everyone 's home sponsored by the french government  the minitel system consisted of a public packetswitched network  based on the x.25 protocol suite  which uses virtual circuits   minitel servers  and inexpensive terminals with built-in low speed modems the minitel became a huge success in 1984 when the french government gave away a free minitel terminal to each french household that wanted one minitel sites included free sites  such as a telephone directory site  as well as private sites  which collected a usage-based fee from each user at its peak in the mid 1990s  it offered more than 20,000 different services  ranging from home banking to specialized research databases it was used by over 20 % of france 's population  generated more than $ 1 billion each year  and created 10,000 jobs the minitel was in a large fraction of french homes ten years before most americans had ever heard of the internet it still enjoys widespread use in france  but is increasingly facing stiff competition from the internet the 1990s  commercialization and the web the 1990 's were issued in with two events that symbolized the continued evolution and the soon-toarrive commercialization of the internet first  arpanet  the progenitor of the internet ceased to exist milnet and the defense data network had grown in the 1980 's to carry most of the us department of defense related traffic and nsfnet had begun to serve as a backbone network connecting regional networks in the united states and national networks overseas also  in 1990  the world  www.world std.com  became the first public dialup internet service provider  isp   in 1991  nsfnet lifted its file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  5 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet restrictions on use of nsfnet for commercial purposes nsfnet itself would be decommissioned in 1995  with internet backbone traffic being carried by commercial internet service providers the main event of the 1990 's however  was to be the release of the world wide web  which brought the internet into the homes and businesses of millions and millions of people  worldwide the web also served as a platform for enabling and deploying hundreds of new applications  including on-line stock trading and banking  streamed multimedia services  and information retrieval services for a brief history of the early days of the www  see  w3c 1995   the www was invented at cern by tim berners-lee in 1989-1991  berners-lee 1989   based on ideas originating in earlier work on hypertext from the 1940 's by bush  bush 1945  and since the 1960 's by ted nelson  ziff-davis 1998   berners-lee and his associates developed initial versions of html  http  a web server and a browser  the four key components of the www the original cern browsers only provided a line-mode interface around the end of 1992 there were about 200 web servers in operation  this collection of servers being the tip of the iceberg for what was about to come at about this time several researchers were developing web browsers with gui interfaces  including marc andreesen  who developed the popular gui browser mosaic for x he released an alpha version of his browser in 1993  and in 1994 formed mosaic communications  which later became netscape communications corporation by 1995 university students were using mosaic and netscape browsers to surf the web on a daily basis at about this time the us government began to transfer the control of the internet backbone to private carriers companies  big and small  began to operate web servers and transact commerce over the web in 1996 microsoft got into the web business in a big way  and in the late 1990s it was sued for making its browser a central component of its operating system in 1999 there were over two-million web servers in operation and all of this happened in less than ten years ! during the 1990 's  networking research and development also made significant advances in the areas of high-speed routers and routing  see  e.g  chapter 4  and local area networks  see  e.g  chapter 5   the technical community struggled with the problems of defining and implementing an internet service model for traffic requiring real-time constraints  such as continuous media applications  see  e.g  chapter 6   the need to secure and manage internet infrastructure  see e.g  chapter 7 and 8  also became of paramount importance as e-commerce applications proliferated and the internet became a central component of the world 's telecommunications infrastructure references two excellent discussions of the history of the internet are  hobbes 1998  and  leiner 1998    abramson 1970  n abramson  the aloha system  another alternative for computer communications  proceedings of fall joint computer conference  afips conference  1970  p.37  baran 1964  p baran  " on distributed communication networks  " ieee transactions on communication systems  march  1964 rand corporation technical report with the same title file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  6 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet  memorandum rm-3420-pr  1964    berners-lee 1989  tim berners-lee  cern  " information management  a proposal  " march 1989  may 1990  bush 1945  v bush  " as we may think  " the atlantic monthly  july 1945  cerf 1974  v cerf and r kahn  " a protocol for packet network interconnection  " ieee transactions on communications technology  vol com-22  number 5  may 1974   pp 627-641  dec 1990  digital equipment corporation  " in memoriam  j.c.r licklider 1915-1990  " src research report 61  august 1990  hobbes 1998  r hobbes zakon  " hobbes internet timeline "  version 3.3  1998  fraser 1983  fraser  a g  1983   towards a universal data transport system ieee journal on selected areas in communications  sac-1  5   803-816  fraser 1993  fraser  a g  1993   early experiments with asynchronous time division networks ieee network magazine  7  1   12-27  jacobson 1988  v jacobson  " congestion avoidance and control  " proc acm sigcomm 1988 conference  in computer communication review  vol 18  no 4  pp 314-329  aug 1988  kleinrock 1961  l kleinrock  " information flow in large communication networks  " rle quarterly progress report  july 1961  kleinrock 1964  l kleinrock  1964 communication nets  stochastic message flow and delay  mcgraw-hill 1964  later re-issued by dover books  kleinrock 1998  l kleinrock  " the birth of the internet  " http  //millenium.cs.ucla.edu/lk/inet/birth html  leiner 98  b leiner  v cerf  d clark  r kahn  l kleinrock  d lynch  j postel  l roberts  s woolf  " a brieif history of the internet  " http  //www.isoc.org/internet/history/brief.html  metcalfe 1976  robert m metcalfe and david r boggs ` ` ethernet  distributed packet switching for local computer networks,' ' communications of the association for computing machinery  vol19/no 7  july 1976  mockapetris 1983  p.v mockapetris  " domain names  implementation specification  " rfc 833  nov 01-1983  mockapetris 1987  p.v mockapetris  " domain names  concepts and facilities  " rfc 1034  nov-01 1987  perkins 1994  a perkins  " networking with bob metcalfe  " the red herring magazine  november 1994  postel 1981  j postel  " ncp/tcp transition plan  " rfc 7801 november 1981  rfc 001  s crocker  " host software  rfc 001  the very first rfc !    roberts 1967  l roberts  t merril " toward a cooperative network of time-shared computers  " fall afips conference  oct 1966  turner 1986  j turner  ` ` new directions in communications  or which way to the information age ?  ,' ' proceedings of the zurich seminar on digital communication  pp 25--32  3/86  w3c 1995  the world wide web consortium  " a little history of the world wide web  " 1995  ziff-davis 1998  ziff-davis publishing  " ted nelson  hypertext pioneer  " file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  7 of 8  20/11/2004 15  51  47 a brief history of computer networking and the internet return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/history.htm  8 of 8  20/11/2004 15  51  47 atmover 1.10 asynchronous transfer mode  atm  networks thus far  our focus has been on the internet and its protocols but many other existing packet-switching technologies can also provide end-to-end networking solutions among these alternatives to the internet  so called asynchronous transfer mode  atm  networks are perhaps the most well-known atm arrived on the scene in the early 1990s it is useful to discuss atm for two reasons first  it provides an interesting contrast to the internet  and by exploring its differences  we will gain more insight into the internet second  atm is often used as a link-layer technology in the backbone of the internet since we will refer to atm throughout this book  we end this chapter with a brief overview of atm the original goals of atm the standards for atm were first developed in the mid 1980s for those too young to remember  at this time there were predominately two types of networks  telephone networks  that were  and still are  primarily used to carry real-time voice ; and data networks  that were primarily used to transfer text files  support remote login  and provide email there were also dedicated private networks available for video conferencing the internet existed at this time  but few people were thinking about using it to transport phone calls  and the www was as yet unheard of it was therefore natural to design a networking technology that would be appropriate for transporting real-time audio and video as well as text  email and image files atm achieved this goal two standards bodies  the atm forum  atm forum  and the international telecommunications union  itu  have developed atm standards for broadband integrated services digital networks  bisdns   the atm standards call for packet switching with virtual circuits  called virtual channels in atm jargon  ; the standards define how applications directly interface with atm  so that atm provides complete networking solution for distributed applications paralleling the development of the atm standards  major companies throughout the world made significant investments in atm research and development these investments have led to a myriad of highperforming atm technologies  including atm switches that can switch terabits per second in recent years  atm technology has been deployed very aggressively within both telephone networks and the internet backbones although atm has been deployed within networks  it has been unsuccessful in extending itself all the way to desktop pcs and workstations and it is now questionable whether atm will ever have a significant presence at the desktop indeed  while atm was brewing in the standards committees and research labs in the late 1980s and early 1990s  the internet and its tcp/ip protocols were already operational and making significant headway  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/atmintro.htm  1 of 4  20/11/2004 15  51  48 atmover l the tcp/ip protocol suite was integrated into all of the most popular operating systems l companies began to transact commerce  e-commerce  over the internet l residential internet access became very cheap l many wonderful desktop applications were developed for tcp/ip networks  including the world wide web  internet phone  and interactive streaming video thousands of companies are currently developing new applications and services for the internet furthermore  throughout the 1990s  several low-cost high-speed lan technologies were developed  including 100 mbps ethernet and more recently gigabit ethernet  mitigating the need for atm use in high-speed lan applications today  we live in a world where almost all networking application products interface directly with tcp/ip nevertheless  atm switches can switch packets at very high rates  and consequently has been deployed in internet backbone networks  where the need to transport traffic at high rates is most acute we will discuss the topic of ip over atm in section 5.8 principle characteristics of atm we shall discuss atm in some detail in subsequent chapters for now we briefly outline its principle characteristics  l the atm standard defines a full suite of communication protocols  from the transport layer all the way down through the physical layer l it uses packet switching with fixed length packets of 53 bytes in atm jargon these packets are called cells each cell has 5 bytes of header and 48 bytes of " payload "  the fixed length cells and simple headers have facilitated high-speed switching l atm uses virtual circuits  vcs   in atm jargon  virtual circuits are called virtual channels the atm header includes a field for the virtual channel number  which is called the virtual channel identifier  vci  in atm jargon as discussed in section 1.3  packet switches use the vci to route cells towards their destinations ; atm switches also perform vci translation l atm provides no retransmissions on a link-by-link basis if a switch detects an error in an atm cell  it attempts to correct the error using error correcting codes if it can not correct the error  it drops the cell and does not ask the preceding switch to retransmit the cell l atm provides congestion control on an end-to-end basis that is  the transmission of atm cells is not directly regulated by the switches in times of congestion however  the network switches themselves do provide feedback to a sending end system to help it regulate its transmission rate when the network becomes congested l atm can run over just about any physical layer it often runs over fiber optics using the sonet standard at speeds of 155.52 mbps  622 mbps and higher overview of the atm layers as shown in figure 1.10-1  the atm protocol stack consists of three layers  the atm adaptation layer file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/atmintro.htm  2 of 4  20/11/2004 15  51  48 atmover  aal   the atm layer  and the atm physical layer  atm adaptation layer  aal  atm layer atm physical layer figure 1.10-1  the three atm layers the atm physical layer deals with voltages  bit timings  and framing on the physical medium the atm layer is the core of the atm standard it defines the structure of the atm cell the atm adaptation layer is analogous to the transport layer in the internet protocol stack atm includes many different types of aals to support many different types of services currently  atm is often used as a link-layer technology within localized regions of the internet a special aal type  aal5  has been developed to allow tcp/ip to interface with atm at the ip-to atm interface  aal5 prepares ip datagrams for atm transport ; at the atm-to-ip interface  aal5 reassembles atm cells into ip datagrams figure 1.10-2 shows the protocol stack for the regions of the internet that use atm application layer  http  ftp  etc  transport layer  tcp or udp  network layer  ip  aal5 atm layer atm physical layer figure 1.10-2  internet-over-atm protocol stack note that in this configuration  the three atm layers have been squeezed into the lower two layers of the internet protocol stack in particular  the internet 's network layer " sees " atm as a link-layer protocol this concludes our brief introduction to atm we will return to atm from time to time throughout this book references  atm forum  the atm forum web site  http  //www.atmforum.com  itu  the itu web site  http  //www.itu.ch file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/atmintro.htm  3 of 4  20/11/2004 15  51  48 atmover return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/atmintro.htm  4 of 4  20/11/2004 15  51  48 chapter 1 summary 1.11 summary in this chapter we 've covered a tremendous amount of material ! we 've looked at the various pieces of hardware and software that make up the internet in particular  and computer networks in general we started at the " edge " of the network  looking at end systems and applications  and at the transport service provided to the applications running on the end systems using network-based distributed applications as examples  we introduced the notion of a protocol  a key concept in networking we then dove deeper inside the network  into the network core  identifying packet-switching and circuit switching as the two basic approaches for transporting data through a telecommunication network  and examining the strengths and weaknesses of each approach we then looked at the lowest  from an architectural standpoint  parts of the network  the link layer technologies and physical media typically found in the access network in the second part of this introductory chapter we then took the broader view on networking from a performance standpoint  we identified the causes of packet delay and packet loss in the internet we identified key architectural principles  layering  service models  in networking we then examined the structure of today 's internet we finished our introduction to networking with a brief history of computer networking the first chapter in itself constitutes a mini-course in computer networking so  we have indeed covered a tremendous amount of ground in this first chapter ! if you 're a bit overwhelmed  do n't worry in the following chapters we will revisit all of these ideas  covering them in much more detail  that 's a promise  not a threat !   at this point  we hope you leave this chapter with a still-developing intuition for the pieces that make up a network  a still-developing command for the vocabulary of networking  do n't be shy to refer back to this chapter   and an ever-growing desire to learn more about networking that 's the task ahead of us for the rest of this book roadmapping this book before starting any trip  we should always glance at a roadmap in order to become familiar with the major roads and junctures that lie between us and our ultimate destination for the trip we are about to embark on  the ultimate destination is a deep understanding of the how  what and why of computer networks our roadmap is the sequence of chapters of this book  1 computer networks and the internet 2 application layer 3 transport layer 4 network layer and routing 5 link layer and local area networks 6 multimedia networking 7 security in computer networks file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/summary1.htm  1 of 2  20/11/2004 15  51  48 chapter 1 summary 8 network management taking a look at this roadmap  we identify chapters 2 through 5 as the four core chapters of this book you should notice that there is one chapter for each of the top four layers of the internet protocol stack further note that our journey will begin at the top of the internet protocol stack  namely  the application layer  and will work its way downward the rationale behind this top-down journey is that once we understand the applications  we can then understand the network services needed to support these applications we can then  in turn  examine the various ways in which such services might be implemented by a network architecture covering applications early thus provides motivation for the remainder of the text the second half of the book  chapters 6 through 8  zoom in on three enormously important  and somewhat independent  topics in modern computer networking in chapter 6  multimedia networking   we examine audio and video applications  such as internet phone  video conferencing  and streaming of stored media we also look at how a packet-switched network can be designed to provide consistent quality of service to audio and video applications in chapter 7  security in computer networks   we first look at the underpinnings of encryption and network security  and then examine how the basic theory is being applied in broad range of internet contexts  including electronic mail and internet commerce the last chapter  network management  examines the key issues in network management as well as the internet protocols that address these issues return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/summary1.htm  2 of 2  20/11/2004 15  51  48 chapter 1 homework and discussion questions homework problems and discussion questions chapter 1 review questions sections 1.1-1.4 1  what are the two types of services that the internet provides to its applications ? what are some of characteristics of each of these services ? 2  it has been said that flow control and congestion control are equivalent is this true for the internet 's connection-oriented service ? are the objectives of flow control and congestion control the same ? 3  briefly describe how the internet 's connection-oriented service provides reliable transport 4  what advantage does a circuit-switched network have over a packet-switched network ? 4  what advantages does tdm have over fdm in a circuit-switched network ? 5  suppose that between a sending host and a receiving host there is exactly one packet switch the transmission rates between the sending host and the switch and between the switch and the receiving host are r1 and r2  respectively assuming that the router uses store-and-forward packet switching  what is the total end-to-end delay to send a packet of length l  ignore queuing and propagation delay  6  what are some of the networking technologies that use virtual circuits ? find good urls that discuss and explain these technologies 7  what is meant by connection state information in a virtual-circuit network ? 8  suppose you are developing a standard for a new type of network you need to decide whether your network will use vcs or datagram routing what are the pros and cons for using vcs ? sections 1.5-1.7 9  is hfc bandwidth dedicated or shared among users ? are collisions possible in a downstream hfc channel ? why or why not ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  1 of 6  20/11/2004 15  51  49 chapter 1 homework and discussion questions 10  what are the transmission rate of ethernet lans ? for a given transmission rate  can each user on the lan continuously transmit at that rate ? 11  what are some of the physical media that ethernet can run over ? 12  dail-up modems  isdn  hfc and adsl are all used for residential access for each of these access technologies  provide a range of transmission rates and comment on whether the bandwidth is shared or dedicated 13  consider sending a series of packets from a sending host to a receiving host over a fixed route list the delay components in the end-to-end delay for a single packet which of these delays are constant and which are fixed ? 14  review the car-caravan analogy in section 1.6 again assume a propagation speed of 100km/hour a  suppose the caravan travels 200 km  beginning in front of one toll booth  passing through a second toll booth  and finishing just before a third toll booth what is the end-to-end delay ? b  repeat  a   now assuming that there are 7 cars in the caravan instead of 10 15  list five tasks that a layer can perform it is possible that one  or more  of these tasks could be performed by two  or more  layers ? 16  what are the five layers in the internet protocol stack ? what are the principle responsibilities for each of these layers ? 17  which layers in the internet protocol stack does a router process ? problems 1  design and describe an application-level protocol to be used between an automatic teller machine  and a bank 's centralized computer your protocol should allow a user 's card and password to be verified  the account balance  which is maintained at the centralized computer  to be queried  and an account withdrawal  i.e  when money is given to the user  to be made your protocol entities should be able to handle the all-too-common case in which there is not enough money in the account to cover the withdrawal specify your protocol by listing the messages exchanged  and the action taken by the automatic teller machine or the bank 's centralized computer on transmission and receipt of messages sketch the operation of your protocol for the case of a simple withdrawl with no errors  using a diagram similar to that in figure 1.2-1 explicity state the assumptions made by your protocol about the underlying end-to-end transport service file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  2 of 6  20/11/2004 15  51  49 chapter 1 homework and discussion questions 2  consider an application which transmits data at a steady rate  e.g  the sender generates a n bit unit of data every k time units  where k is small and fixed   also  when such an application starts  it will stay on for relatively long period of time answer the following questions  briefly justifying your answer  l would a packet-switched network or a circuit-switched network be more appropriate for this application ? why ? l suppose that a packet-switching network is used and the only traffic in this network comes from such applications as described above furthermore  assume that the sum of the application data rates is less that the capacities of each and every link is some form of congestion control needed ? why ? 3  consider sending a file of f = m * l bits over a path of q links each link transmits at r bps the network is lightly loaded so that there are no queueing delays when a form of packet switching is used  the m * l bits are broken up into m packets  each packet with l bits propagation delay is negligible a  suppose the network is a packet-switched virtual-circuit network denote the vc set-up time by ts seconds suppose to each packet the sending layers add a total of hbits of header how long does it take to send the file from source to destination ? b  suppose the network is a packet-switched datagram network  and a connectionless service is used now suppose each packet has 2h bits of header how long does it take to send the file ? c  repeat  b   but assume message switching is used  i.e  2hbits are added to the message  and the message is not segmented   d  finally  suppose that the network is a circuit switched network further suppose that the transmission rate of the circuit between source and destination is rbps assuming tsset-up time and hbits of header appended to the entire file  how long does it take to send the file ? 4  experiment with the message-switching java applet in this chapter do the delays in the applet correspond to the delays in the previous question ? how do link propagation delays effect the the overall end-to-end delay for packet switching and for message switching ? 5  consider sending a large file of f bits from host a to host b.there are two links  and one switch  between a and b  and the links are uncongested  i.e  no queueing delays   host a segments the file into segments of s bits each and adds 40 bits of header to each segment  forming packets of l = 40 + s bits each link has a transmission rate of r bps find the value of s that minimizes the delay of moving the packet from host a to host b neglect propagation delay 6  this elementary problem begins to explore propagation delay and transmission delay  two central file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  3 of 6  20/11/2004 15  51  49 chapter 1 homework and discussion questions concepts in data networking consider two hosts  hosts a and b  connected by a single link of rate r bps suppose that the two hosts are separted by m meters  and suppose the propagation speed along the link is s meters/sec host a is to send a packet of size l bits to host b a  express the propagation delay  dprop in terms of mand s b  determine the transmission time of the packet  dtrans in terms of land r c  ignoring processing and queing delays  obtain an expression for the end-to-end delay d  suppose host a begins to transmit the packet at time t = 0 at time t = dtrans  where is the last bit of the packet ? e  suppose dpropis greater than dtrans  at time t = dtrans  where is the first bit of the packet ? f   suppose dpropis less than dtrans  at time t = dtrans  where is the first bit of the packet ? g  suppose s = 2.5 * 108  l = 100bits and r = 28 kbps find the distance mso that dpropequals dtrans 7  in this problem we consider sending voice from host a to host b over a packet-switched network  e g  internet phone   host a converts on-the-fly analog voice to a digital 64 kbps bit stream host a then groups the bits into 48-byte packets there is one link between host a and b ; its transmission rate is 1 mbps and its propagation delay is 2 msec as soon as host a gathers a packet  it sends it to host b as soon as host b receives an entire packet  it coverts the packet 's bits to an analog signal how much time elapses from when a bit is created  from the original analog signal at a  until a bit is decoded  as part of the analog signal at b  ? 8  suppose users share a 1 mbps link also suppose each user requires 100 kbps when transmitting  but each user only transmits 10 % of the time  see the discussion on " packet switching versus circuit switching " in section 1.4.1  a  when circuit-switching is used  how many users can be supported ? b  for the remainder of this problem  suppose packet-switching is used find the probability that a given user is transmitting c  suppose there are 40 users find the probability that at any given time  n users are transmitting simultaneously d  find the probability that there are 10 or more users transmitting simultaneously 9  consider the queueing delay in a router buffer  preceding an outbound link   suppose all packets are l bits  the transmission rate is r bps and that n packets arrive to the buffer every l/rn seconds find the average queueing delay of a packet 10  consider the queueing delay in a router buffer let i denote traffic intensity  that is  i = la/r suppose that the queueing delay takes the form lr/  1-i  for i < 1  a  provide a formula for the " total file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  4 of 6  20/11/2004 15  51  49 chapter 1 homework and discussion questions delay  " that is  the queueing delay plus the transmission delay  b  plot the transmission delay as a function of l/r 11   a  generalize the end-to-end delay formula in section 1.6 for heterogeneous processing rates  transmission rates  and propagation delays  b  repeat  a   but now also suppose that there is an average queuing delay of dqueue at each node 12  consider an application that transmits data at a steady rate  e.g  the sender generates one packet of n bits every k time units  where k is small and fixed   also  when such an application starts  it will stay on for relatively long period of time a  would a packet-switched network or a circuit-switched network be more appropriate for this application ? why ? b  suppose that a packet-switched network is used and the only traffic in this network comes from such applications as described above furthermore  assume that the sum of the application data rates is less that the capacities of each and every link is some form of congestion control needed ? why or why not ? 13  perform a traceroute between source and destination on the same continent at three different hours of the day find the average and standard deviation of the delays do the same for a source and destination on different continents 14  recall that atm uses 53 byte packets consisting of 5 header bytes and 48 payload bytes fifty-three bytes is unusually small for fixed-length packets ; most networking protocols  ip  ethernet  frame relay  etc  use packets that are  on average  significantly larger one of the drawbacks of a small packet size is that a large fraction of link bandwidth is consumed by overhead bytes ; in the case of atm  almost ten percent of the bandwidth is " wasted " by the atm header in this problem we investigate why such a small packet size was chosen to this end  suppose that the atm cell consists of p bytes  possible different from 48  and 5 bytes of header a  consider sending a digitally encoded voice source directly over atm suppose the source is encoded at a constant rate of 64 kbps assume each cell is entirely filled before the source sends the cell into the network the time required to fill a cell is the packetization delay.in terms of l  determine the packetization delay in milliseconds b  packetization delays greater than 20 msecs can cause noticeable and unpleasant echo determine the packetization delay for l = 1,500 bytes  roughly corresponding to a maximumsize ethernet packet  and for l = 48  corresponding to an atm cell   c  calculate the store-and-forward delay at a single atm switch for a link rate of r = 155 mbps  a popular link speed for atm  for l = 1500 bytes and l = 48 bytes file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  5 of 6  20/11/2004 15  51  49 chapter 1 homework and discussion questions d  comment on the advantages of using a small cell size discussion questions 1  write a one-paragraph description for each of three major projects currently under way at the w3c 2  what is internet phone ? describe some of the existing products for internet phone find some of the web sites of companies that are in the internet phone business 3  what is internet audio-on-demand ? describe some of the existing products for internet audio-ondemand find some of the web sites of companies that are in the internet audio-on-demand business find some web sites which provide audio-on-demand content 4  what is internet video conferencing ? describe some of the existing products for internet video conferencing find some of the web sites of companies that are in the internet video-conferencing business 5  surf the web to find a company that is offering hfc internet access what transmission rate of the cable modem ? is this rate always guaranteed for each user on the network ? 6  discussion question  suppose you are developing an application for the internet.would you have your application run over tcp or udp ? elaborate  we will explore this question in some detail in subsequent chapters for now appeal to your intuition to answer the question  7  discussion question  what are some of the current activities of the the world wide web consortium  w3c  ? what are some of the current activities of the national laboratory for applied network research or nlanr ? 8  discussion question  what does the current topological structure of the internet  i.e  backbone isps  regional isps  and local isps  have in common with the topological structure of the telephone networks in the usa ? how is pricing in the internet the same as or different from pricing in the phone system copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/1problems.htm  6 of 6  20/11/2004 15  51  49 network applications  terminology and basic concepts 2.1 principles of application layer protocols network applications are the raisons d'etre of a computer network if we could n't conceive of any useful applications  there would n't be any need to design networking protocols to support them but over the past thirty years  many people have devised numerous ingenious and wonderful networking applications these applications include the classic text-based applications that became popular in the 1980s  including remote access to computers  electronic mail  file transfers  newsgroups  and chat but they also include more recently conceived multimedia applications  such as the world wide web  internet telephony  video conferencing  and audio and video on demand although network applications are diverse and have many interacting components  software is almost always at their core recall from section 1.2 that for a network application 's software is distributed among two or more end systems  i.e  host computers   for example  with the web there are two pieces of software that communicate with each other  the browser software in the user 's host  pc  mac or workstation   and the web server software in the web server with telnet  there are again two pieces of software in two hosts  software in the local host and software in the remote host with multiparty video conferencing  there is a software piece in each host that participates in the conference in the jargon of operating systems  it is not actually software pieces  i.e  programs  that are communicating but in truth processes that are communicating a process can be thought of as a program that is running within an end system when communicating processes are running on the same end system  they communicate with each other using interprocess communication the rules for interprocess communication are governed by the end system 's operating system but in this book we are not interested in how processes on the same host communicate  but instead in how processes running on different end systems  with potentially different operating systems  communicate processes on two different end systems communicate with each other by exchanging messages across the computer network a sending process creates and sends messages into the network ; a receiving process receives these messages and possibly responds by sending messages back networking applications have application-layer protocols that define the format and order of the messages exchanged between processes  as well as the actions taken on the transmission or receipt of a message the application layer is a particularly good place to start our study of protocols it 's familiar ground we 're acquainted with many of the applications that rely on the protocols we will study it will give us a good feel for what protocols are all about  and will introduce us to many of the same issues that we 'll see again when we study transport  network  and data link layer protocols 2.1.1 application-layer protocols file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  1 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts it is important to distinguish between network applications and application-layer protocols an application-layer protocol is only one piece  albeit  a big piece  of a network application let 's look at a couple of examples the web is a network application that allows users to obtain " documents " from web servers on demand the web application consists of many components  including a standard for document formats  i.e  html   web browsers  e.g  netscape navigator and internet explorer   web servers  e.g  apache  microsoft and netscape servers   and an application-layer protocol the web 's application-layer protocol  http  the hypertext transfer protocol  rfc 2068    defines how messages are passed between browser and web server thus  http is only one piece  albeit  a big piece  of the web application as another example  consider the internet electronic mail application internet electronic mail also has many components  including mail servers that house user mailboxes  mail readers that allow users to read and create messages  a standard for defining the structure of an email message  i.e  mime  and application-layer protocols that define how messages are passed between servers  how messages are passed between servers and mail readers  and how the contents of certain parts of the mail message  e.g  a mail message header  are to be interpreted the principal application-layer protocol for electronic mail is smtp  simple mail transfer protocol  rfc 821    thus  smtp is only one piece  albeit  a big piece  of the email application as noted above  an application layer protocol defines how an application 's processes  running on different end systems  pass messages to each other in particular  an application layer protocol defines  l the types of messages exchanged  e.g  request messages and response messages ; l the syntax of the various message types  i.e  the fields in the message and how the fields are delineated ; l the semantics of the fields  i.e  the meaning of the information in the fields ; l rules for determining when and how a process sends messages and responds to messages some application-layer protocols are specified in rfcs and are therefore in the public domain for example  http is available as an rfc if a browser developer follows the rules of the http rfc  the browser will be able to retrieve web pages from any web server  more precisely  any web server that has also followed the rules of the http rfc   many other application-layer protocols are proprietary and intentionally not available in the public domain for example  many of the existing internet phone products use proprietary application-layer protocols clients and servers a network application protocol typically has two parts or " sides "  a client side and a server side the client side in one end system communicates with the server side in another end system for example  a web browser implements the client side of http and a web server implements the server side of http in another example  e-mail  the sending mail server implements the client side of smtp and the receiving mail server implements the server side of smtp for many applications  a host will implement both the client and server sides of an application for example  consider a telnet session between hosts a and b  recall that telnet is a popular remote login file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  2 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts application  if host a initiates the telnet session  so that a user at host a is logging onto host b   then host a runs the client side of the application and host b runs the server side on the other hand  if host b initiates the telnet session  then host b runs the client side of the application ftp  used for transferring files between two hosts  provides another example when an ftp session exists between two hosts  then either host can transfer a file to the other host during the session however  as is the case for almost all network applications  the host that initiates the session is labeled the client furthermore  a host can actually act as both a client and a server at the same time for a given application for example  a mail server host runs the client side of smtp  for sending mail  as well as the server side of smtp  for receiving mail   processes communicating across a network as noted above  an application involves two processes in two different hosts communicating with each other over a network  actually  a multicast application can involve communication among more than two hosts we shall address this issue in chapter 4  the two processes communicate with each other by sending and receiving messages through their sockets a process 's socket can be thought of as the process 's door  a process sends messages into  and receives message from  the network through its socket when a process wants to send a message to another process on another host  it shoves the message out its door the process assumes that there is a transportation infrastructure on the other side of the door that will transport the message to the door of the destination process figure 2.1-1  application processes  sockets  and the underlying transport protocol figure 2.1-1 illustrates socket communication between two processes that communicate over the internet  the figure assumes that the underlying transport protocol is tcp  although the udp protocol could be used as well in the internet  as shown in this figure  a socket is the interface between the application layer and the transport layer within a host it is also referred to as the api  application programmers file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  3 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts interface  between the application and the network  since the socket is the programming interface with which networked applications are built in the internet the application developer has control of everything on the application-layer side of the socket but has little control of the transport-layer side of the socket the only control that the application developer has on the transport-layer side is  i  the choice of transport protocol and  ii  perhaps the ability to fix a few transport-layer parameters such as maximum buffer and maximum segment sizes once the application developer chooses a transport protocol  if a choice is available   the application is built using the transport layer the services offered by that protocol we will explore sockets in some detail in sections 2.6 and 2.7 addressing processes in order for a process on one host to send a message to a process on another host  the sending process must identify the receiving process to identify the receiving process  one must typically specify two pieces of information   i  the name or address of the host machine  and  ii  an identifier that specifies the identity of the receiving process on the destination host let us first consider host addresses in internet applications  the destination host is specified by its ip address we will discuss ip addresses in great detail in chapter 4 for now  it suffices to know that the ip address is a 32-bit quantity that uniquely identifies the end-system  more precisely  it uniquely identifies the interface that connects that host to the internet   since the ip address of any end system connected to the public internet must be globally unique  the assignment of ip addresses must be carefully managed  as discussed in section 4.4 atm networks have a different addressing standard the itu-t has specified telephone number-like addresses  called e.164 addresses  itu 1997   for use in public atm networks e.164 address consist of between seven and 15 digits  with each digit encoded as a byte  yielding an address of between 56 and 120 bits in length   the assignment of these address is carefully managed by country or region-specific standards bodies ; in the united states  the american national standards institute  ansi  provides this address registration service we will not cover atm end-system addressing in depth in this book ; see  fritz 1997  cisco 1999  for more details in addition to knowing the address of the end system to which a message is destined  a sending application must also specify information that will allow the receiving end system to direct the message to the appropriate process on that system a receive-side port number serves this purpose in the internet popular application-layer protocols have been assigned specific port numbers for example  a web server process  which uses the http protocol  is identified by port number 80 a mail server  using the smtp  protocol is identified by port number 25 a list of well-known port numbers for all internet standard protocols can be found in  rtc 1700   when a developer creates a new network application  the application must be assigned a new port number user agents before we begin a more detailed study of application-layer protocols  it is useful to discuss the notion of a user agent the user agent is an interface between the user and the network application for example  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  4 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts consider the web for this application  the user agent is a browser such as netscape navigator or microsoft explorer the browser allows a user to view web pages  to navigate in the web  to provide input to forms  to interact with java applets  etc the browser also implements the client side of the http protocol thus  when activated  the browser is a process that  along with providing an interface to the user  sends messages into a socket as an another example  consider the electronic mail application in this case  the user agent is a " mail reader " that allows a user to compose and read messages many companies market mail readers  e.g  eudora  netscape messenger  with a graphical user interface that can run on pcs  macs and workstations mail readers running on pcs also implement the client side of application layer protocols ; typically they implement the client side of smtp for sending mail and the client side of a mail retrieval protocol  such as pop3 or imap  see section 2.4   for receiving mail 2.1.2 what services does an application need ? recall that a socket is the interface between the application process and the transport protocol the application at the sending side sends messages through the door at the other side of the door  the transport protocol has the responsibility of moving the messages across the network to the door at the receiving process many networks  including the internet  provide more than one transport protocol when you develop an application  you must choose one of the available transport protocols how do you make this choice ? most likely  you will study the services that are provided by the available transport protocols  and you will pick the protocol with the services that best match the needs of your application the situation is similar to choosing either train or airplane transport for travel between two cities  say new york city and boston   you have to choose one or the other  and each transport mode offers different services  for example  the train offers downtown pick up and drop off  whereas the plane offers shorter transport time  what services might a network application need from a transport protocol ? we can broadly classify an application 's service requirements along three dimensions  data loss  bandwidth  and timing l data loss some applications  such as electronic mail  file transfer  remote host access  web document transfers  and financial applications require fully reliable data transfer  i.e  no data loss in particular  a loss of file data  or data in a financial transaction  can have devastating consequences  in the latter case  for either the bank or the customer !   other loss tolerant applications  most notably multimedia applications such as real-time audio/video or stored audio/ video  can tolerate some amount of data loss in these latter applications  lost data might result in a small glitch in the played-out audio/video  not a crucial impairment the effects of such loss on application quality  and actual amount of tolerable packet loss  will depend strongly on the coding scheme used l bandwidth some applications must be able to transmit data at a certain rate in order to be " effective "  for example  if an internet telephony application encodes voice at 32 kbps  then it must be able to send data into the network  and have data delivered to the receiving application  at this rate if this amount of bandwidth is not available  the application needs to either encode at a different rate  and receive enough bandwidth to sustain this different coding rate  or should give up  receiving half of the needed bandwidth is of no use to such a bandwidth-sensitive application file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  5 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts while many current multimedia applications are bandwidth sensitive  future multimedia applications may use adaptive coding technique to encode at a rate that matches the currentlyavailable bandwidth while bandwidth-sensitive applications require a given amount of bandwidth  elastic applications can make use of as much or as little bandwidth as happens to be available electronic mail  file transfer  remote access  and web transfers are all elastic applications of course  the more bandwidth  the better there 's an adage that says that one can not be too rich  too thin  or have too much bandwidth l timing the final service requirement is that of timing interactive real-time applications  such as internet telephony  virtual environments  teleconferencing  and multiplayer games require tight timing constraints on data delivery in order to be " effective " for example  many of these applications require that end-to-end delays be on the order of a few hundred of milliseconds or less  see chapter 6 and  gauthier 1999  ramjee 94    long delays in internet telephony  for example  tend to result in unnatural pauses in the conversation ; in a multiplayer game or virtual interactive environment  a long delay between taking an action and seeing the response from the environment  e.g  from another player on the end of an end-to-end connection  makes the application feel less " realistic " for non-real-time applications  lower delay is always preferable to high delay  but no tight constraint is placed on the end-to-end delays figure 2.1-2 summarizes the reliability  bandwidth  and timing requirements of some popular and emerging internet applications application data loss bandwidth time sensitive ? file transfer no loss elastic no electronic mail no loss elastic no web documents no loss elastic no real-time audio/video loss-tolerant audio  few kbps to 1mbps video  10 's kbps to 5 mbps yes  100 's of msec stored audio/video loss-tolerant same as interactive audio/video yes  few seconds interactive games loss-tolerant few kbps to 10 's kbps yes  100 's msecs financial applications required elastic yes and no figure 2.1-2  requirements of selected network applications figure 2.1-2 outlines only a few of the key requirements of a few of the more popular internet applications our goal here is not to provide a complete classification  but simply to identify a few of the most important axes along which network application requirements can be classified file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  6 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts 2.1.3 services provided by the internet transport protocols the internet  and more generally tcp/ip networks  makes available two transport protocols to applications  namely  udp  user datagram protocol  and tcp  transmission control protocol   when a developer creates a new application for the internet  one of the first decisions that the developer must make is whether to use udp or tcp each of these protocols offers a different service model to the invoking applications tcp services the tcp service model includes a connection-oriented service and a reliable data transfer service when an application invokes tcp for its transport protocol  the application receives both of these services from tcp l connection-oriented service  tcp has the client and server exchange transport-layer control information with each other before the application-level messages begin to flow this so-called handshaking procedure  that is part of the tcp protocol  alerts the client and server  allowing them to prepare for an onslaught of packets after the handshaking phase  a tcp connection is said to exist between the sockets of the two processes the connection is a full-duplex connection in that the two processes can send messages to each other over the connection at the same time when the application is finished sending messages  it must tear down the connection the service is referred to as a " connection-oriented " service rather than a " connection " service  or a " virtual circuit " service   because the two processes are connected in a very loose manner in chapter 3 we will discuss connection-oriented service in detail and examine how it is implemented l reliable transport service  the communicating processes can rely on tcp to to deliver all messages sent without error and in the proper order when one side of the application passes a stream of bytes into a socket  it can count on tcp to deliver the same stream of data to the receiving socket  with no missing or duplicate bytes tcp also includes a congestion control mechanism  a service for the general welfare of the internet rather than for the direct benefit of the communicating processes the tcp congestion control mechanism throttles a process  client or server  when the network is congested in particular  as we shall see in chapter 3  tcp congestion control attempts to limit each tcp connection to its fair share of network bandwidth the throttling of the transmission rate can have a very harmful effect on real-time audio and video applications that have minimum bandwidth requirements moreover  real-time applications are losstolerant and do not need a fully reliable transport service in fact  the tcp acknowledgments and retransmissions that provide the reliable transport service  discussed in chapter 3  can further slow down the transmission rate of useful real-time data for these reasons  developers of real-time applications usually run their applications over udp rather than tcp file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  7 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts having outlined the services provided by tcp  let us say a few words about the services that tcp does not provide first  tcp does not guarantee a minimum transmission rate in particular  a sending process is not permitted to transmit at any rate it pleases ; instead the sending rate is regulated by tcp congestion control  which may force the sender to send at a low average rate second  tcp does not provide any delay guarantees in particular  when a sending process passes a message into a tcp socket  the message will eventually arrive to receiving socket  but tcp guarantees absolutely no limit on how long the message may take to get there as many of us have experienced with the world wide wait  one can sometimes wait tens of seconds or even minutes for tcp to deliver a message  containing  for example  an html file  from web server to web client in summary  tcp guarantees delivery of all data  but provides no guarantees on the rate of delivery or on the delays experienced by individual messages udp services udp is a no-frills  lightweight transport protocol with a minimalist service model udp is connectionless  so there is no handshaking before the two processes start to communicate udp provides an unreliable data transfer service  that is  when a process sends a message into a udp socket  udp provides no guarantee that the message will ever reach the receiving socket furthermore  messages that do arrive to the receiving socket may arrive out of order returning to our houses/doors analogy for processes/sockets  udp is like having a long line of taxis waiting for passengers on the other side of the sender 's door when a passenger  analogous to an application message  exits the house  it hops in one of the taxis some of the taxis may break down  so they do n't ever deliver the passenger to the receiving door ; taxis may also take different routes  so that passengers arrive to the receiving door out of order on the other hand  udp does not include a congestion control mechanism  so a sending process can pump data into a udp socket at any rate it pleases although all the data may not make it to the receiving socket  a large fraction of the data may arrive also  because udp does not use acknowledgments or retransmissions that can slow down the delivery of useful real-time data  developers of real-time applications often choose to run their applications over udp similar to tcp  udp provides no guarantee on delay as many of us know  a taxi can be stuck in a traffic jam for a very long time  while the meter continues to run !   application application-layer protocol underlying transport protocol electronic mail smtp  rfc 821  tcp remote terminal access telnet  rfc 854  tcp web http  rfc 2068  tcp file transfer ftp  rfc 959  tcp remote file server nfs  mckusik 1996  udp or tcp file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  8 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts streaming multimedia proprietary  e.g  real networks  udp or tcp internet telephony proprietary  e.g  vocaltec  typically udp figure 2.1-3  popular internet applications  their application-layer protocols  and their underlying transport protocols figure 2.1-3 indicates the transport protocols used by some popular internet applications we see that email  remote terminal access  the web and file transfer all use tcp these applications have chosen tcp primarily because tcp provides the reliable data transfer service  guaranteeing that all data will eventually get to its destination we also see that internet telephone typically runs over udp each side of an internet phone application needs to send data across the network at some minimum rate  see figure 2.1 2  ; this is more likely to be possible with udp than with tcp also  internet phone applications are losstolerant  so they do not need the reliable data transfer service  and the acknowledgments and retransmissions that implement the service  provided by tcp as noted earlier  neither tcp nor udp offer timing guarantees does this mean that time-sensitive applications can not run in today 's internet ? the answer is clearly no  the internet has been hosting timesensitive applications for many years these applications often work pretty well because they have been designed to cope  to the greatest extent possible  with this lack of guarantee we shall investigate several of these design tricks in chapter 6 nevertheless  clever design has its limitations when delay is excessive  as is often the case in the public internet in summary  today 's internet can often provide satisfactory service to time-sensitive applications  but it can not provide any timing or bandwidth guarantees in chapter 6  we shall also discuss emerging internet service models that provide new services  including guaranteed delay service for time-sensitive applications 2.1.4 network applications covered in this book new public domain and proprietary internet applications are being developed everyday rather than treating a large number of internet applications in an encyclopedic manner  we have chosen to focus on a small number of important and popular applications in this chapter we discuss in some detail four popular applications  the web  file transfer  electronic mail  and directory service we first discuss the web  not only because the web is an enormously popular application  but also because its applicationlayer protocol  http  is relatively simple and illustrates many key principles of network protocols we then discuss file transfer  as it provides a nice contrast to http and enables us to highlight some additional principles we discuss electronic mail  the internet 's first killer application we shall see that modern electronic mail makes use of not one  but of several  application-layer protocols the web  file transfer  and electronic mail have common service requirements  they all require a reliable transfer service  none of them have special timing requirements  and they all welcome an elastic bandwidth offering the services provided by tcp are largely sufficient for these three applications the fourth application  domain name system  dns   provides a directory service for the internet most users do not interact with dns directly ; instead  users invoke dns indirectly through other applications  including the file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  9 of 10  20/11/2004 15  51  50 network applications  terminology and basic concepts web  file transfer  and electronic mail   dns illustrates nicely how a distributed database can be implemented in the internet none of the four applications discussed in this chapter are particularly time sensitive ; we will defer our discussion of such time-sensitive applications until chapter 6 references  cisco 1999  cisco systems inc  " atm signaling and addressing  " july 1999  gauthier 1999  l gauthier  c diot  j kurose  " end-to-end transmission control mechanisms for multiparty interactive applications on the internet  " proc ieee infocom 99  april 1999  fritz 1997  j fritz  " demystifying atm addressing  " byte magazine  december 1997  itu 1997  international telecommunications union  " recommendation e.164/i.331  the international public telecommunication numbering plan  " may 1997  mckusik 1996  marshall kirk mckusick  keith bostic  michael karels  and john quarterman  " the design and implementation of the 4.4bsd operating system  " addison-wesley publishing company  inc  0-201-54979-4   1996 chapter 9 of this text  is entitled 'the network file system ' and is on-line at http  //www.netapp.com/technology/level3/nfsbook.html  ramjee 1994  r ramjee  j kurose  d towsley  h schulzrinne  " adaptive playout mechanisms for packetized audio applications in wide-area networks "  proc ieee infocom 94  rfc 821  j.b postel  " simple mail transfer protocol  " rfc 821  august 1982  rfc 854  j postel  j  reynolds  " telnet protocol specification  " rfc 854 may 1993  rfc 959  j postel  j reynolds  " file transfer protocol  ftp   " rfc 959  oct 1985  rfc 1035  p mockapetris  " domain names  implementation and specification "  rfc 1035  nov 1987  rfc 1700  j reynolds  j postel  " assigned numbers  " rfc 1700  oct 1994  rfc 2068  r fielding  j gettys  j mogul  h frystyk  and t berners-lee  " hypertext transfer protocol  http/1.1  " rfc 2068  january 1997 return to table of contents copyright keith w ross and james f kurose 1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/client_server.htm  10 of 10  20/11/2004 15  51  50 the hypertext transfer protocol 2.2 the world wide web  http in the 1980s the internet was used by researchers  academics and university students to login to remote hosts  to transfer files from local hosts to remote hosts and vice versa  to receive and send news  and to receive and send electronic mail although these applications were  and continue to be  extremely useful  the internet was essentially unknown outside the academic and research communities then in early 1990s the internet 's killer application arrived on the scene  the world wide web the web is the internet application that caught the general public 's eye it is dramatically changing how people interact inside and outside their work environments it has spawned thousands of start up companies it has elevated the internet from just one of many data networks  including online networks such as prodigy  america on line and compuserve  national data networks such as minitel/transpac in france  and private x.25 and frame relay networks  to essentially the one and only data network history is sprinkled with the arrival of electronic communication technologies that have had major societal impacts the first such technology was the telephone  invented in the 1870s the telephone allowed two persons to orally communicate in real-time without being in the same physical location it had a major impact on society  both good and bad the next electronic communication technology was broadcast radio/television  which arrived in the 1920s and 1930s broadcast radio/television allowed people to receive vast quantities of audio and video information it also had a major impact on society  both good and bad the third major communication technology that has changed the way people live and work is the web perhaps what appeals the most to users about the web is that it is on demand users receive what they want  when they want it this is unlike broadcast radio and television  which force users to " tune in " when the content provider makes the content available in addition to being on demand  the web has many other wonderful features that people love and cherish it is enormously easy for any individual to make any available available over the web ; everyone can become a publisher at extremely low cost hyperlinks and search engines help us navigate through an ocean of web sites graphics and animated graphics stimulate our senses forms  java applets  active x components  as well as many other devices enable us to interact with pages and sites and more and more  the web provides a menu interface to vast quantities of audio and video material stored in the internet  audio and video that can be accessed on demand 2.2.1 overview of http the hypertext transfer protocol  http   the web 's application-layer protocol  is at the heart of the web http is implemented in two programs  a client program and server program the client program and server programs  executing on different end systems  talk to each other by exchanging http messages http defines the structure of these messages and how the client and server exchange the messages before explaining http in detail  it is useful to review some web terminology a web page  also called a document  consists of objects an object is a simply file  such as a html file  a jpeg image  a gif image  a java applet  an audio clip  etc  that is addressable by a single url most web pages consist of a base html file and several referenced objects for example  if a web page contains html text and five jpeg images  then the web page has six objects  the base html file plus the five images the base html file references the other objects in the page with the objects ' urls each url has two components  the host name of the server that houses the object and the object 's path name for example  the url www.someschool.edu/somedepartment/picture.gif has www.someschool.edu for a host name and /somedepartment/picture.gif for a path name a browser is a user agent for the web ; it displays to the user the requested web page and provides numerous navigational and configuration features web browsers also implement the client side of http thus  in the context of the web  we will interchangeably use the words " browser " and " client "  popular web browsers include netscape communicator and microsoft explorer a web server houses web objects  each addressable by a url web servers also implement the server side of http popular web servers include apache  microsoft internet information server  and the netscape enterprise server  netcraft provides a nice survey of web server penetration  netcraft    http defines how web clients  i.e  browsers  request web pages from servers  i.e  web servers  and how servers transfer web pages to clients we discuss the interaction between client and server in detail below  but the general idea is illustrated in figure 2.2-1 when a user requests a web page  e.g  clicks on a hyperlink   the browser sends http request messages for the objects in the page to the server the server receives the requests and responds with http response messages that contain the objects through 1997 essentially all browsers and web servers implement version http/1.0  which is defined in  rfc 1945   beginning in 1998 web servers and browsers began to implement version http/1.1  which is defined in  rfc 2068   http/1.1 is backward compatible with http/1.0 ; a web server file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  1 of 14  20/11/2004 15  51  52 the hypertext transfer protocol running 1.1 can " talk " with a browser running 1.0  and a browser running 1.1 can " talk " with a server running 1.0 figure 2.2-1  http request-response behavior both http/1.0 and http/1.1 use tcp as their underlying transport protocol  rather than running on top of udp   the http client first initiates a tcp connection with the server once the connection is established  the browser and the server processes access tcp through their socket interfaces as described in section 2.1  on the client side the socket interface is the " door " between the client process and the tcp connection ; on the server side it is the " door " between the server process and the tcp connection the client sends http request messages into its socket interface and receives http response messages from its socket interface similarly  the http server receives request messages from its socket interface and sends response messages into the socket interface once the client sends a message into its socket interface  the message is " out of the client 's hands " and is " in the hands of tcp "  recall from section 2.1 that tcp provides a reliable data transfer service to http this implies that each http request message emitted by a client process eventually arrives in tact at the server ; similarly  each http response message emitted by the server process eventually arrives in tact at the client here we see one of the great advantages of a layered architecture  http need not worry about lost data  or the details of how tcp recovers from loss or reordering of data within the network that is the job of tcp and the protocols in the lower layers of the protocol stack tcp also employs a congestion control mechanism which we shall discuss in detail in chapter 3 we only mention here that this mechanism forces each new tcp connection to initially transmit data at a relatively slow rate  but then allows each connection to ramp up to a relatively high rate when the network is uncongested the initial slow-transmission phase is referred to as slow start it is important to note that the server sends requested files to clients without storing any state information about the client if a particular client asks for the same object twice in a period of a few seconds  the server does not respond by saying that it just served the object to the client ; instead  the server resends the object  as it has completely forgotten what it did earlier because an http server maintains no information about the clients  http is said to be a stateless protocol 2.2.2 non-persistent and persistent connections http can use both non-persistent connections and persistent connections non-persistent connections is the default mode for http/1.0 conversely  persistent connections is the default mode for http/1.1 non-persistent connections let us walk through the steps of transferring a web page from server to client for the case of non-persistent connections suppose the page consists of a base html file and 10 jpeg images  and that all 11 of these objects reside on the same server suppose the url for the base html file is www.someschool.edu/somedepartment/home.index  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  2 of 14  20/11/2004 15  51  52 the hypertext transfer protocol here is what happens  1 the http client initiates a tcp connection to the server www.someschool.edu port number 80 is used as the default port number at which the http server will be listening for http clients that want to retrieve documents using http 2 the http client sends a http request message into the socket associated with the tcp connection that was established in step 1 the request message either includes the entire url or simply the path name /somedepartment/home.index  we will discuss the http messages in some detail below  3 the http server receives the request message via the socket associated with the connection that was established in step 1  retrieves the object /somedepartment/home.index from its storage  ram or disk   encapsulates the object in a http response message  and sends the response message into the tcp connection 4 the http server tells tcp to close the tcp connection  but tcp does n't actually terminate the connection until the client has received the response message in tact  5 the http client receives the response message the tcp connection terminates the message indicates that the encapsulated object is an html file the client extracts the file from the response message  parses the html file and finds references to the ten jpeg objects 6 the first four steps are then repeated for each of the referenced jpeg objects as the browser receives the web page  it displays the page to the user two different browsers may interpret  i.e  display to the user  a web page in somewhat different ways http has nothing to do with how a web page is interpreted by a client the http specifications   rfc 1945  and  rfc 2068   only define the communication protocol between the client http program and the server http program the steps above use non-persistent connections because each tcp connection is closed after the server sends the object  the connection does not persist for other objects note that each tcp connection transports exactly one request message and one response message thus  in this example  when a user requests the web page  11 tcp connections are generated in the steps described above  we were intentionally vague about whether the client obtains the 10 jpegs over ten serial tcp connections  or whether some of the jpegs are obtained over parallel tcp connections indeed  users can configure modern browsers to control the degree of parallelism in their default modes  most browsers open five to ten parallel tcp connections  and each of these connections handles one request-response transaction if the user prefers  the maximum number of parallel connections can be set to one  in which case the ten connections are established serially as we shall see in the next chapter  the use of parallel connections shortens the response time since it cuts out some of the rtt and slow-start delays parallel tcp connections can also allow the requesting browser to steal a larger share of its fair share of the end-to-end transmission bandwidth before continuing  let 's do a back of the envelope calculation to estimate the amount of time from when a client requests the base html file until the file is received by the client to this end we define the round-trip time rtt  which is the time it takes for a small packet to travel from client to server and then back to the client the rtt includes packet propagation delays  packet queuing delays in intermediate routers and switches  and packet processing delays  these delays were discussed in section 1.6  now consider what happens when a user clicks on a hyperlink this causes the browser to initiate a tcp connection between the browser and the web server ; this involves a " threeway handshake "  the client sends a small tcp message to the server  the server acknowledges and responds with a small message  and finally the client acknowledges back to the server one rtt elapses after the first two parts of the three-way handshake after completing the first two parts of the handshake  the client sends the http request message into the tcp connection  and tcp " piggybacks " the last acknowledgment  the third part of the three-way handshake  onto the request message once the request message arrives at the server  the server sends the html file into the tcp connection this http request/response eats up another rtt thus  roughly  the total response time is 2rtt plus the transmission time at the server of the html file persistent connections non-persistent connections have some shortcomings first  a brand new connection must be established and maintained for each requested object for each of these connections  tcp buffers must be allocated and tcp variables must be kept in both the client and server this can place a serious burden on the web server  which may be serving requests from hundreds of different clients simultaneously second  as we just described  each object suffers two rtts  one rtt to establish the tcp connection and one rtt to request and receive an object finally  each object suffers from tcp slow start because every tcp connection begins with a tcp slow-start phase however  the accumulation of rtt and slow start delays is partially alleviated by the use of parallel tcp connections file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  3 of 14  20/11/2004 15  51  52 the hypertext transfer protocol with persistent connections  the server leaves the tcp connection open after sending responses subsequent requests and responses between the same client and server can be sent over the same connection in particular  an entire web page  in the example above  the base html file and the ten images  can be sent over a single persistent tcp connection ; moreover  multiple web pages residing on the same server can be sent over one persistent tcp connection typically  the http server closes the connection when it isn ? t used for a certain time  the timeout interval   which is often configurable there are two versions of persistent connections  without pipelining and with pipelining for the version without pipelining  the client issues a new request only when the previous response has been received in this case  each of the referenced objects  the ten images in the example above  experiences one rtt in order to request and receive the object although this is an improvement over non-persistent 's two rtts  the rtt delay can be further reduced with pipelining another disadvantage of no pipelining is that after the server sends an object over the persistent tcp connection  the connection hangs  does nothing  while it waits for another request to arrive this hanging wastes server resources the default mode of http/1.1 uses persistent connections with pipelining in this case  the http client issues a request as soon as it encounters a reference thus the http client can make back-to-back requests for the referenced objects when the server receives the requests  it can send the objects back-to-back if all the requests are sent back-to-back and all the responses are sent back-to-back  then only one rtt is expended for all the referenced objects  rather than one rtt per referenced object when pipelining is n't used   furthermore  the pipelined tcp connection hangs for a smaller fraction of time in addition to reducing rtt delays  persistent connections  with or without pipelining  have a smaller slow-start delay than non-persistent connections this is because that after sending the first object  the persistent server does not have to send the next object at the initial slow rate since it continues to use the same tcp connection instead  the server can pick up at the rate where the first object left off we shall quantitatively compare the performance of non-persistent and persistent connections in the homework problems of chapter 3 the interested reader is also encouraged to see  heidemann 1997  and  nielsen 1997   2.2.3 http message format the http specifications 1.0   rfc 1945  and 1.1  rfc 2068   define the http message formats there are two types of http messages  request messages and response messages  both of which are discussed below http request message below we provide a typical http request message  get /somedir/page.html http/1.1 connection  close user-agent  mozilla/4.0 accept  text/html  image/gif  image/jpeg accept-language  fr  extra carriage return  line feed  we can learn a lot my taking a good look at this simple request message first of all  we see that the message is written in ordinary ascii text  so that your ordinary computer-literate human being can read it second  we see that the message consists of five lines  each followed by a carriage return and a line feed the last line is followed by an additional carriage return and line feed although this particular request message has five lines  a request message can have many more lines or as little as one line the first line of a http request message is called the request line ; the subsequent lines are called the header lines the request line has three fields  the method field  the url field  and the http version field the method field can take on several different values  including get  post  and head the great majority of http request messages use the get method the get method is used when the browser requests an object  with the requested object identified in the url field in this example  the browser is requesting the object /somedir/page.html  the browser does n't have to specify the host name in the url field since the tcp connection is already connected to the host  server  that serves the requested file  the version is self-explanatory ; in this example  the browser implements version http/1.1 now let 's look at the header lines in the example by including the connection  close header line  the browser is telling the server that it does n't want to use persistent connections ; it wants the server to close the connection after sending the requested object thus the browser that generated this request message implements http/1.1 but it does n't want to bother with persistent connections the useragent  header line specifies the user agent  i.e  the browser type that is making the request to the server  here the user agent is file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  4 of 14  20/11/2004 15  51  52 the hypertext transfer protocol mozilla/4.0  a netscape browser this header line is useful because the server can actually send different versions of the same object to different types of user agents  each of the versions is addressed by the same url  the accept  header line tells the server the type of objects the browser is prepared to accept in this case  the client is prepared to accept html text  a gif image or a jpeg image if the file /somedir/page.html contains a java applet  and who says it ca n't !   then the server should n't send the file  since the browser can not handle that object type finally  the accept-language  header indicates that the user prefers to receive a french version of the object  if such an object exists on the server ; otherwise  the server should send its default version having looked at an example  let us now look at the general format for a request message  as shown in figure 2.2-2  figure 2.2-2  general format of a request message we see that the general format follows closely the example request message above you may have noticed  however  that after the header lines  and the additional carriage return and line feed  there is an " entity body "  the entity body is not used with the get method  but is used with the post method the http client uses the post method when the user fills out a form  for example  when a user gives search words to a search engine such as yahoo with a post message  the user is still requesting a web page from the server  but the specific contents of the web page depend on what the user wrote in the form fields if the value of the method field is post  then the entity body contains what the user typed into the form fields the head method is similar to the post method when a server receives a request with the head method  it responds with an http message but it leaves out the requested object the head method is often used by http server developers for debugging http response message below we provide a typical http response message this response message could be the response to the example request message just discussed http/1.1 200 ok connection  close date  thu  06 aug 1998 12  00  15 gmt server  apache/1.3.0  unix  last-modified  mon  22 jun 1998 09  23  24 gmt content-length  6821 content-type  text/html data data data data data  let 's take a careful look at this response message it has three sections  an initial status line  six header lines  and then the entity body the entity body is the meat of the message  it contains the requested object itself  represented by data data data data data    the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  5 of 14  20/11/2004 15  51  52 the hypertext transfer protocol status line has three fields  the protocol version field  a status code  and a corresponding status message in this example  the status line indicates that the server is using http/1.1 and that that everything is ok  i.e  the server has found  and is sending  the requested object   now let 's look at the header lines the server uses the connection  close header line to tell the client that it is going to close the tcp connection after sending the message the date  header line indicates the time and date when the http response was created and sent by the server note that this is not the time when the object was created or last modified ; it is the time when the server retrieves the object from its file system  inserts the object into the response message and sends the response message the server  header line indicates that the message was generated by an apache web server ; it is analogous to the user-agent  header line in the http request message the last-modified  header line indicates the time and date when the object was created or last modified the last-modified  header  which we cover in more detail below  is critical for object caching  both in the local client and in network cache  a.k.a proxy  servers the content-length  header line indicates the number of bytes in the object being sent the content type  header line indicates that the object in the entity body is html text  the object type is officially indicated by the content type  header and not by the file extension  note that if the server receives an http/1.0 request  it will not use persistent connections  even if it is an http/1.1 server instead the http/1.1 server will close the tcp connection after sending the object this is necessary because an http/1.0 client expects the server to close the connection figure 2.2-3  general format of a response message having looked at an example  let us now examine the general format of a response message  which is shown in figure 2.2-3 this general format of the response message matches the previous example of a response message let 's say a few additional words about status codes and their phrases the status code and associated phrase indicate the result of the request some common status codes and associated phrases include  l 200 ok  request succeeded and the information is returned in the response l 301 moved permanently  requested object has been permanently moved ; new url is specified in location  header of the response message the client software will automatically retrieve the new url file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  6 of 14  20/11/2004 15  51  52 the hypertext transfer protocol l 400 bad request  a generic error code indicating that the request could not be understood by the server l 404 not found  the requested document does not exist on this server l 505 http version not supported  the request http protocol version is not supported by the server how would you like to see a real http response message ? this is very easy to do ! first telnet into your favorite www server then type in a one-line request message for some object that is housed on the server for example  if you can logon to a unix machine  type  telnet www.eurecom.fr 80 get / ~ ross/index.html http/1.0  hit the carriage return twice after typing the second line  this opens a tcp connection to port 80 of the host www.eurecom.fr and then sends the http get command you should see a response message that includes the base html file of professor ross 's homepage if you 'd rather just see the http message lines and not receive the object itself  replace get with head finally  replace / ~ ross/index html with / ~ ross/banana.html and see what kind of response message you get in this section we discussed a number of header lines that can be used within http request and response messages the http specification  especially http/1.1  defines many  many more header lines that can be inserted by browsers  web servers and network cache servers we have only covered a small fraction of the totality of header lines we will cover a few more below and another small fraction when we discuss network web caching at the end of this chapter a readable and comprehensive discussion of http headers and status codes is given in  luotonen 1998   an excellent introduction to the technical issues surrounding the web is  yeager 1996   how does a browser decide which header lines it includes in a request message ? how does a web server decide which header lines it includes in a response messages ? a browser will generate header lines as a function of the browser type and version  e.g  an http/1.0 browser will not generate any 1.1 header lines   user configuration of browser  e.g  preferred language  and whether the browser currently has a cached  but possibly out-of-date  version of the object web servers behave similarly  there are different products  versions  and configurations  all of which influence which header lines are included in response messages 2.2.4 user-server interaction  authentication and cookies we mentioned above that an http server is stateless this simplifies server design  and has permitted engineers to develop very highperforming web servers however  it is often desirable for a web site to identify users  either because the server wishes to restrict user access or because it wants to serve content as a function of the user identity http provides two mechanisms to help a server identify a user  authentication and cookies authentication many sites require users to provide a username and a password in order to access the documents housed on the server this requirement is referred to as authentication http provides special status codes and headers to help sites perform authentication let us walk through an example to get a feel for how these special status codes and headers work suppose a client requests an object from a server  and the server requires user authorization 1 the client first sends an ordinary request message with no special header lines 2 the server then responds with empty entity body and with a 401 authorization required status code in this response message the server includes the www-authenticate  header  which specifies the details about how to perform authentication  typically  it indicates to the user needs to provide a username and a password  3 the client receives the response message and prompts the user for a username and password the client resends the request message  but this time includes an authorization  header line  which includes the username and password after obtaining the first object  the client continues to send the username and password in subsequent requests for objects on the server  this typically continues until the client closes his browser however  while the browser remains open  the username and password are cached  so the user is not prompted for a username and password for each object it requests !  in this manner  the site can identify the user for every request file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  7 of 14  20/11/2004 15  51  52 the hypertext transfer protocol we will see in chapter 7 that http performs a rather weak form of authentication  one that would not be difficult to break we will study more secure and robust authentication schemes later in chapter 7 cookies cookies are an alternative mechanism for sites to keep track of users they are defined in rfc 2109 some web sites use cookies and others do n't let 's walk through an example suppose a client contacts a web site for the first time  and this site uses cookies the server ? s response will include a set-cookie  header often this header line contains an identification number generated by the web server for example  the header line might be  set-cookie  1678453 when the the http client receives the response message  it sees the set-cookie  header and identification number it then appends a line to a special cookie file that is stored in the client machine this line typically includes the host name of the server and user 's associated identification number in subsequent requests to the same server  say one week later  the client includes a cookie  request header  and this header line specifies the identification number for that server in the current example  the request message includes the header line  cookie  1678453 in this manner  the server does not know the username of the user  but the server does know that this user is the same user that made a specific request one week ago web servers use cookies for many different purposes  l if a server requires authentication but does n't want to hassle a user with a username and password prompt every time the user visits the site  it can set a cookie l if a server wants to remember a user 's preferences so that it can provide targeted advertising during subsequent visits  it can set a cookie l if a user is shopping at a site  e.g  buying several cds   the server can use cookies to keep track of the items that the user is purchasing  i.e  to create a virtual shopping cart we mention  however  that cookies pose problems for mobile users who access the same site from different machines the site will treat the same user as a different user for each different machine used we conclude by pointing the reader to the page persistent client state http cookies  which provides an in-depth but readable introduction to cookies we also recommend cookies central  which includes extensive information on the cookie controversy 2.2.5 the conditional get by storing previously retrieved objects  web caching can reduce object-retrieval delays and diminish the amount of web traffic sent over the internet web caches can reside in a client or in an intermediate network cache server we will discuss network caching at the end of this chapter in this subsection  we restrict our attention to client caching although web caching can reduce user-perceived response times  it introduces a new problem  a copy of an object residing in the cache may be stale in other words  the object housed in the web server may have been modified since the copy was cached at the client fortunately  http has a mechanism that allows the client to employ caching while still ensuring that all objects passed to the browser are up-to-date this mechanism is called the conditional get an http request message is a so-called conditional get message if  i  the request message uses the get method and  ii  the request message includes an if-modified-since  header line to illustrate how the conditional get operates  let 's walk through an example first  a browser requests an uncached object from some web server  get /fruit/kiwi.gif http/1.0 user-agent  mozilla/4.0 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  8 of 14  20/11/2004 15  51  52 the hypertext transfer protocol accept  text/html  image/gif  image/jpeg second  the web server sends a response message with the object to the client  http/1.0 200 ok date  wed  12 aug 1998 15  39  29 server  apache/1.3.0  unix  last-modified  mon  22 jun 1998 09  23  24 content-type  image/gif data data data data data  the client displays the object to the user but also saves the object in its local cache importantly  the client also caches the last-modified date along with the object third  one week later  the user requests the same object and the object is still in the cache since this object may have been modified at the web server in the past week  the browser performs an up-to-date check by issuing conditional get specifically  the browser sends get /fruit/kiwi.gif http/1.0 user-agent  mozilla/4.0 accept  text/html  image/gif  image/jpeg if-modified-since  mon  22 jun 1998 09  23  24 note that the value of the if-modified-since  header line is exactly equal to value of the last-modified  header line that was sent by the server one week ago this conditional get is telling the server to only send the object if the object has been modified since the specified date suppose the object has not been modified since 22 jun 1998 09  23  24 then  fourth  the web server sends a response message to the client  http/1.0 304 not modified date  wed  19 aug 1998 15  39  29 server  apache/1.3.0  unix   empty entity body  we see that in response to the conditional get  the web server still sends a response message  but it does n't bother to include the requested object in the response message including the requested object would only waste bandwidth and increase user perceived response time  particularly if the object is large  such as a high resolution image   note that this last response message has in the status line 304 not modified  which tells the client that it can go ahead and use its cached copy of the object 2.2.6 web caches a web cache  also called a proxy server  is a network entity that satisfies http requests on the behalf of a client the web cache has its own disk storage  and keeps in this storage copies of recently requested objects as shown in figure 2.2-4  users configure their browsers so that all of their http requests are first directed to the web cache  this is a straightforward procedure with microsoft and netscape browsers  once a browser is configured  each browser request for an object is first directed to the web cache as an example  suppose a browser is requesting the object http  //www.someschool.edu/campus.gif  l the browser establishes a tcp connection to the proxy server and sends an http request for the object to the web cache l the web cache checks to see if it has a copy of the object stored locally if it does  the web cache forwards the object within an http response message to the client browser l if the web cache does not have the object  the web cache opens a tcp connection to the origin server  that is  to www.someschool edu the web cache then sends an http request for the object into the tcp connection after receiving this request  the origin server sends the object within an http response to the web cache l when the web cache receives the object  it stores a copy in its local storage and forwards a copy  within an http response message  to the client browser  over the existing tcp connection between the client browser and the web cache   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/http.htm  9 of 14  20/11/2004 15  51  52 the hypertext transfer protocol figure 2.2-4  clients requesting objects through a web cache note that a cache is both a server and a client at the same time when it receives requests from and sends responses to a browser  it is a server when it sends requests to and receives responses from an origin server it is a client so why bother with a web cache ? what advantages does it have ? web caches are enjoying wide-scale deployment in the internet for at least three reasons first  a web cache can substantially reduce the response time for a client request  particularly if the bottleneck bandwidth between the client and the origin server is much less than the bottleneck bandwidth between the client and the cache if there is a high-speed connection between the client and the cache  as there often is  and if the cache has the requested object  then the cache will be able to rapidly deliver the object to the client second  as we will soon illustrate with an example  web caches can substantially reduce traffic on an institution 's access link to the internet by reducing traffic  the institution  e.g  a company or a university  does not have to upgrade bandwidth as quickly  thereby reducing costs furthermore  web caches can substantially reduce web traffic in the internet as a whole  thereby improving performance for all applications in 1998  over 75 % of internet traffic was web traffic  so a significant reduction in web traffic can translate into a significant improvement in internet performance  claffy 1998   third  an internet dense with web caches  e.g  at institutional  regional and national levels  provides an infrastructure for rapid distribution of content  even for content providers who run their sites on low-speed servers behind low-speed access links if such a " resouce-poor " content provider suddenly has popular content to distribute  this popular content will quickly be copied into the internet caches  and high user demand will be satisfied to gain a deeper understanding of the benefits of caches  let us consider an example in the context of figure 2.2-5 in this figure  there are two networks  the institutional network and the internet the institutional network is a high-speed lan a router in the institutional network and a router in the internet are connected by a 1.5 mbps link the institutional network consists of a high-speed lan which is connected to the internet through a 1.5 mbps access link the origin servers are attached to the internet  but located all over the globe suppose that the average object size is 100 kbits and that the average request rate from the institution 's browsers to the origin servers is 15 requests per second also suppose that amount of time it takes from when the router on the internet side of the access link in figure 2.2-5 forwards an http request  within an ip datagram  until it receives the ip datagram  typically  many ip datagrams  containing the corresponding response is two seconds on average informally  we refer to this last delay as the " internet delay "  the total response time  that is the time from when a browser requests an object until the browser receives the object  is the sum of the lan delay  the access delay  i.e  the delay between the two routers  and the internet delay let us now do a very crude calculation to estimate this delay the traffic intensity on the lan  see section 1.6  is  15 requests/sec  *  100 kbits/request  /  10mbps  = .15 whereas the traffic intensity on access link  from internet router to institution router  is  15 requests/sec  *  100 kbits/request  /  1.5 mbps  = 1 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/http.htm  10 of 14  20/11/2004 15  51  52 the hypertext transfer protocol a traffic intensity of .15 on a lan typically results in at most tens of milliseconds of delay ; hence  we can neglect the lan delay however  as discussed in section 1.6  as the traffic intensity approaches 1  as is the case of the access link in figure 2.2-5   the delay on a link becomes very large and grows without bound thus  the average response time to satisfy requests is going to be on the order of minutes  if not more  which is unacceptable for the institution 's users clearly something must be done figure 2.2-5  bottleneck between institutional network and the internet one possible solution is to increase the access rate from 1.5 mbps to  say  10 mbps this will lower the traffic intensity on the access link to .15  which translates to negligible delays between the two routers in this case  the total response response time will roughly be 2 seconds  that is  the internet delay but this solution also means that the institution must upgrade its access link from 1.5 mbps to 10 mbps  which can be very costly now consider the alternative solution of not upgrading the access link but instead installing a web cache in the institutional network this solution is illustrated in figure 2.2-6 hit rates  the fraction of requests that are satisfied by a cache  typically range from .2 to .7 in practice for illustrative purposes  let us suppose that the cache provides a hit rate of .4 for this institution because the clients and the cache are connected to the same high-speed lan  40 % of the requests will be satisfied almost immediately  say within 10 milliseconds  by the cache nevertheless  the remaining 60 % of the requests still need to be satisfied by the origin servers but with only 60 % of the requested objects passing through the access link  the traffic intensity on the access link is reduced from 1.0 to .6  typically a traffic intensity less than .8 corresponds to a small delay  say tens of milliseconds  on a 1.5 mbps link  which is negligible compared with the 2 second internet delay given these considerations  average delay therefore is .4 *  0.010 seconds  + .6 *  2.01 seconds  which is just slightly larger than 2.1 seconds thus  this second solution provides an even lower response time then the first solution  and it does n't require the institution to upgrade its access rate the institution does  of course  have to purchase and install a web cache but this file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/http.htm  11 of 14  20/11/2004 15  51  52 the hypertext transfer protocol cost is low  many caches use public-domain software that run on inexpensive servers and pcs figure 2.2-6  adding a cache to the institutional network cooperative caching multiple web caches  located at different places in the internet  can cooperate and improve overall performance for example  an institutional cache can be configured to send its http requests to a cache in a backbone isp at the national level in this case  when the institutional cache does not have the requested object in its storage  it forwards the http request to the national cache the national cache then retrieves the object from its own storage or  if the object is not in storage  from the origin server the national cache then sends the object  within an http response message  to the institutional cache  which in turn forwards the object to the requesting browser whenever an object passes through a cache  institutional or national   the cache leaves a copy in its local storage the advantage of passing through a higher-level cache  such as a national cache  is that it has a larger user population and therefore higher hit rates an example of cooperative caching system is the nlanr caching system  which consists of a number of backbone caches in the us providing service to institutional and regional caches from all over the globe  nlanr   the nlanr caching hierarchy is shown in figure 2.2-7  huffaker 1998   the caches obtain objects from each other using a combination of http and icp  internet caching protocol   icp is an application-layer protocol that allows one cache to quickly ask another cache if it has a given document  rfc 2186  ; a cache can then use http to retrieve the object from the other cache icp is used extensively in many cooperative caching systems  and is fully supported by squid  a popular public-domain software for web caching  squid   if you are interested in learning more about icp  you are encouraged to see  luotonen 1998   ross 1998  and the icp rfc  rfc 2186   file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/http.htm  12 of 14  20/11/2004 15  51  52 the hypertext transfer protocol figure 2.2-7  the nlanr caching hierarchy  courtesy of  huffaker 1998    an alternative form of cooperative caching involves clusters of caches  often co-located on the same lan a single cache is often replaced with a cluster of caches when the single cache is not sufficient to handle the traffic or provide sufficient storage capacity although cache clustering is a natural way to scale as traffic increases  they introduce a new problem  when a browser wants to request a particular object  to which cache in the cache cluster should it send the request ? this problem can be elegantly solved using hash routing  if you are not familiar with hash functions  you can read about them in chapter 7  in the simplest form of hash routing  the browser hashes the url  and depending on the result of the hash  the browser directs its request message to one of the caches in the cluster by having all the browsers use the same hash function  an object will never be present in more than one cache in the cluster  and if the object is indeed in the cache cluster  the browser will always direct its request to the correct cache hash routing is the essence of the cache array routing protocol  carp   if you are interested in learning more about hash routing or carp  see  valloppillil 1997    luotonen 1998    ross 1998  and  ross 1997   web caching is a rich and complex subject ; over two thirds  40 pages  of the http/1.1 rfc is devoted to web caching  rfc 2068  ! web caching has also enjoyed extensive research and product development in recent years furthermore  caches are now being built to handle streaming audio and video caches will likely play an important role as the internet begins to provide an infrastructure for the large-scale  on-demand distribution of music  television shows and movies in the internet references some of the best information about http can be found in the w3c pages their overview page is an excellent starting point for a wealth of information about the http activities at the w3c you will also find material on http-next generation and web caching if you are interested in http  the w3c site will keep you busy for a long  long time file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/http.htm  13 of 14  20/11/2004 15  51  52 the hypertext transfer protocol  claffy 1998  k claffy  g miller and k thompson  " the nature of the beast  recent traffic measurements from the internet backbone  caida web site  http  //www.caida.org/papers/inet98/index.html  1998  heidemann 1997  j heidemann  k obraczka and j touch  modeling the performance of http over several transport protocols  " ieee/acm transactions on networking  vol 5  no 5  october 1997  pp 616-630  huffaker 1998  b huffaker  j jung  d wessels and k claffy  visualization of the growth and topology of the nlanr caching hierarchy  http  //squid.nlanr.net/squid/ http  //www.caida.org/tools/plankton/paper/plankton.html  1998  luotonen 1998  a luotonen  " web proxy servers  " prentice hall  new jersey  1998  netcraft  survey of web server penetration  netcraft web site  http  //www.netcraft.com/survey/  nlanr  a distributed testbed for national information provisioning  http  //ircache.nlanr.net   nielsen 1997  h f nielsen  j gettys  a baird-smith  e prud'hommeaux  h.w lie  c lilley  network performance effects of http/1.1  css1  and png  w3c document  1997  also appeared in sigcomm ' 97    rfc 1945  t berners-lee  r fielding  and h frystyk  " hypertext transfer protocol  http/1.0  "  rfc 1945   may 1996  rfc 2068  r fielding  j gettys  j mogul  h frystyk  and t berners-lee  " hypertext transfer protocol  http/1.1  "  rfc 2068   january 1997  rfc 2109  d kristol and l montulli  " http state management mechanism  "  rfc 2109   february 1997  rfc 2186  k claffy and d wessels  " internet caching protocol  icp   version 2  "  rfc 2186   september 1997  ross 1997  k.w ross  " hash-routing for collections of shared web caches  " ieee network magazine  nov-dec 1997  ross 1998  k.w ross  distribution of stored information in the web  a online tutorial  http  //www.eurecom.fr/ ~ ross/cachetutorial/ disttutorial.html  1998  squid  squid internet object cache  http  //squid.nlanr.net/squid/  valloppillil 1997  v valloppillil and k.w ross  " cache array routing protocol  " internet draft  < draft-vinod-carp-v1-03.txt >  june 1997  yeager 1996  n.j yeager and r.e mcgrath  " web server technology  " morgan kaufmann publishers  san francisco  1996 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents copyright keith w ross and james f kurose 1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/http.htm  14 of 14  20/11/2004 15  51  52 disttutorial distribution of stored information in the web part i  l the web in 2005 l overview of caching l persistent and non-persistent http l http message formats l caching fundamentals part ii  l hierarchical caching l icp  internet caching protocol l hash routing and carp l satellite distribution of web pages l survey of some caching products file  ///d | /downloads/livros/computa ? ? o/computer % 20networki % 20approach % 20featuring % 20the % 20internet/disttutorial.html20/11/2004 15  51  53 keith \ book \ applications \ smtp 2.3 file transfer  ftp ftp  file transfer protocol  is a protocol for transferring a file from one host to another host the protocol dates back to 1971  when the internet was still an experiment   but remains enormously popular ftp is described in  rfc 959   figure 2.3-1 provides an overview of the services provided by ftp figure 2.3-1  ftp moves files between local and remote file systems in a typical ftp session  the user is sitting in front of one host  the local host  and wants to transfer files to or from a remote host in order for the user to access the remote account  the user must provide a user identification and a password after providing this authorization information  the user can transfer files from the local file system to the remote file system and vice versa as shown in figure 2.3-1  the user interacts with ftp through an ftp user agent the user first provides the hostname of the remote host  which causes the ftp client process in the local host to establish a tcp connection with the ftp server process in the remote host the user then provides the user identification and password  which get sent over the tcp connection as part of ftp commands once the server has authorized the user  the user copies one or more files stored in the local file system into the remote file system  or vice versa   http and ftp are both file transfer protocols and have many common characteristics ; for example  they both run on top of tcp  the internet 's connection-oriented  transport-layer  reliable data transfer protocol however  the two application-layer protocols have some important differences the most striking difference is that ftp uses two parallel tcp connections to transfer a file  a control connection and a data connection the control connection is used for sending control information between the two hosts  information such as user identification  password  commands to change remote directory  and commands to " put " and " get " files the data connection is used to actually send a file because ftp uses a separate control connection  ftp is said to send its control information out-of-band in chapter 6 we shall see that the rtsp protocol  which is used for controlling the transfer of continuous media such as audio and video  also sends its control information out-ofband http  as you recall  sends request and response header lines into the same tcp connection that carries the transferred file itself for this reason  http is said to send its control information in-band in the next section we shall see that smtp  the main protocol for electronic mail  also sends control information in-band file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ftp.htm  1 of 4  20/11/2004 15  51  54 keith \ book \ applications \ smtp the ftp control and data connections are illustrated in figure 2.3-2 figure 2.3-2  control and data connections when a user starts an ftp session with a remote host  ftp first sets up a control tcp connection on server port number 21 the client side of ftp sends the user identification and password over this control connection the client side of ftp also sends  over the control connection  commands to change the remote directory when the user requests a file transfer  either to  or from  the remote host   ftp opens a tcp data connection on server port number 20 ftp sends exactly one file over the data connection and then closes the data connection if  during the same session  the user wants to transfer another file  ftp opens another data tcp connection thus  with ftp  the control connection remains open throughout the duration of the user session  but a new data connection is created for each file transferred within a session  i.e  the data connections are non-persistent   throughout a session  the ftp server must maintain state about the user in particular  the server must associate the control connection with a specific user account  and the server must keep track of the user 's current directory as the user wanders about the remote directory tree keeping track of this state information for each ongoing user session significantly impedes the total number of sessions that ftp can maintain simultaneously http  on the other hand  is stateless  it does not have to keep track of any user state ftp commands and replies we end this section with a brief discussion of some of the more common ftp commands the commands  from client to server  and replies  from server to client  are sent across the control tcp connection in 7-bit ascii format thus  like http commands  ftp commands are readable by people in order to delineate successive commands  a carriage return and line feed end each command  and reply   each command consists of four uppercase ascii characters  some with optional arguments some of the more common commands are given below  with options in italics   l user username  used to send the user identification to server l pass password  used to send the user password to the server l list  used to ask the server to send back a list of all the files in the current remote directory the list of files is sent over a  new and non-persistent  data tcp connection and not over the control tcp connection l retr filename  used to retrieve  i.e  get  a file from the current directory of the remote host l stor filename  used to store  i.e  put  a file into the current directory of the remote host there is typically a one-to-one correspondence between the command that the user issues and the ftp file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ftp.htm  2 of 4  20/11/2004 15  51  54 keith \ book \ applications \ smtp command sent across the control connection each command is followed by a reply  sent from server to client the replies are three-digit numbers  with an optional message following the number this is similar in structure to the status code and phrase in the status line of the http response message ; the inventors of http intentionally included this similarity in the http response messages some typical replies  along with their possible messages  are as follows  l 331 username ok  password required l 125 data connection already open ; transfer starting l 425 ca n't open data connection l 452 error writing file readers who are interested in learning about the other ftp commands and replies are encouraged to read  rfc 959   references  rfc 959  j.b postel and j.k reynolds  " file transfer protocol  "  rfc 959   october 1985 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ftp.htm  3 of 4  20/11/2004 15  51  54 keith \ book \ applications \ smtp copyright keith w ross and james f kurose 1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ftp.htm  4 of 4  20/11/2004 15  51  54 keith \ book \ applications \ smtp 2.4 electronic mail in the internet along with the web  electronic mail is one of the most popular internet applications just like ordinary " snail mail  " email is asynchronous  people send and read messages when it is convenient for them  without having to coordinate with other peoples ' schedules in contrast with snail mail  electronic mail is fast  easy to distribute  and inexpensive moreover  modern electronic mail messages can include hyperlinks  html formatted text  images  sound and even video in this section we will examine the application-layer protocols that are at the heart of internet electronic mail but before we jump into an in-depth discussion of these protocols  let 's take a bird 's eye view of the internet mail system and its key components figure 2.4-1  a bird 's eye view of the internet e-mail system figure 2.4-1 presents a high-level view of the internet mail system we see from this diagram that it has three major components  user agents  mail servers  and the simple mail transfer protocol  smtp   we now describe each of these components in the context of a sender  alice  sending an email message to a recipient  bob  user agents allow users to read  reply to  forward  save  and compose messages  user agents for electronic mail are sometimes called mail readers  although we will generally avoid this term in this book  when alice is finished composing her message  her user agent sends the message to her mail server  where the message is placed in the mail server 's outgoing message queue when bob wants to read a message  his user agent obtains the message from his mailbox in his mail server in the late 1990s  gui  graphical user interface  user agents became popular  allowing users to view and compose multimedia messages currently  eudora  microsoft 's outlook express  and netscape 's messenger are among the popular gui user agents for email there are also many text-based email user interfaces in the public domain  including mail  pine and elm file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  1 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp mail servers form the core of the e-mail infrastructure each recipient  such as bob  has a mailbox located in one of the mail servers bob 's mailbox manages and maintains the messages that have been sent to him a typical message starts its journey in the sender 's user agent  travels to the sender 's mail server  and then travels to the recipient 's mail server  where it is deposited in the recipient 's mailbox when bob wants to access the messages in his mailbox  the mail server containing the mailbox authenticates bob  with user names and passwords   alice 's mail server must also deal with failures in bob 's mail server if alice 's server can not deliver mail to bob 's server  alice 's server holds the message in a message queue and attempts to transfer the message later reattempts are often done every 30 minutes or so ; if there is no success after several days  the server removes the message and notifies the sender  alice  with an email message the simple mail transfer protocol  smtp  is the principle application-layer protocol for internet electronic mail it uses the reliable data transfer service of tcp to transfer mail from the sender 's mail server to the recipient 's mail server as with most application-layer protocols  smtp has two sides  a client side which executes on the sender 's mail server  and server side which executes on the recipient 's mail server both the client and server sides of smtp run on every mail server when a mail server sends mail  to other mail servers   it acts as an smtp client when a mail server receives mail  from other mail servers  it acts as an smtp server 2.4.1 smtp smtp  defined in  rfc 821   is at the heart of internet electronic mail as mentioned above  smtp transfers messages from senders ' mail servers to the recipients ' mail servers smtp is much older than http  the smtp rfc dates back to 1982  and smtp was around long before that  although smtp has numerous wonderful qualities  as evidenced by its ubiquity in the internet  it is nevertheless a legacy technology that possesses certain " archaic " characteristics for example  it restricts the body  not just the headers  of all mail messages to be in simple seven-bit ascii this restriction was not bothersome in the early 1980s when transmission capacity was scarce and no one was emailing large attachments or large image  audio or video files but today  in the multimedia era  the seven-bit ascii restriction is a bit of a pain  it requires binary multimedia data to be encoded to ascii before being sent over smtp ; and it requires the corresponding ascii message to be decoded back to binary after smtp transport recall from section 2.3 that http does not require multimedia data to be ascii encoded before transfer to illustrate the basic operation of smtp  let 's walk through a common scenario suppose alice wants to send bob a simple ascii message  l alice invokes her user agent for email  provides bob 's email address  e.g  bob @ someschool.edu   composes a message and instructs the user agent to send the message l alice 's user agent sends the message her mail server  where it is placed in a message queue l the client side of smtp  running on alice 's mail server  sees the message in the message queue it opens a tcp connection to a smtp server  running on bob 's mail server l after some initial smtp handshaking  the smtp client sends alice 's message into the tcp connection l at bob 's mail server host  the server side of smtp receives the message bob 's mail server then places the message in bob 's mailbox l bob invokes his user agent to read the message at his convenience the scenario is summarized in the figure 2.4-2 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  2 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp figure 2.4-2  alice 's mail server transfers alice 's message to bob 's mail server it is important to observe that smtp does not use intermediate mail servers for sending mail  even when the two mail servers are located at opposite ends of the world if alice 's server is in hong kong and bob 's server is in mobile  alabama  the tcp " connection " is a direct connection between the hong kong and mobile servers in particular  if bob 's mail server is down  the message remains in alice 's mail server and waits for a new attempt  the message does not get placed in some intermediate mail server let 's now take a closer look at how smtp transfers a message from a sending mail server to a receiving mail server we will see that the smtp protocol has many similarities with protocols that are used for face-to-face human interaction first  the client smtp  running on the sending mail server host  has tcp establish a connection on port 25 to the server smtp  running on the receiving mail server host   if the server is down  the client tries again later once this connection is established  the server and client perform some application-layer handshaking just as humans often introduce themselves before transferring information from one to another  smtp clients and servers introduce themselves before transferring information during this smtp handshaking phase  the smtp client indicates the email address of the sender  the person who generated the message  and the email address of the recipient once the smtp client and server have introduced themselves to each other  the client sends the message smtp can count on the reliable data transfer service of tcp to get the message to the server without errors the client then repeats this process over the same tcp connection if it has other messages to send to the server ; otherwise  it instructs tcp to close the connection let us take a look at an example transcript between client  c  and server  s   the host name of the client is crepes.fr and the host name of the server is hamburger.edu the ascii text prefaced with c  are exactly the lines the client sends into its tcp socket ; and the ascii text prefaced with s  are exactly the lines the server sends into its tcp socket the following transcript begins as soon as the tcp connection is established  s  220 hamburger.edu c  helo crepes.fr s  250 hello crepes.fr  pleased to meet you c  mail from  < alice @ crepes.fr > s  250 alice @ crepes.fr sender ok c  rcpt to  < bob @ hamburger.edu > s  250 bob @ hamburger.edu  recipient ok c  data s  354 enter mail  end with "  " on a line by itself c  do you like ketchup ? c  how about pickles ? c   file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  3 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp s  250 message accepted for delivery c  quit s  221 hamburger.edu closing connection in the above example  the client sends a message  " do you like ketchup ? how about pickles ? "  from mail server crepes.fr to mail server hamburger.edu the client issued five commands  helo  an abbreviation for hello   mail from  rcpt to  data  and quit these commands are self explanatory the server issues replies to each command  with each reply having a reply code and some  optional  english-language explanation we mention here that smtp uses persistent connections  if the sending mail server has several messages to send to the same receiving mail server  it can send all of the messages over the same tcp connection for each message  the client begins the process with a new helo crepes.fr and only issues quit after all messages have been sent it is highly recommended that you use telnet to carry out a direct dialogue with an smtp server to do this  issue telnet servername 25  when you do this  you are simply establishing a tcp connection between your local host and the mail server after typing this line  you should immediately receive the 220 reply from the server then issue the smtp commands helo  mail from  rcpt to  data  and quit at the appropriate times if you telnet into your friend 's smtp server  you should be able to send mail to your friend in this manner  i.e  without using your mail user agent   comparison with http let us now briefly compare smtp to http both protocols are used to transfer files from one host to another ; http transfers files  or objects  from web server to web user agent  i.e  the browser  ; smtp transfers files  i.e  email messages  from one mail server to another mail server when transferring the files  both persistent http and smtp use persistent connections  that is  they can send multiple files over the same tcp connection thus the two protocols have common characteristics however  there are important differences first  http is principally a pull protocol  someone loads information on a web server and users use http to pull the information off the server at their convenience in particular  the tcp connection is initiated by the machine that wants to receive the file on the other hand  smtp is primarily a push protocol  the sending mail server pushes the file to the receiving mail server in particular  the tcp connection is initiated by the machine that wants to send the file a second important difference  which we alluded to earlier  is that smtp requires each message  including the body of each message  to be in seven-bit ascii format furthermore  the smtp rfc requires the body of every message to end with a line consisting of only a period  i.e  in ascii jargon  the body of each message ends with " crlf.crlf "  where cr and lf stand for carriage return and line feed  respectively in this manner  while the smtp server is receiving a series of messages from an smtp client over a persistent tcp connection  the server can delineate the messages by searching for " crlf.crlf " in the byte stream  this operation of searching through a character stream is referred to as " parsing "   now suppose that the body of one of the messages is not ascii text but instead binary data  for example  a jpeg image   it is possible that this binary data might accidentally have the bit pattern associated with ascii representation of " cr lf  cr lf " in the middle of the bit stream this would cause the smtp server to incorrectly conclude that the message has terminated to get around this and related problems  binary data is first encoded to ascii in such a way that certain ascii characters  including "  "  are not used returning to our comparison with http  we note that neither non-persistent nor persistent http has to bother with the ascii conversion for non-persistent http  each tcp connection transfers exactly one object ; when the server closes the connection  the client knows it has received one entire response message for persistent http  each response message includes a content-length  header line  enabling the client to delineate the end of each message a third important difference concerns how a document consisting of text and images  along with possibly other media types  is handled as we learned in section 2.3  http encapsulates each object in its own http response message internet mail  as we shall discuss in greater detail below  places all of the message 's objects into one message 2.4.2 mail message formats and mime file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  4 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp when alice sends an ordinary snail-mail letter to bob  she puts the letter into an envelope  on which there is all kinds of peripheral information such as bob 's address  alice 's return address  and the date  supplied by the postal service   similarly  when an email message is sent from one person to another  a header containing peripheral information proceeds the body of the message itself this peripheral information is contained in a series of header lines  which are defined in  rfc 822   the header lines and the body of message are separated by a blank line  i.e  by crlf   rfc 822 specifies the exact format for mail header lines as well their semantic interpretations as with http  each header line contains readable text  consisting of a keyword followed by a colon followed by a value some of the keywords are required and others are optional every header must have a from  header line and a to  header line ; a header may include a subject  header line as well as other optional header lines it is important to note that these header lines are different from the smtp commands we studied in section 2.4.1  even though they contain some common words such as " from " and " to "   the commands in section 2.4.1 were part of the smtp handshaking protocol ; the header lines examined in this section are part of the mail message itself a typical message header looks like this  from  alice @ crepes.fr to  bob @ hamburger.edu subject  searching for the meaning of life after the message header  a blank line follows then the message body  in ascii  follows the message terminates with a line containing only a period  as discussed above it is highly recommended that you use telnet to send to a mail server a message that contains some header lines  including the subject  header line to do this  issue telnet servername 25  the actual message is sent into the tcp connection right after the smtp data command the message consists of the message headers  the blank line  and the message body the final line with a single period indicates the end of the message the mime extension for non-ascii data while the message headers described in rfc 822 are satisfactory for sending ordinary ascii text  they are not sufficiently rich enough for multimedia messages  e.g  messages with images  audio and video  or for carrying non-ascii text formats  e.g  characters used by languages other than english   to send content different from ascii text  the sending user agent must include additional headers in the message these extra headers are defined in  rfc 2045  and  rfc 2046   the mime extension to  rfc 822   two key mime headers for supporting multimedia are the content-type  header and the content-transfer-encoding  header the content-type  header allows the receiving user agent to take an appropriate action on the message for example  by indicating that the message body contains a jpeg image  the receiving user agent can direct the message body to a jpeg decompression routine to understand the need of the content-transfer encoding  header  recall that non-ascii text messages must be encoded to an ascii format that is n't going to confuse smtp the content-transfer-encoding  header alerts the receiving user agent that the message body has been ascii encoded and the type of encoding used thus  when a user agent receives a message with these two headers  it first uses the value of the content-transfer-encoding  header to convert the message body to its original non-ascii form  and then uses the content-type  header to determine what actions it should take on the message body let 's take a look at a concrete example suppose alice wants to send bob a jpeg image to do this  alice invokes her user agent for email  specifies bob 's email address  specifies the subject of the message  and inserts the jpeg image into the message body of the message  depending on the user agent alice uses  she might insert the image into the message as an " attachment "   when alice finishes composing her message  she clicks on " send "  alice 's user agent then generates a mime message  which might look something like this  from  alice @ crepes.fr to  bob @ hamburger.edu subject  picture of yummy crepe file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  5 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp mime-version  1.0 content-transfer-encoding  base64 content-type  image/jpeg base64 encoded data   ......base64 encoded data  we observe from the above mime message that alice 's user agent encoded the jpeg image using base64 encoding this is one of several encoding techniques standardized in the mime  rfc 2045  for conversion to an acceptable seven-bit ascii format another popular encoding technique is quoted-printable content-transfer-encoding  which is typically used to convert an ordinary ascii message to ascii text void of undesirable character strings  e.g  a line with a single period  when bob reads his mail with his user agent  his user agent operates on this same mime message when bob 's user agent observes the content-transfer-encoding  base64 header line  it proceeds to decode the base64-encoded message body the message also includes a content-type  image/jpeg header line ; this indicates to bob 's user agent that the message body  after base64 decoding  should be jpeg decompressed finally  the message includes the mime-version  header  which  of course  indicates the mime version that is being used note that the message otherwise follows the standard rfc 822/smtp format in particular  after the message header there is a blank line and then the message body ; and after the message body  there is a line with a single period let 's now take a closer look at the content-type  header according to the mime specification   rfc 2046   this header has the following format  content-type  type/subtype ; parameters where the " parameters "  along with the semi-colon  is optional paraphrasing  rfc 2046   the content-type field is used to specify the nature of the data in the body of a mime entity  by giving media type and subtype names after the type and subtype names  the remainder of the header field is a set of parameters in general  the top-level type is used to declare the general type of data  while the subtype specifies a specific format for that type of data the parameters are modifiers of the subtype  and as such do not fundamentally affect the nature of the content the set of meaningful parameters depends on the type and subtype most parameters are associated with a single specific subtype mime has been carefully designed to be extensible  and it is expected that the set of media type/subtype pairs and their associated parameters will grow significantly over time in order to ensure that the set of such types/subtypes is developed in an orderly  well-specified  and public manner  mime sets up a registration process which uses the internet assigned numbers authority  iana  as a central registry for mime 's various areas of extensibility the registration process for these areas is described in  rfc 2048   currently there are seven top-level types defined for each type  there is a list of associated subtypes  and the lists of subtypes are growing every year we describe five of these types below  l text  the text type is used to indicate to the receiving user agent that the message body contains textual information one extremely common type/subtype pair is text/plain the subtype plain indicates plain text containing no formatting commands or directives plain text is to be displayed as is ; no special software is required to get the full meaning of the text  aside from support for the indicated character set if you take a glance at the mime headers in some of the messages in your mailbox  you will almost certainly see content type header lines with text/plain ; charset = us-ascii or text/plain ; charset = " iso-8859-1 "  the parameters indicate the character set used to generate the message another type/subtype pair that is gaining popularity is text/html the html subtype indicates to the mail reader that it should interpret the embedded html tags that are included in the message this file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  6 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp allows the receiving user agent to display the message as a web page  which might include a variety of fonts  hyperlinks  applets  etc l image  the image type is used to indicate to the receiving user agent that the message body is an image two popular type/subtype pairs are image/gif and image/jpeg when the receiving user agent encounters image/gif  it knows that it should decode the gif image and then display it l audio  the audio type requires an audio output device  such as a speaker or a telephone  to render the contents some of the standardized subtypes include basic  basic 8-bit mu-law encoded  and 32kadpcm  a 32 kbps format defined in  rfc 1911    l video  the video type includes mpeg  and quicktime for subtypes l application  the application type is for data that does not fit in any of the other categories it is often used for data that must be processed by an application before it is viewable or usable by a user for example  when a user attaches a microsoft word document to an email message  the sending user agent typically uses application/msword for the type/ subtype pair when the receiving user agent observes the content type application/msword  it launches the microsoft word application and passes the body of the mime message to the application a particularly important subtype for the application type is octet-stream  which is used to indicate that the body contains arbitrary binary data upon receiving this type  a mail reader will prompt the user  providing the option to save to the message to disk for later processing there is one mime type that is particularly important and requires special discussion  namely  the multipart type just as a web page can contain many objects  text  images  applets  etc   so can an email message recall that the web sends each of the objects within independent http response messages internet email  on the other hand  places all the objects  or " parts "  in the same message in particular  when a multimedia message contains more than one object  such as multiple images or some ascii text and some images  the message typically has content-type  multipart/mixed this content type header line indicates to the receiving user agent that the message contains multiple objects with all the objects in the same message  the receiving user agent needs a means to determine  i  where each object begins and ends   ii  how each non-ascii object was transfer encoded  and  iii  the content type of each message this is done by placing boundary characters between each object and preceding each object in the message with content-type  and content-transfer-encoding  header lines to obtain a better understanding of multipart/mixed  let 's look at an example suppose that alice wants to send a message to bob consisting of some ascii text  followed by a jpeg image  followed by more ascii text using her user agent  alice types some text  attaches a jpeg image  and then types some more text her user agent then generates a message something like this  from  alice @ crepes.fr to  bob @ hamburger.edu subject  picture of yummy crepe with commentary mime-version  1.0 content-type  multipart/mixed ; boundary = startofnextpart --startofnextpart dear bob  please find a picture of an absolutely scrumptious crepe --startofnextpart content-transfer-encoding  base64 content-type  image/jpeg base64 encoded data   ......base64 encoded data file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  7 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp --startofnextpart let me know if you would like the recipe  examining the above message  we note that the content-type  line in the header indicates how the various parts in the message are separated the separation always begins with two dashes and ends with crlf as mentioned earlier  the list of registered mime types grows every year the rfc  2048  describes the registration procedures which use the internet assigned numbers authority  iana  as a central registry for such values a list of the current mime subtypes is maintained at numerous sites the reader is also encouraged to glance at yahoo 's mime category page the received message as we have discussed  an email message consists of many components the core of the message is the message body  which is the actually data being sent from sender to receiver for a multipart message  the message body itself consists of many parts  with each part preceded with one or more lines of peripheral information preceding the message body is a blank line and then a number of header lines these header lines include rfc 822 header lines such as from   to  and subject  header lines the header lines also include mime header lines such as content-type  and content-transferencoding  header lines but we would be remiss if we did n't mention another class of header lines that are inserted by the smtp receiving server indeed  the receiving server  upon receiving a message with rfc 822 and mime header lines  appends a received  header line to the top of the message ; this header line specifies the name of the smtp server that sent the message  " from "   the name of the smtp server that received the message  " by "  and the time at which the receiving server received the message thus the message seen by the destination user takes the following form  received  from crepes.fr by hamburger.edu ; 12 oct 98 15  27  39 gmt from  alice @ crepes.fr to  bob @ hamburger.edu subject  picture of yummy crepe mime-version  1.0 content-transfer-encoding  base64 content-type  image/jpeg base64 encoded data   .......base64 encoded data almost everyone who has used electronic mail has seen the received  header line  along with the other header lines  preceding email messages  this line is often directly seen on the screen or when the message is sent to a printer  you may have noticed that a single message sometimes has multiple received  header lines and a more complex return-path  header line this is because a message may be received by more than one smtp server in the path between sender and recipient for example  if bob has instructed his email server hamburger.edu to forward all his messages to sushi.jp  then the message read by bob 's user agent would begin with something like  received  from hamburger.edu by sushi.jp ; 12 oct 98 15  30  01 gmt received  from crepes.fr by hamburger.edu ; 12 oct 98 15  27  39 gmt these header lines provide the receiving user agent a trace of the smtp servers visited as well as timestamps of when the visits occurred you can learn more about the syntax of these header lines in the smtp rfc  which is one of the more readable of file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  8 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp the many rfcs 2.4.3 mail access protocols once smtp delivers the message from alice 's mail server to bob 's mail server  the message is placed in bob 's mailbox throughout this discussion we have tacitly assumed that bob reads his mail by logging onto the server host  most likely through telnet  and then executes a mail reader  e.g  mail  elm  etc  on that host up until the early 1990s this was the standard way of doing things but today a typical user reads mail with a user agent that executes on his or her local pc  or mac   whether that pc be an office pc  a home pc  or a portable pc by executing the user agent on a local pc  users enjoy a rich set of features  including the ability to view multimedia messages and attachments popular mail user agents that run on local pcs include eudora  microsoft 's outlook express  and netscape 's messenger given that bob  the recipient  executes his user agent on the his local pc  it is natural to consider placing a mail server on the his local pc as well there is a problem with this approach  however recall that a mail server manages mailboxes and runs the client and server sides of smtp if bob 's mail server were to reside on his local pc  then bob 's pc would have to remain constantly on  and connected to the internet  in order to receive new mail  which can arrive at any time this is impractical for the great majority of internet users instead  a typical user runs a user agent on the local pc but accesses a mailbox from a shared mail server  a mail server that is always running  that is always connected to the internet  and that is shared with other users the mail server is typically maintained by the user 's isp  which could be a residential or an institutional  university  company  etc  isp with user agents running on users ' local pcs and mail servers hosted by isps  a protocol is needed to allow the user agent and the mail server to communicate let us first consider how a message that originates at alice 's local pc makes its way to bob 's smtp mail server this task could simply be done by having alice 's user agent communicate directly with bob 's mail server in the language of smtp  alice 's user agent would initiate a tcp connection to bob 's mail server  issue the smtp handshaking commands  upload the message with the data command  and then close the connection this approach  although perfectly feasible  is not commonly employed  primarily because it does n't offer the alice any recourse to a crashed destination mail server instead  alice 's user agent initiates a smtp dialogue with her own mail server  rather than with the recipient 's mail server  and uploads the message alice 's mail server then establishes a new smtp session with bob 's mail server and relays the message to bob 's mail server if bob 's mail server is down  then alice 's mail server holds the message and tries again later the smtp rfc defines how the smtp commands can be used to relay a message across multiple smtp servers but there is still one missing piece to the puzzle ! how does a recipient like bob  running a user agent on his local pc  obtain his messages  which are sitting on a mail server within bob 's isp ? the puzzle is completed by introducing a special access protocol that transfers the messages from bob 's mail server to the local pc there are currently two popular mail access protocols  pop3  post office protocol  version 3  and imap  internet mail access protocol   we shall discuss both of these protocols below note that bob 's user agent ca n't use smtp to obtain the messages  obtaining the messages is a pull operation whereas smtp is a push protocol figure 2.4-3 provides a summary of the protocols that are used for internet mail  smtp is used to transfer mail from the sender 's mail server to the recipient 's mail server ; smtp is also used to transfer mail from the sender 's user agent to the sender 's mail server pop3 or imap are used to transfer mail from the recipient 's mail server to the recipient 's user agent file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  9 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp figure 2.4-3  e-mail protocols and their communicating entities pop3 pop3  defined in  rfc 1939   is an extremely simple mail access protocol because the protocol is so simple  its functionality is rather limited pop3 begins when the user agent  the client  opens a tcp connection to the the mail server  the server  on port 110 with the tcp connection established  pop3 progresses through three phases  authorization  transaction and update during the first phase  authorization  the user agent sends a user name and a password to authenticate the user downloading the mail during the second phase  transaction  the user agent retrieves messages during the transaction phase  the user agent can also mark messages for deletion  remove deletion marks  and obtain mail statistics the third phase  update  occurs after the client has issued the quit command ending the pop3 session ; at this time  the mail server deletes the messages that were marked for deletion in a pop3 transaction  the user agent issues commands  and the server responds to each command with a reply there are two possible responses  + ok  sometimes followed by server-to-client data   whereby the server is saying that the previous command was fine ; and -err  whereby the server is saying that something was wrong with the previous command the authorization phase has two principle commands  user < user name > and pass < password >  to illustrate these two commands  we suggest that you telnet directly into a pop3 server  using port 110  and issue these commands suppose that mailserver is the name of your mail server you will see something like  telnet mailserver 110 + ok pop3 server ready user alice + ok pass hungry + ok user successfully logged on if you misspell a command  the pop3 server will reply with an -err message now let 's take a look at the transaction phase a user agent using pop3 can often be configured  by the user  to " download and delete " or to " download and keep "  the sequence of commands issued by a pop3 user agent depend on which of these two modes the user agent is operating in in the download-and-delete mode  the user agent will issue the list  retr and dele commands as an example  suppose the user has two messages in his or her mailbox in the dialogue below c   standing for client  is the user agent and s   standing for server  is the mail server the transaction will look something like  c  list s  1 498 s  2 912 s   file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  10 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp c  retr 1 s  blah blah  s   s  ..........blah s   c  dele 1 c  retr 2 s  blah blah  s   s  ..........blah s   c  dele 2 c  quit s  + ok pop3 server signing off the user agent first asks the mail server to list the size of each of the stored messages the user agent then retrieves and deletes each message from the server note that after the authorization phase  the user agent employed only four commands  list  retr  dele  and quit the syntax for these commands is defined in rfc 1939   after issuing the quit command  the pop3 server enters the update phase and removes messages 1 and 2 from the mailbox a problem with this download-and-delete mode is that the recipient  bob  may be nomadic and want to access his mail from multiple machines  including the office pc  the home pc and a portable computer the download-and-delete mode scatters bob 's mail over all the local machines ; in particular  if bob first reads a message on a home pc  he will not be able to reread the message on his portable later in the evening in the download-and-keep mode  the user agent leaves the messages on the mail server after downloading them in this case  bob can reread messages from different machines ; he can access a message from work  and then access it again later in the week from home during a pop3 session between a user agent the mail server  the pop3 server maintains some state information ; in particular  it keeps track of which messages have been marked deleted however  the pop3 server is not required to carry state information across pop3 sessions for example  no message is marked for deletion at the beginning of each session this lack of state information across sessions greatly simplifies the implementation of a pop3 server imap once bob has downloaded his messages to the local machine using pop3  he can create mail folders and move the downloaded messages into the folders bob can then delete messages  move messages across folders  and search for messages  say by sender name or subject   but this paradigm  folders and messages in the local machine  poses a problem for the nomadic user  who would prefer to maintain a folder hierarchy on a remote server that can be accessed by from any computer this is not possible with pop3 to solve this and other problems  the internet mail access protocol  imap   defined in  rfc 1730   was invented like pop3  imap is a mail access protocol it has many more features than pop3  but it is also significantly more complex  and thus the client and server side implementations are significantly more complex  imap is designed to allow users to manipulate remote mailboxes as if they were local in particular  imap enables bob to create and maintain multiple message folders at the mail server bob can put messages in folders and move messages from one folder to another imap also provides commands that allow bob to search remote folders for messages matching specific criteria one reason why an imap implementation is much more complicated than a pop3 implementation is that the imap server must maintain a folder hierarchy for each of its users this state information persists across a particular user 's successive accesses to the imap server recall that a pop3 server  by contrast  does not maintain anything about a particular user once the user quits the pop3 session another important feature of imap is that it has commands that permit a user agent to obtain components of messages for file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  11 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp example  a user agent can obtain just the message header of a message or just one part of a multipart mime message this feature is useful when there is a low-bandwidth connection between the user agent and its mail server  for example  a wireless or slow-speed modem connection with a low-bandwidth connection  the user may not want to download all the messages in its mailbox  particularly avoiding long messages that might contain  for example  an audio or video clip an imap session consists of the establishment of a connection between the client  i.e  the user agent  and the imap server  an initial greeting from the server  and client-server interactions the client/server interactions are similar to  but richer than  those of pop3 they consist of a client command  server data  and a server completion result response the imap server is always in one of four states in the non-authenticated state  which starts when the connection starts  the user must supply a user name and password before most commands will be permitted in the authenticated state  the user must select a folder before sending commands that affect messages in the selected state  the user can issue commands that affect messages  retrieve  move  delete  retrieve a part in a multipart message  etc   finally  the logout state is when the session is being terminated the imap commands are organized by the state in which the command is permitted you can read all about imap at the official imap site http more and more users today are using browser-based email services such as hotmail or yahoo ! mail with these servers  the user agent is an ordinary web browser and the user communicates with its mailbox on its mailserver via http when a recipient  such as bob  wants to access the messages in his mailbox  the messages are sent from bob 's mail server to bob 's browser using the http protocol rather than the pop3 or imap protocol when a sender with an account on an http-based email server  such as alice  wants to send a message  the message is sent from her browser to her mail server over http rather than over smtp the mail server  however  still sends messages to  and receives messages from  other mail servers using smtp this solution to mail access is enormously convenient for the user on the go the user need only to be able to access a browser in order to send and receive messages the browser can be in an internet cafe  in a friend 's house  in a hotel room with a web tv  etc as with imap  users can organize their messages in a hierarchy of folders on the remote server in fact  webbased email is so convenient that it may replace pop3 and imap access in the upcoming years its principle disadvantage is that it can be slow  as the server is typically far from the client and interaction with the server is done through cgi scripts 2.4.4 continuous media email continuous-media  cm  email is email that includes audio or video cm email is appealing for asynchronous communication among friends and family for example  a young child who can not type would prefer sending an audio message to his or her grandparents furthermore  cm email can be desirable in many corporate contexts  as an office worker may be able to record a cm message more quickly than typing a text message  english can be spoken at a rate of 180 words per minute  whereas the average office worker types words at a much slower rate  continuous-media e-mail resembles in some respects ordinary voicemail messaging in the telephone system however  continuous-media e-mail is much more powerful not only does it provide the user with a graphical interface to the user 's mailbox  but it also allows the user to annotate and reply to cm messages and to forward cm messages to a large number of recipients cm e-mail differs from traditional text mail in many ways these differences include much larger messages  more stringent end-to-end delay requirements  and greater sensitivity to recipients with highly heterogeneous internet access rates and local storage capabilities unfortunately  the current e-mail infrastructure has several inadequacies that obstruct the widespread adoption of cm e-mail first  many existing mail servers do not have the capacity to store large cm objects ; recipient mail servers typically reject such messages  which makes sending cm messages to such recipients impossible second  the existing mail paradigm of transporting entire messages to the recipient 's mail server before recipient rendering can lead to excessive waste of bandwidth and storage indeed  stored cm is often not rendered in its entirety  padhye 1999   so that bandwidth and recipient storage is wasted by receiving data that is never rendered  for example  one can imagine listening to the first fifteen seconds of a long audio email from a rather long-winded colleague  and then deciding to delete the remaining 20 minutes of the message without listening to it  third  current mail access protocols  pop3  imap and http  are inappropriate for streaming cm to recipients  streaming cm is discussed in detail in chapter 6  in particular  the current mail access protocols do not file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  12 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp provide functionality that allows a user to pause/resume a message or to reposition within a message ; furthermore  streaming over tcp is often leads to poor reception  see chapter 6   these inadequacies will hopefully be addressed in the upcoming years possible solutions are discussed in  gay 1997   hess 1998   shurman 1996  and  turner 1999   references in addition to the references below  a readable but detailed  overview of modern electronic mail is given in  hughes 1998    gay 1997  v gay and b dervella  " mhegam  a multimedia messaging system  " ieee multimedia magazine  oct-dec 1997  pp 22-29  hess 1998  c hess  d lin and k nahrstedt  " vistamail  an integrated multimedia mailing system  " ieee multimedia magazine  oct.-dec  1988  pp 13-23  hughes 1998  l hughes  internet e-mail  protocols  standards and implementation  artech house  norwood  ma  1998  padhye 1999  j padhye and j kurose  " an empirical study of client interactions with a continuous-media courseware server  " ieee internet computing  april 1999  rfc 821  j.b postel  " simple mail transfer protocol  "  rfc 821   august 1982  rfc 822  d.h crocker  " standard for the format of arpa internet text messages  "  rfc 822   august 1982  rfc 977  b kantor and p lapsley  " network news transfer protocol  "  rfc 977   february 1986  rfc 1730  m crispin  " internet message access protocol  version 4  "  rfc 1730   december 1994  rfc 1911  g vaudreuil  " voice profil for internet mail  "  rfc 1911   february 1996  rfc 1939  j myers and m rose  " post office protocol  version 3  "  rfc 1939   may 1996  rfc 2045  n borenstein and n freed  " multipurpose internet mail extensions  mime  part one  format of internet message bodies  "  rfc 2045   november 1996  rfc 2046  n borenstein and n freed  " multipurpose internet mail extensions  mime  part two  media types  "  rfc 2046   november 1996  rfc 2048  n freed  j klensin and j postel " multipurpose internet mail extensions  mime  part four  registration procedures  "  rfc 2048   november 1996  schurmann 1996  g schurmann  " multimedia mail  " multimedia systems  acm press  oct 1996  pp 281-295  turner 1999  d.a turner and k.w ross  " continuous-media internet e-mail  infrastructure inadequacies and solutions  http  //www.eurecom.fr/ ~ ross/mmnetlab.htm search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  13 of 14  20/11/2004 15  51  55 keith \ book \ applications \ smtp return to table of contents copyright keith w ross and james f kurose 1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/smtp.htm  14 of 14  20/11/2004 15  51  55 the domain name system 2.5 dns  the internet 's directory service we human beings can be identified in many ways for example  we can be identified by the names that appear on our birth certificates we can be identified by our social security numbers we can be identified by our driver 's license numbers although each of these identifiers can be used to identify people  within a given context  one identifier may be more appropriate than an other for example  the computers at the irs  the infamous tax collecting agency in the us  prefer to use fixed-length social security numbers rather than birth-certificate names on the other hand  ordinary people prefer the more mnemonic birth-certificate names rather than social security numbers  indeed  can you imagine saying  " hi my name is 132 67-9875 please meet my husband  178-87-1146 "  just as humans can be identified in many ways  so too can internet hosts one identifier for a host is its hostname hostnames  such as cnn.com  www.yahoo.com  gaia.cs.umass.edu and surf.eurecom.fr  are mnemonic and are therefore appreciated by humans however  hostnames provide little  if any  information about the location within the internet of the host  a hostname such as surf.eurecom.fr  which ends with the country code .fr  tells us that the host is in france  but does n't say much more  furthermore  because hostnames can consist of variable-length alpha-numeric characters  they would be difficult to process by routers for these reasons  hosts are also identified by so-called ip addresses we will discuss ip addresses in some detail in chapter 4  but it is useful to say a few brief words about them now an ip address consists of four bytes and has a rigid hierarchical structure an ip address looks like 121.7.106.83  where each period separates one of the bytes expressed in decimal notation from 0 to 127 an ip address is hierarchical because as we scan the address from left to right  we obtain more and more specific information about where  i.e  within which network  in the network of networks  the host is located in the internet  just as when we scan a postal address from bottom to top we obtain more and more specific information about where the residence is located   an ip address is included in the header of each ip datagram  and internet routers use this ip address to route s datagram towards its destination 2.5.1 services provided by dns we have just seen that there are two ways to identify a host  a hostname and an ip address people prefer the more mnemonic hostname identifier  while routers prefer fixed-length  hierarchically-structured ip addresses in order to reconcile these different preferences  we need a directory service that translates hostnames to ip addresses this is the main task of the the internet 's domain name system  dns   the dns is  i  a distributed database implemented in a hierarchy of name servers and  ii  an application-layer protocol that allows hosts and name servers to communicate in order to provide the translation service name servers are usually unix machines running the berkeley internet name domain  bind  software the dns protocol runs over udp and uses port 53 following this chapter we provide interactive links to dns programs that allow you to translate arbitrary hostnames  among other things dns is commonly employed by other application-layer protocols  including http  smtp and ftp  to translate usersupplied host names to ip addresses as an example  consider what happens when a browser  i.e  an http client   running on some user 's machine  requests the url www.someschool.edu/index.html in order for the user 's machine to be able to send an http request message to the web server www.someschool.edu  the user 's machine must obtain the ip address of www someschool.edu this is done as follows the same user machine runs the client-side of the dns application the browser extracts the hostname  www.someschool.edu  from the url and passes the hostname to the client-side of the dns application as part of a dns query message  the dns client sends a query containing the hostname to a dns server the dns client eventually receives a reply  which includes the ip address for the hostname the browser then opens a tcp connection to the http server process located at that ip address all ip datagrams sent to from the client to server as part of this connection will include this ip address in the destination address field of the datagrams in particular  the ip datagram  s  that encapsulate the http request message use this ip address we see from this example that dns adds an additional delay  sometimes substantial  to the internet applications that use dns fortunately  as we shall discuss below  the desired ip address is often cached in a " near by " dns name server  which helps to reduce the dns network traffic as well as the average dns delay file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  1 of 10  20/11/2004 15  51  57 the domain name system like http  ftp  and smtp  the dns protocol is an application-layer protocol since  i  it runs between communicating end systems  again using the client-server paradigm   and  ii  it relies on an underlying end-to-end transport protocol  i.e  udp  to transfer dns messages between communicating end systems in another sense  however  the role of the dns is quite different from web  file transfer  and email applications unlike these applications  the dns is not an application with which a user directly interacts instead  the dns provides a core internet function  namely  translating hostnames to their underlying ip addresses  for user applications and other software in the internet we noted earlier in section 1.2 that much of the " complexity " in the internet architecture is located at the " edges " of the network the dns  which implements the critical name-to-address translation process using clients and servers located at the edge of the network  is yet another example of that design philosophy dns provides a few other important services in addition to translating hostnames to ip addresses  l host aliasing  a host with a complicated hostname can have one or more alias names for example  a hostname such as relay1.west-coast.enterprise.com could have  say  two aliases such as enterprise.com and www.enterprise.com in this case  the hostname relay1.west-coast.enterprise.com is said to be canonical hostname alias hostnames  when present  are typically more mnemonic than a canonical hostname dns can be invoked by an application to obtain the canonical hostname for a supplied alias hostname as well as the ip address of the host l mail server aliasing  for obvious reasons  it is highly desirable that email addresses be mnemonic for example  if bob has an account with hotmail  bob 's email address might be as simple as bob @ hotmail.com however  the hostname of the hotmail mail server is more complicated and much less mnemonic than simply hotmail.com  e.g  the canonical hostname might be something like relay1.west-coast.hotmail.com   dns can be invoked by a mail application to obtain the canonical hostname for a supplied alias hostname as well as the ip address of the host in fact  dns permits a company 's mail server and web server to have identical  aliased  hostnames ; for example  a company 's web server and mail server can both be called enterprise.com l load distribution  increasingly  dns is also being used to perform load distribution among replicated servers  such as replicated web servers busy sites  such as cnn.com  are replicated over multiple servers  with each server running on a different end system  and having a different ip address for replicated web servers  a set of ip addresses is thus associated with one canonical hostname the dns database contains this set of ip addresses when clients make a dns query for a name mapped to a set of addresses  the server responds with the entire set of ip addresses  but rotates the ordering of the addresses within each reply because a client typically sends its http request message to the ip address that is listed first in the set  dns rotation distributes the traffic among all the replicated servers dns rotation is also used for email so that multiple mail servers can have the same alias name the dns is specified in  rfc 1034  and  rfc 1035   and updated in several additional rfcs it is a complex system  and we only touch upon key aspects of its operation here the interested reader is referred to these rfcs and the book  abitz 1993   2.5.2 overview of how dns works we now present a high-level overview of how dns works our discussion shall focus on the hostname to ip address translation service from the client 's perspective  the dns is a black box the client sends a dns query message into the black box  specifying the hostname that needs to be translated to an ip address on many unix-based machines  gethostbyname   is the library routine that an application calls in order to issue the query message in section 2.7  we shall present a java program that begins by issuing a dns query after a delay  ranging from milliseconds to tens of seconds  the client receives a dns reply message that provides the desired mapping thus  from the client 's perspective  dns is a simple  straightforward translation service but in fact  the black box that implements the service is complex  consisting of large number of name servers distributed around the globe  as well as an application-layer protocol that specifies how the name servers and querying hosts communicate file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  2 of 10  20/11/2004 15  51  57 the domain name system a simple design for dns would have one internet name server that contains all the mappings in this centralized design  clients simply direct all queries to the single name server  and the name server responds directly to the querying clients although the simplicity of this design is attractive  it is completely inappropriate for today 's internet  with its vast  and growing  number of hosts the problems with a centralized design include  l a single point of failure if the name server crashes  so too does the entire internet ! l traffic volumes a single name server would have to handle all dns queries  for all the http requests  email messages  etc generated from millions of hosts  l distant centralized database a single name server can not be " close " to all the querying clients if we put the single name server in new york city  then all queries from australia must travel to the other side of the globe  perhaps over slow and congested links this can lead to significant delays  thereby increasing the " world wide wait " for the web and other applications   l maintenance the single name server would have to keep records for all internet hosts not only would this centralized database be huge  but it would have to be updated frequently to account for every new host there are also authentication and authorization problems associated with allowing any user to register a host with the centralized database in summary  a centralized database in a single name server simply does n't scale consequently  the dns is distributed by design in fact  the dns is a wonderful example of how a distributed database can be implemented in the internet in order to deal with the issue of scale  the dns uses a large number of name servers  organized in a hierarchical fashion and distributed around the world no one name server has all of the mappings for all of the hosts in the internet instead  the mappings are distributed across the name servers to a first approximation  there are three types of name servers  local name servers  root name servers  and authoritative name servers these name servers  again to a first approximation  interact with each other and with the querying host as follows  l local name servers  each isp  such as a university  an academic department  an employee 's company or a residential isp  has a local name server  also called a default name server   when a host issues a dns query message  the message is first sent to the host 's local name server the ip address of the local name server is typically configured by hand in a host  on a windows 95/98 machine  you can find the ip address of the local name server used by your pc by opening the control panel  and then selecting " network "  then selecting an installed tcp/ip component  and then selecting the dns configuration folder tab  the local name server is typically " close " to the client ; in the case of an institutional isp  it may be on the same lan as the client host ; for a residential isp  the name server is typically separated from the client host by no more than a few routers if a host requests a translation for another host that is part of the same local isp  then the local name server will be able to immediately provide the the requested ip address for example  when the host surf.eurecom.fr requests the ip address for baie.eurecom.fr  the local name server at eurecom will be able to provide the requested ip address without contacting any other name servers l root name servers  in the internet there are a dozen or so of " root name servers  " most of which are currently located in north america a february 1998 map of the root servers is shown in figure 2.5-1 when a local name server can not immediately satisfy a query from a host  because it does not have a record for the hostname being requested   the local name server behaves as a dns client and queries one of the root name servers if the root name server has a record for the hostname  it sends a dns reply message to the local name server  and the local name server then sends a dns reply to the querying host but the root name server may not have a record for the hostname instead  the rootname server knows the ip address of an " authoritative name server " that has the mapping for that particular hostname l authoritative name servers  every host is registered with an authoritative name server typically  the authoritative name server for a host is a name server in the host 's local isp  actually  each host is required to have at least two authoritative name servers  in case of failures  by definition  a name server is authoritative for a host if it always has a dns record that translates the host 's hostname to that host 's ip address when an authoritative name server is queried by a root server  the authoritative name server responds with a dns reply that contains the requested mapping the root server then forwards the mapping to the local name server  which in turn forwards the mapping to the requesting file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  3 of 10  20/11/2004 15  51  57 the domain name system host many name servers act as both local and and authoritative name servers figure 2.5-1  a february 1998 map of the dns root servers obtained from the wia alliance web site  http  //www.wia.org   let 's take a look at a simple example suppose the host surf.eurecom.fr desires the ip address of gaia.cs.umass.edu also suppose that eurecom 's local name server is called dns.eurecom.fr and that an authoritative name server for gaia.cs.umass.edu is called dns.umass.edu as shown in figure 2.5-2  the host surf.eurecom.fr first sends a dns query message to its local name server  dns.eurecom.fr the query message contains the hostname to be translated  namely  gaia.cs.umass.edu the local name server forwards the query message to a root name server the root name server forwards the query message to the name server that is authoritative for all the hosts in the domain umass.edu  namely  to dns.umass.edu the authoritative name server then sends the desired mapping to the querying host  via the root name server and the local name server note that in this example  in order to obtain the mapping for one hostname  six dns messages were sent  three query messages and three reply messages file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  4 of 10  20/11/2004 15  51  57 the domain name system figure 2.5-2  recursive queries to obtain the mapping for gaia.cs.umass.edu our discussion up to this point has assumed that the root name server knows the ip address of an authoritative name server for every hostname this assumption may be incorrect for a given hostname  the root name server may only know the ip address of an intermediate name server that in turn knows the ip address of an authoritative name server for the hostname to illustrate this  consider once again the above example with the host surf.eurecom.fr querying for the ip address of gaia.cs umass.edu suppose now that the university of massachusetts has a name server for the university  called dns.umass.edu also suppose that each of the departments at university of massachusetts has its own name server  and that each departmental name server is authoritative for all the hosts in the department as shown in figure 2.5-3  when the root name server receives a query for a host with hostname ending with umass.edu it forwards the query to the name server dns.umass.edu this name server forwards all queries with hostnames ending with .cs.umass.edu to the name server dns.cs.umass.edu  which is authoritative for all hostnames ending with .cs.umass.edu the authoritative name server sends the desired mapping to the intermediate name server  dns.umass.edu  which forwards the mapping to the root name server  which forwards the mapping to the local name server  dns.eurecom.fr  which forwards the mapping to the requesting host ! in this example  eight dns messages are sent actually  even more dns messages can be sent in order to translate a single hostname  there can be two or more intermediate name servers in the chain between the root name server and the authoritative name server ! file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  5 of 10  20/11/2004 15  51  57 the domain name system figure 2.5-3  recursive queries with an intermediate name server between the root and authoritative name servers the examples up to this point assumed that all queries are recursive queries when a host or name server a makes a recursive query to a name server b  then name server b obtains the requested mapping on behalf of a and then forwards the mapping to a the dns protocol also allows for iterative queries at any step in the chain between requesting host and authoritative name server when a name server a makes an iterative query to name server b  if name server b does not have the requested mapping  it immediately sends a dns reply to a that contains the ip address of the next name server in the chain  say  name server c name server a then sends a query directly to name server c in the sequence of queries that are are required to translate a hostname  some of the queries can be iterative and others recursive such a combination of recursive and iterative queries is illustrated in figure 2.5-4 typically  all queries in the query chain are recursive except for the query from the local name server to the root name server  which is iterative  because root servers handle huge volumes of queries  it is preferable to use the less burdensome iterative queries for root servers  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  6 of 10  20/11/2004 15  51  57 the domain name system figure 2.5-4  a query chain with recursive and iterative queries our discussion this far has not touched on one important feature of the dns  dns caching in reality  dns extensively exploits caching in order to improve the delay performance and to reduce the number of dns messages in the network the idea is very simple when a name server receives a dns mapping for some hostname  it caches the mapping in local memory  disk or ram  while passing the message along the name server chain given a cached hostname/ ipaddress translation pair  if another query arrives to the name server for the same hostname  the name server can provide the desired ip address  even if it is not authoritative for the hostname in order to deal with the ephemeral hosts  a cached record is discarded after a period of time  often set to two days   as an example  suppose that surf.eurecom.fr queries the dns for the ip address for the hostname cnn.com furthermore suppose that a few hours later  another eurecom host  say baie.eurecom.fr  also queries dns with the same hostname because of caching  the local name server at eurecom will be able to immediately return the ip address to the requesting host without having to query name servers on another continent any name server may cache dns mappings 2.5.3 dns records the name servers that together implement the dns distributed database  store resource records  rr  for the hostname to ip address mappings each dns reply message carries one or more resource records in this and the following subsection  we provide a brief overview of dns resource records and messages ; more details can be found in  abitz  or in the dns rfcs  rfc 1034   rfc 1035   a resource record is a four-tuple that contains the following fields  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  7 of 10  20/11/2004 15  51  57 the domain name system  name  value  type  ttl  ttl is the time to live of the resource record ; it determines the time at which a resource should be removed from a cache in the example records given below  we will ignore the ttl field the meaning of name and value depend on type  l if type = a  then name is a hostname and value is the ip address for the hostname thus  a type a record provides the standard hostname to ip address mapping as an example   relay1.bar.foo.com  145.37.93.126  a  is a type a record l if type = ns  then name is a domain  such as foo.com  and value is the hostname of a server that knows how to obtain the ip addresses for hosts in the domain this record is used to route dns queries further along in the query chain as an example   foo.com  dns.foo.com  ns  is a type ns record l if type = cname  then value is a canonical hostname for the alias hostname name this record can provide querying hosts the canonical name for a hostname as an example   foo.com  relay1.bar.foo.com  cname  is a cname record l if type = mx  then value is a hostname of a mail server that has an alias hostname name as an example   foo com mail.bar.foo.com  mx  is an mx record mx records allow the hostnames of mail servers to have simple aliases if a name server is authoritative for a particular hostname  then the name server will contain a type a record for the hostname  even if the name server is not authoritative  it may contain a type a record in its cache  if a server is not authoritative for a hostname  then the server will contain a type ns record for the domain that includes the hostname ; it will also contain a type a record that provides the ip address of the name server in the value field of the ns record as an example  suppose a root server is not authoritative for the host gaia.cs.umass.edu then the root server will contain a record for a domain that includes the host cs.umass.edu  e.g   umass.edu  dns.umass.edu  ns   the root server would also contain a type a record which maps the name server dns.umass.edu to an ip address  e.g   dns.umass.edu  128.119.40.111  a   2.5.4 dns messages earlier in this section we alluded to dns query and reply messages these are the only two kinds of dns messages furthermore  both request and reply messages have the same format  as shown in figure 2.5-5 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  8 of 10  20/11/2004 15  51  57 the domain name system figure 2.5-5  dns message format the semantics of the various fields in a dns message are as follows  l the first 12 bytes is the header section  which has a number of fields the first field is a 16-bit number that identifies the query this identifier is copied into the reply message to a query  allowing the client to match received replies with sent queries there are a number of flags in the flag field a one-bit query/reply flag indicates whether the message is a query  0  or a reply  1   a one bit authoritative flag is set in a reply message when a name server is an authoritative server for a queried name a one bit recursion-desired flag is set when a client  host or name server  desires that the name server to perform recursion when it does n't have the record a one-bit recursion available field is set in a reply if the name server supports recursion in the header  there are also four " number of " fields these fields indicate the number of occurrences of the four types of " data " sections that follow the header l the question section contains information about the query that is being made this section includes  i  a name field that contains the name that is being queried  and  ii  a type field that indicates the type of question being asked about the name  e.g  a host address associated with a name  type " a "  or the mail server for a name  type " mx "   l in a reply from a name server  the answer section contains the resource records for the name that was originally queried recall that in each resource record there is the type  e.g  a  ns  csname and mx   the value and the ttl a reply can return multiple rrs in the answer  since a hostname can have multiple ip addresses  e.g  for replicated web servers  as discussed earlier in this section   l the authority section contains records of other authoritative servers l the additional section contains other " helpful " records for example  the answer field in a reply to an mx query will contain the hostname of a mail server associated with the alias name name the additional section will contain a type a record providing the ip address for the canonical hostname of the mail server file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/dns.htm  9 of 10  20/11/2004 15  51  57 the domain name system the discussion above has focussed on how data is retrieved from the dns database you might be wondering how data gets into the database in the first place ? until recently  the contents of each dns server was configured statically  e.g  from a configuration file created by a system manager more recently  an update option has been added to the dns protocol to allow data to be dynamically added or deleted from the database via dns messages  rfc 2136  specifies dns dynamic updates dnsnet provides a nice collection of documents pertaining to dns  dnsnet   the internet software consortium provides many resources for bind  a popular public-domain name server for unix machines  bind   references  abitz 1993  paul albitz and cricket liu  dns and bind  o'reilly & associates  petaluma  ca  1993  bind  internet software consortium page on bind  http  //www.isc.org/bind.html  dnsnet  dnsnet page on dns resources  http  //www.dns.net/dnsrd/docs/  rfc 1034  p mockapetris  " domain names  concepts and facilities  " rfc 1034  nov 1987  rfc 1035  p mockapetris  " domain names  implementation and specification  " rfc 1035  nov 1987  rfc 2136  p vixie  s thomson  y rekhter  j bound  " dynamic updates in the domain name system  " rfc 2136  april 1997 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/dns.htm  10 of 10  20/11/2004 15  51  57 nslookup interactive programs for exploring dns there are at least three client programs available for exploring the contents of name servers in the internet the most widely available program is nslookup ; two other programs  which are a little more powerful than nslookup  are dig and host lucky for us  several institutions and individuals have made these client programs available through web browsers we stongly encourage you to get your hands dirty and play with these programs they can give significant insight into how dns works all of these programs mimic dns clients they send a dns query message to a name server  which can often be supplied by the user   and they receive a corresponding dns response they then extract information  e.g  ip addresses  whether the response is authoritative  etc  and present the information to the user nslookup some of the nslookup sites provide only the basic nslookup service  i.e  they allow you to enter a hostname and they return an ip address visit some of the nslookup sights below and try entering hostnames for popular hosts  such as cnn.com or www.microsoft.com  as well as hostnames for the less popular hosts you will see that the popular hostnames typically return numerous ip addresses  because the site is replicated in numerous servers  see the discussion in section 2.5 on dns rotation  some of the nslookup sites also return the hostname and ip address of the name server that provides the information also  some of the nslookup sites indicate whether the result is non-authoritative  i.e  obtained from a cache   http  //namespace.pgmedia.net/nslookup/ http  //www.infobear.com/nslookup-form.cgi some of the nslookup sites allow the user to supply more information for example  the user can request to receive the canonical hostname and ip address for a mail server and the user can also indicate the name server at which it wants the chain of queries to begin http  //jeff.aaron.com/ ~ jmaaron/nslookup.cgi http  //ipalloc.utah.edu/html_docs/nslookup.html dig and host the programs dig and host allow the user to further refine the query by indicating  for example  whether file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/nslookup.htm  1 of 2  20/11/2004 15  51  58 nslookup the query should be recursive or interative there are currently not as many web sites that provide the dig and host service but there are a few  http  //www.toetag.com/cgi-bin/host http  //www.netliner.com/dig.html return to table of contents copyright 1996-1999 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/nslookup.htm  2 of 2  20/11/2004 15  51  58 socket programming in java 2.6 socket programming with tcp this and the subsequent sections provide an introduction to network application development recall from section 2.1 that the core of a network application consists of a pair of programs  a client program and a server program when these two programs are executed  a client and server process are created  and these two processes communicate with each other by reading from and writing to sockets when a creating a networking application  the developer 's main task is to write the code for both the client and server programs there are two sorts of client-server applications one sort is a client-server application that is an implementation of a protocol standard defined in an rfc for such an implementation  the client and server programs must conform to the rules dictated by the rfc for example  the client program could be an implementation of the ftp client  defined in  rfc 959   and the server program could be implementation of the ftp server  also defined in  rfc 959   if one developer writes code for the client program and an independent developer writes code for the server program  and both developers carefully follow the rules of the rfc  then the two programs will be able to interoperate indeed  most of today 's network applications involve communication between client and server programs that have been created by independent developers  for example  a netscape browser communicating with an apache web server  or a ftp client on a pc uploading a file to a unix ftp server  when a client or server program implements a protocol defined in an rfc  it should use the port number associated with the protocol  port numbers were briefly discussed in section 2.1 they will be covered in more detail in the next chapter  the other sort of client-server application is a proprietary client-server application in this case the client and server programs do not necessarily conform to any existing rfc a single developer  or development team  creates both the client and server programs  and the developer has complete control over what goes in the code but because the code does not implement a public-domain protocol  other independent developers will not be able to develop code that interoperate with the application when developing a proprietary application  the developer must be careful not to use one of the the well-known port numbers defined in the rfcs in this and the next section  we will examine the key issues for the development of a proprietary client-server application during the development phase  one of the first decisions the developer must make is whether the application is to run over tcp or over udp tcp is connection-oriented and provides a reliable byte stream channel through which data flows between two endsystems udp is connectionless and sends independent packets of data from one end system to the other  without any guarantees about delivery in this section we develop a simple-client application that runs over tcp ; in the subsequent section  we develop a simple-client application that runs over udp we present these simple tcp and udp applications in java we could have written the code in c or c + +  but we opted for java for several reasons first  the applications are more neatly and cleanly written in java ; with java there are fewer lines of code  and each line can be explained to the novice programmer without much difficulty second  client-server programming in java is becoming increasingly popular  and may even become the norm in upcoming years java is platform independent  it has exception mechanisms for robust handling of common problems that occur during i/o and networking operations  and its threading facilities provide a way to easily implement powerful servers but there is no need to be frightened if you are not familiar with java you should be able to follow the code if you have experience programming in another language for readers who are interested in client-server programming in c  there are several good references available  including  stevens 1990    frost 1994  and  kurose 1996   2.6.1 socket programming with tcp recall from section 2.1 that processes running on different machines communicate with each other by sending messages into sockets we said that each process was analogous to a house and the process 's socket is analogous to a door as shown in file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  1 of 9  20/11/2004 15  51  59 socket programming in java figure 2.6.1  the socket is the door between the application process and tcp the application developer has control of everything on the application-layer side of the socket ; however  it has little control of the transport-layer side  at the very most  the application developer has the ability to fix a few tcp parameters  such as maximum buffer and maximum segment sizes  figure 2.6-1  processes communicating through tcp sockets now let 's to a little closer look at the interaction of the client and server programs the client has the job of initiating contact with the server in order for the server to be able to react to the client 's initial contact  the server has to be ready this implies two things first  the server program can not be dormant ; it must be running as a process before the client attempts to initiate contact second  the server program must have some sort of door  i.e  socket  that welcomes some initial contact from a client  running on an arbitrary machine   using our house/door analogy for a process/socket  we will sometimes refer to the client 's initial contact as " knocking on the door "  with the server process running  the client process can initiate a tcp connection to the server this is done in the client program by creating a socket object when the client creates its socket object  it specifies the address of the server process  namely  the ip address of the server and the port number of the process upon creation of the socket object  tcp in the client initiates a three-way handshake and establishes a tcp connection with the server the three-way handshake is completely transparent to the client and server programs during the three-way handshake  the client process knocks on the welcoming door of the server process when the server " hears " the knocking  it creates a new door  i.e  a new socket  that is dedicated to that particular client in our example below  the welcoming door is a serversocket object that we call the welcomesocket when a client knocks on this door  the program invokes welcomesocket 's accept   method  which creates a new door for the client at the end of the handshaking phase  a tcp connection exists between the client 's socket and the server 's new socket henceforth  we refer to the new socket as the server 's " connection socket "  from the application 's perspective  the tcp connection is a direct virtual pipe between the client 's socket and the server 's connection socket the client process can send arbitrary bytes into its socket ; tcp guarantees that the server process will receive  through the connection socket  each byte in the order sent furthermore  just as people can go in and out the same door  the client process can also receive bytes from its socket and the server process can also send bytes into its connection socket this is illustrated in figure 2.6.2 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  2 of 9  20/11/2004 15  51  59 socket programming in java figure 2.6-2  client socket  welcoming socket and connection socket because sockets play a central role in client-server applications  client-server application development is also referred to as socket programming before providing our example client-server application  it is useful to discuss the notion of a stream a stream is a flowing sequence of characters that flow into or out of a process each stream is either an input stream for the process or an output stream for the process if the stream is an input stream  then it is attached to some input source for the process  such as standard input  the keyboard  or a socket into which characters flow from the internet if the stream is an output stream  then it is attached to some output source for the process  such as standard output  the monitor  or a socket out of which characters flow into the internet 2.6.2 an example client-server application in java we shall use the following simple client-server application to demonstrate socket programming for both tcp and udp  1 a client reads a line from its standard input  keyboard  and sends the line out its socket to the server 2 the server reads a line from its connection socket 3 the server converts the line to uppercase 4 the server sends the modified line out its connection socket to the client 5 the client reads the modified line from its socket and prints the line on its standard output  monitor   below we provide the client-server program pair for a tcp implementation of the application we provide a detailed  line-byline analysis after each program the client program is called tcpclient.java  and the server program is called tcpserver.java in order to emphasize the key issues  we intentionally provide code that is to the point but not bullet proof " good code " would certainly have a few more auxiliary lines once the the two programs are compiled on their respective hosts  the server program is first executed at the server  which creates a process at the server as discussed above  the server process waits to be contacted by a client process when the client program is executed  a process is created at the client  and this process contacts the server and establishes a tcp connection with it the user at the client may then " use " the application to send a line and then receive a capitalized version of the line tcpclient.java here is the code for the client side of the application  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  3 of 9  20/11/2004 15  51  59 socket programming in java import java.io * ; import java.net * ; class tcpclient  public static void main  string argv    throws exception  string sentence ; string modifiedsentence ; bufferedreader infromuser = new bufferedreader  new inputstreamreader  system.in   ; socket clientsocket = new socket  " hostname "  6789  ; dataoutputstream outtoserver = new dataoutputstream  clientsocket.getoutputstream    ; bufferedreader infromserver = new bufferedreader  new inputstreamreader  clientsocket.getinputstream     ; sentence = infromuser.readline   ; outtoserver.writebytes  sentence + ' \ n '  ; modifiedsentence = infromserver.readline   ; system.out.println  " from server  " + modifiedsentence  ; clientsocket.close   ;   the program tcpclient creates three streams and one socket  as shown in figure 2.6-3 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  4 of 9  20/11/2004 15  51  59 socket programming in java figure 2.6-3  tcpclient has three streams and one socket the socket is called clientsocket the stream infromuser is an input stream to the program ; it is attached to the standard input  i.e  the keyboard when the user types characters on the keyboard  the characters flow into the stream infromuser the stream infromserver is another input stream to the program ; it is attached to the socket characters that arrive from the network flow into the stream infromserver finally  the stream outtoserver is is an output stream from the program ; it is also attached to the socket characters that the client sends to the network flow into the stream outtoserver let 's now take a look at the various lines in the code import java.io * ; import java.net * ; java.io and java.net are java packages the java.io package contains classes for input and output streams in particular  the java.io package contains the bufferedreader and dataoutputstream classes  classes that the program uses to create the three streams illustrated above the java.net package provides classes for network support in particular  it contains the socket and serversocket classes the clientsocket object of this program is derived from the socket class class tcpclient  public static void main  string argv    throws exception     the above is standard stuff that you see at the beginning of most java code the first line is the beginning of a class definition block the keyword class begins the class definition for the class named tcpclient a class contains variables and methods the variables and methods of the class are embraced by the curly brackets that begin and end the class definition block the class tcpclient has no class variables and exactly one method  the main   method methods are similar to the functions or procedures in languages such as c ; the main method in the java language is similar to the main function in c and c + +  when the java interpreter executes an application  by being invoked upon the application 's controlling class   it starts by calling the class 's main method the main method then calls all the other methods required to run the application for this introduction into socket programming in java  you may ignore the keywords public  static  void  main  throws exceptions  although you must include them in the code   string sentence ; file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  5 of 9  20/11/2004 15  51  59 socket programming in java string modifiedsentence ; these above two lines declare objects of type string the object sentence is the string typed by the user and sent to the server the object modifiedsentence is the string obtained from the server and sent the user 's standard output bufferedreader infromuser = new bufferedreader  new inputstreamreader  system.in   ; the above line creates the stream object infromuser of type bufferedreader the input stream is initialized with system.in  which attaches the stream to the standard input the command allows the client to read text from its keyboard socket clientsocket = new socket  " hostname "  6789  ; the above line creates the object clientsocket of type socket it also initiates the tcp connection between client and server the variable " host name " must be replaced with the host name of the server  e.g  " fling.seas.upenn.edu "   before the tcp connection is actually initiated  the client performs a dns look up on the hostname to obtain the host 's ip address the number 6789 is the port number you can use a different port number ; but you must make sure that you use the same port number at the server side of the application as discussed earlier  the host 's ip address along with the applications port number identifies the server process dataoutputstream outtoserver = new dataoutputstream  clientsocket.getoutputstream    ; bufferedreader infromserver = new bufferedreader  new inputstreamreader  clientsocket.getinputstream     ; the above two lines create stream objects that are attached to the socket the outtoserver stream provides the process output to the socket the infromserver stream provides the process input from the socket  see diagram above  sentence = infromuser.readline   ; the above line places a line typed by user into the string sentence the string sentence continues to gather characters until the user ends the line by typing a carriage return the line passes from standard input through the stream infromuser into the string sentence outtoserver.writebytes  sentence + ' \ n '  ; the above line sends the string sentence augmented with a carriage return into the outtoserver stream the augmented sentence flows through the client 's socket and into the tcp pipe the client then waits to receive characters from the server modifiedsentence = infromserver.readline   ; when characters arrive from the server  they flow through the stream infromserver and get placed into the string modifiedsentence characters continue to accumulate in modifiedsentence until the line ends with a carriage return character system.out.println  " from server " + modifiedsentence  ; the above line prints to the monitor the string modifiedsentence returned by the server file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  6 of 9  20/11/2004 15  51  59 socket programming in java clientsocket.close   ; this last line closes the socket and  hence  closes the tcp connection between the client and the server it causes tcp in the client to send a tcp message to tcp in the server  see section 3.5   tcpserver.java now let 's take a look at the server program import java.io * ; import java.net * ; class tcpserver  public static void main  string argv    throws exception  string clientsentence ; string capitalizedsentence ; serversocket welcomesocket = new serversocket  6789  ; while  true   socket connectionsocket = welcomesocket.accept   ; bufferedreader infromclient = new bufferedreader  new inputstreamreader  connectionsocket.getinputstream     ; dataoutputstream outtoclient = new dataoutputstream  connectionsocket.getoutputstream    ; clientsentence = infromclient.readline   ; capitalizedsentence = clientsentence.touppercase   + ' \ n ' ; outtoclient.writebytes  capitalizedsentence  ;    tcpserver has many similarities with tcpclient let us now take a look at the lines in tcpserver.java we will not comment on the lines which are identical or similar to commands in tcpclient.java the first line in tcpserver that is substantially different from what we saw in tcpclient is  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  7 of 9  20/11/2004 15  51  59 socket programming in java serversocket welcomesocket = new serversocket  6789  ; the above line creates the object welcomesocket  which is of type serversocket the welcomesocket  as discussed above  is a sort of door that waits for a knock from some client the port number 6789 identifies the process at the server the following line is  socket connectionsocket = welcomesocket.accept   ; the above line creates a new socket  called connectionsocket  when some client knocks on welcomesocket tcp then establishes a direct virtual pipe between clientsocket at the client and connectionsocket at the server the client and server can then send bytes to each other over the pipe  and all bytes sent arrive at the other side in order with connectionsocket established  the server can continue to listen for other requests from other clients for the application using welcomesocket  this version of the program does n't actually listen for more connection requests but it can be modified with threads to do so  the program then creates several stream objects  analogous to the stream objects created in clientsocket now consider  capitalizedsentence = clientsentence.touppercase   + ' \ n ' ; this command is the heart of application it takes the line sent by the client  capitalizes it and adds a carriage return it uses the method touppercase    all the other commands in the program are peripheral ; they are used for communication with the client that completes our analysis of the tcp program pair recall that tcp provides a reliable data transfer service this implies  in particular  that if one the user 's characters gets corrupted in the network  then the client host will retransmit the character  thereby providing correct delivery of the data these retransmissions are completely transparent to the application programs the dns lookup is also transparent to the application programs to test the program pair  you install and compile tcpclient.java in one host and tcpserver.java in another host be sure to include the proper host name of the server in tcpclient.java you then execute tcpserver.class  the compiled server program  in the server this creates a process in the server which idles until it is contacted by some client then you execute tcpclient class  the compiled client program  in the client this creates a process in the client and establishes a tcp connection between the client and server processes finally  to use the application  you type a sentence followed by a carriage return to develop your own client-server application  you can begin by slightly modifying the programs for example  instead of converting all the letters to uppercase  the server can count the number of times the letter " s " appears and return this number references in section we provided an introduction to tcp socket programming in java several good online introductions to c socket programming are available  including kurose and keshevref a comprehensive reference on c socket programming for unix hosts is stevens  rfc 959  j.b postel and j.k reynolds  " filel transfer protocol  "  rfc 959   october 1985  stevens 1990  w.r stevens  unix network porgramming  prentice-hall  englewood cliffs  n.j  frost 1994  j frost  bsd sockets  a quick and dirty primer  http  //world.std.com/ ~ jimf/papers/sockets/sockets.html  kurose 1996  j.f kurose  unix network programming  http  //www-aml.cs.umass.edu/ ~ amldemo/courseware/intro.html return to table of contents file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  8 of 9  20/11/2004 15  51  59 socket programming in java copyright keith w ross and james f kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/sockettcp.htm  9 of 9  20/11/2004 15  51  59 socket programming course unix network programming jim kurose university of massachusetts ntu short course may 1996 copyright 1996  j.f kurose  all rights reserved  technology   browser requirements   go !  technology  version 1.5 of our multimedia interactive courseware uses l javascript and java to control the realplayer plugin and communicate with your browser l realnetwork 's realplayer " plug-in " to embed the player controls directly into the courseware window l netscape 's liveconnect to enable communication between javascript  java  and the realplayer plug-in version 1.0 of our multimedia interactive courseware uses l realnetwork 's realplayer application which plays audio clips in a window and program that 's separate from your browser both versions of our multimedia courseware use http cookies to maintain state information these are temporary cookies  once your session ends the cookies expire  no cookies are ever written to your disk   the web browser requirements check on this page will attempt to determine if your browser has the capability to run the latest version of our multimedia interactive courseware based on this requirements check you will be presented with a link to version 1.5 and/or a link to version 1.0 currently version 1.5 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...own % 20approach % 20featuring % 20the % 20internet/intro.html  1 of 2  20/11/2004 15  51  59 socket programming course is most robust on wintel platforms running netscape note that users who registered under version 1.0 will have to reregister for version 1.5 web browser requirements  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...own % 20approach % 20featuring % 20the % 20internet/intro.html  2 of 2  20/11/2004 15  51  59 udpdev 2.7 socket programming with udp we learned in the previous section that when two processes communicate over tcp  from the perspective of the processes it is as if there is a pipe between the two processes this pipe remains in place until one of the two processes closes it when one of the processes wants to send some bytes to the other process  it simply inserts the bytes into the pipe the sending process does not have to attach a destination address to the bytes because the pipe is logically connected to the destination furthermore  the pipe provides a reliably byte stream channel  the sequence of bytes received by the receiving process is exactly the sequence bytes that the sender inserted into the pipe udp also allows two  or more  processes running on different hosts to communicate however  udp differs from tcp in many fundamental ways first  udp is a connectionless service  there is n't an initial handshaking phase during which a pipe is established between the two processes because udp does n't have a pipe  when a process wants to send a batch of bytes to another process  the sending process must exclude attach the destination process 's address to the batch of bytes and this must be done for each batch of bytes the sending process sends thus udp is similar to a taxi service  each time a group of people get in a taxi  the group has to inform the driver of the destination address as with tcp  the destination address is a tuple consisting of the ip address of the destination host and the port number of the destination process we shall refer to the batch of information bytes along with the ip destination address and port number as the the " packet "  after having created a packet  the sending process pushes the packet into the network through a socket continuing with our taxi analogy  at the other side of the socket  there is a taxi waiting for the packet the taxi then drives the packet in the direction of the packet 's destination address however  the taxi does not guarantee that it will eventually get the datagram to its ultimate destination ; the taxi could break down in other terms  udp provides an unreliable transport service to its communication processes  it makes no guarantees that a datagram will reach its ultimate destination in this section we will illustrate udp client-server programming by redeveloping the same application of the previous section  but this time over udp we shall also see that the java code for udp is different from the tcp code in many important ways in particular  we shall see that there is  i  no initial handshaking between the two processes  and therefore no need for a welcoming socket   ii  no streams are attached to the sockets   iii  the sending hosts creates " packets " by attaching the ip destination address and port number to each batch of bytes it sends  and  iv  the receiving process must unravel to received packet to obtain the packet 's information bytes recall once again our simple application  1 a client reads a line from its standard input  keyboard  and sends the line out its socket to the server 2 the server reads a line from its socket 3 the server converts the line to uppercase file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  1 of 8  20/11/2004 15  52  02 udpdev 4 the server sends the modified line out its socket to the client 5 the client reads the modified line through its socket and prints the line on its standard output  monitor   udpclient.java here is the code for the client side of the application  import java.io * ; import java.net * ; class udpclient  public static void main  string args    throws exception  bufferedreader infromuser = new bufferedreader  new inputstreamreader  system.in   ; datagramsocket clientsocket = new datagramsocket   ; inetaddress ipaddress = inetaddress.getbyname  " hostname "  ; byte   senddata = new byte  1024  ; byte   receivedata = new byte  1024  ; string sentence = infromuser.readline   ; senddata = sentence.getbytes   ; datagrampacket sendpacket = new datagrampacket  senddata  senddata.length  ipaddress  9876  ; clientsocket.send  sendpacket  ; datagrampacket receivepacket = new datagrampacket  receivedata  receivedata.length  ; clientsocket.receive  receivepacket  ; file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  2 of 8  20/11/2004 15  52  02 udpdev string modifiedsentence = new string  receivepacket.getdata    ; system.out.println  " from server  " + modifiedsentence  ; clientsocket.close   ;   the program udpclient.java constructs one stream and one socket  as shown in figure 2.7-1 the socket is called clientsocket  and it is of type datagramsocket note that udp uses a different kind of socket than tcp at the client in particular  with udp our client uses a datagramsocket whereas with tcp our client used a socket the stream infromuser is an input stream to the program ; it is attached to the standard input  i.e  the keyboard we had an equivalent stream in our tcp version of the program when the user types characters on the keyboard  the characters flow into the stream infromuser but in contrast with tcp  there are no streams  input or output  attached to the socket instead of feeding bytes to stream attached to a socket object  udp will push individual packets through the datagramsocket object figure 2.7-1  udpclient.java has one stream and one socket file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  3 of 8  20/11/2004 15  52  02 udpdev let 's now take a look at the lines in the code that differ significantly from tcpclient.java datagramsocket clientsocket = new datagramsocket   ; the above line creates the object clientsocket of type datagramsocket in contrast with tcpclient.java  this line does not initiate a tcp connection in particular  the client host does not contact the server host upon execution of this line for this reason  the constructor datagramsocket   does not take the server hostname or port number as arguments using our door/pipe analogy  the execution of the above line creates a door for the client process but does not create a pipe between the two processes inetaddress ipaddress = inetaddress.getbyname  " hostname "  ; in order to send bytes to a destination process  we shall need to obtain the address of the process part of this address is the ip address of the destination host the above line invokes a dns look up that translates " hostname "  supplied in the code by the developer  to an ip address dns was also invoked by the tcp version of the client  although it was done there implicitly rather than explicitly the method getbyname   takes as an argument the hostname of the server and returns the ip address of this same server it places this address in the object ipaddress of type inetaddress byte   senddata = new byte  1024  ; byte   receivedata = new byte  1024  ; the byte arrays senddata and receivedata will hold the data the client sends and receives  respectively senddata = sentence.getbytes   ; the above line essentially performs a type conversion it takes the string sentence and renames it as senddata  which is an array of bytes datagrampacket sendpacket = new datagrampacket  senddata  senddata.length  ipaddress  9876  ; the above line constructs the packet  sendpacket  that the the client will pop into the network through its socket this packet includes that data that is contained in the packet  senddata  the length of this data  the ip address of the server  and the port number of the application  which we have set to 9876   note that sendpacket is of type datagrampacket clientsocket.send  sendpacket  ; in the above line the method send   of the object clientsocket takes the packet just constructed and pops file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  4 of 8  20/11/2004 15  52  02 udpdev it into the network through clientsocket once again  note that udp sends the line of characters in a manner very different from tcp tcp simply inserted the line into a stream  which had a logical direct connection to the server ; udp creates a packet which includes the address of the server after sending the packet  the client then waits to receive a packet from the server datagrampacket receivepacket = new datagrampacket  receivedata  receivedata.length  ; in the above line  while waiting for the packet from the server  the client creates a place holder for the packet  receivepacket  an object of type datagrampacket clientsocket.receive  receivepacket  ; the client idles until it receives a packet ; when it does receive a packet  it puts the packet in receivepacket string modifiedsentence = new string  receivepacket.getdata    ; the above line extracts the data from receivepacket and performs a type conversion  converting an array of bytes into the string modifiedsentence system.out.println  " from server  " + modifiedsentence  ; the above  which is also present in tcpclient  prints out the string modifiedsentence at the client 's monitor clientsocket.close   ; this last line closes the socket because udp is connectionless  this line does not cause the client to send a tranport-layer message to the server  in contrast with tcpclient   udpserver.java let 's now take a look at the server side of the application  import java.io * ; import java.net * ; class udpserver  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  5 of 8  20/11/2004 15  52  02 udpdev public static void main  string args    throws exception  datagramsocket serversocket = new datagramsocket  9876  ; byte   receivedata = new byte  1024  ; byte   senddata = new byte  1024  ; while  true   datagrampacket receivepacket = new datagrampacket  receivedata  receivedata.length  ; serversocket.receive  receivepacket  ; string sentence = new string  receivepacket.getdata    ; inetaddress ipaddress = receivepacket.getaddress   ; int port = receivepacket.getport   ; string capitalizedsentence = sentence.touppercase   ; senddata = capitalizedsentence.getbytes   ; datagrampacket sendpacket = new datagrampacket  senddata  senddata.length  ipaddress  port  ; serversocket.send  sendpacket  ;    the program udpserver.java constructs one socket  as shown in figure 2.7-2 the socket is called serversocket it is an object of type datagramsocket  as was the socket in the client side of the application once again  no streams are attached to the socket file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  6 of 8  20/11/2004 15  52  02 udpdev figure 2.7-2  udpserver.java has one socket let 's now take a look at the lines in the code that differ from tcpserver.java datagramsocket serversocket = new datagramsocket  9876  ; the above line constructs the datagramsocket serversocket at port 9876 all data sent and received will pass through this socket because udp is connectionless  we do not have to spawn a new socket and continue to listen for new connection requests  as done in tcpserver.java if multiple clients access this application  they will all send their packets into this single door  serversocket string sentence = new string  receivepacket.getdata    ; inetaddress ipaddress = receivepacket.getaddress   ; int port = receivepacket.getport   ; the above three lines unravel the packet that arrives from the client the first of the three lines extracts the data from the packet and places the data in the string sentence ; it has an analogous line in udpclient the second line extracts the ip address ; the third line extracts the client port number  which is chosen by the client and is different from the server port number 9876  we will discuss client port file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  7 of 8  20/11/2004 15  52  02 udpdev numbers in some detail in the next chapter  it is necessary for the server to obtain the address  ip address and port number  of the client  so that it can send the capitalized sentence back to the client that completes our analysis of the udp program pair to test the application  you install and compile udpclient.java in one host and udpserver.java in another host  be sure to include the proper hostname of the server in udpclient.java  then execute the two programs on their respective hosts unlike with tcp  you can first execute the client side and then the server side this is because  when you execute the client side  the client process does not attempt to initiate a connection with the server once you have executed the client and server programs  you may use the application by typing a line at the client return to table of contents copyright keith w ross and james f  kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/udpdev.html  8 of 8  20/11/2004 15  52  02 keith \ book \ applications \ webserver 2.8 building a simple web server now that we have studied http in some detail and have learned how to write client-server applications in java  let us combine this new-found knowledge and build a simple web server in java we will see that the task is remarkably easy our goal is to build a server that does the following  l handles only one http request l accepts and parses the http request l gets the requested file from the server 's file system l creates an http response message consisting of the requested file preceded by header lines l sends the response directly to the client let 's try to make the code as simple as possible in order to shed insight on the networking concerns the code that we present will be far from bullet proof ! for example  let 's not worry about handling exceptions and let 's assume that the client requests an object that is in server 's file system webserver.java here is the code for a simple web server  import java.io * ; import java.net * ; import java.util * ; class webserver  public static void main  string argv    throws exception  string requestmessageline ; string filename ; serversocket listensocket = new serversocket  6789  ; socket connectionsocket = listensocket.accept   ; bufferedreader infromclient = file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  1 of 6  20/11/2004 15  52  03 keith \ book \ applications \ webserver new bufferedreader  new inputstreamreader  connectionsocket getinputstream     ; dataoutputstream outtoclient = new dataoutputstream  connectionsocket.getoutputstream    ; requestmessageline = infromclient.readline   ; stringtokenizer tokenizedline = new stringtokenizer  requestmessageline  ; if  tokenizedline.nexttoken   .equals  " get "    filename = tokenizedline.nexttoken   ; if  filename.startswith  " / "  = = true  filename = filename.substring  1  ; file file = new file  filename  ; int numofbytes =  int  file.length   ; fileinputstream infile = new fileinputstream  filename  ; byte   fileinbytes = new byte  numofbytes  ; infile.read  fileinbytes  ; outtoclient.writebytes  " http/1.0 200 document follows \ r \ n "  ; if  filename.endswith  " .jpg "   outtoclient.writebytes  " content-type  image/jpeg \ r \ n "  ; if  filename.endswith  " .gif "   outtoclient.writebytes  " content-type  image/gif \ r \ n "  ; outtoclient.writebytes  " content-length  " + numofbytes + " \ r \ n "  ; outtoclient.writebytes  " \ r \ n "  ; outtoclient.write  fileinbytes  0  numofbytes  ; file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  2 of 6  20/11/2004 15  52  03 keith \ book \ applications \ webserver connectionsocket.close   ;  else system.out.println  " bad request message "  ;   let us now take a look at the code the first half the program is almost identical to tcpserver.java as with tcpserver.java  we import the java.io and java.net packages in addition to these two packages we also import the java.util package  which contains the stringtokenizer class  which is used for parsing http request messages looking now at the lines within the class webserver  we define two string objects  string requestmessageline ; string filename ; the object requestmessageline is a string that will contain the first line in the http request message the object filename is a string that will contain the file name of the requested file the next set of commands is identical to the corresponding set of commands in tcpserver.java serversocket listensocket = new serversocket  6789  ; socket connectionsocket = listensocket.accept   ; bufferedreader infromclient = new bufferedreader  new inputstreamreader  connectionsocket getinputstream     ; dataoutputstream outtoclient = new dataoutputstream  connectionsocket.getoutputstream    ; two socket-like objects are created the first of these objects is listensocket  which is of type serversocket the object listensocket is created by the server program before receiving a request for a tcp connection from a client it listens at port 6789  and waits for a request from some client to establish a tcp connection when a request for a connection arrives  the accept   method of listensocket creates a new object  connectionsocket  of type socket next two streams are created  the bufferedreader infromclient and the dataoutputstream outtoclient the http request message comes from the network  through connectionsocket and into infromclient ; the http response message goes into outtoclient  through connectionsocket and into the network the remaining file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  3 of 6  20/11/2004 15  52  03 keith \ book \ applications \ webserver portion of the code differs significantly from tcpserver.java requestmessageline = infromclient.readline   ; the above command reads the first line of the http request message this line is supposed to be of the form  get file_name http/1.0 our server must now parse the line to extract the filename stringtokenizer tokenizedline = new stringtokenizer  requestmessageline  ; if  tokenizedline.nexttoken   .equals  " get "    filename = tokenizedline.nexttoken   ; if  filename.startswith  " / "  = = true  filename = filename.substring  1  ; the above commands parse the first line of the request message to obtain the requested filename the object tokenizedline can be thought of as the original request line with each of the " words " get  file_name and http/1.0 placed in a separate place holder called a token the server knows from the http rfc that the file name for the requested file is contained in the token that follows the token containing " get "  this file name is put in a string called filename the purpose of the last if statement in the above code is to remove the backslash that may precede the filename fileinputstream infile = new fileinputstream  filename  ; the above command attaches a stream  infile  to the file filename byte   fileinbytes = new byte  numofbytes  ; infile.read  fileinbytes  ; the above commands determine the size of the file and construct an array of bytes of that size the name of the array is fileinbytes the last command reads from the stream infile to the byte array fileinbytes the program must convert to bytes because the output stream outtoclient may only be fed with bytes file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  4 of 6  20/11/2004 15  52  03 keith \ book \ applications \ webserver now we are ready to construct the http response message to this end we must first send the http response header lines into the dataoutputstream outtoclient  outtoclient.writebytes  " http/1.0 200 document follows \ r \ n "  ; if  filename.endswith  " .jpg "   outtoclient.writebytes  " content-type  image/jpeg \ r \ n "  ; if  filename.endswith  " .gif "   outtoclient.writebytes  " content-type  image/gif \ r \ n "  ; outtoclient.writebytes  " content-length  " + numofbytes + " \ r \ n "  ; outtoclient.writebytes  " \ r \ n "  ; the above set of commands are particularly interesting these commands prepare the header lines for http response message and send the header lines to the tcp send buffer the first command sends the mandatory status line  http/1.0 200 document follows  followed by a carriage return and a line feed the next two command lines prepare a single content-type header line if the server is to transfer a gif image  then the server prepares the header line content-type  image/jpeg if  on the other hand  the server is to transfer a jpeg image  then the server prepares the header line content-type  image/gif  in this simple web server  no content line is sent if the object is neither a gif nor a jpeg image  the server then prepares and sends a content-length header line and a mandatory blank line to precede the object itself that is to be sent we now must send the file filename into the dataoutputstream outtoclient but because outtoclient works with bytes  we first must perform a conversion to bytes  we can now send the requested file  outtoclient.write  fileinbytes  0  numofbytes  ; the above command sends the requested file  fileinbytes  to the tcp send buffer tcp will concatenate the file  fileinbytes  to the header lines just created  segment the concatenation if necessary  and send the tcp segments to the client connectionsocket.close   ; after serving one request for one file  the server performs some housekeeping by closing the socket connectionsocket to test this web server  install it on a host also put some files in the host then use a browser running file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  5 of 6  20/11/2004 15  52  03 keith \ book \ applications \ webserver on any machine to request a file from the server when you request a file  you will need to use the port number that you include in the server code  e.g  6789   so if your server is located at somehost somewhere.edu  the file is somefile.html  and the port number is 6789  then the browser should request http  //somehost.somewhere.edu  6789/somefile.html  return to table of contents copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/webserver.htm  6 of 6  20/11/2004 15  52  03 chapter 2  summary 2.10 summary in this chapter we 've studied both the conceptual and the implementation aspects of network applications we 've learned about the ubiquitous client-server paradigm adopted by internet applications and seen its use in the http  ftp  smtp  pop3 and dns protocols we 've studied these important application-level protocols  and their associated applications  the web  file transfer  e-mail  and the domain name system  in some detail we 've examined how the socket api can be used to build network applications and walked through not only the use of sockets over connection-oriented  tcp  and connectionless  udp  end-to-end transport services  but also built a simple web server using this api the first step in our top-down journey " down " the layered network architecture is complete at the very beginning of this book  in section 1.3  we gave a rather vague  bare bones definition of a protocol as defining " the format and the order of messages exchanged between two communicating entities  as well as the actions taken on the transmission and/or receipt of a message " the material in this chapter  and in particular the detailed study of the http  ftp  smtp  pop3 and dns protocols  has now added considerable substance to this definition protocols are a key concept in networking ; our study of applications protocols has now given us the opportunity to develop a more intuitive feels for what protocols are all about in section 2.1 we described the service models that tcp and udp offer to applications that invoke them we took an even closer look at these service models when we developed simple applications that run over tcp and udp in sections 2.6-2.7 however  we have said little about how tcp and udp provide these service models for example  we have said very little about how tcp provides a reliable data transfer service to its applications in the next chapter we shall take a careful look at not only the what  but also the how and why  of transport protocols armed with a knowledge about internet application structure and application-level protocols  we 're now ready to head further down the protocol stack and examine the transport layer in chapter 3 return to table of contents copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20networ...own % 20approach % 20featuring % 20the % 20internet/ch2_summ.htm20/11/2004 15  52  03 homeowrk probems for chapter 2 homework problems and discussion questions chapter 2 review questions section 2.1 1  list five non-proprietary internet applications and the application-layer protocols that they use 2  for a communication session between two hosts  which host is the client and which is the server ? 3  what information is used by a process running on one host to identify a process running running on another host ? 4  list the various network-application user agents that you use on a daily basis 5  referring to figure 2.1-2  we see that not none of applications listed in the table require both " no data loss " and " timing "  can you conceive of an application that requires no data loss and that is also highly time sensitive ? sections 2.2-2.5 6  what is meant by a handshaking protocol ? 7  why do http  ftp  smtp  pop3 and imap run on top of tcp rather than udp ? 8  consider an e-commerce site that wants to keep a purchase record for each of its customers describe how this can be done with http authentication describe how this can be done with cookies 9  what is the difference between persistent http with pipelining and persistent http without pipelining ? which of the two is used by http/1.1 ? 10  telnet into a web server and send a muli-line request message include in the request message the if-modified-since  header line to force a response message with the 304 not modified status code 11  why is it said that ftp sends control information " out of band " ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/apps_hw.html  1 of 4  20/11/2004 15  52  03 homeowrk probems for chapter 2 12  suppose alice with a web-based e-mail account  such as yahoo ! mail or hotmail  sends a message to bob  who accesses his mail from his mail server using pop3 discuss how the message gets from alice 's host to bob 's host be sure to list the series of application-layer protocols that are used to move the message between the two hosts 13  suppose that you send an e-mail message whose only data is a microsoft excel attachment what might the header lines  including mime lines  look like ? 14  print out the header of a message that you have recently received how many recieved  header lines are there ? analyze each of the header lines in the message 15  from a user 's perspective  what is the difference between the download-and-delete mode and the download-and-keep mode in pop3 ? 16  redraw figure 2.5-4 for when all queries from the local nameserver are iterative 17  each internet host will have at least one local name server and one authoratative name server what role does each of these servers have in dns ? 18  is it possible that an organization 's web server and mail server have exactly the same alias for a hostname  e.g  foo.com  ? what would be the " type " for the rr that contains the hostname of the mail server ? 19  use nslookup to find a web server that has multiple ip addresses does the web server of your institution  school  company  etc  have multiple ip addresses ? sections 2.6-2.9 20  the udp server described in section 2.7 only needed one socket  whereas the tcp server described in section 2.6 needed two sockets why ? if the tcp server were to support n simultaneous connections  each from a different client host  how many sockets would the tcp server need ? 21  for the client-server application over tcp described in section 2.6  why must the server program be executed before the client program ? for the client-server application over udp described in section 2.7  why may the client program be executed before the server program ? problems 1  true or false a  suppose a user requests a web page that consists of some text and two images for this page file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/apps_hw.html  2 of 4  20/11/2004 15  52  03 homeowrk probems for chapter 2 the client will send one request message and recieve three response messages ? b  true or false two distinct web pages  e.g  www.mit.edu/research.html and www.mit.edu/ students.html  can be sent over the same persistent connection ? c  with non-persistent connections between browser and origin server  it is possible for a single tcp segment to carry two distinct http request messages ? d  the date  header in the http response message indicates when the object in the response was last modified ? 2  read rfc 959 for ftp list all of the client commands that are supported by the rfc 3  read rfc 1700 what are the well-known port numbers for the " simple file transfer protocol "  sftp  ? for the " network news transfoer protocol "  nntp  ? 4  suppose within your web browser you click on a link to obtain a web page suppose that the ip address for the associated url is not cached in your local host  so that a dns look up is necessary to obtain the ip address suppose that n dns servers are visited before your host receives the ip address from dns ; the successive visits incur a rtt of rtt1    rttn further suppose that web page associated with the link contains exactly one object  a small amount of html text let rtt0 denote the rtt between the local host and the server containing the object assuming zero transmission time of the object  how much time elapses from when the client clicks on the link until the client receives the object 5  referring to question  4   suppose the page contains three very small objects neglecting transmission times  how much time elapses with  a  nonpersistent http with no parallel tcp connections   b  nonpersistent http with parallel connections   c  persistent http with pipelining 6  two http request methods are get and post are there any other methods in http/1.0 ? if so  what are they used for ? how about http/1.1 ? 7  write a simple tcp program for a server that accepts lines of input from a client and prints the lines onto the server 's standard output  you can do this by modifying the tcpserver.java program in the text  compile and execute your program on any other machine which contains a web browser  set the proxy server in the browser to the machine in which your server program is running ; also configure the port number appropriately your browser should now send its get request messages to your server  and your server should display the messages on its standard output use this platform to determine whether your browser generates conditional get messages for objects that are locally cached 7  read the pop3 rfc  rfc 1939 what is the purpose of the uidl pop3 command ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/apps_hw.html  3 of 4  20/11/2004 15  52  03 homeowrk probems for chapter 2 8  install and compile the java programs tcpclient and udpclient on one host and tcpserver and udpserver on another host a  suppose you run tcpclient before you run tcpserver what happens ? why ? b  suppose you run udpclient before you run udpserver what happens ? why ? c  what happens if you use different port numbers for the client and server sides ? 9  rewrite tcpserver.java so that it can accept multiple connections  hint  you will need to use threads  discussion questions 1  what is a cgi script ? give examples of two popular web sites that use cgi scripts explain how these sites use cgi which languages are cgi scripts typically written in ? 2  how can you configure your browser for local caching ? what kinds of options do you have ? 3  can you configure your browser to open multiple simultaneous connections to a web site ? what are the advantages and disadvantages of having a large number of simultaneous tcp connections ? 4  discussion question  consider smtp  pop3 and imap are these stateless protocols ? why or why not ? 5  we have seen that internet tcp sockets treat the data being sent as a byte stream but udp sockets recognize message boundaries what is one advantage and one disadvantage of byte-oriented api versus having the api explicitly recognize and preserve application-defined message boundaries ? 6  would it be possible to implement a connection-oriented service  e.g  smtp or http  on top of a connectionless service ? what would be some of the difficulties involved in doing so  and how could these be overcome ? copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/apps_hw.html  4 of 4  20/11/2004 15  52  03 the transport layer  overview 3.1 transport layer services and principles residing between the application and network layers  the transport layer is in the core of the layered network architecture it has the critical role of providing communication services directly to the application processes running on different hosts in this chapter we 'll examine the possible services provided by a transport layer protocol and the principles underlying various approaches towards providing these services we 'll also look at how these services are implemented and instantiated in existing protocols ; as usual  particular emphasis will be given to the internet protocols  namely  tcp and udp transport layer protocols in the previous two chapters we have touched on the role of the transport layer and the services that it provides let 's quickly review what we have already learned about the transport layer  l a transport layer protocol provides for logical communication between application processes running on different hosts by " logical " communication  we mean that although the communicating application processes are not physically connected to each other  indeed  they may be on different sides of the planet  connected via numerous routers and a wide range of link types   from the applications ' viewpoint  it is as if they were physically connected application processes use the logical communication provided by the transport layer to send messages to each other  free for the worry of the details of the physical infrastructure used to carry these messages figure 3.1-1 illustrates the notion of logical communication l as shown in figure 3.1-1  transport layer protocols are implemented in the end systems but not in network routers network routers only act on the network-layer fields of the layer-3 pdus ; they do not act on the transport-layer fields l at the sending side  the transport layer converts the messages it receives from a sending application process into 4-pdus  that is  transport-layer protocol data units   this is done by  possibly  breaking the application messages into smaller chunks and adding a transport-layer header to each chunk to create 4-pdus the transport layer then passes the 4-pdus to the network layer  where each 4-pdu is encapsulated into a 3-pdu at the receiving side  the transport layer receives the 4-pdus from the network layer  removes the transport header from the 4-pdus  reassembles the messages and passes them to a receiving application process l a computer network can make more than one transport layer protocol available to network applications for example  the internet has two protocols  tcp and udp each of these protocols provides a different set of transport layer services to the invoking application l all transport layer protocols provide an application multiplexing/demultiplexing service this service will be described in detail in the next section as discussed in section 2.1  in addition to multiplexing/ demultiplexing service  a transport protocol can possibly provide other services to invoking applications  including reliable data transfer  bandwidth guarantees  and delay guarantees file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/transport_layer.htm  1 of 5  20/11/2004 15  52  04 the transport layer  overview figure 3.1-1  the transport layer provides logical rather than physical communication between applications 3.1.1 relationship between transport and network layers from the perspective of network applications  the transport layer is the underlying communication infrastructure of course  there is more to the communication infrastructure than just the transport layer for example  the network layer lies just below the transport layer in the protocol stack whereas a transport layer protocol provides logical communication between processes running on different hosts  a network layer protocol provides logical communication between hosts this distinction is subtle but important let 's examine this distinction with the aid of a household analogy consider two houses  one on the east coast and the other on the west coast  with each house being home to a dozen kids the kids in the east coast household are cousins with the kids in the west coast households the kids in the two households love to write each other  each kid writes each cousin every week  with each letter delivered by the traditional postal service in a separate envelope thus  each household sends 144 letters to the other household every week  these kids would save a lot of money if they had e-mail !   in each of the households there is one kid  alice in the west coast house and bob in the east coast house  responsible for mail collection and mail distribution each week alice visits all her brothers and sisters  collects the mail  and gives the mail to a postal-service mail person who makes daily visits to the house when letters arrive to the west coast house  alice also has the job of distributing the mail to her brothers and sisters bob has a similar job on the east coast in this example  the postal service provides logical communication between the two houses  the postal file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/transport_layer.htm  2 of 5  20/11/2004 15  52  04 the transport layer  overview service moves mail from house to house  not from person to person on the other hand  alice and bob provide logical communication between the cousins  alice and bob pick up mail from and deliver mail to  their brothers and sisters note that  from the cousins ' perspective  alice and bob are the mail service  even though alice and bob are only a part  the end system part  of the end-to-end delivery process this household example serves as a nice analogy for explaining how the transport layer relates to the network layer  l hosts  also called end systems  = houses l processes = cousins l application messages = letters in envelope l network layer protocol = postal service  including mail persons  l transport layer protocol = alice and bob continuing with this analogy  observe that alice and bob do all their work within their respective homes ; they are not involved  for example  in sorting mail in any intermediate mail center or in moving mail from one mail center to another similarly  transport layer protocols live in the end systems within an end system  a transport protocol moves messages from application processes to the network edge  i.e  the network layer  and vice versa ; but it does n't have any say about how the messages are moved within the network core in fact  as illustrated in figure 3.1-1  intermediate routers neither act on  nor recognize  any information that the transport layer may have appended to the application messages continuing with our family saga  suppose now that when alice and bob go on vacation  another cousin pair  say  susan and harvey  substitute for them and provide the household-internal collection and delivery of mail unfortunately for the two families  susan and harvey do not do the collection and delivery in exactly the same way as alice and bob being younger kids  susan and harvey pick up and drop off the mail less frequently and occasionally lose letters  which are sometimes chewed up by the family dog   thus  the cousin-pair susan and harvey do not provide the same set of services  i.e  the same service model  as alice and bob in an analogous manner  a computer network may make available multiple transport protocols  with each protocol offering a different service model to applications the possible services that alice and bob can provide are clearly constrained by the possible services that the postal service provides for example  if the postal service does n't provide a maximum bound on how long it can take to deliver mail between the two houses  e.g  three days   then there is no way that alice and bob can guarantee a maximum delay for mail delivery between any of the cousin pairs in a similar manner  the services that a transport protocol can provide are often constrained by the service model of the underlying network-layer protocol if the network layer protocol can not provide delay or bandwidth guarantees for 4 pdus sent between hosts  then the transport layer protocol can not provide delay or bandwidth guarantees for the messages sent between processes nevertheless  certain services can be offered by a transport protocol even when the underlying network protocol does n't offer the corresponding service at the network layer for example  as we 'll see in this chapter  a transport protocol can offer reliable data transfer service to an application even when the underlying network protocol is unreliable  that is  even when the network protocol loses  garbles and duplicates packets as another example  which we 'll explore in chapter 7 when we discuss network security   file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/transport_layer.htm  3 of 5  20/11/2004 15  52  04 the transport layer  overview a transport protocol can use encryption to guarantee that application messages are not read by intruders  even when the network layer can not guarantee the secrecy of 4-pdus 3.1.2 overview of the transport layer in the internet the internet  and more generally a tcp/ip network  makes available two distinct transport-layer protocols to the application layer one of these protocols is udp  user datagram protocol   which provides an unreliable  connectionless service to the invoking application the second of the these protocols is tcp  transmission control protocol   which provides a reliable  connection-oriented service to the invoking application when designing a network application  the application developer must specify one of these two transport protocols as we saw in sections 2.6 and 2.7  the application developer selects between udp and tcp when creating sockets to simplify terminology  when in an internet context  we refer to the 4-pdu as a segment we mention  however  that the internet literature  e.g  the rfcs  also refers to the pdu for tcp as a segment but often refers to the pdu for udp as a datagram but this same internet literature also uses the terminology datagram for the network-layer pdu ! for an introductory book on computer networking such as this one  we believe that it is less confusing to refer to both tcp and udp pdus as segments  and reserve the terminology datagram for the network-layer pdu before preceding with our brief introduction of udp and tcp  it is useful to say a few words about the internet 's network layer  the network layer is examined in detail in chapter 4  the internet 's network-layer protocol has a name  ip  which abbreviates " internet protocol "  ip provides logical communication between hosts the ip service model is a best-effort delivery service this means that ip makes its " best effort " to deliver segments between communicating hosts  but it makes no guarantees in particular  it does not guarantee segment delivery  it does not guarantee orderly delivery of segments  and it does it guarantee the integrity of the data in the segments for these reasons  ip is said to be an unreliable service we also mention here that every host has an ip address we will examine ip addressing in detail in chapter 4 ; for this chapter we need only keep in mind that each host has a unique ip address having taken a glimpse at the ip service model  let 's now summarize the service model of udp and tcp the most fundamental responsibility of udp and tcp is to extend ip 's delivery service between two end systems to a delivery service between two processes running on the end systems extending host-to-host delivery to process-to-process delivery is called application multiplexing and demultiplexing we 'll discuss application multiplexing and demultiplexing in the next section udp and tcp also provide integrity checking by including error detection fields in its header these two minimal transport-layer services  hostto host data delivery and error checking  are the only two services that udp provides ! in particular  like ip  udp is an unreliable service  it does not guarantee data sent by one process will arrive in tact to the destination process udp is discussed in detail in section 3.3 tcp  on the other hand  offers several additional services to applications first and foremost  it provides reliable data transfer using flow control  sequence numbers  acknowledgments and timers  techniques we 'll explore in detail in this chapter   tcp 's guarantee of reliable data transfer ensures that data is delivered from sending process to receiving process  correctly and in order tcp thus converts ip 's unreliable service file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/transport_layer.htm  4 of 5  20/11/2004 15  52  04 the transport layer  overview between end systems into a reliable data transport service between processes tcp also uses congestion control congestion control is not so much a service provided to the invoking application as it is a service for the internet as a whole  a service for the general good in loose terms  tcp congestion control prevents any one tcp connection from swamping the links and switches between communicating hosts with an excessive amount of traffic in principle  tcp permits tcp connections traversing a congested network link to equally share that link 's bandwidth this is done by regulating the rate at which an the sending-side tcps can send traffic into the network udp traffic  on the other hand  is unregulated a an application using udp transport can send traffic at any rate it pleases  for as long as it pleases a protocol that provides reliable data transfer and congestion control is necessarily complex we will need several sections to cover the principles of reliable data transfer and congestion control  and additional sections to cover the tcp protocol itself these topics are investigated in sections 3.4 through 3.8 the approach taken in this chapter is to alternative between the basic principles and the tcp protocol for example  we first discuss reliable data transfer in a general setting and then discuss how tcp specifically provides reliable data transfer similarly  we first discuss congestion control in a general setting and then discuss how tcp uses congestion control but before getting into all this good stuff  let 's first look at application multiplexing and demultiplexing in the next section return to table of contents copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/transport_layer.htm  5 of 5  20/11/2004 15  52  04 multiplexing and demultiplexing network applications 3.2 multiplexing and demultiplexing applications in this section we discuss the multiplexing/demultiplexing of messages by the transport layer from/to the application layer in order to keep the discussion concrete  we 'll discuss this basic service in the context of the internet 's transport layer we emphasize  however  that multiplexing and demultiplexing services are provided in almost every protocol architecture ever designed moreover  multiplexing/demultiplexing are generic services  often found in several layers within a given protocol stack although the multiplexing/demultiplexing service is not among the most exciting services that can be provided by a transport layer protocol  it is an absolutely critical one to understand why it so critical  consider the fact that ip delivers data between two end systems  with each end system identified with a unique ip address ip does not deliver data between the application processes that run on these end systems extending host-to-host delivery to a process-to-process delivery is the job of the transport layer 's application multiplexing and demultiplexing service at the destination host  the transport layer receives segments  i.e  transport-layer pdus  from the network layer just below the transport layer has the responsibility of delivering the data in these segments to the appropriate application process running in the host let 's take a look at an example suppose you are sitting in front of your computer  and you are downloading web pages while running one ftp session and two telnet sessions you therefore have four network application processes running  two telnet processes  one ftp process  and one http process when the transport layer in your computer receives data from the network layer below  it needs to direct the received data to one of these four processes let 's now examine how this is done each transport-layer segment has a field that contains information that is used to determine the process to which the segment 's data is to be delivered at the receiving end  the transport layer can then examine this field to determine the receiving process  and then direct the segment to that process this job of delivering the data in a transport-layer segment to the correct application process is called demultiplexing the job of gathering data at the source host from different application processes  enveloping the data with header information  which will later be used in demultiplexing  to create segments  and passing the segments to the network layer is called multiplexing to illustrate the demultiplexing job  let us return to the household saga in the previous section each of the kids is distinguished by his or her name when bob receives a batch of mail from the mail person  he performs a demultiplexing operation by observing to whom the letters are addressed and then hand delivering the mail to his brothers and sisters alice performs a multiplexing operation when she collects letters from her brothers and sisters and gives the collected mail to the mail person udp and tcp perform the demultiplexing and multiplexing jobs by including two special fields in the segment headers  the source port number field and the destination port number field these two fields are illustrated in figure 3.2-1 when taken together  the fields uniquely identify an application process running on the destination host  the udp and tcp segments have other fields as well  and they will be addressed in the subsequent sections of this chapter  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/fund.html  1 of 4  20/11/2004 15  52  04 multiplexing and demultiplexing network applications figure 3.2-1  source and destination port number fields in a transport layer segment the notion of port numbers was briefly introduced in sections 2.6-2.7  in which we studied application development and socket programming the port number is a 16-bit number  ranging from from 0 to 65535 the port numbers ranging from 0  1023 are called well-known port numbers and are restricted  which means that they are reserved for use by well-known application protocols such as http and ftp http uses port number 80 ; ftp uses port number 21 the list of well-known port numbers is given in  rfc 1700   when we develop a new application  such as one of the applications developed in sections 2.6-2.8   we must assign the application a port number given that each type of application running on an end system has a unique port number  then why is it that the transport-layer segment has fields for two port numbers  a source port number and a destination port number ? the answer is simple  an end system may be running two processes of same type at the same time  and thus the port number of an application may not suffice to identify a specific process for example  many web servers spawn a new http process for every request it receives ; whenever such a web server is servicing more than one request  which is by no means uncommon   the server is running more than one process with port number 80 therefore  in order to uniquely identify processes  a second port number is needed how is this second port number created ? which port number goes in the source port number field of a segment ? which goes in the destination port number field of a segment ? to answer these questions  recall from section 2.1 that networked applications are organized around the client-server model typically  the host that initiates the application is the client and the other host is the server now let 's look at a specific example suppose the application has port number 23  the port number for telnet   consider a transport layer segment leaving the client  i.e  the host that initiated the telnet session  and destined for the server what are the destination and source port numbers for this segment ? for the destination port number  this segment has the port number of the application  namely  23 for the source port number  the client uses a number that is not being used by any of its other processes  this is can be done automatically by the transport-layer software running on the client and is transparent to the application developer an application can also explicitly request a specific port number using the bind   system call on many unix-like systems  let 's say the client chooses port number x then each segment that this process sends will have its source port number set to x and destination port number set to 23 when the segment arrives at the server  the source and destination port numbers in the segment enable the server host to pass the data of the segment to the correct application process  the destination port number 23 identifies a telnet process and the source port number x identifies the specific telnet process the situation is reversed for the segments flowing from the server to the client the source port number is now the application port number  23 the destination port number is now x  the same x used for the source port number for the segments sent from client to server  when a segment arrives at the client  the source and destination port file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/fund.html  2 of 4  20/11/2004 15  52  04 multiplexing and demultiplexing network applications numbers in the segment will enable the client host to pass the data of the segment to the correct application process  which is identified by the port number pair figure 3.2-2 summarizes the discussion  figure 3.2-2  use of source and destination port numbers in a client-server application now you may be wondering  what happens if two different clients establish a telnet session to a server  and each of these clients choose the same source port number x ? how will the server be able to demultiplex the segments when the two sessions have exactly the same port number pair ? the answer to this question is that server also uses the ip addresses in the ip datagrams carrying these segments  we will discuss ip datagrams and addressing in detail in chapter 4  the situation is illustrated in figure 3.2-3  in which host a initiates two telnet sessions to host c  and host a initiates one telnet session to host c hosts a  b and c each have their own unique ip address ; host a has ip address a  host b has ip address b  and host c has ip address c host a assigns two different source port  sp  numbers  x and y  to the two telnet connections emanating from host a but because host b is choosing source port numbers independently from a  it can also assign sp = x to its telnet connection nevertheless  host c is still able to demultiplex the two connections since the two connections have different source ip addresses in summary  we see that when a destination host receives data from the network layer  the triplet  source ip address  source port number  destination port number  is used to forward the data to the appropriate process file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/fund.html  3 of 4  20/11/2004 15  52  04 multiplexing and demultiplexing network applications figure 3.2-3  two clients  using the same port numbers to communicate with the same server application now that we understand how the transport layer can multiplex and demultiplex messages from/to network applications  let 's move on and discuss one of the internet 's transport protocols  udp in the next section we shall see that udp adds little more to the network layer protocol than multiplexing/demultiplexing service references  rfc 1700  j reynolds and j postel  " assigned numbers  " rfc 1700  october 1994 return to table of contents copyright 1996-2000 keith w ross and james f kurose file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/fund.html  4 of 4  20/11/2004 15  52  04 udp  the user datagram protocol 3.3 connectionless transport  udp the internet makes two transport protocols available to its applications  udp and tcp in this section we take a close look at udp  how it works and what it does the reader is encouraged to refer back to material in section 2.1  which includes an overview of the udp service model  and to the material in section 2.7  which discusses socket programming over udp to motivate our discussion about udp  suppose you were interested in designing a no-frills  bare-bones transport protocol how might you go about doing this ? you might first consider using a vacuous transport protocol in particular  on the sending side  you might consider taking the messages from the application process and passing them directly to the network layer ; and on the receiving side  you might consider taking the messages arriving from the network layer and passing them directly to the application process but as we learned in the previous section  we have to do a little more than nothing at the very least  the transport layer must provide a multiplexing/demultiplexing service in order to pass data between the network layer and the correct application udp  defined in  rfc 768   does just about as little as a transport protocol can aside from the multiplexing/demultiplexing function and some light error checking  it adds nothing to ip in fact  if the application developer chooses udp instead of tcp  then the application is talking almost directly with ip udp takes messages from application process  attaches source and destination port number fields for the multiplexing/demultiplexing service  adds two other fields of minor importance  and passes the resulting " segment " to the network layer the network layer encapsulates the segment into an ip datagram and then makes a best-effort attempt to deliver the segment to the receiving host if the segment arrives at the receiving host  udp uses the port numbers and the ip source and destination addresses to deliver the data in the segment to the correct application process note that with udp there is no handshaking between sending and receiving transport-layer entities before sending a segment for this reason  udp is said to be connectionless dns is an example of an application-layer protocol that uses udp when the dns application  see section 2.5  in a host wants to make a query  it constructs a dns query message and passes the message to a udp socket  see section 2.7   without performing any handshaking  udp adds a header fields to the message and passes the resulting segment to the network layer the network layer encapsulates the udp segment into a datagram and sends the datagram to a name server the dns application at the querying host then waits for a reply to its query if it does n't receive a reply  possibly because udp lost the query or the reply   it either tries sending the query to another nameserver  or it informs the invoking application that it ca n't get a reply we mention that the dns specification permits dns to run over tcp instead of udp ; in practice  however  dns almost always runs over udp now you might be wondering why an application developer would ever choose to build an application over udp rather than over tcp is n't tcp always preferable to udp since tcp provides a reliable data file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  1 of 7  20/11/2004 15  52  05 udp  the user datagram protocol transfer service and udp does not ? the answer is no  as many applications are better suited for udp for the following reasons  l no connection establishment as we shall discuss in section 3.5  tcp uses a three-way handshake before it starts to transfer data udp just blasts away without any formal preliminaries thus udp does not introduce any delay to establish a connection this is probably the principle reason why dns runs over udp rather than tcp  dns would be much slower if it ran over tcp http uses tcp rather than udp  since reliability is critical for web pages with text but  as we briefly discussed in section 2.2  the tcp connection establishment delay in http is an important contributor to the " world wide wait "  l no connection state tcp maintains connection state in the end systems this connection state includes receive and send buffers  congestion control parameters  and sequence and acknowledgment number parameters we will see in section 3.5 that this state information is needed to implement tcp 's reliable data transfer service and to provide congestion control udp  on the other hand  does not maintain connection state and does not track any of these parameters for this reason  a server devoted to a particular application can typically support many more active clients when the application runs over udp rather than tcp l small segment header overhead the tcp segment has 20 bytes of header overhead in every segment  whereas udp only has 8 bytes of overhead l unregulated send rate tcp has a congestion control mechanism that throttles the sender when one or more links between sender and receiver becomes excessively congested this throttling can have a severe impact on real-time applications  which can tolerate some packet loss but require a minimum send rate on the other hand  the speed at which udp sends data is only constrained by the rate at which the application generates data  the capabilities of the source  cpu  clock rate  etc  and the access bandwidth to the internet we should keep in mind  however  that the receiving host does not necessarily receive all the data  when the network is congested  a significant fraction of the udp-transmitted data could be lost due to router buffer overflow thus  the receive rate is limited by network congestion even if the sending rate is not constrained table 3.1-1 lists popular internet applications and the transport protocols that they use as we expect  email  remote terminal access  the web and file transfer run over tcp  these applications need the reliable data transfer service of tcp nevertheless  many important applications run over udp rather tcp udp is used for rip routing table updates  see chapter 4 on the network layer   because the updates are sent periodically  so that lost updates are replaced by more up-to-date updates udp is used to carry network management  snmp  see chapter 8  data udp is preferred to tcp in this case  since network management must often run when the network is in a stressed state  precisely when reliable  congestion-controlled data transfer is difficult to achieve also  as we mentioned earlier  dns runs over udp  thereby avoiding tcp 's connection establishment delays application application-layer protocol underlying transport protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  2 of 7  20/11/2004 15  52  05 udp  the user datagram protocol electronic mail smtp tcp remote terminal access telnet tcp web http tcp file transfer ftp tcp remote file server nfs typically udp streaming multimedia proprietary typically udp internet telephony proprietary typically udp network management snmp typically udp routing protocol rip typically udp name translation dns typically udp figure 3.1-1  popular internet applications and their underlying transport protocols as shown in figure 3.1-1  udp is also commonly used today with multimedia applications  such as internet phone  real-time video conferencing  and streaming of stored audio and video we shall take a close look at these applications in chapter 6 we just mention now that all of these applications can tolerate a small fraction of packet loss  so that reliable data transfer is not absolutely critical for the success of the application furthermore  interactive real-time applications  such as internet phone and video conferencing  react very poorly to tcp 's congestion control for these reasons  developers of multimedia applications often choose to run the applications over udp instead of tcp finally  because tcp can not be employed with multicast  multicast applications run over udp although commonly done today  running multimedia applications over udp is controversial to say the least as we mentioned above  udp lacks any form of congestion control but congestion control is needed to prevent the network from entering a congested state in which very little useful work is done if everyone were to start streaming high bit-rate video without using any congestion control  there would be so much packet overflow at routers that no one would see anything thus  the lack of congestion control in udp is a potentially serious problem many researchers have proposed new mechanisms to force all sources  including udp sources  to perform adaptive congestion control  mahdavi   before discussing the udp segment structure  we mention that it is possible for an application to have reliable data transfer when using udp this can be done if reliability is built into the application itself  e g  by adding acknowledgement and retransmission mechanisms  such as those we shall study in the next section   but this a non-trivial task that would keep an application developer busy debugging for a long time nevertheless  building reliability directly into the application allows the application to " have its cake and eat it too "  that is  application processes can communicate reliably without being constrained by the transmission rate constraints imposed by tcp 's congestion control mechanism application-level file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  3 of 7  20/11/2004 15  52  05 udp  the user datagram protocol reliability also allows an application to tailor its own application-specific form of error control an interactive real-time may occasionally choose to retransmit a lost message  provided that round trip network delays are small enough to avoid adding significant playout delays  papadopoulos 1996   many of today 's proprietary streaming applications do just this  they run over udp  but they have built acknowledgements and retransmissions into the application in order reduce packet loss udp segment structure the udp segment structure  shown in figure 3.3-2  is defined in  rfc 768   figure 3.3-2  udp segment structure the application data occupies the data field of the udp datagram for example  for dns  the data field contains either a query message or a response message for a streaming audio application  audio samples fill the data field the udp header has only four fields  each consisting of four bytes as discussed in the previous section  the port numbers allow the destination host to pass the application data to the correct process running on that host  i.e  perform the demultiplexing function   the checksum is used by the receiving host to check if errors have been introduced into the segment during the course of its transmission from source to destination  basic principles of error detection are described in section 5.2   udp checksum the udp checksum provides for error detection udp at the sender side performs the one 's complement file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  4 of 7  20/11/2004 15  52  05 udp  the user datagram protocol of the sum of all the 16-bit words in the segment this result is put in the checksum field of the udp segment  in truth  the checksum is also calculated over a few of the fields in the ip header in addition to the udp segment but we ignore this detail in order to see the forest through the trees  when the segment arrives  if it arrives !  at the receiving host  all 16-bit words are added together  including the checksum if this sum equals 1111111111111111  then the segment has no detected errors if one of the bits is a zero  then we know that errors have been introduced into the segment here we give a simple example of the checksum calculation you can find details about efficient implementation of the calculation in the  rfc 1071   as an example  suppose that we have the following three 16-bit words  0110011001100110 0101010101010101 0000111100001111 the sum of first of these 16-bit words is  0110011001100110 0101010101010101  1011101110111011 adding the third word to the above sum gives 1011101110111011 0000111100001111  1100101011001010 the 1 's complement is obtained by converting all the 0s to 1s and converting all the 1s to 0s thus the 1 's complement of the sum 1100101011001010 is 0011010100110101  which becomes the checksum at the receiver  all four 16-bit words are added  including the checksum if no errors are introduced into the segment  then clearly the sum at the receiver will be 1111111111111111 if one of the bits is a zero  then we know that errors have been introduced into the segment in section 5.1  we 'll see that the internet checksum is not foolproof  even if the sum equals 111111111111111  it is still possible that there are undetected errors in the segment for this reason  a number of protocols use more sophisticated error detection techniques than simple checksumming you may wonder why udp provides a checksum in the first place  as many link-layer protocols  including the popular ethernet protocol  also provide error checking ? the reason is that there is no guarantee that all the links between source and destination provide error checking  one of the links may use a protocol that does not provide error checking because ip is supposed to run over just about file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  5 of 7  20/11/2004 15  52  05 udp  the user datagram protocol any layer-2 protocol  it is useful for the transport layer to provide error checking as a safety measure although udp provides error checking  it does not do anything to recover from an error some implementations of udp simply discard the damaged segment ; others pass the damaged segment to the application with a warning that wraps up our discussion of udp we will soon see that tcp offers reliable data transfer to its applications as well as other services that udp does n't offer naturally  tcp is also more complex than udp before discussing tcp  however  it will be useful to step back and first discuss the underlying principles of reliable data transfer  which we do in the subsequent section we will then explore tcp in section 3.5  where we will see that tcp has it foundations in these underlying principles references  papadopoulos 1996  c papadopoulos and g parulkar  " retransmission-based error control for continuous media applications  " proceedings of the 6th international workshop on network and operating system support for digital audio and video  nossdav   april 1996  mahdavi  j mahdavi and s floyd  " the tcp-friendly website  " http  //www.psc.edu/networking/ tcp_friendly.html  rfc 768  j.postel  " user datagram protocol  " rfc 768  august 1980  rfc 1071  r braden  d borman  c partridge  " computing the internet checksum  " rfc 1071  september 1988 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  6 of 7  20/11/2004 15  52  05 udp  the user datagram protocol return to table of contents copyright keith w ross and james f kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/udp.html  7 of 7  20/11/2004 15  52  05 principle of reliable data transfer 3.4 principles of reliable data transfer in this section  we consider the problem of reliable data transfer in a general context this is appropriate since the problem of implementing reliable data transfer occurs not only at the transport layer  but also at the link layer and the application layer as well the general problem is thus of central importance to networking indeed  if one had to identify a ` ` top-10' ' list of fundamentally important problems in all of networking  this would be a top candidate to lead that list in the next section we will examine tcp and show  in particular  that tcp exploits many of the principles that we are about to describe figure 3.4-1  reliable data transfer  service model and service implementation figure 3.4-1 illustrates the framework for our study of reliable data transfer the service abstraction provided to the upper layer entities is that of a reliable channel through which data can be transferred with a reliable channel  no transferred data bits are corrupted  flipped from 0 to 1  or vice versa  or lost  and all are delivered in the order in which they were sent this is precisely the service model offered by tcp to the internet applications that invoke it it is the responsibility of a reliable data transfer protocol to implement this service abstraction this task is made difficult by the fact that layer below the reliable data transfer protocol may be unreliable for example  tcp is a reliable data transfer protocol that is implemented on top of an unreliable  ip  end-end network layer more generally  the layer beneath the two reliablycommunicating endpoints might consist of a single physical link  e.g  as in the case of a link-level data transfer protocol  or a global internetwork  e.g  as in the case of a transport-level protocol   for our purposes  however  we can view this lower layer simply as an unreliable point-to-point channel in this section  we will incrementally develop the sender and receiver sides of a reliable data transfer protocol  considering increasingly complex models of the underlying channel figure 3.4-1  b  illustrates the interfaces for our data transfer protocol the sending side of the data transfer protocol will be invoked from above by a call to rdt_send    it will be passed the data to be delivered to the upper-layer at the receiving side  here rdt stands for ` ` reliable data transfer' ' protocol and _send indicates that the sending side of rdt is being called the first step in developing any protocol is to choose a good name !  on the receiving side  rdt_rcv   will be called when a packet arrives from the receiving side of the channel when the rdt protocol wants to deliver data to the upper-layer  it will do so by calling deliver_data    in the following we use the terminology " packet " rather than " segment " for the protocol data unit because the theory developed in this section applies to computer networks in general  and file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  1 of 20  20/11/2004 15  52  08 principle of reliable data transfer not just to the internet transport layer  the generic term " packet " is perhaps more appropriate here in this section we consider only the case of unidirectional data transfer  i.e  data transfer from the sending to receiving side the case of reliable bidirectional  i.e  full duplex  data transfer is conceptually no more difficult but considerably more tedious although we consider only unidirectional data transfer  it is important to note that the sending and receiving sides of our protocol will nonetheless need to transmit packets in both directions  as indicated in figure 3.4-1 we will see shortly that in addition to exchanging packets containing the data to be transferred  the sending and receiving sides of rdt will also need to exchange control packets back and forth both the send and receive sides of rdt send packets to the other side by a call to udt_send    unreliable data transfer   3.4.1 building a reliable data transfer protocol reliable data transfer over a perfectly reliable channel  rdt1.0 we first consider the simplest case in which the underlying channel is completely reliable the protocol itself  which we will call rdt1.0  is trivial the finite state machine  fsm  definitions for the rdt1.0 sender and receiver are shown in figure 3.4-2 the sender and receiver fsms in figure 3.4-2 each have just one state the arrows in the fsm description indicate the transition of the protocol from one state to another  since each fsm in figure 3.4-2 has just one state  a transition is necessarily from the one state back to itself ; we 'll see more complicated state diagrams shortly   the event causing the transition is shown above the horizontal line labeling the transition  and the action  s  taken when the event occurs are shown below the horizontal line the sending side of rdt simply accepts data from the upper-layer via the rdt_send  data  event  puts the data into a packet  via the action make_pkt  packet,data   and sends the packet into the channel in practice  the rdt_send  data  event would result from a procedure call  e.g  to rdt_send    by the upper layer application on the receiving side  rdt receives a packet from the underlying channel via the rdt_rcv  packet  event  removes the data from the packet  via the action extract  packet,data   and passes the data up to the upper-layer in practice  the rdt_rcv  packet  event would result from a procedure call  e.g  to rdt_rcv    from the lower layer protocol in this simple protocol  there is no difference between a unit of data and a packet also  all packet flow is from the sender to receiver  with a perfectly reliable channel there is no need for the receiver side to provide any feedback to the sender since nothing can go wrong ! figure 3.4-2  rdt1.0  a protocol for a completely reliable channel reliable data transfer over a channel with bit errors  rdt2.0 a more realistic model of the underlying channel is one in which bits in a packet may be corrupted such bit errors typically occur in the physical components of a network as a packet is transmitted  propagates  or is buffered we 'll continue to assume for the file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  2 of 20  20/11/2004 15  52  08 principle of reliable data transfer moment that all transmitted packets are received  although their bits may be corrupted  in the order in which they were sent before developing a protocol for reliably communicating over such a channel  first consider how people might deal with such a situation consider how you yourself might dictate a long message over the phone in a typical scenario  the message taker might say ` ` ok' ' after each sentence has been heard  understood  and recorded if the message taker hears a garbled sentence  you 're asked to repeat the garbled sentence this message dictation protocol uses both positive acknowledgements  ` ` ok' '  and negative acknowledgements  ` ` please repeat that' '   these control messages allow the receiver to let the sender know what has been received correctly  and what has been received in error and thus requires repeating in a computer network setting  reliable data transfer protocols based on such retransmission are known arq  automatic repeat request  protocols fundamentally  two additional protocol capabilities are required in arq protocols to handle the presence of bit errors  l error detection first  a mechanism is needed to allow the receiver to detect when bit errors have occurred recall from sections 3.3 that the udp transport protocol uses the internet checksum field for exactly this purpose in chapter 5 we 'll examine error detection and correction techniques in greater detail ; these techniques allow the receiver to detect  and possibly correct packet bit errors for now  we need only know that these techniques require that extra bits  beyond the bits of original data to be transferred  be sent from the sender to receiver ; these bits will be gathered into the packet checksum field of the rdt2.0 data packet l receiver feedback since the sender and receiver are typically executing on different end systems  possibly separated by thousands of miles  the only way for the sender to learn of the receiver 's view of the world  in this case  whether or not a packet was received correctly  is for the receiver to provide explicit feedback to the sender the positive  ack  and negative acknowledgement  nak  replies in the message dictation scenario are an example of such feedback our rdt2.0 protocol will similarly send ack and nak packets back from the receiver to the sender in principle  these packets need only be one bit long  e.g  a zero value could indicate a nak and a value of 1 could indicate an ack figure 3.4-3 shows the fsm representation of rdt2.0  a data transfer protocol employing error detection  positive acknowledgements  acks   and negative acknowledgements  naks   the send side of rdt2.0 has two states in one state  the send-side protocol is waiting for data to be passed down from the upper layer in the other state  the sender protocol is waiting for an ack or a nak packet from the receiver if an ack packet is received  the notation rdt_rcv  rcvpkt  && isack  rcvpkt  in figure 3.4-3 corresponds to this event   the sender knows the most recently transmitted packet has been received correctly and thus the protocol returns to the state of waiting for data from the upper layer if a nak is received  the protocol retransmits the last packet and waits for an ack or nak to be returned by the receiver in response to the retransmitted data packet it is important to note that when the receiver is in the wait-for-ack-or-nak state  it can not get more data from the upper layer ; that will only happen after the sender receives an ack and leaves this state thus  the sender will not send a new piece of data until it is sure that the receiver has correctly received the current packet because of this behavior  protocols such as rdt2.0 are known as stop-and-wait protocols the receiver-side fsm for rdt2.0 still has a single state on packet arrival  the receiver replies with either an ack or a nak  depending on whether or not the received packet is corrupted in figure 3.4-3  the notation rdt_rcv  rcvpkt  && corrupt  rcvpkt  corresponds to the event where a packet is received and is found to be in error file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  3 of 20  20/11/2004 15  52  08 principle of reliable data transfer figure 3.4-3  rdt2.0  a protocol for a channel with bit-errors protocol rdt2.0 may look as if it works but unfortunately has a fatal flaw in particular  we have n't accounted for the possibility that the ack or nak packet could be corrupted !  before proceeding on  you should think about how this problem may be fixed  unfortunately  our slight oversight is not as innocuous as it may seem minimally  we will need to add checksum bits to ack/ nak packets in order to detect such errors the more difficult question is how the protocol should recover from errors in ack or nak packets the difficulty here is that if an ack or nak is corrupted  the sender has no way of knowing whether or not the receiver has correctly received the last piece of transmitted data consider three possibilities for handling corrupted acks or naks  l for the first possibility  consider what a human might do in the message dictation scenario if the speaker did n't understand the ` ` ok' ' or ` ` please repeat that' ' reply from the receiver  the speaker would probably ask ` ` what did you say ? ' '  thus introducing a new type of sender-to-receiver packet to our protocol   the speaker would then repeat the reply but what if the speaker 's ` ` what did you say' ' is corrupted ? the receiver  having no idea whether the garbled sentence was part of the dictation or a request to repeat the last reply  would probably then respond with ` ` what did you say ? ' ' and then  of course  that response might be garbled clearly  we 're heading down a difficult path l a second alternative is to add enough checksum bits to allow the sender to not only detect  but recover from  bit errors this solves the immediate problem for a channel which can corrupt packets but not lose them l a third approach is for the sender to simply resend the current data packet when it receives a garbled ack or nak packet this  however  introduces duplicate packets into the sender-to-receiver channel the fundamental difficulty with duplicate packets is that the receiver does n't know whether the ack or nak it last sent was received correctly at the sender thus  it can not know a priori whether an arriving packet contains new data or is a retransmission ! a simple solution to this new problem  and one adopted in almost all existing data transfer protocols including tcp  is to add a new field to the data packet and have the sender number its data packets by putting a sequence number into this field the receiver then need only check this sequence number to determine whether or not the received packet is a retransmission for this simple case of a stop-and-wait protocol  a 1-bit sequence number will suffice  since it will allow the receiver to know whether the sender is resending the previously transmitted packet  the sequence number of the received packet has the same sequence number file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  4 of 20  20/11/2004 15  52  08 principle of reliable data transfer as the most recently received packet  or a new packet  the sequence number changes  i.e  moves ` ` forward' ' in modulo 2 arithmetic   since we are currently assuming a channel that does not lose packets  ack and nak packets do not themselves need to indicate the sequence number of the packet they are acking or naking  since the sender knows that a received ack or nak packet  whether garbled or not  was generated in response to its most recently transmitted data packet figure 3.4-4  rdt2.1 sender file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  5 of 20  20/11/2004 15  52  08 principle of reliable data transfer figure 3.4-5  rdt2.1 recevier figures 3.4-4 and 3.4-5 show the fsm description for rdt2.1  our fixed version of rdt2.0 the rdt2.1 sender and receiver fsm 's each now have twice as many states as before this is because the protocol state must now reflect whether the packet currently being sent  by the sender  or expected  at the receiver  should have a sequence number of 0 or 1 note that the actions in those states where a 0-numbered packet is being sent or expected are mirror images of those where a 1-numbered packet is being sent or expected ; the only differences have to do with the handling of the sequence number protocol rdt2.1 uses both positive and negative acknowledgements from the receiver to the sender a negative acknowledgement is sent whenever a corrupted packet  or an out of order packet  is received we can accomplish the same effect as a nak if instead of sending a nak  we instead send an ack for the last correctly received packet a sender that receives two acks for the same packet  i.e  receives duplicate acks  knows that the recevier did not correctly receive the packet following the packet that is being acked twice many tcp implementations use the receipt of so-called " triple duplicate acks "  three ack packets all ack'ing the same packet  to trigger a retransmission at the sender our nak-free reliable data transfer protocol for a channel with bit errors is rdt2.2  shown in figure 3.4-6 and 3.4-7 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  6 of 20  20/11/2004 15  52  08 principle of reliable data transfer figure 3.4-6  rdt2.2 sender file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  7 of 20  20/11/2004 15  52  08 principle of reliable data transfer figure 3.4-7  rdt2.2 receiver reliable data transfer over a lossy channel with bit errors  rdt3.0 suppose now that in addition to corrupting bits  the underlying channel can lose packets as well  a not uncommon event in today 's computer networks  including the internet   two additional concerns must now be addressed by the protocol  how to detect packet loss and what to do when this occurs the use of checksumming  sequence numbers  ack packets  and retransmissions  the techniques already developed in rdt 2.2  will allow us to answer the latter concern handling the first concern will require adding a new protocol mechanism there are many possible approaches towards dealing with packet loss  several more of which are explored in the exercises at the end of the chapter   here  we 'll put the burden of detecting and recovering from lost packets on the sender suppose that the sender transmits a data packet and either that packet  or the receiver 's ack of that packet  gets lost in either case  no reply is forthcoming at the sender from the receiver if the sender is willing to wait long enough so that it is certain that a packet has been lost  it can simply retransmit the data packet you should convince yourself that this protocol does indeed work but how long must the sender wait to be certain that something has been lost ? it must clearly wait at least as long as a round trip delay between the sender and receiver  which may include buffering at intermediate routers or gateways  plus whatever amount of time is needed to process a packet at the receiver in many networks  this worst case maximum delay is very difficult to even estimate  much less know with certainty moreover  the protocol should ideally recover from packet loss as soon as possible ; waiting for a worst case delay could mean a long wait until error recovery is initiated the approach thus adopted in practice is for the sender to ` ` judiciously' ' chose a time value such that packet loss is likely  although not guaranteed  to have happened if an ack is not received within this time  the packet is retransmitted note that if a packet experiences a particularly large delay  the sender may retransmit the packet even though neither the data packet nor its ack have been lost this introduces the possibility of duplicate data packets in the sender-to-receiver channel happily  protocol rdt2.2 already has enough functionality  i.e  sequence numbers  to handle the case of duplicate packets file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  8 of 20  20/11/2004 15  52  08 principle of reliable data transfer from the sender 's viewpoint  retransmission is a panacea the sender does not know whether a data packet was lost  an ack was lost  or if the packet or ack was simply overly delayed in all cases  the action is the same  retransmit in order to implement a time-based retransmission mechanism  a countdown timer will be needed that can interrupt the sender after a given amount of timer has expired the sender will thus need to be able to  i  start the timer each time a packet  either a first time packet  or a retransmission  is sent   ii  respond to a timer interrupt  taking appropriate actions   and  iii  stop the timer the existence of sender-generated duplicate packets and packet  data  ack  loss also complicates the sender 's processing of any ack packet it receives if an ack is received  how is the sender to know if it was sent by the receiver in response to its  sender 's  own most recently transmitted packet  or is a delayed ack sent in response to an earlier transmission of a different data packet ? the solution to this dilemma is to augment the ack packet with an acknowledgement field when the receiver generates an ack  it will copy the sequence number of the data packet being ack'ed into this acknowledgement field by examining the contents of the acknowledgment field  the sender can determine the sequence number of the packet being positively acknowledged figure 3 4-8  rdt 3.0 sender fsm file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/principles_rdt.htm  9 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-9  operation of rdt 3.0  the alternating bit protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  10 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-8 shows the sender fsm for rdt3.0  a protocol that reliably transfers data over a channel that can corrupt or lose packets figure 3.4-9 shows how the protocol operates with no lost or delayed packets  and how it handles lost data packets in figure 3.4-9  time moves forward from the top of the diagram towards the bottom of the diagram ; note that a receive time for a packet is neccessarily later than the send time for a packet as a result of transmisison and propagation delays in figures 3.4-9  b    d   the send-side brackets indicate the times at which a timer is set and later times out several of the more subtle aspects of this protocol are explored in the exercises at the end of this chapter because packet sequence numbers alternate between 0 and 1  protocol rdt3.0 is sometimes known as the alternating bit protocol we have now assembled the key elements of a data transfer protocol checksums  sequence numbers  timers  and positive and negative acknowledgement packets each play a crucial and necessary role in the operation of the protocol we now have a working reliable data transfer protocol ! 3.4.2 pipelined reliable data transfer protocols protocol rdt3.0 is a functionally correct protocol  but it is unlikely that anyone would be happy with its performance  particularly in today 's high speed networks at the heart of rdt3.0 's performance problem is the fact that it is a stop-and-wait protocol to appreciate the performance impact of this stop-and-wait behavior  consider an idealized case of two end hosts  one located on the west coast of the united states and the other located on the east cost the speed-of-light propagation delay  tprop  between these two end systems is approximately 15 milliseconds suppose that they are connected by a channel with a capacity  c  of 1 gigabit  10 * * 9 bits  per second with a packet size  sp  of 1k bytes per packet including both header fields and data  the time needed to actually transmit the packet into the 1gbps link is ttrans = sp/c =  8 kbits/packet  /  10 * * 9 bits/sec  = 8 microseconds with our stop and wait protocol  if the sender begins sending the packet at t = 0  then at t = 8 microsecs the last bit enters the channel at the sender side the packet then makes its 15 msec cross country journey  as depicted in figure 3.4-10a  with the last bit of the packet emerging at the receiver at t = 15.008 msec assuming for simplicity that ack packets are the same size as data packets and that the receiver can begin sending an ack packet as soon as the last bit of a data packet is received  the last bit of the ack packet emerges back at the receiver at t = 30.016 msec thus  in 30.016 msec  the sender was only busy  sending or receiving  for .016 msec if we define the utilization of the sender  or the channel  as the fraction of time the sender is actually busy sending bits into the channel  we have a rather dismal sender utilization  usender  of usender =  .008/ 30.016  = 0.00015 that is  the sender was busy only 1.5 hundredths of one percent of the time viewed another way  the sender was only able to send 1k bytes in 30.016 milliseconds  an effective throughput of only 33kb/sec  even thought a 1gigabit per second link was available ! imagine the unhappy network manager who just paid a fortune for a gigabit capacity link but manages to get a throughput of only 33kb ! this is a graphic example of how network protocols can limit the capabilities provided by the underlying network hardware also  we have neglected lower layer protocol processing times at the sender and receiver  as well as the processing and queueing delays that would occur at any intermediate routers between the sender and receiver including these effects would only serve to further increase the delay and further accentuate the poor performance file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  11 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-10  stop-and-wait versus pipelined protocols the solution to this particular performance problem is a simple one  rather than operate in a stop-and-wait manner  the sender is allowed to send multiple packets without waiting for acknowledgements  as shown in figure 3.4-10  b   since the many in-transit sender-to-receiver packets can be visualized as filling a pipeline  this technique is known as pipelining pipelining has several consequences for reliable data transfer protocols  l the range of sequence numbers must be increased  since each in-transit packet  not counting retransmissions  must have a unique sequence number and there may be multiple  in-transit  unacknowledged packets l the sender and receiver-sides of the protocols may have to buffer more than one packet minimally  the sender will have to buffer packets that have been transmitted  but not yet acknowledged buffering of correctly-received packets may also be needed at the receiver  as discussed below the range of sequence numbers needed and the buffering requirements will depend on the manner in which a data transfer protocol responds to lost  corrupted  and overly delayed packets two basic approaches towards pipelined error recovery can be identified  go-back-n and selective repeat 3.4.3 go-back-n  gbn  figure 3.4-11  sender 's view of sequence numbers in go-back-n in a go-back-n  gbn  protocol  the sender is allowed to transmit multiple packets  when available  without waiting for an file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  12 of 20  20/11/2004 15  52  09 principle of reliable data transfer acknowledgment  but is constrained to have no more than some maximum allowable number  n  of unacknowledged packets in the pipeline figure 3.4-11 shows the sender 's view of the range of sequence numbers in a gbn protocol if we define base to be the sequence number of the oldest unacknowledged packet and nextseqnum to be the smallest unused sequence number  i.e  the sequence number of the next packet to be sent   then four intervals in the range of sequence numbers can be identified sequence numbers in the interval  0,base-1  correspond to packets that have already been transmitted and acknowledged the interval  base  nextseqnum-1  corresponds to packets that have been sent but not yet acknowledged sequence numbers in the interval  nextseqnum,base + n-1  can be used for packets that can be sent immediately  should data arrive from the upper layer finally  sequence numbers greater than or equal to base + n can not be used until an unacknowledged packet currently in the pipeline has been acknowledged as suggested by figure 3.4-11  the range of permissible sequence numbers for transmitted but not-yet-acknowledged packets can be viewed as a ` ` window' ' of size n over the range of sequence numbers as the protocol operates  this window slides forward over the sequence number space for this reason  n is often referred to as the window size and the gbn protocol itself as a sliding window protocol you might be wondering why even limit the number of outstandstanding  unacknowledged packet to a value of n in the first place why not allow an unlimited number of such packets ? we will see in section 3.5 that flow conontrol is one reason to impose a limt on the sender we 'll examine another reason to do so in section 3.7  when we study tcp congestion control in practice  a packet 's sequence number is carried in a fixed length field in the packet header if k is the number of bits in the packet sequence number field  the range of sequence numbers is thus  0,2k-1   with a finite range of sequence numbers  all arithmetic involving sequence numbers must then be done using modulo 2k arithmetic  that is  the sequence number space can be thought of as a ring of size 2k  where sequence number 2k-1 is immediately followed by sequence number 0  recall that rtd3.0 had a 1-bit sequence number and a range of sequence numbers of  0,1  .several of the problems at the end of this chapter explore consequences of a finite range of sequence numbers we will see in section 3.5 that tcp has a 32-bit sequence number field  where tcp sequence numbers count bytes in the byte stream rather than packets figure 3.4-12 extended fsm description of gbn sender file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  13 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-13 extended fsm description of gbn receiver figures 3.4-12 and 3.4-13 give an extended-fsm description of the sender and receiver sides of an ack-based  nak-free  gbn protocol we refer to this fsm description as an extended-fsm since we have added variables  similar to programming language variables  for base and nextseqnum  and also added operations on these variables and conditional actions involving these variables note that the extended-fsm specification is now beginning to look somewhat like a programming language specification  bochman 84  provides an excellent survey of additional extensions to fsm techniques as well as other programming languagebased techniques for specifying protocols the gbn sender must respond to three types of events  l invocation from above when rdt_send   is called from above  the sender first checks to see if the window is full  i.e  whether there are n outstanding  unacknowledged packets if the window is not full  a packet is created and sent  and variables are appropriately updated if the window is full  the sender simply returns the data back to the upper layer  an implicit indication that the window is full the upper layer would presumably then have to try again later in a real implementation  the sender would more likely have either buffered  but not immediately sent  this data  or would have a synchronization mechanism  e.g  a semaphore or a flag  that would allow the upper layer to call rdt_send   only when the window is not full l receipt of an ack in our gbn protocol  an acknowledgement for packet with sequence number n will be taken to be a cumulative acknowledgement  indicating that all packets with a sequence number up to and including n have been correctly received at the receiver we 'll come back to this issue shortly when we examine the receiver side of gbn l a timeout event the protocol 's name  ` ` go-back-n,' ' is derived from the sender 's behavior in the presence of lost or overly delayed packets as in the stop-and-wait protocol  a timer will again be used to recover from lost data or acknowledgement packets if a timeout occurs  the sender resends all packets that have been previously sent but that have not yet been acknowledged our sender in figure 3.4-12 uses only a single timer  which can be thought of as a timer for the oldest tranmitted-but-not-yet-acknowledged packet if an ack is received but there are still additional transmitted-but-yetto be-acknowledged packets  the timer is restarted if there are no outstanding unacknowledged packets  the timer is stopped the receiver 's actions in gbn are also simple if a packet with sequence number n is received correctly and is in-order  i.e  the data last delivered to the upper layer came from a packet with sequence number n-1   the receiver sends an ack for packet n and delivers the data portion of the packet to the upper layer in all other cases  the receiver discards the packet and resends an ack for the most recently received in-order packet note that since packets are delivered one-at-a-time to the upper layer  if packet k has been received and delivered  then all packets with a sequence number lower than k have also been delivered thus  the use of cumulative acknowledgements is a natural choice for gbn in our gbn protocol  the receiver discards out-of-order packets while it may seem silly and wasteful to discard a correctly received  but out-of-order  packet  there is some justification for doing so recall that the receiver must deliver data  in-order  to the upper layer suppose now that packet n is expected  but packet n + 1 arrives since data must be delivered in order  the receiver could buffer  save  packet n + 1 and then deliver this packet to the upper layer after it had later received and delivered packet n however  if packet n is lost  both it and packet n + 1 will eventually be retransmitted as a result of the gbn retransmission rule at the sender thus  the receiver can simply discard packet n + 1 the advantage of this approach is the simplicity of receiver buffering file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  14 of 20  20/11/2004 15  52  09 principle of reliable data transfer  the receiver need not buffer any out-of-order packets thus  while the sender must maintain the upper and lower bounds of its window and the position of nextseqnum within this window  the only piece of information the receiver need maintain is the sequence number of the next in-order packet this value is held in the variable expectedseqnum  shown in the receiver fsm in figure 3.4-13 of course  the disadvantage of throwing away a correctly received packet is that the subsequent retransmission of that packet might be lost or garbled and thus even more retransmissions would be required figure 3.4-14  go-back-n in operation figure 3.4-14 shows the operation of the gbn protocol for the case of a window size of four packets because of this window size limitation  the sender sends packets 0 through 3 but then must wait for one or more of these packets to be acknowledged before proceeding as each successive ack  e.g  ack0 and ack1  is received  the window slides forwards and the sender can transmit one new packet  pkt4 and pkt5  respectively   on the receiver side  packet 2 is lost and thus packets 3  4  and 5 are found to be outof order and are discarded before closing our discussion of gbn  it is worth noting that an implementation of this protocol in a protocol stack would likely be structured similar to that of the extended fsm in figure 3.4-12 the implementation would also likely be in the form of various procedures that implement the actions to be taken in response to the various events that can occur in such event-based programming  the various procedures are called  invoked  either by other procedures in the protocol stack  or as the result of an interrupt in the sender  these events would be  i  a call from the upper layer entity to invoke rdt_send     ii  a timer interrupt  and  iii  a call from the lower layer to invoke rdt_rcv   when a packet arrives the programming exercises at the end of this chapter will give you a chance to actually implement these routines in a simulated  but realistic  network setting we note here that the gbn protocol incorporates almost all of the techniques that we will enounter when we study the reliable data transfer components of tcp in section 3.5  the use of sequence numbers  cumulative acknowledgements  checksums  and a timeout/ retransmit operation indeed  tcp is often referred to as a gbn style of protocol there are  however  some differences file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  15 of 20  20/11/2004 15  52  09 principle of reliable data transfer many tcp implementations will buffer correctly-received but out-of-order segments  stevens 1994   a proposed modification to tcp  the so-called selective acknowledgment  rfc 2018   will also allow a tcp receiver to selectively acknowledge a single outof order packet rather than cumulatively acknowledge the last correctly received packet the notion of a selective acknowledgment is at the heart of the second broad class of pipelined protocols  the so called selective repeat protocols 3.4.4 selective repeat  sr  the gbn protocol allows the sender to potentially ` ` fill the pipeline' ' in figure 3.4-10 with packets  thus avoiding the channel utilization problems we noted with stop-and-wait protocols there are  however  scenarios in which gbn itself will suffer from performance problems in particular  when the window size and bandwidth-delay product are both large  many packets can be in the pipeline a single packet error can thus cause gbn to retransmit a large number of packets  many of which may be unnecessary as the probability of channel errors increases  the pipeline can become filled with these unnecessary retransmissions imagine in our message dictation scenario  if every time a word was garbled  the surrounding 1000 words  e.g  a window size of 1000 words  had to be repeated the dictation would be slowed by all of the reiterated words as the name suggests  selective repeat  sr  protocols avoid unnecessary retransmissions by having the sender retransmit only those packets that it suspects were received in error  i.e  were lost or corrupted  at the receiver this individual  as-needed  retransmission will require that the receiver individually acknowledge correctly-received packets a window size of n will again be used to limit the number of outstanding  unacknowledged packets in the pipeline however  unlike gbn  the sender will have already received acks for some of the packets in the window figure 3.4-15 shows the sr sender 's view of the sequence number space figure 3.4-16 details the various actions taken by the sr sender the sr receiver will acknowledge a correctly received packet whether or not it is in-order out-of-order packets are buffered until any missing packets  i.e  packets with lower sequence numbers  are received  at which point a batch of packets can be delivered inorder to the upper layer figure figsrreceiver itemizes the the various actions taken by the sr receiver figure 3.4-18 shows an example of sr operation in the presence of lost packets note that in figure 3.4-18  the receiver initially buffers packets 3 and 4  and delivers them together with packet 2 to the upper layer when packet 2 is finally received file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  16 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-15  sr sender and receiver views of sequence number space 1 data received from above when data is received from above  the sr sender checks the next available sequence number for the packet if the sequence number is within the sender 's window  the data is packetized and sent ; otherwise it is either buffered or returned to the upper layer for later transmission  as in gbn 2 timeout timers are again used to protect against lost packets however  each packet must now have its own logical timer  since only a single packet will be transmitted on timeout a single hardware timer can be used to mimic the operation of multiple logical timers 3 ack received if an ack is received  the sr sender marks that packet as having been received  provided it is in the window if the packet 's sequence number is equal to sendbase  the window base is moved forward to the unacknowledged packet with the smallest sequence number if the window moves and there are untransmitted packets with sequence numbers that now fall within the window  these packets are transmitted figure 3.4-16  selective repeat sender actions 1 packet with sequence number in  rcvbase  rcvbase + n-1  is correctly received in this case  the received packet falls within the receivers window and a selective ack packet is returned to the sender if the packet was not previously received  it is buffered if this packet has a sequence number equal to the base of the receive window  rcvbase in figure 3.4-15   then this packet  and any previously buffered and consecutively numbered  beginning with rcvbase  packets are file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  17 of 20  20/11/2004 15  52  09 principle of reliable data transfer delivered to the upper layer the receive window is then moved forward by the number of packets delivered to the upper layer.as an example  consider figure 3.4-18 when a packet with a sequence number of rcvbase = 2 is received  it and packets rcvbase + 1 and rcvbase + 2 can be delivered to the upper layer 2 packet with sequence number in  rcvbase-n,rcvbase-1  is received in this case  an ack must be generated  even though this is a packet that the receiver has previously acknowledged 3 otherwise ignore the packet figure 3.4-17  selective repeat receiver actions it is important to note that in step 2 in figure 3.4-17  the receiver re-acknowledges  rather than ignores  already received packets with certain sequence numbers below the current window base you should convince yourself that this re-acknowledgement is indeed needed given the sender and receiver sequence number spaces in figure 3.4-15 for example  if there is no ack for packet sendbase propagating from the receiver to the sender  the sender will eventually retransmit packet sendbase  even though it is clear  to us  not the sender !  that the receiver has already received that packet if the receiver were not to ack this packet  the sender 's window would never move forward ! this example illustrates an important aspect of sr protocols  and many other protocols as well   the sender and receiver will not always have an identical view of what has been received correctly and what has not for sr protocols  this means that the sender and reeciver windows will not always coincide figure 3.4-18  sr operation file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  18 of 20  20/11/2004 15  52  09 principle of reliable data transfer figure 3.4-19  sr receiver dilemma with too large windows  a new packet or a retransmission ? the lack of synchronization between sender and receiver windows has important consequences when we are faced with the reality of a finite range of sequence numbers consider what could happen  for example  with a finite range of four packet sequence numbers  0,1,2,3 and a window size of three suppose packets 0 through 2 are transmitted and correctly received and acknowledged at the receiver at this point  the receiver 's window is over the fourth  fifth and sixth packets  which have sequence numbers 3  0  and 1  respectively now consider two scenarios in the first scenario  shown in figure 3.4-19  a   the acks for the first three packets are lost and the sender retransmits these packets the receiver thus next receives a packet with sequence number 0  a copy of the first packet sent in the second scenario  shown in figure 3.4-19  b   the acks for the first three packets are all delivered correctly the sender thus file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  19 of 20  20/11/2004 15  52  09 principle of reliable data transfer moves its window forward and sends the fourth  fifth and sixth packets  with sequence numbers 3  0  1  respectively the packet with sequence number 3 is lost  but the packet with sequence number 0 arrives  a packet containing new data now consider the receiver 's viewpoint in figure 3.4-19  which has a figurative curtain between the sender and the receiver  since the receiver can not ` ` see' ' the actions taken by the sender all the receiver observes is the sequence of messages it receives from the channel and sends into the channel as far as it is concerned  the two scenarios in figure 3.4-19 are identical there is no way of distinguishing the retransmission of the first packet from an original transmission of the fifth packet clearly  a window size that is one smaller than the size of the sequence number space wo n't work but how small must the window size be ? a problem at the end of the chapter asks you to show that the window size must be less than or equal to half the size of the sequence number space let us conclude our discussion of reliable data transfer protocols by considering one remaining assumption in our underlying channel model recall that we have assumed that packets can not be re-ordered within the channel between the sender and rceiver this is generally a reasonable assumption when the sender and receiver are connected by a single physical wire however  when the ` ` channel' ' connecting the two is a network  packet reordering can occur one manifestation of packet ordering is that old copies of a packet with a sequence or acknowledgement number of x can appear  even though neither the sender 's nor the receiver 's window contains x with packet reordering  the channel can be thought of as essentially buffering packets and spontaneously emitting these packets at any point in the future because sequence numbers may be reused  some care must be taken to guard against such duplicate packets the approach taken in practice is to insure that a sequence number is not reused until the sender is relatively ` ` sure' ' than any previously sent packets with sequence number x are no longer in the network this is done by assuming that a packet can not ` ` live' ' in the network for longer than some fixed maximum amount of time a maximum packet lifetime of approximately three minutes is assumed in the tcp extensions for high-speed networks  rfc 1323   sunshine  sunshine 1978  describes a method for using sequence numbers such that reordering problems can be completely avoided references  bochman 84  g.v bochmann and c.a sunshine  " formal methods in communication protocol design "  ieee transactions on communicaitons  vol com-28  no 4   april 1980   pp 624-631  rfc 1323  v jacobson  s braden  d borman  " tcp extensions for high performance  " rfc 1323  may 1992  rfc 2018  m mathis  j mahdavi  s floyd  a romanow  " tcp selective acknowledgment options  " rfc 2018  october 1996  stevens 1994  w.r stevens  tcp/ip illustrated  volume 1  the protocols addison-wesley  reading  ma  1994  sunshine 1978  c sunshine and y.k dalal  " connection management in transport protocols "  computer networks  amsterdam  the netherlands  north-holland "  1978 copyright 1999 keith w ross and james f kurose  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...proach % 20featuring % 20the % 20internet/principles_rdt.htm  20 of 20  20/11/2004 15  52  09 transmission control protocol 3.5 connection-oriented transport  tcp now that we have covered the underlying principles of reliable data transfer  let 's turn to tcp  the internet 's transport-layer  connection-oriented  reliable transport protocol in this section  we 'll see that in order to provide reliable data transfer  tcp relies on many of the underlying principles discussed in the previous section  including error detection  retransmissions  cumulative acknowledgements  timers and header fields for sequence and acknowledgement numbers tcp is defined in  rfc 793    rfc 1122    rfc 1323    rfc 2018  and  rfc 2581   3.5.1 the tcp connection tcp provides multiplexing  demultiplexing  and error detection  but not recovery  in exactly the same manner as udp nevertheless  tcp and udp differ in many ways the most fundamental difference is that udp is connectionless  while tcp is connection-oriented udp is connectionless because it sends data without ever establishing a connection tcp is connection-oriented because before one application process can begin to send data to another  the two processes must first " handshake " with each other  that is  they must send some preliminary segments to each other to establish the parameters of the ensuing data transfer as part of the tcp connection establishment  both sides of the connection will initialize many tcp " state variables "  many of which will be discussed in this section and in section 3.7  associated with the tcp connection the tcp " connection " is not an end-to-end tdm or fdm circuit as in a circuit-switched network nor is it a virtual circuit  see chapter 1   as the connection state resides entirely in the two end systems because the tcp protocol runs only in the end systems and not in the intermediate network elements  routers and bridges   the intermediate network elements do not maintain tcp connection state in fact  the intermediate routers are completely oblivious to tcp connections ; they see datagrams  not connections a tcp connection provides for full duplex data transfer that is  application-level data can be transferred in both directions between two hosts  if there is a tcp connection between process a on one host and process b on another host  then application-level data can flow from a to b at the same time as application-level data flows from b to a tcp connection is also always point-to-point  i.e  between a single sender and a single receiver so called " multicasting "  see section 4.8   the transfer of data from one sender to many receivers in a single send operation  is not possible with tcp with tcp  two hosts are company and three are a crowd ! let us now take a look at how a tcp connection is established suppose a process running in one host wants to initiate a connection with another process in another host recall that the host that is initiating the connection is called the client host  while the other host is called the server host the client application process first informs the client tcp that it wants to establish a connection to a process in the server recall from section 2.6  a java client program does this by issuing the command  socket clientsocket = new socket  " hostname "  " port number "  ; the tcp in the client then proceeds to establish a tcp connection with the tcp in the server we will discuss in some detail the connection establishment procedure at the end of this section for now it suffices to know that the client first sends a special tcp segment ; the server responds with a second special tcp segment ; and finally the client responds again with a third special segment the first two segments contain no " payload  " i e  no application-layer data ; the third of these segments may carry a payload because three segments are sent between the two hosts  this connection establishment procedure is often referred to as a three-way handshake once a tcp connection is established  the two application processes can send data to each other ; because tcp is full-duplex they can send data at the same time let us consider the sending of data from the client process to the server process the client process passes a stream of data through the socket  the door of the process   as described in section 2.6 once the data passes through the door  the data is now in the hands of tcp running in the client as shown in the figure 3.5-1  tcp directs this data to the connection 's send buffer  which is one of the buffers that is set aside during the initial three-way handshake from time to time  tcp will " grab " chunks of data from the send buffer the maximum amount of data that can be grabbed and placed in a segment is limited by the maximum segment size  mss   the mss depends on the tcp implementation  determined by the operating system  and can often be configured ; common values are 1,500 bytes  536 bytes and 512 bytes  these segment sizes are often chosen in order to avoid ip fragmentation  which will be discussed in the next chapter  note that the mss is the maximum amount of application-level data in the segment  not the maximum size of the tcp segment including headers  this terminology is confusing  but we have to live with it  as it is well entrenched  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  1 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-1  tcp send and receive buffers tcp encapsulates each chunk of client data with tcp header  thereby forming tcp segments the segments are passed down to the network layer  where they are separately encapsulated within network-layer ip datagrams the ip datagrams are then sent into the network when tcp receives a segment at the other end  the segment 's data is placed in the tcp connection 's receive buffer the application reads the stream of data from this buffer each side of the connection has its own send buffer and its own receive buffer the send and receive buffers for data flowing in one direction are shown in figure 3.5-1 we see from this discussion that a tcp connection consists of buffers  variables and a socket connection to a process in one host  and another set of buffers  variables and a socket connection to a process in another host as mentioned earlier  no buffers or variables are allocated to the connection in the network elements  routers  bridges and repeaters  between the hosts 3.5.2 tcp segment structure having taken a brief look at the tcp connection  let 's examine the tcp segment structure the tcp segment consists of header fields and a data field the data field contains a chunk of application data as mentioned above  the mss limits the maximum size of a segment 's data field when tcp sends a large file  such as an encoded image as part of a web page  it typically breaks the file into chunks of size mss  except for the last chunk  which will often be less than the mss   interactive applications  however  often transmit data chunks that are smaller than the mss ; for example  with remote login applications like telnet  the data field in the tcp segment is often only one byte because the tcp header is typically 20 bytes  12 bytes more than the udp header   segments sent by telnet may only be 21 bytes in length figure 3.3-2 shows the structure of the tcp segment as with udp  the header includes source and destination port numbers  that are used for multiplexing/demultiplexing data from/to upper layer applications also as with udp  the header includes a checksum field a tcp segment header also contains the following fields  l the32-bit sequence number field  and the 32-bit acknowledgment number field are used by the tcp sender and receiver in implementing a reliable data transfer service  as discussed below l the 16-bit window size field is used for the purposes of flow control we will see shortly that it is used to indicate the number of bytes that a receiver is willing to accept l the 4-bit length field specifies the length of the tcp header in 32-bit words the tcp header can be of variable length due to the tcp options field  discussed below  typically  the options field is empty  so that the length of the typical tcp header is 20 bytes  l the optional and variable length options field is used when a sender and receiver negotiate the maximum segment size  mss  or as a window scaling factor for use in high-speed networks a timestamping option is also defined see  rfc 854    rfc1323  for additional details l the flag field contains 6 bits the ack bit is used to indicate that the value carried in the acknowledgment field is valid the rst  syn and fin bits are used for connection setup and teardown  as we will discuss at the end of this section when the psh bit is set  this is an indication that the receiver should pass the data to the upper layer immediately finally  the urg bit is used to indicate there is data in this segment that the sending-side upper layer entity has marked as ` ` urgent.' ' the location of the last byte of this urgent data is indicated by the 16 bit urgent data pointer tcp must inform the receiving-side upper layer entity when urgent data exists and pass it a pointer to the end of the urgent data  in practice  the psh  urg and pointer to urgent data are not used however  we mention these fields for completeness  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  2 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-2  tcp segment structure 3.5.3 sequence numbers and acknowledgment numbers two of the most important fields in the tcp segment header are the sequence number field and the acknowledgment number field these fields are a critical part of tcp 's reliable data transfer service but before discussing how these fields are used to provide reliable data transfer  let us first explain what exactly tcp puts in these fields tcp views data as an unstructured  but ordered  stream of bytes tcp 's use of sequence numbers reflects this view in that sequence numbers are over the stream of transmitted bytes and not over the series of transmitted segments the sequence number for a segment is the byte-stream number of the first byte in the segment let 's look at an example suppose that a process in host a wants to send a stream of data to a process in host b over a tcp connection the tcp in host a will implicitly number each byte in the data stream suppose that the data stream consists of a file consisting of 500,000 bytes  that the mss is 1,000 bytes  and that the first byte of the data stream is numbered zero as shown in figure 3.5-3  tcp constructs 500 segments out of the data stream the first segment gets assigned sequence number 0  the second segment gets assigned sequence number 1000  the third segment gets assigned sequence number 2000  and so on each sequence number is inserted in the sequence number field in the header of the appropriate tcp segment figure 3.5-3  dividing file data into tcp segments now let us consider acknowledgment numbers these are a little trickier than sequence numbers recall that tcp is full duplex  so that host a may be receiving data from host b while it sends data to host b  as part of the same tcp connection   each of the segments that arrive from host b have a sequence number for the data flowing from b to a the acknowledgment number that host a puts in its segment is sequence number of the next byte host a is expecting from host b it is good to look at a few examples to understand what is going on here suppose that host a has received all bytes numbered 0 through 535 from b and suppose that it is about to send a segment to host b in other words  host a is waiting for byte 536 and all the file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  3 of 15  20/11/2004 15  52  11 transmission control protocol subsequent bytes in host b 's data stream so host a puts 536 in the acknowledgment number field of the segment it sends to b as another example  suppose that host a has received one segment from host b containing bytes 0 through 535 and another segment containing bytes 900 through 1,000 for some reason host a has not yet received bytes 536 through 899 in this example  host a is still waiting for byte 536  and beyond  in order to recreate b 's data stream thus  a 's next segment to b will contain 536 in the acknowledgment number field because tcp only acknowledges bytes up to the first missing byte in the stream  tcp is said to provide cumulative acknowledgements this last example also brings up an important but subtle issue host a received the third segment  bytes 900 through 1,000  before receiving the second segment  bytes 536 through 899   thus  the third segment arrived out of order the subtle issue is  what does a host do when it receives out of order segments in a tcp connection ? interestingly  the tcp rfcs do not impose any rules here  and leave the decision up to the people programming a tcp implementation there are basically two choices  either  i  the receiver immediately discards out-of-order bytes ; or  ii  the receiver keeps the out-of-order bytes and waits for the missing bytes to fill in the gaps clearly  the latter choice is more efficient in terms of network bandwidth  whereas the former choice significantly simplifies the tcp code throughout the remainder of this introductory discussion of tcp  we focus on the former implementation  that is  we assume that the tcp receiver discards out-of-order segments in figure 3.5.3 we assumed that the initial sequence number was zero in truth  both sides of a tcp connection randomly choose an initial sequence number this is done to minimize the possibility a segment that is still present in the network from an earlier  already-terminated connection between two hosts is mistaken for a valid segment in a later connection between these same two hosts  who also happen to be using the same port numbers as the old connection   sunshine 78   3.5.4 telnet  a case study for sequence and acknowledgment numbers telnet  defined in  rfc 854   is a popular application-layer protocol used for remote login it runs over tcp and is designed to work between any pair of hosts unlike the bulk-data transfer applications discussed in chapter 2  telnet is an interactive application we discuss a telnet example here  as it nicely illustrates tcp sequence and acknowledgment numbers suppose one host  88.88.88.88  initiates a telnet session with host 99.99.99.99  anticipating our discussion on ip addressing in the next chapter  we take the liberty to use ip addresses to identify the hosts  because host 88.88.88.88 initiates the session  it is labeled the client and host 99.99.99.99 is labeled the server each character typed by the user  at the client  will be sent to the remote host ; the remote host will send back a copy of each character  which will be displayed on the telnet user 's screen this " echo back " is used to ensure that characters seen by the telnet user have already been received and processed at the remote site each character thus traverses the network twice between when the user hits the key and when the character is displayed on the user 's monitor now suppose the user types a single letter  'c '  and then grabs a coffee let 's examine the tcp segments that are sent between the client and server as shown in figure 3.5-4  we suppose the starting sequence numbers are 42 and 79 for the client and server  respectively recall that the sequence number of a segment is the sequence number of first byte in the data field thus the first segment sent from the client will have sequence number 42 ; the first segment sent from the server will have sequence number 79 recall that the acknowledgment number is the sequence number of the next byte of data that the host is waiting for after the tcp connection is established but before any data is sent  the client is waiting for byte 79 and the server is waiting for byte 42 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  4 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-4  sequence and acknowledgment numbers for a simple telnet application over tcp as shown in figure 3.5-4  three segments are sent the first segment is sent from the client to the server  containing the one-byte ascii representation of the letter 'c ' in its data field this first segment also has 42 in its sequence number field  as we just described also  because the client has not yet received any data from the server  this first segment will have 79 in its acknowledgment number field the second segment is sent from the server to the client it serves a dual purpose first it provides an acknowledgment for the data the client has received by putting 43 in the acknowledgment field  the server is telling the client that it has successfully received everything up through byte 42 and is now waiting for bytes 43 onward the second purpose of this segment is to echo back the letter 'c' thus  the second segment has the ascii representation of 'c ' in its data field this second segment has the sequence number 79  the initial sequence number of the server-to-client data flow of this tcp connection  as this is the very first byte of data that the server is sending note that the acknowledgement for client-to-server data is carried in a segment carrying server-to-client data ; this acknowledgement is said to be piggybacked on the server-to-client data segment the third segment is sent from the client to the server its sole purpose is to acknowledge the data it has received from the server  recall that the second segment contained data  the letter 'c '  from the server to the client  this segment has an empty data field  i.e  the acknowledgment is not being piggybacked with any cient-to-server data   the segment has 80 in the acknowledgment number field because the client has received the stream of bytes up through byte sequence number 79 and it is now waiting for bytes 80 onward you might think it odd that this segment also has a sequence number since the segment contains no data but because tcp has a sequence number field  the segment needs to have some sequence number 3.5.5 reliable data transfer recall that the internet 's network layer service  ip service  is unreliable ip does not guarantee datagram delivery  does not guarantee in-order delivery of datagrams  and does not guarantee the integrity of the data in the datagrams with ip service  datagrams can overflow router buffers and never reach their destination  datagrams can arrive out of order  and bits in the datagram can get corrupted  flipped from 0 to 1 and vice versa   because transport-layer segments are carried across the network by ip datagrams  transport-layer segments can also suffer from these problems as well tcp creates a reliable data transfer service on top of ip 's unreliable best-effort service many popular application protocols  including ftp  smtp  nntp  http and telnet  use tcp rather than udp primarily because tcp provides reliable data transfer service tcp 's reliable data transfer service ensures that the data stream that a process reads out of its tcp receive buffer is uncorrupted  without gaps  without duplication  and in sequence  i.e  the byte stream is exactly the same byte stream that was sent by the end system on the other side of the connection in this subsection we provide an informal overview of how tcp provides reliable data transfer we shall see that the reliable data transfer service of tcp uses many of the principles that we studied in section 3.4 retransmissions file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  5 of 15  20/11/2004 15  52  11 transmission control protocol retransmission of lost and corrupted data is crucial for providing reliable data transfer tcp provides reliable data transfer by using positive acknowledgments and timers in much the same way as we studied in section 3.4 tcp acknowledges data that has been received correctly  and retransmits segments when segments or their corresponding acknowledgements are thought to be lost or corrupted just as in the case of our reliable data transfer protocol  rdt3.0  tcp can not itself tell for certain if a segment  or its ack  is lost  corrupted  or overly delayed in all cases  tcp 's response will be the same  retransmit the segment in question tcp also uses pipelining  allowing the sender to have multiple transmitted but yet-to-be-acknowledged segments outstanding at any given time we saw in the previous section that pipelining can greatly improve the throughput of a tcp connection when the ratio of the segment size to round trip delay is small the specific number of outstanding unacknowledged segments that a sender can have is determined by tcp 's flow control and congestion control mechanisms tcp flow control is discussed at the end of this section ; tcp congestion control is discussed in section 3.7 for the time being  we must simply be aware that the sender can have multiple transmitted  but unacknowledged  segments at any given time / * assume sender is not constrained by tcp flow or congestion control  that data from above is less than mss in size  and that data transfer is in one direction only * / sendbase = initial_sequence number / * see figure 3.4-11 * / nextseqnum = initial_sequence number loop  forever   switch  event  event  data received from application above create tcp segment with sequence number nextseqnum start timer for segment nextseqnum pass segment to ip nextseqnum = nextseqnum + length  data  event  timer timeout for segment with sequence number y retransmit segment with sequence number y compue new timeout interval for segment y restart timer for sequence number y event  ack received  with ack field value of y if  y > sendbase   / * cumulative ack of all data up to y * / cancel all timers for segments with sequence numbers < y sendbase = y  else  / * a duplicate ack for already acked segment * / increment number of duplicate acks received for y if  number of duplicate acks received for y = = 3   / * tcp fast retransmit * / resend segment with sequence number y restart timer for segment y   / * end of loop forever * / figure 3.5-5  simplified tcp sender figure 3.5-5 shows the three major events related to data transmission/retransmission at a simplified tcp sender let us consider a tcp connection between host a and b and focus on the data stream being sent from host a to host b at the sending host  a   tcp is passed application-layer data  which it frames into segments and then passes on to ip the passing of data from the application to tcp and the subsequent framing and transmission of a segment is the first important event that the tcp sender must handle each time tcp releases a segment to ip  it starts a timer for that segment if file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  6 of 15  20/11/2004 15  52  11 transmission control protocol this timer expires  an interrupt event is generated at host a tcp responds to the timeout event  the second major type of event that the tcp sender must handle  by retransmitting the segment that caused the timeout the third major event that must be handled by the tcp sender is the arrival of an acknowledgement segment  ack  from the receiver  more specifically  a segment containing a valid ack field value   here  the sender 's tcp must determine whether the ack is a first-time ack for a segment that the sender has yet to receive an acknowledgement for  or a so-called duplicate ack that re-acknowledges a segment for which the sender has already received an earlier acknowledgement in the case of the arrival of a first-time ack  the sender now knows that all data up to the byte being acknowledged has been received correctly at the receiver the sender can thus update its tcp state variable that tracks the sequence number of the last byte that is known to have been received correctly and in-order at the receiver to understand the sender 's response to a duplicate ack  we must look at why the receiver sends a duplicate ack in the first place table 3.5-1 summarizes the tcp receiver 's ack generation policy when a tcp receiver receives a segment with a sequence number that is larger than the next  expected  in-order sequence number  it detects a gap in the data stream  i.e  a missing segment since tcp does not use negative acknowledgements  the receiver can not send an explicit negative acknowledgement back to the sender instead  it simply re-acknowledges  i.e  generates a duplicate ack for  the last in-order byte of data it has received if the tcp sender receives three duplicate acks for the same data  it takes this as an indication that the segment following the segment that has been acked three times has been lost in this case  tcp performs a fast retransmit  rfc 2581   retransmitting the missing segment before that segment 's timer expires event tcp receiver action arrival of in-order segment with expected sequence number all data up to up to expected sequence number already acknowledged no gaps in the received data delayed ack wait up to 500 ms for arrival of another in-order segment if next in-order segment does not arrives in this interval  send an ack arrival of in-order segment with expected sequence number one other in-order segment waiting for ack transmission no gaps in the received data immediately send single cumulative ack  acking both in-order segments arrival of out-of-order segment with higherthan expected sequence number gap detected immediately send duplicate ack  indicating sequence number of next expected byte arrival of segment that partially or completely fills in gap in received data immediately send ack  provided that segment starts at the lower end of gap table 3.5-1  tcp ack generation recommendations  rfc 1122  rfc 2581  a few interesting scenarios we end this discussion by looking at a few simple scenarios figure 3.5-6 depicts the scenario where host a sends one segment to host b suppose that this segment has sequence number 92 and contains 8 bytes of data after sending this segment  host a waits for a segment from b with acknowledgment number 100 although the segment from a is received at b  the acknowledgment from b to a gets lost in this case  the timer expires  and host a retransmits the same segment of course  when host b receives the retransmission  it will observe that the bytes in the segment duplicate bytes it has already deposited in its receive buffer thus tcp in host b will discard the bytes in the retransmitted segment file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  7 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-6  retransmission due to a lost acknowledgment in a second scenario  host a sends two segments back to back the first segment has sequence number 92 and 8 bytes of data  and the second segment has sequence number 100 and 20 bytes of data suppose that both segments arrive intact at b  and b sends two separate acknowledgements for each of these segments the first of these acknowledgements has acknowledgment number 100 ; the second has acknowledgment number 120 suppose now that neither of the acknowledgements arrive at host a before the timeout of the first segment when the timer expires  host a resends the first segment with sequence number 92 now  you may ask  does a also resend second segment ? according to the rules described above  host a resends the segment only if the timer expires before the arrival of an acknowledgment with an acknowledgment number of 120 or greater thus  as shown in figure 3.5-7  if the second acknowledgment does not get lost and arrives before the timeout of the second segment  a does not resend the second segment figure 3.5-7  segment is not retransmitted because its acknowledgment arrives before the timeout in a third and final scenario  suppose host a sends the two segments  exactly as in the second example the acknowledgment of the first segment is lost in the network  but just before the timeout of the first segment  host a receives an acknowledgment with acknowledgment number 120 host a therefore knows that host b has received everything up through byte 119 ; so host a does not resend either of the two segments this scenario is illustrated in the figure 3.5-8 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  8 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-8  a cumulative acknowledgment avoids retransmission of first segment recall that in the previous section we said that tcp is a go-back-n style protocol this is because acknowledgements are cumulative and correctlyreceived but out-of-order segments are not individually acked by the receiver consequently  as shown in figure 3.5-5  see also figure 3.4-11   the tcp sender need only maintain the smallest sequence number of a transmitted but unacknowledged byte  sendbase  and the sequence number of the next byte to be sent  nextseqnum   but the reader should keep in mind that although the reliable-data-transfer component of tcp resembles go-back-n  it is by no means a pure implementation of go-back-n to see that there are some striking differences between tcp and go-back-n  consider what happens when the sender sends a sequence of segments 1  2  n  and all of the segments arrive in order without error at the receiver further suppose that the acknowledgment for packet n < n gets lost  but the remaining n-1 acknowledgments arrive at the sender before their respective timeouts in this example  go-back-n would retransmit not only packet n  but also all the subsequent packets n + 1  n + 2,...,n tcp  on the other hand  would retransmit at most one segment  namely  segment n moreover  tcp would not even retransmit segment n if the acknowledgement for segment n + 1 arrives before the timeout for segment n there have recently been several proposals  rfc 2018  fall 1996  mathis 1996  to extend the tcp acking scheme to be more similar to a selective repeat protocol the key idea in these proposals is to provide the sender with explicit information about which segments have been received correctly  and which are still missing at the receiver 3.5.6 flow control recall that the hosts on each side of a tcp connection each set aside a receive buffer for the connection when the tcp connection receives bytes that are correct and in sequence  it places the data in the receive buffer the associated application process will read data from this buffer  but not necessarily at the instant the data arrives indeed  the receiving application may be busy with some other task and may not even attempt to read the data until long after it has arrived if the application is relatively slow at reading the data  the sender can very easily overflow the connection 's receive buffer by sending too much data too quickly tcp thus provides a flow control service to its applications by eliminating the possibility of the sender overflowing the receiver 's buffer flow control is thus a speed matching service  matching the rate at which the sender is seding to the rate at which the receiving application is reading as noted earlier  a tcp sender can also be throttled due to congestion within the ip network ; this form of sender control is referred to as congestion control  a topic we will explore in detail in sections 3.6 and 3.7 while the actions taken by flow and congestion control are similar  the throttling of the sender   they are obviously taken for very different reasons unfortunately  many authors use the term interchangeably  and the savvy reader would be careful to distinguish between the two cases let 's now discuss how tcp provides its flow control service tcp provides flow control by having the sender maintain a variable called the receive window informally  the receive window is used to give the sender an idea about how much free buffer space is available at the receiver in a full-duplex connection  the sender at each side of the connection maintains a distinct receive window the receive window is dynamic  i.e  it changes throughout a connection 's lifetime let 's investigate the receive window in the context of a file transfer suppose that host a is sending a large file to host b over a tcp connection host b allocates a receive buffer to this connection ; denote its size by rcvbuffer from time to time  the application process in host b reads from the buffer define the following variables  lastbyteread = the number of the last byte in the data stream read from the buffer by the application process in b lastbytercvd = the number of the last byte in the data stream that has arrived from the network and has been placed in the receive buffer at b file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  9 of 15  20/11/2004 15  52  11 transmission control protocol because tcp is not permitted to overflow the allocated buffer  we must have  lastbytercvd  lastbyteread < = rcvbuffer the receive window  denoted rcvwindow  is set to the amount of spare room in the buffer  rcvwindow = rcvbuffer   lastbytercvd  lastbyteread  because the spare room changes with time  rcvwindow is dynamic the variable rcvwindow is illustrated in figure 3.5-9 figure 3.5-9  the receive window  rcvwindow  and the receive buffer  rcvbuffer  how does the connection use the variable rcvwindow to provide the flow control service ? host b informs host a of how much spare room it has in the connection buffer by placing its current value of rcvwindow in the window field of every segment it sends to a initially host b sets rcvwindow = rcvbuffer note that to pull this off  host b must keep track of several connection-specific variables host a in turn keeps track of two variables  lastbytesent and lastbyteacked  which have obvious meanings note that the difference between these two variables  lastbytesent  lastbyteacked  is the amount of unacknowledged data that a has sent into the connection by keeping the amount of unacknowledged data less than the value of rcvwindow  host a is assured that it is not overflowing the receive buffer at host b thus host a makes sure throughout the connection 's life that lastbytesent  lastbyteacked < = rcvwindow there is one minor technical problem with this scheme to see this  suppose host b 's receive buffer becomes full so that rcvwindow = 0 after advertising rcvwindow = 0 to host a  also suppose that b has nothing to send to a as the application process at b empties the buffer  tcp does not send new segments with new rcvwindows to host a  tcp will only send a segment to host a if it has data to send or if it has an acknowledgment to send therefore host a is never informed that some space has opened up in host b 's receive buffer  host a is blocked and can transmit no more data ! to solve this problem  the tcp specification requires host a to continue to send segments with one data byte when b 's receive window is zero these segments will be acknowledged by the receiver eventually the buffer will begin to empty and the acknowledgements will contain non-zero rcvwindow having described tcp 's flow control service  we briefly mention here that udp does not provide flow control to understand the issue here  consider sending a series of udp segments from a process on host a to a process on host b for a typical udp implementation  udp will append the segments  more precisely  the data in the segments  in a finite-size queue that " precedes " the corresponding socket  i.e  the door to the process   the process reads one entire segment at a time from the queue if the process does not read the segments fast enough from the queue  the queue will overflow and segments will get lost following this section we provide an interactive java applet which should provide significant insight into the tcp receive window 3.5.7 round trip time and timeout recall that when a host sends a segment into a tcp connection  it starts a timer if the timer expires before the host receives an acknowledgment for file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  10 of 15  20/11/2004 15  52  11 transmission control protocol the data in the segment  the host retransmits the segment the time from when the timer is started until when it expires is called the timeout of the timer a natural question is  how large should timeout be ? clearly  the timeout should be larger than the connection 's round-trip time  i.e  the time from when a segment is sent until it is acknowledged otherwise  unnecessary retransmissions would be sent but the timeout should not be much larger than the round-trip time ; otherwise  when a segment is lost  tcp would not quickly retransmit the segment  thereby introducing significant data transfer delays into the application before discussing the timeout interval in more detail  let us take a closer look at the round-trip time  rtt   the discussion below is based on the tcp work in  jacobson 1988   estimating the average round-trip time the sample rtt  denoted samplertt  for a segment is the time from when the segment is sent  i.e  passed to ip  until an acknowledgment for the segment is received each segment sent will have its own associated samplertt obviously  the samplertt values will fluctuate from segment to segment due to congestion in the routers and to the varying load on the end systems because of this fluctuation  any given samplertt value may be atypical in order to estimate a typical rtt  it is therefore natural to take some sort of average of the samplertt values tcp maintains an average  called estimatedrtt  of the samplertt values upon receiving an acknowledgment and obtaining a new samplertt  tcp updates estimatedrtt according to the following formula  estimatedrtt =  1-x  estimatedrtt + x samplertt the above formula is written in the form of a programming language statement  the new value of estimatedrtt is a weighted combination of the previous value of estimated rtt and the new value for samplertt a typical value of x is x = .1  in which case the above formula becomes  estimatedrtt = .9 estimatedrtt + .1 samplertt note that estimatedrtt is a weighted average of the samplertt values as we will see in the homework  this weighted average puts more weight on recent samples than on old samples  this is natural  as the more recent samples better reflect the current congestion in the network in statistics  such an average is called an exponential weighted moving average  ewma   the word " exponential " appears in ewma because the weight of a given samplertt decays exponentially fast as the updates proceed in the homework problems you will be asked to derive the exponential term in estimatedrtt setting the timeout the timeout should be set so that a timer expires early  i.e  before the delayed arrival of a segment 's ack  only on rare occasions it is therefore natural to set the timeout equal to the estimatedrtt plus some margin the margin should be large when there is a lot of fluctuation in the samplertt values ; it should be small when there is little fluctuation tcp uses the following formula  timeout = estimatedrtt + 4 * deviation  where deviation is an estimate of how much samplertt typically deviates from estimatedrtt  deviation =  1-x  deviation + x | samplertt  estimatedrtt | note that deviation is an ewma of how much samplertt deviates from estimatedrtt if the samplertt values have little fluctuation  then deviation is small and timeout is hardly more than estimatedrtt ; on the other hand  if there is a lot of fluctuation  deviation will be large and timeout will be much larger than estimatedrtt 3.5.8 tcp connection management in this subsection we take a closer look at how a tcp connection is established and torn down although this particular topic may not seem particularly exciting  it is important because tcp connection establishment can significantly add to perceived delays  for example  when surfing the web   let 's now take a look at how a tcp connection is established suppose a process running in one host wants to initiate a connection with another process in another host the host that is initiating the connection is called the client host whereas the other host is called the server host the client application process first informs the client tcp that it wants to establish a connection to a process in the server recall from section 2.6  that a java client program does this by issuing the command  socket clientsocket = new socket  " hostname "  " port number "  ; the tcp in the client then proceeds to establish a tcp connection with the tcp in the server in the following manner  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  11 of 15  20/11/2004 15  52  11 transmission control protocol l step 1 the client-side tcp first sends a special tcp segment to the server-side tcp this special segment contains no application-layer data it does  however  have one of the flag bits in the segment 's header  see figure 3.3-2   the so-called syn bit  set to 1 for this reason  this special segment is referred to as a syn segment in addition  the client chooses an initial sequence number  client_isn  and puts this number in the sequence number field of the initial tcp syn segment.this segment is encapsulated within an ip datagram and sent into the internet l step 2 once the ip datagram containing the tcp syn segment arrives at the server host  assuming it does arrive !   the server extracts the tcp syn segment from the datagram  allocates the tcp buffers and variables to the connection  and sends a connection-granted segment to client tcp this connection-granted segment also contains no application-layer data however  it does contain three important pieces of information in the segment header first  the syn bit is set to 1 second  the acknowledgment field of the tcp segment header is set to isn + 1 finally  the server chooses its own initial sequence number  server_isn  and puts this value in the sequence number field of the tcp segment header this connection granted segment is saying  in effect  " i received your syn packet to start a connection with your initial sequence number  client_isn i agree to establish this connection my own initial sequence number is server_isn " the conenction-granted segment is sometimes referred to as a synack segment l step 3 upon receiving the connection-granted segment  the client also allocates buffers and variables to the connection the client host then sends the server yet another segment ; this last segment acknowledges the server 's connection-granted segment  the client does so by putting the value server_isn + 1 in the acknowledgment field of the tcp segment header   the syn bit is set to 0  since the connection is established once the following three steps have been completed  the client and server hosts can send segments containing data to each other in each of these future segments  the syn bit will be set to zero note that in order to establish the connection  three packets are sent between the two hosts  as illustrated in figure 3.5-10 for this reason  this connection establishment procedure is often referred to as a three-way handshake several aspects of the tcp three-way handshake  why are initial sequence numbers needed ? why is a three-way handshake  as opposed to a two-way handshake  needed ?  are explored in the homework problems figure 3.5-10  tcp three-way handshake  segment exchange all good things must come to an end  and the same is true with a tcp connection either of the two processes participating in a tcp connection can end the connection when a connection ends  the " resources "  i.e  the buffers and variables  in the hosts are de-allocated as an example  suppose the client decides to close the connection the client application process issues a close command this causes the client tcp to send a special tcp segment to the server process this special segment has a flag bit in the segment 's header  the so-called fin bit  see figure 3.3-2   set to 1 when the server receives this segment  it sends the client an acknowledgment segment in return the server then sends its own shut-down segment  which has the fin bit set to 1 finally  the client acknowledges the server 's shut-down segment at this point  all the resources in the two hosts are now deallocated during the life of a tcp connection  the tcp protocol running in each host makes transitions through various tcp states figure 3.5-11 illustrates a typical sequence of tcp states that are visited by the client tcp the client tcp begins in the closed state the application on the client side initiates a new tcp connection  by creating a socket object in our java examples   this causes tcp in the client to send a syn segment to tcp in the server after having sent the syn segment  the client tcp enters the syn_sent sent while in the syn_state the client tcp waits for a segment from the server tcp that includes an acknowledgment for the client 's previous segment as well as the syn bit set to 1 once having received such a segment  the client tcp enters the established state while in the established state  the tcp client can send and receive tcp segments containing payload  i.e  application-generated  data suppose that the client application decides it wants to close the connection this causes the client tcp to send a tcp segment with the fin bit set to 1 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  12 of 15  20/11/2004 15  52  11 transmission control protocol and to enter the fin_wait_1 state while in the fin_wait state  the client tcp waits for a tcp segment from the server with an acknowledgment when it receives this segment  the client tcp enters the fin_wait_2 state while in the fin_wait_2 state  the client waits for another segment from the server with the fin bit set to 1 ; after receiving this segment  the client tcp acknowledges the server 's segment and enters the time_wait state the time_wait state lets the tcp client resend the final acknowledgment in the case the ack is lost the time spent in the time-wait state is implementation dependent  but typical values are 30 seconds  1 minute and 2 minutes after the wait  the connection formally closes and all resources on the client side  including port numbers  are released figure 3.5-11  a typical sequence of tcp states visited by a client tcp figure 3.5-12 illustrates the series of states typically visited by the server-side tcp ; the transitions are self-explanatory in these two state transition diagrams  we have only shown how a tcp connection is normally established and shut down we are not going to describe what happens in certain pathological scenarios  for example  when both sides of a connection want to shut down at the same time if you are interested in learning about this and other advanced issues concerning tcp  you are encouraged to see steven 's comprehensive book  stevens 1994   file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  13 of 15  20/11/2004 15  52  11 transmission control protocol figure 3.5-12  a typical sequence of tcp states visited by a server-side tcp this completes our introduction to tcp in section 3.7 we will return to tcp and look at tcp congestion control in some depth before doing so  in the next section we step back and examine congestion control issues in a broader context references  fall 1996  k fall  s floyd  " simulation-based comparisons of tahoe  reno and sack tcp "  acm computer communication review  july 1996  jacobson 1988  v jacobson  " congestion avoidance and control  " proc acm sigcomm 1988 conference  in computer communication review  vol 18  no 4  pp 314-329  aug 1988  mathis 1996  m mathis  j mahdavi  " forward acknowledgment  refining tcp congestion control "  proceedings of acm sigcomm'96  august 1996  stanford  ca  rfc 793  " transmission control protocol  " rfc 793  september 1981  rfc 854  j postel and j reynolds  " telnet protocol specifications  " rfc 854  may 1983  rfc 1122  r braden  " requirements for internet hosts  communication layers  " rfc 1122  october 1989  rfc13 23  v jacobson  s braden  d borman  " tcp extensions for high performance  " rfc 1323  may 1992  rfc 2018  mathis  m  mahdavi  j  floyd  s and a romanow  " tcp selective acknowledgement options "  rfc 2018  october 1996  rfc 2581  m allman  v paxson  w stevens  " tcp congestion control  rfc 2581  april 1999  stevens 1994  w.r stevens  tcp/ip illustrated  volume 1  the protocols addison-wesley  reading  ma  1994 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  14 of 15  20/11/2004 15  52  11 transmission control protocol query options  case insensitive maximum number of hits  return to table of contents copyright keith w ross and james f kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/segment.html  15 of 15  20/11/2004 15  52  11 tcp flow control 3 tcp flow control notes  1 host b comsumes data in 2kbyte chunks at random times 2 when host a receives an acknowledgment with win = 0  host a sends a packet with one byte of data it is assumed for simplicity  that this one byte is not comsumed by the receiver file  ///d | /downloads/livros/computa ? ? o/computer % 20networ...p-down % 20approach % 20featuring % 20the % 20internet/tcp3.html20/11/2004 15  52  09 principles of congestion control 3.6 principles of congestion control in the previous sections  we 've examined both the general principles and specific tcp mechanisms used to provide for a reliable data transfer service in the face of packet loss we mentioned earlier that  in practice  such loss typically results from the overflowing of router buffers as the network becomes congested packet retransmission thus treats a symptom of network congestion  the loss of a specific transport-layer packet  but does not treat the cause of network congestion  too many sources attempting to send data at too high a rate to treat the cause of network congestion  mechanisms are needed to throttle the sender in the face of network congestion in this section  we consider the problem of congestion control in a general context  seeking to understand why congestion is a " bad thing  " how network congestion is manifested in the performance received by upper-layer applications  and various approaches that can be taken to avoid  or react to  network congestion this more general study of congestion control is appropriate since  as with reliable data transfer  it is high on the " top-10 " list of fundamentally important problems in networking we conclude this section with a discussion of congestion control in the atm abr protocol the following section contains a detailed study of tcp 's congestion control algorithm 3.6.1 the causes and the " costs " of congestion let 's begin our general study of congestion control by examing three increasingly complex scenarios in which congestion occurs in each case  we 'll look at why congestion occurs in the first place  and the " cost " of congestion  in terms of resources not fully utilized and poor performance received by the end systems   scenario 1  two senders  a router with infinte buffers we begin by considering perhaps the simplest congestion scenario possible  two hosts  a and b  each have a connection that share a single hop between source and destination  as shown in figure 3.6-1 figure 3.6-1  congestion scenario 1  two connections sharing a single hop with infinte buffers let 's assume that the application in host a is sending data into the connection  e.g  passing data to the transport-level protocol via a socket  at an average rate of ? in bytes/sec these data are " original " in the sense that each unit of data is sent file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  1 of 9  20/11/2004 15  52  13 principles of congestion control into the socket only once the underlying transport-level protocol is a simple one  data is encapsulated and sent ; no error recovery  e.g  retransmission   flow control  or congestion control is performed host b operates in a similar manner and we assume for simplicity that it too is sending at a rate of ? in bytes/sec packets from hosts a and b pass through a router and over a shared outgoing link of capacity c the router has buffers that allow it to store incoming packets when the packet arrival rate exceeds the outgoing link 's capacity in this first scenario  we 'll assume that the router has an infinite amount of buffer space figure 3.6-2  congestion scenario 1  throughtput and delay as a function of host sending rate figure 3.6-2 plots the performance of host a 's connection under this first scenario the left graph plots the perconnection throughput  number of bytes per second at the receiver  as a function of the connection sending rate for a sending rate between zero and c/2  the throughput at the receiver equals the sender 's sending rate  everything sent by the sender is received at the receiver with a finite delay when the sending rate is above c/2  however  the throughput is only c/2 this upper limit on throughput is a consequence of the sharing of link capacity between two connections  the link simply can not deliver packets to a receiver at a steady state rate that exceeds c/2 no matter how high hosts a and b set their sending rates  they will each never see a throughput higher than c/2 achieving a per-connection throughput of c/2 might actually appear to be a " good thing  " as the link is fully utilized in delivering packets to their destinations the right graph in figure 3.6-2  however  shows the consequences of operating near link capacity as the sending rate approaches c/2  from the left   the average delay becomes larger and larger when the sending rate exceeds c/2  the average number of queued packets in the router is unbounded and the average delay between source and destination becomes infinite  assuming that the connections operate at these sending rates for an infinite period of time   thus  while operating at an aggregate throughput of near c may be ideal from a throughput standpoint  it is far from ideal from a delay standpoint even in this  extremely  idealized scenario  we 've already found one cost of a congested network  large queueing delays are experienced as the packet arrival rate nears the link capacity scenario 2  two senders  a router with finite buffers let us now slightly modify scenario 1 in the following two ways first  the amount of router buffering is assumed to be finite second  we assume that each connection is reliable if a packet containing a transport-level segment is dropped at the router  it will eventually be retransmitted by the sender because packets can be retransmitted  we must now be more careful with our use of the term " sending rate " specifically  let us again denote the rate at which the application sends original data into the socket by ? in bytes/sec the rate at which the transport layer sends segments  containing original data or retransmitted data  into the network will be denoted ? in ' bytes/sec ? in ' is sometimes referred to as the offered load to the network file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  2 of 9  20/11/2004 15  52  13 principles of congestion control figure 3.6-3  scenario 2  two hosts  with retransmissions  and a router with finite buffers figure 3.6-4  scenario 2 performance   a  no retransmissions  b  only needed retransmisisons  c  extraneous  undeeded retransmissions the performance realized under scenario 2 will now depend strongly on how retransmission is performed first  consider the unrealistic case that host a is able to somehow  magically !  determine whether or not a buffer is free in the router and thus sends a packet only when a buffer is free in this case  no loss would occur  ? in would be equal to ? in '  and the throughput of the connection would be equal to ? in this case is shown in figure 3.6-4  a   from a throughput standpoint  performance is ideal  everything that is sent is received note that the average host sending rate can not exceed c/2 under this scenario  since packet loss is assumed never to occur file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  3 of 9  20/11/2004 15  52  13 principles of congestion control consider next the slightly more realistic case that the sender retransmits only when a packet is known for certain to be lost  again  this assumption is a bit of a stretch however  it possiible that the sending host might set its timeout large enough to be virtually assured that a packet that has not been acked has been lost  in this case  the performance might look something like that shown in figure 3.6-4  b   to appreciate what is happening here  consider the case that the offered load  ? in '  the rate of original data transmission plus retransmissions   equals .6c according to figure 3.6-4  b   at this value of the offered load  the rate at which data are delivered to the receiver application is c/3 thus  out of the .6c units of data transmitted  .3333 bytes/sec  on average  are original data and .26666 bytes per second  on average  are retransmitted data we see here another " cost " of a congested network  the sender must perform retransmissions in order to compensate for dropped  lost  packets due to buffer overflow finally  let us consider the more realistic case that the sender may timeout prematurely and retransmit a packet that has been delayed in the queue  but not yet lost in this case  both the original data packet and the retransmission may both reach the receiver of course  the receiver needs but one copy of this packet and will discard the retransmission in this case  the " work " done by the router in forwarding the retransmitted copy of the original packet was " wasted  " as the receiver will have already received the original copy of this packet the router would have better used the link transmission capacity transmitting a different packet instead here then is yet another " cost " of a congested network  unneeded retransmissions by the sender in the face of large delays may cause a router to use its link bandwidth to forward uneeded copies of a packet figure 3.6.4  c  shows the throughput versus offered load when each packet is assumed to be forwarded  on average  at least twice by the router since each packet is forwarded twice  the throughput achieved will be bounded above by the two-segment curve with the asymptotic value of c/4 scenario 3  four senders  routers with finite buffers  and multihop paths in our final congestion scenario  four hosts transmit packets  each over overlapping two-hop paths  as shown in figure 3.6 5 we again assume that each host uses a timeout/retransmission mechanism to implement a reliable data transfer service  that all hosts have the same value of ? in  and that all router links have capacity c bytes/sec file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  4 of 9  20/11/2004 15  52  13 principles of congestion control figure 3.6-5  four senders  routers with finite buffers  and multihop paths let us consider the connection from host a to host c  passing through routers r1 and r2 the a-c connection shares router r1 with the d-b connection and shares router r2 with the b-d connection for extremely small values of ? in  buffer overflows are rare  as in congestion scenarios 1 and 2   and the throughput approximately equals the offered load for slightly larger values of ? in  the corresponding throughput is also larger  as more original data is being transmitted into the network and delivered to the destination  and overflows are still rate  thus  for small values of ? in  an increase in ? in results in an increase in ? ? out having considered the case of extremely low traffic  let us next examine the case that ? in  and hence ? in '  is extremely large consider router r2 the a-c traffic arriving to router r2  which arrives at r2 after being forwarded from r1  can have an arrival rate at r2 that is at most c  the capacity of the link from r1 to r2  regardless of the value of ? in if ? in ' is extremely large for all connections  including the b-d connection   then the arrival rate of b-d traffic at r2 can be much larger than that of the a-c traffic because the a-c and b-d traffic must compete at router r2 for the limited amount of buffer space  the amount of a-c traffic that successfully gets through r2  i.e  is not lost due to buffer overflow  becomes smaller and smaller as the offered load from b-d gets larger and larger in the limit  as the offered load approaches infinity  an empty buffer at r2 is immediately filled by a b-d packet and the throughput of the a-c connection at r2 goes to zero this  in turn  implies that the a-c end-end throughput goes to zero in the limt of heavy traffic these considerations give rise to the offered load versus throughput tradeoff shown below in figure 3.6-6 figure 3.6-6  scenario 2 performance with finite buffers and multihope paths the reason for the eventual decrease in throughput with increasing offered load is evident when one considers the amount of wasted " work " done by the network in the high traffic scenario outlined above  whenever a packet is dropped at a second-hop router  the " work " done by the first-hop router in forwarding a packet to the second-hop router ends up being " wasted " the network would have been equally well off  more accurately  equally as bad off  if the first router had simply discarded that packet and remained idle more to the point  the transmission capacity used at the first router to forward the packet to the second router could have been much more profitably used to transmit a different packet  for example  when selecting a packet for transmission  it might be better for a router to give priorty to packets that have already traversed some number of upstream routers   so here we see yet another cost of dropping a packet due to congestion  when a packet is dropped along a path  the transmission capacity that was used at each of the upstream routers to forward that packet to the point at which it is dropped ends up having been wasted file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  5 of 9  20/11/2004 15  52  13 principles of congestion control 3.6.2 approaches toward congestion control in section 3.7  we will examine tcp 's specific approach towards congestion control in great detail here  we identify the two broad approaches that are taken in practice towards congestion control  and discuss specific network architectures and congestion control protocols embodying these approaches at the broadest level  we can distinguish among congestion control approaches based on the whether or not the network layer provides any explicit assistance to the transport layer for congestion control purposes  l end-end congestion control in an end-end approach towards congestion control  the network layer provides no explicit support to the transport layer for congestion control purposes even the presence of congestion in the network must be inferred by the end systems based only on observed network behavior  e.g  packet loss and delay   we will see in section 3.7 that tcp must necessarily take this end-end approach towards congestion control  since the ip layer provides no feedback to the end systems regarding network congestion tcp segment loss  as indicated by a timeout or a triple duplicate acknowledgement  is taken as an indication of network congestion and tcp decreases its window size accordingly we also see that new proposals for tcp use increasing round-trip delay values as indicators of increased network congestion l network-assisted congestion control with network-assisted congestion control  network-layer components  i.e  routers  provide explicit feedback to the sender regarding the congestion state in the network this feedback may be as simple as a single bit indicating congestion at a link  this approach was taken in the early ibm sna  schwartz 1982  and dec decnet  jain 1989   ramakrishnan 1990  architectures  was recently proposed for tcp/ ip networks  floyd 1994   ramakrishnan 1998   and is used in atm abr congestion control as well  as discussed below more sophisticated network-feedback is also possible for example  one form of atm abr congestion control that we will study shortly allows a router to explictly inform the sender of the transmission rate it  the router  can support on an outgoing link for network-assisted congestion control  congestion information is typically fed back from the network to the sender in one of two ways  as shown in figure 3.6-7 direct feedback may be sent from a network router to the sender this form of notification typically takes the form of a choke packet  essentially saying  " i 'm congested ! "   the second form of notification occurs when a router marks/updates a field in a packet flowing from sender to receiver to indiciate congestion upon receipt of a marked packet  the receiver then notifies the sender of the congestion indication note that this latter form of notification takes up to a full round-trip time file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  6 of 9  20/11/2004 15  52  13 principles of congestion control figure 3.6-7  two feedback pathways for network-indicated congestion information 3.6.3 atm abr congestion control our detailed study of tcp congestion control in section 3.7 will provide an in-depth case study of an end-end approach towards congestion control we conclude this section with a brief case study of the network-assisted congestion control mechanisms used in atm abr  available bit rate  service abr has been designed as an elastic data transfer service in a manner reminiscent of tcp when the network is underloaded  abr service should be able to take advantage of the spare available bandwidth ; when the network is congested  abr service should throttle its transmission rate to some predetermined minimum transmititon rate a detailed tutorial on atm abr congestion control and traffic management is provided in  jain 1996   figure 3.6-8 shows the framework for atm abr congestion control in our discussion below we adopt atm terminology  e.g  using the term " switch " rather than " router  " and the term " call " rather than " packet   with atm abr service  data cells are transmitted from a source to a destination through a series of intermediate switches interpersed with the data cells are so-called rm  resource management  cells ; we will see shortly that these rm cells can be used to convey congestion-related information among the hosts and switches when an rm cell is at a destination  it will be " turned around " and sent back to the sender  possibly after the destination has modified the contents of the rm cell   it is also possible for a switch to generate an rm cell itself and send this rm cell directly to a source rm cells can thus be used to provide both direct network feedback and network-feedback-via-the-receiver  as shown in figure 3.6-8 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  7 of 9  20/11/2004 15  52  13 principles of congestion control figure 3.6-8  congestion control framework for atm abr service atm abr congestion control is a rate-based approach that is  the sender explicitly computes a maximum rate at which it can send and regulates itself accordingly abr provides three mechanisms for signaling congestion-related information from the siwtches to the receiver  l efci bit each data cell contains an efci  explicit forward congestion indication  bit a congested network switch can set the efci bit in a data cell to 1 to signal congestion to the destination host  the destination must check the efci bit in all received data cells when an rm cell arrives at the destination  if the most recentlyreceived data cell had the efci bit set to 1  then the destination sets the ci  congestion indication  bit of the rm cell to 1 and sends the rm cell back to the sender using the efci in data cells and the ci bit in rm cells  a sender can thus be notified about congestion at a network switch l ci and ni bits as noted above  sender-to-receiver rm cells are interpersed with data cells the rate of rm cell interspersion is a tunable parameter  with one rm cell every 32 data cells being the default value these rm cells have a ci bit and a ni  no increase  bit that can be set by a congested network switch specifically  a switch can set the ni bit in a passing rm cell to1 under mild congestion and can set the ci bit to 1 under severe congestion conditions when a destination host receives an rm cell  it will send the rm cell back to the sender with its ci and ni bits intact  except that ci may be set to 1 by the destination as a result of the efci mechanism decribed above   l explicit rate  er  setting each rm cell also contains a 2-byte er  explicit rate  field a congested switch may lower the value contained in the er field in a passing rm cell in this manner  the er field will be set to the minimum supportable rate of all switches on the source-to-destination path an atm abr source adjusts the rate at which it can send cells as a function of the ci  ni and er values in a returned rm cell the rules for making this rate adjustment are rather complicated and tedious the interested reader is referred to  jain 1996  for details references  floyd 1994  floyd  s  " tcp and explicit congestion notification  " acm computer communication review  v 24 n 5  october 1994  p 10-23  jain 1989  r jain  " a delay-based approach for congestion avoidance in interconnected heterogeneous computer networks  " acm comp commun rev  vol 19  no 5  1989  pp 56-71 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  8 of 9  20/11/2004 15  52  13 principles of congestion control  jain 1996  r jain s kalyanaraman  s fahmy  r goyal  s kim  " tutorial paper on abr source behavior  " atm forum/96-1270  october 1996  ramakrishnan 1990  k k ramakrishnan and raj jain  " a binary feedback scheme for congestion avoidance in computer networks "  acm transactions on computer systems  vol.8  no.2  pp 158-181  may 1990  ramakrishnan 1998  ramakrishnan  k.k  and floyd  s  a proposal to add explicit congestion notification  ecn  to ip  internet draft draft-kksjf-ecn-03.txt  october 1998  work in progress  schwartz 1982  m schwartz  " performance analysis of the sna virtual route pacing control  " ieee transactions on communications  vol com-30  no 1  jan 1982   pp 172-184 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo % 20featuring % 20the % 20internet/principles_congestion.htm  9 of 9  20/11/2004 15  52  13 tcp congestion control 3.7 tcp congestion control in this section we return to our study of tcp as we learned in section 3.5  tcp provides a reliable transport service between two processes running on different hosts another extremely important component of tcp is its congestion control mechanism as we indicated in the previous section  tcp must use end-to-end congestion control rather than networkassisted congestion control  since the ip layer provides no feedback to the end systems regarding network congestion before diving into the details of tcp congestion control  let 's first get a high-level view of tcp 's congestion control mechanism  as well as the overall goal that tcp strives for when multiple tcp connections must share the bandwidth of a congested link  a tcp connection controls its transmission rate by limiting its number of transmitted-but-yet-to-be-acknowledged segments let us denote this number of permissible unacknowledged segments as w  often referred to as the tcp window size ideally  tcp connections should be allowed to transmit as fast as possible  i.e  to have as large a number of outstanding unacknowledged packets as possible  as long as segments are not lost  dropped at routers  due to congestion in very broad terms  a tcp connection starts with a small value of w and then " probes " for the existence of additional unused link bandwidth at the links on its end-to-end path by increasing w a tcp connection continues to increase w until a segment loss occurs  as detected by a timeout or duplicate acknowledgements   when such a loss occurs  the tcp connection reduces w to a " safe level " and then begins probing again for unused bandwidth by slowly increasing w  an important measure of the performance of a tcp connection is its throughput  the rate at which it transmits data from the sender to the receiver clearly  throughput will depend on the value of w w if a tcp sender transmits all w segments back-to-back  it must then wait for one round trip time  rtt  until it receives acknowledgments for these segments  at which point it can send w additional segments if a connection transmits w segments of size mss bytes every rtt seconds  then the connection 's throughput  or transmission rate  is  w * mss  /rtt bytes per second suppose now that k tcp connections are traversing a link of capacity r suppose also that there are no udp packets flowing over this link  that each tcp connection is transferring a very large amount of data  and that none of these tcp connections traverse any other congested link ideally  the window sizes in the tcp connections traversing this link should be such that each connection achieves a throughput of r/k more generally  if a connection passes through n links  with link n having transmission rate rn and supporting a total of kn tcp connections  then ideally this connection should achieve a rate of rn/kn on the nth link however  this connection 's end-to-end average rate can not exceed the minimum rate achieved at all of the links along the end-to-end path that is  the end-to-end transmission rate for this connection is r = min  r1/k1  rn/kn   the goal of tcp is to provide this connection with this end-to-end rate  r  in actuality  the formula for r is more complicated  as we should take into account the fact that one or more of the intervening connections may be bottlenecked at some other link that is not on this end-to-end path and hence can not use their bandwidth share  rn/kn in this case  the value of r would be higher than min  r1/k1,...,rn/kn    3.7.1 overview of tcp congestion control in section 3.5 we saw that each side of a tcp connection consists of a receive buffer  a send buffer  and several variables  lastbyteread  rcvwin  etc  the tcp congestion control mechanism has each side of the connection keep track of two additional variables  the congestion window and the threshold the congestion window  denoted congwin  imposes an additional constraint on how much traffic a host can send into a connection specifically  the amount of unacknowledged data that a host can have within a tcp connection may not exceed the minimum of congwin and rcvwin  i.e  lastbytesent  lastbyteacked < = min  congwin  rcvwin   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  1 of 15  20/11/2004 15  52  14 tcp congestion control the threshold  which we discuss in detail below  is a variable that effects how congwin grows let us now look at how the congestion window evolves throughout the lifetime of a tcp connection in order to focus on congestion control  as opposed to flow control   let us assume that the tcp receive buffer is so large that the receive window constraint can be ignored in this case  the amount of unacknowledged data hat a host can have within a tcp connection is solely limited by congwin further let 's assume that a sender has a very large amount of data to send to a receiver once a tcp connection is established between the two end systems  the application process at the sender writes bytes to the sender 's tcp send buffer tcp grabs chunks of size mss  encapsulates each chunk within a tcp segment  and passes the segments to the network layer for transmission across the network the tcp congestion window regulates the times at which the segments are sent into the network  i.e  passed to the network layer   initially  the congestion window is equal to one mss tcp sends the first segment into the network and waits for an acknowledgement if this segment is acknowledged before its timer times out  the sender increases the congestion window by one mss and sends out two maximum-size segments if these segments are acknowledged before their timeouts  the sender increases the congestion window by one mss for each of the acknowledged segments  giving a congestion window of four mss  and sends out four maximum-sized segments this procedure continues as long as  1  the congestion window is below the threshold and  2  the acknowledgements arrive before their corresponding timeouts during this phase of the congestion control procedure  the congestion window increases exponentially fast  i.e  the congestion window is initialized to one mss  after one rtt the window is increased to two segments  after two round-trip times the window is increased to four segments  after three round-trip times the window is increased to eight segments  etc this phase of the algorithm is called slow start because it begins with a small congestion window equal to one mss  the transmission rate of the connection starts slowly but accelerates rapidly  the slow start phase ends when the window size exceed the value of threshold once the congestion window is larger than the current value of threshold  the congestion window grows linearly rather than exponentially specifically  if w is the current value of the congestion window  and w is larger than threshold  then after w acknowledgements have arrived  tcp replaces w with w + 1  this has the effect of increasing the congestion window by one in each rtt for which an entire window 's worth of acknowledgements arrives this phase of the algorithm is called congestion avoidance the congestion avoidance phase continues as long as the acknowledgements arrive before their corresponding timeouts but the window size  and hence the rate at which the tcp sender can send  can not increase forever eventually  the tcp rate will be such that one of the links along the path becomes saturated  and which point loss  and a resulting timeout at the sender  will occur when a timeout occurs  the value of threshold is set to half the value of the current congestion window  and the congestion window is reset to one mss the sender then again grows the congestion window exponentially fast using the slow start procedure until the congestion window hits the threshold in summary  l when the congestion window is below the threshold  the congestion window grows exponentially l when the congestion window is above the threshold  the congestion window grows linearly l whenever there is a timeout  the threshold is set to one half of the current congestion window and the congestion window is then set to one if we ignore the slowstart phase  we see that tcp essentially increases its window size by 1 each rtt  and thus increases its transmission rate by an additive factor  when its network path is not congested  and decreases its window size by a factor of two each rtt when the path is congested for this reason  tcp is often referred to as an additive-increase  multiplicativedecrease  aimd  algorithm file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  2 of 15  20/11/2004 15  52  14 tcp congestion control figure 3.7-1  evolution of tcp 's congestion window the evolution of tcp 's congestion window is illustrated in figure 3.7-1 in this figure  the threshold is initially equal to 8 * mss the congestion window climbs exponentially fast during slow start and hits the threshold at the third transmission the congestion window then climbs linearly until loss occurs  just after transmission 7 note that the congestion window is 12 * mss when loss occurs the threshold is then set to .5 * congwin = 6 * mss and the congestion window is set 1 and the process continues this congestion control algorithm is due to v jacobson  jac88  ; a number of modifications to jacobson 's initial algorithm are described in  stevens 1994  rfc 2581   a trip to nevada  tahoe  reno and vegas the tcp congestion control algorithm just described is often referred to as tahoe one problem with the tahoe algorithm is that when a segment is lost the sender side of the application may have to wait a long period of time for the timeout for this reason  a variant of tahoe  called reno  is implemented by most operating systems like tahoe  reno sets its congestion window to one segment upon the expiration of a timer however  reno also includes the fast retransmit mechanism that we examined in section 3.5 recall that fast retransmit triggers the transmission of a dropped segment if three duplicate acks for a segment are received before the occurrence of the segment 's timeout reno also employs a fast recovery mechanism  which essentially cancels the slow start phase after a fast retransmission the interested reader is encouraged so see  stevens 1994  rfc 2581  for details most tcp implementations currently use the reno algorithm there is  however  another algorithm in the literature  the vegas algorithm  that can improve reno 's performance whereas tahoe and reno react to congestion  i.e  to overflowing router buffers   vegas attempts to avoid congestion while maintaining good throughput the basic idea of vegas is to  1  detect congestion in the routers between source and destination before packet loss occurs  and  2  lower the rate linearly when this imminent packet loss is detected imminent packet loss is predicted by observing the round-trip times  the longer the round-trip times of the packets  the greater the congestion in the routers the vegas algorithm is discussed in detail in  brakmo 1995  ; a study of its performance is given in  ahn 1995   as of 1999  vegas is not a part of the most popular tcp file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  3 of 15  20/11/2004 15  52  14 tcp congestion control implementations we emphasize that tcp congestion control has evolved over the years  and is still evolving what was good for the internet when the bulk of the tcp connections carried smtp  ftp and telnet traffic is not necessarily good for today 's webdominated internet or for the internet of the future  which will support who-knows-what kinds of services does tcp ensure fairness ? in the above discussion  we noted that the goal of tcp 's congestion control mechanism is to share a bottleneck link 's bandwidth evenly among the tcp connections traversing that link but why should tcp 's additive increase  multiplicative decrease algorithm achieve that goal  particularly given that different tcp connections may start at different times and thus may have different window sizes at a given point in time ?  chiu 1989  provides an elegant and intuitive explanation of why tcp congestion control converges to provide an equal share of a bottleneck link 's bandwidth among competing tcp connections let 's consider the simple case of two tcp connections sharing a single link with transmission rate r  as shown in figure 3.7 2 we 'll assume that the two connections have the same mss and rtt  so that if they have the same congestion window size  then they have the same throughput   that they have a large amount of data to send  and that no other tcp connections or udp datagrams traverse this shared link also  we 'll ignore the slow start phase of tcp  and assume the tcp connections are operating in congestion avoidance mode  additive increase  multiplicative decrease  at all times figure 3.7-2  two tcp connections sharing a single bottleneck link figure 3.7-3 plots the throughput realized by the two tcp connections if tcp is to equally share the link bandwidth between the two connections  then the realized throughput should fall along the 45 degree arrow  " equal bandwidth share "  emanating from the origin ideally  the sum of the two throughputs should equal r  certainly  each connection receiving an equal  but zero  share of the link capacity is not a desirable situation !   so the goal should be to have the achieved throughputs fall somewhere near the intersection of the " equal bandwidth share " line and the " full bandwidth utilization " line in figure 3.7-3 suppose that the tcp window sizes are such that at a given point in time  connections 1 and 2 realize throughputs indicated by point a in figure 3.7-3 because the amount of link bandwidth jointly consumed by the two connections is less than r  no loss will occur  and both connections will increase their window by 1 per rtt as a result of tcp 's congestion avoidance algorithm thus  the joint throughput of the two connections proceeds along a 45 degree line  equal increase for both connections  starting from point a eventually  the link bandwidth jointly consumed by the two connections will be greater than r and eventually packet loss will occur suppose that connections 1 and 2 experience packet loss when they realize file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  4 of 15  20/11/2004 15  52  14 tcp congestion control throughputs indicated by point b connections 1 and 2 then decrease their windows by a factor of two the resulting throughputs realized are thus at point c  halfway along a vector starting at b and ending at the origin because the joint bandwidth use is less than r at point c  the two connections again increase their throughputs along a 45 degree line starting from c eventually  loss will again occur  e.g  at point d  and the two connections again decrease their window sizes by a factor of two and so on you should convince yourself that the bandwidth realized by the two connections eventually fluctuates along the equal bandwidth share line you should also convince yourself that the two connections will converge to this behavior regardless of where they being in the two-dimensional space ! although a number of idealized assumptions lay behind this scenario  it still provides an intuitive feel for why tcp results in an equal sharing of bandwidth among connections figure 3.7-3  throughput realized by tcp connections 1 and 2 in our idealized scenario  we assumed that only tcp connections traverse the bottleneck link  and that only a single tcp connection is associated with a host-destination pair in practice  these two conditions are typically not met  and client-server applications can thus obtain very unequal portions of link bandwidth many network applications run over tcp rather than udp because they want to make use of tcp 's reliable transport service but an application developer choosing tcp gets not only reliable data transfer but also tcp congestion control we have just seen how tcp congestion control regulates an application 's transmission rate via the congestion window mechanism many multimedia applications do not run over tcp for this very reason  they do not want their transmission rate throttled  even if the network is very congested in particular  many internet telephone and internet video conferencing applications typically run over udp these applications prefer to pump their audio and video into the network at a constant rate and occasionally lose packets  rather than reduce their rates to " fair " levels at times of congestion and not lose any packets from the perspective of tcp  the multimedia applications running over udp are not being fair  they do not cooperate with the other connections nor adjust their transmission rates appropriately a major challenge in the upcoming years will be to develop congestion control mechanisms for the internet that prevent udp traffic from bringing the internet 's throughput to a grinding halt file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  5 of 15  20/11/2004 15  52  14 tcp congestion control but even if we could force udp traffic to behave fairly  the fairness problem would still not be completely solved this is because there is nothing to stop an application running over tcp from using multiple parallel connections for example  web browsers often use multiple parallel tcp connections to transfer a web page  the exact number of multiple connections is configurable in most browsers  when an application uses multiple parallel connections  it gets a larger fraction of the bandwidth in a congested link as an example consider a link of rate r supporting 9 on-going client-server applications  with each of the applications using one tcp connection if a new application comes along and also uses one tcp connection  then each application approximately gets the same transmission rate of r/10 but if this new application instead uses 11 parallel tcp connections  then the new application gets an unfair allocation of r/2 because web traffic is so pervasive in the internet  multiple parallel connections are not uncommon macroscopic description of tcp dynamics consider sending a very large file over a tcp connection if we take a macroscopic view of the traffic sent by the source  we can ignore the slow start phase indeed  the connection is in the slow-start phase for a relatively short period of time because the connection grows out of the phase exponentially fast when we ignore the slow-start phase  the congestion window grows linearly  gets chopped in half when loss occurs  grows linearly  gets chopped in half when loss occurs  etc this gives rise to the saw-tooth behavior of tcp  stevens 1994  shown in figure 3.7-1 given this sawtooth behavior  what is the average throuphput of a tcp connection ? during a particular round-trip interval  the rate at which tcp sends data is function of the congestion window and the current rtt  when the window size is w * mss and the current round-trip time is rtt  then tcp 's transsmission rate is  w * mss  /rtt during the congestion avoidance phase  tcp probes for additional bandwidth by increasing w by one each rtt until loss occurs ; denote by w the value of w at which loss occurs assuming that the rtt and w are approximately constant over the duration of the connection  the tcp transmission rate ranges from  w * mss  /  2rtt  to  w * mss  /rtt these assumputions lead to a highly-simplified macroscopic model for the steady-state behavior of tcp  the network drops a packet from the connection when the connection 's window size increases to w * mss ; the congestion window is then cut in half and then increases by one mss per round-trip time until it again reaches w this process repeats itself over and over again because the tcp throughput increases linearly between the two extreme values  we have  average throughput of a connection =  .75 * w * mss  /rtt using this highly idealized model for the steady-state dynamics of tcp  we can also derive an interesting expression that relates a connection 's loss rate to its available bandwidth  mahdavi 1997   this derivation is outlined in the homework problems 3.7.2 modeling latency  static congestion window many tcp connections transport relatively small files from one host to another for example  with http/1.0 each object in a web page is transported over a separate tcp connection  and many of these objects are small text files or tiny icons when transporting a small file  tcp connection establishment and slow start may have a significant impact on the latency in this section we present an analytical model that quantifies the impact of connection establishment and slow start on latency for a given object  we define the latency as the time from when the client initiates a tcp connection until when the client receives the requested object in its entirety the analysis presented here assumes that that the network is uncongested  i.e  the tcp connection transporting the object does not have to share link bandwidth with other tcp or udp traffic  we comment on this assumption below  also  in order to not to obscure the central issues  we carry out the analysis in the context of the simple one-link network as shown in figure 3.7-4  this link might model a single bottleneck on an end-to-end path see also the homework problems for an explicit extention to the case of multiple links  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  6 of 15  20/11/2004 15  52  14 tcp congestion control figure 3.7-4  a simple one-link network connecting a client and a server we also make the following simplifying assumptions  1 the amount of data that the sender can transmit is solely limited by the sender 's congestion window  thus  the tcp receive buffers are large  2 packets are neither lost nor corrupted  so that there are no retransmissions 3 all protocol header overheads  including tcp  ip and link-layer headers  are negligible and ignored 4 the object  that is  file  to be transferred consists of an integer number of segments of size mss  maximum segment size   5 the only packets that have non-negligible transmission times are packets that carry maximum-size tcp segments request packets  acknowledgements and tcp connection establishment packets are small and have negligible transmission times 6 the initial threshold in the tcp congestion control mechanism is a large value which is never attained by the congestion window we also introduce the following notation  1 the size of the object to be transferred is o bits 2 the mss  maximum size segment  is s bits  e.g  536 bytes   3 the transmission rate of the link from the server to the client is r bps 4 the round-trip time is denoted by rtt in this section we define the rtt to be the time elapsed for a small packet to travel from client to server and then back to the client  excluding the transmission time of the packet it includes the two end-to-end propagation delays between the two end systems and the processing times at the two end systems we shall assume that the rtt is also equal to the roundtrip time of a packet beginning at the server although the analysis presented in this section assumes an uncongested network with a single tcp connection  it nevertheless sheds insight on the more realistic case of multi-link congested network for a congested network  r roughly represents the amount of bandwidth recieved in steady state in the end-to-end network connection ; and rtt represents a round-trip delay that includes queueing delays at the routers preceding the congested links in the congested network case  we model each tcp connection as a constant-bit-rate connection of rate r bps preceded by a single slow-start phase  this is roughly how tcp tahoe behaves when losses are detected with triplicate acknowledgements  in our numerical examples we use values of r and rtt that reflect typical values for a congested network before beginning the formal analysis  let us try to gain some intuition let us consider what would be the latency if there were no congestion window constraint  that is  if the server were permitted to send segments back-to-back until the entire object is sent ? to answer this question  first note that one rtt is required to initiate the tcp connection after one rtt the client sends a request for the object  which is piggybacked onto the third segment in the three-way tcp handshake   after a total of two rtts the client begins to receive data from the server the client receives data from the server for a period of file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  7 of 15  20/11/2004 15  52  14 tcp congestion control time o/r  the time for the server to transmit the entire object thus  in the case of no congestion window constraint  the total latency is 2 rtt + o/r this represents a lower bound ; the slow start procedure  with its dynamic congestion window  will of course elongate this latency static congestion window although tcp uses a dynamic congestion window  it is instructive to first analyze the case of a static congestion window let w  a positive integer  denote a fixed-size static congestion window for the static congestion window  the server is not permitted to have more than w unacknowledged outstanding segments when the server receives the request from the client  the server immediately sends w segments back-to-back to the client the server then sends one segment into the network for each acknowledgement it receives from the client the server continues to send one segment for each acknowledgement until all of the segments of the object have been sent there are two cases to consider  1 ws/r > rtt + s/r in this case  the server receives an acknowledgement for the first segment in the first window before the server completes the transmission of the first window 2 ws/r < rtt + s/r in this case  the server transmits the first window 's worth of segments before the server receives an acknowledgement for the first segment in the window let us first consider case 1  which is illustrated in figure 3.7-5 in this figure the window size is w = 4 segments figure 3.7-5  the case that ws/r > rtt + s/r one rtt is required to initiate the tcp connection after one rtt the client sends a request for the object  which is piggybacked onto the third segment in the three-way tcp handshake   after a total of two rtts the client begins to receive data from the server segments arrive periodically from the server every s/r seconds  and the client acknowledges every segment it receives from the server because the server receives the first acknowledgement before it completes sending a file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  8 of 15  20/11/2004 15  52  14 tcp congestion control window 's worth of segments  the server continues to transmit segments after having transmitted the first window 's worth of segments and because the acknowledgements arrive periodically at the server every s/r seconds from the time when the first acknowledgement arrives  the server transmits segments continuously until it has transmitted the entire object thus  once the server starts to transmit the object at rate r  it continues to transmit the object at rate r until the entire object is transmitted the latency therefore is 2 rtt + o/r now let us consider case 2  which is illustrated in figure 3.7-6 in this figure  the window size is w = 2 segments figure 3.7-6  the case that ws/r < rtt + s/r once again  after a total of two rtts the client begins to receive segments from the server these segments arrive peridodically every s/r seconds  and the client acknowledges every segment it receives from the server but now the server completes the transmission of the first window before the first acknowledgment arrives from the client therefore  after sending a window  the server must stall and wait for an acknowledgement before resuming transmission when an acknowledgement finally arrives  the server sends a new segment to the client once the first acknowledgement arrives  a window 's worth of acknowledgements arrive  with each successive acknowledgement spaced by s/r seconds for each of these acknowledgements  the server sends exactly one segment thus  the server alternates between two states  a transmitting state  during which it transmits w segments ; and a stalled state  during which it transmits nothing and waits for an acknowledgement the latency is equal to 2 rtt plus the time required for the server to transmit the object  o/r  plus the amount of time that the server is in the stalled state to determine the amount of time the server is in the stalled state  let k = o/ws ; if o/ws is not an integer  then round k up to the nearest integer note that k is the number of windows of data there are in the object of size o the server is in the stalled state between the transmission of each of the windows  that is  for k-1 periods of time  with each period lasting rtt  w-1  s/r  see above diagram   thus  for case 2  latency = 2 rtt + o/r +  k-1   s/r + rtt  w s/r   combining the two cases  we obtain file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/congestion.html  9 of 15  20/11/2004 15  52  14 tcp congestion control latency = 2 rtt + o/r +  k-1   s/r + rtt  w s/r  + where  x  + = max  x,0   this completes our analysis of static windows the analysis below for dynamic windows is more complicated  but parallels the analysis for static windows 3.7.3 modeling latency  dynamic congestion window we now investigate the latency for a file transfer when tcp 's dynamic congestion window is in force recall that the server first starts with a congestion window of one segment and sends one segment to the client when it receives an acknowledgement for the segment  it increases its congestion window to two segments and sends two segments to the client  spaced apart by s/r seconds   as it receives the acknowledgements for the two segments  it increases the congestion window to four segments and sends four segments to the client  again spaced apart by s/r seconds   the process continues  with the congestion window doubling every rtt a timing diagram for tcp is illustrated in figure 3.7-7 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  10 of 15  20/11/2004 15  52  15 tcp congestion control figure 3.7-7  tcp timing during slow start note that o/s is the number of segments in the object ; in the above diagram  o/s = 15 consider the number of segments that are in each of the windows the first window contains 1 segment ; the second window contains 2 segments ; the third window contains 4 segments more generally  the kth window contains 2k-1 segments let k be the number of windows that cover the object ; in the preceding diagram k = 4 in general we can express k in terms of o/s as follows  after transmitting a window 's worth of data  the server may stall  i.e  stop transmitting  while it waits for an acknowledgement in the preceding diagram  the server stalls after transmitting the first and second windows  but not after transmitting the third let us now calculate the amount of stall time after transmitting the kth window the time from when the server begins to transmit the kth window until when the server receives an acknowledgement for the first segment in the window is s/r + rtt the transmission time of the kth window is  s/r  2k-1 the stall time is the difference of these two quantities  that is   s/r + rtt  2k-1  s/r   +  the server can potentially stall after the transmission of each of the first k-1 windows  the server is done after the transmission of the kth window  we can now calculate the latency for transferring the file the latency has three components  2rtt for setting up the tcp connection and requesting the file ; o/r  the transmission time of the object ; and the sum of all the stalled times thus  the reader should compare the above equation for the latency equation for static congestion windows ; all the terms are exactly the same except the term ws/r for static windows has been replaced by 2k-1s/r for dynamic windows to obtain a more compact expression for the latency  let q be the number of times the server would stall if the object contained an infinite number of segments  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  11 of 15  20/11/2004 15  52  15 tcp congestion control the actual number of times the server stalls is p = min  q,k-1   in the preceding diagram p = q = 2 combining the above two equations gives we can further simplify the above formula for latency by noting combining the above two equations gives the following closed-form expression for the latency  thus to calculate the latency  we simple must calculate k and q  set p = min  q,k-1   and plug p into the above formula it is interesting to compare the tcp latency to the latency that would occur if there were no congestion control  that is  no congestion window constraint   without congestion control  the latency is 2rtt + o/r  which we define to be the minimum latency it is simple exercise to show that we see from the above formula that tcp slow start will not significantly increase latency if rtt < < o/r  that is  if the round-trip time is much less than the transmission time of the object thus  if we are sending a relatively large object over an uncongested  high-speed link  then slow start has an insignificant affect on latency however  with the web we are often transmitting many small objects over congested links  in which case slow start can significantly increase latency  as we shall see in the following subsection   let us now take a look at some example scenarios in all the scenarios we set s = 536 bytes  a common default value for tcp we shall use a rtt of 100 msec  which is not an atypical value for a continental or inter-continental delay over moderately congested links first consider sending a rather large object of size o = 100kbytes the number of windows that cover this object is k = 8 for a number of transmission rates  the following chart examines the affect of the the slow-start file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  12 of 15  20/11/2004 15  52  15 tcp congestion control mechanism on the latency r o/r p minimum latency  o/r + 2 rtt latency with slow start 28 kbps 28.6 sec 1 28.8 sec 28.9 sec 100 kbps 8 sec 2 8.2 sec 8.4 sec 1 mbps 800 msec 5 1 sec 1.5 sec 10 mbps 80 msec 7 .28 sec .98 sec we see from the above chart that for a large object  slow-start adds appreciable delay only when the transmission rate is high if the transmission rate is low  then acknowledgments come back relatively quickly  and tcp quickly ramps up to its maximum rate for example  when r = 100 kbps  the number of stall periods is p = 2 whereas the number of windows to transmit is k = 8 ; thus the server stalls only after the first two of eight windows on one otherhand  when r = 10 mbps  the server stalls between each window  which causes a significant increase in the delay now consider sending a small object of size o = 5 kbytes the number of windows that cover this object is k = 4 for a number of transmission rates  the following chart examines the affect of the the slow-start mechanism r o/r p minimum latency  o/r + 2 rtt latency with slow start 28 kbps 1.43 sec 1 1.63 sec 1.73 sec 100 kbps .4 sec 2 .6 sec .757 sec 1 mbps 40 msec 3 .24 sec .52 sec 10 mbps 4 msec 3 .20 sec .50 sec once again slow start adds an appreciable delay when the transmission rate is high for example  when r = 1mbps the server stalls between each window  which causes the latency to be more than twice that of the minimum latency for a larger rtt  the affect of slow start becomes significant for small objects for smaller transmission rates the following chart examines the affect of slow start for rtt = 1 second and o = 5 kbytes  k = 4   r o/r p minimum latency  o/r + 2 rtt latency with slow start 28 kbps 1.43 sec 3 3.4 sec 5.8 sec 100 kbps .4 sec 3 2.4 sec 5.2 sec 1 mbps 40 msec 3 2.0 sec 5.0 sec 10 mbps 4 msec 3 2.0 sec 5.0 sec in summary  slow start can significantly increase latency when the object size is relatively small and the rtt is relatively large unfortunately  this is often the scenario when sending of objects over the world wide web an example  http file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  13 of 15  20/11/2004 15  52  15 tcp congestion control as an application of the the latency analysis  let 's now calculate the response time for a web page sent over non-persistent http suppose that the page consists of one base html page and m referenced images to keep things simple  let us assume that each of the m + 1 objects contains exactly o bits with non-persistent http  each object is tranferred independently  one after the other the response time of the web page is therefore the sum of the latencies for the individual objects thus note that the response time for non-persistent http takes the form  response time =  m + 1  o/r + 2  m + 1  rtt + latency due to tcp slow-start for each of the m + 1 objects clearly if there are many objects in the web page and if rtt is large  then non-persistent http will have poor responsetime performance in the homework problems we will investigate the response time for other http transport schemes  including persistent connections and non-persistent connections with parallel connections the reader is also encouraged to see  heidemann  for a related analysis references tcp congestion control has enjoyed a tremendous amount of study and pampering since its original adoption in 1988 this is not surprising as it is both an important and interesting topic there is currently a large and growing literature on the subject below we provide references for the citations in this section as well references to some other important works  ahn 1995  j.s ahn  p.b danzig  z liu and y yan  experience with tcp vegas  emulation and experiment  proceedings of acm sigcomm '95  boston  august 1995  brakmo 1995  l brakmo and l peterson  tcp vegas  end to end congestion avoidance on a global internet  ieee journal of selected areas in communications  13  8   1465-1480  october 1995  chiu 1989  d chiu and r jain  " analysis of the increase and decrease algorithms for congestion avoidance in computer networks  " computer networks and isdn systems  vol 17  pp 1  14  floyd 1991  s floyd  connections with multiple congested gateways in packet-switched networks  part 1  one-wat traffic  acm computer communications review  vol 21  no 5  october 1991  pp 30-47  heidemann 1997  j heidemann  k obraczka and j touch  modeling the performance of http over several transport protocols  " ieee/acm transactions on networking  vol 5  no 5  october 1997  pp 616-630  hoe 1996  j.c hoe  improving the start-up behavior of a congestion control scheme for tcp proceedings of acm sigcomm'96  stanford  august 1996  jacobson 1988  v jacobson  congestion avoidance and control proceedings of acm sigcomm '88 august 1988  p 314-329  lakshman 1995  t.v lakshman and u madhow  " performance analysis of window-based flow control using tcp/ip  the effect of high bandwidth-delay products and random loss "  ifip transactions c-26  high performance networking v  north holland  1994  pp 135-150  mahdavi 1997  j mahdavi and s floyd  tcp-friendly unicast rate-based flow control unpublsihed note  january 1997  nielsen 1997  h f nielsen  j gettys  a baird-smith  e prud'hommeaux  h.w lie  c lilley  network performance effects of http/1.1  css1  and png  w3c document  1997  also appeared in sigcomm ' 97    rfc 793  " transmission control protocol  " rfc 793  september 1981  rfc 854  j postel and j reynolds  " telnet protocol specifications  " rfc 854  may 1983 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  14 of 15  20/11/2004 15  52  15 tcp congestion control  rfc 1122  r braden  " requirements for internet hosts  communication layers  " rfc 1122  october 1989  rfc 1323  v jacobson  s braden  d borman  " tcp extensions for high performance  " rfc 1323  may 1992  rfc 2581  m allman  v paxson  w stevens  " tcp congestion control  rfc 2581  april 1999  shenker 1990  s shenker  l zhang and d.d clark  " some observations on the dynamics of a congestion control algorithm "  acm computer communications review  20  4   october 1990  pp 30-39  stevens 1994  w.r stevens  tcp/ip illustrated  volume 1  the protocols addison-wesley  reading  ma  1994  zhang 1991  l zhang  s shenker  and d.d clark  obervations on the dynamics of a congestion control algorithm  the effects of two way traffic  acm sigcomm '91  zurich  1991 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents copyright keith w ross and james f kurose 1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/congestion.html  15 of 15  20/11/2004 15  52  15 summary 3.8 summary we began this chapter by studying the services that a transport layer protocol can provide to network applications at one extreme  the transport layer protocol can be very simple and offer a no-frills service to applications  providing only the multiplexing/demultiplexing function for communicating processes the internet 's udp protocol is an example of such a no-frills  and no-thrills  from the persective of someone interested in networking  transport-layer protocol at the other extreme  a transport layer protocol can provide a variety of guarantees to applications  such as reliable delivery of data  delay guarantees and bandwidth guarantees nevertheless  the services that a transport protocol can provide are often constrained by the service model of the underlying network-layer protocol if the network layer protocol can not provide delay or bandwidth guarantees to transport-layer segments  then the transport layer protocol can not provide delay or bandwidth guarantees for the messages sent between processes we learned in section 3.4 that a transport layer protocol can provide reliable data transfer even if the underlying network layer is unreliable we saw that providing reliable data transfer has many subtle points  but that the task can be accomplished by carefully combining acknowledgments  timers  retransmissions and sequence numbers although we covered reliable data transfer in this chapter  we should keep in mind that reliable data transfer can be provided by link  network  transport or application layer protocols any of upper four layers of the protocol stack can implement acknowledgments  timers  retransmissions and sequence numbers and provide reliable data transfer to the layer above in fact  over the years  engineers and computer scientists have independently designed and implemented link  network  transport and application layer protocols that provide reliable data transfer  although many of these protocols have quietly disappeared   in section 3.5 we took a close look at tcp  the internet 's connection-oriented and reliable transportlayer protocol we learned that tcp is complex  involving connection management  flow control  roundtrip time estimation  as well as reliable data transfer in fact  tcp is actually more complex that we made it out to be  we intentionally did not discuss a variety of tcp patches fixes  and improvements that are widely implemented in various versions of tcp all of this complexity  however  is hidden from the network application if a client on one host wants to reliably send data to a server on another host  it simply opens a tcp socket to the server and then pumps data into that socket the client-server application is oblivious to all of tcp 's complexity in section 3.6 we examined congestion control from a broad perspective  and in section 3.7 we showed how tcp implements congestion control we learned that congestion is imperative for the well-being of the network without congestion control  a network can easily become grid locked  with little or no data being transported end-to-end in section 3.7 we learned that tcp implements an end-to-end congestion control mechanism that additively increases its transmission rate when the tcp connection 's path is judged to be congestion-free  and nultiplicatively decreases its transmission rate when loss occurs this file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/summary.html  1 of 2  20/11/2004 15  52  15 summary mechanism also strives to give each tcp connection passing through a congested link an equal share of the link bandwidth we also examined in some depth the impact of tcp connection establishment and slow start on latency we observed that in many important scenarios  connection establishment and slow start significantly contribute to end-to-end delay we emphasize once more that tcp congestion control has evolved over the years  remains an area of intensive research  and will likely continue to evolve in the upcoming years in chapter 1 we said that a computer network can be partitioned into the " network edge " and the " network core "  the network edge covers everything that happens in the end systems having now covered the application layer and the transport layer  our discussion of the network edge is now complete it is time to explore the network core ! this journey begins in the next chapter  where we 'll study the network layer  and continues into chapter 5  where we 'll study the link layer copyright 1999 keith w ross and james f kurose  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/summary.html  2 of 2  20/11/2004 15  52  15 chapter 4 homework problems homework problems and discussion questions chapter 3 review questions sections 3.1-3.3 1  consider a tcp connection between host a and host b suppose that the tcp segments traveling from host a to host b have source port number x and destination port number y what are the source and destination port numbers for the segments travelling from host b to host a ? 2  describe why an application developer may choose to run its application over udp rather than tcp 3  is it possible for application to enjoy reliable data transfer even when the application runs over udp ? if so  how ? section 3.5 4  true or false  a  host a is sending host b a large file over a tcp connection assume host b has no data to send a host b will not send acknowledgements to host a because b can not piggyback the acknowledgementson data ? b  the size of the tcp rcvwindow never changes throughout the duration of the connection ? c  suppose host a is sending host b a large file over a tcp connection the number of unacknowledged bytes that a sends can not exceed the size of the receive buffer ? d  suppose host a is sending a large file to host b over a tcp connection if the sequence number for a segment of this connection is m  then the sequence number for the subsequent segment will necessarily be m + 1 ? e  the tcp segment has a field in its header for rcvwindow ? f  suppose that the last samplertt in a tcp connection is equal to 1 sec then timeout for the connection will necessarily be set to a value > = 1 sec g  suppose host a sends host b one segment with sequence number 38 and 4 bytes of data then in this same segment the acknowledgement number is necessarily 42 ? 5  suppose a sends two tcp segments back-to-back to b the first segment has sequence number 90 ; the second has sequence number 110 a  how much data is the first segment ? b  suppose that the first segment is lost  but the second segment arrives at b in the acknowledgement that b sends to a  what will be the acknowledgment number ? 6  consider the telent example discussed in section 3.5 a few seconds after the user types the letter 'c ' the user types the letter 'r' after typing the letter 'r ' how many segments are sent and what is put in the sequence number and acknowledgement fields of the segments section 3.7 7  suppose two tcp connections are present over some bottleneck link of rate r bps both connections have a huge file to send  in the same direction over the bottleneck link   the transmissions of the files start at the same time what is the transmission rate that tcp would like to give to each of the connections ? 8  true or false  consider congestion control in tcp when a timer expires at the sender  the threshold is set to one half of its previous value ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/hw_2.htm  1 of 5  20/11/2004 15  52  16 chapter 4 homework problems problems 1  suppose client a initiates an ftp session with server s at about the same time  client b also initiates an ftp session with server s provide possible source and destination port numbers for   a  the segments sent from a to s ?  b  the segments sent from b to s ?  c  the segments sent from s to a ?  d  the segments sent from s to b ?  e  if a and b are different hosts  is it possible that the source port numbers in the segments from a to s are the same as those from b to s ?  f  how about if they are the same host ? 2  udp and tcp use 1 's complement for their checksums suppose you have the following three 8-bit words  01010101  01110000  11001100 what is the 1 's complement of the sum of these words ? show all work why is it that udp take the 1 's complement of the sum  i.e  why not just use the sum ? with the 1 's complement scheme  how does the receiver detect errors is it possible that a 1-bit error will go undetected ? how about a 2-bit error ? 3  protocol rdt2.1 uses both ack 's and naks redesign the protocol  adding whatever additional protocol mechanisms are needed  for the case that only ack messages are used assume that packets can be corrupted  but not lost give the sender and receiver fsms  and a trace of your protocol in operation  using traces as in figure \ ref  fig57    show also how the protocol works in the case of no errors  and show how your protocol recovers from channel bit errors 4  consider the following  incorrect  fsm for the receiver for protocol rtd2.1 show that this receiver  when operating with the sender shown in figure 3.4-5 can lead the sender and receiver to enter into a deadlock state  where each is waiting for an event that will never occur 5  in protocol rdt3.0  the ack packets flowing from the receiver to the sender do not have sequence numbers  although they do have an ack field that contains the sequence number of the packet they are acknowledging   why is it that our ack packets do not require sequence numbers ? 6  draw the fsm for the receiver side of protocol rdt 3.0 7  give a trace of the operation of protocol rdt3.0 when data packets and acknowledgements packets are garbled your trace should be similar to that used in figure 3.4-9 8  consider a channel that can lose packets but has a maximum delay that is known modify protocol rdt2.1 to include sender timeout and retransmit informally argue why your protocol can communicate correctly over this channel file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/hw_2.htm  2 of 5  20/11/2004 15  52  16 chapter 4 homework problems 9  the sender side of rdt3.0 simply ignores  i.e  takes no action on  all received packets which are either in error  or have the wrong value in the acknum field of an acknowledgement packet suppose that in such circumstances  rdt3.0 were to simply retransmit the current data packet would the protocol still work ?  hint  consider what would happen in the case that there are only it errors ; no packet losses and no premature timeouts occur consider how many times the nth packet is sent  in the limit as n approaches infinity 10  consider the cross-country example shown in figure 3.4-10 how big would the window size have to be for the channel utilization to be greater than 90 % ? 11  design a reliable  pipelined  data transfer protocol that uses only negative acknowledgements how quickly will your protocol respond to lost packets when the arrival rate of data ot the sender is low ? is high ? 12  consider transferring an enormous file of l bytes from host a to host b assumme an mss of 1460 bytes a  what us the maximum length of l such that tcp sequence numbers are not exhausted ? recall that the tcp number field has four bytes b  for the l you obtain in  a   find how long it takes to transmit the file assme that a total of 66 bytes of transport  network and data-link header are added to each segment before the resulting packet is sent out over a 10 mbps link ignore flow control and congestion control  so a can pump out the segments back-to-back and continuously 13  in figure 3.5-5  we see that tcp waits until it has received three duplicate ack before performing a fas retransmit why do you think the tcp designers chose not to perform a fast retransmit after the first duplicate ack for a segment is received ? 14  consider the tcp procedure for estimating rtt suppose that x = .1 let samplertt1 be the most recent sample rtt  let samplertt2 be the next most recent sample rtt  etc  a  for a given tcp connection  suppose 4 acknowledgements have been returned with corresponding sample rtts samplertt4  samplertt3  samplertt2  and samplertt1 express estimatedrtt in terms of the four sample rtts  b  generalize your formula for n sample round-trip times  c  for the formula in part  b  let n approach infinity comment on why this averaging procedure is called an exponential moving average 15  refer to figure 3.7-3 that illustrates the convergence of tcp 's additive increase  multiplicative decrease algorithm suppose that instead of a multiplicative decrease  tcp decreased the window size by a constant amount would the resulting additive increase additive decrease converge to an equal share algorithm ? justify your answer using a diagram similar to figure 3.7-3 16  recall the idealized model for the steady-state dynamics of tcp in the period of time from when the connection 's window size varies from  w * mss  /2 to w * mss  only one packet is lost  at the very end of the period    a  show that the loss rate is equal to l = loss rate = 1/   3/8  * w2  w/4    b  use the above result to show that if a connection has loss rate l  then its average bandwidth is approximately given by  average bandwidth of connection ~ 1.22 * mss /  rtt * sqrt  l    17  consider sending an object of size o = 100 kbytes from server to client let s = 536 bytes and rtt = 100msec suppose the transport protocol uses static windows with window size w a  for a transmission rate of 28 kbps  determine the minimum possible latency determine the minimum window size that achieves this latency b  repeat  a  for 100 kbps c  repeat  a  for 1 mbps d  repeat  a  for 10 mbps 18  suppose tcp increased its congestion window by two rather than by one for each received acknowledgement during slow start thus the first window consists of one segment  the second of three segments  the third of nine segments  etc for this slow-start procedure  a  express k in terms of o and s b  express q in terms of rtt  s and r file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/hw_2.htm  3 of 5  20/11/2004 15  52  16 chapter 4 homework problems c  express latency in terms of p = min  k-1,q   o  r and rtt 19  consider the case rtt = 1 second and o = 100 kbytes prepare a chart  similar to the charts in section 3.5.2  that compares the minimum latency  o/r + 2 rtt  with the latency with slow start for r = 28kbps  100 kbps  1 mbps and 10 mbps 20  true or false a  if a web page consists of exactly one object  then non-persistent and persistent connections have exactly the same response time performance ? b  consider sending one object of size o from server to browser over tcp if o > s  where s is the maximum segment size  then the server will stall at least once ? c  suppose a web page consists of 10 objects  each of size o bits for persistent http  the rtt portion of the response time is 20 rtt ? d  suppose a web page consists of 10 objects  each of size o bits for non-persistent http with 5 parallel connections  the rtt portion of the response time is 12 rtt ? 21  the analysis for dynamic windows in the text assumes that there is one link between server and client redo the analysis for t links between server and client assume the network has no congestion  so the packets experience no queueing delays the packets do experience a store-andforward delay  however the definition of rtt is the same as that given in the section on tcp congestion control  hint  the time for the server to send out the first segment until it receives the acknowledgement is ts/r + rtt  22  recall the discussion at the end of section 3.7.3 on the response time for a web page for the case of non-persistent connections  determine a general expression for the fraction of the response time that is due to tcp slow start 23  with persistent http  all objects are sent over the same tcp connection as we discussed in chapter 2  one of the motivations behind persistent http  with pipelining  is to diminish the affects of tcp connection establishment and slow start on the response time for a web page in this problem we investigate the response time for persistent http assume that the client requests all the images at once  but only when it has it has received the entire html base page let m + 1 denote the number of objects and let o denote the size of each object a  argue that the response time takes the form  m + 1  o/r + 3rtt + latency due to slow-start compare the contribution of the rtts in this expression with that in non-persistent http b  assume that k = log2  o/r + 1  is an integer ; thus  the last window of the base html file transmits an entire window 's worth of segments  i e  window k transmits 2k-1segments let p ' = min  q,k'-1  and note that k ' is the number of windows that cover an object of size  m + 1  o and p ' is the number of stall periods when sending the large object over a single tcp connection suppose  incorrectly  the server can send the images without waiting for the formal request for the images from the client show that the response time is that of sending one large object of size  m + 1  o  c  the actual response time for persistent http is somewhat larger than the approximation this is because the server must wait for a request for the images before sending the images in particular  the stall time between the kth and  k + 1  st window is not  s/r + rtt  2k-1  s/r   + but is instead rtt show that 24  consider the scenario of rtt = 100 msec  o = 5 kbytes  and m = 10 construct a chart that compares the response times for non-persistent and file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/hw_2.htm  4 of 5  20/11/2004 15  52  16 chapter 4 homework problems persistent connections for 28 kbps  100 kbps  1 mbps and 10 mbps note that persistent http has substantially lower response time than nonpersistent http for all the transmission rates except 28 kbps 25  repeat the above question for the case of rtt = 1 sec  o = 5 kbytes  m = 10 note that for these parameters  persistent http gives a significantly lower response time than non-persistent http for all the transmission rates 26  consider now non-persistent http with parallel tcp connections recall that browsers typically operate in this mode when using http/1.0 let x denote the maximum number of parallel connections that the client  browser  is permitted to open in this mode  the client first uses one tcp connection to obtain the base html file upon receiving the base html file  the client establishes m/x sets of tcp connections  with each set having x parallel connections argue that the total response time takes the form  response time =  m + 1  o/r + 2  m/x + 1  rtt + latency due to slow-start stalling compare the contribution of the term involving rtt to that of persistent connections and non-persistent  non-parallel  connections discussion questions 1  consider streaming stored audio does it make sense to run the application over udp or tcp ? which one does realnetworks use ? why ? are there any other streaming stored audio products ? which transport protocol do they use and why ? programming assignment in this programming assignment  you will be writing the sending and receiving transport-level code for implementing a simple reliable data transfer protocol  for either the alternating bit protocol or a go-back-n protocol this should be fun since your implementation will differ very little from what would be required in a real-world situation since you presumably do not have standalone machines  with an os that you can modify   your code will have to execute in a simulated hardware/ software environment however  the programming interface provided to your routines  i.e  the code that would call your entities from above  i.e  from layer 5  and from below  i.e  from layer 3   is very close to what is done in an actual unix environment  indeed  the software interfaces described in this programming assignment are much more realistic that the infinite loop senders and receivers that many textbooks describe   stopping/starting of timers are also simulated  and timer interrupts will cause your timer handling routine to be activated you can find full details of the programming assignment  as well as c code that you will need to create the simulated hardware/software environment at http  //gaia.cs.umass.edu/kurose/transport/programming_assignment.htm file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/hw_2.htm  5 of 5  20/11/2004 15  52  16 network layer  introduction and service models 4.1 introduction and network service models we saw in the previous chapter that the transport layer provides communication service between two processes running on two different hosts in order to provide this service  the transport layer relies on the services of the network layer  which provides a communication service between hosts in particular  the network-layer moves transport-layer segments from one host to another at the sending host  the transport layer segment is passed to the network layer the network layer then " somehow " gets the segment to the destination host and passes the segment up the protocol stack to the transport layer exactly how the network layer moves a segment from the transport layer of an origin host to the transport layer of the destination host is the subject of this chapter we will see that unlike the transport layers  the network layer requires the coordination of each and every host and router in the network because of this  network layer protocols are among the most challenging  and therefore interesting !  in the protocol stack figure 4.1-1 shows a simple network with two hosts  h1 and h2  and four routers  r1  r2  r3 and r4   the role of the network layer in a sending host is to begin the packet on its journey to the the receiving host for example  if h1 is sending to h2  the network layer in host h1 transfers these packets to it nearby router  r2 at the receiving host  e.g  h2   the network layer receives the packet from its nearby router  in this case  r3  and delivers the packet up to the transport layer at h2 the primary role of the routers is to " switch " packets from input links to output links note that the routers in figure 4.1-1 are shown with a truncated protocol stack  i.e  with no upper layers above the network layer  since routers do not run transport and application layer protocols such as those we examined in chapters 2 and 3 figure 4.1-1  the network layer the role of the network layer is thus deceptively simple  to transport packets from a sending host to a receiving host to do so  three important network layer functions can be identified  l path determination the network layer must determine the route or path taken by packets as they flow from a sender to a receiver the algorithms that calculate these paths are referred to as routing algorithms a routing file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  1 of 7  20/11/2004 15  52  17 network layer  introduction and service models algorithm would determine  for example  whether packets from h1 to h2 flow along the path r2-r1-r3 or path r2 r4-r3  or any other path between h1 and h2   much of this chapter will focus on routing algorithms in section 4.2 we will study the theory of routing algorithms  concentrating on the two most prevalent classes of routing algorithms  link state routing and distance vector routing we will see that the complexity of a routing algorithms grows considerably as the number of routers in the network increases this motivates the use of hierarchical routing  a topic we cover in section 4.3 in section 4.8 we cover multicast routing  the routing algorithms  switching function  and call setup mechanisms that allow a packet that is sent just once by a sender to be delivered to multiple destinations l switching when a packet arrives at the input to a router  the router must move it to the appropriate output link for example  a packet arriving from host h1 to router r2 must either be forwarded towards h2 either along the link from r2 to r1 or along the link from r2 to r4 in section 4.6  we look inside a router and examine how a packet is actually switched  moved  from an input link to an output link l call setup recall that in our study of tcp  a three-way handshake was required before data actually flowed from sender to receiver this allowed the sender and receiver to setup the needed state information  e.g  sequence number and initial flow control window size   in an analogous manner  some network layer architectures  e.g  atm  requires that the routers along the chosen path from source to destination handshake with each other in order to setup state before data actually begins to flow in the network layer  this process is referred to as call setup the network layer of the internet architecture does not perform any such call setup before delving into the details of the theory and implementation of the network layer  however  let us first take the broader view and consider what different types of service might be offered by the network layer 4.1.1 network service model when the transport layer at a sending host transmits a packet into the network  i.e  passes it down to the network layer at the sending host   can the transport layer count on the network layer to deliver the packet to the destination ? when multiple packets are sent  will they be delivered to the transport layer in the receiving host in the order in which they were sent ? will the amount of time between the sending of two sequential packet transmissions be the same as the amount of time between their reception ? will the network provide any feedback about congestion in the network ? what is the abstract view  properties  of the channel connecting the transport layer in the two hosts ? the answers to these questions and others are determined by the service model provided by the network layer the network service model defines the characteristics of end-to-end transport of data between one " edge " of the network and the other  i.e  between sending and receiving end systems datagram or virtual circuit ? perhaps the most important abstraction provided by the network layer to the upper layers is whether or not the network layer uses virtual circuits  vcs  or not you may recall from chapter 1 that a virtual-circuit packet network behaves much like a telephone network  which uses " real circuits " as opposed to " virtual circuits "  there are three identifiable phases in a virtual circuit  l vc setup during the setup phase  the sender contacts the network layer  specifies the receiver address  and waits for the network to setup the vc the network layer determines the path between sender and receiver  i.e  the series of links and switches through which all packets of the vc will travel as discussed in chapter 1  this typically involves updating tables in each of the packet switches in the path during vc setup  the network layer may also reserve resources  e.g  bandwidth  along the path of the vc l data transfer once thevc has been established  data can begin to flow along the vc l virtual circuit teardown this is initiated when the sender  or receiver  informs the network layer of its desire to terminate the vc the network layer will then typically inform the end system on the other side of the network of file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  2 of 7  20/11/2004 15  52  17 network layer  introduction and service models the call termination  and update the tables in each of the packet switches on the path to indicate that the vc no longer exists there is a subtle but important distinction between vc setup at the network layer and connection setup at the transport layer  e.g  the tcp 3-way handshake we studied in chapter 3   connection setup at the transport layer only involves the two end systems the two end systems agree to communicate and together determine the parameters  e.g  initial sequence number  flow control window size  of their transport level connection before data actually begins to flow on the transport level connection although the two end systems are aware of the transport-layer connection  the switches within the network are completely oblivious to it on the otherhand  with a virtual-circuit network layer  packet switches are involved in virtual-cicuit setup  and each packet switch is fully aware of all the vcs passing through it the messages that the end systems send to the network to indicate the initiation or termination of a vc  and the messages passed between the switches to set up the vc  i.e to modify switch tables  are known as signaling messages and the protocols used to exchange these messages are often referred to as signaling protocols vc setup is shown pictorially in figure 4.1-2 figure 4.1-2  virtual circuit service model we mentioned in chapter 1 that atm uses virtual circuits  although virtual circuits in atm jargon are called virtual channels thus atm packet switches receive and process vc setup and tear down messages  and they also maintain vc state tables frame relay and x.25  which will be covered in chapter 5  are two other networking technologies that use virtual circuits with a datagram network layer  each time an end system wants to send a packet  it stamps the packet with the address of the destination end system  and then pops the packet into the network as shown in figure 4.1-3  this is done without any vc setup packet switches  called " routers " in the internet  do not maintain any state information about vcs because there are no vcs ! instead  packet switches route a packet towards its destination by examining the packet 's destination address  indexing a routing table with the destination address  and forwarding the packet in the direction of the destination  as discussed in chapter 1  datagram routing is similar to routing ordinary postal mail  because routing tables can be modified at any time  a series of packets sent from one end system to another may follow different paths through the network and file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  3 of 7  20/11/2004 15  52  17 network layer  introduction and service models may arrive out of order the internet uses a datagram network layer figure 4.1-3  datagram service model you may recall from chapter 1 that a packet-switched network typically offers either a vc service or a datagram service to the transport layer  and not both services for example  an atm network offers only a vc service to the atm transport layer  more precisely  to the atm adaptation layer   and the internet offers only a datagram sevice to the transport layer the transport layer in turn offers services to communicating processes at the application layer for example  tcp/ip networks  such as the internet  offers a connection-oriented service  using tcp  and connectionless service  udp  to its communicating processes an alternative terminology for vc service and datagram service is network-layer connection-oriented service and network-layer connectionless service  respectively indeed  the vc service is a sort of connection-oriented service  as it involves setting up and tearing down a connection-like entity  and maintaining connection state information in the packet switches the datagram service is a sort of connectionless service in that it does n't employ connection-like entities both sets of terminology have advantages and disadvantages  and both sets are commonly used in the networking literature we decided to use in this book the " vc service " and " datagram service " terminology for the network layer  and reserve the " connection-oriented service " and " connectionless service " terminology for the transport layer we believe this decision will be useful in helping the reader delineate the services offered by the two layers the internet and atm network service models network architecture service model bandwidth guarantee no loss guarantee ordering timing congestion indication internet best effort none none any order possible not maintained none atm cbr guaranteed constant rate yes in order maintained congestion will not occur file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  4 of 7  20/11/2004 15  52  17 network layer  introduction and service models atm vbr guaranteed rate yes in order maintained congestion will not occur atm abr guaranteed minimum none in order not maintained congestion indication provided atm ubr none none in order not maintained none table 4.1-1  internet and atm network service models the key aspects of the service model of the internet and atm network architectures are summarized in table 4.1-1 we do not want to delve deeply into the details of the service models here  it can be quite " dry " and detailed discussions can be found in the standards themselves  atm forum 1997    a comparison between the internet and atm service models is  however  quite instructive the current internet architecture provides only one service model  the datagram service  which is also known as " best effort service " from table 4.1-1  it might appear that best effort service is a euphemism for " no service at all " with best effort service  timing between packets is not guaranteed to be preserved  packets are not guaranteed to be received in the order in which they were sent  nor is the eventual delivery of transmitted packets guaranteed given this definition  a network which delivered no packets to the destination would satisfy the definition best effort delivery service  indeed  today 's congested public internet might sometimes appear to be an example of a network that does so !   as we will discuss shortly  however  there are sound reasons for such a minimalist network service model the internet 's best-effort only service model is currently being extended to include so-called " integrated services " and " differentiated service " we will cover these still evolving service models later in chapter 6 let us next turn to the atm service models as noted in our overview of atm in chapter 1  there are two atm standards bodies  the itu and the atm forum   their network service model definitions contain only minor differences and we adopt here the terminology used in the atm forum standards the atm architecture provides for multiple service models  that is  each of the two atm standards each has multiple service models   this means that within the same network  different connections can be provided with different classes of service constant bit rate  cbr  network service was the first atm service model to be standardized  probably reflecting the fact that telephone companies were the early prime movers behind atm  and cbr network service is ideally suited for carrying real-time  constant-bit-rate  streamline audio  e.g  a digitized telephone call  and video traffic the goal of cbr service is conceptually simple  to make the network connection look like a dedicated copper or fiber connection between the sender and receiver with cbr service  atm cells are carried across the network in such a way that the end-end delay experienced by a cell  the so-called cell transfer delay  cdt   the variability in the end-end delay  often referred to as " jitter " or " cell delay variation  cdv  "   and the fraction of cells that are lost or deliver late  the so-called cell loss rate  clr  are guaranteed to be less than some specified values also  an allocated transmission rate  the peak cell rate  pcr  is defined for the connection and the sender is expected to offer data to the network at this rate the values for the pcr  cdt  cdv  and clr are agreed upon by the sending host and the atm network when the cbr connection is first established a second conceptually simple atm service class is unspecified bit rate  ubr  network service unlike cbr service  which guarantees rate  delay  delay jitter  and loss  ubr makes no guarantees at all other than in-order delivery of cells  that is  cells that are fortunate enough to make it to the receiver   with the exception of in-order delivery  ubr service is thus equivalent to the internet best effort service model as with the internet best effort service model  ubr also provides no feedback to the sender about whether or not a cell is dropped within the network for reliable transmission of data over a ubr network  higher layer protocols  such as those we studied in the previous chapter  are needed ubr service might be well suited for non-interactive data transfer applications such as email and newsgroups file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  5 of 7  20/11/2004 15  52  17 network layer  introduction and service models if ubr can be thought of as a " best effort " service  then available bit rate  abr  network service might best be characterized as a " better " best effort service model the two most important additional features of abr service over ubr service are  l a minimum cell transmission rate  mcr  is guaranteed to a connection using abr service if  however  the network has enough free resources at a given time  a sender may actually be able to successfully send traffic at a higher rate than the mcr l congestion feedback from the network an atm network provides feedback to the sender  in terms of a congestion notification bit  or a lower rate at which to send  that controls how the sender should adjust its rate between the mcr and some peak cell rate  pcr   abr senders must decrease their transmission rates in accordance with such feedback abr provides a minimum bandwidth guarantee  but on the other hand will attempt to transfer data as fast as possible  up to the limit imposed by the pcr   as such  abr is well suited for data transfer where it is desirable to keep the transfer delays low  e.g  web browsing   the final atm service model is variable bit rate  vbr  network service vbr service comes in two flavors  and in the itu specification of vbr-like service comes in four flavors  perhaps indicating a service class with an identity crisis !   in real-time vbr service  the acceptable cell loss rate  delay  and delay jitter are specified as in cbr service however  the actual source rate is allowed to vary according to parameters specified by the user to the network the declared variability in rate may be used by the network  internally  to more efficiently allocate resources to its connections  but in terms of the loss  delay and jitter seen by the sender  the service is essentially the same as cbr service while early efforts in defining a vbr service models were clearly targeted towards real-time services  e.g  as evidenced by the pcr  cdt  cdv and clr parameters   a second flavor of vbr service is now targeted towards non-real-time services and provides a cell loss rate guarantee an obvious question with vbr is what advantages it offers over cbr  for real-time applications  and over ubr and abr for non-real-time applications currently  there is not enough  any ?  experience with vbr service to answer this questions an excellent discussion of the rationale behind various aspects of the atm forum 's traffic management specification 4.0  atm forum 1996  for cbr  vbr  abr and ubr service is  garret 1996   4.1.2 origins of datagram and virtual circuit service the evolution of the internet and atm network service models reflects their origins with the notion of a virtual circuit as a central organizing principle  and an early focus on cbr services  atm reflects its roots in the telephony world  which uses " real circuits "   the subsequent definition of ubr and abr service classes acknowledges the importance of the types of data applications developed in the data networking community given the vc architecture and a focus on supporting real-time traffic with guarantees about the level of received performance  even with data-oriented services such as abr   the network layer is significantly more complex than the best effort internet this too  is in keeping with the atm 's telephony heritage telephone networks  by necessity  had their " complexity ' within the network  since they were connecting " dumb " end-system devices such as a rotary telephone  for those too young to know  a rotary phone is a nondigital telephone with no buttons  only a dial   the internet  on the other hand  grew out of the need to connect computers  i.e  more sophisticated end devices  together with sophisticated end-systems devices  the internet architects chose to make the network service model  best effort  as simple as possible and to implement any additional functionality  e.g  reliable data transfer   as well as any new application level network services at a higher layer  at the end systems this inverts the model of the telephone network  with some interesting consequences  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  6 of 7  20/11/2004 15  52  17 network layer  introduction and service models l the resulting network service model which made minimal  no !  service guarantees  and hence posed minimal requirements on the network layer  also made it easier to interconnect networks that used very different link layer technologies  e.g  satellite  ethernet  fiber  or radio  which had very different characteristics  transmission rates  loss characteristics   we will address the interconnection of ip networks in detail section 4.4 l as we saw in chapter 2  applications such as email  the web  and even a network-layer-centric service such as the dns are implemented in hosts  servers  at the edge of the network the ability to add a new service simply by attaching a host to the network and defining a new higher layer protocol  such as http  has allowed new services such as the www to be adopted in a breathtakingly short period of time as we will see in chapter 6  however  there is considerable debate in the internet community about how the network layer architecture must evolve in order to support the real-time services such a multimedia an interesting comparison of the atm and the proposed next generation internet architecture is given in  crowcroft 95   references  atm forum 1996  atm forum  " traffic management 4.0  " atm forum document af-tm-0056.0000 on-line  atm forum 1997  atm forum " technical specifications  approved atm forum specifications " on-line  crowcroft 1995  j crowcroft  z wang  a smith  j adams  " a comparison of the ietf and atm service models  " ieee communications magazine  nov./dec 1995  pp 12  16 compares the internet engineering task force int-serv service model with the atm service model on-line  garrett 1996  m garett  " a service architecture for atm  from applications to scheduling  " ieee network magazine  may/june 1996  pp 6  14 a thoughtful discussion of the the atm forum 's recent tm 4.0 specification of cbr  vbr  abr and ubr service copyright keith w ross and jim kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/service.htm  7 of 7  20/11/2004 15  52  17 point-to-point routing algorithms 4.2 routing principles in order to transfer packets from a sending host to the destination host  the network layer must determine the path or route that the packets are to follow whether the network layer provides a datagram service  in which case different packets between a given host-destination pair may take different routes  or a virtual circuit service  in which case all packets between a given source and destination will take the same path   the network layer must nonetheless determine the path for a packet this is the job of the network layer routing protocol at the heart of any routing protocol is the algorithm  the " routing algorithm "  that determines the path for a packet the purpose of a routing algorithm is simple  given a set of routers  with links connecting the routers  a routing algorithm finds a " good " path from source to destination typically  a " good " path is one which has " least cost  " but we will see that in practice  " real-world " concerns such as policy issues  e.g  a rule such as " router x  belonging to organization y should not forward any packets originating from the network owned by organization z "  also come into play to complicate the conceptually simple and elegant algorithms whose theory underlies the practice of routing in today 's networks figure 4.2-1  abstract model of a network the graph abstraction used to formulate routing algorithms is shown in figure 4.2-1  to view some graphs representing real network maps  see  dodge 1999  ; for a discussion of how well different graph-based models model the internet  see  zegura 1997    here  nodes in the graph represent routers  the points at which packet routing decisions are made  and the lines  " edges " in graph theory terminology  connecting these nodes represent the physical links between these routers a link also has a value representing the " cost " of sending a packet across the link the cost may reflect the level of congestion on that link  e.g  the current average delay for a packet across that link  or the physical distance traversed by that link  e.g  a transoceanic link might have a higher cost than a terrestrial link   for our current purposes  we will simply take the link costs as a given and wo n't worry about how they are determined given the graph abstraction  the problem of finding the least cost path from a source to a destination requires identifying a series of links such that  l the first link in the path is connected to the source l the last link in the path is connected to the destination l for all i  the i and i-1st link in the path are connected to the same node l for the least cost path  the sum of the cost of the links on the path is the minimum over all possible paths between the source and destination note that if all link costs are the same  the least cost path is also the shortest path  i.e  the path crossing the smallest number of links between the source and the destination   in figure 4.2-1  for example  the least cost path between nodes a  source  and c  destination  is along the path adec  we will find it notationally easier to refer to the path in terms of the nodes on the path  rather than the links on the path   classification of routing algorithms file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  1 of 13  20/11/2004 15  52  19 point-to-point routing algorithms as a simple exercise  try finding the least cost path from nodes a to f  and reflect for a moment on how you calculated that path if you are like most people  you found the path from a to f by examining figure 4.2-1  tracing a few routes from a to f  and somehow convincing yourself that the path you had chosen was the least cost among all possible paths  did you check all of the 12 possible paths between a and f ? probably not !   such a calculation is an example of a centralized routing algorithm broadly  one way in which we can classify routing algorithms is according to whether they are centralized or decentralized  l a global routing algorithm computes the least cost path between a source and destination using complete  global knowledge about the network that is  the algorithm takes the connectivity between all nodes and all links costs as inputs this then requires that the algorithm somehow obtain this information before actually performing the calculation the calculation itself can be run at one site  a centralized global routing algorithm  or replicated at multiple sites the key distinguishing feature here  however  is that a global algorithm has complete information about connectivity and link costs in practice  algorithms with global state information are often referred to as link state algorithms  since the algorithm must be aware of the state  cost  of each link in the network we will study a global link state algorithm in section 4.2.1 l in a decentralized routing algorithm  the calculation of the least cost path is carried out in an iterative  distributed manner no node has complete information about the costs of all network links instead  each node begins with only knowledge of the costs of its own directly attached links and then through an iterative process of calculation and exchange of information with its neighboring nodes  i e  nodes which are at the " other end " of links to which it itself is attached  gradually calculates the least cost path to a destination  or set of destinations we will study a decentralized routing algorithm known as a distance vector algorithm in section 4.2.2 it is called a distance vector algorithm because a node never actually knows a complete path from source to destination instead  it only knows the direction  which neighbor  to which it should forward a packet in order to reach a given destination along the least cost path  and the cost of that path from itself to the destination a second broad way to classify routing algorithms is according to whether they are static or dynamic in static routing algorithms  routes change very slowly over time  often as a result of human intervention  e.g  a human manually editing a router 's forwarding table   dynamic routing algorithms change the routing paths as the network traffic loads  and the resulting delays experienced by traffic  or topology change a dynamic algorithm can be run either periodically or in direct response to topology or link cost changes while dynamic algorithms are more responsive to network changes  they are also more susceptible to problems such as routing loops and oscillation in routes  issues we will consider in section 4.2.2 only two types of routing algorithms are typically used in the internet  a dynamic global link state algorithm  and a dynamic decentralized distance vector algorithm we cover these algorithms in section 4.2.1 and 4.2.2 respectively other routing algorithms are surveyed briefly in section 4.2.3 4.2.1 a link state routing algorithm recall that in a link state algorithm  the network topology and all link costs are known  i.e  available as input to the link state algorithm in practice this is accomplished by having each node broadcast the identities and costs of its attached links to all other routers in the network this link state broadcast  perlman 1999   can be accomplished without the nodes having to initially know the identities of all other nodes in the network a node need only know the identities and costs to its directly-attached neighbors ; it will then learn about the topology of the rest of the network by receiving link state broadcast from other nodes  in chapter 5  we will learn how a router learns the identities of its directly attached neighbors   the result of the nodes ' link state broadcast is that all nodes have an identical and complete view of the network each node can then run the link state algorithm and compute the same set of least cost paths as every other node the link state algorithm we present below is known as dijkstra 's algorithm  named after its inventor  a closely related algorithm is prim 's algorithm ; see  corman 1990  for a general discussion of graph algorithms   it computes the least cost path from one node  the source  which we will refer to as a  to all other nodes in the network dijkstra 's algorithm is iterative and has the property that after the kth iteration of the algorithm  the least cost paths are known to k destination nodes  and among the least cost paths to all destination nodes  these k path will have the k smallest costs let us define the following notation  l c  i,j   link cost from node i to node j if nodes i and j are not directly connected  then c  i,j  = infty we will assume for simplicity that c  i,j  equals c  j,i   l d  v   the cost of path from the source node to destination v that has currently  as of this iteration of the algorithm  the least cost l p  v   previous node  neighbor of v  along current least cost path from source to v l n  set of nodes whose shortest path from the source is definitively known the link state algorithm consists of an initialization step followed by a loop the number of times the loop is executed is equal to the number of nodes in the network upon termination  the algorithm will have calculated the shortest paths from the source node to every other node in file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  2 of 13  20/11/2004 15  52  19 point-to-point routing algorithms the network link state  ls  algorithm  1 initialization  2 n =  a  3 for all nodes v 4 if v adjacent to a 5 then d  v  = c  a,v  6 else d  v  = infty 7 8 loop 9 find w not in n such that d  w  is a minimum 10 add w to n 11 update d  v  for all v adjacent to w and not in n  12 d  v  = min  d  v   d  w  + c  w,v   13 / * new cost to v is either old cost to v or known 14 shortest path cost to w plus cost from w to v * / 15 until all nodes in n as an example  let us consider the network in figure 4.2-1 and compute the shortest path from a to all possible destinations a tabular summary of the algorithm 's computation is shown in table 4.2-1  where each line in the table gives the values of the algorithms variables at the end of the iteration let us consider the few first steps in detail  step n d  b  ,p  b  d  c  ,p  c  d  d  ,p  d  d  e  ,p  e  d  f  ,p  f  0 a 2,a 5,a 1,a infty infty 1 ad 2,a 4,d 2,d infty 2 ade 2,a 3,e 4,e 3 adeb 3e 4e 4 adebc 4e 5 adebcf table 4.2-1  steps in running the link state algorithm on network in figure 4.2-1 l in the initialization step  the currently known least path costs from a to its directly attached neighbors  b  c and d are initialized to 2  5 and 1 respectively note in particular that the cost to c is set to 5  even though we will soon see that a lesser cost path does indeed exists  since this is cost of the direct  one hop  link from a to c the costs to e and f are set to infinity since they are not directly connected to a l in the first iteration  we look among those nodes not yet added to the set n and find that node with the least cost as of the end of the previous iteration that node is d  with a cost of 1  and thus d is added to the set n line 12 of the ls algorithm is then performed to update d  v  for all nodes v  yielding the results shown in the second line  step 1  in table 4.2-1 the cost of the path to b is unchanged the cost of the path to c  which was 5 at the end of the initialization  through node d is found to have a cost of 4 hence this lower cost path is selected and c 's predecessor along the shortest path from a is set to d similarly  the cost to e  through d  is computed to be 2  and the table is updated accordingly l in the second iteration  nodes b and e are found to have the shortest path costs  2   and we break the tie arbitrarily and add e to the set n so that n now contains a  d  and e the cost to the remaining nodes not yet in n  i.e  nodes b  c and f  are updated via line 12 of the ls algorithm  yielding the results shown in the third row in the above table l and so on  when the ls algorithm terminates  we have for each node  its predecessor along the least cost path from the source node for each predecessor  we also have its predecessor and so in this manner we can construct the entire path from the source to all destinations what is the computation complexity of this algorithm ? that is  given n nodes  not counting the source   how much computation must be file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  3 of 13  20/11/2004 15  52  19 point-to-point routing algorithms done in the worst case to find the least cost paths from the source to all destinations ? in the first iteration  we need to search through all n nodes to determine the node  w  not in n that has the minimum cost in the second iteration  we need to check n-1 nodes to determine the minimum cost ; in the third iteration n-2 nodes and so on overall  the total number of nodes we need to search through over all the iterations is n *  n + 1  /2  and thus we say that the above implementation of the link state algorithm has worst case complexity of order n squared  o  n2    a more sophisticated implementation of this algorithm  using a data structure known as a heap  can find the minimum in line 9 in logarithmic rather than linear time  thus reducing the complexity   before completing our discussion of the ls algorithm  let us consider a pathology that can arise with the use of link state routing figure 4.2 2 shows a simple network topology where link costs are equal to the load carried on the link  e.g  reflecting the delay that would be experienced  in this example  link costs are not symmetric  i.e  c  a,b  equals c  b,a  only if the load carried on both directions on the ab link is the same in this example  node d originates a unit of traffic destined for a  node b also originates a unit of traffic destined for a  and node c injects an amount of traffic equal to e  also destined for a the initial routing is shown in figure 4.2-2a  with the link costs corresponding to the amount of traffic carried figure 4.2-2  oscillations with link state routing when the ls algorithm is next run  node c determines  based on the link costs shown in figure 4.2-2a  that the clockwise path to a has a cost of 1  while the counterclockwise path to a  which it had been using  has a cost of 1 + e hence c 's least cost path to a is now clockwise similarly  b determines that its new least cost path to a is also clockwise  resulting in the routing and resulting path costs shown in figure 4.2-2b when the ls algorithm is run next  nodes b  c and d all detect that a zero cost path to a in the counterclockwise direction and all route their traffic to the counterclockwise routes the next time the ls algorithm is run  b  c  and d all then route their traffic to the clockwise routes what can be done to prevent such oscillations in the ls algorithm ? one solution would be to mandate that link costs not depend on the amount of traffic carried  an unacceptable solution since one goal of routing is to avoid highly congested  e.g  high delay  links another solution is to insure that all routers do not run the ls algorithm at the same time this seems a more reasonable solution  since we would hope that even if routers run the ls algorithm with the same periodicity  the execution instants of the algorithm would not be the same at each node interestingly  researchers have recently noted that routers in the internet can self-synchronize among themselves  floyd 1994   i.e  even though they initially execute the algorithm with the same period but at different instants of time  the algorithm execution instants can eventually become  and remain  synchronized at the routers one way to avoid such self-synchronization is to purposefully introduce randomization into the period between execution instants of the algorithm at each node having now studied the link state algorithm  let 's next consider the other major routing algorithm that is used in practice today  the distance vector routing algorithm 4.2.2 a distance vector routing algorithm while the ls algorithm is an algorithm using global information  the distance vector  dv  algorithm is iterative  asynchronous  and distributed it is distributed in that each node receives some information from one or more of its directly attached neighbors  performs a file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  4 of 13  20/11/2004 15  52  19 point-to-point routing algorithms calculation  and may then distribute the results of its calculation back to its neighbors it is iterative in that this process continues on until no more information is exchanged between neighbors  interestingly  we will see that the algorithm is self terminating  there is no " signal " that the computation should stop ; it just stops   the algorithm is asynchronous in that it does not require all of the nodes to operate in lock step with each other we 'll see that an asynchronous  iterative  self terminating  distributed algorithm is much more " interesting " and " fun " than a centralized algorithm the principal data structure in the dv algorithm is the distance table maintained at each node each node 's distance table has a row for each destination in the network and a column for each of its directly attached neighbors consider a node x that is interested in routing to destination y via its directly attached neighbor z node x 's distance table entry  dx  y,z  is the sum of the cost of the direct one hop link between x and z  c  x,z   plus neighbor z 's currently known minimum cost path from itself  z  to y that is  dx  y,z  = c  x,z  + minw  dz  y,w    4-1  the minw term in equation 4-1 is taken over all of z 's directly attached neighbors  including x  as we shall soon see   equation 4-1 suggests the form of the neighbor-to-neighbor communication that will take place in the dv algorithm  each node must know the cost of each of its neighbors minimum cost path to each destination thus  whenever a node computes a new minimum cost to some destination  it must inform its neighbors of this new minimum cost before presenting the dv algorithm  let 's consider an example that will help clarify the meaning of entries in the distance table consider the network topology and the distance table shown for node e in figure 4.2-3 this is the distance table in node e once the dv algorithm has converged let 's first look at the row for destination a l clearly the cost to get to a from e via the direct connection to a has a cost of 1 hence de  a,a  = 1 l let 's now consider the value of de  a,d   the cost to get from e to a  given that the first step along the path is d in this case  the distance table entry is the cost to get from e to d  a cost of 2  plus whatever the minimum cost it is to get from d to a  note that the minimum cost from d to a is 3  a path that passes right back through e ! nonetheless  we record the fact that the minimum cost from e to a given that the first step is via d has a cost of 5 we 're left  though  with an uneasy feeling that the fact the path from e via d loops back through e may be the source of problems down the road  it will !   l similarly  we find that the distance table entry via neighbor b is de  a,b  = 14 note that the cost is not 15  why ?  figure 4.2-3  a distance table example a circled entry in the distance table gives the cost of the least cost path to the corresponding destination  row   the column with the circled entry identifies the next node along the least cost path to the destination thus  a node 's routing table  which indicates which outgoing link should be used to forward packets to a given destination  is easily constructed from the node 's distance table in discussing the distance table entries for node e above  we informally took a global view  knowing the costs of all links in the network the distance vector algorithm we will now present is decentralized and does not use such global information indeed  the only information a node file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  5 of 13  20/11/2004 15  52  19 point-to-point routing algorithms will have are the costs of the links to its directly attached neighbors  and information it receives from these directly attached neighbors the distance vector algorithm we will study is also known as the bellman-ford algorithm  after its inventors it is used in many routing algorithms in practice  including  internet bgp  iso idrp  novell ipx  and the original arpanet distance vector  dv  algorithm at each node  x  1 initialization  2 for all adjacent nodes v  3 dx  * ,v  = infty / * the * operator means " for all rows " * / 4 dx  v,v  = c  x,v  5 for all destinations  y 6 send minwd  y,w  to each neighbor / * w over all x 's neighbors * / 7 8 loop 9 wait  until i see a link cost change to neighbor v 10 or until i receive update from neighbor v  11 12 if  c  x,v  changes by d  13 / * change cost to all dest 's via neighbor v by d * / 14 / * note  d could be positive or negative * / 15 for all destinations y  dx  y,v  = dx  y,v  + d 16 17 else if  update received from v wrt destination y  18 / * shortest path from v to some y has changed * / 19 / * v has sent a new value for its minw dv  y,w  * / 20 / * call this received new value is " newval " * / 21 for the single destination y  dx  y,v  = c  x,v  + newval 22 23 if we have a new minw dx  y,w  for any destination y 24 send new value of minw dx  y,w  to all neighbors 25 26 forever the key steps are lines 15 and 21  where a node updates its distance table entries in response to either a change of cost of an attached link or the receipt of an update message from a neighbor the other key step is line 24  where a node sends an update to its neighbors if its minimum cost path to a destination has changed figure 4.2-4 illustrates the operation of the dv algorithm for the simple three node network shown at the top of the figure the operation of the algorithm is illustrated in a synchronous manner  where all nodes simultaneously receive messages from their neighbors  compute new distance table entries  and inform their neighbors of any changes in their new least path costs after studying this example  you should convince yourself that the algorithm operates correctly in an asynchronous manner as well  with node computations and update generation/ reception occurring at any times the circled distance table entries in figure 4.2-4 show the current least path cost to a destination an entry circled in red indicates that a new minimum cost has been computed  in either line 4 of the dv algorithm  initialization  or line 21   in such cases an update message will be sent  line 24 of the dv algorithm  to the node 's neighbors as represented by the red arrows between columns in figure 4.2-4 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  6 of 13  20/11/2004 15  52  19 point-to-point routing algorithms figure 4.2-4  distance vector algorithm  example the leftmost column in figure 4.2-4 shows the distance table entries for nodes x  y  and z after the initialization step let us now consider how node x computes the distance table shown in the middle column of figure 4.2-4 after receiving updates from nodes y and z as a result of receiving the updates from y and z  x computes in line 21 of the dv algorithm  dx  y,z  = c  x,z  + minw dz  y,w  = 7 + 1 = 8 dx  z,y  = c  x,y  + minw dy  z,w  = 2 + 1 = 3 it is important to note that the only reason that x knows about the terms minw dz  y,w  and minw dy  z,w  is because nodes z and file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  7 of 13  20/11/2004 15  52  19 point-to-point routing algorithms y have sent those values to x  and are received by x in line 10 of the dv algorithm   as an exercise  verify the distance tables computed by y and z in the middle column of figure 4.2-4 the value dx  z,y  = 3 means that x 's minimum cost to z has changed from 7 to 3 hence  x sends updates to y and z informing them of this new least cost to z note that x need not update y and z about its cost to y since this has not changed note also that y 's recomputation of its distance table in the middle column of figure 4.2-4 does result in new distance entries  but does not result in a change of y 's least cost path to nodes x and z hence y does not send updates to x and z the process of receiving updated costs from neighbors  recomputation of distance table entries  and updating neighbors of changed costs of the least cost path to a destination continues until no update messages are sent at this point  since no update messages are sent  no further distance table calculations will occur and the algorithm enters a quiescent state  i.e  all nodes are performing the wait in line 9 of the dv algorithm the algorithm would remain in the quiescent state until a link cost changes  as discussed below the distance vector algorithm  link cost changes and link failure when a node running the dv algorithm detects a change in the link cost from itself to a neighbor  line 12  it updates its distance table  line 15  and  if there is a change in the cost of the least cost path  updates its neighbors  lines 23 and 24   figure 4.2-5 illustrates this behavior for a scenario where the link cost from y to x changes from 4 to 1 we focus here only on y and z 's distance table entries to destination  row  x l at time t0  y detects the link cost change  the cost has changed from 4 to 1  and informs its neighbors of this change since the cost of a minimum cost path has changed l at time t1  z receives the update from y and then updates its table since it computes a new least cost to x  it has decreased from a cos of 5 to a cost of 2   it informs its neighbors l at time t2  y has receives z 's update and has updates its distance table y 's least costs have not changed  although its cost to x via z has changed  and hence y does not send any message to z the algorithm comes to a quiescent state file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  8 of 13  20/11/2004 15  52  19 point-to-point routing algorithms figure 4.2-5  link cost change  good news travels fast in figure 4.2-5  only two iterations are required for the dv algorithm to reach a quiescent state the " good news " about the decreased cost between x and y has propagated fast through the network let 's now consider what can happen when a link cost increases suppose that the link cost between x and y increases from 4 to 60 figure 4.2-6  link cost changes  bad news travels slow and causes loops l at time t0 y detects the link cost change  the cost has changed from 4 to 60   y computes its new minimum cost path to x to have a cost of 6 via node z of course  with our global view of the network  we can see that this new cost via z is wrong but the only information node y has is that its direct cost to x is 60 and that z has last told y that z could get to x with a cost of 5 so in order to get to x  y would now route through z  fully expecting that z will be able to get to x with a cost of 5 as of t1 we have a routing loop  in order to get to x  y routes through z  and z routes through y a routing loop is like a black hole  a packet arriving at y or z as of t1 will bounce back and forth between these two nodes forever  or until the routing tables are changed l since node y has computed a new minimum cost to x  it informs z of this new cost at time t1 l sometime after t1  z receives the new least cost to x via y  y has told z that y 's new minimum cost is 6   z knows it can get to y with a cost of 1 and hence computes a new least cost to x  still via y  of 7 since y 's least cost to x has increased  it then informs y of its new cost at t2 l in a similar manner  y then updates its table and informs z of a new cost of 9 z then updates its table and informs y of a new cost of 10  etc how long will the process continue ? you should convince yourself that the loop will persist for 44 iterations  message exchanges between y and z   until z eventually computes its path via y to be larger than 50 at this point  z will  finally !  determine that its least cost path to x is via its direct connection to x y will then route to x via z the result of the " bad news " about the increase in link cost has indeed traveled slowly ! what would have happened if the link cost change of c  y,x  had been from 4 to 10,000 and the cost c  z,x  had been 9,999 ? because of such scenarios  the problem we have seen is sometimes referred to as the " count-to-infinity " problem distance vector algorithm  adding poisoned reverse file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  9 of 13  20/11/2004 15  52  19 point-to-point routing algorithms the specific looping scenario illustrated in figure 4.2-6 can be avoided using a technique known as poisoned reverse the idea is simple  if z routes through y to get to destination x  then z will advertise to y that its  z 's  distance to x is infinity z will continue telling this little " white lie " to y as long as it routes to x via y since y believes that z has no path to x  y will never attempt to route to x via z  as long as z continues to route to x via y  and lie about doing so   figure 4.2-7  poisoned reverse figure 4.2-7 illustrates how poisoned reverse solves the particular looping problem we encountered before in figure 4.2-6 as a result of the poisoned reverse  y 's distance table indicates an infinite cost when routing to x via z  the result of z having informed y that z 's cost to x was infinity   when the cost of the xy link changes from 4 to 60 at time t0  y updates its table and continues to route directly to x  albeit at a higher cost of 60  and informs z of this change in cost after receiving the update at t1  z immediately shifts it route to x to be via the direct zx link at a cost of 50 since this is a new least cost to x  and since the path no longer passes through y  z informs y of this new least cost path to x at t2 after receiving the update from z  y updates its distance table to route to x via z at a least cost of 51 also  since z is now on y 's least path to x  y poisons the reverse path from z to x by informing z at time t3 that it  y  has an infinite cost to get to x the algorithm becomes quiescent after t4  with distance table entries for destination x shown in the rightmost column in figure 4.2-7 does poison reverse solve the general count-to-infinity problem ? it does not you should convince yourself that loops involving three or more nodes  rather than simply two immediately neighboring nodes  as we saw in figure 4.2-7  will not be detected by the poison reverse technique a comparison of link state and distance vector routing algorithms let us conclude our study of link state and distance vector algorithms with a quick comparison of some of their attributes l message complexity we have seen that ls requires each node to know the cost of each link in the network this requires o  ne  messages to be sent  where n is the number of nodes in the network and e is the number of links also  whenever a link cost changes  the new link cost must be sent to all nodes the dv algorithm requires message exchanges between directly connected neighbors at each iteration we have seen that the time needed for the algorithm to converge can depend on many factors when link costs change  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  10 of 13  20/11/2004 15  52  19 point-to-point routing algorithms the dv algorithm will propagate the results of the changed link cost only if the new link cost results in a changed least cost path for one of the nodes attached to that link l speed of convergence we have seen that our implementation of the ls is an o  n2  algorithm requiring o  ne  messages  and potentially suffer from oscillations the dv algorithm can converge slowly  depending on the relative path costs  as we saw in figure 4.2-7  and can have routing loops while the algorithm is converging dv also suffers from the count to infinity problem l robustness what can happen is a router fails  misbehaves  or is sabotaged ? under ls  a router could broadcast an incorrect cost for one of its attached links  but no others   a node could also corrupt or drop any ls broadcast packets it receives as part of link state broadcast but an ls node is only computing its own routing tables ; other nodes are performing the similar calculations for themselves this means route calculations are somewhat separated under ls  providing a degree of robustness under dv  a node can advertise incorrect least path costs to any/all destinations  indeed  in 1997 a malfunctioning router in a small isp provided national backbone routers with erroneous routing tables this caused other routers to flood the malfunctioning router with traffic  and caused large portions of the internet to become disconnected for up to several hours  neumann 1997    more generally  we note that at each iteration  a node 's calculation in dv is passed on to its neighbor and then indirectly to its neighbor 's neighbor on the next iteration in this sense  an incorrect node calculation calculation can be diffused through the entire network under dv in the end  neither algorithm is a " winner " over the other ; as we will see in section 4.4  both algorithms are used in the internet 4.2.3 other routing algorithms the ls and dv algorithms we have studied are not only widely used in practice  they are essentially the only routing algorithms used in practice today nonetheless  many routing algorithms have been proposed by researchers over the past 30 years  ranging from the extremely simple to the very sophisticated and complex one of the simplest routing algorithms proposed is hot potato routing the algorithm derives its name from its behavior  a router tries to get rid of  forward  an outgoing packet as soon as it can it does so by forwarding it on any outgoing link that is not congested  regardless of destination although initially proposed quite some time ago  interest in hot-potato-like routing has recently been revived for routing in highly structured networks  such as the so-called manhattan street network  brassil 1994   another broad class of routing algorithms are based on viewing packet traffic as flows between sources and destinations in a network in this approach  the routing problem can be formulated mathematically as a constrained optimization problem known as a network flow problem  bertsekas 1991   let us define ? ? ij as the amount of traffic  e.g  in packets/sec  entering the network for the first time at node i and destined for node j the set of flows   ? ? ij  for all i,j  is sometimes referred to as the network traffic matrix in a network flow problem  traffic flows must be assigned to a set of network links subject to constraints such as  l the sum of the flows between all source destination pairs passing though link m must be less than the capacity of link m ; l the amount of ? ? ij traffic entering any router r  either from other routers  or directly entering that router from an attached host  must equal the amount of ? ? ij traffic leaving router either via one of r 's outgoing links or to an attached host at that router this is a flow conservation constraint let us define ? ? ij m as the amount of source i  destination j traffic passing through link m the optimization problem then is to find the set of link flows   ? ? ij m  for all links m and all sources  i  and designations  j  that satisfies the constraints above and optimizes a performance measure that is a function of  ? ? ij m   the solution to this optimization problem then defines the routing used in the network for example  if the solution to the optimization problem is such that ? ? ij m = ? ? ij for some link m  then all i-to-j traffic will be routed over link m in particular  if link m is attached to node i  then m is the first hop on the optimal path from source i to destination j but what performance function should be optimized ? there are many possible choices if we make certain assumptions about the size of packets and the manner in which packets arrive at the various routers  we can use the so-called m/m/1 queueing theory formula  kleinrock 1976  to express the average delay at link as  dm = 1 /  rm  ? i ? j ? ? ij m   where rm is link m 's capacity  measured in terms of the average number of packets/sec it can transmit  and ? i ? j ? ? ij m is the total arrival rate of packets  in packets/sec  that arrive to link m the overall network wide performance measure to be optimized might then be the sum of all file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  11 of 13  20/11/2004 15  52  19 point-to-point routing algorithms link delays in the network  or some other suitable performance metric a number of elegant distributed algorithms exist for computing the optimum link flows  and hence routing determine the routing paths  as discussed above   the reader is referred to  bertsekas 1991  for a detailed study of these algorithms the final set of routing algorithms we mention here are those derived from the telephony world these circuit-switched routing algorithms are of interest to packet-switched data networking in cases where per-link resources  e.g  buffers  or a fraction of the link bandwidth  are to reserved  i.e  set aside  for each connection that is routed over the link while the formulation of the routing problem might appear quite different from the least cost routing formulation we have seen in this chapter  we will see that there are a number of similarities  at least as far as the path finding algorithm  routing algorithm  is concerned our goal here is to provide a brief introduction for this class of routing algorithms the reader is referred to  ash 1998    ross 1995    girard 1990  for a detailed discussion of this active research area the circuit-switched routing problem formulation is illustrated in figure 4.2-8 each link has a certain amount of resources  e.g  bandwidth   the easiest  and a quite accurate  way to visualize this is to consider the link to be a bundle of circuits  with each call that is routed over the link requiring the dedicated use of one of the link 's circuits a link is thus characterized both by its total number of circuits  as well as the number of these circuits currently in use in figure 4.2-8  all links except ab and bd have 20 circuits ; the number to the left of the number of circuits indicates the number of circuits currently in use figure 4.2-8  circuit-switched routing suppose now that a call arrives at node a  destined to node d what path should be take ? in shortest path first  spf  routing  the shortest path  least number of links traversed  is taken we have already seen how the dijkstra ls algorithm can be used to find shortest path routes in figure 4.2-8  either that abd or acd path would thus be taken in least loaded path  llp  routing  the load at a link is defined as the ratio of the number of used circuits at the link and the total number of circuits at that link the path load is the maximum of the loads of all links in the path in llp routing  the path taken is that with the smallest path load in example 4.2-8  the llp path is abcd in maximum free circuit  mfc  routing  the number of free circuits associated with a path is the minimum of the number of free circuits at each of the links on a path in mfc routing  the path the maximum number of free circuits is taken in figure 4.2-8 the path abd would be taken with mfc routing given these examples from the circuit switching world  we see that the path selection algorithms have much the same flavor as ls routing all nodes have complete information about the network 's link states note however  that the potential consequences of old or inaccurate sate information are more severe with circuit-oriented routing  a call may be routed along a path only to find that the circuits it had been expecting to be allocated are no longer available in such a case  the call setup is blocked and another path must be attempted nonetheless  the main differences between connection-oriented  circuit-switched routing and connectionless packet-switched routing come not in the path selection mechanism  but rather in the actions that must be taken when a connection is set up  or torn down  from source to destination references  ash 1998  g r ash  dynamic routing in telecommunications networks  mcgraw hill  1998  bertsekas 1991  d bertsekas  r gallager  data networks  prentice hall  1991  brassil 1994  j t brassil  a k choudhury  n f maxemchuk  " the manhattan street network  a high performance  highly reliable metropolitan area network  " computer networks and isdn systems  mar 1994  corman 1990  t corman  c leiserson  r rivest,introduction to algorithms   the mit press  cambridge  massachusett  1990    dodge 1999  m dodge  " an atlas of cyberspaces  " http  //www.cybergeography.org/atlas/isp_maps.html  girard 1990  a girard  routing and dimensioning in circuit-switched networks  addison wessley  1990 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  12 of 13  20/11/2004 15  52  19 point-to-point routing algorithms  ross 1995  k.w ross  " multiservice loss models for broadband telecommunications networks  " springer-verlay  1995  floyd 1994  s floyd  v jacobson  " synchronization of periodic routing messages  " ieee/acm transactions on networking  vol 2 no 2  pp 122-136  april 1994  kleinrock 1975  l kleinrock  queueing systems  theory  john wiley and sons  1975  neumann 1997  r neumann  " internet routing black hole  " the risks digest  forum on risks to the public in computers and related systems  vol 19  no 12  2-may-1997    perlman 1999  r perlman  interconnections  second edition  bridges  routers  switches  and internetworking protocols  addison-wesley professional computing series   1999  zegura 1997  e zegura  k calvert  m donahoo  " a quantitative comparison of graph-based models for internet topology  " ieee/acm transactions on networking  volume 5  no 6  december 1997 see also http  //www.cc.gatech.edu/projects/gtim for a software package that generates networks with realistic structure copyright keith w ross and james f kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/algor.htm  13 of 13  20/11/2004 15  52  19 file  ///d | /downloads/livros/computa ? ? o/computer % 20networking/computer % 20networking % 20a % 20top-down % 20approach % 20featuring % 20the % 20internet/dvoscill.gif file  ///d | /downloads/livros/computa ? ? o/computer % 20networking/computer % 20networking % 20a % 20top-down % 20approach % 20featuring % 20the % 20internet/dvoscill.gif20/11/2004 15  52  19 the network layer  hierarchical networks 4.3 hierarchical routing in the previous section  we viewed " the network " simply as a collection of interconnected routers one router was indistinguishable from another in the sense that all routers executed the same routing algorithm to compute routing paths through the entire network in practice  this model and its view of a homogenous set of routers all executing the same routing algorithm is a bit simplistic for at least two important reasons  l scale as the number of routers becomes large  the overhead involved in computing  storing  and communicating the routing table information  e.g  link state updates or least cost path changes  becomes prohibitive today 's public internet consists of millions of interconnected routers and more than 50 million hosts storing routing table entries to each of these hosts and routers would clearly require enormous amounts of memory the overhead required to broadcast link state updates among millions of routers would leave no bandwidth left for sending the data packets ! a distance vector algorithm that iterated among millions of routers would surely never converge ! clearly  something must be done to reduce the complexity of route computation in networks as large as the public internet l administrative autonomy although engineers tend to ignore issues such as a company 's desire to run its routers as it pleases  e.g  to run whatever routing algorithm it chooses   or to " hide " aspects of the networks ' internal organization from the outside  these are important considerations ideally  an organization should be able to run and administer its network as it wishes  while still being able to connect its network to other " outside " networks both of these problems can be solved by aggregating routers into " regions " or " autonomous systems "  ass   routers within the same as all run the same routing algorithm  e.g  a ls or dv algorithm  and have full information about each other  exactly as was the case in our idealized model in the previous section the routing algorithm running within an autonomous system is called an intraautonomous system routing protocol it will be necessary  of course  to connect ass to each other  and thus one or more of the routers in an as will have the added task for being responsible for routing packets to destinations outside the as routers in an as that have the responsibility of routing packets to destinations outside the as are called gateway routers in order for gateway routers to route packets from one as to another  possibly passing through multiple other ass before reaching the destination as   the gateways must know how to route  i.e  determine routing paths  among themselves the routing algorithm that gateways use to route among the various ass is known as an inter-autonomous system routing protocol in summary  the problems of scale and administrative authority are solved by defining autonomous systems within an as  all routers run the same intra-autonomous system routing protocol special gateway routers in the various ass run an inter-autonomous system routing protocol that determines routing paths among the ass the problem of scale is solved since an intra-as router need only know about routers within its as and the gateway router  s  in its as the problem of administrative authority file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/hierarch.htm  1 of 4  20/11/2004 15  52  20 the network layer  hierarchical networks is solved since an organization can run whatever intra-as routing protocol it chooses  as long as the as 's gateway  s  is able to run an inter-as routing protocol that can connect the as to other ass figure 4.3-1  intra-as and inter-as routing figure 4.3-1 illustrates this scenario here  there are three routing ass  a  b and c autonomous system a has four routers  a.a  a.b  a.c and a.d  which run the intra-as routing protocol used within autonomous system a these four routers have complete information about routing paths within autonomous system a similarly  autonomous systems b and c have three and two routers  respectively note that the intra-as routing protocols running in a  b and c need not be the same the gateway routers are a.a  a.c  b.a and c.b in addition to running theintra-as routing protocol in conjunction with other routers in their ass  these four routers run an inter-as routing protocol among themselves the topological view they use for their inter-as routing protocol is shown at the higher level  with " links " shown in light gray note that a " link " at the higher layer may be an actual physical link  e.g  the link connection a.c and b.a  or a logical link  such as the link connecting a.c and a.a figure 4.3-2 illustrates that the gateway router a.c must run an intra-as routing protocol with its neighbors a.b and a.d  as well as an inter-as protocol with gateway router b.a file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/hierarch.htm  2 of 4  20/11/2004 15  52  20 the network layer  hierarchical networks figure 4.3-2  internal architecture of gateway router a.c suppose now that a host h1 attached to router a.d needs to route a packet to destination h2 in autonomous system b  as shown in figure 4.3-3 assuming that a.d 's routing table indicates that router a.c is responsible for routing its  a.d 's  packets outside the as  the packet is first routed from a.d to a.c using a 's intra-as routing protocol it is important to note that router a.d does not know about the internal structure of autonomous systems b and c and indeed need not even know about the topology connecting autonomous systems a  b and c router a.c will receive the packet and see that it is destined to an autonomous system outside of a a 's routing table for the intra-as protocol would indicate that a packet destined to autonomous system b should be routed along the a.c to b.a link when the packet arrives at b.a  b.a 's inter-as routing sees that the packet is destined for autonomous system b the packet is then " handed over " to the intra-as routing protocol within b  which routes the packet to its final destination  h2 in figure 4.3-3  the portion of the path routed using a 's intra-as protocol is shown in red  the portion using the inter-as routing protocol is shown in blue  and the portion of the path routed using b 's intra-as protocol is shown in green we will examine specific inter as and intra-as routing protocols used in the internet in section 4.5 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/hierarch.htm  3 of 4  20/11/2004 15  52  20 the network layer  hierarchical networks figure 4.3-3  the route from a.d to b.b  intra-as and inter-as path segments copyright keith w ross and james f kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/hierarch.htm  4 of 4  20/11/2004 15  52  20 point-topoint routing in the internet 4.4 internet protocol so far in this chapter we have examined the underlying principles of the network layer we have discussed the network layer service models  including virtual circuit service and datagram service  the routing algorithms commonly used to determine paths between origin and destination hosts  and how problems of scale are addressed with hierarchical routing we are now going to turn our attention to the internet 's network layer as we mentioned in section 4.1  the internet 's network layer does not provide a virtual-circuit service  but instead a connectionless datagram service when the network layer at the sending host receives a segment from the transport layer  it encapsulates the segment within an ip datagram  writes the destination address of the host  as well as other fields  on the datagram  and drops the datagram into the network as we mentioned in chapter 1  this process is similar to a person writing a letter  inserting the letter in an envelope  writing the destination address on the envelope  and dropping the envelope into a mailbox neither the internet 's network layer nor the postal service make any kind of preliminary contact with the destination before moving its " parcel " to the destination furthermore  as discussed in section 4.1  the network layer service is a best effort service it does not guarantee that the datagram will arrive within a certain time  it does not guarantee that a series of datagrams will arrive in the same order sent ; in fact  it does not even guarantee that the datagram will ever arrive at its destination as we discussed in section 4.1  the network layer for a datagram network  such as the internet  has two major components first  it has a network protocol component  which defines network-layer addressing  the fields in the datagram  i.e  the network layer pdu   and how the end systems and routers act on these fields the network protocol in the internet is called the internet protocol  or more commonly  the ip protocol there are currently two versions of the ip protocol in use today in this section we examine the more widespread version  namely  internet protocol version 4  which is specified in  rfc 791  and which is more commonly known as ipv4 in section 4.7 we shall examine  ipv6  which is expected to slowly replace ipv4 in the upcoming years.the second major component of the network layer is the path determination component  which determines the route a datagram follows from origin to destination we study the path determination component in the next section 4.4.1 ip addressing before discussing ip addressing  we need to say a few words about hosts and routers a host  also called an end system  has one link into the network when ip in the host wants to send a datagram  it passes the datagram to its link the boundary between the host and the link is called the interface a router is fundamentally different from a host in that it has two or more links that connect to it when a router forwards a datagram  it forwards the datagram over one of its links the boundary between the router and any one of its links is also called an interface thus  a router has multiple interfaces  one for each of its links because every interface  for a host or router  is capable of sending and receiving ip datagrams  ip requires each interface to have an ip address each ip address is 32 bits long  equivalently  four bytes  long ip addresses are typically written in so-called " dot-decimal notation "  whereby each byte of the address is written in its decimal form and is separated by a period for example  a typical ip address would be 193.32.216.9 the 193 is the decimal equivalent for the first 8 bits of the address ; the 32 is the decimal equivalent for the second 8 bits of the address  etc thus  the address 193.32.216.9 in binary notation is  11000001 00100000 11011000 00001001  a space as been added between the bytes for visual purposes  because each ip address is 32 bits long  there are 232 possible ip addresses file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  1 of 12  20/11/2004 15  52  21 point-topoint routing in the internet figure 4.4-1  lans are networks in ip jargon figure 4.4-1 provides an example of ip addressing and interfaces in this figure there is one router which interconnects three lans  lans  also known as local area networks  were briefly discussed in chatper 1 and will be studied in detail in the next chapter  in the jargon of ip  each of these lans is called an ip network or more simply a " network "  there are several things to observe from this diagram first  the router has threes interfaces  labeled 1  2 and 3 each of the router interfaces has its own ip address  which are provided in figure 4.4-2 ; each host also has its own interface and ip address second  all of the interfaces attached to lan 1  including a router interface  have an ip address of the form 223.1.1.xxx  similarly  all the interfaces attached to lan 2 and lan 3 have ip addresses of the form 223.1.2.xxx and 233.1.3.xxx  respectively in other words  each address has two parts  the first part  the first three bytes in this example  that specifies the network ; and the second part  the last byte in this example  that addresses a specific host on the network router interface ip address 1 223.1.1.4 2 223.1.2.9 3 223.1.3.27 figure 4.4-2  ip addresses for router interfaces the ip definition of a " network " is not restricted to a lan to get some insight here  let us now take a look at another example figure 4.4-3 shows several lans interconnected with three routers all of the interfaces attached to lan 1  including the router r1 interface that is attached to lan 1  have an ip address of the form 223.1.1.xxx similarly  all the interfaces attached to lan 2 and to lan 3 have the form 223.1.2.xxx and 223.1.3.xxx  respectively each of the three lans again constitute their own network  i.e  ip network   but note that there are three additional " networks " in this example  one network for the interfaces that connect router 1 to router 2 ; another network for the interfaces that connect router 2 to router 3 ; and a third network for the interfaces that connect router 3 to router 1 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  2 of 12  20/11/2004 15  52  21 point-topoint routing in the internet figure 4.4-3  an interconnected system consisting of six networks for a general interconnected system of routers and hosts  such as the internet   we use the following recipe to define the " networks " in the system we first detach each router interface from its router and each host interface from its host this creates " islands " of isolated networks  with " interfaces " terminating all the leaves of the isolated networks  we then call each of these isolated networks a network indeed  if we apply this procedure to the internconnected system in figure 4.4-3  we get six islands or " networks "  the current internet consists of millions of networks  in the next chapter we will consider bridges we mention here that when applying this recipe  we do not detach interfaces from bridges thus each bridge lies within the interior of some network  now that we have defined a network  we are ready to discuss ip addressing in more detail ip addresses are globally unique  that is  no two interfaces in the world have the same ip address figure 4.4-3 shows the four possible formats of an ip address  a fifth address  beginning with 11110  is reserved for future use  in general  each interface  for a host or router  belongs to a network ; the network part of the address identifies the network to which the interface belongs the host part identifies the specific interface within the network  we would prefer to use the terminology " interface part of the address " rather than " host part of the address " because ip address is really for an interface and not for a host ; but the terminology " host part " is commonly used in practice  for a class a address  the first 8 bits identify the network  and the last 24 bits identify the interface within that network thus with a class a we can have up to 27 networks  the first of the eight bits is fixed as 0  and and 224 interfaces note that the interfaces in figures 4-4.1 and 4-4.3 use class a addresses the class b address space allows for 214 networks  with up to 216 interfaces within each network a class c address uses 21 bits to identify the network and leaves only 8 bits for the interface identifier class d addresses are reserved for so-called multicast addresses as we will see in section 4.7  these addresses do not identify a specific interface but rather provide a mechanism through which multiple hosts can receive a copy of each single packet sent by a sender file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  3 of 12  20/11/2004 15  52  21 point-topoint routing in the internet figure 4.4-4  ipv4 address formats assigning addresses having introduced ip addressing  one question that immediately comes to mind is how does a host get its own ip address ? we have just learned that an ip address has two parts  a network part and a host part the host part of the address can be assigned in several different ways  including  l manual configuration  the ip address is configured into the host  typically in a file  by the system administrator l dynamic host configuration protocol  dhcp    rfc 2131   dhcp is an extension of the bootp  rfc 1542  protocol  and is sometimes referred to as plug and play with dhcp  a dhcp server in a network  e.g  in a lan  receives dhcp requests from a client and in the case of dynamic address allocation  allocates an ip address back to the requesting client dhcp is used extensively in lans and in residential internet access the network part of the address is the same for all the hosts in the network to obtain the network part of the address for a network  the network administrator might first contact the network 's isp  which would provide addresses from a larger block of addressees that have already been allocated to the isp but how does an isp get a block of addresses ? ip addresses are managed under the authority of the internet assigned numbers authority  iana   under the guidelines set forth in  rfc 2050   the actual assignment of addresses is now managed by regional internet registries as of mid-1998  there are three such regional registries  the american registry for internet number  arin  which handles registrations for north and south america  as well as parts of africa arin has recently taken over a number of the functions previously provided by network solutions   the reseaux ip europeans  ripe  which covers europe and nearby countries   and the asia pacific network information center  apnic   before leaving our discussion of addressing  we want to mention that mobile hosts may change the network to which they are attached  either dynamically while in motion or on a longer time scale because routing is to a network first  and then to a host within the network  this means that the mobile host 's ip address must change when the host changes networks techniques for handling such issues are now under development within the ietf and the research community  rfc2002   rfc2131   4.4.2 the big picture  transporting a datagram from source to destination now that we have defined interfaces and networks  and that we have a basic understanding of ip addressing  we take a step file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  4 of 12  20/11/2004 15  52  21 point-topoint routing in the internet back and discuss how ip transports a datagram from source to destination to this end  a high level view of an ip datagram is shown in figure 4.4-5 note that every ip datagram has a destination address field and a source address field the source host fills the source address field with its own 32-bit ip address and fills the destination address field with the 32-bit ip address of the host to which it wants to send the datagram note that these actions are analogous to what you do when you send a letter  on the envelope of the letter  you provide a destination address and a return  source  address the data field of the datagram is typically filled with a tcp or udp segment we will discuss the remaining ip datagram fields a little later in this section figure 4.4-5  the key fields in an ip datagram once the source host creates the ip datagram  how does the network layer transport the datagram from the source host to the destination host ? let us answer this question in the context of network figure 4.4-1 first suppose host a wants to send an ip datagram to host b the datagram is transported from host a to host b as follows ip in host a first extracts the network portion of the address  223.1.1  and scans its routing table  which is shown in figure 4.4-6 in this table  the " number of hops to destination " is defined to be the number of networks that need to be traversed  including the destination network scanning the table  host a finds a match in the first row  and observes that the number of hops to the destination is 1 this indicates to host a that the destination host is on the same network host a then passes the ip datagram to the link layer protocol and indicates to the link layer protocol that the destination is on the same lan the link layer protocol then has the responsibility of transporting the datagram to host b  we will study how the link layer transports a datagram between to interfaces on the same network in the next chapter  destination network next router number of hops to destination 223.1.1  1 223.1.2 223.1.1.4 2 223.1.3 223.1.1.4 2 figure 4.4-6  routing table in host a now consider the more interesting case of host a sending an ip datagram to host e  which has ip address 223.1.2.2 and is on a different lan host a again scans its routing table  but now finds a match in the second row because the number of hops to the destination is 2  host a knows that the destination is on another network the routing table also tells host a that in order to get the datagram to host e  host a should first send the datagram to router address 223.1.1.4 ip in host a then passes the datagram down to the link layer  and indicates to the link layer that it should first send the datagram to ip address 223.1.1.4  the link layer then transports the datagram to the router interface 1 the datagram is now in the router  and it is the job the router to move the datagram towards the datagram 's ultimate destination the router extracts the network portion of the destination address of the ip datagram  namely 223.1.2  and scans its routing table  which is shown in figure 4.4-7 the router finds a match in the second row of the table the table tells the router that the datagram should be forwarded on router interface 2 ; also the number of hops to the destination is 1  which indicates to the router that the destination host is on the lan directly attached to interface 2 the router moves the datagram to interface 2  the moving of a datagram from in input interface to an output interface within a router will be covered in section 4.6  once the datagram is at interface 2  the router passes the datagram to link layer protocol and indicates to the link layer protocol that the destination host is on the same lan the link layer protocol has the job of transporting the datagram from the router interface 2 to host e  both of which are attached to the same lan file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  5 of 12  20/11/2004 15  52  21 point-topoint routing in the internet destination network next router number of hops to destination interface 223.1.1  1 1 223.1.2  1 2 223.1.3  1 3 figure 4.4-7  routing table in router in figure 4.4-7  note that the entries in the " next router " column are all empty this is because all of the networks  223.1.1  223.1.2  and 223.1.3  are each directly attached to the router  that is  there is no need to go through an intermediate router to get to the destination host however  if host a and host e were separated by two routers  then within the routing table of the first router along the path from a to b  the appropriate row would indicate 2 hops to the destination and would specify the ip address of the second router along the path the first router would then forward the datagram to the second router  using the link layer protocol that connects the two routers the second router then forwards the datagram to the destination host  using the link layer protocol that connects the second router to the destination host you may recall from chapter 1 that we said that routing a datagram in the internet is similar to a person driving a car and asking gas station attendants at each intersection along the way how to get to the ultimate destination it should now be clear why this an appropriate analogy for routing in the internet as a datagram travels from source to destination  it visits a series of routers at each router in the series  it stops and asks the router how to get to its ultimate destination unless the router is on the same lan as the ultimate destination  the routing table essentially says to the datagram  " i do n't know exactly how to get to the ultimate destination  put i do know that the ultimate destination is in the direction of the link  analogous to a road  connected to interface 3 " the datagram then sets out on the link connected to interface 3  arrives at a new router  and again asks for new directions from this discussion we see that the routing tables in the routers play a central role in routing datagrams through the internet but how are these routing tables configured and maintained for large networks with mulitple paths between sources and destinations  such as in the internet  ? clearly  these routing tables should be configured so that the datagrams follow good  if not optimal  routes from source to destination as you probably guessed  routing algorithms  like those studied in section 4.2  have the job of configuring and maintaining the routing tables furthermore  as discussed in section 4.3  the internet is partitioned into autonomous systems  ass   intra-as routing algorithms independently configure the routing tables within the autonomous systems ; inter-as routing algorithms have the job configuring routing tables so that datagrams can pass through multiple autonomous systems we will discuss the internet 's intra-as and inter-as routing algorithms in section 4.5 but before moving on to routing algorithms  we cover three more important topics for the ip protocol  namely  the datagram format  datagram fragmentation  and the internet control message protocol  icmp   4.4.3 datagram format the ipv4 datagram format is shown in figure 4.4-8 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  6 of 12  20/11/2004 15  52  21 point-topoint routing in the internet figure 4.4-8  ipv4 datagram format the key fields in the ipv4 datagram are the following  l version number  these 4 bits specify the ip protocol version of the datagram by looking at the version number  the router can then determine how to interpret the remainder of the ip datagram different versions of ip use different datagram formats the datagram format for the " current " version of ip  ipv4  is shown in figure 4..4-8 the datagram format for the " new " version of ip  ipv6  is discussed in section 4.7 l header length  because an ipv4 datagram can contain a variable number of options  which are included in the ipv4 datagram header  these 4 bits are needed to determine where in the ip datagram the data actually begins most ip datagrams do not contain options so the typical ip datagram has a 20 byte header l tos  the type of service  tos  bits were included in the ipv4 header to allow different " types " of ip datagrams to be distinguished from each other  presumably so that they could be handled differently in times of overload when the network is overloaded  for example  it would be useful to be able to distinguish network control datagrams  e.g  see the icmp discussion in section 4.4.5  from datagrams carrying data  e.g  http messages   it would also be useful to distinguish real-time datagrams  e.g  used by an ip telephony application  from non-real-time traffic  e.g  ftp   more recently  one major routing vendor  cisco  interprets the first three tos bits as defining differential levels of service that can be provided by the router the specific level of service to be provided is a policy issue determined by the router 's administrator we shall explore the topic of differentiated service in detail in chapter 6 l datagram length  this is the total length of the ip datagram  header plus data  measured in bytes since this field is 16 bits long  the theoretical maximum size of the ip datagram to 65,535 bytes however  datagrams are rarely greater than 1500 bytes  and are often limited in size to 576 bytes l identifier  flags  fragmentation offset  these three fields have to do with so-called ip fragmentation  a topic we will consider in depth shortly interestingly  the new version of ip  ipv6  simply does not allow for fragmentation l time-to-live  the time-to-live  ttl  field is included to insure that datagrams do not circulate forever  due to  for example  a long lived router loop  in the network this field is decremented by one each time the datagram is processed by a router if the ttl field reaches 0  the datagram must be dropped l protocol  this field is only used when an ip datagram reaches its final destination the value of this field indicates the transport-layer protocol at the destination to which the data portion of this ip datagram will be passed for example  a value of 6 indicates that the data portion is passed to tcp  while a value of 17 indicates that the data is passed to udp for a listing of all possible numbers  see  rfc 1700   note that the the protocol number in the ip datagram has a role file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  7 of 12  20/11/2004 15  52  21 point-topoint routing in the internet that is fully analogous to the role of the port number field in the transport-layer segment the protocol number is the " glue " that holds the network and transport layers together  whereas port number is the " glue " that holds the transport and application layers together we will see in chapter 5 that the link layer frame also has a special field which glues the link layer to the network layer l header checksum  the header checksum aids a router in detecting bit errors in a received ip datagram the header checksum is computed by treating each 2 bytes in the header as a number and summing these numbers using 1 's complement arithmetic as discussed in section 3.3  the 1 's complement of this sum  known as the internet checksum  is stored in the checksum field a router computes the internet checksum for each received ip datagram and detects an error condition if the checksum carried in the datagram does not equal the computed checksum routers typically discard datagrams for which an error has been detected note that the checksum must be recomputed and restored at each router  as the ttl field  and possibly options fields as well  may change an interesting discussion of fast algorithms for computing the internet checksum is  1071   a question often asked at this point is  why does tcp/ip perform error checking at both the transport and network layers ? there are many reasons for this first  routers are not required to perform error checking  so the transport layer can not count on the network layer to do the job second  tcp/ udp and ip do not necessarily have to both belong to the same protocol stack tcp can  in principle  run over a different protocol  e.g  atm  and ip can carry data without passing through tcp/udp  e.g  rip data   l source and destination ip address  these fields carry the 32 bit ip address of the source and final destination for this ip datagram the use and importance of the destination address is clear the source ip address  along with the source and destination port numbers  is used at the destination host to direct the application data in the proper socket l options  the optional options fields allows an ip header to be extended header options were meant to be used rarely  hence the decision to save overhead by not including the information in options fields in every datagram header however  the mere existence of options does complicate matters  since datagram headers can be of variable length  one can not determine a priori where the data field will start also  since some datagrams may require options processing and others may not  the amount of time needed to process a ip datagram can vary greatly these considerations become particularly important for ip processing in high performance routers and hosts for these reasons and others  ip options were dropped in the ipv6 header l data  payload   finally  we come to the last  and most important field  the raison d ' ? tre for the datagram in the first place ! in most circumstances  the data field of the ip datagram contains the transport-layer segment  tcp or udp  to be delivered to the destination however  the data field can carry other types of data  such icmp messages  discusssed in section 4.4.5   note that ip datagram has a total of 20 bytes of header  assuming it has no options   if the ip datagram carries a tcp segment  then each  non-fragmented  datagram carries a total of 40 bytes of header  20 ip bytes and 20 tcp bytes  along with the application-layer data 4.4.4 ip fragmentation and reassembly we will see in chapter 5 that not all link layer protocols can carry packets of the same size some protocols can carry " big " packets whereas other protocols can only carry " little " packets for example  ethernet packets can carry no more than 1500 bytes of data  whereas packets for many wide-area links can carry no more than 576 bytes the maximum amount of data that a link-layer packet can carry is called the mtu  maximum transfer unit   because each ip datagram is encapsulated within the link-layer packet for transport from one router to the next router  the mtu of the link-layer protocol places a hard limit on the length of an ip datagram having a hard limit on the size of an ip datagram is not much of a problem what is a problem is that each of the links along the route between sender and destination can use different link-layer protocols  and each of these protocols can have different mtus to understand the problem better  imagine that you are a router that interconnects several links  each running different linklayer protocols with different mtus suppose you receive an ip datagram from one link  you check your routing table to determine the outgoing link  and this outgoing link has an mtu that is smaller than the length of the ip datagram time to panic  how are you going to squeeze this oversized ip packet into the payload field of the link-layer packet ? the solution to this problem is to " fragment " the data in the ip datagram among two or more smaller ip datagrams  and then send these smaller datagrams over the outgoing link each of these smaller datagrams is referred to as a fragment file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  8 of 12  20/11/2004 15  52  21 point-topoint routing in the internet fragments need to be reassembled before they reach the transport layer at the destination indeed  both tcp and udp are expecting to receive from the network layer complete  un-fragmented segments the designers of ipv4 felt that reassembling  and possibly re-fragmenting  datagrams in the routers would introduce significant complication into the protocol and put a damper on router performance  if you were a router  would you want to be reassembling fragments on top of everything else you have to do ?  sticking to end-to-end principle for the internet  the designers of ipv4 decided to put the job of datagram reassembly in the end systems rather than in the network interior when a destination host receives a series of datagrams from the same source  it needs to determine if any of these datagrams are fragments of some " original " bigger datagram if it does determine that some datagrams are fragments  it must further determine when it has received the last fragment and how the fragments it has received should be pieced back together to form the original datagram to allow the destination host to perform these reassembly tasks  the designers of of ip  version 4  put identification  flag and fragmentation fields in the ip datagram when a datagram is created  the sending host stamps the datagram with an identification number as well as a source and destination address the sending host increments the identification number for each datagram it sends when a router needs to fragment a datagram  each resulting datagram  i.e  " fragment "  is stamped with the source address  destination address and identification number of the original datagram when the destination receives a series of datagrams from the same sending host  it can examine the identification numbers of the datagrams to determine which of the datagrams are actually fragments of the same bigger datagram because ip is an unreliable service  one or more of the fragments may never arrive at the destination for this reason  in order for the destination host to be absolutely sure it has received the last fragment of the original datagram  the last fragment has a flag bit set to 0 whereas all the other fragments have this flag bit set to 1 also  in order for the destination host to determine if a fragment is missing  and also to be able to reassemble the fragments in the proper order   the offset field is used to specify where the fragment fits within the original ip datagram this bit is set to 1 in all except the last fragment figure 4.4-9  ip fragmentation figure 4.4-9 illustrates an example a datagram 4,000 bytes arrives to a router  and this datagram must be forwarded to a link with a mtu of 1500 bytes these implies that the 3,980 data bytes in the original datagram must be allocated to three separate fragments  each of which are also ip datagrams   suppose that the original datagram is stamped with an identification number of 777 then the characteristics of the three fragments are as follows  1st fragment m 1480 bytes in the data field of the ip datagram m identification = 777 m offset = 0  meaning the data should be inserted beginning at byte 0  m flag = 1  meaning there is more  2nd fragment m 1480 byte information field m identification = 777 m offset = 1,480  meaning the data should be inserted beginning at btye 1,480 m flag = 1  meaning there is more  3rd fragment m 1020 byte  = 3980-1480-1480  information field file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ip.htm  9 of 12  20/11/2004 15  52  21 point-topoint routing in the internet m identification = 777 m offset = 2,960  meaning the data should be inserted beginning at byte 2,960  m flag = 0  meaning this is the last fragment  the payload of the datagram is only passed to the transport layer once the ip layer has fully reconstructed the original ip datagram if one or more of the fragments does not arrive to the destination  the datagram is " lost " and not passed to the transport layer but  as we learned in the previous chapter  if tcp is being used at the transport layer  then tcp will recover from this loss by having the source retransmit the data in the original datagram fragmentation and reassembly puts an additional burden on internet routers  the additional effort to create fragments out of a datagram  and on the destination hosts  the additional effort to reassembly fragments   for this reason it is desirable to keep fragmentation to a minimum this is often done by limiting the tcp and udp segments to a relatively small size  so that the fragmentation of the corresponding datagrams is unlikely because all data link protocols supported by ip are supposed to have mtus of at least 576 bytes  fragmentation can be entirely eliminated by using a mss of 536 bytes  20 bytes of tcp segment header and 20 bytes of ip datagram header this is why most tcp segments for bulk data transfer  such as with http  are 512 536 bytes long  you may have noticed while surfing the web that 500 or so bytes of data often arrive at a time  following this section we provide a java applet that generates fragments you provide the incoming datagram size  the mtu and the incoming datagram identification it automatically generates the fragments for you 4.4.5 icmp  internet control message protocol we conclude this section with a discussion of the internet control message protocol  icmp  which is used by hosts  routers  and gateways to communicate network layer information to each other icmp is specified in  rfc 792   the most typical use of icmp is for error reporting for example  when running a telnet  ftp  or http session  you may have encountered an error message such as " destination network unreachable " this message had its origins in icmp at some point  an ip router was unable to find a path to the host specified in your telnet  ftp or http application that router created and sent a type-3 icmp message to your host indicating the error your host received the icmp message and returned the error code to the tcp code that was attempting to connect to the remote host tcp in turn returned the error code to your application icmp is often considered part of ip  but architecturally lies just above ip  as icmp messages are carried inside ip packets that is  icmp messages are carried as ip payload  just as tcp or udp packets are carried at ip payload similarly  when an host receives an ip packet with icmp specified as the upper layer protocol  it demultiplexes the packet to icmp  just as it would demultiplex a packet to tcp or udp icmp messages have a type and a code field  and also contain the first 8 bytes of the ip packet that caused the ip message to be generated in the first place  so that the sender can determine which packet is sent that caused the error   selected icmp messages are shown below in figure 4.4-10 note that icmp messages are used not only for signaling error conditions the well-known ping  ping man page  program uses icmp ping sends an icmp type 8 code 0 message to the specified host the destination host  seeing the echo request sends back an type 0 code 0 icmp echo reply another interesting icmp message is the source quench message this message is seldom used in practice its original purpose was to perform congestion control  to allow a congested router to send an icmp source quench message to a host to force that host to reduce its transmission rate we have seen in chapter 3 that tcp has its own congestion control mechanism that operates at the transport layer  without the use of network layer support such as the icmp source quench message icmp type code description 0 0 echo reply  to ping  file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...-down % 20approach % 20featuring % 20the % 20internet/ip.htm  10 of 12  20/11/2004 15  52  21 point-topoint routing in the internet 3 0 destination network unreachable 3 1 destination host unreachable 3 2 destination protocol unreachable 3 3 destination port unreachable 3 6 destination network unknown 3 7 destination host unknown 4 0 source quench  congestion control  8 0 echo request 9 0 router advertisement 10 0 router discovery 11 0 ttl expired 12 0 ip header bad table 4.4-10  selected icmp messages in chapter 1 we introduced the traceroute program  which enabled you to trace the route from a few given hosts to any host in the world interesting enough  traceroute also uses icmp messages to determine the names and addresses of the routers between source and destination  traceroute in the source sends a series of ordinary ip datagrams to the destination the first of these datagrams has a ttl of 1  the second of 2  the third of 3  etc the source also starts timers for each of the datagrams when the nth datagram arrives at the nth router  the nth router observers that the ttl of the datagram has just expired according to the rules of the ip protocol  the router discards the datagram  because there may be a routing loop  and sends an icmp warning message to the source  type 11 code 0   this warning message includes the name of the router and its ip address when the icmp message corresponding to the nth datagram arrives at the source  the source obtains the round-trip time from the timer and the name and ip address from the icmp message now that you understand how traceroute works  you may want to go back and play with it some more references  arin 1996  arin  " ip allocation report " ftp  //rs.arin.net/netinfo/ip_network_allocations  bradner 1996  s bradner  a mankin  ipng  internet protocol next generation  adddison wesley  1996  cisco 97  cisco  advanced qos services for the intelligent internet  rfc 791  j postel  " internet protocol  darpa internet program protocol specification  " rfc 791  sept 1981  rfc 950  j mogul  j postel  " internet standard subnetting procedure  " rfc 950  august 1985  rfc 1071  r braden  d borman  and c partridge  " computing the internet checksum  " rfc 1071  september 1988  rfc 1542  w wimer  " clarifications and extensions for the bootstrap protocol  " rfc 1532  october 1993  rfc 1700  j reynolds  j postel  " assigned numbers " rfc 1700  oct 1994  rfc 2002  c perkins  " ip mobility support  " rfc 2002  1996  rfc 2131  r droms  " dynamic host configuration protocol  " rfc 2131  march 1997  rfc 2050  k hubbard  m kosters  d conrad  d karrenberg  j postel  " internet registry ip allocation guidelines "  rfc 2050  nov 1996  rfc 2131  r droms  " dynamic host configuration protocol  " rfc 2131  march 1997 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...-down % 20approach % 20featuring % 20the % 20internet/ip.htm  11 of 12  20/11/2004 15  52  21 point-topoint routing in the internet query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents copyright keith w ross and james f kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...-down % 20approach % 20featuring % 20the % 20internet/ip.htm  12 of 12  20/11/2004 15  52  21 ip fragmentation fragmentation applet provide an mtu  maximum transfer unit  and an incoming datagram size  and the applet will generate all the fragments for you file  ///d | /downloads/livros/computa ? ? o/computer % 20network...p-down % 20approach % 20featuring % 20the % 20internet/index.html20/11/2004 15  52  21 point-topoint routing in the internet 4.5 routing in the internet the internet consists of interconnected autonomous systems  ass   an as typically consists of many networks  where a network  also called an ip network  was defined in the previous section recall from section 4.3 that each autonomous system is administered independently the administrator of an autonomous system chooses the intra-as routing algorithm for that as  and is responsible for administering that as and no others datagrams must also be routed among the ass  and this is the job of inter-as routing protocols as discussed in section 4.3  this hierarchical organization of the internet has permitted the internet to scale in this section we examine the intra-as and inter-as routing protocols for that are commonly used in the internet 4.5.1 intra-autonomous system routing in the internet an intra-as routing protocol is used to configure and maintain the routing tables within an autonomous system  as   once the routing tables are configured  datagrams are routed within the as as described in the previous section inter-as routing protocols are also known as interior gateway protocols historically  three routing protocols have been used extensively for routing within an autonomous system in the internet  rip  the routing information protocol   and ospf  open shortest path first   and igrp  cisco 's propriety interior gateway routing protocol   rip  routing information protocol the routing information protocol  rip  was one of the earliest intra-as internet routing protocols and is still in widespread use today it traces its origins and its name to the xerox network systems  xns  architecture the widespread deployment of rip was due in great part to its inclusion in 1982 of the berkeley software distribution  bsd  version of unix supporting tcp/ip rip version 1 is defined in  rfc 1058   with a backwards compatible version 2 defined in  rfc 1723   rip is a distance vector protocol that operates in a manner very close to the idealized protocol we examined in section 4.2.3 the version of rip specified in rfc 1058 uses hop count as a cost metric  i e  each link has a cost of 1  and limits the maximum cost of a path to 15 this limits the use of rip to autonomous systems that are less than 15 hops in diameter.recall that in distance vector protocols  neighboring routers exchange routing information with each other in rip  the routing tables are exchanged between neighbors every 30 seconds using rip 's this is done with rip 's so-called response message  with each response message containing that host 's routing table entries for up to 25 destination networks these response messages containing routing tables are also called advertisements let us take a look at a simple example of how rip advertisements work consider the portion of an as shown in figure 4.5-2 in this figure  the rectangles denote routers and the lines connecting the rectangles denote networks note that the routers are labeled a  b  etc and the networks are labeled 1  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  1 of 12  20/11/2004 15  52  22 point-topoint routing in the internet 10  20  30  etc for visual convenience  some of the routers and networks are not labeled dotted lines in the figure indicate that the autonomous system continues on and perhaps loops back thus this autonomous system has many more routers and links than are shown in the figure figure 4.5-2  a portion of an autonomous system now suppose that the routing table for router d is as shown in figure 4.5-3 note that the routing table has three columns the first column is for the destination network  the second column indicates the next router along the shortest path to the destination network  and the third column indicates the number of hops  i.e  the number of networks that have to be traversed  including the destination network  to get to the destination network along the shortest path   for this example  the table indicates that to send a datagram from router d to destination network 1  the datagram should be first sent to neighboring router a ; moreover  the table indicates that destination network 1 is two hops away along the shortest path also note that the table indicates that network 30 is seven hops away via router b in principle  the routing table should have one row for each network in the as  although aggregation  a topic beyond the scope of this book  can be used to aggregate entries  it should also have at least one row for networks that are outside of the as the table in figure 4.5-3  and the subsequent tables to come  are only partially complete destination network next router number of hops to destination 1 a 2 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  2 of 12  20/11/2004 15  52  22 point-topoint routing in the internet 20 b 2 30 b 7 10  1    figure 4.5-3  routing table in router d before receiving advertisement from router a now suppose that 30 seconds later  router d receives from router a the advertisement shown in figure 4.5-4 note that this advertisement is nothing other but the routing table in router a ! this routing table says  in particular  that network 30 is only 4 hops away from router a destination network next router number of hops to destination 30 c 4 1  1 10  1    figure 4.5-4  advertisement from router a router d  upon receiving this advertisement  merges the advertisement  figure 4.5-4  with the " old " routing table  figure 4.5-3   in particular  router d learns that there is now a path through router a to network 30 that is shorter than the path through router b thus  router d updates its routing table to account for the " shorter " shortest path  as shown in figure 4.5-5 how is it  you might ask  that the shortest path to network 30 became shorter this is because either this decentralized distance vector algorithm was still in the process of converging  see section 4.2   or new links and/or routers were added to the as  which changed the actual shortest paths in the network destination network next router number of hops to destination 1 a 2 20 b 2 30 a 5    figure 4.5-5  routing table in router d after receiving advertisement from router a file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  3 of 12  20/11/2004 15  52  23 point-topoint routing in the internet returning now to the general properties of rip  if a router does not hear from its neighbor at least once every 180 seconds  that neighbor is considered to be no longer reachable  i.e  either the neighbor has died or the connecting link has gone down when this happens  rip modifies its local routing table and then propagates this information by sendind advertisements to its neighboring routers  the ones that are still reachable   a router can also request information about its neighbor 's cost to a given destination using rip 's request message routers send rip request and response messages to each other over udp using port number 520.the udp packet is carried between routers in a standard ip packet the fact that rip uses a transport layer protocol  udp  on top of a network layer protocol  ip  to implement network layer functionality  a routing algorithm  may seem rather convoluted  it is !   looking a little deeper at how rip is implemented will clear this up figure 4.5-6 sketches how rip is typically implemented in a unix system  e.g  for example  a unix workstation serving as a router a process called routed  pronounced " route dee "  executes the rip protocol  i.e  maintains the routing table and exchanges messages with routed processes running in neighboring routers because rip is implemented as an application-layer process  albeit a very special one that is able to manipulate the routing tables within the unix kernel   it can send and receive messages over a standard socket and use a standard transport protocol thus  rip is an applicationlayer protocol  see chapter 2   running over udp figure 4.5-6  implementation of rip as the routed daemon finally  let us take a quick look at a rip routing table the rip routing table below in figure 4.5-7 is taken from a unix router giroflee.eurecom.fr if you give a netstat -rn command on a unix system  you can view the routing table for that host or router performing a netstat on giroflee eurecom.fr yields the following routing table  destination gateway flags ref use interface file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  4 of 12  20/11/2004 15  52  23 point-topoint routing in the internet       127.0.0.1 127.0.0.1 uh 0 26492 lo0 192.168.2 192.168.2.5 u 2 13 fa0 193.55.114 193.55.114.6 u 3 58503 le0 192.168.3 192.168.3.5 u 2 25 qaa0 224.0.0.0 193.55.114.6 u 3 0 le0 default 193.55.114.129 ug 0 143454 table 4.5-7 rip routing table from giroflee.eurecom.fr the router giroflee is connected to three networks the second  third and fourth rows in the table tell us that these three networks are attached to giroflee via giroflee 's network interfaces fa0  le0 and qaa0 these giroflee interfaces have ip addresses 192.168.2.5  193.55.114.6 and 192.168.3.5  respectively to transmit a packet to any host belonging to one of these three networks  giroflee will simply send the outgoing ip datagram over the appropriate interface of particular interest to us is the default route any ip datagram that is not destined for one of the networks explicitly listed in the routing table will be forwarded to the router with ip address 193.55.114.129 ; this router is reached by sending the datagram over the default network interface the first entry in the routing table is the socalled loopback interface when ip sends a datagram to the loopback interface  the packet is simply returned back to ip ; this is useful for debugging purposes the address 224.0.0.0 is a special multicast  class d  ip address we will examine ip multicast in section 4.8 ospf  open shortest path first like rip  the open shortest path first  ospf  routing is used for intra-as routing the " open " in ospf indicates that the routing protocol specification is publicly available  e.g  as opposed to cisco 's igrp protocol   the most recent version of ospf  version 2  is defined in rfc 2178  a public document ospf was conceived as the successor to rip and as such has a number of advanced features at its heart  however  ospf is a link-state protocol that uses flooding of link state information and a dijkstra least cost path algorithm with ospf  a router constructs a complete topological map  i.e  a directed graph  of the entire autonomous system the router then locally runs dijkstra 's shortest path algorithm to determine a shortest path tree to all networks with itself as the root node the router 's routing table is then obtained from this shortest path tree individual link costs are configured by the network administrator let us now contrast and compare the advertisements sent by rip and ospf with ospf  a router periodically sends routing information to all other routers in the autonomous system  not just to its neighboring routers this routing information sent by a router has one entry for each of the router 's neighbors ; the entry gives the distance  i.e  link state  from the router to the neighbor on the otherhand  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  5 of 12  20/11/2004 15  52  23 point-topoint routing in the internet a rip advertisement sent by a router contains information about all the networks in the autonomous system  although this information is only sent to its neighboring routers in a sense  the advertising techniques of rip and ospf are duals of each other some of the advances embodied in ospf include the following  l security all exchanges between ospf routers  e.g  link state updates  are authenticated this means that only trusted routers can participate in the ospf protocol within a domain  thus preventing malicious intruders  or networking students taking their newfound knowledge out for a joyride  from injecting incorrect information into router tables l multiple same-cost paths when multiple paths to a destination have the same cost  ospf allows multiple paths to be used  i.e  a single path need not be not chosen for carrying all traffic when multiple equal cost paths exist   l different cost metrics for different tos traffic ospf allows each link to have different costs for different tos  type of service  ip packets for example  a high bandwidth satellite link might be configured to have a low cost  and hence be attractive  for non-time critical traffic  but a very high cost metric for delay-sensitive traffic in essence  ospf sees different network topologies for different classes of traffic  and hence can compute different routes for each type of traffic l integrated support for unicast and multicast routing multicast ospf  rfc 1584  provides simple extensions to ospf to provide for multicast routing  a topic we cover in more depth in section 4.8   mospf uses the existing ospf link database and adds a new type of link state advertisement to the existing ospf link state broadcast mechanism l support for hierarchy within a single routing domain perhaps the most significant advance in ospf is the ability to hierarchically structure an autonomous system section 4.3 has already looked at the many advantages of hierarchical routing structures we cover the implementation of ospf hierarchical routing in the remainder of this section as ospf autonomous system can be configured into " areas " each area runs its own ospf link state routing algorithm  with each router in an area broadcasting its link state to all other routers in that area the internal details of an area thus remain invisible to all routers outside the area intra-area routing involves only those routers within the same area within each area  one of more area border routers are responsible for routing packets outside the area exactly one ospf area in the as is configured to be the backbone area the primary role of the backbone area is to route traffic between the other areas in the as the backbone always contains all area border routers in the as and may contain non border routers as well inter-area routing within the as requires that the packet be first routed to an area border router  ntradomain routing   then routed though the backbone to the area border router that is in the destination area  and then routed to the final destination file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  6 of 12  20/11/2004 15  52  23 point-topoint routing in the internet figure 4.5-7  hierarchically structured ospf as with four areas a diagram of a hierarchically structured ospf network is shown in figure 4.4-5  we can identify four types of ospf routers in figure 4.5-7  l internal routers these routers  shown in black  are in a non-backbone areas and only perform intra-as routing l area border routers these routers  shown in blue  belong to both an area and the backbone l backbone routers  non border routers   these routers  shown in gray  perform routing within the backbone but themselves are not area border routers within a non-backbone area  internal routers learn of the existence of routes to other areas from information  essentially a link state advertisement  but advertising the cost of a route to another area  rather than a link cost  broadcast within the area by its backbone routers l boundary routers a boundary router  shown in blue  exchanges routing information with routers belonging to other autonomous systems this router might  for example  use bgp to perform inter-as routing it is through such a boundary router that other routers learn about paths to external networks igrp  internal gateway routing protocol the interior gateway routing protocol  igrp   cisco97  is a proprietary routing algorithm developed by cisco systems  inc in the mid-1980 's as a successor for rip igrp is a distance vector protocol several cost metrics  including delay  bandwidth  reliability  and load  can be used in making routing decisions  with the weight given to each of the metrics being determined by the network administrator this ability to use administrator-defined costs in making route selections is an important difference from rip ; we will see shortly that so-called policy-based interdomain internet routing protocols such as bgp file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  7 of 12  20/11/2004 15  52  23 point-topoint routing in the internet also allow administratively defined routing decisions to be made other important differences from rip include the use of a reliable transport protocol to communicate routing information  the use of update messages that are sent only when routing table costs change  rather than periodically   and the use of a distributed diffusing update routing algorithm  garcia-luna-aceves 1991  to quickly compute loop free routing paths 4.5.2 inter-autonomous system routing the border gateway protocol version 4  specified in rfc 1771  see also rfc 1772  rfc 1773   is the de facto standard interdomain routing protocol in today 's internet it is commonly referred to as bgp4 or simply as bgp as an inter-autonomous system routing protocol  it provides for routing between autonomous systems  that is  administrative domains   while bgp has the same general flavor as the distance vector protocol that we studied in section 4.2  it is more appropriately characterized as a path vector protocol this is because bgp in a router does not propagate cost information  e.g  number of hops to a destination   but instead propagates path information  such as the sequence of ass on a route to a destination as we will examine the path information in detail shortly we note though that while this information includes the names of the ass on a route to the destination  they do not contain cost information nor does bgp specify how a specific route to a particular destination should be chosen among the routes that have been advertised that decision is a policy decision that is left up to the domain 's administrator each domain can thus choose its routes according to whatever criteria it chooses  and need not even inform its neighbors of its policy !   allowing a significant degree of autonomy in route selection in essence  bgp provides the mechanisms to distribute path information among the interconnected autonomous systems  but leaves the policy for making the actual route selections up to the network administrator let 's begin with a grossly simplified description of how bgp works this will help us see the forest through the trees as discussed in section 4.3  as far as bgp is concerned  the whole internet is a graph of ass  and each as is identified by an as number at any instant of time  a given as x may  or may not  know of a path of ass that lead to a given destination as z as an example  suppose x has listed in its bgp table such a path xy1y2y3z from itself to z this means that x knows that it can send datagrams to z through the ass x  y1  y2 and y3  z when x sends updates to its bgp neighbors  i.e  the neighbors in the graph   x actually sends the enitre path information  xy1y2y3z  to its neighbors  as well as other paths to other ass   if  for example  w is a neighbor of x  and w receives an advertisement that includes the path xy1y2y3z  then w can list a new entry wxy1y2y3z in its bgp table .however  we should keep in mind that w may decide to not create this new entry for one of several reasons for example  w would not create this entry if w is equal to  say  y2  thereby creating an undesirable loop in the routing ; or if w already has a path to z in its tables  and this existing path is preferable  with respect to the metric used by bgp at w  to wxy1y2y3z ; or  finally  if w has a policy decision to not forward datagrams through  say  y2  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  8 of 12  20/11/2004 15  52  23 point-topoint routing in the internet in bgp jargon  the immediate neighbors in the graph of ass are called peers bgp information is proprogated through the network by exchanges of bgp messages between peers the bgp protocol defines the four types of messages  open  update  notification and keepalive l open  bgp peers communicate using the tcp protocol and port number 179 tcp thus provides for reliable and congestion controlled message exchange between peers in contrast  recall that we earlier saw that two rip peers  e.g  the routed 's in figure 4.5-6 communicate via unreliable udp when a bgp gateway wants to first establish contact with a bgp peer  e.g  after the gateway itself or a connecting link has just be booted   an open message is sent to the peer the open message allows a bgp gateway to identify and authenticate itself  and provide timer information if the open is acceptable to the peer  it will send back a keepalive message l update  a bgp gateway uses the update message to advertise a path to a given destination  e.g  xy1y2y3z  to the bgp peer the update message can also be used to withdraw routes that had previously been advertised  that is  to tell a peer that a route that it had previously advertised is no longer a valid route   l keepalive  this bgp message is used to let a peer know that the sender is alive but that the sender does n't have other information to send it also serves as an acknowledgment to a received open message l notification  this bgp message is used to inform a peer that an error has been detected  e g  in a previously transmitted bgp message  or that the sender is about to close the bgp session recall from our discussion above that bgp provides mechanisms for distributing path information but does not mandate policies for selecting a route from those available within this framework  it is thus possible for an as such as hatfield.net to implement a policy such as " traffic from my as should not cross the as mccoy.net  " since it knows the identities of all as 's on the path  the hatfield and the mccoy 's are two famous feuding families in the us   but what about a policy that would prevent the mccoy 's from sending traffic through the hatfield 's network ? the only means for an as to control the traffic it passes though its as  known as " transit " traffic  traffic that neither originates in  nor is destined for  the network  but instead is " just passing through "  is by controlling the paths that it advertises for example  if the mccoy 's are immediate neighbors of the hatfields  the hatfields could simply not advertise any routes to the mccoy 's that contain the hatfield network but restricting transit traffic by controlling an as 's route advertisement can only be partially effective for example  if the jones are between the hatfield 's and the mccoy 's  and the hatfield 's advertise routes to the jones ' that pass through the hatfields  then the hatfields can not prevent  using bgp mechanisms  the jones from advertising these routes to the mccoys very often an as will have muliple gateway routers that provide connections to other ass even though bgp is an inter-as protocol  it can still be used inside an as as a pipe to exchange bgp updates among gateway routers belonging to the same as bgp connections inside an as are called internal bgp  ibgp   whereas bgp connections between ass are called external bgp  ebgp   file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  9 of 12  20/11/2004 15  52  23 point-topoint routing in the internet as noted above  bgp  which is the successor to egp  is becoming the de facto standard for inter-as routing for the public internet bgp is used for example at the major network access points  nap 's  where major internet carries connect to each other and exchange traffic to see the contents of today 's  less than four hours out of date  bgp routing table  large !  at one of the major nap 's in the us  which include chicago and san francisco   click here this completes our brief introduction of bgp although bgp is complex  it plays a central role in the internet we encourage readers to see the references  halabi 97  and  huitema 95  to learn more about bgp 4.5.3 why are there different inter-as and intra-as routing protocols ? having now studied the details of specific inter-as and intra-as routing protocols deployed in today 's internet  let us conclude by considering perhaps the most fundamental question we could ask about these protocols in the first place  hopefully  you have been wondering this all along  and have not lost the forest for the trees !   why are different inter-as and intra-as routing protocols used ? the answer to this question gets at the heart of the differences between the goals of routing within an as and among ass  l policy among ass  policy issues dominate it may well be important that traffic originating in a given as specifically not be able to pass through another specific as similarly  a given as may well want to control what transit traffic it carries between other ass we have seen that bgp specifically carries path attributes and provide for controlled distribution of routing information so that such policy-based routing decisions can be made within an as  everything is nominally under the same administrative control  and thus policy issues play a much less important role in choosing routes within the as l scale the ability of a routing algorithm and its data structures to scale to handle routing to/ among large numbers of networks is a critical issue in inter-as routing within an as  scalability is less of a concern for one thing  if a single administrative domain become too large  it is always possible to divide it into two ass and perform inter-as routing between the two new ass  recall that ospf allows such a hierarchy to be built by splitting an as into " areas "   l performance because inter-as routing is so policy-oriented  the quality  e.g  performance  of the routes used is often of secondary concern  i.e  a longer or more costly route that satisfies a certain policy criteria may well be taken over a route that is shorter but does not meet that criteria   indeed  we saw that among ass  there is not even the notion of preference or costs associated with routes within a single as  however  such policy concerns can be ignored  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  10 of 12  20/11/2004 15  52  23 point-topoint routing in the internet allowing routing to focus more on the level of performance realized on a route references  cisco97  interior gateway routing protocol and enhanced igrp  rfc 792  j postel  " internet control message protocol  " rfc 792  sep-01-1981  rfc 904  d mills  " exterior gateway protocol formal specification  " rfc 791  april 1984  rfc 1058  c.l hendrick  " routing information protocol  " rfc 1058  june 1988  rfc 1256  s deering  " icmp router discovery messages  " rfc 1256  sept 1991  rfc 1584  j moy  " multicast extensions to ospf  " rfc 1584  march 1994  rfc 1723  g malkin  rip version 2  carrying additional information rfc 1723  november 1994  rfc 1771  y rekhter and t li  " a border gateway protocol 4  bgp-4   " rfc 1771  march 1995  rfc 1772  y rekhter and p gross  " application of the border gateway protocol in the internet  " rfc 1772  march 1995  rfc 1773  p traina  " experience with the bgp-4 protocol  " rfc 1773  march 1995  rfc 2002  c perkins  " ip mobility support  " rfc 2002  1996  rfc 2178  j moy  " open shortest path first version 2 "  rfc 2178  july 1997  halabi 97  b halabi  internet routing architectures  cisco systems publishing  indianapolis  1997  huitema 95  c huiteman  routing in the internet  prentice hall  new jersey  1995 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  11 of 12  20/11/2004 15  52  23 point-topoint routing in the internet return to table of contents copyright keith w ross and james f kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/routinet.htm  12 of 12  20/11/2004 15  52  23 what 's inside a router ? 4.6 what 's inside a router ? our study of the network layer so far has focussed on network layer service models  the routing algorithms that control the routes taken by packets through the network  and the protocols that embody these routing algorithms these topics  however  are only part  albeit important ones  of what goes on in the network layer we have yet to consider the switching function of a router  the actual transfer of datagrams from a router 's incoming links to the appropriate outgoing links studying just the control and service aspects of the network layer is like studying a company and considering only its management  which controls the company but typically performs very little of the actual " grunt " work that makes a company run !  and its public relations  " our product will provide this wonderful service to you ! "   to fully appreciate what really goes on within a company  one needs to consider the workers in the network layer  the real work  that is  the reason the network layer exists in the first place  is the forwarding of datagrams a key component in this forwarding process is the transfer of a datagram from a router 's incoming link to an outgoing link in this section we study how this is accomplished our coverage here is necessarily brief  as an entire course would be needed to cover router design in depth consequently  we 'll make a special effort in this section to provide pointers to material that covers this topic in more depth a high level view of a generic router architecture is shown in figure 4.6-1 four components of a router can be identified  l input ports the input port performs several functions it performs the physical layer functionality  shown in light blue in figure 4.6-1  of terminating an incoming physical link to a router it performs the data link layer functionality  shown in dark blue  needed to interoperate with the data link layer functionality  see chapter 5  on the other side of the incoming link it also performs a lookup and forwarding function  shown in red  so that a datagram forwarded into the switching fabric of the router emerges at the appropriate output port control packets  e.g  packets carrying routing protocol information such as rip  ospf or igmp  are forwarded from the input port to the routing processor in practice  multiple ports are often gathered together on a single line card within a router l switching fabric the switching fabric connects the router 's input ports to its output ports this switching fabric is completely contained with the router  a network inside of a network router ! l output ports an output port stores the datagrams that have been forwarded to it through the switching fabric  and then transmits the datagrams on the outgoing link the output port thus performs the reverse data link and physical layer functionality as the input port l routing processor the routing processor executes the routing protocols  e.g  the protocols we studied in section 4.4   maintains the routing tables  and performs network management functions  see chapter 8   within the router since we cover these topics elsewhere in this book  we defer discussion of these topics to elsewhere file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  1 of 11  20/11/2004 15  52  24 what 's inside a router ? figure 4.6-1  router architecture in the following  we 'll take a look at input ports  the switching fabric  and output ports in more detail  turner 1988  giacopelli 1990  mckeown 1997a  partridge 1998  provide a discussion of some specific router architectures  mckeown 1997b  provides a particularly readable overview of modern router architectures  using the cisco 12000 router as an example 4.6.1 input ports a more detailed view of input port functionality is given in figure 4.6-2 as discussed above  the input port 's line termination function and data link processing implement the physical and data link layers associated with an individual input link to the router the lookup/forwarding function of the input port is central to the switching function of the router in many routers  it is here that the router determines the output port to which an arriving datagram will be forwarded via the switching fabric the choice of the output port is made using the information contained in the routing table although the routing table is computed by the routing processor  a " shadow copy " of the routing table is typically stored at each input port and updated  as needed  by the routing processor with local copies of the routing table  the switching decision can be made locally  at each input port  without invoking the centralized routing processor such decentralized switching avoids creating a forwarding bottleneck at a single point within the router in routers with limited processing capabilities at the input port  the input port may simply forward the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  2 of 11  20/11/2004 15  52  24 what 's inside a router ? packet to the centralized routing processor  which will then perform the routing table lookup and forward the packet to the appropriate output port this is the approach taken when a workstation or server serves as a router  e.g   microsoft 1998   ; here  the " routing processor " is really just the workstation 's cpu and the " input port " is really just a network interface card  e.g  a ethernet card   figure 4.6-2  input port processing given the existence of a routing table  the routing table lookup is conceptually simple  we just search through the routing table  looking for a destination entry that matches the destination address of the datagram  or a default route if the destination entry is missing in practice  however  life is not so simple perhaps the most important complicating factor is that backbone routers must operate at high speeds  being capable of performing millions of lookups per second indeed  it is desirable for the input port processing to be able to proceed at line speed  i.e  that a lookup can be done in less than the amount of time needed to receive a packet at the input port in this case  input processing of a received packet can be completed before the next receive operation is complete to get an idea of the performance requirements for lookup  consider that a so-called oc48 link runs at 2.5 gbps with 256 byte long packets  this implies a lookup speed of approximately a million lookups per second given the need to operate at today 's high link speeds  a linear search through a large routing table is impossible a more reasonable technique is to store the routing table entries in a tree data structure each level in the tree can be thought of as corresponding to a bit in the destination address to lookup an address  one simply starts at the root node of the tree if the first address bit is a zero  then the left subtree will contain the routing table entry for destination address ; otherwise it will be in the right subtree the appropriate subtree is then traversed using the remaining address bits  if the next address bit is a zero the left subtree of the initial subtree is chosen ; otherwise  the right subtree of the initial subtree is chosen in this manner  one can lookup the routing table entry in n steps  where n is the number of bits in the address  the reader will note that this is essentially a binary search through an address space of size 2n  refinements of this approach are discussed in  doeringer 1996   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  3 of 11  20/11/2004 15  52  24 what 's inside a router ? but even with n = 32  e.g  a 32-bit ip address  steps  the lookup speed is not fast enough for today 's backbone routing requirements for example  assuming a memory access at each step  less than a million address lookups/sec could be performed with 40 ns memory access times several techniques have thus been explored to increase lookup speeds content addressable memories  cams  allow a 32 bit ip address to be presented to the cam  which then returns the content of the routing table entry for that address in essentially constant time the cisco 8500 series router  cisco 1998a  has a 64k cam for each input port another technique for speeding lookup is to keep recently accessed routing table entries in a cache  feldmeier 1998   here  the potential concern is the size of the cache measurements in  thompson 1997  suggest that even for an oc-3 speed link  approximately 256,000 sourcedestination pairs might be seen in one minute in a backbone router most recently  even faster data structures  which allow routing table entry to be located in log  n  steps  waldvogel 1997   or which compress routing tables in novel ways  degemark 1997   have been proposed a hardware-based approach to lookup that is optimized for the common case that the address being looked up has 24 or less significant bits is discussed in  gupta 1998   once the output port for a packet has been determined via the lookup  the packet can be forwarded into the switching fabric however  as we 'll see below  a packet may be temporarily blocked from entering the switching fabric  due to the fact that packets from other input ports are currently using the fabric   a blocked packet must thus be queued at the input port and then scheduled to cross the switching fabric at a later point in time we 'll take a closer look at the blocking  queueing and scheduling of packets  at both input ports and output ports  within a router in section 4.6.4 below 4.6.2 switching fabrics the switching fabric is at the very heart of a router it is through this switching that the datagrams are actually moved from an input port to an output port switching can be accomplished in a number of ways  as indicated in figure 4.6-3  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  4 of 11  20/11/2004 15  52  24 what 's inside a router ? figure 4.6-3  three switching techniques l switching via memory the simplest  earliest routers were often traditional computers  with switching between input and output port being done under direct control of the cpu  routing processor   input and output ports functioned as traditional i/o devices in a traditional operating system an input port with an arriving datagram first signaled the routing processor via an interrupt the packet was then copied from the input port into processor memory the routing processor then extracted the destination address from the header  looked up the appropriate output port in the routing table  and copied the packet to the output port 's buffers note that if the memory bandwidth is such that b packets/sec can be written into  or read from  memory  then the overall switch throughput  the total rate at which packets are transferred from input ports to file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  5 of 11  20/11/2004 15  52  24 what 's inside a router ? output ports  must be less than b/2 many modern routers also switch via memory a major difference from early routers  however  is that the lookup of the destination address and the storing  switching  of the packet into the appropriate memory location is performed by processors on the input line cards in some ways  routers that switch via memory look very much like shared memory multiprocessors  with the processors on a line line card storing datagrams into the memory of the appropriate output port cisco 's catalyst 8500 series switches  cisco 1998a  and bay networks accelar 1200 series routers switch packets via a shared memory l switching via a bus in this approach  the input ports transfer a datagram directly to the output port over a shared bus  without intervention by the routing processor  note that when switching via memory  the datagram must also cross the system bus going to/from memory   although the routing processor is not involved in the bus transfer  since the bus is shared  only one packet at a time can be transferred over the bus at a time a datagram arriving at an input port and finding the bus busy with the transfer of another datagram is blocked from passing through the switching fabric and queued at the input port because every packet must cross the single bus  the switching bandwidth of the router is limited to the bus speed given that bus bandwidths of over a gigabit per second are possible in today 's technology  switching via a bus is often sufficient for routers that operate in access and enterprise networks  e.g  local area and corporate networks   bus-based switching has been adopted in a number of current router products  including the cisco 1900  cisco 1997b   which switches packets over a 1gbps packet exchange bus 3com 's corebuilder 5000 systems  kapoor 1997  interconnects ports that reside on different switch modules over its packetchannel data bus  with a bandwidth of 2 gbps l switching via an interconnection network one way to overcome the bandwidth limitation of a single  shared bus is to use a more sophisticated interconnection network  such as those that have been used in the past to interconnect processors in a multiprocessor computer architectures a crossbar switch is an interconnection network consisting of 2n busses that connect n input ports to n output ports  as shown in figure 4.6-3 a packet arriving at an input port travels along the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  6 of 11  20/11/2004 15  52  24 what 's inside a router ? horizontal bus attached to the input port until it intersects with the vertical bus leading to the desired output port if the vertical bus leading to the output port is free  the packet is transferred to the output port if the vertical bus is being used to transfer a packet from another input port to this same output port  the arriving packet is blocked and must be queued at the input port delta and omega switching fabrics have also been proposed as an interconnection network between input and output ports see  tobagi 90  for a survey of switch architectures cisco 12000 family switches  cisco 1998b  use an interconnection network  providing up to 60 gbps through the switching fabric one current trend in interconnection network design  keshav 1998  is to fragment a variable length ip datagram into fixed length cells  and then tag and switch the fixed length cells through the interconnection network the cells are then reassembled into the original datagram at the output port the fixed length cell and internal tag can considerably simplify and speed up the switching of the packet through the interconnection network 4.6.3 output ports output port processing  shown in figure 4.6-4  takes the datagrams that have been stored in the output port 's memory and transmits them over the outgoing link the data link protocol processing and line termination are the send-side link and physical layer functionality that interact with the input port on the other end of the outgoing link  as discussed above in section 4.6.2 the queueing and buffer management functionality are needed when the switch fabric delivers packets to the output port at a rate that exceeds the output link rate ; we 'll cover output port queueing below figure 4.6-4  output port processing 4.6.4 where does queueing occur ? looking at the input and output port functionality and the configurations shown in figure 4.6-3  it is evident that packet queues can form at both the input ports and the output ports it is important to file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  7 of 11  20/11/2004 15  52  24 what 's inside a router ? consider these queues in a bit more detail  since as these queues grow large  the router 's buffer space will eventually be exhausted and packet loss will occur recall that in our earlier discussions  we said rather vaguely that packets were lost " within the network " or " dropped at a router " it is here  at these queues within a router  where such packets are dropped and lost the actual location of packet loss  either at the input port queues or the output port queues  will depend on the traffic load  the relative speed of the switching fabric and the line speed  as discussed below suppose that the input line speeds and output line speeds are all identical  and that there are n input ports and n output ports if the switching fabric speed is at least n times as fast as the input line speed  than no queuing can occur at the input ports this is because even in the worst case that all n input lines are receiving packets  the switch will be able to transfer n packets from input port to output port in the time it takes each of the n input ports to  simultaneously  receive a single packet but what can happen at the output ports ? let us suppose still that the switching fabric is at least n times as fast as the line speeds in the worst case  the packets arriving at each of the n input ports will be destined to the same output port in this case  in the time it takes to receive  or send  a single packet  n packets will arrive at this output port since the output port can only transmit a single packet in a unit of time  the packet transmission time   the n arriving packets will have to queue  wait  for transmission over the outgoing link n more packets can then possibly arrive in the time it takes to transmit just one of the n packets that had previously been queued and so on eventually  buffers can grow large enough to exhaust the memory space at the output port  in which case packets are dropped figure 4.6-5  output port queueing output port queueing is illustrated in figure 4.6-5 at time t  a packet has arrived at each of the incoming input ports  each destined for the uppermost outgoing port assuming identical line speeds and a switch operating at three times the line speed  one time unit later  i.e  in the time needed to receive or send a packet   all three original packets have been transferred to the outgoing port and are queued awaiting transmission in the next time unit  one of these three packets will have been file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  8 of 11  20/11/2004 15  52  24 what 's inside a router ? transmitted over the outgoing link in our example  two new packets have arrived at the incoming side of the switch ; one of these packets is destined for this uppermost output port a consequence of output port queueing is that a packet scheduler at the output port must choose one packet among those queued for transmission this selection might be done on a simple basis such as first-come-first-served  fcfs  scheduling  or a more sophisticated scheduling discipline such as weighted fair queueing  wfq   which shares the outgoing link " fairly " among the different end-to-end connections that have packets queued for transmission packet scheduling plays a crucial role in providing quality of service guarantees we will cover this topic extensively in section 6.6 a discussion of output port packet scheduling disciplines used in today 's routers is  cisco 1997a   if the switch fabric is not fast enough  relative to the input line speeds  to transfer all arriving packets through the fabric without delay  then packet queueing will also occur at the input ports  as packets must join input port queues to wait their turn to be transferred through the switching fabric to the output port to illustrate an important consequence of this queueing  consider a crossbar switching fabric and suppose that  i  all link speeds are identical  ii  that one packet can be transferred from any one input port to a given output port in the same amount of time it takes for packet to be received on an input link and  iii  packet are moved from a given input queue to their desired output queue in a fcfs manner multiple packets can be transferred in parallel  as long as their output ports are different however  if two packets at the front of two input queues are destined to the same output queue  then one of the packets be blocked and must wait at the input queue  the switching fabric can only transfer one packet to a given output port at a time file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  9 of 11  20/11/2004 15  52  24 what 's inside a router ? figure 4.6-6  hol blocking at an input queued switch figure 4.6-6 shows an example where two packets  red  at the front of their input queues are destined for the same upper right output port suppose that the switch fabric chooses to transfer the packet from the front of the upper left queue in this case  the red packet in the lower left queue must wait but not only must this red packet wait  but so too must the green packet that is queued behind that packet in the lower left queue  even though there is no contention for the middle right output port  the destination for the green packet   this phenomenon is known as head-of-the-line  hol  blocking in an input-queued switch  a queued packet in an input queue must wait for transfer through the fabric  even though its output port is free  due to the blocking of another packet at the head-of-the-line  karol 1987  shows that due to hol blocking  the input queue will grow to unbounded length  informally  this is equivalent to saying that significant packet loss will occur  as soon as packet arrival rate on the input links reaches only 58 % of their capacity a number of solutions to hol blocking are discussed in  mckeown 1997b   references  cisco 1997a  cisco systems  " queue management  " http  //www.cisco.com/warp/public/614/ quemg_wp.htm  1997  cisco 1997b  cisco systems  next generation clearchannel architecture for catalyst 1900/2820 ethernet switches  http  //www.cisco.com/warp/public/729/c1928/nwgen_wp.htm  1997 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  10 of 11  20/11/2004 15  52  24 what 's inside a router ?  cisco 1998 a  cisco systems " catalyst 8500 campus switch router architecture  " http  //www.cisco.com/warp/public/729/c8500/csr/8510_wp.htm  1998  cisco 1998b  cisco systems  " cisco 12000 series gigabit switch routers  " http  //www.cisco.com/ warp/public/733/12000/12000_ov.htm  1998  degemark 1997  m degemark et al  " small forwarding tables for fast router lookup  " proc 1997 acm sigcomm conference   canes  france  sept 1997    doeringer 1996  w doeringer  g karjoth  m nassehi  " routing on longest matching prefixes  " ieee/acm transactions on networking  vol 4  no 1  feb 1996   pp 86-97  giacopelli 1990  j giacopelli  m littlewood  w.d sincoskie ? sunshine  a high performance selfrouting broadband packet switch architecture ?  1990 international switching symposium  gupta 1998  p gupta  s lin  n.mckeown ? routing lookups in hardware at memory access speeds ?  proc ieee infocom 1998  pp 1241-1248  kapoor 1997  h kapoor  " corebuilder 5000 switchmodule architecture  " http  //www.3com.com/ technology/tech_net/white_papers/500645.html  1997  karol 1987  m karol  m hluchyj  a morgan  " input versus output queueing on a space-division packet switch  " ieee transactions on communications  vol com-35  no 12  pp 1347-1356  december 1987  keshav 1998  s keshav  r sharma  " issues and trends in router design  " ieee communications magazine  vol 36  no 5  may 1998   pp 144-151  microsoft 1998  microsoft corp  " microsoft routing and remote access service for windows nt server 4.0   http  //www.microsoft.com/ntserver/basics/communications/basics/remoteaccess/routing/ default.asp  mckeown 1997a  n mckeown  m izzard  a mekkittikul  w ellersick  m horowitz  ? the tiny tera  a packet switch core ?  ieee micro magazine  jan-feb 1997  mckeown 1997b  n mckeown  " a fast switched backplane for a gigabit switched router  " business communications review  vol 27 n0 12  partridge 1998  c partridge et al ? a fifty gigabit per second ip router ?  ieee/acm transactions on networking  1998  tobagi 1990  f tobagi  " fast packet switch architectures for broadband integrated networks  " proc ieee  vol 78  no 1  pp 133-167  turner 1988  j s turner ? design of a broadcast packet switching network ?  ieee trans comm  june 1988  pp 734-743  feldmeier 1988  d feldmeier  " improving gateway performance with a routing table cache  " proc 1988 ieee conference   new orleans la  march 1988    thomson 1997  k thomson  g miller  r wilder  " wide area traffic patterns and characteristics  " ieee network magazine  dec 1997  waldvogel 1997  m waldvogel et al  " scalable high speed ip routing lookup  " proc 1997 acm sigcomm conference   canes  france  sept 1997   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/inside.htm  11 of 11  20/11/2004 15  52  24 ipv6 4.7 ipv6 in the early 1990 's the internet engineering task force began an effort to develop a successor to the ipv4 protocol a prime motivation for this effort was the realization that the 32-bit ip address space was beginning to be used up  with new networks and ip nodes being attached to the internet  and being allocated unique ip addresses  at a breathtaking rate to respond to this need of a large ip address space  a new ip protocol  ipv6  was developed the designers of ipv6 also took this opportunity to tweak and augment other aspects of ipv4  based on the accumulated operational experience with ipv4 the point in time when ipv4 addresses would have been completely allocated  and hence no new networks could have attached to the internet  was the subject of considerable debate based on current trends in address allocation  the estimates of the two leaders of the ietf 's address lifetime expectations working group were that addresses would become exhausted in 2008 and 2018 respectively  solensky 1996   in 1996  the american registry for internet number  arin  reported that all of the ipv4 class a addresses have been assigned  62 % of the class b addresses have been assigned  and 37 % of the class c addresses have been assigned  arin 1996   while these estimates and numbers suggested that a considerable amount of time might be left until the ipv4 address space became exhausted  it was realized that considerable time would be needed to deploy a new technology on such an extensive scale  and so the " next generation ip "  ipng  effort  bradner 1996    rfc1752  was begun an excellent on-line source of information about ipv6 is the ip next generation homepage an excellent book is also available on the subject  huitema 1997   4.7.1 ipv6 packet format the format of the ipv6 packet is shown in figure 4.7-1 the most important changes introduced in ipv6 are evident in the packet format  l expanded addressing capabilities ipv6 increases the size of the ip address from 32 to 128 bits this insures that the world wo n't run out of ip addresses now  every grain of sand on the planet can be ip-addressable in addition  the address space contains new hierarchical structure  allocating portions of the enlarged address space to geographical regions  rfc 1884   in addition to unicast and multicast addresses  a new type of address  called an anycast address  has also been introduced  which allows a packet addressed to an anycase address to be delivered to any one of a group of hosts this feature could be used  for example  to send an http get to the nearest of a number of mirror sites that contain a given document   l a streamlined 40 byte header as discussed below  a number of ipv4 fields have ben dropped or made optional the resulting 40-byte fixed-length header allows for faster processing of the ip packet a new encoding of options allows for more flexible options processing l flow labeling and priority ipv6 has an elusive definition of a " flow "  rfc 1752  and  rfc file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  1 of 7  20/11/2004 15  52  25 ipv6 2460  state this allows " labeling of packets belonging to particular flows for which the sender requests special handling  such as a non-default quality of service or real-time service " for example  audio and video transmission might likely be treated as a flow on the other hand  the more traditional applications  such as file transfer and email might not be treated as flows it is possible that the traffic carried by a high-priority user  e.g  someone paying for better service for their traffic  might also be treated as a flow what is clear  however  is that the designers of ipv6 foresee the eventual need to be able to differentiate among the " flows  " even if the exact meaning of a flow has not yet been determined the ipv6 header also has a 4-bit priority field this field  as the tos field in ipv4  can be used to give priority to certain packets within a flow  or it can be used to give priority to datagrams from certain applications  e.g  icmp packets  over packets from other applications  e.g  network news   figure 4.7-1  ipv6 packet format the ipv6 packet format is shown in figure 4.7-1 as noted above  a comparison of figure 4.7-1 with figure 4.4-8 reveals the simpler  more streamlined structure of the ipv6 packet the following packet fields are defined in ipv6  l version this four bit field identifies the ip version number not surprisingly  ipv6 carries a value of " 6 " in this field note that putting a " 4 " in this field does not create a valid ipv4 packet  if it did  life would be a lot simpler  see the discussion below regarding the transition from ipv4 to ipv6 l priority this four bit field is similar in spirit to the tos field we saw in ip version 4  rfc 2460  states that values 0 through 7 are to be used for priority among traffic that is congestionfile  /// d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  2 of 7  20/11/2004 15  52  25 ipv6 controlled  i.e  for which the source will back off on detection of congestion   while values 8 through 15 are used for non-congestion controlled traffic  such as constant bit rate real-time traffic l flow label as discussed above  this field is used to identify a " flow " of packets l payload length this 16-bit value is treated as an unsigned integer given the number of bytes in the ipv6 packet following the fixed length  40 byte packet header l next header this field identifies the protocol to which the contents  data field  of this packet will be delivered  e.g  to tcp or udp   the field uses the same values as the protocol field in the ipv4 header l hop limit the contents of this field are decremented by one by each router that forward the packet if the hop limit count reaches zero  the packet is discarded l source and destination address an ip v6 address has the following structure  l data this is the payload portion of the ipv6 packet when the packet reaches its destination  the payload will be removed from the ip packet and passed on to the protocol specified in the nex header field the discussion above identified the purpose of the fields that are included in the ipv6 packet comparing the ipv6 packet format in figure 4.7-1 with the ipv4 packet format that we saw earlier in figure 4.4-8  we notice that several fields appearing in the ipv4 packet are no longer present in the ipv6 packet  l fragmentation/reassembly ipv6 does not provide for fragmentation and reassembly if an ipv6 packet received by a router is too large to be forwarded over the outgoing link  the router simply drops the packet and sends a " packet too big " icmp error message  see below  back to the sender the sender can then resend the data  using a smaller ip packet size fragmentation and reassembly is a time-consuming operating ; removing this functionality from the routers and placing it squarely in the end systems considerably speeds up ip forwarding within the network l checksum because the transport layer  e.g  tcp and udp  and data link  e.g  ethernet  protocols in the internet layers perform checksumming  the designers of ip probably felt that this functionality was sufficiently redundant in the network layer that it could be removed once again  fast processing of ip packets was a central concern recall from our discussion of ipv4 in section 4.4.1  that since the ipv4 header contains a ttl field  similar to the hop limit field in ipv6   the ipv4 header checksum needed to be recomputed at every router as with fragmentation and reassembly  this too was a costly operation in ipv4 l options an options field is no longer a part of the standard ip header however  it has not gone away instead  the options field is one of the possible " next headers " pointed to from within the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  3 of 7  20/11/2004 15  52  25 ipv6 ipv6 header that is  just as tcp or udp protocol headers can be the next header within an ip packet  so too can an options field the removal of the options filed results in a fixed length  40 byte ip header a new icmp for ipv6 recall from our discussion in section 4.3  that the icmp protocol is used by ip nodes to report error conditions and provide limited information  e.g  the echo reply to a ping message  to an end system a new version of icmp has been defined for ipv6 in  rfc 1885   in addition to reorganizing the existing icmp type and code definitions  icmpv6 also added new types and codes required by the new ipv6 functionality these include the " packet too big " type  and an " unrecognized ipv6 options " error code in addition  icmpv6 subsumes the functionality of the internet group management protocol  igmp  that we will study in section 4.8 igmp  which is used to manage a host 's joining and leaving of socalled multicast groups  was previously a separate protocol from icmp in ipv4 5.7.2 transitioning from ipv4 to ipv6 now that we have seen the technical details of ipv6  let us consider a very practical matter  how will the public internet  which is based on ipv4  be transitioned to ipv6 ? the problem is that while new ipv6 capable systems can be made " backwards compatible "  i.e  can send  route  and receive ipv4 packets  already deployed ipv4-capable systems are not capable of handling ipv6 packets several options are possible one option would be to declare a " flag day "  a given time and date when all internet machines would be turned off  be upgraded from ipv4 to ipv6 the last major technology transition  from using ncp to using tcp for reliable transport service  occurred almost 20 years ago even back then  rfc 801   when the internet was tiny and still being administered by a small number of " wizards  " it was realized the such a flag day was not possible a flag day involving hundreds of millions of machines and millions of network administrators and users is even more unthinkable today  rfc 1993  describes two approaches  which can be used either alone or together  for gradually integrating ipv6 hosts and routers into an ipv4 world  with the long term goal  of course  of having all ipv4 nodes eventually transition to ipv6   probably the most straightforward way to introduce ipv6-capable nodes is a dual stack approach  where ipv6 nodes also have a complete ipv4 implementation as well such a node  referred to as ipv6/ipv4 node in  rfc 1993   the ability to send and receive both ipv4 and ipv6 packets when interoperating with an ipv4 node  an ipv6/ipv4 node can use ipv4 packets ; when interoperating with an ipv6 node  it can speak ipv6 ipv6/ipv4 nodes must have both ipv6 and ipv4 addresses they must furthermore be able to determine whether another node is ipv6-capable or ipv4-only this problem can be solved using the dns  see chapter 2   which can return an ipv6 address if the node name being resolved is ipv6 capable  or otherwise return an ipv4 address of course  if the node issuing the dns request in only file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  4 of 7  20/11/2004 15  52  25 ipv6 ipv4 capable  the dns returns only an ipv4 address figure 4.7-3  a dual stack approach in the dual stack approach  if either the sender of the receiver is only ipv4-capable  ipv4 packets must be used as a result  it is possible that two ipv6-capable nodes can end  in essence  sending ipv4 packets to each other this is illustrated in figure 4.7-3 suppose node a is ipv6 capable and wants to send an ip packet to node e  which is also ipv6-capable nodes a and b can exchange an ipv6 packet however  node b must create an ipv4 packet to send to c certainly  the data field of the ipv6 packet can be copied into the data field of the ipv4 packet and appropriate address mapping can be done however  in performing the conversion from ipv6 to ipv4  there will be ipv6-specific fields in the ipv6 packet  e.g  the flow identifier field  that have no counterpart in ipv4 the information is these fields will be lost thus  even though e and f can exchange ipv6 packets  the arriving ipv4 packets at e from d do not contain all of the fields that were in te original ipv6 packet sent from a  an alternative to the dual stack approach  also discussed in  rfc 1993   is known as tunneling tunneling can solve the problem noted above  allowing  for example  e to receive the ipv6 packet originated by a the basic idea behind tunneling is the following suppose two ipv6 nodes  e.g  b and e in figure 4.7-3  want to interoperate using ipv6 packets  but are connected to each other by intervening ipv4 routers we refer to the intervening set of ipv4 routers between two ipv6 routers as a tunnel  as illustrated in figure 4.7-4 with tunneling  the ipv6 node on the sending side of the tunnel  e g  b  takes the entire ipv6 packet  and puts it in the data  payload  field of an ipv4 packet this ipv4 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  5 of 7  20/11/2004 15  52  25 ipv6 packet is then addressed to the ipv6 node on the receiving side of the tunnel  e.g  e  and sent to the first node in the tunnel  e.g  c   the intervening ipv4 routers in the tunnel route this ipv4 packet amongst themselves  just as they would any other packet  blissfully unaware that the ipv4 packet itself contains a complete ipv6 packet the ipv6 node on the receiving side of the tunnel eventually receives the ipv4 packet  it is the destination of the ipv4 packet !   determines that the ipv4 packet contains an ipv6 packet  extracts the ipv6 packet and then routes the ipv6 packet exactly as it would if it had received the ipv6 packet from a directly-connected ipv6 neighbor figure 4.7-4  tunneling we end this section by mentioning that there is currently some doubt about whether ipv6 will make significant inroads into the internet in the near future  2000-2002  or even ever at all  garber 1999   indeed  at the time of this writing  a number of north american isps have said they do n't plan to buy ipv6-enabled networking equipment these isps say that there is little customer demand for ipv6 's capabilities when ipv4  with some patches  such as network address translator boxes   is working well enough on the other hand  there appears to be more interest in ipv6 in europe and asia thus the fate of ipv6 remains an open question one important lesson that we can learn from the ipv6 experience is that it is enormously difficult to change network-layer protocols since the early 1990s  numerous new network-layer protocols have file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  6 of 7  20/11/2004 15  52  25 ipv6 been trumpeted as the next major revolution for the internet  but most of these protocols have had minor  if any  penetration to date these protocols include ipv6  multicast protocols  section 4.8   and resource reservation protocols  section 6.9   indeed  introducing new protocols into the network layer is like replacing the foundation of a house  it is difficult to do without tearing the whole house down or at least temporarily relocated the house 's residents on the other hand  the internet has witnessed rapid deployment of new protocols at the application layer the classic example  of course  is http and the web ; other examples include audio and video streaming and chat introducing new application layer protocols is like adding a new layer of paint to a house  it is relatively easy to do  and if you choose an attractive color  others in the neighborhood will copy you in summary  in the future we can expect to see changes in the internet 's network layer  but these changes will likely occur on a time scale that is much slower than the changes that will occur at the application layer references  garber 1999  l garber  'steve deering on ip next generation  " ieee computer  pp 11-13  april 1999  gilligan 1996  r gilligan r callon  " ipv6 transition mechanisms overview  " in in ipng  internet protocol next generation  s bradner  a mankin  ed   adddison wesley  1996  huitema 1997  c huitema  ipv6  the new internet protocol  prentice hall  1997  rfc 801  j postel  " ncp/tcp transition plan  " rfc 801  nov 1981  rfc 1752  s bradner  a mankin  " the recommendations for the ip next generation protocol  " rfc 1752  jan 1995  rfc 2460  s deering and r hinden  " internet protocol  version 6  ipv6  specification  " rfc 2460  december 1998  rfc 1884  r hinden  s deering  " ip version 6  addressing architecture "  rfc 1884  december 1995  rfc 2463  a conta  s deering  " internet control message protocol  icmpv6  for the internet protocol version 6  ipv6   rfc 2463  december 1998  rfc 1993  r gilligan  e nordmark  " transition mechanisms for ipv6 hosts and routers  " rfc 1933  april 1996  solensky 1996  f solensky  " ipv4 address lifetime expectations  " in ipng  internet protocol next generation  s bradner  a mankin  ed   adddison wesley  1996 copyright keith w ross and jim kurose  1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/ipv6.htm  7 of 7  20/11/2004 15  52  25 multicast routing 4.8 multicast routing the transport and network layer protocols we have studied so far provide for the delivery of packets from a single source to a single destination protocols involving just one sender and one receiver are often referred to as unicast protocols a number of emerging network applications require the delivery of packets from one or more senders to a group of receivers these applications include bulk data transfer  e.g  the transfer of a software upgrade from the software developer to users needing the upgrade   streaming continuous media  e.g  the transfer of the audio  video and text of a live lecture to a set of distributed lecture participants   shared data applications  e.g  a whiteboard or teleconferencing application that is shared among many distributed participants   data feeds  e.g  stock quotes   and interactive gaming  e.g  distributed interactive virtual environments or multiplayer games such as quake   for each of these applications  an extremely useful abstraction is the notion of a multicast  the sending of a packet from one sender to multiple receivers with a single " transmit " operation in this section we consider the network layer aspects of multicast we continue our primary focus on the internet here  as multicast is much more mature  although it is still undergoing significant develop and evolution  in the internet than in atm networks we will see that as in the unicast case  routing algorithms again play a central role in the network layer we will also see  however  that unlike the unicast case  internet multicast is not a connectionless service --state information for a multicast connection must be established and maintained in routers that handle multicast packets sent among hosts in a so-called multicast group this  in turn  will require a combination of signaling and routing protocols in order to set up  maintain  and tear down connection state in the routers 4.8.1 introduction  the internet multicast abstraction and multicast groups from a networking standpoint  the multicast abstraction  a single send operation that results in copies of the sent data being delivered to many receivers  can be implemented in many ways one possibility is for the sender to use a separate unicast transport connection to each of the receivers an applicationlevel data unit that is passed to the transport layer is then duplicated at the sender and transmitted over each of the individual connections this approach implements a one-sender-to-many-receivers multicast abstraction using an underlying unicast network layer  talpade 1997   it requires no explicit multicast support from the network layer to implement the multicast abstraction ; multicast is emulated using multiple point-to-point unicast connections this is shown in the left of figure 4.8-1  with network routers shaded in white to indicate that they are not actively involved in supporting the multicast here  the multicast sender uses three separate unicast connections to reach the three receivers file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  1 of 20  20/11/2004 15  52  28 multicast routing figure 4.8-1  two approaches towards implementing the multicast abstraction a second alternative is to provide explicit multicast support at the network layer in this latter approach  a single datagram is transmitted from the sending host this datagram  or a copy of this datagram  is then replicated at a network router whenever it must be forwarded on multiple outgoing links in order to reach the receivers the right side of figure 4.8-1 illustrates this second approach  with certain routers shaded in red to indicate that they are actively involved in supporting the multicast here  a single datagram is transmitted by the sender that datagram is then duplicated by the router within the network ; one copy is forwarded to the uppermost receiver and another copy is forwarded towards the rightmost receivers at the rightmost router  the multicast datagram is broadcast over the ethernet that connects the two receivers to the rightmost router clearly  this second approach towards multicast makes more efficient use of network bandwidth in that only a single copy of a datagram will ever traverse a link other the other hand  considerable network layer support is needed to implement a mutlicast-aware network layer for the remainder of this section we will focus on a multicast-aware network layer  as this approach is implemented in the internet and poses a number of interesting challenges with multicast communication  we are immediately faced with two problems that are much more complicated than in the case of unicast  how to identify the receivers of a multicast datagram and how to address a datagram sent to these receivers in the case of unicast communication  the ip address of the receiver  destination  is carried in each ip unicast datagram and identifies the single recipient but in the case of multicast  we now have multiple receivers does it make sense for each multicast datagram to carry the ip addresses of all of the multiple recipients ? while this approach might be workable with a small number of recipients  it would not scale well to the case of hundreds or thousands of receivers ; the amount of addressing information in the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  2 of 20  20/11/2004 15  52  28 multicast routing datagram would swamp the amount of data actually carried in the datagram 's payload field explicit identification of the receivers by the sender also requires that the sender know the identities and addresses of all of the receivers we will see shortly that there are cases where this requirement might be undesirable for these reasons  in the internet architecture  and the atm architecture as well   a multicast datagram is addressed using address indirection that is  a single " identifier " is used for the group of receivers  and a copy of the datagram that is addressed to the group using this single " identifier " is delivered to all of the multicast receivers associated with that group in the internet  the single " identifier " that represents a group of receivers is a class d multicast address  as we saw earlier in section 4.4 the group of receivers associated with a class d address is referred to as a multicast group the multicast group abstraction is illustrated in figure 4.8-2 here  four hosts  shown in red  are associated with the multicast group address of 226.17.30.197 and will receive all datagrams addressed to that multicast address the difficulty that we must still address is the fact that each host has a unique ip unicast address that is completely independent of the address of the multicast group in which it is participating figure 4.8-2  the multicast group  a datagram addressed to the group is delivered to all members of the multicast group while the multicast group abstraction is simple  it raises a host  pun intended  of questions how does a group get started and how does it terminate ? how is the group address chosen ? how are new hosts added to the group  either as senders or receivers  ? can anyone join a group  and send to  or receive from  that group  or is group membership restricted and if so  by whom ? do group members know the identities of the other group members as part of the network layer protocol ? how do the network routers interoperate with each other to deliver a multicast datagram to all group members ? for the internet  the answers to all of these questions involve the internet group management protocol  rfc 2236   so  let us next consider the igmp protocol and then return to these broader questions file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  3 of 20  20/11/2004 15  52  28 multicast routing 4.8.2 the igmp protocol the internet group management protocol  igmp version 2  rfc 2236   operates between a host and its directly attached router  informally  think of the directly-attached router as the " first-hop " router that a host would see on a path to any other host outside its own local network  or the " last-hop " router on any path to that host   as shown in figure 4.8-3 figure 4.8-3 shows three first-hop multicast routers  each connected to its attached hosts via one outgoing local interface this local interface is attached to a lan in this example  and while each lan has multiple attached hosts  at most a few of these hosts will typically belong to a given multicast group at any given time igmp provides the means for a host to inform its attached router that an application running on the host wants to join a specific multicast group given that the scope of igmp interaction is limited to a host and its attached router  another protocol is clearly required to coordinate the multicast routers  including the attached routers  throughout the internet  so that multicast datagrams are routed to their final destinations this latter functionality is accomplished by the network layer multicast routing algorithms such as pim  dvmrp  mosfp and bgp we will study multicast routing algorithms in sections 4.8.3 and 4.8.4 network layer multicast in the internet thus consists of two complementary components  igmp and multicast routing protocols figure 4.8-3  the two components of network layer multicast  igmp and multicast routing protocols although igmp is referred to as a " group membership protocol  " the term is a bit misleading since igmp operates locally  between a host and an attached router despite its name  igmp is not a protocol that operates among all the hosts that have joined a multicast group  hosts that may be spread around the world indeed  there is no network-layer multicast group membership protocols that operates among all the internet hosts in a group there is no protocol  for example  that allows a host to determine the identities of all of the other hosts  network-wide  that have joined the multicast group  see the homework problems for a further exploration of the consequences of this design choice   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  4 of 20  20/11/2004 15  52  28 multicast routing igmp message types sent by purpose membership query  general router query multicast groups joined by attached hosts membership query  specific router query if specific multicast group joined by attached hosts membership report host report host wants to join or is joined to given multicast group leave group host report leaving given multicast group table 4.8-1  igmp v2 message types figure 4.8-4  igmp member query and membership report igmp version 2  fenner 1997  has only three message types  as shown in table 4.8-1 a general membership_query messageis sent by a router to all hosts on an attached interface  e.g  to all hosts on a local area network  to determine the set of all multicast groups that have been joined by the hosts on that interface a router can also determine if a specific multicast group has been joined by hosts on an attached interface using a specific membership_query the specific query includes the multicast address of the group being queried in the multicast group address field of the igmp membership_query message  as shown in figure 4.8-5 hosts respond to a membership_query message with an igmp membership_report message  as illustrated in figure 4.8-4 membership_report messages can also be generated by a host when an application first joins a multicast group without waiting for a membership_query message from the router  membership_report messages are received by the router  as well as all hosts on the attached interface  e.g  in the case of a lan   each membership_report contains the multicast address of a single group that the responding host has joined note that an attached router does n't really care which hosts have joined a given multicast group or even how many hosts on the same lan have joined the same group  in either case  the router 's work is the same  it must run a multicast routing protocol together with other routers to ensure that it receives the multicast datagrams for the appropriate file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  5 of 20  20/11/2004 15  52  28 multicast routing multicast groups  since a router really only cares about whether one or more of its attached hosts belong to a given multicast group  it would ideally like to hear from only one of the attached hosts that belongs to each group  why waste the effort to receive identical responses from multiple hosts ?   igmp thus provides an explicit mechanism aimed at decreasing the number of membership_report messages generated when multiple attached hosts belong to the same multicast group specifically  each membership_query message sent by a router also includes a " maximum response time " value field  as shown in figure 4.8-5 after receiving a membership_query message and before sending a membership_report message for a given multicast group  a host waits a random amount of time between zero and the maximum response time value if the host observes a membership_report message from some other attached host for that given multicast group  it suppresses  discards  its own pending membership_report message  since the host now knows that the attached router already knows that one or more hosts are joined to that multicast group this form of feedback suppression is thus a performance optimization  it avoids the transmission of unnecessary membership_report messages similar feedback suppression mechanisms have been used in a number of internet protocols  including reliable multicast transport protocols  floyd 1997   the final type of igmp message is the leave_group message interestingly  this message is optional ! but if it is optional  how does a router detect that there are no longer any hosts on an attached interface that are joined to a given multicast group ? the answer to this question lies in the use of the igmp membership_query message the router infers that no hosts are joined to a given multicast group when no host responds to a membership_query message with the given group address this is an example of what is sometimes called soft state in an internet protocol in a soft state protocol  the state  in this case of igmp  the fact that there are hosts joined to a given multicast group  is removed via a timeout event  in this case  via a periodic membership_query message from the router  if it is not explicitly refreshed  in this case  by a membership_report message from an attached host   it has been argued that soft-state protocols result in simpler control than hard-state protocols  which not only require state to be explicitly added and removed  but also require mechanisms to recover from situation where the entity responsible for removing state has terminated prematurely or failed  sharma 1997   an excellent discussion of soft state can be found in  raman 1999   the igmp message format is summarized in figure 4.8-5 like icmp  igmp messages are carried  encapsulated  within an ip datagram  with an ip protocol number of 2 figure 4.8-5  igmp message format file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  6 of 20  20/11/2004 15  52  28 multicast routing having examined the protocol for joining and leaving multicast groups we are now in a better position to reflect on the current internet multicast service model  which is based on the work of steve deering  rfc 1112  deering 1991   in this multicast service model  any host can " join " a multicast group at the network layer a host simply issues a membership_report igmp message to its attached router that router  working in concert with other internet routers  will soon begin delivering multicast datagrams to the host joining a multicast group is thus receiver-driven a sender need not be concerned with explicitly adding receivers to the multicast group  as is the case with multicast in atm  but neither can it control who joins the group and therefore receives datagrams sent to that group indeed  recall that it is not possible at the network layer to even know which hosts  network-wide  have joined a multicast group similarly  there is no control over who sends to the multicast group datagrams sent by different hosts can be arbitrarily interleaved at the various receivers  with different interleaving possible at different receivers   a malicious sender can inject datagrams into the multicast group datagram flow even with benign senders  since there is no network layer coordination of the use of multicast addresses  it is possible that two different multicast groups will choose to use the same multicast address from a multicast application viewpoint  this will result in interleaved extraneous multicast traffic these problems may seem to be insurmountable drawbacks for developing multicast applications all is not lost  however although the network layer does not provide for filtering  ordering  or privacy of multicast datagrams  these mechanisms can all be implemented at the application layer there is also ongoing work aimed at adding some of this functionality into the network layer  cain 1999   in many ways  the current internet multicast service model reflects the same philosophy as the internet unicast service model  an extremely simple network layer with additional functionality being provided in the upper layer protocols in the hosts of the " edges " of the network this philosophy has been unquestionably successful for the unicast case ; whether the minimalist network layer philosophy will be equally successful for the multicast service model still remains an open question an interesting discussion of an alternate multicast service model is  holbrook 1999   4.8.3 multicast routing  the general case in the previous section we have seen how the igmp protocol operates at the " edge " of the network between a router and its attached hosts  allowing a router to determine what multicast group traffic it needs to receive for forwarding to its attached hosts we can now focus our attention on just the multicast routers  how should they route packets amongst themselves in order to insure that each router receives the multicast group traffic that it needs file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  7 of 20  20/11/2004 15  52  28 multicast routing figure 4.8-6  multicast hosts  their attached routers  and other routers figure 4.8-6 illustrates the setting for the multicast routing problem let us consider a single multicast group and assume that any router that has an attached host that has joined this group may either send or receive traffic addressed this group  footnote 1   in figure 4.8-6  hosts joined to the multicast group are represented by shaded red squares ; their immediately attached router is also shaded in red as shown in figure 4.8-6  among the population of multicast routers  only a subset of these routers  those with attached hosts that are joined to the multicast group  actually need to receive the multicast traffic in figure 4.8-6 only routers a  b  e and f need to receive the multicast traffic since none of the attached hosts to router d are joined to the multicast group and since router c has no attached hosts  neither c nor d need to receive the multicast group traffic the goal of multicast routing then is to find a tree of links that connects all of the routers that have attached hosts belonging to the multicast group multicast packets will then be routed along this tree from the sender to all of the hosts belonging to the multicast tree of course  the tree may contain routers that do not have attached hosts belonging to the multicast group  e.g  in figure 4.8-6  it is impossible to connect routers a  b  e  and f in a tree without involving either routers c and/or d   in practice  two approaches have been adopted for determining the multicast routing tree the two approaches differ according to whether a single tree is used to distribute the traffic for all senders in the group  or whether a source-specific routing tree is constructed for each individual sender  l group-shared tree in the group-shared tree approach  only a single routing tree is constructed for the entire multicast group for example  the single multicast tree shown in red in the left of figure 4.8-7  connects routers a  b  c  e  and f  following our conventions from figure 4.8-6  router c is not shaded in red although it participates in the multicast tree  it has no attached hosts that are members of the multicast group   multicast packets will flow only over those links file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  8 of 20  20/11/2004 15  52  28 multicast routing shown in red note that the links are bi-directional  since packets can flow in either direction on a link l source-based trees in a source-based approach  an individual routing tree is constructed for each sender in the multicast group in a multicast group with n hosts  n different routing trees will be constructed for that single multicast group packets will be routed to multicast group members in a source-specific manner in the right of figure 4.8-7  two source-specific multicast trees are shown  one rooted at a and another rooted at b note that not only are there different links than in the group-shared tree case   e.g  the link from bc is used in the source-specific tree routed at b  but not in the group-shared tree in the left of figure 4.8-7   but that some links may also be used only in a single direction figure 4.8-7  a single  shared tree  left   and two source-based trees  right  multicast routing using a group-shared tree let us first consider the case where all packets sent to a multicast group are to be routed along the same singe multicast tree  regardless of the sender in this case  the multicast routing problem appears quite simple  find a tree within the network that connects all routers having an attached host belonging to that multicast group in figure 4.8-7  left   the tree composed of red links is one such tree note that the tree contains routers that have attached hosts belonging to the multicast group  i.e  routers a  b  e and f  as well as routers that have no attached hosts belonging to the multicast group ideally  one might also want the tree to have minimal " cost " if we assign a " cost " to each link  as we did for unicast routing in section 4.2.2  then an optimal multicast routing tree is one having the smallest sum of the tree link costs for the link costs given in figure 4.8-8  the optimum multicast tree  with a cost of 7  is shown in red file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/mcast.htm  9 of 20  20/11/2004 15  52  28 multicast routing figure 4.8-8  a minimum cost multicast tree the problem of finding a minimum cost tree is known as the steiner tree problem  hakimi 1971   solving this problem has been shown to be np-complete  garey 1978   but the approximation algorithm in  kou 1981  has been proven to be within a constant of the optimal solution other studies have shown that  in general  approximation algorithms for the steiner tree problem do quite well in practice  wall 1982  waxman 1988  wei 1993   even though good heuristics exist for the steiner tree problem  it is interesting to note that none of the existing internet multicast routing algorithms have been based on this approach why ? one reason is that information is needed about all links in the network another reason is that in order for a minimum cost tree to be maintained  the algorithm needs to be re-run whenever link costs change finally  we will see that other considerations  such as the ability to leverage the routing tables that have already been computed for unicast routing  play an important role in judging the suitability of a multicast routing algorithm in the end  performance  and optimality  are but one of many concerns an alternate approach towards determining the group-shared multicast tree  one that is used in practice by several internet multicast routing algorithms  is based on the notion of defining a center node  also known as a rendezvous point or a core  in the single shared multicast routing tree in the center-based approach  a center node is first identified for the multicast group routers with attached hosts belonging to the multicast group then unicast so-called " join " messages addressed to the center node a join message is forwarded using unicast routing towards the center until it either arrives at a router that already belongs to the multicast tree or arrives at the center in either case  the path that the join message has followed defines the branch of the routing tree between the edge router that initiated the join message and the center one can think of this new path as being " grafted " onto the existing multicast tree for the group file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  10 of 20  20/11/2004 15  52  28 multicast routing figure 4.8-9  constructing a center-based tree figure 4.8-9 illustrates the construction of a center-based multicast routing tree suppose that router e is selected as the center of the tree node f first joins the multicast group and forwards a join message to e the single link ef becomes the initial multicast tree node b then joins the multicast tree by sending its join message to e suppose that the unicast path route to e from b is via d in this case  the join message results in the path bde being grafted onto the multicast tree finally  node a joins the multicast group by forwarding its join message towards e let us assume that a 's unicast path to e is through b since b has already joined the multicast tree  the arrival of a 's join message at b will result in the ab link being immediately grafted on to the multicast tree a critical question for center-based tree multicast routing is the process used to select the center center selection algorithms are discussed in  wall 1982  thaler97  estrin97    wall 982  shows that centers can be chosen so that the resulting tree is within a constant factor of optimum  the solution to the steiner tree problem   multicast routing using a source-based tree while the multicast routing algorithms we have studied above construct a single  shared routing tree that is used to route packets from all senders  the second broad class of multicast routing algorithms construct a multicast routing tree for each source in the multicast group we have already studied an algorithm  dijkstra 's link-state routing algorithm  in section 4.2.1  that computes the unicast paths that are individually the least cost paths from the source to all destinations the union of these paths might be thought of as forming a least unicast-cost path tree  or a shortest unicast path tree  if all link costs are identical   figure 4.8-10 shows the construction of the least cost path tree rooted at a by comparing the tree in figure 4.8-10 with that of figure 4.8-8  it is evident that file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  11 of 20  20/11/2004 15  52  28 multicast routing the least cost path tree is not the same as the minimum overall cost tree computed as the solution to the steiner tree problem the reason for this difference is that the goals of these two algortihms are different  least unicast-cost path tree minimizes the cost from the source to each of the destinations  that is  there is no other tree that has a shorter distance path from the source to any of the destinations   while the steiner tree minimizes the sum of the link costs in the tree you might also want to convince yourself that the least unicast-cost path tree often differs from one source to another  e.g  the source tree rooted at a is different from the source tree rooted at e in figure 4.8-10   figure 4.8-10  construction of a least cost path routing tree the least cost path multicast routing algorithm is a link-state algorithm it requires that each router know the state of each link in the network in order to be able to compute the least cost path tree from the source to all destinations a simpler multicast routing algorithm  one which requires much less link state information than the least cost path routing algorithm  is the reverse path forwarding  rpf  algorithm the idea behind reverse path forwarding is simple  yet elegant when a router receives a multicast packet with a given source address  it transmits the packet on all of its outgoing links  except the one on which it was received  only if the packet arrived on the link that is on its own shortest path back to the sender otherwise the router simply discards the incoming packet without forwarding it on any of its outgoing links such a packet can be dropped because the router knows it either will receive  or has already received  a copy of this packet on the link that is on its own shortest path back to the sender  you might want to convince yourself that this will  in fact  happen   note that reverse path forwarding does not require that a router know the complete shortest path from itself to the source ; it need only know the next hop on its unicast shortest path to the sender figure 4.8-11 illustrates rpf suppose that the links in red represent the least cost paths from the receivers to the source  a   router a initially multicasts a source-s packet to routers c and b router b will forward the source-s packet it has received from a  since a is on its least cost path to a  to both c and d b will ignore  drop  without forwarding  any source-s packets it receives from any other routers file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  12 of 20  20/11/2004 15  52  28 multicast routing  e.g  from routers c or d   let us now consider router c  which will receive a source-s packet directly from a as well as from b since b is not on c 's own shortest path back to a  c will ignore  drop  any source-s packets it receives from b on the other hand  when c receives an source-s packet directly from a it will forward the packet to routers b  e  and f figure 4.8-11  reverse path forwarding rpf is a nifty idea but considers what happens at router d in figure 4.8-11 it will forward packets to router g  even though router g has no attached hosts that are joined to the multicast group while this is not so bad for this case where d has only a single downstream receiver  g  imagine what would happen if there were thousands of routers downstream from d ! each of these thousands of routers would receive unwanted multicast packets  this scenario is not as far-fetched as it might seem the initial mbone  casner 1992  macedonia 1994   the first global multicast network suffered from precisely from this problem at first !  the solution to the problem of receiving unwanted multicast packets under rpf is known as pruning a multicast router that receives multicast packets and has no attached hosts joined to that group will send a prune message to its upstream router if a router receives prune messages from each of its downstream routers  then it can forward a prune message upstream pruning is illustrated in figure 4 8.12 while pruning is conceptually straightforward  two subtle issues arise first  pruning requires that a router know which routers downstream are dependent on it for receiving their multicast packets this requires additional information beyond that required for rpf alone a second complication is more fundamental  if a router sends a prune message upstream  then what should happen if a router later needs to join that multicast group ? recall that under rpf  multicast packets are " pushed " down the rpf tree to all routers if a prune message removes a branch from that tree  then some mechanism is needed to restore that branch one possibility is to add a graft message that allows a router to " unprune " a branch file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  13 of 20  20/11/2004 15  52  28 multicast routing another option is to allow pruned branches to time-out and be added again to the multicast rpf tree ; a router can then re-prune the added brach if the multicast traffic is still not wanted figure 4.8-12  pruning a rpf tree 4.8.4 multicast routing in the internet having now studied multicast routing algorithms in the abstract  let 's now consider how these algorithms are put into practice in today 's internet by examining the three currently-standardized internet multicast routing protocls  dvmrp  mospf  and pim dvmrp the first multicast routing protocol used in the internet and the most widely supported multicast routing algorithm  ip multicast initiative 1998  is the distance vector multicast routing protocol  dvmrp   rfc1075   dvmrp implements source-based trees with reverse path forwarding  pruning  and grafting dvmrp uses a distance vector algorithm  see section 4.2  that allows each router to compute the outgoing link  next hop  that is on its shortest path back to each possible source this information is then used in the rpf algorithm  as discussed above a public copy of dvmrp software is available at  mrouted 1996   in addition to computing next hop information  dvmrp also computes a list of dependent downstream routers for pruning purposes when a router has received a prune message from all of its dependent downstream routers for a given group  it will propagate a prune message upstream to the router from which it receives its multicast traffic for that group a dvmrp prune message contains a prune lifetime  with a default value of two hours  that indicates how long a pruned branch will remain pruned before being automatically restored dvmrp graft messages are sent by a router to its upstream neighbor to force a previously-pruned branch to be added back on to the multicast tree file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  14 of 20  20/11/2004 15  52  28 multicast routing before examining other multicast routing algorithms  let us consider how multicast routing can be deployed in the internet the crux of the problem is that only a small fraction of the internet routers are multicast capable if one router is multicast capable but all of its immediate neighbors are not  is this lone island of multicast routing lost in a sea of unicast routers ? most decidedly not ! tunneling  a technique we examined earlier in the context of ip version 6  section 4.7   can be used to create a virtual network of multicast capabale routers on top of a physical network that contains a mix of unicast and multicast routers this is the approach taken in the internet mbone figure 4.8-13  multicast tunnels multicast tunnels are illustrated in figure 4.8-13 suppose that multicast router a wants to forward a multicast datagram to multicast router b suppose that a and b are not physical connected to each other and that the intervening routers between a and b are not multicast capable to implement tunneling  router a takes the multicast datagram and " encapsulates " it  rfc 2003  t inside a standard unicast datagram that is  the entire multicast datagram  including source and multicast address fields  is carried as the payload of an ip unicast datagram  a complete multicast ip dagram inside of a unicast ip datagram ! the unicast datagram is then addressed to the unicast address of router b and forwarded towards b by router a the unicast routers between a and b dutifully forward the unicast packet to b  blissfully unaware that the unicast datagram itself contains a multicast datagram when the unicast datagram arrives at b  b then extracts the multicast datagram b may then forward the multicast datagram on to one of its attached hosts  forward the packet to a directly attached neighboring router that is multicast capable  or forward the multicast datagram to another logical multicast neighbor via another tunnel mospf the multicast open shortest path first protocol  mospf   rfc 1584  operates in an autonomous system  as  that uses the ospf protocol  see section 4.4  for unicast routing mospf extends ospf by having routers add their multicast group membership to the link state advertisements that are broadcast by routers as part of the ospf protocol with this extension  all routers have not only complete topology information  but also know which edge routers have attached hosts belonging to various multicast groups with this information  the routers within the as can build source-specific  pre-pruned  file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  15 of 20  20/11/2004 15  52  28 multicast routing shortest path trees for each multicast group cbt  core-based trees the core-based tree  cbt  multicast routing protocol  rfc 2201  rfc2189  builds a bi-directional  group-shared tree with a single " core "  center   a cbt edge router unicasts sends a join_request message towards the tree core the core  or the first router that receives this join_request and itself has already successfully joined the tree  will respond with a join_ack message to the edge router once a multicast routing tree has been built  it is maintained by having a downstream router send keepalive messages  echo_request  messages to its immediate upstream router the immediate upstream router responds with an echo_reply message these messages are exchanged at a time granularity of minutes if a downstream router receives no reply to its echo_request  it will retry sending the echo_request for a small number of times if no echo_reply is received  the router will dissolve the downstream tree by sending a flush_tree message downstream  pim  protocol independent multicast the protocol independent multicast  pim  routing protocol  deering 1996  rfc 2362  estrin 1998b  explicitly envisions two different multicast distribution scenarios in so-called dense mode  multicast group members are densely located  that is  many or most of the routers in the area need to be involved in routing multicast datagrams in sparse mode  the number of routers with attached group members is small with respect to the total number of routers ; group members are widely dispersed the pim designers noted several consequences of the sparse-dense dichotomy in dense mode  since most routers will be involved in multicast  e.g  have attached group members   it is reasonable to assume that each and every router should be involved in multicast thus  an approach like rpf  which floods datagrams to every multicast router  unless a router explicitly prunes itself  is well-suited to this scenario on the other hand  in sparse mode  the routers that need to be involved in multicast forwarding are few and far between in this case  a data-driven multicast technique like rpf  which forces a router to constantly do work  prune  simply to avoid receiving multicast traffic is much less satisfactory in sparse mode  the default assumption should be that a router is not involved in a multicast distribution ; the router should not have to do any work unless it wants to join a multicast group this argues for a center-based approach  where routers send explicit join messages  but are otherwise uninvolved in multicast forwarding one can think of the sparse mode approach as being receiver-driven  i.e  nothing happens until a receiver explicitly joins a group  versus the dense mode approach as being data-driven  i e  that datagrams are multicast everywhere  unless explicitly pruned   pim accommodates this dense versus sparse dichotomy by offering two explicit modes of operation  dense mode and sparse mode pim dense mode is a flood-and-prune reverse path forwarding technique similar in spirit to dvmrp recall that pim is " protocol independent  " i.e  independent of the underlying unicast routing protocol a better description might be that it can interoperate with any underlying unicast routing protocol because pim makes no assumptions about the underlying routing file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  16 of 20  20/11/2004 15  52  28 multicast routing protocol  its referse path forwarding algorithm is slightly simpler  although slightly less efficient than dvmrp pim sparse mode is a center-based approach pim routers send join messages towards a rendezvous point  center  to join the tree as with cbt  intermediate routers set up multicast state and forward the join message towards the rendezvous point unlike cbt  there is no acknowledgment generated in response to a join message join message are periodically sent upstream to refresh/maintain the pim routing tree one novel feature of pim is the ability to switch from a group-shared tree to a sourcespecific tree after joining the rendezvous point a source-specific tree may be preferred due to the decreased traffic concentration that occurs when multiple source-specific trees are used  see homework problems   in pim sparse mode the router that receives a datagram to send from one of its attached hosts will unicast the datagram to the rendezvous point the rendezvous point then multicasts the datagram via the group-shared tree a sender is notified by the rp that it must stop sending to the rp whenever there are no routers joined to the tree  i.e  no one is listening !   pim is implemented in numerous router platforms  ip multicast initiative 1998  and has recently been deployed in uunet as part of their streaming multimedia delivery effort  lapolla 1997   inter-autonomous system multicast routing  bgmp in our discussion above  we have implicitly assumed that all routers are running the same multicast routing protocol as we saw with unicasting  this will typically be the case within a single autonomous system  as   however  different as 's may choose to run different multicast routing protocols one as might choose to run pim within autonomous system  while another may choose to run mospf interoperability rules have been defined for all of the major internet multicast routing protocols  this is a particularly messy issue due to the very different approaches taken to multicast routing by sparse and dense mode protocols  what is still missing  however  is an inter-as multicast routing protocol to route multicast datagrams among different as 's today  dvmrp is the defacto inter-as multicast routing protocol however  as a dense mode protocol  it is not particularly well-suited to the rather sparse set of routers participating in today 's internet mbone the development of an inter-as multicast protocol is an active area of research and development  being carried out by the idmr working group of the ietf  idrm 1998   bgmp  the border gateway multicast protocol is an interdomain multicast protocol being developed in idmr it takes a group-shared tree approach towards routing an interesting problem that arises in the interdomain case is the location of the tree 's center in the intra-as case  all routers are within the same as in the inter-as case  however  a center could conceivably be chosen in an autonomous system that does not even contain any hosts in the multicast group ; such third party dependency would not only " unfairly " burden the autonomous system  which  after all  has no interest in the multicast group   but also may unnecessarily subject the multicast group to performance dependencies on ass outside of file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  17 of 20  20/11/2004 15  52  28 multicast routing those participating in the group bgmp is described in  kumar 1998   having now considered the multicast routing problem and a number of multicast protocols embodying the group-shared tree and source-based tree approaches  let us conclude by enumerating some of the factors involved in evaluating a multicast protocol  l scalability what is the amount of state required in the routers by a multicast routing protocol ? how does the amount of state change as the number of groups  or number of senders in a group  change ? l reliance on underlying unicast routing to what extent does a multicast protocol rely on information maintained by an underlying unicast routing protocol we have seen solutions that range from reliance on one specific underlying unicast routing protocol  mospf   to a solution that is completely independent of the underlying unicast routing  pim  to a solution that implements much of the same distance vector functionality that we saw earlier for the unicast case  dvmrp   l excess  un-needed  traffic received we have seen solutions where a router receives data only if it has an attached host in the multicast group  mospf  pim-sparse mode  to solutions where the default is for a router to receive all traffic for all multicast groups  dvmrp  pim dense mode   l traffic concentration the group-shared tree approach tends to concentrate traffic on a smaller number of links  those in the single tree   whereas source-specific trees tend to distribute multicast traffic more evenly l optimality of forwarding paths we have seen that determining the minimum cost multicast tree  i.e  solving the steiner problem  is difficult and that this approach has not been adopted in practice instead  heuristic approaches  based on either using the tree of shortest paths  or selecting a center router from which to " grow " the routing multicast tree  have been adopted in practice references  ballardie 1997a  a ballardie  ? core based trees  cbt  multicast routing architecture  rfc 2201  sept 1997  ballardie 1997b  a ballardie  ? core based trees  cbt version 2  multicast routing  protocol specification  ? rfc 2189  sept 1997  cain 1999  b cain  s deering  a thyagarajan  ? internet group management protocol  version 3  ? work in progress  august 1999  casner 1992  casner  s  deering  s   " first ietf internet audiocast  " acm sigcomm computer communications review  san diego california  july 1992  pp 92-97 available on-line  deering 1991  s deering  ? multicast routing in a datagram network  ? phd thesis  dept of computer science  stanford university  1991  deering 1996  s deering  d estrin  d faranacci  v jacobson  c liu  l wei  ? the pim file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  18 of 20  20/11/2004 15  52  28 multicast routing architecture for wide area multicasting  ? ieee/acm transactions on networking  vol 4  no 2  april 1996  estrin 1997  d estrin  m handley  a helmy  p huang  d thaler  ? a dynamic bootstrap mechanism for rendezvous-based multicast routing ?  technical report  department of computer science  usc 1997 available via http  //netweb.usc.edu/estrin  estrin 1998a  deborah estrin  david meyer  david thaler  " border gateway multicast protocol  bgmp   protocol specification "  work in progress  08/07/1998  estrin 1998b  deborah estrin  v jacobson  d farinacci  l wei  steve deering  mark handley  david thaler  ching-gung liu  puneet sharma  a helmy  " protocol independent multicast-sparse mode  pim-sm   motivation and architecture "  work in porgies  fenner 1997  r fenner  ? internet group management protocol  version 2 ?  rfc 2236  november 1997  floyd 1997  floyd  s  jacobson  v  liu  c  mccanne  s  and zhang  l  a reliable multicast framework for light-weight sessions and application level framing  ieee/acm transactions on networking  december 1997  volume 5  number 6  pp 784-803  garey 1978  m.r garey  r.l graham  and d.s johnson  ` ` the complexity of computing steiner minimal trees' '  siam journal on applied mathematics  vol 34  pp 477--495  1978  hakimi 1971  s.l hakimi  ` ` steiner 's problem in graphs and its implications' '  networks  vol 1  pp 113--133  1971  holbrook 1999  h holbrook  d cheriton  " ip multicast channels  express support for large scale single-source applications  " proceedings of acm sigcomm '99  boston  ma  august 1999    idmr 1998  ietf interdomain multicast routing working group  homepage  http  //www.ietf.org/ html.charters/idmr-charter.html  ip multicast initiative 1998  ip multicast initiative  " ip multicast buyers guide  " http  //www ipmulticast.com/ipmi_dir/dc_indexes/protocols/0.html  kou 1981  l kou  g markowsky  and l berman  ` ` a fast algorithm for steiner trees' '  acta informatica  vol 15  pp 141--145  1981  kumar 1998  k kumar  p radoslavov  d thaler  c alaettinoglu  d estrin  m handley " the masc/bgmp architecture for inter-domain multicast routing "  acm sigcomm 98  september 1998  vancouver  canada available on-line  lapolla 1997  s lapolla  ? ip multicast makes headway among isps  ? pc week on-line  http  //www zdnet.com/pcweek/news/1006/06isp.html  macedonia 1994  macedonia  m r  brutzman  d p  " mbone provides audio and video across the internet  " ieee computer magazine  vol.27 no 4  april 1994  pp 30-36  mrouted 1996  ? mrouted ? v3.8 of dvmrp routing software for various workstation routing platforms  ftp  //parcftp.xerox.com/pub/net-research/ipmulti  raman 1999  s raman  s mccanne  " a model  analysis  and protocol framework for soft statebased communication  " proceedings of acm sigcomm '99  boston  ma  august 1999    rfc 1075  d waitzman  s deering  c partridge  ? distance vector multicast routing protocol  ? rfc 1075  nov 1988 the version of dvmrp in use today is considerably enhanced over the rfc1075 spec a more up-to-date ? work-in-progress ? defines a version 3 of dvmrp  t pusateri  file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  19 of 20  20/11/2004 15  52  28 multicast routing ? distance vector multicast routing protocol  ? work-in-progress  draft-ietf-idmr-v3-08.txt  rfc 1112  s deering  ? host extension for ip multicasting  ? rfc 1112  august 1989  rfc 2003  c perkins  ? ip encapsulation within ip  ? rfc 2003  oct 1996  rfc 1584  j moy  multicast extensions to ospf  rfc 1584  march 1994  rfc 2189  a ballardie  " core based trees  cbt version 2  multicast routing  protocol specification  rfc 2189  sept  1997  rfc 2201  a ballardie  core based trees  cbt  multicast routing architecture  rfc 2201  sept 1997  rfc 2362  d estrin  d farinacci  a helmy  d thaler  s deering  m handley  v jacobson  c liu  p sharma  l wei  " protocol independent multicast-sparse mode  pim-sm   protocol specification  " rfc 2362  june 1998  semeria 1997  c semeria and t maufer  ? introduction to ip multicast routing  ? www document available at http  //www.3com.com/nsc/501303.html this is a very readable introduction to multicast routing  sharma 1997  puneet sharma  deborah estrin  sally floyd  van jacobson  " scalable timers for soft state protocols  " proc ieee infocom conference  april 1997  kobe  japan    talpade 95  talpade  r  ammar  m h  ` ` single connection emulation  sce   an architecture for providing a reliable multicast transport service,' ' proceedings of the ieee international conference on distributed computing systems  vancouver  bc  canada  june 1995  thaler 1997  d thaler and c ravishankar  ? distributed center-location algorithms  ? ieee journal on selected areas in communications  vol 15  no 3  pp 291-303  april 1997  wall 1980  d wall  ? mechanisms for broadcast and selective broadcast  ? phd dissertation  stanford u  june 1980  waxman 1988  b.m waxman  ` ` routing of multipoint connections' '  ieee journal on selected areas in communications  vol 6  no 9  pp 1617--1622  december 1988  wei 1993  l wei and d estrin  ? a comparison of multicast trees and algorithms  ? tr usc-cd-93 560  dept computer science  university of california  sept 1993 footnotes  footnote 1  for simplicity  we will assume throughout this section that the hosts sending to the multicast group are all members of the group  e.g  have used igmp to join the multicast group   we have seen in section 4.6.1  however  that in the internet multicast model  any host can send to a multicast group  i.e  a host need not have explicitly joined the group in order to send to the group   copyright keith w ross and jim kurose  1998-1999 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...wn % 20approach % 20featuring % 20the % 20internet/mcast.htm  20 of 20  20/11/2004 15  52  28 summary 4.9 summary in this chapter we began our journey into the network core we learned that the network layer requires the coordination of each and every host and router in the network because of this  network layer protocols are among the most challenging in the protocol stack we learned that one of the biggest challenges in the network layer is routing packets through a network of millions of hosts and routers we saw that this scaling problem is solved by partitioning large networks into independent administrative domains  which are called autonomous systems  ass  in the jargon of computer networking each as independently routes its packets through the as  just as each country independently routes its postal mail through the country in the internet  the two most popular protocols for intra-as routing are currently rip and ospf to route packets among ass  an inter-as routing protocol is needed the dominant inter-as protocol today is bgp4 performing routing on two levels  one level for within each of the ass and another level for among the ass  is referred to as hierarchical routing we saw that the scaling problem of routing packets through millions of hosts and routers is largely solved by a hierarchical organization of the network this is a general principle we should keep in mind when designing protocols  particularly for network-layer protocols  scaling problems can often be solved by hierarchical organizations it is interesting to note that this principle has been applied throughout the ages to many of other disciplines besides computer networking  including corporate  government  religious and military organizations in this chapter we also learned about a second scaling issue  for large computer networks  a router may need to process millions of flows of packets between different source-destination pairs at the same time to permit a router to process such a large number of flows  network designers have learned over the years that the router 's tasks should be as simple as possible many measures can be taken to make the router 's job easier  including using a datagram network layer rather than virtual-circuit network layer  using a streamlined and fixed-sized header  as in ipv6   eliminating fragmentation  also done in ipv6  and providing the one and only best-effort service perhaps the most important trick here is to not keep track of individual flows  but instead base routing decisions solely on a hierachical-structured destination addresses in the packets it is interesting to note that the postal service has been using this same trick for many years in this chapter we also looked at the underlying principles of routing algorithms we learned that designers of routing algorithms abstract the computer network to a graph with nodes and links with this abstraction  we can exploit the rich theory of shortest-path routing in graphs  which has been developed over the past 40 years in the operations research and algorithms communities we saw that are two broad approaches  a centralized approach in which each node obtains a complete map of the network and applies independently a shortest-path routing algorithm ; and a decentralized approach  in which file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/5summary.htm  1 of 2  20/11/2004 15  52  29 summary individual nodes only have a partial picture of the entire network  yet the nodes work together to deliver packets along the shortest routes routing algorithms in computer networks had been an active research area for many years  and will undoubtedly remain so at the end of this chapter we examined two advanced subjects  reflecting current trends in computer networking and the internet the first subject is ipv6  which provides a streamlined network layer and resolves the ipv4 address space problem the second subject is multicast routing  which can potentially save tremendous amounts of bandwidth  router and server resources in a computer networking it will be interesting to see how the deployment of ipv6 and multicast routing protocols plays out over the next decade of computer networking having competed our study of the network layer  our journey now takes us one further step down the protocol stack  namely  to the link layer like the network layer  the link layer is also part of the network core but we will see in the next chapter that the link layer has the much more localized task of moving packets between nodes on the same link or lan although this task may appear on the surface trivial compared to that of network layer 's tasks  we will see that the link layer involves a lot of important and fascinating issues that can keep us busy for a long time copyright 1996-2000 keith w ross and james f kurose  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/5summary.htm  2 of 2  20/11/2004 15  52  29 homework problems and discussion questions  chapter 4 homework problems and discussion questions chapter 4 review questions sections 4.1-4.4 1  what are the two main functions of a datagram-based network layer ? what additional functions does a vc-based network layer have ? 2  list and describe the atm network service models 3  compare and contrast link-state and distance-vector routing algorithms 4  discuss how a hierarchical organization of the internet has helped to scale to millions of users 5  it is necessary that every autonomous system use the same intra-autonomous routing algorithm ? why or why not ? section 4.5 6  what is the decimal equivalent of the ip address 223.1.3.27 ? 7  consider a lan to which ten host interfaces and three router interfaces are attached suppose all three lans use class c addresses the ip addresses for the 13 devices will be identical in which of the first 32 bits ? 8  consider a router with three interfaces suppose all three interfaces use class c addresses will the ip addresses of the three interfacess necessarily have the same first 8 bits ? 9  suppose there are three routers between source and destination hosts ignoring fragmentation  an ip segment sent from source host to destination host will travel over how many interfaces ? how many routing tables will be indexed to move the datagram from source to destination ? 10  suppose an application generates chunks 40 bytes of data every 20 msec  and each chunk gets encapsulated in a tcp segment and then an ip datagram what percentage of each datagram will be overhead and what percentage will be application data ? file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  1 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 11  consider sending a 3000 byte datagram into a link that has a mtu of 500 bytes suppose the original datagram is stamped with the identification number 422 how many fragments are generated ? what are their characteristics ? 12  consider figure 4.5-2 starting with the original table in d  suppose that d receives from a the following advertisement  destination network next router number of hops to destination 30 c 10 1  1 10  1    will the table in a change ? if so how ? 13  contrast and compare the advertisements used by rip and ospf 14  rip advertisements typically announce the number of hops to various destinations bgp updates  on the otherhand  announce the __________  fill in the blank  to the various destinations 15  why are different inter-as and intra-as protocols used in the internet ? section 4.6 16  describe three different types of switching fabrics commonly used in packet switches 17  why are buffers needed at the output ports of switches ? why are buffers needed at the input port of switches ? section 4.7 18  compare and contrast the ipv4 and the ipv6 header fields do they have any fields in common ? 19  it has been said that ipv6 tunnels through ipv4 routers  ipv6 treats the ipv4 tunnels as link layer protocols do you agree with this statement ? why or why not ? section 4.8 file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  2 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 20  what is an important difference between implementing the multicast abstract via multiple unicasts  and a single network  router  supported multicast group 21  true or false  when a host joins a multicst group  it must change its ip address to be that of the multicast group it is joining 22  what are the roles played by the igmp protocol and a wide-area multicast routing protocol ? 23  what is the difference between a group-shared tree and a source-based tree in the context of multicast routing ? 24  true or false  in reverse path forwarding  a node will receive multiple copies of the same packet true or false  in reverse path forwarding  a node may forward multiple copies of a packet over the same outgoing link 25  classify each of the following multicast routing algorithms as either a source-baed tree approach or a group-shared tree approach  dvmrp  mospf  cbt  pim sparse mode  pim dense mode problems 1  let us consider some of the pros and cons of a connection-oriented versus connectionless architecture a  suppose that in the network layer  routers were subjected to " stressful " conditions that might cause them to fail fairly often at a high level  what actions would need to be taken on such router failure does this argue for a connection-oriented or a connectionless environment ? b  suppose that in order to provide a guarantee regarding the level of performance  e.g  delay  that would be seen along a source-to-destination path  the network requires a sender to declare its peak traffic rate if the declared peak traffic rate and the existing declared traffic rates that have been declared are such that there is no way to get traffic from the source to the destination that meets the required delay requirements  the source is not allowed access to the network would such a approach be more easily accomplished within a connection-oriented or connectionless paradigm ? 2  in figure 4.2.1  enumerate the paths from a to f that do not contain any loops 3  consider the network shown below  with the indicated link costs use dijkstra 's shortest path algorithm to compute the shortest past from f to all network nodes show how the algorithm works by file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  3 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 computing a table similar to table 4.2.1 4  consider the network shown below and assume that each node initially knows the costs to each of its neighbors consider the distance vector algorithm and show the distance table entries at node e 5  consider a general topology  i.e  not the specific network shown above  and a synchronous version of the distance vector algorithm suppose that at each iteration  a node exchanges its minimum costs with its neighbors and receives their minimum costs assuming that the algorithm begins with each node file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  4 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 knowing only the costs to its immediate neighbors  what is the maximum number of iterations required until the distributed algorithm converges ? justify your answer 6  consider the network fragment shown below x has only two attached neighbors  w and y w has a minimum cost path to destination a of cost 5 and y has a minimum cost path to a of 6 the complete paths from w and y to a  and between w and y  are not shown all link costs in the network have strictly positive integer values a  give x 's distance table  row  entries for destinations x  y and a b  give a link cost change for either c  x,w  or c  x,y  such that x will inform its neighbors of a new minimum cost path to a as a result of executing lines 15 and 24 of the distance vector algorithm c  give a link cost change for either c  x,w  or c  x,y  such that x will not inform its neighbors of a new minimum cost path to a as a result of executing lines 15 and 24 of the distance vector algorithm 7  compute the distance tables for x  y and z shown in rightmost column of figure 4.2-4 after the computation of the new distance tables  which nodes will send which updated values to which neighbors ? 8  consider the three node topology shown in figure 4.2.4 rather than having the link costs shown in figure 4.2-4  the link costs are c  x,y  = 5  c  y,z  = 6  c  z,x  = 2 compute the distance tables after the initialization step and after each iteration of a synchronous version of the distance vector algorithm  as we did in our earlier discussion of figure 4.2-4  9  consider the 8-node network  with nodes labeled a-h  above show the minimal cost spanning tree rooted at a that includes  as end hosts  nodes c  d  e  and g informally argue why your spanning tree is a minimal cost spanning tree 10  we saw in section 4.8 that there is no network layer protocol that can be used to identify the hosts participating in a multicast group given this  how can multicast applications learn the identities of the file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  5 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 hosts that are participating in a multicast group ? 11  consider the two basic approaches identified towards achieving multicast  unicast emulation and network-layer-multicast consider a single sender and 32 receivers suppose the sender is connected to the receiver through a binary tree of routers what is the cost of sending a multicast packet in the case of unicast emulation and network-layer multicast for this topology ? here  each time a packet  or copy of a packet  is sent over a single link  it incurs a unit of " cost "  what topology for interconnecting the sender  receivers  and routers will bring the cost of unicast emulation and true network-layer-multicast as far apart as possible ? you can choose as many routers as you 'd like 12  design  give a pseudocode description of  an application-level protocol that maintains the host addresses of all hosts participating in a multicast group specifically identify the network service  unicast or multicast  that is used by your protocol  and indicate whether your protocol is sending messages in-band or out-of-band  with respect to the application-data flow among the multicast group participants   and why 13  consider the topology from figure 4.8-8 suppose the link cost from b to d changes from 1 to 10 find the steiner tree that connects all of the shaded routers  note  you are not being asked here to program a solution to the steiner tree problem instead  you should be able to construct the minimum costs tree by inspection and informally convince yourself that it is the minimum costs tree   if you were asked  you are not being asked to actually do so !   how would you prove that your tree is indeed a minimum cost tree ? 14  center-based routing consider the topology shown in figure 4.8-8 suppose node c is chosen as the center in a center-based multicast routing algorithm assuming that each attached router in the multicast group uses its least cost path to node c to send join messages to c  draw the resulting centerbased multicast routing tree is the resulting tree a minimum cost steiner tree ? justify your answer 15  least unicast-cost path routing consider figure 4.8-8 suppose that node e is chosen as the source compute the least unicast-cost path multicast routing tree from e to multicast routers a  b  and f 16  reverse path forwarding consider the topology and link costs shown in figure 4.8-8 and suppose that node e is the multicast source using arrows like those shown in figure 4.8-11  indicate links over which packets will be forwarded using rpf  and links over which packets will not be forwarded  given that node e is the source 17  suppose that the cost of a transmitting a multicast packet on a link is completely independent of the cost of transmitting a unicast packet on a link will reverse path forwarding still work in this case ? justify your answer 18  traffic concentration in center-based trees consider the simple topology shown in figure 4.8-8 suppose that each of the multicast routers receive one unit of traffic per unit time from an attached host file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  6 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 this traffic must be forwarded to the other three multicast routers suppose that node c is chosen as the center node in a center-based multicast routing protocol  see homework problem above   given the resulting routing tree  compute the rate of traffic on each link in the topology  compute the total amount of traffic on each link  regardless of the direction of the traffic flow   suppose next that rpf is used to build four source-specific routing trees rooted at each of the routers a  b  e  f recompute the rate of traffic on each of the links in this second scenario in this example  does a center-based tree or sourcespecific trees tend to concentrate traffic ? 19  suppose that a network has g multicast groups  each with s group members  hosts   each of which can be a sender under dvmrp  each router must thus maintain up to s pieces of routing information  the outgoing link on the shortest reverse path to the sender  for each of the s senders  for each group thus  in the worst case  each router must maintain s * g pieces of routing information  when taking all groups into account what is the worst case amount of routing information needed by mospf  pim sparse mode and pim dense mode ? justify your answers 20  birthday problem what is the size of the mutlicast address space suppose now that two different multicast groups randomly choose a multicast address what is the probability that they choose the same address ? suppose now that 1000 multicast groups are ongoing at the same time and chose their multicast group addresses at random what is the probability that they interfere with each other ? 21  recall that in our discussion of multicast tunneling  we said that an ip multicast datagram is carried inside of a ip unicast datagram how does the ip router at the end of the multicast tunnel know that the unicast datagram contains an ip multicast datagram  as opposed to simply being an ip unicast datagram that should be forwarded along  ? discussion questions 1  suppose as x and z are not directly connected but instead connected by as y further suppose that x has a peering agreement with y  and that y has a peering agreement with z finally  suppose that z wants to transit all of y 's traffic but does not want to transit x 's traffic does bgp allow z to implement this policy ? 2  in section 4.7 we indicated that deployment of ipv6 has been slow to date why has it been slow ? what is needed to accelerate its deployment ?  see article by l garber  3  in section 4.8.1 we saw that the multicast abstraction can be implemented by having a sender open an individual connection to each of the receivers what are the drawbacks of this approach compared to the approach that provides native multicast support at the network layer ? what are the advantages of this approach ? 4  in section 4.8 we identified a number of multicast applications which of these applications are wellsuited for the minimalist internet multicast service model ? why ? which applications are not file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  7 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 particularly well-suited for this service model ? 5  given the cbt soft state mechanism for maintaining a tree  why do you think there is a separate flush_tree message ? what would happen if the flush_tree message were lost ? programming assignment in this third programming assignment  you will be writing a ` ` distributed' ' set of procedures that implement a distributed asynchronous distance vector routing for the network shown below  you are to write the following routines that will ` ` execute' ' asynchronously within the emulated environment provided for this assignment for node 0  you will write the routines  l rtinit0   this routine will be called once at the beginning of the emulation rtinit0   has no arguments it should initialize your distance table in node 0 to reflect the direct costs of 1  3  and 7 to nodes 1  2  and 3  respectively in the figure above  all links are bi-directional and the costs in both directions are identical after initializing the distance table  and any other data structures needed by your node 0 routines  it should then send its directly-connected neighbors  in this case  1  2 and 3  the cost of it minimum cost paths to all other network nodes this minimum cost information is sent to neighboring nodes in a routing update packet by calling the routine tolayer2    as described in the full assignment the format of the routing update packet is also file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  8 of 9  20/11/2004 15  52  30 homework problems and discussion questions  chapter 4 described in the full assignment l rtupdate0  struct rtpkt * rcvdpkt   this routine will be called when node 0 receives a routing packet that was sent to it by one if its directly connected neighbors the parameter * rcvdpkt is a pointer to the packet that was received rtupdate0   is the ` ` heart' ' of the distance vector algorithm the values it receives in a routing update packet from some other node i contain i 's current shortest path costs to all other network nodes rtupdate0   uses these received values to update its own distance table  as specified by the distance vector algorithm   if its own minimum cost to another node changes as a result of the update  node 0 informs its directly connected neighbors of this change in minimum cost by sending them a routing packet recall that in the distance vector algorithm  only directly connected nodes will exchange routing packets thus nodes 1 and 2 will communicate with each other  but nodes 1 and 3 will not communicate with each other similar routines are defined for nodes 1  2 and 3 thus  you will write 8 procedures in all  rtinit0    rtinit1    rtinit2    rtinit3    rtupdate0    rtupdate1    rtupdate2    rtupdate3   .these routines will together implement a distributed  asynchronous computation of the distance tables for the topology and costs shown in the figure above you can find the full details of the programming assignment  as well as c code that you will need to create the simulated hardware/software environment at http  //gaia.cs.umass.edu/kurose/network/ programming_assignment.htm file  ///d | /downloads/livros/computa ? ? o/computer % 20n...20approach % 20featuring % 20the % 20internet/rout_hw.htm  9 of 9  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3 lab  implemented a distributed  asynchronous distance vector routing algorithm overview in this lab  you will be writing a ` ` distributed' ' set of procedures that implement a distributed asynchronous distance vector routing for the network shown in figure lab.4-1 figure lab.4-1  network topology and link costs for dv routing lab the basic assignment the routines you will write for the basic part of the assignment  you are to write the following routines which will ` ` execute' ' asynchronously within the emulated environment that we have written for this assignment for node 0  you will write the routines  l rtinit0   this routine will be called once at the beginning of the emulation rtinit0   has no arguments it should initialize the distance table in node 0 to reflect the direct costs of 1  3  and 7 to nodes 1  2  and 3  respectively in figure 1  all links are bi-directional and the costs in both directions are identical after initializing the distance table  and any other data structures needed by your node 0 routines  it should then send its directly-connected neighbors  in this case  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  1 of 6  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3 1  2 and 3  the cost of it minimum cost paths to all other network nodes this minimum cost information is sent to neighboring nodes in a routing packet by calling the routine tolayer2    as described below the format of the routing packet is also described below l rtupdate0  struct rtpkt * rcvdpkt   this routine will be called when node 0 receives a routing packet that was sent to it by one if its directly connected neighbors the parameter * rcvdpkt is a pointer to the packet that was received rtupdate0   is the ` ` heart' ' of the distance vector algorithm the values it receives in a routing packet from some other node i contain i 's current shortest path costs to all other network nodes rtupdate0   uses these received values to update its own distance table  as specified by the distance vector algorithm   if its own minimum cost to another node changes as a result of the update  node 0 informs its directly connected neighbors of this change in minimum cost by sending them a routing packet recall that in the distance vector algorithm  only directly connected nodes will exchange routing packets thus nodes 1 and 2 will communicate with each other  but nodes 1 and 3 will node communicate with each other as we saw in class  the distance table inside each node is the principal data structure used by the distance vector algorithm you will find it convenient to declare the distance table as a 4-by-4 array of int 's  where entry  i,j  in the distance table in node 0 is node 0 's currently computed cost to node i via direct neighbor j if 0 is not directly connected to j  you can ignore this entry we will use the convention that the integer value 999 is ` ` infinity.' ' figure lab.4-2 provides a conceptual view of the relationship of the procedures inside node 0 similar routines are defined for nodes 1  2 and 3 thus  you will write 8 procedures in all  rtinit0    rtinit1    rtinit2    rtinit3   ,rtupdate0    rtupdate1    rtupdate2    rtupdate3   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  2 of 6  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3 figure lab.4-2  relationship between procedures inside node 0 software interfaces the procedures described above are the ones that you will write we have written the following routines that can be called by your routines  tolayer2  struct rtpkt pkt2send  where rtpkt is the following structure  which is already declared for you the procedure tolayer2   is defined in the file prog3.c extern struct rtpkt  int sourceid ; / * id of node sending this pkt  0  1  2  or 3 * / int destid ; / * id of router to which pkt being sent  must be an immediate neighbor  * / int mincost  4  ; / * min cost to node 0  3 * / file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  3 of 6  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3  ; note that tolayer2   is passed a structure  not a pointer to a structure printdt0   will pretty print the distance table for node 0 it is passed a pointer to a structure of type distance_table printdt0   and the structure declaration for the node 0 distance table are declared in the file node0.c similar pretty-print routines are defined for you in the files node1.c  node2.c node3.c the simulated network environment your procedures rtinit0    rtinit1    rtinit2    rtinit3   and rtupdate0    rtupdate1    rtupdate2    rtupdate3   send routing packets  whose format is described above  into the medium the medium will deliver packets in-order  and without loss to the specified destination only directly-connected nodes can communicate the delay between is sender and receiver is variable  and unknown   when you compile your procedures and my procedures together and run the resulting program  you will be asked to specify only one value regarding the simulated network environment  l tracing setting a tracing value of 1 or 2 will print out useful information about what is going on inside the emulation  e.g  what 's happening to packets and timers   a tracing value of 0 will turn this off a tracing value greater than 2 will display all sorts of odd messages that are for my own emulator-debugging purposes a tracing value of 2 may be helpful to you in debugging your code you should keep in mind that real implementors do not have underlying networks that provide such nice information about what is going to happen to their packets ! the basic assignment file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  4 of 6  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3 you are to write the procedures rtinit0    rtinit1    rtinit2    rtinit3   and rtupdate0    rtupdate1    rtupdate2    rtupdate3   which together will implement a distributed  asynchronous computation of the distance tables for the topology and costs shown in figure 1 you should put your procedures for nodes 0 through 3 in files called node0.c   node3.c you are not allowed to declare any global variables that are visible outside of a given c file  e.g  any global variables you define in node0.c may only be accessed inside node0.c   this is to force you to abide by the coding conventions that you would have to adopt is you were really running the procedures in four distinct nodes to compile your routines  cc prog3.c node0.c node1.c node2.c node3 prototype versions of these files are here  node0.c  node1.c  node2.c  node3.c you can pick up a copy of the file prog3.c at http  //gaia.cs.umass.edu/kurose/network/prog3.c this assignment can be completed on any machine supporting c it makes no use of unix features as always  most instructors would expect you to hand in a code listing  a design document  and sample output for your sample output  your procedures should print out a message whenever your rtinit0    rtinit1    rtinit2    rtinit3   or rtupdate0    rtupdate1    rtupdate2    rtupdate3   procedures are called  giving the time  available via my global variable clocktime   for rtupdate0    rtupdate1    rtupdate2    rtupdate3   you should print the identity of the sender of the routing packet that is being passed to your routine  whether or not the distance table is updated  the contents of the distance table  you can use my pretty-print routines   and a description of any messages sent to neighboring nodes as a result of any distance table updates the sample output should be an output listing with a trace value of 2 highlight the final distance table produced in each node your program will run until there are no more routing packets in-transit in the network  at which point our emulator will terminate the advanced assignment you are to write two procedures  rtlinkhandler0  int linkid  int newcost  and rtlinkhandler1  int linkid  int newcost   which will be called if  and when  the cost of the link between 0 and 1 changes these routines should be defined in the files node0.c and node1 c  respectively the routines will be passed the name  id  of the neighboring node on the other side of the link whose cost has changed  and the new cost of the link note that when a link cost changes  these routines will have to update the distance table and may  or may not  have to send updated routing file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  5 of 6  20/11/2004 15  52  30 cmpsci 653/491g  programming assignment 3 packets to neighboring nodes in order to complete the advanced part of the assignment  you will need to change the value of the constant linkchanges  line 3 in prog3.c  to 1 fyi  the cost of the link will change from 1 to 20 at time 10000 and then change back to 1 at time 20000 your routines will be invoked at these times we would again strongly recommend that you first implement the undergraduate assignment and then extend your code to implement the graduate assignment it will not be time wasted  believe me  i learned this the hard way !  q&a when we 've taught this lab in our introductory neworking course  students have posed versious questions if you are interested in looking at the questions we 've received  and answers   check out http  //gaia.cs.umass.edu/kurose/network/programming_assignment_qa.htm file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...eaturing % 20the % 20internet/programming_assignment-1.htm  6 of 6  20/11/2004 15  52  30 introduction to the data link layer 5.1 the data link layer  introduction  services in the previous chapter we learned that the network layer provides a communication service between two hosts as shown in figure 5.1-1  this communication path starts at the source host  passes through a series of routers  and ends at the destination host we 'll find it convenient here to refer to the hosts and the routers simply as nodes  since  as we 'll see shortly  we will not be particularly concerned whether a node is a router or a host   and to the communication channels that connect adjacent nodes along the communication path as links in order to move a datagram from source host to destination host  the datagram must be moved over each of the individual links in the path in this chapter  we focus on the data link layer  which is responsible for transferring a datagram across an individual link we 'll first identify and study the services provided by the link layer in sections 5.2 through 5.4  we 'll then examine important principles behind the protocols that provide these services  including the topics of error detection and correction  socalled multiple access protocols that are used share a single physical link among multiple nodes  and link-level addressing   we 'll see that many different types of link-level technology can be used to connect two nodes in sections 5.5 through 5.10  we 'll examine specific link-level architectures and protocols in more detail figure 5.1-1  thedata link layer 5.1.1 the services provided by the link layer a link-layer protocol is used to move a datagram over an individual link the link-layer protocol defines the format of the packets exchanged between the nodes at the ends of the link  as well as the actions taken by these nodes when sending and receiving packets recall from chapter 1 that the packets exchanged by a link-layer protocol are called frames  and that each link-layer frame typically encapsulates one network-layer datagram as we shall see shortly  the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/overdll.htm  1 of 5  20/11/2004 15  52  31 introduction to the data link layer actions taken by a link-layer protocol when sending and receiving frames include error detection  retransmission  flow control and random access examples of link-layer protocols include ethernet  token ring  fddi  and ppp ; in some contexts  atm and frame relay can be considered link-layer protocols as well we will cover these protocols in detail in the latter half of this chapter whereas the network layer has the end-to-end job of moving transport-layer segments from the source host to the destination host  a link-layer protocol has the node-to-node job of moving a network-layer datagram over a single link in the path an important characteristic of the link layer is that a datagram may be handled by different link-layer protocols on the different links in the path for example  a datagram may be handled by ethernet on the first link  ppp on the last link  and frame relay on all intermediate links it is important to note that the services provided by the different link-layer protocols may be different for example  a link-layer protocol may or may not provide reliable delivery thus  the network layer must be able to accomplish its end-to-end job in the face of a varying set of individual link-layer services in order to gain insight to the link layer and how it relates to the network layer  let 's consider a transportation analogy consider a travel agent who is planning a tr for a tourist traveling from princeton  new jersey to lausanne  switzerland suppose the travel agent decides that it is most convenient for the tourist to take a limousine from princeton to jfk airport  then a plane from jfk airport to geneva airport  and finally a train from geneva to lausanne 's train station  there is a train station at geneva 's airport  once the travel agent makes the three reservations  it is the responsibility of the princeton limousine company to get the tourist from princeton to jfk ; it is the responsibility of the airline company to get the tourist from jfk to geneva ; and it is responsibility of the swiss train service to get the tourist from the geneva to lausanne each of the three segments of the trip is " direct " between two " adjacent " locations note that the three transportation segments are managed by different companies and use entirely different transportation modes  limousine  plane and train   although the transportation modes are different  they each provide the basic service of moving passengers from one location to an adjacent location this service is used by the travel agent to plan the tourist 's trip in this transportation analogy  the tourist is analogous to a datagram  each transportation segment is analogous to a communication link  the transportation mode is analogous to the linklayer protocol  and the travel agent who plans the trip is analogous to a routing protocol the basic service of the link layer is to " move " a datagram from one node to an adjacent node over a single communication link but the details of the link-layer service depend on the specific link-layer protocol that is employed over the link possible services that can be offered by a link-layer protocol include  l framing and link access  almost all link-layer protocols encapsulate each network-layer datagram within a link-layer frame before transmission onto the link a frame consists of a data field  in which the network-layer datagram is inserted  and a number of header fields  a frame may also include trailer fields ; however  we will refer to both header and trailer fields as header fields  a data link protocol specifies the structure of the frame  as well as a channel access protocol that specifies the rules by which a frame is transmitted onto the link for point-to-point links that have a single sender on one end of the link and a single receiver at the other end of the link  the link access protocol is simple  or non-existent   the sender can send a frame whenever the link is idle the more interesting case is when multiple nodes share a single broadcast link  the so-called multiple access problem here  the channel access protocol serves to coordinate the frame transmissions of the many nodes ; we cover multiple access protocols in detail in section 5.3  we 'll see several different frame formats when we examine specific link-layer protocols in the second half of this chapter in section 5.3  we 'll see that frame headers also often include fields for a node 's so-called physical address  which is completely distinct from the node 's network layer  e.g  ip  address l reliable delivery  if a link-layer protocol provides the reliable-delivery service  then it guarantees to move file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/overdll.htm  2 of 5  20/11/2004 15  52  31 introduction to the data link layer each network-layer datagram across the link without error recall that transport-layer protocols  such as tcp  may also provide a reliable-delivery service similar to a transport-layer reliable-delivery service  a link-layer reliable-delivery service is achieved with acknowledgments and retransmissions  see section 3.4   a link-layer reliable-delivery service is often used for links that are prone to high error rates  such as a wireless link  with the goal of correcting an error locally  on the link at which the error occurs  rather than forcing an end-to-end retransmission of the data by transport or application-layer protocol however  link-layer reliable delivery is often considered to be unnecessary overhead for low bit-error links  including fiber  coax and many twistedpair copper links for this reason  many of the most popular link-layer protocols do not provide a reliabledelivery service l flow control  the nodes on each side of a link have a limited amount of packet buffering capacity this is a potential problem  as a receiving node may receive frames at a rate faster than it can process the frames  over some time interval   without flow control  the receiver 's buffer can overflow and frames can get lost similar to the transport layer  a link-layer protocol can provide flow control in order to prevent the sending node on one side of a link from overwhelming the receiving node on the other side of the link l error detection  a node 's receiver can incorrectly decide that a bit in a frame to be a zero when it was transmitted as a one  and vice versa   these errors are introduced by signal attenuation and electromagnetic noise because there is no need to forward a datagram that has an error  many link-layer protocols provide a mechanism for a node to detect the presence of one or more errors this is done by having the transmitting node set error detection bits in the frame  and having the receiving node perform an error check error detection is a very common service among link-layer protocols recall from chapters 3 and 4 that the transport layer and network layers in the internet also provide a limited form of error detection error detection in the link layer is usually more sophisticated and implemented in hardware l error correction  error correction is similar to error detection  except that a receiver can not only detect whether errors have been introduced in the frame but can also determine exactly where in the frame the errors have occurred  and hence correct these errors   some protocols  such as atm  provide link-layer error correction for the packet header rather than for the entire packet we cover error detection and correction in section 5.2 l half-duplex and full-dulpex  with full-duplex transmission  both nodes at the ends of a link may transmit packets at the same time with half-duplex transmission  a node can not both transmit and receive at the same time as noted above  many of the services provided by the link layer have strong parallels with services provided at the transport layer for example  both the link layer and the transport layer can provide reliable delivery although the mechanisms used to provide reliable delivery in the two layers are similar  see section 3.4   the two reliable delivery services are not the same a transport protocol provides reliable delivery between two processes on an end-to-end basis ; a reliable link-layer protocol provides the reliable-delivery service between two nodes connected by a single link similarly  both link-layer and transport-layer protocols can provide flow control and error detection ; again  flow control in a transport-layer protocol is provided on an end-to-end basis  whereas it is provided in a link-layer protocol on a node-to-adjacent-node basis 5.1.2 adapters communicating for a given communication link  the link-layer protocol is for the most part implemented in a pair of adapters an adapter is a board  or a pcmcia card  that typically contains ram  dsp chips  a host bus interface and a link file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/overdll.htm  3 of 5  20/11/2004 15  52  31 introduction to the data link layer interface adapters are also commonly known as network interface cards or nics as shown in figure 5.1-2  the network layer in the transmitting node  i.e  a host or router  passes a network-layer datagram to the adapter that handles the sending side of the communication link the adapter encapsulates the datagram in a frame and then transmits the frame into the communication link at the other side  the receiving adapter receives the entire frame  extracts the network-layer datagram  and passes it to the network layer if the link-layer protocol provides error detection  then it is the sending adapter that sets the error detection bits and it is the receiving adapter that performs the error checking if the link-layer protocol provides reliable delivery  then the mechanisms for reliable delivery  e.g  sequence numbers  timers and acknowledgments  are entirely implemented in the adapters if the link-layer protocol provides random access  see section 5.3   then the random access protocol is entirely implemented in the adapters figure 5.1-2  the link-layer protocol for a communication link is implemented in the adapters at the two ends of the link dg abbreviates " datagram "  a computer in itself  an adapter is a semi-autonomous unit for example  an adapter can receive a frame  determine if a frame is in error and discard the frame without notifying its " parent " node an adapter that receives a frame only interrupts its parent node when it wants to pass a network-layer datagram up the protocol stack similarly  when a node passes a datagram down the protocol stack to an adapter  the node fully delegates to the adapter the task of transmitting the datagram across that link on the other hand  an adapter is not an completely autonomous unit although we have shown the adapter as a separate " box " in figure 5.3.1  the adapter is typically housed in the same physical box as rest of the node  shares power and busses with the rest of the node  and is ultimately under the control of the node figure 5.1-3  the adapter is a semi-autonomous unit as shown in figure 5.1.3  the main components of an adapter are the bus interface and the link interface the bus interface is responsible for communicating with the adapter 's parent node it sends to and receives from the parent node network-layer datagrams and control information the link interface is responsible for implementing the linklayer protocol in addition to framing and de-framing datagrams  it may provide error detection  random access and file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/overdll.htm  4 of 5  20/11/2004 15  52  31 introduction to the data link layer other link-layer functions it also includes the transmit and receive circuitry for popular link-layer technologies  such as ethernet  the link interface is implemented by chip set that can be bought on the commodity market for this reason  ethernet adapters are incredibly cheap  often less than $ 30 for 10 mbps and 100 mbps transmission rates adapter design has become very sophisticated over the years one of the critical issues in adapter performance has always been whether the adapter can move data in and out of a node at the full line speed  that is  at the transmission rate of the link you can learn more about adapter architecture for 10mbps ethernet  100 mbps ethernet and 155 mbps atm by visiting the 3com adapter page  3com   data communications magazine provides a nice introduction to gbps ethernet adapters  gigaadapter   references  3com  3com corporation  network interface cards  http  //www.3com.com/products/nics.html  gigaadapter  data communications  " lan gear  " http  //www.data.com/hot_products/lan_gear/alteon.html return to table of contents copyright 1996-1999 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/overdll.htm  5 of 5  20/11/2004 15  52  31 error detection and correction 5.2 error detection and correction techniques in the previous section  we noted that bit-level error detection and correction  detecting and correcting the corruption of bits in a data-link-layer frame sent from one node to another physically-connected neighboring node  are two services often provided by the data link layer we saw in chapter 3 that error detection and correction services are also often offered at the transport layer as well in this section  we 'll examine a few of the simplest techniques that can be used to detect and  in some cases  correct such bit errors a full treatment of the theory and implementation of this topic is itself the topic of many textbooks  e.g   schwartz 1980    and our treatment here is necessarily brief our goal here is to develop an intuitive feel for the capabilities that error detection and correction techniques provide  and to see how a few simple techniques work and are used in practice in the data link layer figure 5.2-1 illustrates the setting for our study at the sending node  data  d  to be " protected " against bit errors is augmented with error detection and correction bits  edc typically  the data to be protected includes not only the datagram passed down from the network layer for transmission across the link  but also link-level addressing information  sequence numbers  and other fields in the data link frame header both d and edc are sent to the receiving node in a link-level frame at the receiving node  a sequence of bits  d ' and edc ' are received note that d ' and edc ' may differ from the original d and edc as a result of in-transit bit flips figure 5.2-1  error detection and correction scenario file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  1 of 8  20/11/2004 15  52  32 error detection and correction the receiver 's challenge is to determine whether or not d ' is the same as the original d  given that it has only received d ' and edc' the exact wording of the receiver 's decision in figure 5.2-1  we ask whether an error is detected  not whether an error has occurred !  is important error detection and correction techniques allow the receiver to sometimes  but not always  detect that bit errors have occurred that is  even with the use of error detection bits there will still be a possibility that undetected bit errors will occur  i.e  that the receiver will be unaware that the received information contains bit errors as a consequence  the receiver might deliver a corrupted datagram to the network layer  or be unaware that the contents of some other field in the frame 's header have been corrupted we thus want to choose an error detection scheme so that the probability of such occurrences is small generally  more sophisticated error detection and correction techniques  i.e  those that have a smaller probability of allowing undetected bit errors  incur a larger overhead  more computation is need to compute and transmit a larger number of error detection and correction bits let 's now examine three techniques for detecting errors in the transmitted data  parity checks  to illustrate the basic ideas behind error detection and correction   checksumming methods  which are more typically employed in the transport layer  and cyclic redundancy checks  which are typically employed in the data link layer   5.2.1 parity checks perhaps the simplest form of error detection is the use of a single parity bit suppose that the information to be sent  d in figure 5.2-1  has d bits in an even parity scheme  the sender simply includes one additional bit and chooses its value such that the total number of 1 's in the d + 1 bits  the original information plus a parity bit  is even for odd parity schemes  the parity bit value is chosen such that there are an odd number of 1 's figure 5.2-2 illustrates an even parity scheme  with the single parity bit being stored in a separate field figure 5.2-2  one-bit even parity receiver operation is also simple with a single parity bit the receiver need only count the number of 1 's in the received d + 1 bits if an odd number of 1-valued bits are found with an even parity scheme  the receiver knows that at least one bit error has occurred more precisely  it knows that some odd number of bit errors file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  2 of 8  20/11/2004 15  52  32 error detection and correction have occurred but what happens if an even number of bit errors occur ? you should convince yourself that this would result in an undetected error if the probability of bit errors is small and errors can be assumed to occur independently from one bit to the next  the probability of multiple bit errors in a packet would be extremely small in this case  a single parity bit might suffice however  measurements have shown that rather than occurring independently  errors are often clustered together in ` ` bursts.' ' under burst error conditions  the probability of undetected errors in a frame protected by single-bit-partity can approach 50 percent  spragins 1991   clearly  a more robust error detection scheme is needed  and  fortunately  is used in practice !   but before examining error detection schemes that are used in practice  let 's cosider a simple generalization of onebit parity that will provide us with insight into error correction techniques file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  3 of 8  20/11/2004 15  52  32 error detection and correction figure 5.2-3  two-dimensional even parity figure 5.2-3 shows a two-dimensional generalization of the single-bit parity scheme here  the d bits in d are divided into i rows and j columns a parity value is computed for each row and for each column the resulting i + j + 1 parity bits are the data link frame 's error detection bits suppose now that a single bit error occurs in the original d bits of information with this two-dimensional parity scheme  the parity of both the column and the row containing the flipped bit will be in error the receiver can thus not only detect the fact that a single bit error has occurred  but can use the column and row indices of the column and row with parity errors to actually identify the bit that was corrupted and correct that error ! figure 5.2-3 shows an example in which the 0-valued bit in position  1,1  is corrupted and switched to a 1  an error that is both detectable and correctable at the receiver although our discussion has focussed on the original d bits of information  a single error in the parity bits themselves is also detectable and correctable two dimensional parity can also detect  but not correct !  any combination of two errors in a packet other properties of the two-dimensional parity scheme are explored in the problems at the end of the chapter the ability of the receiver to both detect and correct errors is known as forward error correction  fec   these techniques are commonly used in audio storage and playback devices such as audio cd 's in a network setting  fec techniques can be used by themselves  or in conjunction with the arq techniques we examined in chapter 3 fec techniques are valuable because they can decrease the number of sender retransmissions required perhaps more importantly  they allow for immediate correction of errors at the receiver this avoids having to wait the round-trip propagation delay needed for the sender to receive a nak packet and for the retransmitted packet to propagate back to the receiver  a potentially important advantage for real-time network applications  rubenstein 1998   recent work examining the use of fec in error control protocols include  biersack 1992  nonnenmacher 1998  byers 1998  shacham 1990   5.2.2 checksumming methods in checksumming techniques  the d bits of data in figure 5.2-1 are treated as a sequence of k-bit integers one simple checksumming method is to simply sum these k-bit integers and use the resulting sum as the error detection bits the so-called internet checksum  rfc 1071  is based on this approach  bytes of data are treated as 16-bit integers and their ones-complement sum forms the internet checksum a receiver calculates the checksum it calculates over the received data and checks whether it matches the checksum carried in the received packet rfc1071  rfc 1071  discusses the internet checksum algorithm and its implementation in detail in the tcp/ip protocols  the internet checksum is computed over all fields  header and data fields included   in other protocols  e.g  xtp  strayer 1992   one checksum is computed over the header  with another checksum computed over the entire packet mcauley  mcauley 1994  describe improved weighted checksum codes that are suitable for high-speed software implementation and feldmeier  feldmeier 1995  presents fast software implementation techniques file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  4 of 8  20/11/2004 15  52  32 error detection and correction for not only weighted checksum codes  but crc  see below  and other codes as well 5.2.3 cyclic redundancy check an error detection technique used widely in today 's computer networks is based on cyclic redundancy check  crc  codes crc codes are also known as polynomial codes  since it is possible to view the bit string to be sent as a polynomial whose coefficients are the 0 and 1 values in the bit string  with operations on the bit string interpreted as polynomial arithmetic figure 5.2-4  crc codes crc codes operate as follows consider the d-bit piece of data  d  that the sending node wants to send to the receiving node the sender and receiver must first agree on a r + 1 bit pattern  known as a generator  which we will denote as g we will require that the most significant  leftmost  bit of g be a 1 the key idea behind crc codes is shown in figure 5.2-4 for a given piece of data  d  the sender will choose r additional bits  r  and append them to d such that the resulting d + r bit pattern  interpreted as a binary number  is exactly divisible by g using modulo 2 arithmetic the process of error checking with crc 's is thus simple  the receiver divides the d + r received bits by g if the remainder is non-zero  the receiver knows that an error has occurred ; otherwise the data is accepted as being correct all crc calculations are done in modulo 2 arithmetic without carries in addition or borrows in subtraction this means that addition and subtraction are identical  and both are equivalent to the bitwise exclusive-or  xor  of the operands thus  for example  1011 xor 0101 = 1110 1001 xor 1101 = 0100 also  we similarly have file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  5 of 8  20/11/2004 15  52  32 error detection and correction 1011  0101 = 1110 1001  1101 = 0100 multiplication and division are the same as in base 2 arithmetic  except that any required addition or subtraction is done without carries or borrows as in regular binary arithmetic  multiplication by 2k left shifts a bit pattern by k places thus  given d and r  the quantity d * 2r xor r yields the d + r bit pattern shown in figure 5.2-4 we 'll use this algebraic characterization of the d + r bit pattern from figure 5.2-4 in our discussion below let us now turn to the crucial question of how the sender computes r recall that we want to find r such that there is an n such that d * 2r xor r = ng that is  we want to choose r such that g divides into d * 2rxor r without remainder if we exclusive-or  i e  add modulo 2  without carry  r to both sides of the above equation  we get d * 2r = ng xor r this equation tells us that if we divide d * 2r by g  the value of the remainder is precisely r in other words  we can calculate r as r = remainder  d * 2r / g  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  6 of 8  20/11/2004 15  52  32 error detection and correction figure 5.2-5  an example crc calculation figure 5.2-5 illustrates this calculation for the case of d = 101110  d = 6 and g = 1001  r = 3 the nine bits transmitted in this case are 101110 011 you should check these calculations for yourself and also check that indeed d2r = 101011 * g xor r international standards have been defined for 8  12  16 and 32-bit generators  g an 8-bit crc is used to protect the 5-byte header in atm cells the crc-32 32-bit standard  which has been adopted in a number of link-level ieee protocols  uses a generator of gcrc-32 = 100000100110000010001110110110111 each of the crc standards can detect burst errors of less than r + 1 bits and any odd number of bit errors furthermore  under appropriate assumptions  a burst of length greater than r + 1 bits is detected with probability 1  0.5r the theory behind crc codes and even more powerful codes is beyond the scope of this text the text  schwartz 1980  provides an excellent introduction to this topic file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  7 of 8  20/11/2004 15  52  32 error detection and correction references  biersak 1992  e.w biersack  " performance evaluation of forward error correction in atm networks "  proc acm sigcomm conference   baltimore  md 1992   pp 248-257  byers 1998  j byers  m luby  m mitzenmacher  a rege  " a digital fountain approach to reliable distribution of bulk data  " proc acm sigcomm conference   vancouver  1998   pp 56-67  feldmeier 1995  d feldmeier  " fast software implementation of error detection codes  " ieee/acm transactions on networking  vol 3  no 6  dec 1995   pp 640 -652  fletcher 1982  j.g fletcher  " an arithmetic checksum for serial transmissions "  ieee transactions on communications  vol 30  no 1  january 1982   pp 247-253  mcauley 1984  a mcauley  " weighted sum codes for error detection and their comparison with existing codes "  ieee/acm transactions on networking  vol 2  no 1  february 1994   pp 16-22  nonnenmacher 1998  j nonnenmacher  e biersak  d towsley  " parity-based loss recovery for reliable multicast transmission  " ieee/acm transactions on networking  vol 6  no 4  aug 1998   pages 349  361  rfc 1071  b draden  d borman  c partridge  " computing the internet checksum  " rfc 1071  sept 1988  rubenstein 1998  d rubenstein  j kurose  d towsley ` ` real-time reliable multicast using proactive forward error correction' '  proceedings of nossdav '98   cambridge  uk  july 1998    schwartz 1980  m schwartz  information  transmission  modulation  and noise  mcgraw hill  ny  ny 1980  shacham 1990  n shacham  p mckenney  " packet recovery in high-speed networks using coding and buffer management "  proc ieee infocom conference   san francisco  1990   pp 124-131  spragins 1991  j d spragins  telecommunications protocols and design  addison-wesley  reading ma  1991  strayer 1992  w.t strayer  b dempsey  a.weaver  xtp  the xpress transfer protocol  addison wesley  reading ma  1992 copyright 1999-2000 keith w ross and jim kurose all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...p-down % 20approach % 20featuring % 20the % 20internet/ec.htm  8 of 8  20/11/2004 15  52  32 multiple access protocols and lans 5.3 multiple access protocols and lans in the introduction to this chapter  we noted that there are two types of network links  point-to-point links  and broadcast links a point-to-point link consists of a single sender on one end of the link  and a single receiver at the other end of the link many link-layer protocols have been designed for point-to-point links ; ppp  the point-to-point protocol  and hdlc are two such protocols that we 'll cover later in this chapter the second type of link  a broadcast link  can have multiple sending and receiving nodes all connected to the same  single  shared broadcast channel the term " broadcast " is used here because when any one node transmits a frame  the channel broadcasts the frame and each of the other nodes receives a copy ethernet is probably the most widely deployed broadcast link technology ; we 'll cover ethernet in detail in section 5.5 in this section we 'll take step back from specific link layer protocols and first examine a problem of central importance to the data link layer  how to coordinate the access of multiple sending and receiving nodes to a shared broadcast channel  the so-called multiple access problem broadcast channels are often used in local area networks  lans   networks that are geographically concentrated in a single building  or on a corporate or university campus   thus  we 'll also look at how multiple access channels are used in lans at the end of this section figure 5.3-1  various multiple access channels we are all familiar with the notion of broadcasting  as television has been using it since its invention but traditional television is a one-way broadcast  i.e  one fixed node transmitting to many receiving nodes   while nodes on a computer network broadcast channel can both send and receive perhaps a more apt human analogy for a broadcast channel is a cocktail party  where many people gather together in a large room  the air providing the broadcast medium  to talk and listen a second good analogy is something many readers will be familiar with  a classroom  where teacher  s  and student  s  similarly share the same  single  broadcast medium a central problem in both scenarios is that of determining who gets to talk  i.e  transmit into the channel   and when as humans  we 've evolved an elaborate set of protocols for sharing the broadcast channel  " give everyone a chance to speak " " do n't speak until you are spoken to " " do n't monopolize the conversation " " raise your hand if you have question " " do n't interrupt when someone is speaking " " do n't fall asleep when someone else is talking "   computer networks similarly have protocols  so-called multiple access protocols  by which nodes regulate their transmission onto the shared broadcast channel as shown in figure 5.3-1  multiple access protocols are needed in a wide variety of network settings  including both wired and wireless local area networks  and satellite networks figure 5.3-2 takes a more abstract view of the broadcast channel and of the nodes sharing that channel although technically file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  1 of 16  20/11/2004 15  52  35 multiple access protocols and lans each node accesses the broadcast channel through its adapter  in this section we will refer to the node as the sending and receiving device in practice  hundreds or even thousands of nodes can directly communicate over a broadcast channel figure 5.3-2  a broadcast channel interconnecting four nodes because all nodes are capable of transmitting frames  more than two nodes can transmit frames at the same time when this happens  all of the nodes receive multiple frames at the same time  that is  the transmitted frames collide at all of the receivers typically  when there is a collision  none of the receiving nodes can make any sense of any of the frames that were transmitted ; in a sense  the signals of the colliding frame become inextricably tangled together thus  all the frames involved in the collision are lost  and the broadcast channel is wasted during the collision interval clearly  if many nodes want to frequently transmit frames  many transmissions will result in collisions  and much of the bandwidth of the broadcast channel will be wasted in order to ensure that the broadcast channel performs useful work when multiple nodes are active  it is necessary to somehow coordinate the transmissions of the active nodes this coordination job is the responsibility of the multiple access protocol over the past thirty years  thousands of papers and hundreds of ph.d dissertations have been written on multiple access protocols ; a comprehensive survey of this body of work is  rom 1980  furthermore  dozens of different protocols have been implemented in a variety of link-layer technologies nevertheless  we can classify just about any multiple access protocol as belonging to one of three categories  channel partitioning protocols  random access protocols  and taking-turns protocols we 'll cover these categories of multiple access protocols in the following three subsections let us conclude this overview by noting that ideally  a multiple access protocol for a broadcast channel of rate r bits per second should have the following desirable characteristics  1 when only one node has data to send  that node has a throughput of r bps file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  2 of 16  20/11/2004 15  52  35 multiple access protocols and lans 2 when m nodes have data to send  each of these nodes has a throughput of r/m bps this need not necessarily imply that each of the m nodes always have an instantaneous rate of r/m  but rather that each node should have an average transmission rate of r/m over some suitably-defined interval of time 3 the protocol is decentralized  i.e  there are no master nodes that can fail and bring down the entire system 4 the protocol is simple  so that it is inexpensive to implement 5.2.1 channel partitioning protocols recall from our early discussion back in section 1.4  that time division multiplexing  tdm  and frequency division multiplexing  fdm  are two techniques that can be used to partition a broadcast channel 's bandwidth among all nodes sharing that channel as an example  suppose the channel supports n nodes and that the transmission rate of the channel is r bps tdm divides time into time frames  not to be confused the unit of data  the frame  at the data link layer  and further divides each time frame into n time slots each slot time is then assigned to one of the n nodes whenever a node has a frame to send  it transmits the frame 's bits during its assigned time slot in the revolving tdm frame typically  frame sizes are chosen so that a single frame can be transmitting during a slot time figure 5.3-3 shows a simple four-node tdm example returning to our cocktail party analogy  a tdm-regulated cocktail party would allow one partygoer to speak for a fixed period of time  and then allow another partygoer to speak for the same amount of time  and so on once everyone has had their chance to talk  the pattern repeats figure 5.3-3  a four-node tdm and fdm example tdm is appealing as it eliminates collisions and is perfectly fair  each node gets a dedicated transmission rate of r/n bps during each slot time however  it has two major drawbacks first  a node is limited to this rate of r/n bps over a file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  3 of 16  20/11/2004 15  52  35 multiple access protocols and lans slot 's time even when it is the only node with frames to send a second drawback is that a node must always wait for its turn in the transmission sequence  again  even when it is the only node with a frame to send imagine the partygoer who is the only one with anything to say  and imagine that this is the even rarer circumstance where everyone at the party wants to hear what that one person has to say   clearly  tdm would be a poor choice for a multiple access protocol for this particular party while tdm shares the broadcast channel in time  fdm divides the r bps channel into different frequencies  each with a bandwidth of r/n  and assigns each frequency to one of the n nodes fdm thus creates n " smaller " channels of r/n bps out of the single  " larger " r bps channel fdm shares both the advantages and drawbacks of tdm it avoids collisions and divides the bandwidth fairly among the n nodes however  fdm also shares a principal disadvantage with tdm  a node is limited to a bandwidth of r/n  even when it is the only node with frames to send a third channel partitioning protocol is code division multiple access  cdma   while tdm and fdm assign times slots and frequencies  respectively  to the nodes  cdma assigns a different code to each node each node then uses its unique code to encode the data bits it sends  as discussed below we 'll see that cdma allows different nodes to transmit simultaneously and yet have their respective receivers correctly receive a sender 's encoded data bits  assuming the receiver knows the sender 's code  in spite of " interfering " transmissions by other nodes cdma has been used in military systems for some time  due its anti jamming properties  and is now beginning to find widespread civilian use  particularly for use in wireless multiple access channels in a cdma protocol  each bit being sent by the sender is encoded by multiplying the bit by a signal  the code  that changes at a much faster rate  known as the chipping rate  than the original sequence of data bits figure 5.3-4 shows a simple  idealized cdma encoding/decoding scenario suppose that the rate at which original data bits reach the cdma encoder defines the unit of time ; that is  each original data bit to be transmitted requires one bit-slot time let di be the value of the data bit for the ith bit slot each bit slot is further subdivided into m mini-slots ; in figure 5.3-4  m = 8  although in practice m is much larger the cdma code used by the sender consists of a sequence of m values  cm  m = 1,...,m  each taking a + 1 or -1 value in the example in figure 5.3-4  the m-bit cdma code being used by the sender is  1  1  1  -1  1  -1  -1  -1   file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  4 of 16  20/11/2004 15  52  35 multiple access protocols and lans figure 5.3-4  a simple cdma example  sender encoding  receiver decoding to illustrate how cdma works  let us focus on the ith data bit  di for the mth mini-slot of the bit-transmission time of di  the output of the cdma encoder  zi,m  is the value of di multiplied by the mth bit in the assigned cdma code  cm  zi,m = di  cm  equation 5.3-1  in a simple world  with no interfering senders  the receiver would receive the encoded bits  zi,m  and recover the original data bit  di  by computing  di =  1/m  ? m = 1,m zi,m  cm  equation 5.3-2  the reader might want to work through the details of the example in figure 5.3-4 to see that the original data bits are indeed correctly recovered at the receiver using equation 5.3-2 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  5 of 16  20/11/2004 15  52  35 multiple access protocols and lans the world is far from ideal  however  and as noted above  cdma must work in the presence of interfering senders that are encoding and transmitting their data using a different assigned code but how can a cdma receiver recover a sender 's original data bits when those data bits are being tangled with bits being transmitted by other senders ? cdma works under the assumption that the interfering transmitted bit signals are additive  e.g  that if three senders send a 1 value  and a fourth sender sends a -1 value during the same mini-slot  then the received signal at all receivers during hat mini-slot is a 2  since 1 + 1 + 1  1 = 2   in the presence of multiple senders  sender s computes its encoded transmissions  zi,m s  in exactly the same manner as in equation 5.3-1 the value received at a receiver during the mth minislot of the ith bit slot  however  is now the sum of the transmitted bits from all n senders during that minislot  zi,m * = ? s = 1,n zi,m s amazingly  if the senders ' codes are chosen carefully  each receiver can recover the data sent by a given sender out of the aggregate signal simply by using the sender 's code in exactly the same manner as in equation 5.3-2  di =  1/m  ? m = 1,m zim *  cm  equation 5.3-3  figure 5.3-5 illustrates a two-sender cdma example the m-bit cdma code being used by the upper sender is  1  1  1  -1  1  -1  -1  -1   while the cdma code being used by the lower sender is  1  -1  1  1  1  -1  1  1   figure 5.3-5 illustrates a receiver recovering the original data bits from the upper sender note that the receiver is able to extract the data from sender 1 in spite of the interfering transmission from sender 2 returning to our cocktail party analogy  a cdma protocol is similar to having partygoers speaking in multiple languages ; in such circumstances humans are actually quite good at locking into the conversation in the language they understand  while filtering out the remaining conversations file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  6 of 16  20/11/2004 15  52  35 multiple access protocols and lans figure 5.3-5  a two-sender cdma example our discussion here of cdma is necessarily brief and a number of difficult issues must be addressed in practice first  in order for the cdma receivers to be able to extract out a particular sender 's signal  the cdma codes must be carefully chosen secondly  our discussion has assumed that the received signal strengths from various senders at a receiver are the same ; this can be difficult to achieve in practice there is a considerable body of literature addressing these and other issues related to cdma ; see  pickholtz 1982  viterbi95  for details 5.2.2 random access protocols file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  7 of 16  20/11/2004 15  52  35 multiple access protocols and lans the second broad class of multiple access protocols are so-called random access protocols in a random access protocol  a transmitting node always transmits at the full rate of the channel  namely  r bps when there is a collision  each node involved in the collision repeatedly retransmit its frame until the frame gets through without a collision but when a node experiences a collision  it does n't necessarily retransmit the frame right away instead it waits a random delay before retransmitting the frame each node involved in a collision chooses independent random delays because after a collision the random delays are independently chosen  it is possible that one of the nodes will pick a delay that is sufficiently less than the delays of the other colliding nodes  and will therefore be able to " sneak " its frame into the channel without a collision there are dozens if not hundreds of random access protocols described in the literature  rom 1990  bertsekas 1992   in this section we 'll describe a few of the most commonly used random access protocols  the aloha protocols  abramson 1970  abramson 1985  and the carrier sense multiple access  csma  protocols  kleinrock 1975   later  in section 5.5  we 'll cover the details of ethernet  metcalfe 1976   a popular and widely deployed csma protocol slotted aloha let 's begin our study of random access protocols with one of the most simple random access protocols  the so-called slotted aloha protocol in our description of slotted aloha  we assume the following  l all frames consist of exactly l bits l time is divided into slots of size l/r seconds  i.e  a slot equals the time to transmit one frame   l nodes start to transmit frames only at the beginnings of slots l the nodes are synchronized so that each node knows when the slots begin l if two or more frames collide in a slot  then all the nodes detect the collision event before the slot ends let p be a probability  that is  a number between 0 and 1 the operation of slotted aloha in each node is simple   l when the node has a fresh frame to send  it waits until the beginning of the next slot and transmits the entire frame in the slot l if there is n't a collision  the node wo n't consider retransmitting the frame  the node can prepare a new frame for transmission  if it has one  l if there is a collision  the node detects the collision before the end of the slot the node retransmits its frame in each subsequent slot with probability p until the frame is transmitted without a collision by retransmitting with probability p  we mean that the node effectively tosses a biased coin ; the event heads corresponds to retransmit  which occurs with probability p the event tails corresponds to " skip the slot and toss the coin again in the next slot " ; this occurs with probability  1-p   each of the nodes involved in the collision toss their coins independently slotted aloha would appear to have many advantages unlike channel partitioning  slotted aloha allows a single active node  i.e  a node with a frame to send  to continuously transmit frames at the full rate of the channel slotted aloha is also highly decentralized  as each node detects collisions and independently decides when to retransmit  slotted aloha does  however  require the slots to be synchronized in the nodes ; we 'll shortly discuss an unslotted version of the aloha protocol  as well as csma protocols ; noe of which require such synchronization and are therefore fully decentralized  slotted aloha is also an extremely simple protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  8 of 16  20/11/2004 15  52  35 multiple access protocols and lans slotted aloha also works great when there is only one active node  but how efficient is it when there are multiple active nodes ? there are two possible efficiency concerns here first  as shown in figure 5.3-6  when there are multiple active nodes  a certain fraction of the slots will have collisions and will therefore be " wasted " the second concern is that another fraction of the slots will be empty because all active nodes refrain from transmitting as a result of the probabilistic transmission policy the only " unwasted " slots will be those in which exactly one node transmits a slot in which exactly one node transmits is said to be a successful slot the efficiency of a slotted multiple access protocol is defined to be the long-run fraction of successful slots when there are a large number of active nodes  with each node having a large number of frames to send note that if no form of access control were used  and each node were to immediately retransmits after each collision  the efficiency would be zero slotted aloha clearly increases the efficiency beyond zero  but by how much ? figure 5.3-6  nodes 1  2 and 3 collide in the first slot node 2 finally succeeds in the fourth slot  node 1 in the eighth slot  and node 3 in the ninth slot the notation c  e and s represent " collision slot "  " empty slot " and " successful slot "  respectively we now proceed to outline the derivation of the maximum efficiency of slotted aloha to keep this derivation simple  let 's modify the protocol a little and assume that each node attempts to transmit a frame in each slot with probability p  that is  we assume that each node always has a frame to send and that the node transmits with probability p for a fresh frame as well as for a frame that has already suffered a collision  suppose first there are n nodes then the the probability that a given slot is a successful slot is the probability that one of the nodes transmits and that the remaining n-1 nodes do not transmit the probability that a given node transmits is p ; the probability that the remaining nodes do not transmit is  1-p  n-1 therefore the probability a given node has a success is p  1-p  n-1  because there are n nodes  the probability that an arbitrary node has a success is np  1-p  n-1  thus  when there are n active nodes  the efficiency of slotted aloha is np  1-p  n-1  to obtain the maximum efficiency for n active nodes  we have to find the p * that maximizes this expression  see the homework problems for a general outline of this derivation  and to obtain the maximum efficiency for a large number of active nodes  we take the limit of np *  1-p *  n-1 as n approaches infinity  again  see homework problems  after performing these calculations  we 'll find that the maximum efficiency of the protocol is given by 1/e = .37 that is  when a large number of nodes have many frames to transmit  then  at best  only 37 % of the slots do useful work thus the effective transmission rate of the channel is not r bps but only .37 r bps ! a similar analysis also shows that 37 % of the slots go empty and 26 % of slots have collisions imagine the poor network administrator who has purchased a 100 mbps slotted aloha system  expecting to be able to use the network to transmit data among a large number of users at an aggregate rate of  say  80 mbps ! although the channel is capable of transmitting a given frame at the full channel rate of 100mbps  in the long term  the successful throughput of this channel will be less that 37 mbps file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/lan.htm  9 of 16  20/11/2004 15  52  35 multiple access protocols and lans aloha the slotted aloha protocol required that all nodes synchronize their transmissions to start at the beginning of a slot the first aloha protocol  abramson 1970  was actually an unslotted  fully decentralized  protocol in so-called pure aloha  when a frame first arrives  i.e  a network layer datagram is passed down from the network layer at the sending node   the node immediately transmits the frame in its entirely into the broadcast channel if a transmitted frame experiences a collision with one or more other transmissions  the node will then immediately  after completely transmitting its collided frame  retransmit the frame with probability p otherwise  the node waits for a frame transmission time after this wait  it then transmits the frame with probability p  or waits  remaining idle  for another frame time with probability 1-p figure 5.3-7  interfering transmissions in pure aloha to determine the maximum efficiency of pure aloha  we focus on an individual node we 'll make the same assumptions as in our slotted aloha analysis and take the frame transmission time to be the unit of time at any given time  the probability that a node is transmitting a frame is p suppose this frame begins transmission at time t0 as shown in figure 5.3-7  in order for this frame to be successfully transmitted  no other nodes can begin their transmission in the interval of time  t0-1  t0   such a transmission would overlap with the beginning of the transmission of node i 's frame the probability that all other nodes do not begin a transmission in this interval is  1-p  n-1 similarly  no other node can begin a transmission while node i is transmitting  as such a transmission would overlap with the latter part of node i 's transmission the probability that all other nodes do not begin a transmission in this interval is also  1-p  n-1 thus  the probability that a given node has a successful transmission is p  1-p  2  n-1   by taking limits as in the slotted aloha case  we find that the maximum efficiency of the pure aloha protocol is only 1/  2e   exactly half that of slotted aloha this then is the price to be paid for a fully decentralized aloha protocol csma  carrier sense multiple access in both slotted and pure aloha  a node 's decision to transmit is made independently of the activity of the other nodes attached to the broadcast channel in particular  a node neither pays attention to whether another node happens to be transmitting when it begins to transmit  nor stops transmitting if another node begins to interfere with its transmission in our cocktail party analogy  aloha protocols are quite like a boorish partygoer who continues to chatter away file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  10 of 16  20/11/2004 15  52  35 multiple access protocols and lans regardless of whether other people are talking as humans  we have human protocols that allow allows us to not only behave with more civility  but also to decrease the amount of time spent " colliding " with each other in conversation and consequently increasing the amount of amount of data we exchange in our conversations specifically  there are two important rules for polite human conversation  l listen before speaking if someone else is speaking  wait until they are done in the networking world  this is termed carrier sensing  a node listens to the channel before transmitting if a frame from another node is currently being transmitted into the channel  a node then waits  " backs off "  a random amount of time and then again senses the channel if the channel is sensed to be idle  the node then begins frame transmission otherwise  the node waits another random amount of time and repeats this process l if someone else begins talking at the same time  stop talking in the networking world  this is termed collision detection  a transmitting node listens to the channel while it is transmitting if it detects that another node is transmitting an interfering frame  it stops transmitting and uses some protocol to determine when it should next attempt to transmit these two rules are embodied in the family of csma  carrier sense multiple access  and csma/cd  csma with collision detection  protocols  kleinrock 1975  metcalfe 1976  lam 1980  rom 1990   many variations on csma and csma/cd have been proposed  with the differences being primarily in the manner in which nodes perform backoff the reader can consult these references for the details of these protocols we 'll study the csma/cd scheme used in ethernet in detail in section 5.5 here  we 'll consider a few of the most important  and fundamental  characteristics of csma and csma/cd the first question that one might ask about csma is that if all nodes perform carrier sensing  why do collisions occur in the first place ? after all  a node will refrain from transmitting whenever it senses that another node is transmitting the answer to the question can best be illustrated using space-time diagrams  molle 1987   figure 5.3-7 shows a space-time diagram of four nodes  a  b  c  d  attached to an linear broadcast bus the horizontal axis shows the position of each node in space ; the y-axis represents time at time t0  node b senses the channel is idle  as no other nodes are currently transmitting node b thus begins transmitting  with its bits propagating in both directions along the broadcast medium the downward propagation of b 's bits in figure 5.3-7 with increasing time indicates that a non-zero amount of time is needed for b 's bits to actually propagate  albeit at near the speed-of-light  along the broadcast medium at time t1  t1 > t0   node d has a frame to send although node b is currently transmitting at time t1  the bits being transmitted by b have yet to reach d  and thus d senses the channel idle at t1 in accordance with the csma protocol  d thus begins transmitting its frame a short time later  b 's transmission begins to interfere with d 's transmission at d from figure 5.3-7  it is evident that the end-to-end channel propagation delay of a broadcast channel  the time it takes for a signal to propagate from one of the the channel to another  will play a crucial role in determining its performance the longer this propagation delay  the larger the chance that a carrier-sensing node is not yet able to sense a transmission that has already begun at another node in the network file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  11 of 16  20/11/2004 15  52  35 multiple access protocols and lans figure 5.3-7  space-time diagram of two csma nodes with colliding transmissions in figure 5.3-7  nodes do not perform collision detection ; both b and d continue to transmit their frames in their entirety even though a collision has occurred when a node performs collision detection it will cease transmission as soon as it detects a collision figure 5.3-8 shows the same scenario as in figure 5.3-7  except that the two nodes each abort their transmission a short time after detecting a collision clearly  adding collision detection to a multiple access protocol will help protocol performance by not transmitting a useless  damaged  by interference with a frame from another node  frame in its entirety the ethernet protocol we will study in section 5.5 is a csma protocol that uses collision detection file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  12 of 16  20/11/2004 15  52  35 multiple access protocols and lans figure 5.3-8  csma with collision detection 5.2.2 taking-turns protocols recall that two desirable properties of a multiple access protocol are  i  when only one node is active  the active node has a throughput of r bps  and  ii  when m nodes are active  then each active node has a throughput of nearly r/m bps the aloha and csma protocols have this first property but not the second this has motivated researchers to create another class of protocols  the taking-turns protocols as with random-access protocols  there are dozens of taking-turns protocols  and each one of these protocols has many variations we 'll discuss two of the more important protocols here the first one is the polling protocol the polling protocol requires one of the nodes to be designated as a " master node "  or requires the introduction of a new node serving as the master   the master node polls each of the nodes in a round-robin fashion in particular  the master node first sends a message to node 1  saying that it can transmit up to some maximum number of frames after node 1 transmits some frames  from zero up to the maximum number   the master node tells node 2 it can transmit up to the maximum number of frames  the master node can determine when a node has finished sending its frames by observing the lack of a signal on the channel  the procedure continues in this manner  with the master node polling each of the nodes in a cyclic manner the polling protocol eliminates the collisions and the empty slots that plague the random access protocols this allows it to have a much higher efficiency but it also has a few drawbacks the first drawback is that the protocol introduces a polling delay  the amount of time required to notify a node that it can transmit if  for example  only one node is file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  13 of 16  20/11/2004 15  52  35 multiple access protocols and lans active  then the node will transmit at a rate less than r bps  as the master node must poll each of the inactive nodes in turn  each time the active node sends its maximum number of frames the second drawback  which is potentially more serious  is that if the master node fails  the entire channel becomes inoperative the second taking-turn protocol is the token-passing protocol in this protocol there is no master node a small  special-purpose frame known as a token is exchanged among the nodes in some fixed order for example  node 1 might always send the token to node 2  node 2 might always send the token to node 3  node n might always send the token to node 1 when a node receives a token  it holds onto the token only if it has some frames to transmit ; otherwise  it immediately forwards the token to the next node if a node does have frames to transmit when it receives the token  it sends up to a maximum number of frames and then forwards the token to the next node token passing is decentralized and has a high efficiency but it has its problems as well for example  the failure of one node can crash the entire channel or if a node accidentally neglects to release the token  then some recovery procedure must be invoked to get the token back in circulation ? over the years many token-passing products have been developed  and each one had to address these as well as other sticky issues 5.2.3 local area networks multiple access protocols are used in conjunction with many different types of broadcast channels they have been used for satellite and wireless channels  whose nodes transmit over a common frequency spectrum they are currently used in the upstream channel for cable access to the internet  see section 1.5   and they are extensively used in local area networks  lans   recall that a lan is a computer network that is concentrated in a geographical area  such as in a building or on a university campus when a user accesses the internet from a university or corporate campus  the access is almost always by way of a lan for this type of internet access  the user 's host is a node on the lan  and the lan provides access to the internet through a router  as shown in figure 5.3-9 the lan is a single " link " between each user host and the router ; it therefore uses a link-layer protocol  which incorporates a multiple access protocol the transmission rate  r  of most lans is very high even in the early 1980s  10 mbps lans were common ; today  100 mbps lans are common  and 1 gbps lans are available file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  14 of 16  20/11/2004 15  52  35 multiple access protocols and lans figure 5.3-9  user hosts access an internet web server through a lan the broadcast channel between a user host and the router consists of one " link "  in the 1980s and the early 1990s  two classes of lan technologies were popular in the workplace the first class consists of the ethernet lans  also known as 802.3 lans  ieee 1998b  spurgeon 1999    which are random-access based the second class of lan technologies are token-passing technologies  including token ring  also known as ieee 802.5  ieee 1998   and fddi  also known as fiber distributed data interface  jain 1994    because we shall explore the ethernet technologies in some detail in section 5.4  we focus our discussion here on the token-passing lans our discussion on token-passing technologies is intentionally brief  since these technologies have become relatively minor players in the face of relentless ethernet competition nevertheless  in order to provide examples about token-passing technology and to give a little historical perspective  it is useful to say a few words about token rings in a token ring lan  the n nodes of the lan  hosts and routers  are connected in a ring by direct links the topology of the token ring defines the token-passing order when a node obtains the token and sends a frame  the frame propagates around the entire ring  thereby creating a virtual broadcast channel the node that sends the frame has the responsibility of removing the frame from the ring fddi was designed for geographically larger lans  so called mans  that is  metropolitan area networks   for geographically large lans  spread out over several kilometers  it is inefficient to let a frame propagate back to the sending node once the frame has passed the destination node fddi has the destination node remove the frame from the ring  strictly speaking  fddi is not a pure broadcast channel  as every node does not receive every transmitted frame  you can learn more about token ring and fddi by visiting the 3com adapter page  3com   references  abramson 1970  n abramson  " the aloha system  " afips conf proc  vol 37  1970 fall joint computer confernce  afips press  montvale  n.j  1970  pp 281-285 file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  15 of 16  20/11/2004 15  52  35 multiple access protocols and lans  abramson 1985  n abramson  " development of the alohanet  " ieee transactions on information theory  " vol it 31  no 3  march 1985   pp 119-123  bertsekas 1992  d bertsekas and r gallager  data networks  second edition  prentice hall  englewood cliffs  new jersey  1992  3com 1999  http  //www.3com.com/products/nics.html  boggs 1988  d boggs  j mogul  and c kent  " measured capacity of an ethernet  myths and reality ; " proc acm sigcomm 1988  pp 222  234  ieee 1998  ieee  token ring access method  iso/iec 8802-5  1998 and 8802-5  1998/amd 1   1998 see the 802.5 standards page at http  //www.8025.org/802.5/documents/  ieee 1998b  ieee  " carrier sense multiple access with collision detection  csma/cd  access method and physical layer specifications " see the ieee 802.3 publication catalog at http  //standards.ieee.org/catalog/ieee802.3.html  jain 1994  r jain  " fddi handbook  high-speed networking using fiber and other media  " addison-wesley  reading ma  1994    kleinrock 1975  l kleinrock and f a tobagi  " packet switching in radio channels  part i  carrier sense multiple-access modes and their throughput-delay characteristics  " ieee transactions on communications  vol com-23  no 12  pp 1400-1416  dec 1975  lam 1980  s lam  a carrier sense multiple access protocol for local networks  " computer networks  volume 4  pp 21-32  1980  metcalfe 1976  r metcalfe  d boggs  " ethernet  distributed packet switching for local computer networks  " communications of the acm  19  7   1976   pp 395-404  molle 87  m molle  " space time analysis of csma protocol  " ieee journal on selected areas in communications  1987  pickholtz 1982  r pickholtz  d schilling  l milstein  " theory of spread spectrum communication  a tutorial  " ieee transactions on communications  col com-30  no 5  may 1982   pp 855-884  rom 1990  r rom and m sidi  " multiple access protocols  performance and analysis  " springer-verlag  new york  1990  spurgeon 1999  c spurgeon  " charles spurgeon 's ethernet web site  " http  //wwwhost.ots.utexas.edu/ethernet/ ethernet-home.html  viterbi 1995  a viterbi  cdma  principles of spread spectrum communication  addison-wesley   reading ma 1995   return to table of contents copyright 1996-1999 james f kurose and keith w ross  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20n...own % 20approach % 20featuring % 20the % 20internet/lan.htm  16 of 16  20/11/2004 15  52  35 lan addresses and arp 5.4 lan addresses and arp as we learned in the previous section  nodes in lans send frames to each other over a broadcast channel this means that when a node in a lan transmits a frame  every other node connected to the lan receives the frame but usually  a node in the lan does n't want to send a frame to all of the other lan nodes but instead wants to send to some particular lan node to provide this functionality  the nodes on the lan need to be able to address each other when sending frames  i.e  the nodes need lan addresses and the frame needs a field for a destination lan address in this manner  when a node receives a frame it can determine whether the frame was intended for it or for some other node in the lan  l if the destination address of the frame matches a receiving node 's lan address  then the node extracts the network-layer datagram from the data link layer frame and passes the datagram up the protocol stack l if the destination address does not match the address of the receiving node  the node simply discards the frame 5.4.1 lan addresses in truth  it is not a node that has a lan address but instead a node 's adapter that has a lan address this is illustrated in figure 5-4.1 a lan address is also variously called a physical address an ethernet address  or a mac  media access control  address for most lans  including ethernet and token-passing lans   the lan address is six-bytes long  giving 248 possible lan addresses these sixbyte addresses are typically expressed in hexadecimal notation  with each byte of the address expressed by a pair of hexadecimal numbers an adapter 's lan address is permanent  when an adapter is manufactured  a lan address is burned into the adapter 's rom file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  1 of 8  20/11/2004 15  52  36 lan addresses and arp figure 5.4-1  each adapter connected to a lan has a unique lan address one interesting property of lan addresses is that no two adapters have the same address this might seem surprising given that adapters are manufactured in many different countries by many different companies how does a company manufacturing adapters in taiwan make sure that it is using different addresses from a company manufacturing adapters in belgium ? the answer is that ieee manages the physical address space in particular  when a company wants to manufacture adapters  it purchases a chunk of the address space consisting of 224 addresses for a nominal fee ieee allocates the chunk of 224 addresses by fixing the first 24 bits of a physical address and letting the company create unique combinations of the last 24 bits for each adapter an adapter 's lan address has a flat structure  as opposed to a hierarchical structure   and does n't change no matter where the adapter goes a portable computer with an ethernet card always has the same lan address  no matter where the portable goes recall that  in contrast  an ip address has a hierarchical structure  i.e  a network part and a host part   and a node 's ip address needs to be changed when the host moves an adapter 's lan address is analogous to a person 's social security number  which also has a flat addressing structure and which also does n't change no matter where the person goes an ip address is analogous to a person 's postal address  which is hierarchical and which needs to be changed whenever a person moves one natural question at this juncture is  because all nodes also have ip addresses  why do they have to file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  2 of 8  20/11/2004 15  52  36 lan addresses and arp have lan addresses as well ? there are several good answers to this question first  lans are designed for " arbitrary " network-layer protocols  not just for ip if adapters were to get assigned ip addresses rather than " neutral " lan addresses  then the adapters would not be able to easily support other networklayer protocols  e.g  ipx or decnet   second  if adapters were to use ip addresses instead of lan addresses  the ip address would have to stored in adapter ram and configured every time the adapter were moved  or powered up   another option is to not use any addresses in the adapters  and have each adapter pass the data  i.e  the ip datagram  of each frame it receives to its parent node the parent node could then check for a matching ip address one problem with this option is that the parent node will be interrupted by every frame sent on the lan  including by the frames that are destined for other nodes on the lan as we described at the beginning of this section  when an adapter wants to send a frame to some destination adapter on the same lan  the sending adapter inserts the destination lan address into the frame when the destination adapter receives the frame  it extracts the enclosed datagram and passes the datagram up the protocol stack all the other adapters on the lan also receive the frame ; but these other adapters discard the frame without passing the network-layer datagram up the protocol stack thus  these other adapters do not have to interrupt their hosts when they receive datagrams destined to other hosts having said this  sometimes a sending adapter does want all the other adapters on the lan to receive and process the frame it is about to send in this case  the sending adapter inserts a special lan broadcast address into the destination address field of the frame for lans that use the six-byte addresses  such as ethernet and token-passing lans   the broadcast address is a string of 48 consecutive 1s  i.e  ff-ff-ff-ff-ff-ff in hexadecimal notation   5.4.2 address resolution protocol because there are both network-layer addresses  e.g  internet ip addresses  and link-layer addresses  i e  lan addresses   there is a need to translate between them for the internet  this is the job of the address resolution protocol  arp   rfc 826   every internet host and router on a lan has an arp module to motivate arp  consider the network shown in figure 5.4.2 in this figure each node has an ip address and each node 's adapter has a lan address as usual  ip addresses are shown in dotteddecimal notation and lan addresses are shown in hexadecimal notation now suppose that the node with ip address 222.222.222.220 wants to send an ip datagram to node 222.222.222.222 to accomplish this task  the sending node must give its adapter not only the ip datagram but also the lan address for node 222.222.222.222 when passed the ip datagram and the lan address  the sending node 's adapter can construct a data link layer frame and broadcast the frame into the lan but how does the sending node determine the lan address for the node with ip address 222.222.222.222 ? it does this by providing its arp module with the ip address 222.222.222.222 arp then responds with the corresponding lan address  namely  49-bd-d2-c7-56-2a  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  3 of 8  20/11/2004 15  52  36 lan addresses and arp figure 5.4-2  each node on a lan has an ip address  and each node 's adapter has a lan address so we see that arp resolves an ip address to a lan address in many ways it is analogous to dns  studied in section 2.5   which resolves hostnames to ip addresses however  one important difference between the two resolvers is that dns resolves hostnames for hosts anywhere in the internet  whereas arp only resolves ip addresses for nodes on the same lan if a node in california were to try to use arp to resolve the ip address for a node in mississippi  arp would return with an error now that we have explained what arp does  let 's look at how it works the arp module in each node has a table in its ram called an arp table this table contains the mappings of ip addresses to lan addresses figure 5.4-3 shows what an arp table in node 222.222.222.220 might look like for each address mapping the table also contains a time-to-live  ttl  entry  which indicates when the entry will be deleted note that the table does not necessarily contain an entry for every node on the lan ; some nodes may have had entries that expired over time  whereas other nodes may have never been entered into the table we note that a typical expiration time for an entry is 20 minutes from when an entry is placed in an arp table ip address lan address ttl 222.222.222.221 88-b2-2f-54-1a-0f 13  45  00 222.222.222.223 5c-66-ab-90-75-b1 13  52  00 figure 5.4-3  a possible arp table in node 222.222.222.220 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  4 of 8  20/11/2004 15  52  36 lan addresses and arp now suppose that node 222.222.222.220 wants to send a datagram that is ip-addressed to another node on that lan as we indicated above  the sending node needs to obtain the lan address of the destination node  given the ip address of that node this task is easy if the destination node has an entry in the sending node 's arp table but what if the destination node does not currently have an entry in the arp table ? in particular  suppose node 222.222.222.220 wants to send a datagram to node 222.222.222.222 in this case  the sending node uses the arp protocol to resolve the address first  the sending node constructs a special packet called an arp packet an arp packet has several fields  including the sending and receiving ip and lan addresses both arp query and response packets have the same format the purpose of the arp query packet to is to query all the other nodes on the lan to determine the lan address corresponding to the ip address that is being resolved returning to the example  node 222.222.222.220 passes an arp query packet to the adapter along with an indication that the adapter should send the packet to the lan broadcast address  namely  ff-ff-ffff ff-ff the adapter encapsulates the arp packet in a data link frame  uses the broadcast address for the frame 's destination address  and transmits the frame into the lan recalling our social security number / postal address analogy  note that an arp query is equivalent to a person shouting out in a crowded room of cubicles in some company  say  anycorp   " what is the social security number of the person whose postal address is cubicle 13  room 112  anycorp  palo alto ca ? "  the frame containing the arp query is received by all the other adapters on the lan  and  because of the broadcast address  each adapter passes the arp packet within the frame up to its parent node each node that receives the arp packet checks to see if its ip address matches the destination ip address in the arp packet the one node with a match sends back to the querying node a response arp packet with the desired mapping the querying node  222.222.222.220  can then update its arp table and send its ip datagram there are a couple of interesting things to note about the arp protocol first  the query arp message is sent within a broadcast frame whereas the response arp message is sent within a standard frame before reading on you should think about why this is so second  arp is plug-and-play  that is  a node 's arp table gets built automatically  it does n't have to be configured by a systems administrator and if a node is disconnected from the lan  its entry is eventually deleted from the table sending a datagram to a node off the lan it should now be clear how arp operates when a node wants to send a datagram to another node on the same lan but now let 's look at the more complicated situation when a node on a lan wants to send a network-layer datagram to a node off the lan let us discuss this issue in the context of figure 5.4-4  which shows a simple network consisting of two lans interconnected by a router file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  5 of 8  20/11/2004 15  52  36 lan addresses and arp figure 5.4-4  two lans interconnected by a router there are several interesting things to note about figure 5.4-4 first  there are two types of nodes  hosts and routers each host has exactly one ip address and one adapter but  as discussed in section 4.4  a router has an ip address for each of its interfaces each router interface also has its own arp module  in the router  and its own adapter because the router in figure 5.4-4 has two interfaces  it has two ip addresses  two arp modules and two adapters of course  each adapter in the network has its own lan address also note that all of the interfaces connected to lan 1 have addresses of the form 111.111.111.xxx and all of the interfaces connected to lan 2 have the form 222.222.222.xxx  thus  in this example  the first three bytes of the ip address specifies the " network " whereas the last byte specifies the specific interface on a network now suppose that host 111.111.111.111 wants to send an ip datagram to host 222.222.222.222 the sending host passes the datagram to its adapter  as usual but the sending host must also indicate to its adapter an appropriate destination lan address what lan address should the adapter use ? one might venture to guess that the appropriate lan address is the address of the adapter for host 222.222.222.222  namely  49-bd-d2-c7-58-2a this guess is  however  wrong if the sending adapter were to use that lan address  then none of the adapters on lan 1 would bother to pass the ip datagram up to its network layer ; the datagram would just die and go to datagram heaven if we look carefully at figure 5.4-4  we see that in order for a datagram to go from 111.111.111.111 to a node on lan 2  the datagram must first be sent to the router interface 111.111.111.110 thus  the appropriate lan address for the frame is the address of the adapter for router interface 111.111.111.110  namely  e6-e9-00-17-bb-4b how does the sending host acquire the lan address of 111.111.111.110 ? by using arp  of course ! once the sending adapter has this lan address  it creates a frame and sends file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  6 of 8  20/11/2004 15  52  36 lan addresses and arp the frame into lan 1 the router adapter on lan 1 sees that the data link frame is addressed to it  and therefore passes the frame to the network layer of the router hooray  the ip datagram has successfully been moved from source host to the router ! but we are not done we still have to move the datagram from the router to the destination ! the router now has to determine the correct interface on which the datagram is to be forwarded as discussed in section 4.4  this is done by consulting a routing table in the router the routing table tells the router that the datagram is to be forwarded router interface 222.222.222.220 this interface then passes the datagram to its adapter  which encapsulates the datagram in a new frame and sends the frame into lan 2 this time  the destination lan address of the frame is indeed the lan address of the ultimate destination and how does the router obtain this destination lan address ? from arp  of course ! arp for ethernet is defined in  rfc 826   a nice introduction to arp is given in the tcp/ip tutorial   rfc 1180   we shall explore arp in more detail in the homework problems references  rfc 826  d.c plummer  " an ethernet address resolution protocol  " rfc 826  november 1982  rfc 1180  t socolofsky and c kale  " a tcp/ip tutorial  " rfc 1180  january 1991 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  7 of 8  20/11/2004 15  52  36 lan addresses and arp return to table of contents copyright james f kurose and keith w ross  1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/arp.htm  8 of 8  20/11/2004 15  52  36 ethernet 5.5 ethernet ethernet has pretty much taken over the lan market as recently as the 1980s and the early 1990s  ethernet faced many challenges from other lan technologies  including token ring  fddi and atm some of these other technologies succeeded at capturing a part of the market share for a few years but since its invention in the mid-1970  ethernet has continued to evolve and grow  and has held on to its dominant market share today  ethernet is by far the most prevalent lan technology  and is likely to remain so for the foreseeable future one might say that ethernet has been to local area networking what the internet has been to global networking  there are many reasons for ethernet 's success first  ethernet was the first widely-deployed high-speed lan because it was deployed early  network administrators became intimately familiar with ethernet  its wonders and its quirks  and were reluctant to switch over to other lan technologies when they came on the scene second  token ring  fddi and atm are more complex and expensive than ethernet  which further discouraged network administrators from switching over third  the most compelling reason to switch to another lan technology  such as fddi or atm  was usually the higher data rate of the new technology ; however  ethernet always fought back  producing versions that operated at equal data rates or higher switched ethernet was also introduced in the early 1990s  which further increased its effective data rates finally  because ethernet has been so popular  ethernet hardware  in particular  network interface cards  has become a commodity and is remarkably cheap this low cost is also due o the fact that ethernet 's multiple access protocol  csma/cd  is totally decentralized  which has also contributed to the low cost and simple design the original ethernet lan  as shown in figure 5.5-1  was invented in the mid 1970s by bob metcalfe an excellent source of online information about ethernet is spurgeon 's ethernet web site  spurgeon 1999   file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  1 of 12  20/11/2004 15  52  37 ethernet figure 5.5-1  the original metcalfe design led to the 10base5 ethernet standard  which included an interface cable that connected the ethernet adapter  i.e  interface  to an external transceiver drawing taken from charles spurgeon 's ethernet web site 5.5.1 ethernet basics today ethernet comes in many shapes and forms an ethernet lan can have a " bus topology " or a " star topology " an ethernet lan can run over coaxial cable  twisted-pair copper wire  or fiber optics furthermore  ethernet can transmit data at different rates  specifically  at 10 mbps  100 mbps and 1 gbps but even though ethernet comes in many flavors  all of the ethernet technologies share a few important characteristics before examining the different technologies  let 's first take a look at the common characteristics ethernet frame structure given that there are many different ethernet technologies on the market today  what do they have in common  what binds them together with a common name ? first and foremost is the ethernet frame structure all of the ethernet technologies  whether they use coaxial cable or copper wire  whether they run at 10 mbps  100 mbps or 1 gbps  use the same frame structure file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  2 of 12  20/11/2004 15  52  37 ethernet figure 5.5-2  ethernet frame structure the ethernet frame is shown in figure 5.5-2 once we understand the ethernet frame  we will already know a lot about ethernet to put our discussion of the ethernet frame in a tangible context  let us consider sending an ip datagram from one host to another host  with both hosts on the same ethernet lan let the sending adapter  adapter a  have physical address aa-aa-aa-aa-aa-aa and the receiving adapter  adapter b  have physical address bb-bb-bb-bb-bb-bb the sending adapter encapsulates the ip datagram within an ethernet frame and passes the frame to the physical layer the receiving adapter receives the frame from the physical layer  extracts the ip datagram  and passes the ip datagram to the network layer in this context  let us now examine the six fields of the ethernet frame  l data field  46 to 1500 bytes   this field carries the ip datagram the maximum transfer unit  mtu  of ethernet is 1500 bytes this means that if the ip datagram exceeds 1500 bytes  then the host has to fragment the datagram  as discussed in section 4.4 the minimum size of the data field is 46 bytes this means that if the ip datagram is less than 46 bytes  the data field has to be " stuffed " to fill it out to 46 bytes when stuffing is used  the data passed to the network layer contains the stuffing as well as an ip datagram the network layer uses the length field in the ip datagram header to remove the stuffing l destination address  6 bytes   this field contains the lan address of the destination adapter  namely  bb-bb-bb-bb-bb-bb when adapter b receives an ethernet frame with destination address other than its own physical address  bb-bb-bb-bb-bb-bb  or the lan broadcast address  it discards the frame otherwise  it passes the contents of the data field to the network layer l source address  6 bytes   this field contains the lan address of the adapter that transmits the frame onto the lan  namely  aa-aa-aa-aa-aa-aa l type field  two bytes   the type field permits ethernet to " multiplex " network-layer protocols to understand this idea  we need to keep in mind that hosts can use other network-layer protocols besides ip in fact  a given host may support multiple network layer protocols  and use different protocols for different applications for this reason  when the ethernet frame arrives at adapter b  adapter b needs to know to which network-layer protocol it should pass the contents of the data field ip and other data-link layer protocols  e.g  novell ipx or appletalk  each have there own  standardized type number furthermore  the arp protocol  discussed in the previous section  has its own type number note that the type field is analogous to the protocol field in the networklayer datagram and the port number fields in the transport-layer segment ; all of these fields serve to glue a protocol at one layer to a protocol at the layer above file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  3 of 12  20/11/2004 15  52  37 ethernet l cyclic redundancy check  crc   4 bytes   as discussed in section 5.2  the purpose of the crc field is to allow the receiving adapter  adapter b  to detect whether any errors have been introduced into the frame  i.e  if bits in the frame have been toggled causes of bit errors include attenuation in signal strength and ambient electromagnetic energy that leaks into the ethernet cables and interface cards error detection is performed as follows when host a constructs the ethernet frame  it calculates a crc field  which is obtained from a mapping of the other bits in frame  except for the preamble bits   when host b receives the frame  it applies the same mapping to the frame and checks to see if the result of the mapping is equal to what is in the crc field this operation at the receiving host is called the crc check if the crc check fails  that is  if the result of the mapping does not equal the contents of the crc field   then host b knows that there is an error in the frame l preamble   8 bytes  the ethernet frame begins with an eight-byte preamble field each of the first seven bytes of the preamble is 10101010 ; the last byte is 10101011 the first seven bytes of the preamble serve to " wake up " the receiving adapters and to synchronize their clocks to that of the sender 's clock why should the clocks be out of synchronization ? keep in mind that adapter a aims to transmit the frame at 10 mbps  100 mbps or 1 gbps  depending on the type of ethernet lan however  because nothing is absolutely perfect  adapter a will not transmit the frame at exactly the target rate ; there will always be some drift from the target rate  a drift which is not known a priori by the other adapters on the lan a receiving adapter can lock onto adapter a 's clock by simply locking onto the bits in the first seven bytes of the preamble the last two bits of the eighth byte of the preamble  the first two consecutive 1s  alert adapter b that the " important stuff " is about to come when host b sees the two consecutive 1s  it know that the next six bytes is the destination address an adapter can tell when a frame ends by simply detecting absence of current an unreliable connectionless service all of the ethernet technologies provide connectionless service to the network layer that is to say  when adapter a wants to send a datagram to adapter b  adapter a encapsulates the datagram in an ethernet frame and sends the frame into the lan  without first " handshaking " with adapter b this layer-2 connectionless service is analogous to ip 's layer-3 datagram service and udp 's layer-4 connectionless service all the ethernet technologies provide an unreliable service to the network layer in particular when adapter b receives a frame from a  adapter b does not send an acknowledgment when a frame passes the crc check  nor does it send a negative acknowledgment when a frame fails the crc check   adapter a has n't the slightest idea whether a frame arrived correctly or incorrectly when a frame fails the crc check  adapter b simply discards the frame this lack of reliable transport  at the link layer  helps to make ethernet simple and cheap but it also means that the stream of datagrams passed to the network layer can have gaps if there are gaps due to discarded ethernet frames  does the application-layer protocol at host b see gaps as well ? as we learned in chapter 3  this solely depends on whether the application is using udp or file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  4 of 12  20/11/2004 15  52  37 ethernet tcp if the application is using udp  then the application-layer protocol in host b will indeed suffer from gaps in the data on the other hand  if the application is using tcp  then tcp in host b will not acknowledge the discarded data  causing tcp in host a to retransmit note that when tcp retransmits data  ethernet retransmits the data as well but we should keep in mind that ethernet does n't know that it is retransmitting ethernet thinks it is receiving a brand new datagram with brand new data  even though this datagram contains data that has already been transmitted at least once baseband transmission and manchester encoding ethernet uses baseband transmission  that is  the adapter sends a digital signal directly into the broadcast channel the interface card does not shift the signal into another frequency band  as do adsl and cable modem systems ethernet also uses manchester encoding  as shown in figure 5.5-3 with manchester encoding each bit contains a transition ; a 1 has a transition from up to down  whereas a zero has a transition from down to up the reason for manchester encoding is that the clocks in the sending and receiving adapters are not perfectly synchronized by including a transition in the middle of each bit  the receiving host can synchronize its clock to that of the sending host once the receiving adapter 's clock is synchronized  the receiver can delineate each bit and determine whether it is a one or zero manchester encoding is a physical layer operation rather than a link-layer operation ; however  we have briefly described it here as it is used extensively in ethernet figure 5.5-3  manchester encoding 5.5.2 csma/cd  ethernet 's multiple access protocol nodes in an ethernet lan are interconnected by a broadcast channel  so that when an adapter transmits a frame  all the adapters on the lan receive the frame as we discussed in section 5.3  ethernet uses a csma/cd multiple access algorithm summarizing our discussion from section 5.3  recall that csma/ cd employs the following mechanisms  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  5 of 12  20/11/2004 15  52  37 ethernet 1 an adapter may begin to transmit at any time  i.e  no slots are used 2 an adapter never transmits a frame when it senses that some other adapter is transmitting  i.e  it uses carrier-sensing 3 a transmitting adapter aborts its transmission as soon as it detects that another adapter is also transmitting  i.e  it uses collision detection 4 before attempting a retransmission  an adapter waits a random time that is typically small compared to a frame time these mechanisms give csma/cd much better performance than slotted aloha in a lan environment in fact  if the maximum propagation delay between stations is very small  the efficiency of csma/cd can approach 100 %  but note that the second and third mechanisms listed above require each ethernet adapter to be able to  1  sense when some other adapter is transmitting  and  2  detect a collision while it is transmitting ethernet adapters perform these two tasks by measuring voltage levels before and during transmission each adapter runs the csma/cd protocol without explicit coordination with the other adapters on the ethernet within a specific adapter  the csma/cd protocol works as follows  1 the adapter obtains a network-layer pdu from its parent node  prepares an ethernet frame  and puts the frame in an adapter buffer 2 if the adapter senses that the channel is idle  i.e  there is no signal energy from the channel entering the adapter   it starts to transmit the frame if the adapter senses that the channel is busy  it waits until it senses no signal energy  plus a few hundred microseconds  and then starts to transmit the frame 3 while transmitting  the adapter monitors for the presence of signal energy coming from other adapters if the adapter transmits the entire frame without detecting signal energy from other adapters  the adapter is done with the frame 4 if the adapter detects signal energy from other adapters while transmitting  it stops transmitting its frame and instead transmits a 48-bit jam signal 5 after aborting  i.e  transmitting the jam signal   the adapter enters an exponential backoff phase specifically  when transmitting a given frame  after experiencing the nth collision in a row for this frame  the adapter chooses a value for k at random from  0,1,2,...,2m  1  where m  = min  n,10   the adapter then waits k x 512 bit times and then returns to step 2 a few comments about the csma/cd protocol are certainly in order the purpose of the jam signal is to make sure that all other transmitting adapters become aware of the collision let 's look at an example suppose adapter a begins to transmit a frame  and just before a 's signal reaches adapter b  adapter b begins to transmit so b will have transmitted only a few bits when it aborts its transmission these few bits will indeed propagate to a  but they may not constitute enough energy for a to detect the collision to make sure that a detects the collision  so that it to can also abort   b transmits the 48-bit jam signal next consider the exponential backoff algorithm the first thing to notice here is that a bit time  i.e  the file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  6 of 12  20/11/2004 15  52  37 ethernet time to transmit a single bit  is very short ; for a 10 mbps ethernet  a bit time is .1 microseconds now let 's look at an example suppose that an adapter attempts for the first time to transmit a frame  and while transmitting it detects a collision the adapter then chooses k = 0 with probability .5 and chooses k = 1 with probability .5 if the adapter chooses k = 0  then it immediately jumps to step 2 after transmitting the jam signal if the adapter chooses k = 1  it waits 51.2 microseconds before returning to step 2 after a second collision  k is chosen with equal probability from  0,1,2,3   after three collisions  k is chosen with equal probability from  0,1,2,3,4,5,6,7   after ten or more collisions  k is chosen with equal probability from  0,1,2,...,1023   thus the size of the sets from which k is chosen grows exponentially with the number of collisions  until n = 10  ; it is for this reason that ethernet 's backoff algorithm is referred to as " exponential backoff "  the ethernet standard imposes limits on the distance between any two nodes these limits ensure that if adapter a chooses a lower value of k than all the other adapters involved in a collision  then adapter a will be able to transmit its frame without experiencing a new collision we will explore this property in more detail in the homework problems why use exponential backoff ? why not  for example  select k from  0,1,2,3,4,5,6,7  after every collision ? the reason is that when an adapter experiences its first collision  it has no idea how many adapters are involved in the collision if there are only a small number of colliding adapters  it makes sense to choose k from a small set of small values on the other hand  if many adapters are involved in the collision  it makes sense to choose k from a larger  more dispersed set of values  why ?   by increasing the size of the set after each collision  the adapter appropriately adapts to these different scenarios we also note here that each time an adapter prepares a new frame for transmission  it runs the csma/ cd algorithm presented above in particular  the adapter does not take into account any collisions that may have occurred in the recent past so it is possible that an adapter with a new frame will be able to immediately sneak in a successful transmission while several other adapters are in the exponential backoff state ethernet efficiency when only one node has a frame to send  which is typically the case   the node can transmit at the full rate of the ethernet technology  either 10 mbps  100 mbps  or 1 gbps   however  if many nodes have frames to transmit  the effective transmission rate of the channel can be much less we define the efficiency of ethernet to be the long-run fraction of time during which frames are being transmitted on the channel without collisions when there is a large number of active nodes  with each node having a large number of frames to send in order to present a closed-form approximation of the efficiency of ethernet  let tprop denote the maximum time it takes signal energy to propagate between any two adapters let ttrans be the time to transmit a maximum size ethernet frame  approximately 1.2 msecs for a 10 mbps ethernet   a derivation of the efficiency of ethernet is beyond the scope of this book  see  lam 1980  and  bertsekas 1992    here we simply state the following approximation  file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  7 of 12  20/11/2004 15  52  37 ethernet efficiency = 1/  1 + 5 tprop/ttrans   we see from this formula that as tprop approaches 0  the efficiency approaches 1 this is intuitive because if the propagation delay is zero  colliding nodes will abort immediately without wasting the channel also  as ttrans becomes very large  efficiency approaches 1 this is also intuitive because when a frame grabs the channel  it will hold on to the channel for a very long time ; thus the channel will be doing productive work most of the time 5.5.3 ethernet technologies the most common ethernet technologies today are 10base2  which uses thin coaxial cable in a bus topology and has a transmission rate of 10 mbps ; 10baset  which uses twisted-pair cooper wire in a star topology and has a transmission rate of 10 mbps ; 100baset  which typically uses twisted-pair cooper wire in a star topology and has a transmission rate of 100 mbps ; and gigabit ethernet  which uses both fiber and twisted-pair cooper wire and transmits at a rate of 1 gbps these ethernet technologies are standardized by the ieee 802.3 working groups for this reason  ethernet is often referred to as an 802.3 lan before discussing specific ethernet technologies  we need to discuss repeaters  which are commonly used in lans as well as in wide-area transport a repeater is a physical-layer device that acts on individual bits rather than on packets it has two or more interfaces when a bit  representing a zero or a one  arrives from one interface  the repeater simply recreates the bit  boosts its energy strength  and transmits the bit onto all the other interfaces repeaters are commonly used in lans in order to extend their geographical range when used with ethernet  it is important to keep in mind that repeaters do not implement carrier sensing or any other part of csma/cd ; a repeater repeats an incoming bit on all outgoing interfaces even if there is signal energy on some of the interfaces 10base2 ethernet 10base2 is a very popular ethernet technology if you look at how your computer  at work or at school  is connected to the network  it is very possible you will see a 10base2 connection the " 10 " in 10base2 stands for " 10 mbps " ; the " 2 " stands for " 200 meters "  which is the approximate maximum distance between any two nodes without repeaters between them  the actual maximum distance is 185 meters  a 10base2 ethernet is shown in figure 5.5-4 file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  8 of 12  20/11/2004 15  52  37 ethernet figure 5.5-4  a 10base2 ethernet we see from figure 5.4.3 that 10base2 uses a bus topology ; that is  nodes are connected  through their adapters  in a linear fashion the physical medium used to connect the nodes is thin coaxial cable  which is similar to what is used in cable tv  but with a thinner and lighter cable when an adapter transmits a frame  the frame passes through a " tee connector ; " two copies of the frame leave the tee connector  one copy going in one direction and one copy in the other direction as the frames travel towards the terminators  they leave a copy at every node they pass  more precisely  as a bit passes in front of a node  part of the energy of the bit leaks into the adapter  when the frame finally reaches a terminator  it gets absorbed by the terminator note when an adapter transmits a frame  the frame is received by every other adapter on the ethernet thus  10base2 is indeed a broadcast technology suppose you want to connect a dozen pcs in your office using 10base2 ethernet to do this  you would need to purchase 12 ethernet cards with thin ethernet ports ; 12 bnc trees  which are small metalic objects that attach to the adapters  less than one dollar each  ; a dozen or so thin coax segments  5-20 meters each ; and two " terminators  " which you put at the two ends of the bus the cost of the whole network  including adapters  is likely to be less than the cost of a single pc ! because 10base2 is incredibly inexpensive  it is often referred to as " cheapnet "  without a repeater  the maximum length of a 10base2 bus is 185 meters if the bus becomes any longer  then signal attenuation can cause the system to malfunction also  without a repeater  the maximum number of nodes is 30  as each node contributes to signal attenuation repeaters can be used to connect 10base2 segments in a linear fashion  with each segment having up to 30 nodes and having a length up to 185 meters up to four repeaters can be included in a 10base2 ethernet  which creates up to five " segments "  thus a 10base2 ethernet bus can have a total length of 985 meters and support up to 150 nodes note that the csma/cd access protocol is completely oblivious to the repeaters ; if any two of 150 nodes transmit at the same time  there will be a collision the online reader can learn more 10base2 by visiting spurgeon 's 10base2 page 10baset and 100baset file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  9 of 12  20/11/2004 15  52  37 ethernet we discuss 10baset and100baset ethernet together  as they are similar technologies the most important difference between them is that 10baset transmits at 10 mbps and 100baset ethernet transmits at 100 mbps 100baset is also commonly called " fast ethernet " and " 100 mbps ethernet "  10baset and 100baset are also very popular ethernet technologies ; in fact  for new installations  10baset and ethernet are often today the technology of choice both 10baset and 100baset ethernet use a star topology  as shown in figure 5.5-5 figure 5.5-5  star topology for 10baset and 100baset in the star topology there is a central device called a hub  also sometimes called a concentrator  each adapter on each node has a direct  point-to-point connection to the hub this connection consists of two pairs of twisted-pair cooper wire  one for transmitting and the other for receiving at each end of the connection there is a connector that resembles the rj-45 connector used for ordinary telephones the " t " in 10baset and 100baset stands for " twisted pair "  for both 10baset and 100baset  the maximum length of the connection between an adapter and the hub is 100 meters ; the maximum length between any two nodes is 200 meters as we will discuss in the next section  this maximum distance can be increased by using tiers of hubs  bridges  switches and fiber links a 10baset in essence  a hub is a repeater  when it receives a bit from an adapter  it sends the bit to all the other file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  10 of 12  20/11/2004 15  52  37 ethernet adapters in this manner  each adapter can  1  sense the channel to determine if it is idle  and  2  detect a collision while it is transmitting but hubs are popular because they also provide network management features for example  if an adapter malfunctions and continually sends ethernet frames  a so-called " jabbering adapter "   then in a 10base2 ethernet will become totally dysfunctional ; none of the nodes will be able to communicate but a 10baset network will continue to function  because the hub will detect the problem and internally disconnect the malfunctioning adapter with this feature  the network administrator does n't have to get out of bed and drive back to work in order to correct the problem for hackers who work late at night also  most hubs can gather information and report the information to a host that connects directly to the hub this monitoring host provides a graphical interface that displays statistics and graphs  such as bandwidth usage  collision rates  average frame sizes  etc network administrators can use this information to not only debug and correct problems  but also to plan how the lan should evolve in the future many ethernet adapters today are 10/100 mbps adapters this means that they can be used for both 10baset and 100baset ethernets 100baset  which typically uses category-5 twisted pair  a highquality twisted pair with a lot of twists   unlike the 10base2 and 10baset  100baset does not use manchester encoding  but instead a more efficient encoding called 4b5b  every group of five clock periods is used to send 4 bits in order to provide enough transitions to allow clock synchronization the online reader can learn more about 10baset and 100baset by visiting spurgeon 's 10baset page and spurgeon 's 100basetx page the reader is also encouraged to read the following articles from data communications on 100mbps ethernet  l fast track  100 mbps ethernet made easy l lab test  100base-t enterprise switching without the wait l lab test  100base-t vs 100vg-anylan  the real fast ethernet we briefly mention at this point that both 10 mbps and 100 mbps ethernet technologies can employ fiber links a fiber link is often used to interconnect to hubs that are in different buildings on the same campus fiber is expensive because of cost of the cost of its connectors  but it has excellent noise immunity the ieee 802 standards permit a lan to have a larger geographically reach when fiber is used to connect backbone nodes gigabit ethernet gigabit ethernet is an extension to the highly successful 10 mbps and 100 mbps ethernet standards offering a raw data rate of 1000 mbps  gigabit ethernet maintains full compatibility with the huge installed base of ethernet equipment the standard for gigabit ethernet  referred to as ieee 802.3z  does the following  l uses the standard ethernet frame format  figure 5.4.1   and is backward compatible with file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  11 of 12  20/11/2004 15  52  37 ethernet 10baset and 100baset technologies this allows for easy integration of gigabit ethernet with the existing installed base of ethernet equipment l allows for point-to-point links as well as shared broadcast channels point-to-point links use switches  see section 5.6  where as broadcast channels use hubs  as described above for 10baset and 100 baset un gigabit ethernet jargon  hubs are called " buffered distributors "  l uses csma/cd for shared broadcast channels in order to have acceptable efficiency  the maximum distance between nodes must be severely restricted l allows for full-duplex operation at 1000 mbps in both directions for point-to-point channels like 10baset and 100baset  gigabit ethernet has a star topology with a hub or switch at its center  ethernet switches will be discussed in section 5.6  gigabit ethernet often serves as a backbone for interconnecting multiple 10 mbps and 100 mbps ethernet lans initially operating over optical fiber  gigabit ethernet will be able to use category 5 utp cabling the gigabit ethernet alliance is an open forum whose purpose is to promote industry cooperation in the development of gigabit ethernet their web site is rich source of information on gigabit ethernet  alliance 1999   the interoperability lab at the university of new hampshire also maintains a nice page on gigabit ethernet  inter 1999   references  lam 1980  s lam  a carrier sense multiple access protocol for local networks  " computer networks  volume 4  pp 21-32  1980  bertsekas 1992  d bertsekas and r gallager  data networks  second edition  prentice hall  englewood cliffs  new jersey  1992  spurgeon 1999  c spurgeon  charles spurgeon 's ethernet web site  http  //wwwhost.ots.utexas.edu/ ethernet/  alliance 1999  gigabit ethernet alliance  http  //www.gigabit-ethernet.org/  inter 1999  interoperability lab gigabit ethernet page  http  //www.iol.unh.edu/training/ge.html copyright 1996-1999 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net % 20approach % 20featuring % 20the % 20internet/ethernet.htm  12 of 12  20/11/2004 15  52  37 csma/cd simulation ethernet applet this applet allows you to visualize how transmission time and propagation delay effect csma/cd the applet uses a bus topology  such as with 10base2  as opposed to a star topology  although similar effects occur with a star topology   the applet assumes a propagation speed of 2 * 108 meters/sec 1 set the parameters  bus length  frame size  and transmission rate 2 click on start 3 click on stations to generate packets file  ///d | /downloads/livros/computa ? ? o/computer % 20network...op-down % 20approach % 20featuring % 20the % 20internet/enet.html20/11/2004 15  52  38 hubs  bridges  and switches 5.6 bridges and switches institutions  including  companies  universities and high schools  typically consist of many departments  with each department having and managing its own ethernet lan naturally  an institution will want its departments to interconnect their departmental lan segments in this section  we consider a number of different approaches in which lans can be connected together we 'll cover three approaches  hubs  bridges  and switches in the following subsections all three of these approaches are in widespread use today 5.6.1 hubs the simplest way to interconnect lans is to use a hub a hub is a simple device that takes an input  i.e  a frame 's bits  an retransmits the input on the hub 's outgoing ports hubs are essentially repeaters  operating on bits they are thus physical-layer devices when a bit comes into a hub interface  the hub simply broadcasts the bit on all the other interfaces in this section we investigate bridges  which are another type of interconnection device figure 5.6-1 shows how three academic departments in a university might interconnect their lans in this figure  each of the three departments has a 10baset ethernet that provides network access to the faculty  staff and students of the departments each host in a department has a point-to-point connection to the departmental hub a fourth hub  called a backbone hub  has point-to-point connections to the departmental hubs  interconnecting the lans of the three departments the design shown in figure 5.6-1 is a multi-tier hub design because the hubs are arranged in a hierarchy it is also possible to create multi-tier designs with more than two tiers  for example  one tier for the departments  one tier for the schools within the university  e.g  engineering school  business school  etc  and one tier at the highest university level multiple tiers can also be created out of 10base2  bus topology ethernets  with repeaters figure 5.6-1  three departmental ethernets interconnected with a hub file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  1 of 12  20/11/2004 15  52  39 hubs  bridges  and switches in a multi-tier design  we refer to the entire interconnected network as a lan  and we refer to each of the departmental portions of the lan  i.e  the departmental hub and the hosts that connect to the hub  as a lan segment it is important to note that all of the lan segments in figure 5-6.1 belong to the same collision domain  that is  whenever two or more nodes on the lan segments transmit at the same time  there will be a collision and all of the transmitting nodes will enter exponential backoff interconnecting departmental lans with a backbone hub has many benefits first and foremost  it provides interdepartmental communication to the hosts in the various departments second  it extends the maximum distance between any pair of nodes on the lan for example  with 10baset the maximum distance between a node and its hub is 100 meters ; therefore  in a single lan segment the maximum distance between any pair of nodes is 200 meters by interconnecting the hubs  this maximum distance can be extended  since the distance between directly-connected hubs can also be 100 meters when using twisted pair  and more when using fiber   third  the multi-tier design provides a degree of graceful degradation specifically  if any one of the departmental hubs starts to malfunction  the backbone hub can detect the problem and disconnect the departmental hub from the lan ; in this manner  the remaining departments can continue to operate and communicate while the faulty departmental hub gets repaired although a backbone hub is a useful interconnection device  it has three serious limitations that hinder its deployment first  and perhaps more important  when departmental lans are interconnected with a hub  or a repeater   then the independent collision domains of the departments are transformed into one large and common collision domain let us explore this latter issue in the context of figure 5.6-1 before interconnecting the three departments  each departmental lan had a maximum throughput of 10 mbps  so that maximum aggregate throughput of the three lans was 30 mbps but once the three lans are interconnected with a hub  all of the hosts in the three departments belong to the same collision domain  and the maximum aggregate throughput is reduced to 10 mbps a second limitation is that if the various departments use different ethernet technologies  then it may not be possible to interconnect the departmental hubs with a backbone hub for example  if some departments use 10baset and the remaining departments use 100baset  then it is impossible to interconnect all the departments without some frame buffering at the interconnection point ; since hubs are essentially repeaters and do not buffer frames  they can not interconnect lan segments operating at different rates a third limitation is that each of the ethernet technologies  10base2  10baset  100baset  etc  has restrictions on the maximum number of nodes that can be in a collision domain  the maximum distance between two hosts in a collision domain  and the maximum number of tiers that can be present in a multi-tier design these restrictions constrain both the total number of hosts that connect to a multi-tier lan as well as geographical reach of the multi-tier lan 5.6.2 bridges in contrast to hubs  which are physical-level devices  bridges operate on ethernet frames and thus are layer-2 devices in fact  bridges are full-fledged packet switches that forward and filter frames using the lan destination addresses when a frame comes into a bridge interface  the bridge does not just copy the frame onto all of the other interfaces instead  the bridge examines the destination address of the frame and attempts to forward the frame on the interface that leads to the destination figure 5.6-2 shows how the three academic departments of our previous example might be interconnected with a bridge the three numbers next to the bridge are the interface numbers for the three bridge interfaces when the file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  2 of 12  20/11/2004 15  52  39 hubs  bridges  and switches departments are interconnected by a bridge  as in figure 5.6-2  we again refer to the entire interconnected network as a lan  and we again refer to each of the departmental portions of the network as lan segments but in contrast to the multi-tier hub design in figure 5.6-1  each lan segment is now an isolated collision domain figure 5.6-2  three departmental lans interconnected with a bridge bridges can overcome many of the problems that plague hubs first  bridges permit inter-departmental communication while preserving isolated collision domains for each of the departments second  bridges can interconnect different lan technologies  including 10 mbps and 100 mbps ethernets third  there is no limit to how big a lan can be when bridges are used to interconnect lan segments  in theory  using bridges  it is possible to build a lan that spans the entire globe bridge forwarding and filtering filtering is the ability to determine whether a frame should be forwarded to an interface or should just be dropped when the frame should be forwarded  forwarding is the ability to determine which of the interfaces the frame should be directed to bridge filtering and forwarding are done with a bridge table for each node on the lan  the bridge table contains  1  the lan address of the node   2  the bridge interface that leads towards the node   3  and the time at which the entry for the node was placed in the table an example table for the lan in figure 5.6.2 is shown in figure 5.6-3 this description of frame forwarding may sound similar to our discussion of datagram forwarding in chapter 4 we note here that the addressees used by bridges are physical addresses  not network addresses   we will also see shortly that a bridge table is constructed in a very different manner than routing tables address interface time 62-fe-f7-11-89-a3 1 9  32 7c-ba-b2-b4-91-10 3 9  36    figure 5.6-3  portion of a bridge table for the lan in figure 5.6.2 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  3 of 12  20/11/2004 15  52  39 hubs  bridges  and switches to understand how bridge filtering and forwarding works  suppose a frame with destination address dd-dd-dd-dddd dd arrives to the bridge on interface x the bridge indexes its table with the lan address dd-dd-dd-dd-dddd and finds the corresponding interface y l if x equals y  then the frame is coming from a lan segment that contains adapter dd-dd-dd-dd-dd-dd there being no need to forward the frame to any of the other interfaces  the bridge performs the filtering function by discarding the frame l if x does not equal y  then the frame needs to be routed to the lan segment attached to interface y the bridge performs its forwarding function by putting the frame in an output buffer that precedes interface y these simple rules allow a bridge to preserve separate collision domains for each of the different lan segments connected to its interfaces the rules also allow the nodes on different lan segments to communicate let 's walk through these rules for the network in figures 5.6-2 and its bridge table in figure 5.6-3 suppose that a frame with destination address 62-fe-f7-11-89-a3 arrives to the bridge from interface 1 the bridge examines its table and sees that the destination is on the lan segment connected to interface 1  i.e  the electrical engineering lan   this means that the frame has already been broadcast on the lan segment that contains the destination the bridge therefore filters  i.e  discards  the frame now suppose a frame with the same destination address arrives from interface 2 the bridge again examines its table and sees that the destination is the direction of interface 1 ; it therefore forwards the frame to the output buffer preceding interface 1 it should be clear from this example that as long as the bridge table is complete and accurate  the bridge isolates the departmental collision domains while permitting the departments to communicate recall that when a hub  or a repeater  forwards a frame onto a link  it just sends the bits onto the link without bothering to sense whether another transmission is currently taking place on the link in contrast  when a bridge wants to forward a frame onto a link  it runs the csma/cd algorithm discussed in section 5.3 in particular  the bridge refrains from transmitting if it senses that some other node on the lan segment is transmitting ; furthermore  the bridge uses exponential backoff when one of its transmissions results in a collision thus bridge interfaces behave very much like node adapters but technically speaking  they are not node adapters because neither a bridge nor its interfaces have lan addresses recall that a node adapter always inserts its lan address into the source address of every frame it transmits this statement is true for router adapters as well as host adapters a bridge  on the other hand  does not change the source address of the frame one significant feature of bridges is that they can be used to combine ethernet segments using different ethernet technologies for example  if in figure 5.6-2  electrical engineering has a 10base2 ethernet  computer science has a 100baset ethernet  and electrical engineering has a 10baset ethernet  then a bridge can be purchased that can interconnect the three lans with gigabit ethernet bridges  it is possible to have an additional 1 gbps connection to a router  which in turn connects to a larger university network as we mentioned earlier  this feature of being able to interconnect different link rates is not available with hubs also  when bridges are used as interconnection devices  there is no theoretical limit to the geographical reach of a lan in theory  we can build a lan that spans the globe by interconnecting hubs in a long  linear topology  with each pair of neighboring hubs interconnected by a bridge because in this design each of the hubs has its own collision domain  there is no limit on how long the lan can be we shall see shortly  however  that it is undesirable to build very large networks exclusively using bridges as interconnection devices  large networks need routers as well self-learning file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  4 of 12  20/11/2004 15  52  39 hubs  bridges  and switches a bridge has the very cool property of building its table automatically  dynamically and autonomously  without any intervention from a network administrator or from a configuration protocol in other words  bridges are self-learning this is accomplished as follows l the bridge table is initially empty l when a frame arrives on one of the interfaces and the frame 's destination address is not in the table  then the bridge forwards copies of the frame to the output buffers of all of the other interfaces  at each of these other interfaces  the frame accesses the lan segment using csma/cd  l for each frame received  the bridge stores in its table  1  the lan address in the frame 's source address field   2  the interface from which the frame arrived   3  the current time in this manner the bridge records in its table the lan segment on which the sending node resides if every node in the lan eventually sends a frame  then every node will eventually get recorded in the table l when a frame arrives on one of the interfaces and the frame 's destination address is in the table  then the bridge forwards the frame to the appropriate interface l the bridge deletes an address in the table if no frames are received with that address as the source address after a period of time  the aging time   in this manner  if a pc is replaced by another pc  with a different adapter   the lan address of the original pc will eventually be purged from the bridge table let 's walk through the self-learning property for the network in figures 5.6-2 and its corresponding bridge table in figure 5.6-3 suppose at time 9  39 a frame with source address 01-12-23-34-45-56 arrives from interface 2 suppose that this address is not in the bridge table then the bridge appends a new entry in the table  as shown in figure 5.6-4 address interface time 01-12-23-34-45-56 2 9  39 62-fe-f7-11-89-a3 1 9  32 7c-ba-b2-b4-91-10 3 9  36    figure 5.6-4  bridge learns about the location of adapter with address 01-12-23-34-45-56 continuing with this same example  suppose that the aging time for this bridge is 60 minutes and no frames with source address 62-fe-f7-11-89-a3 arrive to the bridge between 9  32 and 10  32 then at time 10  32 the bridge removes this address from its table bridges are plug and play devices because they require absolutely no intervention from a network administrator or user when a network administrator wants to install a bridge  it does no more than connect the lan segments to the bridge interfaces the administrator does not have to configure the bridge tables at the time of installation or when a host is removed from one of the lan segments because bridges are plug and play  they are also referred as transparent bridges spanning tree one of the problems with a pure hierarchical design for interconnected lan segments is that if a hub or a bridge near the top of the hierarchy fails  then much  if not all  of the interconnected lan will go down for this reason it is desirable to build networks with multiple paths between lan segments an example of such a network is shown in figure 5.6-5 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  5 of 12  20/11/2004 15  52  39 hubs  bridges  and switches figure 5.6-5  interconnected lan segments with redundant paths multiple redundant paths between lan segments  such as departmental lans  can greatly improve fault tolerance but  unfortunately  multiple paths have a serious side effect  frames cycle and multiply within the interconnected lan  thereby crashing the entire network  permian 1999   to see this  suppose that the bridge tables in figure 5.6-5 are empty  and a host in electrical engineering sends a frame to a host in computer science when the frame arrives to the electrical engineering hub  the hub will generate two copies of the frame and send one copy to each of the two bridges when a bridge receives the frame  it will generate two copies  send one copy to the computer science hub and the other copy to the systems engineering hub since both bridges do this  there will be four identical frames in the lan this multiplying of copies will continue indefinitely since the bridges do not know where the destination host resides  to route the frame to the destination host in computer science  the destination host has to first generate a frame so that its address can be recorded in the bridge tables  the number of copies of the original frame grows exponentially fast  crashing the entire network to prevent the cycling and multiplying of frames  bridges use a spanning tree protocol  permian 1999   in the spanning tree protocol  bridges communicate with each other over the lans in order to determine a spanning tree  that is  a subset of the original topology that has no loops once the bridges determine a spanning tree  the bridges disconnect appropriate interfaces in order to create the spanning tree out of the original topology for example  in figure 5.6-5  a spanning tree is created by having the top bridge disconnect its interface to electrical engineering and the bottom bridge disconnect its interface to systems engineering with the interfaces disconnected and the loops removed  frames will no longer cycle and multiply if  at some later time  one of links in the spanning tree fails  the bridges can reconnect the interfaces  run the spanning tree algorithm again  and determine a new set of interfaces that should be disconnected bridges versus routers as we learned in chapter 4  routers are store-and-forward packet switches that forward packets using ip addresses although a bridge is also a store-and-forward packet switch  it is fundamentally different from a router in that it forwards packets using lan addresses whereas a router is layer-3 packet switch  a bridge is a layer-2 packet switch file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  6 of 12  20/11/2004 15  52  39 hubs  bridges  and switches even though bridges and routers are fundamentally different  network administrators must often choose between them when installing an interconnection device for example  for the network in figure 5.6-2  the network administrator could have just as easily used a router instead of a bridge indeed  a router would have also kept the three collision domains separate while permitting interdepartmental communication given that both bridges and routers are candidates for interconnection devices  what are the pros and cons of the two approaches ? figure 5.6-6  packet processing and bridges  routers and hosts first consider the pros and cons of bridges as mentioned above  bridges are plug and play  a property that is cherished by all the over-worked network administrators of the world bridges can also have relatively high packet filtering and forwarding rates  as shown in figure 5.6-6  bridges only have to process packets up through layer 2  whereas routers have to process frames up through layer 3 on the other hand  the spanning tree protocol restricts the effective topology of a bridged network to a spanning tree this means that all frames most flow along the spanning tree  even when there are more direct  but disconnected  paths between source and destination the spanning tree restriction also concentrates the traffic on the spanning tree links when it could have otherwise been spread through all the links of the original topology furthermore  bridges do not offer any protection against broadcast storms  if one host goes haywire and transmits an endless stream of ethernet broadcast packets  the bridges will forward all of the packets and the entire network will collapse now consider the pros and cons of routers because ip addressing is hierarchical  and not flat as is lan addressing   packets do not normally cycle through routers even when the network has redundant paths  actually  packets can cycle when router tables are misconfigured ; but as we learned in chapter 4  ip uses a special datagram header field to limit the cycling  thus  packets are not restricted to a spanning tree and can use the best path between source and destination because routers do not have the spanning tree restriction  routers have allowed the internet to be built with a rich topology which includes  for example  multiple active links between europe and north america another feature of routers is that they provide firewall protection against layer-2 broadcast storms perhaps the most significant drawback of routers is that they are not plug and play  they and the hosts that connect to them need their ip addresses to be configured also  routers often have a larger prepackage processing time than bridges  because they have to process up through the layer-3 fields finally  there are two different ways to pronounce the word " router "  either as " rootor " or as " rowter "  and people waste a lot of time arguing over the proper pronunciation  perlman 1999   given that both bridges and routers have their pros and cons  when should an institutional network  e.g  university file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  7 of 12  20/11/2004 15  52  39 hubs  bridges  and switches campus network or a corporate campus network  use bridges  and when should it use bridges ? typically  small networks consisting of a few hundred hosts have a few lan segments bridges suffice for these small networks  as they localize traffic and increase aggregate throughput without requiring any configuration of ip addresses but larger networks consisting of thousands of hosts typically include routers within the network  in addition to bridges   the routers provide a more robust isolation of traffic  control broadcast storms  and use more " intelligent " routes among the hosts in the network connecting lan segments with backbones consider once again the problem of interconnecting with bridges the ethernets in the three departments in figure 5.6 2 an alternative design is shown in figure 5.6-7 this alternative design uses two two-interface bridges  i.e  bridges with two interfaces   with one bridge connecting electrical engineering to computer science  and the other bridge connecting computer science to systems engineering although two-interface bridges are very popular due to their low cost and simplicity  the design in figure 5.6-7 is not recommended for two reasons first  if the computer science hub were to fail  then electrical engineering and systems engineering would no longer be able to communicate second  and more important  all the inter-departmental traffic between electrical and systems engineering has to pass through computer science  which may overly burden the computer science lan segment figure 5.6-7  an example of an institutional lan without a backbone one important principle when designing an interconnected lan is that the various lan segments should be interconnected with a backbone a backbone is a network that has direct connections to all the lan segments when a lan has a backbone  then each pair of lan segments can communicate without passing through a third-party lan segment the design shown if figure 5.6-2 uses a three-interface bridge for a backbone in the homework problems at the end of this chapter we shall explore how to design backbone networks with two-interface bridges 5.6.2 switches up until the mid 1990s  three types of lan interconnection devices were essentially available  hubs  and their cousins  repeaters   bridges and routers more recently yet another interconnection device became widely available  namely  ethernet switches ethernet switches  often trumpeted by network equipment manufacturers with great fanfare  are in essence high-performance multi-interface bridges as do bridges  they forward and filter frames using lan destination addresses  and they automatically build routing tables using the source addresses in the traversing frames the most important difference between a bridge and switch is that bridges usually have a small number of interfaces  i e  2-4   whereas switches may have dozens of interfaces a large number interfaces generates a high aggregate forwarding rate through the switch fabric  therefore necessitating a high-performance design  especially for 100 mbps file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  8 of 12  20/11/2004 15  52  39 hubs  bridges  and switches and 1 gbps interfaces   switches can be purchased with various combinations of 10 mbps  100 mbps and 1 gbps interfaces for example  you can purchase switches with four 100 mbps interfaces and twenty 10 mbps interfaces ; or switches with four 100 mbps interfaces and one 1 gbps interface of course  the more the interfaces and the higher transmission rates of the various interfaces  the more you pay many switches also operate in a full-duplex mode ; that is  they can send and receive frames at the same time over the same interface with a full duplex switch  and corresponding full duplex ethernet adapters in the hosts   host a can send a file to host b while that host b simultaneously sends to host a figure 5.6-8  an ethernet switch providing dedicated ethernet access to six hosts one of the advantages of having a switch with a large number of interfaces is that it creates direct connections between hosts and the switch when a host has a full-duplex direct connection to a switch  it can transmit  and receive  frames at the full transmission rate of its adapter ; in particular  the host adapter always senses an idle channel and never experiences a collision when a host has a direct connection to a switch  rather than a shared lan connection   the host is said to have dedicated access in figure 5.6-8  an ethernet switch provides dedicated access to six hosts this dedicated access allows a to send a file to a ' while that b is sending a file to b ' and c is sending a file to c' if each host has a 10mbps adapter card  then the aggregate throughput during the three simultaneous file transfers is 30 mbps if a and a ' have 100 mbps adapters and the remaining hosts have 10 mbps adapters  then the aggregate throughput during the three simultaneous file transfers is 120 mbps file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...ch % 20featuring % 20the % 20internet/transparent_bridges.htm  9 of 12  20/11/2004 15  52  39 hubs  bridges  and switches figure 5.6-9  an institutional network using a combination of hubs  ethernet switches and a router figure 5.6-9 shows how an institution with several departments and several critical servers might deploy a combination of hubs  ethernet switches and routers in figure 5.6-9  each of the three departments has its own 10 mbps ethernet segment with its own hub because each departmental hub has a connection to the switch  all intradepartmental traffic is confined to the ethernet segment of the department  assuming the routing tables in the ethernet switch are complete   the web and mail servers each have dedicated 100 mbps access to the switch finally  a router  leading to the internet  has dedicated 100 mbps access to the switch note that this switch has at least three 10 mbps interfaces and three100 mbps interfaces cut-through switching in addition to large numbers of interfaces  support for multitudes of physical media types and transmission rates  and enticing network management features  ethernet switch manufacturers often tout that their switches use cut-through switching rather than store-and-forward packet switching  used by routers and bridges the difference between storeand forward and cut-through switching is subtle to understand this difference consider a packet that is being forwarded through a packet switch  i.e  a router  a bridge  or an ethernet switch   the packet arrives to the switch on a inbound link and leaves the switch on a outbound link when the packet arrives  there may or may not be other packets in the outbound link 's output buffer when there are packets in the output buffer  there is absolutely no difference between store-and-forward and cut-through switching the two switching techniques only differ when the output buffer is empty recall from chapter 1  when a packet is forwarded through a store-and-forward packet switch  the packet is first file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...h % 20featuring % 20the % 20internet/transparent_bridges.htm  10 of 12  20/11/2004 15  52  39 hubs  bridges  and switches gathered and stored in its entirety before the switch begins to transmit it on the outbound link in the case when the output buffer becomes empty before the whole packet has arrived to the switch  this gathering generates a store-andforward delay at the switch  a delay which contributes to the total end-to-end delay  see chapter 1   an upper bound on this delay is l/r  where l is the length of the packet and r is transmission rate of the inbound link note that a packet only incurs a store-and-forward delay if the output buffer becomes empty before the entire packet arrives to the switch with cut-through switching  if the buffer becomes empty before the entire packet has arrived  the switch can start to transmit the front of the packet while the back of the packet continues to arrive of course  before transmitting the packet on the outbound link  the portion of the packet that contains the destination address must first arrive  this small delay is inevitable for all types of switching  as the switch must determine the appropriate outbound link  in summary  with cut-through switching a packet does not have to be fully " stored " before it is forwarded ; instead the packet is forwarded through the switch when the output link is free if the output link is shared with other hosts  e.g  the output link connects to a hub   then the switch must also sense the link as idle before it can " cut-through " a packet to shed some insight on the difference between store-and-forward and cut-through switching  let us recall the caravan analogy introduced in section 1.6 in this analogy  there is a highway with occasional toll booths  with each toll booth having a single attendant on the highway there is a caravan of 10 cars traveling together  each at the same constant speed the cars in the caravan are the only cars on the highway each toll booth services the cars at a constant rate  so that when the cars leave the toll booth they are equally spaced apart as before  we can think of the caravan as being a packet  each car in the caravan as being a bit  and the toll booth service rate as the transmission rate of a link consider now what the cars in the caravan do when they arrive to a toll booth if each car proceeds directly to the toll booth upon arrival  then the toll booth is a " cut-through toll booth "  if  on the other hand  each car waits at the entrance until all the remaining cars in the caravan arrive  then the toll booth is " store-and-forward toll booth "  the store-and-forward toll booth clearly delays the caravan more than the cut-through toll booth a cut-through switch can reduce a packet 's end-to-end delay  but by how much ? as we mentioned above  the maximum store-and-forward delay is l/r  where l is the packet size and r is the rate of the inbound link the maximum delay is approximately 1.2 msec for 10 mbps ethernet and .12 msec for 100 mbps ethernet  corresponding to a maximum size ethernet packet   thus  a cut-through switch only reduces the delay by .12 to .2 msec  and this reduction only occurs when the outbound link is lightly loaded how significant is this delay ? probably not very much in most practical applications  so you may want to think second about selling the family house before investing in the cut-through feature hubs bridges routers ethernet switches traffic isolation no yes yes yes plug and play yes yes no yes optimal routing no no yes no cut-through yes no no yes figure 5.6-10  comparison of the typical features of popular interconnection devices we have learned in this section that hubs  bridges  routers and switches can all be used as an interconnection device for hosts and lan segments figure 5.6-10 provides a summary of the features of each of these interconnection devices the cisco web site provides numerous comparisons of the different interconnection technologies  cisco 1999   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...h % 20featuring % 20the % 20internet/transparent_bridges.htm  11 of 12  20/11/2004 15  52  39 hubs  bridges  and switches references  perlman 1999  r perlman  interconnections  bridges and routers  2nd ed  addison-wesley  reading  ma  1999  cisco 1999  cisco lan switches page  http  //www.cisco.com/warp/public/729/ copyright james f kurose and keith w ross 1996-1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...h % 20featuring % 20the % 20internet/transparent_bridges.htm  12 of 12  20/11/2004 15  52  39 ieee 802.11 wireless lans 5.7 ieee 802.11 lans in section 5.5  we examined the dominant wired lan protocol  ethernet in the previous section we examined how lan segments can be connected together via hubs  bridges and routers to form larger lans in this section we examine a lan standard  belonging to the same ieee 802 family as ethernet  that is being increasingly deployed for untether  wireless  lan communication the ieee 802.11 standard  brenner 1997  crow 1997  ieee 1999  defines the physical layer and media access control  mac  layer for a wireless local area network the standard defines three different physical layers for the 802.11 wireless lan  each operating in a different frequency range and at rates of 1 mbps and 2 mbps in this section we focus on the architecture of 802.11 lans and their media access protocols we 'll see that although it belongs to the same standard family as ethernet  it has a significantly different architecture and media access protocol 5.7.1 802.11 lan architecture figure 5.7-1  ieee 802.11 lan architecture figure 5.7-1 illustrates the principal components of the 802.11 wireless lan architecture the fundamental building block of the 802.11 architecture is the cell  known as the basic service set  bss  in 802.11 parlance a bss typically contains one or more wireless stations and a central base station  known as an access point  ap  in 802.11 terminology the stations  which may be either fixed or mobile  and the central base station communicate amongst themselves using the ieee 802.11 wireless mac protocol multiple aps may be connected together  e.g  using a wired ethernet or another wireless channel  to form a so-called distribution system  ds   the ds appears to upper level protocols  e.g  ip  as a single 802 network  in much the same way that a bridged  wired 802.3 ethernet network appears as a single 802 network to the upper layer protocols file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  1 of 6  20/11/2004 15  52  41 ieee 802.11 wireless lans figure 5.7-2  an ieee 802.11 ad hoc network figure 5.7-2 shows that ieee 802.11 stations can also group themselves together to form an ad hoc network  a network with no central control and with no connections to the " outside world " here  the network is formed " on the fly  " simply because there happen to be mobile devices that have found themselves in proximity to each other  that have a need to communication  and that find no pre-existing network infrastructure  e.g  a preexisting 802.11 bss with an ap  in the location an ad hoc network might be formed  for example  when people with laptops meet together  e.g  in a conference room  a train  or a car  and want to exchange data in the absence of a centralized ap there has been a tremendous recent increase in interest in ad hoc networking  as communicating portable devices continue to proliferate within the ietf  activity in ad hoc networking is centered around the mobile ad hoc networks  manet  working group 5.7.2 802.11 media access protocols just as in a wired 802.3 ethernet network  stations in an ieee 802.11 wireless lan must coordinate their access and use of the shared communication media  in this case the radio frequency   once again  this is the job of the media access control  mac  protocol the ieee 802.11 mac protocol is a carrier sense multiple access protocol with collision avoidance  csma/ca   recall from our study of ethernet in section 5.5 that a csma protocol first senses the channel to determine if the channel is " busy " with the transmission of a frame from some other station in the 802.11 specification  the physical layer monitors the energy level on the radio frequency to determine whether or not another station is transmitting and provides this carrier sensing information to the mac protocol if the channel is sensed idle for an amount of time equal to or greater than the distributed inter frame space  difs   a station is then allowed to transmit as with any random access protocol  this frame will be successfully received at the destination station if no other station 's transmission has interfered with the frame 's transmission file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  2 of 6  20/11/2004 15  52  41 ieee 802.11 wireless lans when a receiving station has correctly and completely received a frame for which it was the addressed recipient  it waits a short period of time  known as the short inter frame spacing  sifs  and then sends an explicit acknowledgment frame back to the sender this data link layer acknowledgment lets the sender know that the receiver has indeed correctly received the sender 's data frame we will see shortly that this explicit acknowledgment is needed because  unlike the case of wired ethernet  a wireless sender can not itself determine whether or not its frame transmission was successfully received at the destination the transmission of a frame by a sending station and its subsequent acknowledgment by the destination station is shown in figure 5.7-3 figure 5.7-3  data transmission and acknowledgment in ieee 802.11 figure 5.7-3 illustrates the case when the sender senses the channel to be idle what happens if the sender senses the channel busy ? in this case  the station performs a backoff procedure that is similar to that of ethernet more specifically  a station that senses the channel busy will defer its access until the channel is later sensed idle once the channel is sensed idle for an amount of time equal to difs  the station then computes an additional random backoff time and counts down this time as the channel is sensed idle when the random backoff timer reaches zero  the station transmits its frame as in the case of ethernet  the random backoff timer serves to avoid having multiple stations immediately begin transmission  and thus collide  after a difs idle period as in the case of ethernet  the interval over which the backoff timer is randomizes is doubled each time a transmitted frame file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  3 of 6  20/11/2004 15  52  41 ieee 802.11 wireless lans experiences a collision we noted above that unlike the 802.3 ethernet protocol  the wireless 802.11 mac protocol does not implement collision detection there are a couple of reasons for this  l the ability to detect collisions requires the ability to both send  one 's own signal  and receive  to determine if another station 's transmissions is interfering with one 's own transmission  at the same time this can be costly l more importantly  even if one had collision detection and sensed no collision when sending  a collision could still occur at the receiver this situation results from the particular characteristics of the wireless channel suppose that station a is transmitting to station b suppose also that station c is transmitting to station b with the so-called hidden terminal problem  physical obstructions in the environment  e.g a mountain  may prevent a and c from hearing each others transmissions  even though a 's and c 's transmissions are indeed interfering at the destination  b this is shown in figure 5.7-4  a   a second scenario that results in undetectable collisions at the receiver results from the fading of a signal 's strength as propagates through the wireless medium figure 5.7-4  b  illustrates the case where a and c are placed such that their signal strengths are not strong enough for them to detect each others ' transmissions  and yet their transmissions are strong enough to have interfered with each other at station b figure 5.7-4  hidden terminal problem  a  and fading  b  given these difficulties with detecting collisions at a wireless receiver  the designers of ieee 802.11 developed an access protocol which aimed to avoid collisions  hence the name csma/ca   rather than detect and recover from collisions  csma/cd   first  the ieee 802.11 frame contains a duration field in which the sending station explicit indicates the length of time that its frame will be transmitting on the channel this value allows other stations to determine the minimum amount of time  the so-called network allocation vector  nav  for which they should defer their access  as shown in figure 5.7.3 the ieee 802.11 protocol can also use a short request to send  rts  control frame and a short clear to send file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  4 of 6  20/11/2004 15  52  41 ieee 802.11 wireless lans  cts  frame to reserve access to the channel when a sender wants to send a frame  it can first send a rts frame to the receiver  indicating the duration of the data packet and the ack packet a receiver that receives an rts frame responds with a cts frame  giving the sender explicit permission to send all other stations hearing the rts or cts then know about the pending data transmission and can avoid interfering with those transmissions the rts  cts  data and ack frames are shown in figure 5.7-5 an ieee 802.11 sender can operate either using the rts/cts control frames  as shown in figure 5.7-5  or can simply send its data without first using the rts control frame  as shown in figure 5.7-3 figure 5.7-5  collision avoidance using the rts and cts frames the use of the rts and cts frames helps avoid collisions in three important ways  l because the receiver 's transmitted cts frame will be heard by all stations within the receiver 's vicinity  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  5 of 6  20/11/2004 15  52  41 ieee 802.11 wireless lans the cts frame helps avoid both the hidden station problem and the fading problem l because the rts and cts frames are short  a collision involving a rts or cts frame will only last for the duration of the whole rts or cts frame note that when the rts and cts frames are correctly transmitted  there should be no collisions involving the subsequent data and ack frames in our discussion above  we have only highlighted some of the key aspects of the 802.11 protocol additional protocol capabilities such as time synchronization  power management  joining and leaving a network  i.e  roaming stations  are covered in the full ieee 802.11 standard see  brenner 1997  crow 1997  ieee 1999  for details references  brenner 1997  p brenner  " a technical tutorial on the ieee802.11 protocol  " breezecom wireless communications  crow 1997  b crow  i widjaja  j kim  p sakai  " ieee 802.11 wireless local area networks  " ieee communications magazine  sept 1997  pp 116-126  ieee 1999  ieee p802.11  working group for wireless local area networks copyright james f kurose and keith w ross 1996-1999  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/80211.htm  6 of 6  20/11/2004 15  52  41 the ppp protocol 5.8 ppp  the point-to-point protocol most of our discussion of data link protocols thus far has focused on protocols for broadcast channels in this section we cover a data link protocol for point-to-point links  ppp  the point-to-point protocol because ppp is typically the protocol of choice for a dialup link from residential hosts  it is undoubtedly one of the most widely-deployed data link protocols today the other important data link protocol in use today is the hdlc  high level data link control  protocol ; see  spragins 1991  for a discussion of hdlc our discussion here of the simpler ppp protocol will allow us to explore many of the most important features of point-to-point data link protocol as its name implies  the point-to-point protocol  ppp   rfc 1661  rfc 2153  is a data link layer protocol that operates over a point-to-point link  a link connecting two communicating link-level peers  one on each end of the link the point-to-point link over which ppp operates might be a serial dialup telephone line  e.g  a 56k modem connection   a sonet/sdh link  an x.25 connection  or over an isdn circuit an noted above  ppp has become the protocol of choice for connecting home users to their isp 's over a dialup connection before diving into the details of ppp  it is instructive to examine the original requirements that the ietf placed on the design of ppp  rfc 1547   l packet framing the ppp protocol data link layer sender must be able to take a network-level packet and frame  a.k.a encapsulate  it within the ppp data link layer frame such that the receiver will be able to identify the start and end of both the data link frame  and the network layer packet within the frame l transparency the ppp protocol must not place any constraints on data appearing on the network layer packet  headers or data   thus  for example  the ppp protocol can not forbid the use of certain bit patterns in the network layer packet we 'll return this issue shortly in our discussion of byte stuffing below l multiple network layer protocols the ppp protocol must be able to support multiple network layer protocols  e.g  ip and decnet  running over the same physical link at the same time just as the ip protocol is required to multiplex different transport level protocols  e.g  tcp and udp  over a single end-to-end connection  so too must ppp be able to multiplex different network layer protocols over a single point-to-point connection this requirement means that at a minimum  ppp will likely require a " protocol type " field or some similar mechanism so the receiving side ppp can demultiplex a received frame up to the appropriate network layer protocol l multiple types of links in addition to being able to carry multiple higher level protocols  ppp must also be able to operate over a wide variety of link types  including links that are either serial  transmitting a bit at a time in a given direction  or parallel  transmitting bits in parallel   synchronous  transmitting a clock signal along with the data bits  or asynchronous  low speed or high speed  electrical or optical file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  1 of 7  20/11/2004 15  52  42 the ppp protocol l error detection a ppp receiver must be able to detect bit errors in the received frame l connection liveness ppp must be able to detect a failure at the link level  e.g  the inability to transfer data from the sending side of the link to the receiving side of this link  and signal this error condition to the network layer l network layer address negotiation ppp must provide a mechanism for the communicating network layers  e.g  ip  to learn or configure each other 's network layer address l simplicity ppp was required to meet a number of additional requirements beyond the seven listed above on top of all of these requirements  first and foremost among all of the ppp requirements is that of " simplicity " rfc 1547 states " the watchword for a point-to-point protocol should be simplicity " a tall order indeed given all of the other requirements placed on the design of ppp ! more than 50 rfc 's now define the various aspects of this " simple " protocol while it may appear that many requirements were placed on the design of ppp  the situation could actually have been much more difficult ! the design specifications for ppp also explicitly note protocol functionality that was ppp was not required to implement  l error correction ppp is required to detect bit errors but is not required to correct them l flow control a ppp receiver is expected to be able to receive frames at the full rate of the underlying physical layer if a higher layer can not receive packets at this full rate  it is then up to the higher layer to drop packets or throttle the sender at the higher layer that is  rather than having the ppp sender throttle its own transmission rate  it is the responsibility of a higher level protocol to throttle the rate at which packets are delivered to ppp for sending l sequencing ppp is not required to deliver frames to the link receiver in the same order in which they were sent by the link sender it is interesting to note that while this flexibility is compatible with the ip service model  which allows ip packets to be delivered end-to-end in any order   other network layer protocols which operate over ppp do require sequenced end-to-end packet delivery l multipoint links ppp need only operate over links that have a single sender and a single receiver other link layer protocols  e.g  hdlc  can accommodate multiple receivers  e.g  an ethernet-like scenario  on a link having now considered the design goals  and non-goals  for ppp  let us see how the design of ppp met these goals 5.8.1 ppp data framing figure 5.8-1 shows a ppp data frame using hdlc-like framing  rfc 1662   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  2 of 7  20/11/2004 15  52  42 the ppp protocol figure 5.8-1  ppp data frame format the ppp frame contains the following fields  l flag field every ppp frame begins and ends with a 1 byte flag field with a value of 01111110 l address field the only possible value for this field is 11111111 l control field the only possible value of this field is 00000011 because both the address and control fields can currently take only a fixed value  one wonders why the fields are even defined in the firstplace the ppp specification  rfc 1622  states that other values " may be defined at a later time  " although none have been defined to date because these fields take fixed values  ppp allows the sender to simply not send the address and control bytes  thus saving two bytes of overhead in the ppp frame l protocol the protocol field tells the ppp receiver the upper layer protocol to which the received encapsulated data  i.e  the contents of the ppp frame 's info field  belongs on receipt of a ppp frame  the ppp receiver will check the frame for correctness and then pass the encapsulated data on to the appropriate protocol  rfc 1700  defines the 16-bit protocol codes used by ppp of interest to us are the ip protocol  i.e  the data encapsulated in the ppp frame is an ip datagram  which has a value of 21 hexadecimal  other network layer protocols such as appletalk  29  and decnet  27   the ppp link control protocol  c021 hexadecimal  that we discuss in detail in the following section  and the ip control protocol  8021  which is called by ppp when a link is first activated in order to configure the ip-level connection between the two routers on each end of the link  see below   l information this field contains the encapsulate packet  data  that is being sent by an upper layer protocol  e.g  ip  over the ppp link the default maximum length of the information field is 1500 bytes  although this can be changed when the link is first configured  as discussed below l checksum the checksum field is used to detect bit errors in a transmitted frame it uses either a two or four byte hdlc-standard cyclic redundancy code byte stuffing before closing our discussion of ppp framing  let us consider a problem that arises when any protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  3 of 7  20/11/2004 15  52  42 the ppp protocol uses a specific bit pattern  flag field  to delineate the beginning or end of the frame  what happens if the flag pattern itself occurs elsewhere in the packet ? for example  what happens if the flag field value of 01111110 appears in the information field ? will the receiver incorrectly detect the end of the ppp frame ? one way to solve this problem would be for ppp to forbid the upper layer protocol from sending data containing the flag field bit pattern the ppp requirement of transparency discussed above obviates this possibility an alternate solution  and the one taken in ppp and many other protocols  is to use a technique known as byte stuffing ppp defines a special control escape byte  01111101 if the flag sequence  01111110 appears anywhere in the frame  except in the flag field  ppp precedes that instance of the flag pattern with the control escape byte that is  it " stuffs "  adds  a control escape byte into the transmitted data stream  before the 01111110  to indicate that the following 011111110 is not a flag value but is  in fact  actual data a receiver that sees a 01111110 preceded by a 01111101 will  of course  remove the stuffed control escape to reconstruct the original data similarly  if the control escape byte bit pattern itself appears as actual data  it too must be preceded by a stuffed control escape byte thus  when the receiver see a single control escape byte by itself in the data stream  it knows that the byte was stuffed into the data stream a pair of control escape bytes occurring back-to-back means that one instance of the control escape byte appears in the original data being sent figure 5.8-2 illustrates ppp byte stuffing  actually  ppp also xors the data byte being escaped with 20 hexadecimal  a detail we omit here for simplicity   figure 5.8-2  byte stuffing file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  4 of 7  20/11/2004 15  52  42 the ppp protocol 5.8.2 ppp link control protocol  lcp  and network control protocols thus far  we have seen how ppp frames the data being sent over the point-to-point link but how does the link get initialized when a host or router on one end of the ppp link is first turned on ? the initialization  maintenance  error reporting  and shutdown of a ppp link is accomplished using ppp 's link control protocol  lcp  and family of ppp network control protocols before any data is exchanged over a ppp link  the two peers  one at each end of the ppp link  must first perform a considerable amount of work to configure the link  in much the same way that a tcp sender and receiver must perform a threeway handshake  see section 3.4  to set the parameters of the tcp connection before tcp data segments are transmitted figure 5.8-3 illustrates the state transition diagram for the lcp protocol for configuring  maintaining and terminating the ppp link figure 5.8-3  ppp link control protocol the ppp link always begins and ends in the dead state when an event such as a carrier detection or network administrator intervention indicates that a physical layer is present and ready to be used  ppp enters the link establishment state in this state  one end of the link sends its desired link configuration options using an lcp configure-request frame  a ppp frame with the protocol field set to lcp and the ppp information field containing the specific configuration request   the other side then file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  5 of 7  20/11/2004 15  52  42 the ppp protocol responds with a configure-ack frame  all options acceptable   a configure-nak frame  all options understood but not acceptable  or a configure-reject frame  options not recognizable or not acceptable for negotiation   lcp configuration options include a maximum frame size for the link  the specification of an authentication protocol  if any  to be used  and an option to skip the use of the address and control fields in the ppp frames once the link has been established  link options negotiated  and the authentication  if any  performed  the two sides of the ppp link then exchange network-layer-specific network control packets with each other if ip is running over the ppp link  the ip control protocol  rfc 1332  is used to configure the ip protocol modules at each end of the ppp link ipcp packets are carried within a ppp frame  with a protocol field value of 8021   just as lcp packets are carried in a ppp frame ipcp allows the two ip modules to exchange or configure their ip addresses and negotiate whether or not ip packets will be set in compressed form similar network control protocols are defined for other network layer protocols  such as decnet  rfc 1762  and appletalk  rfc 1378   once the network layer has been configured  ppp may then begin sending network-layer datagrams  the link is in the opened state and data has begun to flow across the ppp link the lcp echo-request packet and echo-reply packet can be exchanged between the two ppp endpoints in order to check the status of the link the ppp link remains configured for communication until an lcp terminate-request packet is sent if a terminate-request lcp packet is sent by one end of the ppp link and replied to with a terminate-ack lcp packet  the link then enters the dead state in summary  ppp is a data link layer protocol by which two communicating link-level peers  one on each end of a point-to-point link  exchange ppp frames containing network layer datagrams the principal components of ppp are  l framing a method for encapsulating data in a ppp frame  identifying the beginning and end of the frame  and detecting errors in the frame l link control protocol a protocol for initializing  maintaining  and taking down the ppp link l network control protocols a family of protocols  one for each upper layer network protocol  that allows the network layer modules to configure themselves before network-level datagrams begin flowing across the ppp link references  rfc 1332  g mcgregor  " the ppp internet protocol control protocol  ipcp   " rfc 1332  may 1992  rfc 1378  b parker  " the ppp appletalk control protocol  atcp   " rfc 1378 november 1992  rfc 1547  d perkins  " requirements for an internet standard point-to-point protocol  " rfc 1547  december 1993  rfc 1661  w simpson  ed   " the point-to-point protocol  ppp   " rfc 1661  july 1994 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  6 of 7  20/11/2004 15  52  42 the ppp protocol  rfc 1662  w simpson  ed   " ppp in hdlc-like framing  " rfc 1662  july 1994  rfc 1700  j reynolds  j postel  " assigned numbers  " rfc 1700  october 1994  rfc 1762  s senum  " the ppp decnet phase iv control protocol  dncp   " rfc 1762  march 1995  rfc 2153  w simpson  " ppp vendor extensions  " rfc 2153  may 1997  spragins 1991  j d spragins  telecommunications protocols and design  addison-wesley  1991   copyright keith w ross and jim kurose 1996-1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/ppp.htm  7 of 7  20/11/2004 15  52  42 atm 5.9 atm in section 1.10 we briefly introduced atm in this section we cover atm in more detail and discuss atm 's current role in the internet but before we begin  we list a few useful references a nice tutorial on atm is given in  leboudec 1992   ip-over-atm is discussed in detail in  kercheval 1998   recall that atm was standardized in 1990 by two standards bodies  the atm forum  atm forum 1999  and the international telecommunications union  itu 1999   paralleling the development of the atm standards  major companies throughout the world made significant investments in atm research and development these investments lead to a myriad of high-performing atm technologies  including atm switches that have throughputs of terabits per second because internet backbone networks need to distribute traffic at very high  and exponentially growing  rates  many backbone isps currently make extensive use of atm 5.9.1 ip over atm figure 5.9-1 shows such an atm backbone with four entry/exit points for internet ip taffic note that each entry/exit point is a router an atm backbone can span an entire continent and may have tens or even hundreds of atm switches most atm backbones have a permanent virtual channel  vc  between each pair of entry/exit points  recall that atm uses the jargon " virtual channel " for " virtual circuit "   by using permanent vcs  atm cells are routed from entry point to exit point without having to dynamiccally establish and tear-down vcs permanent vcs  however  are only feasible when the number of entry/exit points is relatively small for n entry points  n  n-1  permanent vcs are necessary each router interface that connects to the atm network will have two addresses the router interface will have an ip address  as usual and the router will have an atm address  which is esssentially a lan address  see section 5.4 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  1 of 10  20/11/2004 15  52  43 atm figure 5.9-1  atm network in the core of an internet backbone consider now an ip datagram that is to be moved across the backbone in figure 5.9-1 let us refer to the router at which the datagram enters the atm network as the " entry router " and the router at which the datagram leaves the network as the " exit router "  the entry router does the following  1 examines the destination address of the datagram 2 indexes its routing table and determines the ip address of the exit router  i.e  the next router in its route   3 to get the datagram to the exit router  the entry router views atm as just another link-layer protocol in particular  the entry router indexes an atm arp table with the ip address of the exit router and determines the atm address of the exit router 4 ip in the entry router then passes down to the link layer  i.e  atm  the datagram along with the atm address of the exit router after these four steps have been completed  the job of moving the datagram to the exit router is out of the hands of ip and in the hands of atm atm must now move the datagram to the atm destination address obtained in step 3 above this task has two sub-tasks  l determine the vci for the vc that leads to the atm destination address l segment the datagram into cells at the sending side of the vc  i.e  at the entry router   and reassemble the cells into the original datagram at the receiving side of the vc  i.e  at the exit router   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  2 of 10  20/11/2004 15  52  43 atm the first sub-task listed above is straightforward the interface at the sending side maintains a table that maps atm addresses to vcis because we are assuming that the vcs are permanent  this table is up-todate and static  if the vcs were not permanent  then an atm signalling protocol would be needed to dynamically establish and tear down the vcs  the second  task  merits careful one approach is to use ip fragmentation  as discussed in section 4.4 with ip fragmentation  the sending router would first fragment the original datagram into fragments  with each fragment being no more than 48 bytes  so that the fragment could fit into the payload of the atm cell but this fragmentation approach has a big problem  each ip fragment typically has 20 bytes of header  so that an atm cell carrying a fragment would have 25 bytes of " overhead " and only 28 bytes of useful information as we shall see in section 5.8.4  the atm standard provides a more efficient way to segment and reassemble a datagram recall from section 1.10 that atm has three layers  the physical layer  the atm layer  and the atm adaptation layer we now provide a brief introduction into these layers we will then return to issue just raised  how does atm efficiently segment and reassemble ip datagrams that are sent across an atm backbone ? 5.9.2 atm physical layer the physical layer is concerned with sending an atm cell over a single physical link as shown in figure 5.9-2  the physical layer has two sublayers  the physical medium dependent  pmd  sublayer and the transmission convergence  tc  sublayer sublayer responsibilites transmission convergence  tc  sublayer idle cell insertion cell delineation transmission frame adaptation physical medium dependent  pmd  sublayer physical medium bit voltages and timings frame structure figure 5.9-2  the two sublayers of the physical layer  and their responsibilities the physical medium dependent sublayer the pmd sublayer is at the very bottom of atm protocol stack as the name implies  the pmd sublayer depends on the physical medium of the link ; in particularly  the sublayer is specified differently for different physical media  fiber  copper  etc   as shown in the above chart  it specifies the medium itself it is also responsible for generating and delineating bits there are two classes of pmd sublayers  pmd sublayers which have a transmission frame structure  e.g  t1  t3  sonet  or sdh  and pmd sublayers which do not have a transmission frame structure if the pmd has a frame structure  then it is responsible for generating and delineating frames  the terminology " frames " in this section is not to be confused with link-layer frames used in the earlier sections of this chapter the transmission frame is a file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  3 of 10  20/11/2004 15  52  43 atm physcial-layer mechanism for organizing the bits sent on a link  the pmd sublayer does not recognize cells some possible pmd sublayers include  1 sonet/sdh  synchronous optical network / synchronous digital hierarchy  over single-mode fiber like t1 and t3  sonet and sdh have frame structures which establish bit synchronization between the transmitter and receiver at the two ends of the link there are several standardized rates  including  m oc-1  51.84 mbps m oc-3  155.52 mbps m oc-12  622.08 mbps 2 t1/t3 frames over fiber  microwave  and copper 3 cell based with no frames in this case  the clock at receiver is derived from transmitted signal transmission convergence sublayer the atm layer is specified independently of the physical layer ; it has no concept of sonet  t1  or physical media a sublayer is therefore needed  1  at the sending side of the link to accept atm cells from the atm layer and put the cells ' bits on the physical medium  and  2  at the receiving side of the link to group bits arriving from the physcial medium into cells and pass the cells to the atm layer these are the jobs of the tc sublayer  which sits on top of the pmd sublayer and just below the atm layer we note that the tc sublayer is also physical medium dependent  if we change the physical medium or the underlying frame structure  then we must also change the tc sublayer on the transmit side  the tc sublayer places atm cells into the bit and transmission frame structure of the pmd sublayer on the receive side  it extracts atm cells from the bit and transmission frame structure of the pmd sublayer it also peforms header error correction  hec   more specifically  the tc sublayer has the following tasks  l at the transmit side  the tc sublayer generates the hec byte for each atm cell that is to be transmitted at the receive side  the tc sublayer uses the hec byte to correct all one-bit errors in the header and some multiple-bit errors in the header  reducing the possibility of incorrect routing of cells  the hec is created by dividing the first 32 bits of the header by the polynomial x8 + x2 + x + 1 and then taking the 8-bit remainder  l at the receive side  the tc sublayer delineates cells if the pmd sublayer is cell based with no frames  then this is typically done by running the hec on all contiguous sets of 40 bits  i.e  5 bytes   when a match occurs  a cell is delineated upon matching four consecutive cells  cell synchronization is declared and subsequent cells are passed to the atm layer l if the pmd sublayer is cell based with no frames  the sublayer sends an idle cell when atm layer has not provided a cell  thereby generating a continuous stream of cells the receiving tc sublayer does not pass idle cells to the atm layer idle cells are marked in the pt field in the atm header file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  4 of 10  20/11/2004 15  52  43 atm 5.8.3 atm layer when ip runs over atm  the atm cell plays the role of the link-layer frame the atm layer defines the structure of the atm cell and the meaning of the fields within this structure the first 5 five bytes of the cell constitute the atm header ; the remaining 48 bytes constitute the atm payload figure 5.9-3 shows the structure of the atm header figure 5.9-3  the format of the atm cell header the fields in the atm cell are as follows  l vci  virtual channel identifier   indicates the vc to which the cell belongs as with most network technologies that use virtual circuits  a cell 's vci is translated from link to link  see section 1.3   l pt  payload type   indicates the type of payload the cell contains there are several data payload types  several maintenance payload types  and an idle cell payload type  recall that idle cells are sometimes needed by the physical layer for synchronization  l clp  cell loss priority  bit  can be set by the source  entry router in figure 5.8-1  to differentiate between high-priority traffic and low priority traffic if congestion occurs and an atm switch must discard cells  the switch can use this bit to first discard low-priority traffic l header error checksum hec byte  a checksum across the header  as described in section 5.8.1 recall that the tc sublayer  of the physical layer  calculates the hec byte at the transmitter and the checks the header at the receiver virtual channels before a source can begin to send cells to a destination  the atm network must first establish a virtual channel  vc  from source to destination a virtual channel is nothing more than a vc  as described in section 1.4 each vc is a path consisting of a sequence of links between source and destination on each of the links the vc has a virtual circuit identifier  vci   whenever a vc is established or torndown  vc translation tables must be updated  see section 1.4   as we mentioned above  atm backbones in the internet often use permanent vcs  which obviates the need for dynamic vc establishment and tear-down 5.9.4 atm adaptation layer file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  5 of 10  20/11/2004 15  52  43 atm the purpose of the aal is to allow existing protocols  e.g  ip  and applications  e.g  constant-bit-rate video  to run on top of atm as shown in figure 5.9-4  aal is implemented in the atm end systems  e.g.  entry end exit routers in an internet backbone   not in the intermediate atm switches thus  the aal layer is analogous in this respect to the transport layer in the internet protocol stack figure 5.9-4  the aal layer is present only at the edges of the atm network the aal sublayer has its own header fields as shown in figure 5.9-6  these fields occupy a small portion of the payload in the atm cell figure 5.9-5  the aal fields within the atm payload the itu and the atm forum have standardized several aals some of the most important aals include  aal 1  for constant bit rate  cbr  services and circuit emulation aal 2  for variable bit rate  vbr  services aal 5  for data  e.g  ip datagrams  aal structure aal has two sublayers  the segmentation and reassembly  sar  sublayer and the convergence sublayer  cs   as shown in figure 5.9-6  the sar sits just above the atm layer ; the cs sublayer sits between the user application and the sar sublayer file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  6 of 10  20/11/2004 15  52  43 atm figure 5.9-6  the sublayers of the aal the user data  e.g  an ip datagram  is first encapsulated in a common part convergence sublayer  cpcs  pdu in the convergence sublayer this pdu can have cpcs header and cpsc trailer typically the cpcs-pdu is much to large to fit into the payload of an atm cell ; thus the cpcs-pdu has to be segmented at the atm source and reassembled at the atm destination the sar sublayer segments the cpcs-pdu and adds aal header and trailer bits to form the payloads f the atm cells depending on the aal types  the aal and cpcs header and trailers could be empty aal 5  simple and efficient adaptation layer  seal  aal5 is a low-overhead aal that is is used to transport ip datagrams over atm networks with aal5  the aal header and trailer are empty ; thus  all 48 bytes of the atm payload are used to carry segments of the cpcs-pdu an ip datagram occupies the cpcs-pdu payload  which can be from 1 to 65,535 bytes the aal5 cpcs-pdu is shown in figure 5.9-7 figure 5.9-7  cpcs-pdu for aal5 the pad ensures that the cpcs-pdu is an integer multiple of 48 bytes the length field identifies the size of the cpcs-pdu payload  so that the pad can be removed at the receiver the crc is the same one that is used by ethernet  token ring and fddi at the atm source  the aal5 sar chops the cpcs-pdu into 48-byte segments as shown in figure file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  7 of 10  20/11/2004 15  52  43 atm 5.9-8  a bit in the pt field of the atm cell header  which is nominally 0  is set to 1 for the last cell of the cpcs-pdu at the atm destination  the atm layer directs cells with a specific vci to a sar-sublayer buffer the atm cell headers are removed  and the aal-indicate bit is used to delineate the cpcspdus once the cpcs-pdu is delineated  it is passed to the aal convergence sublayer at the convergence sublayer  the length field is used to extract the cpcs-pdu payload  e.g  an ip datagram   which is passed to the higher layer figure 5.9-8  the aal_indicate bit is used to reassemble ip datagrams from atm cells moving a datagram through an internet backbone let us now return to the problem of moving a datagram from an entry router to an exit router in figure 5.9-1 recall that ip in the entry router passes down to atm the datagrm along with the atm address of the exit router atm in the entry router indexes an atm table to determine the vci for the vc that leads to the atm destination address aal5 then creates atm cells out of the ip datagarm  l the datagram is encapsulated in a cpcs-pdu using the format in figure 5.8-8 l the cpcs-pdu is chopped up into 48-byte chunks each chunk is placed in the payload field of an atm cell l all of the cells except for the last cell have the third bit of the pt field set to zero the last cell has the bit set to one aal5 then passes the cells to the atm layer atm sets the vci and clp fields and passes each cell to the tc sublayer for each cell  the tc sublayer calculates the hec and inserts it in the hec field the tc sublayer then inserts the bits of the cells into the pmd sublayer the atm network then moves each cell across to the atm destination address at each atm switch between atm source and atm destination  the atm cell is processed by the atm physical and atm layers  but not by the aal layer at each switch the vci is typically translated  see section 1.4  and the hec is recalculated when the cells arrive at the atm destination address  they are directed to an aal buffer that has been put aside for the particular vc the cpcs-pdu is reconstructed using the aal_indicate bit to determine which cell is the last cell of the cpcs-pdu finally  the ip datagram is extracted out of the cpcs-pdu and is passed up the protocol stack to the ip layer file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  8 of 10  20/11/2004 15  52  43 atm 5.9.5 arp and atm consider once again the problem of moving a datagram from entry router to exit router across the atm network in figure 5.8-1 recall that arp has the important role of translating the exit router 's address to an atm destination address this translation is straightforward if the arp table is complete and accurate but as with ethernet  atm arp tables are auto-configured and may not be complete as with ethernet  if the desired mapping is not in the table  an arp protocol must contact the exit router and obtain the mapping however  there is a fundamental difference here between ethernet and atm  ethernet is a broadcast technology and atm is a switched technology what this means is that atm can simply send arp request message when a broadcast packet atm must work harder to get the mapping there are two generic approaches that can be used  broadcast arp request messages and arp server broadcast arp request messages in this approach  the entry router constructs an arp request message  converts the message to cells  and sends the cells into the atm network these cells are sent by the source along a special vc reserved for arp request messages the switches broadcast all cells received on this special vc the exit router receives the arp request message and sends the entry router an arp response message  which is not broadcasted   the entry router then updates its arp table this approach can place a significant amount of overhead arp broadcast traffic into the network arp server in this approach  arp server is attached directly to one of the atm switches in the network  and permanent vcs exist between each router and the arp server all of these permanent vcs use the same vci on all links from the touters to the arp server there are also permanent vcs from the arp server to each router ; each of these vcs have different vcis out of the arp server the arp server contains an up-to-date arp table that maps ip addresses to atm addresses using some registration protocol  all touters must register themselves with the arp server this approach eliminates the the broadcast arp traffic however it requires an arp server  which can swamped with arp request messages an important reference for running arp over atm is  rfc 1577   which discusses ip and arp over atm  rfc 1932  also provides a good overview of ip over atm references  atm forum 1999  the atm forum web site  http  //www.atmforum.com file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/atm.html  9 of 10  20/11/2004 15  52  43 atm  itu 1999  the itu web site  http  //www.itu.ch  kercheval 1998  b kercheval  tcp/ip over atm  prentice-hall  new jersey  1998  leboudec 1992  jean-yves leboudec  atm  a tutorial  computer networks and isdn systems  vol 24  1992  pp 279-309  rfc 1577  m laubach  classical ip and arp over atm   rfc 1577   1994  rfc 1932  r cole  s shur and c villamizar  ip over atm  a framework document   rfc 1932   1996 return to table of contents copyright jim kurose and keith w ross 1996-1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/atm.html  10 of 10  20/11/2004 15  52  43 t1 5.10 x.25 and frame relay in this section we discuss two end-to-end wide-area-networking  wan  technologies  namely  x.25 and frame relay introduced in the early 1980s and popular in europe up through the mid 1990s  x.25 is arguably the first public packetswitching technology frame relay  a successor to x.25  is another public packet-switching technology which has been popular in north america throughout the 1990s given that x.25 and frame relay are end-to-end wan technologies  you may be wondering why we are discussing them in a chapter that is devoted to the data-link layer ? we have chosen to discuss these technologies in this chapter for the same reason we chose to discuss atm in this chapter  all of these technologies are often employed today to carry ip datagrams from one ip router to another thus  from the perspective of ip  which is also an end-to-end wan technology   x.25  frame relay and atm are link layer technologies because ip is one of the protocols being highlighted in this book  we have put x.25  frame relay and atm were ip believes these technologies belong  namely  in the link layer although x.25 still exists throughout europe and in certain nitch markets in north america  the x.25 networks are on the verge of extinction throughout the world they were designed almost twenty years ago for a technological context that is very different from today 's frame relay had great appeal to corporate customers throughout the 1990s  but it is increasingly fighting fierce competition from the public internet in fact  due to this competition  frame relay may become a minor player in the mid 2000s even though x.25 is on its way out  if not already completely gone   and frame relay may disappear as well a few years down the road  we have chosen to cover these technologies in this book because of their immense historical importance 5.10.1 a few words about x.25 the x.25 protocol suite was designed in the late 1970s to understand the motivation behind the design  we need to understand the technological context of that ancient era although the apple ii personal computer was making a big hit at this time  nerds   pcs and workstations were not wide spread and did n't have much networking support instead  most people were using inexpensive " dumb terminals " to access distant mainframe over computer networks these dumb terminals had minimal intelligence and storage  no disks  ; what appeared on their screens was completely controlled by the mainframe at the other end of the network in order to widely support dumb terminals  the designers of x.25 decided to " put the intelligence in the network "  this philosophy  as we now know  very different from the internet philosophy  which puts intelligence in the end systems and assumes little about the network one way the designers put intelligence in the x.25 network was by employing virtual circuits in x.25 networks recall from chapter 1 that virtual-circuit networks require the packet switches to maintain state information in particular  the switch must maintain a table that maps inbound interface/vc-number to outbound interface/vc-number moreover  complex signalling protocols are needed to establish vcs and tear them down as we learned in chapter 4  the ip protocol is connectionless and  thus  does not use vcs when a node wants to send an ip packet into the network it just stamps the datagram with a destination address and injects it into the network ; it does not first request the network to establish a virtual circuit between itself and the destination another important part of the technological context of the late 1970s and early 1980s conerns the physical links in those days  almost all of the wired links were noisy  error-prone copper links fiber-optic links were only being researched in the laboratory at that time bit error rates over long-haul copper links were many orders of magnitude higher than they are now over fiber links because of the high error rates  it made sense to design x.25 protocol with file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/framerelay.htm  1 of 5  20/11/2004 15  52  44 t1 error recovery on a hop-by-hop basis in particular  whenever an x.25 switch sends a packet  it keeps a copy of the packet until the next switch  in the packet 's route  returns an acknwoledgement thus each switch  when receiving a packet  performs error checking  and if the packet is error-free it sends an acknowledgement to the previous switch hop-by-hop error recovery significantly reduces link transmission rates  but it is consistent with the technological context of the era  high link error rates and dumb terminals the x.25 design also calls for flow-control on a hop-byhop basis recall  that the tcp transport protocol performs error recovery and flow control on an end-to-end basis  and thereby does not require the links to perform these tasks 5.10.2 frame relay frame relay  designed in the late 1980s and widely deployed in the 1990s  is in many ways a second-generation x.25 like x.25  it uses virtual circuits however  because the fiber-based systems of 1990s had much lower bit error rates than the copper-based systems of the 1980s  frame relay was naturally designed for much lower error rates the essence of frame relay is a vc-based packet-switching service with no error recovery and no flow control whenever a frame relay switch detects an error in a packet  its only possible course of action is to discard the data this results in a network with lower processing overheads and higher transmission rates than x.25  but requires intelligent end systems for data integrity in most cases today  the frame relay network is owned by a public network service provider  e.g  at&t  sprint or bell atlantic  and its use is contracted on a multi-year basis to corporate customers frame relay is extensively used today to allow lans on different corporate campuses to send data to each other at reasonably high speeds as shown in figure 5.10-1  often frame relay interconnects these lans throguh ip routers  with each ip router in a different corporate campus frame relay offers a corporation an alternative to sending its inter-campus ip traffic over the public internet  for which the corporation may have reliability and security concerns figure 5.10-1  public frame relay network interconnected two ethernets through routers located on the ethernets the dotted line represents a virtual circuit frame relay networks can use either switched vcs  svcs  or permanent virtual circuits  pvc 's   for router interconnection  a pvc is often permanently established between each pair of routers n  n-1  /2 pvc 's are necessary to interconnect n routers throughout our discussion we shall assume that the frame relay network uses pvcs  which is the more common case   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/framerelay.htm  2 of 5  20/11/2004 15  52  44 t1 sending an ip datagram from ethernet to frame relay to ethernet consider the transmission of an ip datagram between two end systems on two ethernets interconnected by a frame relay network let us walk through the steps in the context of figure 5.9.1 when an ethernet frame arrives to the source router  the router 's ethernet card strips off the ethernet fields and passes the ip datagram to the network layer the network layer passes the ip datagram to the frame relay interface card this card encapsulates the ip datagram in the frame relay packet  as shown in figure 5.10-2 it also calculates the crc  2 bytes  and inserts the resulting value crc field the link layer field  2 bytes  includes a 10-bit virtual circuit number field the interface card obtains the vc number from a table that associates ip network numbers to vc numbers the interface card then transmits the packet figure 5.10-2  encapsulating user data  e.g  and ip datagram  into a frame relay frame the interface card transmits the frame relay packet onto a leased line  typically obtained from local telephone company  e.g bell atlantic   the leased line connects the router to a nearby frame relay switch  owned by the frame relay service provider  e.g sprint   the switch examines the fcs field if the frame has an error  the switch discards the frame ; unlike x.25  frame relay does not bother to retransmit packets on a hop-by-hop basis if there is no error in the frame  the switch uses the frame 's vc number to route the frame to the next switch  or to the destination router   the destination router removes the frame relay fields and then delivers the datagram over ethernet to the destination host if tcp segments are lost or arrive out of sequence  then tcp in the communicating hosts  intelligent end systems  correct the problem for more details about how an ip datagram is sent across and ip network  see  rfc 2427   committed information rate frame relay makes use of innovative mechanism referred to as the committed information rate  cir   every frame relay vc has a committed information rate we will define the cir rigorously below  but roughly the cir is a commitment on the part of the frame relay network to dedicate to the vc a specified transmission rate determined by the cir the cir servicet  introduced by frame relay in the early 1990s  is many ways a forerunner to the internet 's differentiated service  see chapter 6  as we shall shortly see  frame relay provides the cir service by marking packets in frame relay networks  frame relay packets can belong to one of two priority levels  either high priority or low priority packets are assigned priorities by marking a special bit in the packet header  the so-called discard eligibility  de  bit  to either 0 for high priority and 1 for low priority if a frame is a high-priority frame  then the frame relay file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/framerelay.htm  3 of 5  20/11/2004 15  52  44 t1 network should deliver the packet to the destination under all but the most desperate network conditions  including periods of congestion and backbone link failures however  for low priority packets  the frame relay network is permitted to discard the frame under congested conditions under particularly draconian conditions  the network can even discard high-priority packets congestion is typically measured by the state of output buffers in frame relay switches when an output buffer in a frame relay switch is about to overflow  the switch will first discard the low priority packets  that is  the packets in the buffer with the de bit set to 0 the actions that a frame-relay switch takes on the marked packets should be clear  but we have n't said anything about how packets get marked this is where the cir comes in to explain this  we need to introduce a little frame-relay jargon  which we do in the context of figure 5.9.1 the access rate is the rate of the access link  that is  the rate of the link from the source router to the " edge " frame relay switch this rate is often 64 kbps but integer multiples of 64 kbps up to 1.544 mbps are also common denote by r for the access rate as we learned in chapter 1  each packet sent over the link of rate r is transmitted at rate r bps the edge switch is responsible for marking packets that arrive from the source router to perform the marking  the edge switch examines the arrival times of packets from the source router over short  fixed intervals of time  called the measurement interval  denoted by tc most frame-relay service providers use a tc value that falls somewhere between 100 msecs and 1 sec now we can precisely describe the cir each vc that emanates from the source router  there may be many  possibly destined to different lans  is assigned a committed information rate  cir   which is in units of bits/sec the cir is never greater than r  the access rate customers pay for a specific cir ; the higher the cir  the more the customer pays to the frame-relay service provider if the vc generates packets at a rate that is less than the cir  than all of the vcs packets will be marked as high-priority packets  de = 0   however  if the rate at which the vc generates packets exceeds the cir  then the fraction of the vc 's packets that exceed the rate will be marked as low priority packets more specifically  over each measurement interval tc  for the first cir * tc bits the vc sends  the edge switch marks the corresponding packets as high-priority packets  de = 0   the edge switch marks all additional packets sent over this interval as low priority packets  de = 1   to get a feel for what is going on here  let us look at an example let us suppose that the frame-relay service provider uses a measurement interval of tc = 500 msec suppose that the access link is r = 64 kbps and that the cir assigned to a particular vc is 32 kbps also suppose  for simplicity  that each frame relay packet consists of exactly l = 4000 bits this means that every 500 msec the vc can send cir * tc/l = 4 packets as high-priority packets all additional packets sent within the 500 msec interval are marked as low priority packets note that up to 4 low-priority packets can be sent in over each 500 msec interval  in addition to 4 high-priority packets   because the frame network " almost " guarantees that all of the high-priority packets will be delivered to the destination frame-relay node  the vc is essentially guaranteed of a throughput of at least 32 kbps frame relay does not  however  make any guarantees about the end-to-end delays of either the high or low-priority packets increasing the measurement interval tc increases the potential burstiness of the high-priority packets emmitted from the source router in the previous example  if tc = .5 sec  up to four high-priority packets can be emmitted back-toback ; for tc = 1 sec  up to eight high-priority packets can be emmitted back-to-back when the frame relay network uses a smaller value of tc  it forces the stream of high priority packets to be smoother  less bursty  ; but a large value of tc gives the vc more flexibility but for every choice of tc  the long-run average rate of bits emmitted as high-priority bits never exceeds the cir of the vc we must keep in mind that many pvcs may emanate from the source router and travel over the access link it is interesting to note that the sum of the cirs for all these vcs is permitted to exceed the access rate  r this is referred to as overbooking because overbooking is permitted  an access link may transmit high-priority packets at a file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/framerelay.htm  4 of 5  20/11/2004 15  52  44 t1 corresponding bit rate that exceeds the cir  even though each individual vc sends prioirty packets at a rate that does not exceed the cir   we conclude this section by mentioning that the frame relay forum  frforum  maintains a number or relevant specifications an excellent introductory course for frame relay is made available on the hill associates web site  hill   walter goralski has also written a readable yet in depth book about frame relay  goralski   references  nerds  triumph of the nerds  web site for pbs television special  http  //www.pbs.org/nerds  frforum  frame relay forum  http  //www.frforum.com  hill  hill associates web site  http  //www.hill.com  goralski  w goralski  frame relay for high-speed networks  john wiley  new york  1999  rfc 2427  c brown and a malis  " multiprotocol interconnect over frame relay  " rfc 2427  september 1998 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/framerelay.htm  5 of 5  20/11/2004 15  52  44 chapter 5 summary 5.11 summary in this chapter  we 've examined the data link layer  its services  the principles underlying its operation  and a number of important specific protocols that use these principles in implementing data link services we saw that the basic service of the data link layer is to move a network-layer datagram from one node  router or host  to an adjacent node we saw that all data link protocols operate by encapsulating a network-layer datagram within a link-layer frame before transmitting the frame over the " link " to the adjacent node beyond this common framing function  however  we learned that different data link protocols can provide very different link access  delivery  reliability  error detection/correction   flow control  and transmission  e.g  full-duplex versus half-duplex  services these differences are due in part to the wide variety of link types over which data link protocols must operate a simple point-topoint link has a single sender and receiver communicating over a single " wire " a multiple access link is shared among many senders and receivers ; consequently the data link protocol for a multiple access channel has a protocol  its multiple access protocol  for coordinating link access in the cases of atm  x.25 and frame relay  we saw that the " link " connecting two adjacent nodes  e.g  two ip routers that are adjacent in an ip sense  that they are next-hop ip routers towards some destination   may actually be a network in and of itself in one sense  the idea of a network being considered as a " link " should not seem odd a telephone " link " connecting a home modem/computer to a remote modem/router  for example  is actually a path through a sophisticated and complex telephone network among the principles underlying data link communication  we examined error detection and correction techniques  multiple access protocols  link-layer addressing  and the construction of extended local area networks via hubs bridges  and switches in the case of error detection/correction  we examined how it is possible to add additional bits to a frame 's header that are used to detect  and in some cases correct  bitflip errors that might occur when the frame is transmitted over the link we covered simple parity and checksumming schemes  as well as the more robust cyclic redundancy check we then moved on to the topic of multiple access protocols we identified and studied three broad approaches for coordinating access to a broadcast channel  channel partitioning approaches  tdm  fdm  cdma   random access approaches  the aloha protocols  and csma protocols   and taking-turns approaches  polling and token passing   we saw that a consequence of having multiple nodes share a single broadcast channel was the need to provide node address at the data link level we learned that physical addresses were quite different from network-layer addresses  and that in the case of the internet  a special protocol  arp  the address resolution protocol  is used to translate between these two forms of addressing we then examined how nodes sharing a broadcast channel form a local area network  lan   and how multiple lans can be connected together to form larger lans  all without the intervention of network-layer routing to interconnect these local nodes finally  we covered a number of specific data link layer protocols in detail  ethernet  the wireless ieee 802.11 protocol  and the point-to-point protocol  ppp as discussed in sections 5.9 and 5.10  atm  x.25  and frame relay can also be used to connect two file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/ch5_summary.htm  1 of 2  20/11/2004 15  52  44 chapter 5 summary network-layer routers for example  in the ip-over-atm scenario  two adjacent ip routers can be connected to each other by a virtual circuit through an atm network in such circumstances  a network that is based on one network architecture  e.g  atm  or frame relay  can serve as a single logical link between two neighboring nodes  e.g  ip routers  in another network architecture having covered the data link layer  our journey down the protocol stack is now over ! certainly  the physical layer lies below the data link layer  but the details of physical layer is the topic probably best left for another course  e.g  in communication theory  rather than computer networking   we have  however  touched upon several aspects of the physical layer in this chapter  e.g  our brief discussions of manchester encoding in section 5.5 and of signal fading in section 5.7  and in chapter 1  our discussion of physical media in section 1.5   although our journey down the protocol stack is over  our study of computer networking is not yet over in the following three chapters we cover multimedia networking  network security  and network management these three topics do not fit conveniently into any one layer ; indeed  each topic crosscuts many layers understanding these topics  sometimes billed as " advanced topics " in some networking texts  thus requires a firm foundation in all layers of the protocol stack  a foundation that is now complete with our completed study of the data link layer ! copyright 1999 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...approach % 20featuring % 20the % 20internet/ch5_summary.htm  2 of 2  20/11/2004 15  52  44 chapter 5 homework problems chapter 5 homework problems and discussion questions review questions sections 5.1-5.3 1  if all the links in the internet were to provide the reliable-delivery service  would the tcp reliabledelivery service be completely redundant ? why or why not ? 2  what are some of possible services that a link-layer protocol can offer to the network layer ? which of these link-layer services have corresponding services in ip ? in tcp ? 3  suppose the information content of a packet is the bit pattern 1010101010101011 and an even parity scheme is being used what would be the value of the checksum field in a single parity scheme ? 4  suppose two nodes start to transmit at the same time a packet of length l over a broadcast channel of rate r denote the propagation delay between the two nodes as tprop will there be a collision if tprop < l/r ? why or why not ? 5  in section 5.2.1  we listed for desirable characteristics of a broadcast channel slotted aloha has which of these charateristics ? token passing has which of these characteristics ? 6  what are human cocktail analogies for polling  and token passing protocols ? 7  why would the token-ring protocol be inefficient if the lan has a very large perimeter ? 8  how big is the lan address space ? the ipv4 address space ? the ipv6 address space ? 9  suppose nodes a  b  and c each attach to the same broadcast lan  through their adapters   if a sends thousands of frames to b with each frame adddressed to the lan address of b  will c 's adapter process these frames ? if so  will c 's adapter pass the ip datagrams in these frames to c  i.e  the adapter 's parent node  ? how will your answers change if a sends frames with the lan broadcast address ? 10  why is an arp query sent within a broadcast frame ? why is an arp response sent within a frame with a specific lan address ? file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  1 of 9  20/11/2004 15  52  45 chapter 5 homework problems 11  for the network in figure 5.3-4  the router has two arp modules each with its own arp table is it possible that the same lan address appear in both tables ? 12  compare the frame structures for 10baset  100baset and gigabit ethernet how do they differ ? 13  suppose a 10 mbps adapter sends into a channel an infinite stream of 1s using manchester encoding the signal emerging from the adatper will have how many transitions per second ? 14  after the 5th collision  what is the probability that the value of k that a node chooses is 4 ? the result k = 4 corresponds to a delay of how many seconds on a 10 mbps ethernet 15  does the tc sublayer at the transmitter fill in any of the fields in the atm header ? which ones section 5.6 16  in the ieee 802.11 specification  the length of the sifs period must be shorter than the difs paeriod why ? 17  suppose the ieee 802.11 rts and cts frames were as long as the standard data and ack frames would there be any advantage to using the cts and rts frames ? why ? section 5.9 18  does the tc sublayer distinguish between different vcs at either the transmitter or receiver ? 19  why is it important for the tc sublayer in the transmitter to provide a continuous stream of cells when the pmd sublayer is cell based ? 20  does the tc sublayer at the transmitter fill in any of the fields in the atm header ? which ones ? problems 1  suppose the information content of a packet is the bit pattern 1010101010101011 and an even parity scheme is being used what would the value of the checksum field be for the case of a two-dimensional parity scheme ? your answer should be such that a minumum length checksum field is used 2  give an example  other than the one in figure 5.2-3 !  showing that two-dimensional parity checks can correct and detect a single bit error show by counterexample that a double bit error can not always be corrected show by example that some double bit errors can be detected file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  2 of 9  20/11/2004 15  52  45 chapter 5 homework problems 3  suppose the information portion of a packet  d in figure 5.2-1 contains 10 bytes consisting of the 8 bit unsigned binary representation of the integers 0 through 9 compute the internet checksum for this data 4  consider the 4-bit generator  g shown in figure 5.2-5  and suppose that d has the value 10101010 what is the value of r ? 5  consider the single sender cdma example in figure 5.3-4 what would be the sender 's output  for the two data bits shown  if the senders cdma code were  1  -1  1  -1  1  -1  1  -1  ? 6  consider sender 2 in figure 5.3-5 what is the sender 's output to the channel  before it is added to the signal from sender 1   zi,m 2 ? 7  suppose that the receiver in figure 5.3-5 wanted to receive the data being sent by sender 2 show  by calculation   that the receiver is indeed able to recover sender 2 's data from the aggregate channel signalby using sender 2 's code 8  in section 5.3  we provided an outline of the derivation of the efficiency of slotted aloha in this problem we ' 'll complete the derivation a  recall that when there are n active nodes the efficiency of slotted aloha is np  1-p  n-1 find the value of p that maximizes this expression b  using the value of p found in part  a   find the efficiency of slotted aloha by letting n approach infinity hint   1  1/n  n approches 1/e as n approaches infinity 9  show that the maximum efficiency of pure aloha is 1/  2e   note  this problem is easy if you have completed the problem above ! 10  graph the efficiency of slotted aloha and pure aloha as a function of p for n = 100 11  consider a broadcast channel with n nodes and a transmission rate of r bps suppose the broacast channel uses polling  with an additional polling node  for multiple access suppose the amount of time from when a node completes transmission until the subsequent node is permitted to transmit  i.e  the polling delay  is tpoll suppose that within a polling round  a given node is allowed to transmit at most q bits what is the maximum throughput of the broadcast channel 12  consider three lans interconnected by two routers  as shown in the diagram below a  redraw the diagram to include adapters b  assign ip addresses to all of the interfaces for lan 1 use addresses of the form 111.111.111 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  3 of 9  20/11/2004 15  52  45 chapter 5 homework problems xxx ; for lan 2 uses addresses of the form 122.222.222.xxx ; and for lan 3 use addresses of the form 133.333.333.xxx  c  assign lan addresses to all of the adapters d  consider sending an ip datagram from host a to host f suppose all the arp tables are up-todate enumerate all the steps as done for the single-router example in section 5.3.2 e  repeat  d   now assuming that the arp table in the sending host is empty  and the other tables are up-to-date   13  recall that with the csma/cd protocol  the adapter waits k * 512 bit times after a collision  where k is drawn randomly for k = 100  how long does the adapter wait until returning to step 2 for a 10 mbps ethernet ? for a 100 mbps ethernet ? 14  suppose nodes a and b are on the same 10 mbps ethernet segment  and the propagation delay between the two nodes is 225 bit times suppose node a begins transmitting a frame  and before it finishes station b begins transmitting a frame can a finish transmitting before it detects that b has transmitted ? why or why not ? if the answer is yes  then a incorrectly believes that its frame was successfully transmitted without a collision hint  suppose at time t = 0 bit times  a begins transmitting a frame in the worst case  a transmits a minimum size frame of 512 + 64 bit times so a would finish transmitting the frame at t = 512 + 64 bit times thus the answer is no if b 's signal reaches a before bit time t = 512 + 64 bits in the worst case  when does b 's signal reach a ? 15  suppose nodes a and b are on the same 10 mbps ethernet segment  and the propagation delay between the two nodes is 225 bit times suppose a and b send frames at the same time  the frames collide  and then a and b choose different values of k in the csma/cd algorithm assuming no other nodes are active  can the retransmissions from a and b collide ? for our purposes  it suffices to work out the following example suppose a and b begin transmission at t = 0 bit times they both detect collisions at t = 225 bit times they finish transmitting jam signal at t = 225 + 48 = 273 bit times suppose ka = 0 and file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  4 of 9  20/11/2004 15  52  45 chapter 5 homework problems kb = 1 at what time does b schedule its retransmission ? at what time does a begin transmission ?  note  the nodes must wait for an idle channel after returning to step 2 see protocol  at what time does a 's signal reach b ? does b refrain from transmitting at its scheduled time ? 16  consider a 100mbps 100bt ethernet in order to have an efficiency of .50  what should be the maximum distance between a node and the hub ? assume a frame length of 64 bytes and that there are no repeaters does this maximum distance also ensure that a transmitting node a will be able to detect whether any other node transmitted while a was transmitting ? why or why not ? how does your maximum distance compare to the actual 100 mbps standard ? 17  in this problem you will derive the efficiency of a csma/cd-like multiple access protocol in this protocol  time is slotted and all adapters are synchronized to the slots unlike slotted aloha  however  the length of a slot  in seconds  is much less than a frame time  the time to transmit a frame   let s be the length of a slot suppose all frames are of constant length l = k r s  where r is the transmission rate of the channel and k is a large integer suppose there are n nodes  each with an infinite number of frames to send we also assume that tprop < s  so that all nodes can detect a collision before the end of a slot time the protocol is as follows  l if for a given slot  no node has possession of the channel  all nodes contend for the channel ; in particular  each node transmits in the slot with probability p if exactly one node transmits in the slot  that node takes possession of the channel for the subsequent k-1 slots and transmits its entire frame l if some node has possession of the channel  all other nodes refrain from transmitting until the node that possesses the channel has finsished transmitting its frame once this node has transmitted its frame  all nodes contend for the channel note that the channel alternates between two states  the " productive state " which lasts exactly k slots  and the non-productive state which lasts for a random number of slots clearly  the channel efficiency is the ratio of k/  k + x   where x is the expected number of consecutive unproductive slots a  for fixed n and p  determine the efficiency of this protocol b  for fixed n  determine the p that maximizes the efficiency c  using the p  which is a function of n  found in part  b   determine the efficiency as n approaches infinity d  show that this efficiency approaches 1 as the frame length becomes large 18  suppose two nodes  a and b  are attached to opposite ends of a 900 m cable  and that they each have one frame of 1000 bits  including all headers and preambles  to send to each other both nodes attempt to transmit at time t = 0 suppose there are four repeaters between a and b  each inserting a 20 bit delay assume the transmission rate is 10 mbps  and csma/cd with backoff intervals of multiples of 512 bits is used after the first collision  a draws k = 0 and b draws k = 1 in the exponential backoff protocol ignore the jam signal file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  5 of 9  20/11/2004 15  52  45 chapter 5 homework problems a  what is the one-way propagation delay  including repeater delays  between a and b in seconds assume that the signal propragation speed is 2 * 108m/sec b  at what time  in seconds  is a 's packet completely delivered at b c  now suppose that only a has a packet to send and that the repeaters are replaced with bridges suppose that each bridge has a 20 bit processing delay in addition to a store-and-forward delay at what time in seconds is a 's packet delivered at b ? 19  consider the network shown below a  how many ip networks are there in the above figure ? provide class c ip addresses for all of the interfaces including the router interfaces b  provide lan addresses for all of the adaptors c  consider sending a datagram from host a to host f trace the steps assuming all the arp tables are up-to-date d  repeat c   but now assume that all arp tables are up to date  except for the arp tables in router  which are empty 20  you are to design a lan for the campus layout shown below file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  6 of 9  20/11/2004 15  52  45 chapter 5 homework problems you may use the following equipment  thin coax $ 1 per meter utp $ 1 per meter fiber optic cable  pair $ 2 per meter file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  7 of 9  20/11/2004 15  52  45 chapter 5 homework problems nic  thin coax ports $ 70 nic  utp port $ 70 2-port repeater $ 800 multiport repeater  8 thin coax ports  $ 1,500 multiport fiber repeater  6 fiber ports  $ 2,000 2-port bridge  any combo of thin coax  utp  fiber  $ 2,200 hub  36 utp ports $ 4,000 hub  6 fiber ports  24 utp ports $ 6,000 pentium file server  w/nos  max 30 users  $ 9,000 bridges always include interface cards you must respect the followng design requirements  1 each department must have access to the resources of all other departments 2 the traffic generated by users of one department can not affect another department 's lan unless accessing a resource on that other department 's lan 3 a file server can support only 30 users 4 file servers may not be shared by multiple departments 5 all repeaters  bridges  and hubs must reside in the wiring closets  wcs   a  you are required to use thin coax  no utp  and  if deemed necessary  fiber optics provide a diagram for your design also provide a list of the equipment you use  with quantities  and the total cost of the lan b  repeat  a   but using utp  no thin coax  and  if deemed necessary  fiber optics 21  suppose a frame-relay vc generates packets of fixed lenght l let r  tc and cir denote the access rate  the measurement interval and the committed information rate  respectively  a  as a function of these variables  determine how many high-priority packets the vc can send in a measurement interval  b  as a function of these variables  determine how many low-priority packets the vc can send in a measurement interval for part  b  assume that in each measurement interval  the vc first generates the maximum number of high-priority packets permitted and then generates low-priority packets file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  8 of 9  20/11/2004 15  52  45 chapter 5 homework problems 22  in figure 5.9.1  suppose the source ethernet includes a web server which is very busy serving requests from clients in the destination ethernet each http response message is carried in one or more ip datagrams when the ip datagrams arrive to the frame relay interface  each datagram is encapsulated in a frame-relay frame suppose that each web object is of size o and each frame-relay packet is of size l suppose that the web server begins to serve one object at the beginning of each measurement interval ignoring all packet overheads  at the application  transport  ip and frame-relay layers !   determine the maximum size of o  as a function of tc  cir and l  such that each object is entirely carried by high-priority frame-relay packets discussion questions you are encouraged to surf the web in answering the following questions 1  roughly,what is the current price range of a 10 mbps ethernet adapter ? of a 10/100 mbps adapter ? of a gigabit ethernet adapter ? 2  hubs and switches are often priced in terms of number of interfaces  also called ports in lan jargon   roughly  what is current per-interface price range for a 10 mbps hub ? for a 100 mbps hub ? for a switch consisting of only 10 mbps interfaces ? for a switch consisting of only 100 mbps interfaces ? 3  many of the functions of an adapter can be performed in software that runs on the node 's cpu what are the advantages and disadvantages of moving this functionality from the adapter to the node ? 4  use the web to find the protocol numbers used in a ethernet frame for ip and arp 5  is some form of arp protocol necessary for ip over frame relay ? why or why not ? file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/additional.htm  9 of 9  20/11/2004 15  52  45 introduction 6.1 multimedia networking applications back in chapter 2 we examined the web  file transfer  and electronic mail in some detail the data carried by these networking applications is  for the most part  static content such as text and images when static content is sent from one host to another  it is desirable for the content to arrive at the destination as soon as possible nevertheless  moderately long end-to-end delays  up to tens of seconds  are often tolerated for static content in this chapter we consider networking applications whose data contains audio and video content we shall refer to networking applications as multimedia networking applications  some authors refer to these applications continuous-media applications  multimedia networking applications are typically highly sensitive to delay ; depending on the particular multimedia networking application  packets that incur more than an x second delay  where x can range from a 100 msecs to five seconds  are useless on the otherhand  multimedia networking applications are typically loss tolerant ; occassional loss only causes occassional glitches in the audio/video playback  and often these losses can be partially or fully concealed thus  in terms of service requirements  multimedia applications are diametrically opposite of static-content applications  multimedia applications are delay sensitive and loss tolerant whereas the static-content applications are delay tolerant and loss intolerant 6.1.1 examples of multimedia applications the internet carries a large variety of exciting multimedia applications below we define three classes of multimedia applications 1 streaming stored audio and video  in this class of applications  clients request on-demand compressed audio or video files  which are stored on servers for audio  these files can contain a professor 's lectures  rock songs  symphonies  archives of famous radio broadcasts  as well as historical archival recordings for video  these files can contain video of professors ' lectures  fulllength movies  prerecorded television shows  documentaries  video archives of historical events  video recordings of sporting events  cartoons and music video clips at any time a client machine can request an audio/video file from a server in most of the existing stored audio/video applications  after a delay of a few seconds the client begins to playback the audio file while it continues to receive the file from the server the feature of playing back audio or video while the file is being received is called streaming many of the existing products also provide for user interactivity  e.g  pause/resume and temporal jumps to the future and past of the audio file the delay from when a user makes a request  e.g  request to hear an audio file or skip two-minutes forward  until the action manifests itself at the the user host  e.g  user begins to hear audio file  should be on the order of 1 to 10 seconds for acceptable responsiveness requirements for packet delay and jitter are not as stringent as those for real-time applications such as internet telephony and real-time video conferencing  see below   there are many streaming products for stored file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  1 of 7  20/11/2004 15  52  46 introduction audio/video  including realplayer from realnetworks and netshow from microsoft 2 one to many streaming of real-time audio and video  this class of applications is similar to ordinary broadcast of radio and television  except the transmission takes place over the internet these applications allow a user to receive a radio or television transmission emitted from any corner of the world  for example  one of the authors of this book often listens to his favorite philadelphia radio stations from his home in france  microsoft provides an internet radio station guide typically  there are many users who are simultaneously receiving the same real-time audio/ video program this class of applications is non-interactive ; a client can not control a server 's transmission schedule as with streaming of stored multimedia  requirements for packet delay and jitter are not as stringent as those for internet telephony and real-time video conferencing delays up to tens of seconds from when the user clicks on a link until audio/video playback begins can be tolerated distribution of the real-time audio/video to many receivers is efficiently done with multicast ; however  as of this writing  most of the one-to-many audio/video transmissions in the internet are done with separate unicast streams to each of the receivers 3 real-time interactive audio and video  this class of applications allows people to use audio/ video to communicate with each other in real-time real-time interactive audio is often referred to as internet phone  since  from the user 's perspective  it is similar to traditional circuitswitched telephone service internet phone can potentially provide pbx  local and long-distance telephone service at very low cost it can also facilitate computer-telephone integration  so called cti   group real-time communication  directory services  caller identification  caller filtering  etc there are many internet telephone products currently available.with real-time interactive video  also called video conferencing  individuals communicate visually as well as orally during a group meeting  a user can open a window for each participant the user is interested in seeing there are also many real-time interactive video products currently available for the internet  including microsoft 's netmeeting note that in a real-time interactive audio/video application  a user can speak or move at anytime the delay from when a user speaks or moves until the action is manifested at the receiving hosts should be less than a few hundred milliseconds for voice  delays smaller than 150 milliseconds are not perceived by a human listener  delays between 150 and 400 milliseconds can be acceptable  and delays exceeding 400 milliseconds result frustrating if not completely unintilligible voice conversations one-to-many real-time audio and video is not interactive  a user can not pause or rewind a transmission that hundreds of others listen to although streaming stored audio/video allows for interactive actions such as pause and rewind  it is not real-time  since the content has already been gathered and stored on hard disks finally  real-time interactive audio/video is interactive in the sense that participants can orally and visually respond to each other in real time 6.1.2 hurdles for multimedia in the internet ip  the internet 's network-layer protocol  provides a best-effort service to all the datagrams it carries in other words  the internet makes its best effort to move each datagram from sender to receiver as quickly as possible however  the best-effort service does not make any promises whatsoever about the end-tofile  /// d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  2 of 7  20/11/2004 15  52  46 introduction end delay for an individual packet nor does the service make any promises about the variation of pakcet delay within a packet stream as we learned in chapter 3  because tcp and udp run over ip  neither of these protocols can make any delay guarantees to invoking applications due to the lack of any special effort to deliver packets in a timely manner  it is extermely challenging problem to develop successful multimedia networking applications for the internet to date  multimedia over the internet has achieved significant but limited success for example  streaming store audio/video with user-interactivity delays of five-to-ten seconds is now commonplace in the internet but during peak traffic periods  performance may be unsatisfactory  particularly when intervening links are congested links  such as congested transoceanic link   internet phone and real-time interactive video has  to date  been less successful than streaming stored audio/video indeed  real-time interactive voice and video impose rigid constraints on packet delay and packet jitter packet jitter is the variability of packet delays within the same packet stream real-time voice and video can work well in regions where bandwidth is plentiful  and hence delay and jitter are minimal but quality can deteriorate to unacceptable levels as soon as the real-time voice or video packet stream hits a moderately congested link the design of multimedia applications would certainly be more straightforward if their were some sort of first-class and second-class internet services  whereby first-class packets are limited in number and always get priorities in router queues such a first-class service could be satisfactory for delay-sensitive applications but to date  the internet has mostly taken an egalitarian approach to packet scheduling in router queues  all packets receive equal service ; no packets  including delay-sensitive audio and video packets  get any priorities in the router queues no matter how much money you have or how important you are  you must join the end of the line and wait your turn ! so for the time being we have to live with the best effort service no matter how important or how rich we are  our packets have to wait their turn in router queues but given this constraint  we can make several design decisions and employ a few tricks to improve the user-perceived quality of a multimedia networking application for example  we can send the audio and video over udp  and thereby circumvent tcp 's low throughput when tcp enters its slow-start phase we can delay playback at the receiver by 100 msecs or more in order to diminish the effects of network-induced jitter we can timestamp packets at the sender so that the receiver knows when the packets should be played back for stored audio/video we can prefetch data during playback when client storage and extra bandwidth is available we can even send redundant information in order to mitigate the effects of network-induced packet loss we shall investigate many of these techniques in this chapter 6.1.3 how should the internet evolve to better support multimedia ? today there is a tremendous  and sometimes ferocious  debate about how the internet should evolve in order to better accommodate multimedia traffic with its rigid timing constraints at one extreme  some researchers argue that it is n't necessary to make any fundamental changes to the best-effort service file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  3 of 7  20/11/2004 15  52  46 introduction and the underlying internet protocols instead  according to these extremists  it is only necessary to add more bandwidth to the links  along with network caching for stored information and multicast support for one-to-many real-time streaming   opponents to this viewpoint argue that additional bandwidth can be costly  and as soon as it is put in place it will be eaten up by new bandwidth hungry applications  e.g  high-definition video on demand   at the other extreme  some researchers argue that fundamental changes should be made to the internet so that applications can explicitly reserve end-to-end bandwidth these researchers feel  for example  that if a user wants to make an internet phone call from host a to host b  then the user 's internet phone application should be able to explicitly reserve bandwidth in each link along a route from host a to host b but allowing applications to make reservations and requiring the network to honor the reservations requires some big changes first we need a protocol that  on the behalf of applications  reserves bandwidth from the senders to their receivers second  we need to modify scheduling policies in the router queues so that bandwidth reservations can be honored with these new scheduling policies  all packets no longer get equal treatment ; instead  those that reserve  and pay  more get more third  in order to honor reservations  the applications need to give the network a description of the traffic that they intend to send into the network the network must then police each application 's traffic to make sure that it abides to the description finally  the network must have a means of determining whether it has sufficient available bandwidth to support any new reservation request these mechanisms  when combined  require new and complex software in the hosts and routers as well as new types of services there is a camp inbetween the two extremes  the so-called differentiated services camp this camp wants to make relatively small changes at the network and transport layers  and introduce simple pricing and policing schemes at the edge of the network  i.e  at the interface between the user and the user 's isp   the idea is to introduce a small number of classes  possibly just two classes   assign each datagram to one of the classes  give datagrams different levels of service according to their class in the router queues  and charge users to reflect the class of packets that they are emitting into the network a simple example of a differentiated-services internet is as follows by toggling a single bit in the datagram header  all ip datagrams are labeled as either first-class or second-class datagrams in each router queue  each arriving first class datagram jumps in front of all the second-class datagrams ; in this manner  second-class datagrams do not interfere with first-class datagrams  it as if the first-class packets have their own network ! the network edge counts the number of first-class datagrams each user sends into the network each week when a user subscribes to an internet service  it can opt for a " plantinum service " whereby the user is permitted to send a large but limited number of first-class datagrams into the network each week ; first-class datagrams in excess of the limit are converted to second-class datagrams at the network edge a user can also opt for a " low-budget " service  whereby all of his datagrams are second-class datagrams of course  the user pays a higher subscription rate for the plantinum service than for the low-budget service finally  the network is dimensioned and the firstclass service is priced so that " almost always " first-class datagrams experience insignificant delays at all router queues in this manner  sources of audio/video can subscribe to the first-class service  and thereby receive " almost always " satisfactory service we will cover differentiated services in section 6.8 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  4 of 7  20/11/2004 15  52  46 introduction 6.1.4 audio and video compression before audio and video can be transmitted over a computer network  it has to be digitized and compressed the need for digitization is obvious  computer networks transmit bits  so all transmitted information must be represented as a sequence of bits compression is important because uncompressed audio and video consumes a tremendous amount of storage and bandwidth ; removing the inherent redundancies in digitized audio and video signals can reduce by orders of magnitude the amount the data that needs to be stored and transmitted as an example  a single image consisting of 1024 pixels x 1024 pixels with each pixel encoded into 24 bist requires 3 mb of storage without compression it would take seven minutes to send this image over a 64 kbps link if the image is compressed at a modest 10  1 compression ratio  the storage requirement is reduced to 300 kb and the transmission time drops to under 6 seconds the fields of audio and video compression are vast they have been active areas of research for more than 50 years  and there are now literally hundreds of popular techniques and standards for both audio and video compression most universities offer entire courses on audio and video compression  and often offer a separate course on audio compression and a separate course on video compression furthermore  electrical engineering and computer science departments often offer independent courses on the subject  with each department approaching the subject from a different angle we therefore only provide here a brief and high-level introduction to the subject audio compression in the internet a continuously-varying analog audio signal  which could emanate from speech or music  is normally converted to a digital signal as follows  l the analog audio signal is first sampled at some fixed rate  e.g  at 8,000 samples per second the value of each sample is an arbitrary real number l each of the samples is then " rounded " to one of a finite number of values this operation is referred to as " quantization "  the number of finite values  called quantization values  is typically a power of 2  e.g  256 quantization values l each of the quantization values is represented by a fixed number of bits for example if there are 256 quantization values  then each value  and hence each sample  is represented by 1 byte each of the samples is converted to its bit representation the bit representations of all the samples are concatenated together to form the digital representation of the signal as an example  if an analog audio signal is sampled at 8,000 samples per second  each sample is quantized and represented by 8 bits  then the resulting digital signal will have a rate of 64,000 bits per second this digital signal can then be converted back  i.e  decoded  to an analog signal for playback however  the decoded analog signal is typically different from the original audio signal by increasing the sampling rate and the number of quantization values the decoded signal can approximate  and even be exactly equal to  the original analog signal thus  there is a clear tradeoff between the quality of the file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  5 of 7  20/11/2004 15  52  46 introduction decoded signal and the storage and bandwidth requirements of the digital signal the basic encoding technique that we just described is called pulse code modulation  pcm   speech encoding often uses pcm  with a sampling rate of 8000 samples per second and 8 bits per sample  giving a rate of 64 kbs the audio compact disk  cd  also uses pcm  without a sampling rate of 44,100 samples per second with 16 bits per sample ; this gives a rate of 705.6 kbps for mono and 1.411 mbps for stereo a bit rate of 1.411 mbps for stereo music exceeds most access rates  and even 64 kbps for speech exceeds the access rate for a dial-up modem user for these reasons  pcm encoded speech and music is rarely used in the internet instead compression techniques are used to reduce the bit rates of the stream popular compression techniques for speech include gsm  13 kbps   g.729  8.5 kbps  and g.723  both 6.4 and 5.3 kbps   and also a large number of proprietary techniques  including those used by realnetworks a popular compression technique for near cd-quality stereo music is mpeg layer 3  more commonly known as mp3 mp3 compresses the bit rate for music to 128 or 112 kbps  and produces very little sound degradation an mp3 file can be broken up into pieces  and each piece is still playable this headerless file format allows mp3 music files to be streamed across the internet  assuming the playback bitrate and speed of the internet connection are compatible   the mp3 compression standard is complex ; it uses psychoacoustic masking  redundancy reduction and bit reservoir buffering video compression in the internet a video is a sequence images  with each image typically being displayed at a constant rate  for example at 24 or 30 images per second an uncompressed  digitally encoded image consists of an array of pixels  with each pixel encoded into a number of bits to respresent luminance and color there are two types of redundancy in video  both of which can be exploited for compression spatial redundancy is the redundancy within a given image for example  an image that consists of mostly white space can be efficiently compressed temporal redundancy reflects repitition from image to subsequent image if  for example  an image and the subsequent image are exactly the same  there is no reason re-encode the subsequent image ; it is more efficient to simply indicate during encoding the subsequent image is exactly the same the mpeg compression standards are among the most popular compression techniques these include mpeg 1 for cd-rom quality video  1.5 mbps   mpeg2 for high-quality dvd video  3-6 mbps  and mpeg 4 for object-oriented video compression the mpeg standard draws heavily from the jpeg standard for image compression the h.261 video compression standards are also very popular in the internet  as well are numerous proprietary standards readers interested in learning more about audio and video encoding are encouraged to see  rao  and  solari   also  paul amer maintains a nice set of links to audio and video compression file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  6 of 7  20/11/2004 15  52  46 introduction references  rao  k.r rao and j.j hwang  techniques and standards for image  video and audio coding  prentice hall  1996  solari  s.j solari  digital video and audio compression  mcgraw hill text  1997 return to table of contents copyright 1996 2000 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/multimedia.htm  7 of 7  20/11/2004 15  52  46 introduction 6.2 streaming stored audio and video in recent years  audio/video streaming has become a popular class of applications and a major consumer of network bandwidth we expect this trend to continue for several reasons first  the cost of disk storage is decreasing at phenomenal rates  even faster than processing and bandwidth costs ; the cheap storage will lead to an exponential increase in the amount of stored/audio video in the internet second  improvements in internet infrastructure  such as high-speed residential access  i.e  cable modems and adsl as discussed in chapter 1  network caching of video  see section 2.2   and a new qos-oriented internet protocols  see sections 6.5-6.9  will greatly facilitate the distribution of stored audio and video and third  there is an enormous pent-up demand for high quality video streaming  an application which combines two existing killer communication technologies  television and the on-demand web in audio/video streaming  clients request compressed audio/video files  which are resident on servers as we shall discuss in this section  the servers can be " ordinary " web servers  or can be special streaming servers tailored for the audio/video streaming application the files on the servers can contain any type of audio/video content  including a professor 's lectures  rock songs  movies  television shows  recorded sporting events  etc upon client request  the server directs an audio/video file to the client by sending the file into a socket  sockets are discussed in sections 2.6-2.7  both tcp and udp socket connections are used in practice before sending the audio/video file into the network  the file may is segmented  and the segments are typically encapsulated with special headers appropriate for audio/video traffic real-time protocol  rtp   discussed in section 6.4  is a public-domain standard for encapsulating the segments once the client begins to receive the requested audio/video file  the client begins to render the file  typically  within a few seconds most of the existing products also provide for user interactivity  e.g  pause/resume and temporal jumps to the future and past of the audio/video file user interactivity also requires a protocol for client/server interaction real time streaming protocol  rtsp   discussed at the end of this section  is a public-domain protocol for providing user interactivity audio/video streaming is often requested by users through a web client  i.e  browser   but because audio/video play out is not integrated directly in today 's web clients  a separate helper application is required for playing out the audio/video the helper application is often called a media player  the most popular of which are currently realnetworks ' real players and the microsoft windows media player the media player performs several functions  including  l decompresssion  audio/video is almost always compressed to save disk storage and network bandwidth a media player has to decompress the audio/video on the fly during play out l jitter-removal  packet jitter is the variability of packet delays within the same packet stream packet jitter  if not suppressed  can easily lead to unintelligible audio and video as we shall examine in some detail in section 6.3  packet jitter can often be limited by buffering audio/ video for a few seconds at the client before playback l error correction  due to unpredictable congestion in the internet  a fraction of packets in the packet stream can be lost if this fraction becomes too large  user perceived audio/video quality becomes unacceptable to this end  many streaming systems attempt to recover from losses by either  i  reconstructing loss packets through the transmission of redundant packets   ii  by having the client explicitly request retransmissions of lost packets   iii  or both l graphical user interface with control knobs  this is the actual interface that the user interacts with it typically includes volume controls  pause/resume buttons  sliders for making temporal jumps in the audio/video stream  etc plug-ins may be used to embed the user interface of the media player within the window of the web browser for such embeddings  the browser reserves screen space on the current web page  and it is up to the media player to manage the screen space but either appearing in a separate window or within the browser window  as a plug-in   the media player is a program that is being executed separately from the browser 6.2.1 acessing audio and video from a web server the stored audio/video can either reside on a web server  which delivers the audio/video to the client over http ; or on an audio/video streaming server  which delivers the audio/video over non-http protocols  protocols that can be either proprietary or in the public domain   in this subsection we examine the delivery of audio/video from a web server ; in the next subsection  we examine the delivery from a streaming server consider first the case of audio streaming when an audio file resides on a web server  the audio file is an ordinary object in the server 's file system  just as are html and jpeg files when a user wants to hear the audio file  its host establishes a tcp connection with the web server and sends an http request for the object  see section 2.2  ; upon receiving such a request  the web server bundles the audio file in an http response message and sends the response message back into the tcp connection the case of video can be a little more tricky  only because the audio and video parts of the " video " may be stored in two different files  that is  they may be two different objects in the web server 's file system in this case  two separate http requests are sent to the server  over two separate tcp connections for http/1.0   and the audio and video files arrive at the client in parallel it is up to the client to manage the synchronization of the two streams it is also possible that the audio and video are interleaved in the same file  so that only one object has to be sent to the client to keep the discussion simple  for the case of " video " we assume that the audio and video is contained in one file for the remainder of this section file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  1 of 7  20/11/2004 15  52  47 introduction a naive architecture for audio/video streaming is shown in figure 6.2.1 in this architecture  1 the browser process establishes a tcp connection with the web server and requests the audio/video file with an http request message 2 the web server sends to the browser the audio/video file in an http response message 3 the content-type  header line in the http response message indicates a specific audio/video encoding the client browser examines the content-type of the response message  launches the associated media player  and passes the file to the media player 4 the media player then renders the audio/video file figure 6.2-1 a naive implementation for audio streaming although this approach is very simple  it has a major drawback  the media player  i.e  the helper application  must interact with the server through the intermediary of a web browser this can lead to many problems in particular  when the browser is an intermediary  the entire object must be downloaded before the browser passes the object to a helper application ; the resulting initial delay is typically unacceptable for audio/video clips of moderate length for this reason  audio/video streaming implementations typically have the server send the audio/video file directly to the media player process in other words  a direct socket connection is made between the server process and the media player process as shown in figure 6.2 2  this is typically done by making use of a meta file  which is a file that provides information  e.g  url  type of encoding  etc  about the audio/ video file that is to be streamed file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  2 of 7  20/11/2004 15  52  47 introduction figure 6.2-2 web server sends audio/video directly to the media player a direct tcp connection between the server and the media player is obtained as follows  1 the user clicks on a hyperlink for an audio/video file 2 the hyperlink does not point directly to the audio/video file  but instead to a meta file the meta file contains the the url of the actual audio/ video file the http response message that encapsulates the meta file includes a content-type  header line that indicates the specific audio/video application 3 the client browser examines the content-type header line of the response message  launches the associated media player  and passes the entity body of the response message  i.e  the meta file  to the media player 4 the media player sets up a tcp connection directly with the http server the media player sends an http request message for the audio/ video file into the tcp connection 5 the audio/video file is sent within an http response message to the media player the media player streams out the audio/video file the importance of the intermediate step of acquiring the meta file is clear when the browser sees the content-type for the file  it can launch the appropriate media player  and thereby have the media player directly contact the server we have have just learned how a meta file can allow a media player to dialogue directly with a web server housing an audio/video yet many companies that sell products for audio/video streaming do not recommend the architecture we just described this is because the architecture has the media player communicate with the server over http and hence also over tcp http is often considered insufficiently rich to allow for satisfactory user interaction with the server ; in particular  http does not easily allow a user  through the media server  to send pause/resume  fastforward and temporal jump commands to the server tcp is often considered inappropriate for audio/video streaming  particularly when users are behind slow modem links this is because  upon packet loss  the tcp sender rate almost comes to a halt  which can result in extended periods of time during which the media player is starved nevertheless  audio and video is often streamed from web servers over tcp with satisfactory results 6.2.2 sending multimedia from a streaming server to helper application in order to get around http and/or tcp  the audio/video can be stored on and sent from a streaming server to the media player this streaming server could be a proprietary streaming server  such as those marketed by realnetworks and microsoft  or could be a public-domain streaming server with a streaming server  the audio/video can be sent over udp  rather than tcp  using application-layer protocols that may be tailored to audio/video streaming than is http this architecture requires two servers  as shown in figure 6.2-3 one server  the http server  serves web pages  including meta files   the second server  the streaming server  serves the audio/video files the two servers can run on the same end system or on two distinct end systems  if the web server is very busy serving web pages  it may be advantageous to put the streaming server on its own machine  the steps for this architecture are similar to those described in the previous architecture however  now the media player requests the file from a streaming server rather than from a web server  and now the media player and streaming server can interact using their own protocols these protocols can allow for rich user file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  3 of 7  20/11/2004 15  52  47 introduction interaction with the audio/video stream furthermore  the audio/video file can be sent to the media player over udp instead of tcp figure 6.2-3 streaming from a streaming server to a media player in the architecture of figure 6.2-3  there are many options for delivering the audio/video from the streaming server to the media player a partial list of the options is given below  1 the audio/video is sent over udp at a constant rate equal to the drain rate at the reciever  which is the encoded rate of the audio/video   for example  if the audio is compressed using gsm at a rate of 13 kbps  then the server clocks out the compressed audio file at 13 kbps as soon as the client receives compressed audio/video from the network  it decompresses the audio/video and plays it back 2 this is the same as option 1  but the media player delays play out for 2-5 seconds in order to eliminate network induced jitter the client accomplishes this task by placing the compressed media that it receives from the network into a client buffer  as shown in figure 6.2-4 once the client has " prefetched " a few seconds of the media  it begins to drain the buffer for this and the previous option  the drain rate d is equal to the fill rate x  t   except when there is packet loss  in which case x  t  is less momentarily less than d 3 the audio is sent over tcp and the media player delays play out for 2-5 seconds the server passes data to the tcp socket at a constant rate equal to the receiver drain rate d tcp retransmits lost packets  and thereby possibly improves sound quality but the fill rate x  t  now fluctuates with time due to tcp slow start and window flow control  even when there is no packet loss if there is no packet loss  the average fill rate should be approximately equal to the drain rate d furthermore  after packet loss tcp congestion control may reduce the instantaneous rate to less than d for long periods of time this can can empty the client buffer and introduce undesirable pauses into the output of the audio/video stream at the client 4 this is the same as option 3  but now the media player uses a large client buffer  large enough to hold the much if not all of the audio/video file  possibly within disk storage   the server pushes the audio/video file into its tcp socket as quickly as it can ; the client reads from its tcp socket as quickly as it can  and places the decompressed audio video into the large client buffer in this case  tcp makes use of all the instantaneous bandwidth available to the connection  so that at times x  t  can be much larger than d when the instantaneous bandwidth drops below the drain rate  the receiver does not experience loss as long as the client buffer is nonempty file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  4 of 7  20/11/2004 15  52  47 introduction figure 6.2-4 client buffer being filled at rate x  t  and drained at rate d 6.2.3 real time streaming protocol  rtsp  audio  video and smil presentations  etc  are often referred to as continuous media  smil stands for synchronized multimedia integration language ; it is a document language standard  as is html as its name suggests  smil defines how continuous media objects  as well as static objects  are synchronized in a presentation that unravels over time an indepth discussion of smil is beyond the scope of this book  users typically want to control the playback of continous media by pausing playback  repositioning playback to a future or past point of time  visual fast-forwarding playback  visual rewinding playback  etc this functionality is similar to what to a user has with a vcr when watching a video cassette or with a cd player when listening to cd music to allow a user to control playback  the media player and server need a protocol for exchanging playback control information rtsp  defined in  rfc 2326   is such a protocol but before getting into the details of rtsp  let us indicate what rtsp does not do  l rtsp does not define compression schemes for audio and video l rtsp does not define the how audio and video is encapusalated in packets for transmission over a network ; encapsulation for streaming media can be provided by rtp or by a proprietary protocol  rtp is discussed in section 6.4  for example  realmedia ? s g2 server and player use rtsp to send control information to each other but the media stream itself can be encapsulated rtp packets or with some proprietary realnetworks scheme l rtsp does not restrict how the the streamed media is transported ; it can be transported over udp or tcp l rtsp does not restrict how the media player buffers the audio/video the audio/video can be played out as soon as it begins to arrive at the client  it can be played out after a delay of a few seconds  or it can be downloaded in its entirety before play out so if rtsp does n't do any of the above  what does rtsp do ? rtsp is a protocol that allows a media player to control the transmission of a media stream as mentioned above  control actions inlcude pause/resume  repositioning of playback  fast forward and rewind rtsp is a so-called out-ofband protocol in particular  the rtsp messages are sent out-of-band  whereas the media stream  whose packet structure is not defined by rtsp  is considered ? in-band ?  the rtsp messages use different port numbers than the media stream rtsp uses port number 554  if the rtsp messages were to use the same port numbers as the media stream  then rtsp messages would be said to be ? interleaved ? with the media stream  the rtsp specification  rfc 2326  permits rtsp messages to be sent either over tcp or udp recall from section 2.3 that file transfer protocol  ftp  also uses the out-of-band notion in particular  ftp uses two client/server pairs of sockets  each pair with its own port number  one client/server socket pair supports a tcp connection that transports control information ; the other client/ server socket pair supports a tcp connection that actually transports the file the control tcp connection is the so-called out-of-band channel whereas the tcp connection that transports the file is the so-called data channel the out-of-band channel is used for sending remote directory changes  remote file deletion  remote file renaming  file download requests  etc the inband channel transports the file itself the rtsp channel is in many ways similar to ftp 's control channel let us now walk through a simple rtsp example  which is illustrated in figure 6.2-5 the web browser first requests a presentation description file from a web server the presentation description file can have references to several continous-media files as well as directives for syncrhonization of the continuous-media files each reference to a continuous-media file begins with the the url method  rtsp  //  below we provide a sample presentation file  which has been adapted from the paper  schulzrinne   in this presentation  an audio and video stream are played in parallel and in lipsync  as part of the same " group "   for the audio stream  the media player can choose  " switch "  among two audio recordings  a low fidelity recording and a hi fidelity recording file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  5 of 7  20/11/2004 15  52  47 introduction < title > twister < /title > < session > < group language = en lipsync > < switch > < track type = audio e = " pcmu/8000/1 " src = " rtsp  //audio.example.com/twister/audio.en/lofi " > < track type = audio e = " dvi4/16000/2 " pt = " 90 dvi4/8000/1 " src = " rtsp  //audio.example.com/twister/audio.en/hifi " > < /switch > < track type = " video/jpeg " src = " rtsp  //video.example.com/twister/video " > < /group > < /session > the web server encapsulates the presentation description file in an http response message and sends the message to the browser when the browser receives the http response message  the browser invokes a media player  i.e  the helper application  based on the content-type  field of the message the presentation description file includes references to media streams  using the url method rtsp  //  as shown in the above sample as shown in figure 6.2-4  the player and the server then send each other a series of rtsp messages the player sends an rtsp setup request  and the server sends an rtsp setup response the player sends an rtsp play request  say  for lofi auido  and server sends rtsp play response at this point  the streaming server pumps the lofi audio into its own in-band channel later  the media player sends an rtsp pause request  and the server responds with an rtsp pause response when the user is finished  the media player sends an rtsp teardown request  and the server responds with an rtsp teardown response figure 6.2-4 interaction between client and server using rtsp each rtsp session has a session identifier  which is chosen by the server the client initiates the session with the setup request  and the server file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  6 of 7  20/11/2004 15  52  47 introduction responds to the request with an identifier the client repeats the session identifier for each request  until the client closes the session with the teardown request the following is a simplified example of an rtsp session  c  setup rtsp  //audio.example.com/twister/audio rtsp/1.0 transport  rtp/udp ; compression ; port = 3056 ; mode = play s  rtsp/1.0 200 1 ok session 4231 c  play rtsp  //audio.example.com/twister/audio.en/lofi rtsp/1.0 session  4231 range  npt = 0 c  pause rtsp  //audio.example.com/twister/audio.en/lofi rtsp/1.0 session  4231 range  npt = 37 c  teardown rtsp  //audio.example.com/twister/audio.en/lofi rtsp/1.0 session  4231 s  200 3 ok notice that in this example  the player choose not to playback the complete present  but instead only hte lofi portion of the presentation the rtsp protocol is actually capable of doing much more than described in this brief introduction in particular  rtsp has facilities that allows clients to stream towards the server  e.g  for recording   rtsp has been adapted by realnetworks  currently the industry leader in audio/video streaming realnetworks makes available a nice page on rtsp  realnetworks   references  schulzrinne  h schulzrinne  " a comprehensive multimedia control architectuure for the internet  " nossdav'97  network and operating system support for digital audio and video   st louis  missouri ; may 19  1997 online version available  realnetworks  rtsp resource center  http  //www.real.com/devzone/library/fireprot/rtsp/  rfc 2326  h schulzrinne  a rao  r lanphier  " real time streaming protocol  rtsp  "  rfc 2326  april 1998 return to table of contents copyright 1996-2000 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ch % 20featuring % 20the % 20internet/audiovideooverweb.html  7 of 7  20/11/2004 15  52  47 introduction 6.3 making the best of the best-effort service  an internet phone example the internet 's network layer protocol  ip  provides a best-effort service that is to say that the internet makes its best effort to move each datagram from source to destination as quickly as possible however  the best-effort service does not make any promises whatsoever on the extent of the endto end delay for an individual packet  or on the extent of packet jitter and packet loss within the packet stream real-time interactive multimedia applications  such as internet phone and real-time video conferencing  are acutely senstive to packet delay  jitter and loss fortunately  designers of these applications can introduce several useful mechanisms that can preserve good audio and video quality as long as delay  jitter and loss are not excessive in this section we examine some of these mechanisms to keep the discussion concrete  we discuss these mechanisms in the context of an internet phone application  described in the paragraph below the situation is similar for real-time video conferencing applications  bolot 1994   the speaker in our internet phone application generates an audio signal consisting of alternating talk spurts and silent periods in order to conserve bandwidth  our internet phone application only generates packets during talk spurts during a talk spurt the sender generates bytes at a rate of 8 kbytes per second  and every 20 milliseconds the sender gathers bytes into chunks thus the number of bytes in a chunk is  20 msecs  *  8 kbytes/ sec  = 160 bytes a special header is attached to each chunk  the contents of which is discussed below the chunk along with its header are encapsulated in a udp segment  and then the udp datagram is sent into the socket interface thus  during a talk spurt a udp segment is sent every 20 msec if each packet makes it to the receiver  i.e  no loss  and has a small constant end-to-end delay  then packets arrive at the receiver periodically every 20 msec during a talk spurt in these ideal conditions  the receiver can simply play back each chunk as soon as it arrives but  unfortunately  some packets can be lost and most packets will not have a fixed end-to-end delay  in even a lightly congested internet for this reason  the receiver must take more care in  i  determining when to play back a chunk  and  ii  determining what to do with a missing chunk 6.3.1 the limitations of a best-effort service we mentioned that the best-effort service can lead to packet loss  excessive end-to-end delay  and delay jitter let 's examine now these issues in more detail packet loss consider one of the udp datagrams generated by our internet phone application the udp segment is encapsulated in an ip datagram  and the ip datagram makes it way through the network towards the receiver as the datagram wanders through the network  it passes through buffers  i.e  queues  in the routers in order to access outbound links it is possible that one or more of the buffers in the route from sender to receiver is full and can not admit the ip datagram in this case  the ip datagram is discarded and becomes a lost packet it never arrives to the receiving application loss could be eliminated by sending the packets over tcp rather than over udp recall that tcp retransmits packets that do not arrive at the destination however  retransmission mechanisms are generally not acceptable for interactive real-time audio applications  such as internet phone  because they increase end-to-end delay  bolot 1996   furthermore  due to tcp congestion control  after packet loss the transmission rate at the sender can be reduced to a rate that is lower than the drain rate at the receiver this can have a severe impact on voice intelligibility at the receiver for these reasons  almost all existing internet phone applications run over udp and do not bother to retransmit lost packets but losing packets is not necessarily as grave as one might think indeed  packet loss rates between 1 % and 20 % can be tolerated  depending on how the voice is encoded and transmitted  and on how the loss is concealed at the receiver for example  forward error correction  fec  can help conceal packet loss as we shall see below  with fec redundant information is transmitted along with the original information so that some of the lost original data can be recovered from the redundant information nevertheless  if one or more of the links between sender and receiver is severely congested  and packet loss exceeds 10-20 %  then there is really nothing that can be done to achieve acceptable sound quality the best-effort service has its limitations end-to-end delay end-to-end delay is the accumulation of processing and queueing delays in routers  propagation delays  and end-system processing delays for highly interactive audio applications  like internet phone  end-to-end delays smaller than 150 milliseconds are not perceived by a human listener ; delays between 150 and 400 milliseconds can be acceptable but not ideal ; and delays exceeding 400 milliseconds result in unintilligible voice file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  1 of 7  20/11/2004 15  52  48 introduction conversations the receiver in an internet phone application will typically disregard any packets that are delayed more than a certain threshold  e.g  more than 400 milliseconds thus  packets that are delayed by more than the threshold are effectively lost delay jitter one of the components of end-to-end delay is the random queueing delays in the routers because of these random queueing delays within the network  the time from when a packet is generated at the source until it is received at the receiver can fluctuate from packet to packet this phenonemom is called jitter as an example  consider two consecutive packets within a talk spurt in our internet phone application the sender sends the second packet 20 msec after sending the first packet but at the receiver the spacing between these packets can become greater than 20 msec to see this  suppose the first packet arrives to a nearly empty queue at a router  but just before the second packet arrives to the queue a large number of packets from other sources arrive to the same queue because the second packet suffers a large queueing delay  the first and second packets become spaced apart by more than 20 milliseconds  in fact  the spacing between two consecutive packets can become one second or more  the spacing between consecutive packets can also become less than 20 milliseconds to see this  again consider two consecutive packets within a talk spurt suppose the first packet joins the end of a queue with a large number of packets  and the second packet arrives to the queue before packets from other sources arrive to the queue thus  our two packets find themselves right behind each other in the queue if the time it takes to transmit a packet on the router 's onbound link is less than 20 milliseconds  then the first and second packets become spaced apart by less than 20 milliseconds the situation is analogous to driving cars on roads suppose you and your friend are each driving in your own cars from san diego to phoenix suppose you and your friend have similar driving styles  and that you both drive at 100 km/hour  traffic permitting finally  suppose your friend starts out one hour before you then  depending on intervening traffic  you may arrive at phoenix more or less than one hour after your friend if the receiver ignores the presence of jitter  and plays out chunks as soon as they arrive  then the resulting audio quality can easily become unintelligible at the receiver fortunately  jitter can be often be removed by using sequence numbers  timestamps and a playout delay  as we discuss below 6.3.2 removing jitter at the receiver for audio for a voice application such as internet phone or audio-on-demand  the receiver should attempt to provide synchronous playout of voice chunks in the presence of random network jitter this is typically done by combining the following three mechanisms  l appending a sequence number on each chunk the sender increments the sequence number by one for each of the packet it generates l appending a timestamp on each chunk the sender stamps each chunk with time at which the chunk was generated l delaying playout of chunks at the receiver the playout delay of the received audio chunks must be long enough so that most of the packets are received before their scheduled playout times this playout delay can be either fixed throughout the duration of the conference  or it may vary adaptively during the conference 's lifetime packets that do not arrive before their scheduled playout times are considered lost and forgotten ; as mentioned above  the receiver may use some form of speech interpolation to attempt to conceal the loss the sequence number and timestamp occupy fields in the header of the audio chunk a standardized format for the header of the audio chunks is described in the next section we now discuss how these three mechanisms  when combined  can alleviate or even eliminate the effects of jitter we examine two playback strategies  fixed playout delay and adaptive playout delay fixed playout delay with the fixed delay strategy  the receiver attempts to playout each chunk exactly q milliseconds after the chunk is generated so if a chunk is timestamped at time t  the receiver plays out the chunk at time t + q  assuming the chunk has arrived by the scheduled playout time t + q packets that arrive after their scheduled playout times are discarded and considered lost note that sequence numbers are not necessary for this fixed delay strategy also note that even in the presence of occassional packet loss  we can continue to operate the fixed delay strategy what is a good choice of q ? internet telephone can support delays up to about 400 milliseconds  although a more satisfying interactive experience is achieved with smaller values of q on the otherhand  if q is made much smaller than 400 milliseconds  then many packets may miss their scheduled playback times due to the network-induced delay jitter roughly speaking  if large variations in end-to-end delay are typical  it is preferable to use a large q ; on the other hand  if delay is small and variations in delay are also small  it is preferable to use a small q  perhaps less than 150 milliseconds file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  2 of 7  20/11/2004 15  52  48 introduction the tradeoff between the playback delay and packet loss is illustrated in figure 6.3-1 the figure shows the times at which packets are generated and played out for a single talkspurt two distinct initial playout delays are considered as shown by the left-most staircase  the sender generates packets at regular intervals  specifically  every 20 msec the first packet in this talkspurt is received at time r as shown in the figure  the arrivals of subsequent packets are not evenly spaced due to the network jitter for the first playout schedule  the fixed inital playout delay is set to p r with this schedule  the fourth packet does not arrive by its scheduled playout time  and the receiever considers it lost for the second playout schedule  the fixed initial playout delay is set to p' r for this schedule all of the packets arrive before their scheduled playout times  and there is therefore no loss figure 6.3-1  packet loss for different fixed playout delays adaptive playout delay the above example demonstrates an important delay-loss tradeoff that arises when designing a playout strategy with fixed playout delays by making the initial playout delay large  most packets will make their deadlines and there will therefore be negligible loss ; however  for interactive services such as internet phone  long delays can become bothersome if not intolerable ideally  we would like the playout delay to be minimized subject to the constraint that the loss be below a few percent the natural way to deal with this tradeoff is to estimate the network delay and the variance of the network delay  and to accordingly adjust the playout delay at the beginning of each talkspurt this adaptive adjustment of the playout delays at the beginning of the talkspurts will cause the the sender 's silent periods to be compressed and elongated ; however  compression and elongation of silence by a small amount is not noticeable in speech file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  3 of 7  20/11/2004 15  52  48 introduction following the paper  ramjee 1994   we now describe a generic algorithm that the receiver can use to adaptively adjust its playout delays to this end  let ti = timestamp of the ith packet = the time packet was generated by sender ri = the time packet i is received by receiver pi = the time packet i is played at receiver the end-to-end network delay of the ith packet is ri  ti due to network jitter  this delay will vary from packet to packet let di denote an estimate of the average network delay upon reception of the ith packet this estimate is constructed from the timestamps as follows  di =  1-u  di-1 + u  ri  ti  where u is a fixed constant  e.g  u = .01   thus di is a smoothed average of the observed network delays r1  t1  ri  ti ; the estimate places more weight on the recently observed network delays than on the observed network delays of the distant past this form of estimate should not be completely unfamiliar ; a similar idea is used to estimate round-trip times  as discussed in chapter 3 let vi denote an estimate of the average deviation of the delay from the estimated average delay this estimate is also constructed from the timestamps  vi =  1-u  vi-1 + u | ri  ti  di |  the estimates di and vi are calculated for every packet received  although they are only used to determine the playout point for the first packet in any talkspurt once having calculated these estimates  the receiver employs the following algorithm for the playout of packets if packet i is the first packet of a talkspurt  its playout time  pi  is computed as  pi = ti + di + kvi  where k is a positive constant  e.g  k = 4   the purpose of the k vi term is to set the playout time far enough into the future so that only a small fraction of the arriving packets in the talk spurt will be lost due to late arrivals the playout point for any subsequent packet in a talkspurt is computed as an offset from the point in time when the first packet in the talkspurt was played out in particular  let qi = pi -ti  be length of time from when the first packet in the talk spurt is generated until it is played out if packet j also belongs to this talk spurt  it is played out at time pj = tj + qi  the algorithm just described makes perfect sense assuming that the receiver can tell whether a packet is the first packet in the talk spurt if there is no packet loss  then the receiver can determine whether packet i is the first packet of the talk spurt by comparing the timestamp of the ith packet with the timestamp of the  i-1  st packet indeed  if ti  ti-1 > 20 msec  then the receiver knows that ith packet starts a new talkspurt but now suppose there is occassional packet loss in this case two successive packets received at the destination may have timestamps that differ by more than 20 msec when the two packets belong to the same talkspurt so here is where the sequence numbers become useful the receiver can use the sequence numbers to determine whether the > 20 msec difference in timestamps is due to a new talkspurt or to lost packets 6.3.3 recovering from packet loss we have discussed in some detail how an internet phone application can deal with packet jitter we now briefly describe a few schemes that attempt to preserve acceptable audio quality in the presence of packet loss such schemes are called loss recovery schemes here we define packet loss in a broad sense  a packet is lost if either it never arrives at the receiver or if it arrives after its scheduled playout time our internet phone example will again serve as a context for describing the loss recovery schemes as mentioned at the beginning of this section  retransmitting lost packets is not appropriate in an interactive real-time application such as internet phone indeed  retransmitting a packet that missed its playout deadline serves absolutely no purpose and retransmitting a packet that overflowed a router queue can not normally be accomplished quickly enough because retransmissions are inappropriate  internet phone applications often use some type of loss anticipation scheme two types of loss-anticipiation schemes are forward-error correction  fec  and interleaving forward-error correction  fec  file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  4 of 7  20/11/2004 15  52  48 introduction the basic idea of fec is to add redundant information to the original packet stream for the cost of marginally increasing the transmission rate of the audio of the stream  the redundant information can be used to reconstruct " approximations " or exact versions of some of the lost packets following  bolot 1996  and  perkins 1998   we now outline two fec mechanisms the first mechanism sends a redundant encoded chunk after every n chunks the redundant chunk is obtained by exclusive or-ing the n original chunks  shacham 1990   in this manner if any one packet of the group of n + 1 packets is lost  the receiver can fully reconstruct the lost packet but if two or more packets in a group are lost  ther receiver can not reconstuct the lost packets by keeping n + 1  the group size  small  a large fraction of the lost packets can be recovered when loss is not excessive however  the smaller the group size  the greater the relative increase of the transmission rate of the audio stream in particular  the transmission rate increases by a factor of 1/n ; for example  if n = 3  then the transmission rate increases by 33 %  furthermore  this simple scheme increases the playout delay because the receiver must receive the entire group of packets before it can playout a group  during a talkspurt  the receiver schedules periodic playback of the chunks based on the worst-case scenario  namely  the first packet in a group is lost within some group this requires the receiver to delay playback of each packet for the time it takes to receive an entire group  the second fec mechanism to send a lower quality audio stream as the redundant information for example  the sender creates a nominal audio stream and a corresponding low-bit rate audio stream  the nominal stream could be a pcm encoding at 64 kbps and the lower-quality stream could be a gsm encoding at 13 kbps  the low-bit rate stream is referred to as the redundant stream as shown in figure 6.3-2  the sender constructs the nth packet by taking the nth chunk from the nominal stream and appending to it the  n-1  st chunk from the redundant stream in this manner  whenever there is non-consecutive packet loss  the receiver can conceal the loss by playing out the low-bit-rate encoded chunk that arrives with the subsequent packet of course  low-bit-rate chunks give lower quality than the nominal chunks ; but a stream of mostly high-quality chunks  occasional low-quality chunks and no missing chunks gives good overall audio quality note that in this scheme  the receiver only has to receive two packets before playback  so that the increased playout delay is small furthermore  if the low-bit-rate encoding is much less than the nominal encoding  then the marginal increase in the transmission rate is small figure 6.3-2  piggybacking lower-quality redundant information in order to cope with non-consecutive loss  a simple variation can be employed instead of appending just the  n-1  st low-bit-rate chunk to the nth nominal chunk  the sender can append the  n-1  st and  n-2  nd low-bit-rate chunk  or append the  n-1  st and  n-3  rd low-bit-rate chunk  etc by appending more low-bit-rate chunks to each nominal chunk  the audio quality at the receiver becomes acceptable for a wider variety of harsh besteffort environments on the otherhand  the additional chunks increase the transmission bandwidth and the playout delay free phone and rat are well-documented internet phone application that uses fec they can transmit lower-quality audio streams along with the nominal audio stream  as described above interleaving as an alternative to redundant transmission  an internet phone application can send interleaved audio as shown in figure 6.3-3  the sender resequences units of audio data before transmission  so that originally adjacent units are separated by a certain distance in the transmitted stream interleaving reduces the effect of packet losses if  for example  units are 5 ms in length and chunks are 20 ms  i.e  4 units per chunk   then the first chunk could contain units 1  5  9  13 ; the second chunk could contain units 2  6  10  14 ; and so on figure 6.3-3 shows that the loss of a single packet from an interleaved stream results in multiple small gaps in the reconstructed stream  as opposed to the single large gap which would occur in a noninterleaved stream file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  5 of 7  20/11/2004 15  52  48 introduction figure 6.3-3  sending interleaved audio interleaving can significantly improve the perceived quality of an audio stream  perkins 1998   the obvious disadvantage of interleaving is that it increases latency this limits its use for interactive applications such as internet phone  although it can perform well for streaming stored audio the major advantage of interleaving is that it does not increase the bandwidth requirements of a stream receiver-based repair of damaged audio streams receiver-based recovery schemes attempt to produce a replacement for a lost packet that is similar to the original as discussed in  perkins 1998   this is possible since audio signals  and in particular speech  exhibit large amounts of short-term self similarity as such  these techniques work for relatively small loss rates  less than 15 %   and for small packets  4-40ms   when the loss length approaches the length of a phoneme  5-100ms  these techniques breakdown  since whole phonemes may be missed by the listener a simple form of receiver-based recovery is packet repetition packet repetition replaces lost packets with copies of the packets that arrived immediately before the loss it has low computational complexity and performs reasonably well another form of receiver-based recovery is interpolation  which uses audio before and after the loss to interpolate a suitable packet to cover the loss it performs somewhat better than packet repetition  but is significantly more computationally intensive  perkins 1998   6.3.4 streaming stored audio and video we conclude this section with a few words about streaming stored audio and video streaming stored audio/video can also use sequence numbers  timestamps  and playout delay to alleviate or even eliminate the effects of network jitter however  there is an important difference between realtime interactive audio/video and streaming stored audio/video  specifically  streaming of stored audio/video can tolerate significantly larger delays indeed  when a user requests an audio/video clip  the user may find it acceptable to wait five seconds or more before playback begins and most users can tolerate similar delays after interactive actions such as a temporal jump to the future this greater tolerance for delay gives the application developer greater flexibility when designing an stored media applications references  bolot 1994  j-c bolot and t turletti  " a rate control scheme for packet video in the internet  " proceedings of ieee infocom  1994  pp 1216 1223  bolot 1996  j-c bolot and andreas vega-garcia  " control mechanisms for packet audio in the internet  " proceedings of ieee infocom  1996  pp 232-239  ramjee 1994  r ramjee  j kurose  d towsley  and h schulzrinn  " adaptive playout mechanisms for packetized audio applications in wide area networks  " proceedings of ieee infocom  1994  pp 680-688  perkins 1998  c perkins  o hodson and v hardman  " a survey of packet loss recovery techniques for streaming audio  " ieee network magazine  september/october 1998  pp 40-47 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  6 of 7  20/11/2004 15  52  48 introduction  shacham 1990  n shacham and p mckenny  " packet recovery in high-speed networks using coding and buffer management  " proceedings of ieee infocom  1990  pp 124-131 return to table of contents copyright 1996-2000 james f kurose and keith w ross file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...proach % 20featuring % 20the % 20internet/overbesteffort.html  7 of 7  20/11/2004 15  52  48 rtp 6.4 rtp in the previous section we learned that the sender side of a multimedia application appends header fields to the audio/video chunks before passing the chunks to the transport layer these header fields include sequence numbers and timestamps since most all multimedia networking applications can make use of sequence numbers and timestamps  it is convenient to have a standardized packet structure that includes fields for audio/video data  sequence number and timestamp  as well as other potentially useful fields rtp  defined in  rfc 1889   is such a standard rtp can be used for transporting common formats such as wav or gsm for sound and mpeg1 and mpeg2 for video it can also be used for transporting proprietary sound and video formats in this section we attempt to provide a readable introduction to rtp and to its companion protocol  rtcp we also discuss the role of rtp in the h.323 standard for real-time interactive audio and video conferencing the reader is encouraged to visit henning schulzrinne 's rtp site  schulzrinne 1997   which provides a wealth of information on the subject also  readers may want to visit the free phone site  which describes an internet phone application that uses rtp 6.4.1 rtp basics rtp typically runs on top of udp specifically  audio or video chunks of data  generated by the sending side of a multimedia application  are encapsulated in rtp packets  and each rtp packet is in turn encapsulated in a udp segment because rtp provides services  timestamps  sequence numbers  etc  to the multimedia application  rtp can be viewed as a sublayer of the transport layer  as shown in figure 6.4-1 figure 6.4-1 rtp can be viewed as a sublayer of the transport layer from the application developer 's perspective  however  rtp is not part of the transport layer but instead part of the application layer this is because the developer must integrate rtp into the application specifically  for the sender side of the application  the developer must write code into the application which creates the rtp encapsulating packets ; the application then sends the rtp packets into a udp socket interface similarly  at the receiver side of the application  the rtp packets enter the application through a udp socket interface ; the developer therefore must write code into the application that extracts the media chunks from the rtp packets this is illustrated in figure 6.4-2 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  1 of 10  20/11/2004 15  52  50 rtp figure 6.4-2 from a developer 's perspective  rtp is part of the application layer as an example consider using rtp to transport voice suppose the voice source is pcm encoded  i.e  sampled  quantized  and digitized  at 64 kbps further suppose that the application collects the encoded data in 20 msec chunks  i.e  160 bytes in a chunk the application precedes each chunk of the audio data with an rtp header  which includes the type of audio encoding  a sequence number and a timestamp the audio chunk along with the rtp header form the rtp packet the rtp packet is then sent into the udp socket interface  where it is encapsulated in a udp packet at the receiver side  the application receives the rtp packet from its socket interface the application extracts the audio chunk from the rtp packet  and uses the header fields of the rtp packet to properly decode and playback the audio chunk if an application incorporates rtp  instead of a proprietary scheme to provide payload type  sequence numbers or timestamps  then the application will more easily interoperate with other networking applications for example  if two different companies develop internet phone software and they both incorporate rtp into their product  there may be some hope that a user using one of the internet phone products will be able to communicate with a user using the other internet phone product at the end of this section we shall see that rtp has been incorporated into an important part of an internet telephony standard it should be emphasized that rtp in itself does not provide any mechanism to ensure timely delivery of data or provide other quality of service guarantees ; it does not even guarantee delivery of packets or prevent out-of-order delivery of packets indeed  rtp encapsulation is only seen at the end systems  it is not seen by intermediate routers routers do not distinguish between ip datagrams that carry rtp packets and ip datagrams that do n't rtp allows each source  for example  a camera or a microphone  to be assigned its own independent rtp stream of packets for example  for a videoconference between two participants  four rtp streams could be opened  two streams for transmitting the audio  one in each direction  and two streams for the video  again  one in each direction   however  many popular encoding techniques  including mpeg1 and mpeg2  bundle the audio and video into a single stream during the encoding process when the audio and video are bundled by the encoder  then only one rtp stream is generated in each direction rtp packets are not limited to unicast applications they can also be sent over one-to-many and many-to-many multicast trees for a many-to-many multicast session  all of the senders and sources in the session typically send their rtp streams into the same multicast tree with the same multicast address rtp multicast streams belonging together  such as audio and video streams emanating from multiple senders in a videoconference application  belong to an rtp session 6.4.2 rtp packet header fields as shown in the figure 6.4-3  the four principle packet header fields are the payload type  sequence number  timestamp and the source identifier figure 6.4-3 rtp header fields payload type field file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  2 of 10  20/11/2004 15  52  50 rtp the payload type field in the rtp packet is seven-bits long thus 27 or 128 different payload types can be supported by rtp for an audio stream  the payload type field is used to indicate the type of audio encoding  e.g  pcm  adaptive delta modulation  linear predictive encoding  that is being used if a sender decides to change the encoding in the middle of a session  the sender can inform the receiver of the change through this payload type field the sender may want to change the encoding in order to increase the audio quality or to decrease the rtp stream bit rate figure 6.4-4 lists some of the audio payload types currently supported by rtp payload type number audio format sampling rate throughput 0 pcm mu-law 8 khz 64 kbps 1 1016 8 khz 4.8 kbps 3 gsm 8 khz 13 kbps 7 lpc 8 khz 2.4 kbps 9 g.722 8 khz 48-64 kbps 14 mpeg audio 90 khz  15 g.728 8 khz 16 kbps figure 6.4-4 some audio payload types supported by rtp for a video stream the payload type can be used to indicate the type of video encoding  e.g  motion jpeg  mpeg1  mpeg2  h.231   again  the sender can change video encoding on-the-fly during a session figure 6.4-5 lists some of the video payload types currently supported by rtp payload type number video format 26 motion jpeg 31 h.261 32 mpeg1 video 33 mpeg2 video figure 6.4-5 some video payload types supported by rtp sequence number field the sequence number field is 16-bits long the sequence number increments by one for each rtp packet sent  and may be used by the receiver to detect packet loss and to restore packet sequence for example if the receiver side of the application receives a stream of rtp packets with a gap between sequence numbers 86 and 89  then the receiver knows that packets 87 and 88 were lost the receiver can then attempt to conceal the lost data timestamp field the timestamp field is 32 bytes long it reflects the sampling instant of the first byte in the rtp data packet as we saw in the previous section  the receiver can use the timestamps in order to remove packet jitter introduced in the network and to provide synchronous playout at the receiver the timestamp is derived from a sampling clock at the sender as an example  for audio the timestamp clock increments by one for each sampling period  for example  each 125 usecs for a 8 khz sampling clock  ; if the audio application generates chunks consisting of 160 encoded samples  then the timestamp increases by 160 for each rtp packet when the source is active the timestamp clock continues to increase at a constant rate even if the source is inactive synchronization source identifier  ssrc  the ssrc field is 32 bits long it identifies the source of the rtp stream typically  each stream in a rtp session has a distinct ssrc the ssrc is not the ip address of the sender  but instead a number that the source assigns randomly when the new stream is started the probability that two streams get assigned the same ssrc is very small 6.4.3 rtp control protocol  rtcp  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  3 of 10  20/11/2004 15  52  50 rtp  rfc 1889  also specifies rtcp  a protocol which a multimedia networking application can use in conjunction with rtp the use of rtcp is particularly attractive when the networking application multicasts audio or video to multiple receivers from one or more senders as shown in figure 6.4-6  rtcp packets are transmitted by each participant in an rtp session to all other participants in the session the rtcp packets are distributed to all the participants using ip multicast for an rtp session  typically there is a single multicast address  and all rtp and rtcp packets belonging to the session use the multicast address rtp and rtcp packets are distinguished from each other through the use of distinct port numbers figure 6.4-6 both senders and receivers send rtcp messages rtcp packets do not encapsulate chunks of audio or video instead  rtcp packets are sent periodically and contain sender and/or receiver reports that announce statistics that can be useful to the application these statistics include number of packets sent  number of packets lost and interarrival jitter the rtp specification  rfc 1889  does not dictate what the application should do with this feedback information it is up to the application developer to decide what it wants to do with the feedback information senders can use the feedback information  for example  to modify their transmission rates the feedback information can also be used for diagnostic purposes ; for example  receivers can determine whether problems are local  regional or global rtcp packet types receiver reception packets for each rtp stream that a receiver receives as part of a session  the receiver generates a reception report the receiver aggregates its reception reports into a single rtcp packet the packet is then sent into multicast tree that connects together all the participants in the session the reception report includes several fields  the most important of which are listed below m the ssrc of the rtp stream for which the reception report is being generated m the fraction of packets lost within the rtp stream each receiver calculates the number of rtp packets lost divided by the number of rtp packets sent as part of the stream if a sender receives reception reports indicating that the receivers are receiving only a small fraction of the sender 's transmitted packets  the sender can switch to a lower encoding rate  thereby decreasing the congestion in the network  which may improve the reception rate m the last sequence number received in the stream of rtp packets m the interarrival jitter  which is calculated as the average interarrival time between successive packets in the rtp stream sender report packets for each rtp stream that a sender is transmitting  the sender creates and transmits rtcp sender-report packets these packets include information about the rtp stream  including  l the ssrc of the rtp stream l the timestamp and wall-clock time of the most recently generated rtp packet in the stream l the number of packets sent in the stream l the number of bytes sent in the stream file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  4 of 10  20/11/2004 15  52  50 rtp the sender reports can be used to synchronize different media streams within a rtp session for example  consider a videoconferencing application for which each sender generates two independent rtp streams  one for video and one for audio the timestamps in these rtp packets are tied to the video and audio sampling clocks  and are not tied to the wall-clock time  i.e  to real time   each rtcp sender-report contains  for the most recently generated packet in the associated rtp stream  the timestamp of the rtp packet and the wall-clock time for when the packet was created thus the rtcp sender-report packets associate the sampling clock to the real-time clock receivers can use this association in the rtcp sender reports to synchronize the playout of audio and video source description packets for each rtp stream that a sender is transmitting  the sender also creates and transmits source-description packets these packets contain information about the source  such as e-mail address of the sender  the sender 's name and the application that generates the rtp stream it also includes the ssrc of the associated rtp stream these packets provide a mapping between the source identifier  i.e  the ssrc  and the user/host name rtcp packets are stackable  i.e  receiver reception reports  sender reports  and source descriptors can be concatenated into a single packet the resulting packet is then encapsulated into a udp segment and forwarded into the multicast tree rtcp bandwidth scaling the astute reader will have observed that rtcp has a potential scaling problem consider for example an rtp session that consists of one sender and a large number of receivers if each of the receivers periodically generate rtcp packets  then the aggregate transmission rate of rtcp packets can greatly exceed the rate of rtp packets sent by the sender observe that the amount of traffic sent into the multicast tree does not change as the number of receivers increases  whereas the amount of rtcp traffic grows linearly with the number of receivers to solve this scaling problem  rtcp modifies the rate at which a participant sends rtcp packets into the multicast tree as a function of the number of participants in the session observe that  because each participant sends control packets to everyone else  each participant can keep track of the total number of participants in the session rtcp attempts to limit its traffic to 5 % of the session bandwidth for example  suppose there is one sender  which is sending video at a rate of 2 mbps then rtcp attempts to limit its traffic to 5 % of 2 mbps  or 100 kbps  as follows the protocol gives 75 % of this rate  or 75 kbps  to the receivers ; it gives the remaining 25 % of the rate  or 25 kbps  to the sender the 75 kbps devoted to the receivers is equally shared among the receivers thus  if there are r receivers  then each receiver gets to send rtcp traffic at a rate of 75/r kbps and the sender gets to send rtcp traffic at a rate of 25 kbps a participant  a sender or receiver  determines the rtcp packet transmission period by dynamically calculating the the average rtcp packet size  across the entire session  and dividing the average rtcp packet size by its allocated rate in summary  the period for transmitting rtcp packets for a sender is and the period for transmitting rtcp packets for a receiver is 6.4.4 h.323 h.323 is a standard for real-time audio and video conferencing among end systems on the internet as shown in figure 6.4-7  it also covers how end systems attached to the internet communicate with telephones attached to ordinary circuit-switched telephone networks in principle  if manufacturers of internet telephony and video conferencing all conform to h.323  then all their products should be able to interoperate  and should be able to communicate with ordinary telephones we discuss h.323 in this section  as it provides an application context for rtp indeed  we shall see below that rtp is an integral part of the h.323 standard file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  5 of 10  20/11/2004 15  52  50 rtp figure 6.4-7 h.323 end systems attached to the internet can communicate with telephones attached to a circuit-switched telephone network h.323 end points  a.k.a terminals  can be stand-alone devices  e.g  web phones and web tvs  or applications in a pc  e.g  internet phone or video conferencing software   h.323 equipment also includes gateways and gatekeepers gateways permit communication among h.323 end points and ordinary telephones in a circuit-switched telephone network gatekeepers  which are optional  provide address translation  authorization  bandwidth management  accounting and billing we will discuss gatekeepers in more detail at the end of this section the h.323 is an umbrella specification that includes  l a specification for how endpoints negotiate common audio/video encodings because h.323 supports a variety of audio and video encoding standards  a protocol is needed to allow the communicating endpoints to agree on a common encoding l a specification for how audio and video chunks are encapsulated and sent over network as you may have guessed  this is where rtp comes into the picture l a specification for how endpoints communicate with their respective gatekeepers l a specification for how internet phones communicate through a gateway with ordinary phones in the public circuit-switched telephone network figure 6.4-8 shows the h.323 protocol architecture file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  6 of 10  20/11/2004 15  52  50 rtp figure 6.4-8 h.323 protocol architecture minimally  each h.323 endpoint must support the g.711 speech compression standard g.711 uses pcm to generate digitized speech at either 56 kbps or 64 kbps although h.323 requires every endpoint to be voice capable  through g.711   video capabilities are optional because video support is optional  manufacturers of terminals can sell simpler speech terminals as well as more complex terminals that support both audio and video as shown in figure 6.4-8  h.323 also requires that all h.323 end points use the following protocols  l rtp  the sending side of an endpoint encapsulates all media chunks within rtp packets sending side then passes the rtp packets to udp l h.245  an ? out-of-band ? control protocol for controlling media between h.323 endpoints this protocol is used to negotiate a common audio or video compression standard that will be employed by all the participating endpoints in a session l q.931  a signaling protocol for establishing and terminating calls this protocol provides traditional telephone functionality  e.g  dial tones and ringing  to h.323 endpoints and equipment l ras  registration/admission/status  channel protocol  a protocol that allows end points to communicate with a gatekeeper  if gatekeeper is present   audio and video compression the h.323 standard supports a specific set of audio and video compression techniques let 's first consider audio as we just mentioned  all h.323 end points must support the g.711 speech encoding standard because of this requirement  two h.323 end points will always be able to default to g.711 and communicate but h.323 allows terminals to support a variety of other speech compression standards  including g.723.1  g.722  g.728 and g.729 many of these standards compress speech to rates that will pass through 28.8 kbps dial-up modems for example  g.723.1 compresses speech to either 5.3 kbps or 6.3 kbps  with sound quality that is comparable to g.711 as we mentioned earlier  video capabilities for an h.323 endpoint are optional however  if an endpoint does supports video  then it must  at the very least  support the qcif h.261  176x144 pixels  video standard a video capable endpoint my optionally support other h.261 schemes  including cif  4cif and 16cif  and the h.263 standard as the h.323 standard evolves  it will likely support a longer list of audio and video compression schemes h.323 channels when a end point participates in an h.323 session  it maintains several channels  as shown in figure 6.4-9 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  7 of 10  20/11/2004 15  52  50 rtp figure 6.4-9 h.323 channels examining figure 6.4-9  we see that an end point can support many simultaneous rtp media channels for each media type  there will typically be one send media channel and one receive media channel ; thus  if audio and video are sent in separate rtp streams  there will typically be four media channels accompanying the rtp media channels  there is one rtcp media control channel  as discussed in section 6.4.3 all of the rtp and rtcp channels run over udp in addition to the rtp/rtcp channels  two other channels are required  the call control channel and the call signaling channel the h.245 call control channel is a tcp connection that carries h.245 control messages its principle tasks are  i  opening and closing media channels ; and  ii  capability exchange  i.e  before sending media  endpoints agree on and encoding algorithm h.245  being a control protocol for real-time interactive applications  is analogous to rtsp  which is a control protocol for streaming of stored multimedia finally  the q.931 call signaling channel provides classical telephone functionality  such as dial tone and ringing gatekeepers the gatekeeper is an optional h.323 device each gatekeeper is responsible for an h.323 zone a typical deployment scenario is shown in figure 6.4 10 in this deployment scenario  the h.323 terminals and the gatekeeper are all attached to the same lan  and the h.323 zone is the lan itself if a zone has a gatekeeper  then all h.323 terminals in the zone are required to communicate with it using the ras protocol  which runs over tcp address translation is one of the more important gatekeeper services each terminal can have an alias address  such as the name of the person at the terminal  the e-mail address of the person at the terminal  etc the gateway translates these alias addresses to ip addresses this address translation service is similar to the dns service  covered in section 2.5 another gatekeeper service is bandwidth management  the gatekeeper can limit the number of simultaneous real-time conferences in order to save some bandwidth for other applications running over the lan optionally  h.323 calls can be routed through gatekeeper  which is useful for billing file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  8 of 10  20/11/2004 15  52  50 rtp figure 6.4-10 h.323 terminals and gatekeeper on the same lan h.323 terminal must register itself with the gatekeeper in its zone when the h.323 application is invoked at the terminal  the terminal uses ras to send its ip address and alias  provided by user  to the gatekeeper if gatekeeper is present in a zone  each terminal in the zone must contact gatekeeper to ask permission to make a call once it has permission  the terminal can send the gatekeeper an e-mail address  alias string or phone extension for the terminal it wants to call  which may be in another zone if necessary  a gatekeeper will poll other gatekeepers in other zones to resolve an ip address an excellent tutorial on h.323 is provided by  web proforums   the reader is also encouraged to see  rosenberg 1999  for an alternative architecture than h.323 for providing telephone service in the internet references  web proforum 1999  tutorial on h.323  http  //www.webproforum.com/h323/index.html  1999  rfc 1889  h schulzrinne  s casner  r frederick  and v jacobson  rtp  a transport protocol for real-time applications   rfc 1889   1996  schulzrinne 1997  henning schulzrinne 's rtp site  http  //www.cs.columbia.edu/ ~ hgs/rtp/  1997  rosenberg 1999  j rosenberg and henning schulzrinne  " the ietf internet telephony architecture and protocols  " ieee network  vol 13  pp.18 23  may/june 1999 search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  here query  press button to submit your query or reset the form  query options  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/rtp.htm  9 of 10  20/11/2004 15  52  50 rtp case insensitive maximum number of hits  return to table of contents copyright james f kurose and keith w ross 1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...down % 20approach % 20featuring % 20the % 20internet/rtp.htm  10 of 10  20/11/2004 15  52  50 better than best effort service 6.5 beyond best-effort in previous sections we learned how sequence numbers  timestamps  fec  rtp and rtcp can be used by multimedia applications in today 's internet but are these techniques alone enough to support reliable and robust multimedia applications  e.g  an ip telephony service that is equivalent to a service in today 's telephone network ? before answering this question  let us first recall that today 's internet provides a best-effort service to all of its applications  i.e  does not make any promises about the quality of service  qos  an application will receive an application will receive whatever level of performance  e.g  end-end packet delay and loss  that the network is able to provide at that moment recall also that today 's public internet does not allow delay-sensitive multimedia applications to request any special treatment all packets are treated equal at the routers  including delay-sensitive audio and video packets given that all packets are treated equally  all that 's required to ruin the quality of an on-going ip telephone call is enough interfering traffic  i.e  network congestion  to noticeably increase the delay and loss seen by an ip telephone call in this section  we will identify new architectural components that can be added to the internet architecture to shield an application from such congestion and thus make high-quality networked multimedia applications a reality many of the issues that we will discuss in this  and the remaining sections of this chapter are currently under active discussion in the ietf diffserv  intserv  and rsvp working groups figure 6.5-1  a simple network with two applications figure 6.5-1 shows a simple network scenario that illustrates the most important architectural components that have been proposed for the internet in order to provide explicit support for the qos needs of multimedia applications suppose that two application packet flows originate on hosts h1 and h2 on one lan and are are destined for hosts h3 and h4 on another lan the routers on the two lans are connected by a 1.5 mbps link let us assume the lan speeds are significantly higher than 1.5 mbps  and focus on the output queue of router file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  1 of 7  20/11/2004 15  52  52 better than best effort service r1 ; it is here that packet delay and packet loss will occur if the aggregate sending rate of the h1 and h2 exceeds 1.5 mbps let us now consider several scenarios  each of which will provide us with important insight into the underlying principles for providing qos guarantees to multimedia applications scenario 1  a 1 mbps audio application and an ftp transfer figure 6.5-2  competing audio and ftp applications scenario 1 is illustrated in figure 6.5-2 here  a 1 mbps audio application  e.g  a cd-quality audio call  shares the 1.5 mbps link between r1 and r2 with an ftp application that is transferring a file from h2 to h4 in the best-effort internet  the audio and ftp packets are mixed in the output queue at r1 and  typically  transmitted in a first-in-first-out  fifo  order in this scenario  a burst of packets from the ftp source could potentially fill up the queue  causing ip audio packets to be excessively delayed or lost due to buffer overflow at r1 how should we solve this potential problem ? given that the ftp application does not have time constraints  our intuition might be to give strict priority to audio packets at r1 under a strict priority scheduling discipline  an audio packet in the r1 output buffer would always be transmitted before any ftp packet in the r1 output buffer the link from r1 to r2 would look like a dedicated link of 1.5mbps to the audio traffic  with ftp traffic only using the r1-to-r2 link only when no audio traffic is queued in order for r1 to distinguish between the audio and ftp packets in its queue  each packet must be marked as belonging to one of these two " classes " of traffic recall from section 4.7 that this was the original goal of the type-of-service  tos  field in ipv4 as obvious as this might seem  this then is our first principle underlying the provision of quality of service guarantees  principle 1  packet marking allows a router to distinguish among packets belonging to different classes of traffic file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  2 of 7  20/11/2004 15  52  52 better than best effort service scenario 2  a 1 mbps audio application and a high priority ftp transfer our second scenario is only slightly different from scenario 1 suppose now that the ftp user has purchased " platinum service "  i.e  high priced  internet access from its isp  while the audio user has purchased cheap  low-budget internet service that costs only a minuscule fraction of platinum service should the cheap user 's audio packets be given priority over ftp packets in this case ? arguably not in this case  it would seem more reasonable to distinguish packets on the basis of the sender 's ip address more generally  we see that it is necessary for a router to classify packets according to some criteria this then calls for a slight modification to principle 1  principle 1  packet classification allows a router to distinguish among packets belonging to different classes of traffic explicit packet marking is one way in which packets may be distinguished however  the marking carried by a packet does not  by itself  mandate that the packet will receive a given quality of service marking is but one mechanism for distinguishing packets the manner in which a router distinguishes among packets by treating them differently is a policy decision scenario 3  a misbehaving audio application and an ftp transfer suppose now that somehow  by use of mechanisms that we will study in subsequent sections   the router knows it should give priority to packets from the 1 mbps audio application since the outgoing link speed is 1.5 mbps  even though the ftp packets receive lower priority  they will still  on average  receive 0.5 mbps of transmission service but what happens if the audio application starts sending packets at a rate of 1.5 mbps or higher  either maliciously or due to an error in the application  ? in this case  the ftp packets will starve  i.e  will not receive any service on the r1-to-r2 link similar problems would occur if multiple applications  e.g  multiple audio calls   all with the same priority  were sharing a link 's bandwidth ; one non-compliant flow could degrade and ruin the performance of the other flows ideally  one wants a degree of isolation among flows  in order to protect one flow from another misbehaving flow this then is a second underlying principle the provision of qos guarantees principle 2  it is desirable to provide a degree of isolation among traffic flows  so that one flow is not adversely affected by another misbehaving flow in the following section  we will examine several specific mechanisms for providing this isolation among flows we note here that two broad approaches can be taken first  it is possible to " police " traffic flows  as shown in figure 6.5-3 if a traffic flow must meet certain criteria  e.g  that the audio flow not exceed a peak rate of 1 mbps   then a policing mechanism can be put into place to ensure that this criteria is indeed observed if the policed application misbehaves  the policing mechanism will take some action  e.g  drop or delay packets that are in violation of the criteria  so that the traffic actually entering the network conforms to the criteria the leaky bucket mechanism that we examine in the following section is perhaps the most widely used policing mechanism in figure 6.5-3  the packet classification and marking mechanism  principle 1  and the policing mechanism  principle 2  are co-located at the " edge " of the network  either in the end system  or at an file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  3 of 7  20/11/2004 15  52  52 better than best effort service edge router figure 6.5-3  policing  and marking  the audio and ftp traffic flows an alternate approach for providing isolation among traffic flows is for the link-level packet scheduling mechanism to explicitly allocate a fixed amount of link bandwidth to each application flow for example  the audio flow could be allocated 1mbps at r1  and the ftp flow could be allocated 0.5 mbps in this case  the audio and ftp flows see a logical link with capacity 1.0 and 0.5 mbps  respectively  as shown in figure 6.5-4 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  4 of 7  20/11/2004 15  52  52 better than best effort service figure 6.5-4  logical isolation of audio and ftp application flows with strict enforcement of the link-level allocation of bandwidth  a flow can only use the amount of bandwidth that is has been allocated ; in particular  it can not utilize bandwidth that is not currently being used by the other applications for example  if the audio flow goes silent  e.g  if the speaker pauses and generates no audio packets   the ftp flow would still not be able to transmit more than .5 mbps over the r1-to-r2 link  even though the audio flow 's 1 mbps bandwidth allocation is not being used at that moment it is therefore desirable to use bandwidth as efficiently as possible  allowing one flow to use another flow 's unused bandwidth at any given point in time this the the third principle underlying the provision of quality of service  principle 3  while providing isolation among flows  it is desirable to use resources  e.g  link bandwidth and buffers  as efficiently as possible scenario 4  two 1 mbps audio applications over an overloaded 1.5 mbps link in our final scenario  two 1 mbps audio connections transmit their packets over the 1.5 mbps link  as shown in figure 6.5-5 the combined data rate of the two flows  2 mbps  exceeds the link capacity even with classification and marking  principle 1   isolation of flows  principle 2   and sharing of unused bandwidth  principle 3   of which there is none  this is clearly a losing proposition there is simply not enough bandwidth to accommodate the applications ' needs if the two applications equally share the bandwidth  each would only receive 0.75 mbps looked at another way  each application would lose 25 % of its transmitted packets this is such an unacceptably low quality of service that the application is completely unusable ; there 's no need even to transmit any audio packets in the first place file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  5 of 7  20/11/2004 15  52  52 better than best effort service figure 6.5-5  two competing audio applications overloading the r1-to-r2 link for a flow that needs a minimum quality of service in order to be considered " usable  " the network should either allow the flow to use the network  if the network can provide the required qos  or else block the flow from using the network the telephone network is an example of a network that performs such call blocking  if the required resources  an end-to-end circuit  in the case of the telephone network  can not be allocated to the call  the call is blocked  prevented form entering the network  and a busy signal is returned to the user in our example above  there is no gain in allowing a flow into the network if it will not receive a sufficient qos to be considered " usable " indeed  there is a cost to admitting a flow that does not receive its needed qos  as network resources are being used to support a flow which provides no utility to the end user implicit with the need to provide a guaranteed qos to a flow is the need for the flow to declare its qos requirements this process of having a flow declare its qos requirement  and then having the network either accept the flow  at the required qos  or block the flow  because the resources needed to meet the declared qos requirements can not be provided  is referred to as the call admission process the need for call admission is the fourth underlying principle in the provision of qos guarantees  principle 4  a call admission process is needed in which flows declare their qos requirements and are then either admitted to the network  at the required qos  or blocked from the network  if the required qos can not be provided by the network   in our discussion above  we have identified four basic principles in providing qos guarantees for multimedia applications these principles are summarized in figure 6.5-6 in the following section we consider various mechanisms for implementing these principles in the sections following that  we then examine proposed internet service models for providing qos guarantees file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  6 of 7  20/11/2004 15  52  52 better than best effort service figure 6.5-6  four principles of providing qos support return to table of contents copyright james f kurose and keith w ross 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...roach % 20featuring % 20the % 20internet/better_than_best.htm  7 of 7  20/11/2004 15  52  52 scheduling and policing mechanisms for providing qos guarantees 6.6 scheduling and policing mechanisms in the previous section we identified the important underlying principles in providing quality of service  qos  guarantees to networked multimedia applications in this section  we will examine various mechanisms that are used to provides these qos guarantees in the following section  we will then examine how these mechanisms can be combined to provide various forms of quality of service in the internet 6.6.1 scheduling mechanisms recall from our discussion in section 1.6  delay and loss in packet-switched networks  and section 4.8  what 's inside a router ?  that packets belonging to various network flows are multiplexed together and queued for transmission at the output buffers associated with a link the manner in which queued packets are selected for transmission on the link is known as the link scheduling discipline we saw in the previous section that the link scheduling discipline plays an important role in providing qos guarantees let us now consider several of the most important link scheduling disciplines in more detail first-in-first-out  fifo  figure 6.6-1 shows the queuing model abstractions for the first-in-first-out  fifo  link scheduling discipline packets arriving to the link output queue are queued for transmission if the link is currently busy transmitting another packet if there is not sufficient buffering space to hold the arriving packet  the queue 's packet discarding policy then determines whether the packet will be dropped  " lost "  or whether other packets will be removed from the queue to make space for the arriving packet in our discussion below we will ignore packet discard when a packet is completely transmitted over the outgoing link  i.e  receives service  it is removed from the queue figure 6.6-1  fifo queuing abstraction the fifo scheduling discipline  also known as first-come-first-served  fcfs  selects packets for link transmission in the same order in which they arrived at the output link queue we 're all familiar with file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  1 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees fifo queuing from bus stops  particularly in england  where queuing seems to have been perfected  or other service centers  where arriving customers join the back of the single waiting line  remain in order  and are then served when they reach the front of the line figure 6.6-2  the fifo queue in operation figure 6.6-2 shows an example of the fifo queue in operation packet arrivals are indicated by numbered arrows above the upper timeline  with the number indicating the order in which the packet arrived individual packet departures are shown below the lower timeline the time that a packet spends in service  being transmitted  is indicated by the shaded rectangle between the two timelines because of the fifo discipline  packets leave in the same order in which they arrived note that after the departure of packet 4  the link remains idle  since packets 1 through 4 have been transmitted and removed from the queue  until the arrival of packet 5 priority queuing file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  2 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees figure 6.6-3  priority queuing model under priority queuing  packets arriving to the output link are classified into one of two or more priority classes at the output queue  as shown in figure 6.6-3 as discussed in the previous section  a packet 's priority class may depend on an explicit marking that it carries in its packet header  e.g  the value of the type of service  tos  bits in an ipv4 packet   its source or destination ip address  its destination port number  or other criteria each priority class typically has its own waiting area  queue   when choosing a packet to transmit  the priority queuing discipline will transmit a packet from the highest priority class that has a non-empty queue  i.e  has packets waiting for transmission   the choice among packets in the same priority class is typically done in a fifo manner figure 6.6-4 illustrates the operation of a priority queue with two priority classes packets 1,3 and 4 belong the the high priority class and packets 2 and 5 belong to the low priority class packet 1 arrives and  finding the link idle  begins transmission during the transmission of packet 1  packets 2 and 3 arrive and are queued in the low and high priority queues  respectively after the transmission of packet 1  packet 3  a high priority packet  is selected for transmission over packet 2  which  even though it arrived earlier  is a low priority packet   at the end of the transmission of packet 3  packet 2 then begins transmission packet 4  a high priority packet  arrives during the transmission of packet 3  a low priority packet   under a so-called non-preemptive priority queuing discipline  the transmission of a packet is not interrupted once it has begun in this case  packet 4 queues for transmission and begins being transmitted after the transmission of packet 2 is completed file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  3 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees figure 6.6-4  operation of the priority queue round robin and weighted fair queuing under the round robin queuing discipline  packets are again sorted into classes  as with priority queuing however  rather than there being a strict priority of service among classes  a round robin scheduler alternates service among the classes in the simplest form of round robin scheduling  a class 1 packet is transmitted  followed by a class 2 packet  followed by a class 1 packet  followed by a class 2 packet  etc a so-called work-conserving queuing discipline will never allow the link to remain idle whenever there are packets  of any class  queued for transmission a work-conserving round robin discipline that looks for a packet of a given class but finds none will immediately check the next class in the round robin sequence figure 6.6-5 illustrates the operating of a two-class round robin queue in this example  packets 1  2 and 4 belong to class one  and packets 3 and 5 belong to the second class packet 1 begins transmission immediately upon arrival at the output queue packets 2 and 3 arrive during the transmission of packet 1 and thus queue for transmission after the transmission of packet 1  the link scheduler looks for a classtwo packet and thus transmits packet 3 after the transmission of packet 3  the scheduler looks for a class-one packet and thus transmits packet 2 after the transmission of packet 2  packet 4 is the only queued packet ; it is thus transmitted immediately after packet 2 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  4 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees figure 6.6-5  operation of the two-class round robin queue a generalized abstraction of round robin queuing that has found considerable use in qos architectures is the so-called weighted fair queuing  wfq  discipline  demers 90  parekh 93   wfq is illustrated in figure 6.6-6 arriving packets are again classified and queued in the appropriate per-class waiting area as in round robin scheduling  a wfq scheduler will again serve classes in a circular manner  first serving class 1  then serving class 2  then serving class 3  and then  assuming there are three classes  repeating the service pattern wfq is also a work-conserving queuing discipline and thus will immediately move on to the next class in the service sequence upon finding an empty class queue file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  5 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees figure 6.6-6  weighted fair queuing  wfq  wfq differs from round robin in that each class may receive a differential amount of service in any interval of time specifically  let each class  i  is assigned a weight  wi under wfq  during any interval of time during which there are class i packets to send  class i will then be guaranteed to receive a fraction of service equal to wi/  ? wj   where the sum in the denominator is taken over all classes that also have packets queued for transmission in the worst case  even if all classes have queued packets  class i will still be guaranteed to receive a fraction wi/  ? wj   of the bandwidth thus  for a link with transmission rate r  class i will always achieve a throughput of at least r  wi/  ? wj   our description of wfq has been an idealized one  as we have not considered the fact that packets are discrete units of data and a packet 's transmission will not be interrupted to begin transmission another packet ;  demers 90    parekh 93  discuss this packetization issue as we will see in the following sections  wfq plays a central role in qos architectures it is also widely available in today 's router products  cisco 1999    intranets that use wfq-capable routers can therefore provide qos to their internal flows  6.6.2 policing  the leaky bucket in the section 6.5 we also identified policing  the regulation of the rate at which a flow is allowed to file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  6 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees inject packets into the network  as one of the cornerstones of any qos architecture but what aspects of a flow 's packet rate should be policed ? we can identify three important policing criteria  each differing from the other according to the time scale over which the packet flow is policed  l average rate the network may wish to limit the long-term average rate  packets per time interval  at which a flow 's packets can be sent into the network a crucial issue here is the interval of time over which the average rate will be policed a flow whose average rate is limited to 100 packets per second is more constrained than a source that is limited to 6000 packets per minute  even though both have the same average rate over a long enough interval of time for example  the latter constraint would allow a flow to send 1000 packets in a given second-long interval of time  subject to the constraint that the rate be less that 6000 packets over a minute-long interval containing these 1000 packets   while the former constraint would disallow this sending behavior l peak rate while the average rate constraint limits the amount of traffic that can be sent into the network over a relatively long period of time  a peak rate constraint limits the maximum number of packets that can be sent over a shorter period of time using our example above  the network may police a flow at an average rate of 6000 packets per minute  while limiting the flow 's peak rate to 1500 packets per second l burst size the network may also wish to limit the maximum number of packets  the " burst " of packets  that can be sent into the network over a extremely short interval of time in the limit as the interval length approaches zero  the burst size limits the number of packets that can be instantaneously sent into the network while it is physically impossible to instantaneously send multiple packets into the network  after all  every link has a physical transmission rate that can not be exceeded !   the abstraction of a maximum burst size is a useful one file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  7 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees figure 6.6-7  the leaky bucket policer the leaky bucket  also call a token bucket  mechanism is an abstraction that can be used to characterize these policing limits as shown in figure 6.6-7  a leaky bucket consists of a bucket that can hold up to b tokens tokens are added to this bucket as follows new tokens  which may potentially be added to the bucket  are always being generated at a rate of r tokens per second  we assume here for simplicity that the unit of time is a second  if the bucket is filled with less that b tokens when a token is generated  the newly generated token is added to the bucket ; otherwise the newly generated token is ignored  and the token bucket remains full with b tokens let us now consider how is the leaky bucket can be used to police a packet flow suppose before a packet is transmitted into the network  it must first remove a token from the token bucket if the token bucket is empty  the packet must wait for a token  an alternative is for the packet to be dropped  although we will not consider that option here  let us now consider how this behavior polices a traffic flow because there can be at most b tokens in the bucket  the maximum burst size for a leaky-bucketpoliced flow is b packets furthermore  because the token generation rate is r  the maximum number of packets that can enter the network of any interval of time of length t is rt + b thus  the token generation rate  r  serves to limit the long term average rate at which packet can enter the network it is also possible to use leaky buckets  specifically  two leaky buckets in series  to police a flow 's peak rate in addition to the long-term average rate ; see the homework problems at the end of this chapter leaky bucket + weighted fair queuing = > provable maximum delay in a queue file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  8 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees in sections 6.7 and 6.8 we will examine the so-called intserv and diffserv approaches for providing quality of service in the internet we will see that both leaky bucket policing and wfq scheduling will play an important role let us thus close this section by considering a router 's output that multiplexes n flows  each policed by a leaky bucket with parameters bi and ri  i = 1,...,n  using wfq scheduling we assume that each flow is treated as a separate class by the wfq scheduler  as shown in figure 6.6-8 figure 6.6-8  n multiplexed leaky bucket flows with wfq scheduling recall from our discussion of wfq that each flow is guaranteed to receive a share of the link bandwidth equal to at least r  wi/  ? wj   where r is the transmission rate of the link in packets/sec what then is the maximum delay that a packet will experience while waiting for service in the wfq  i.e  after passing through the leaky bucket  ? let us focus on flow 1 suppose that flow 1 's token bucket is initially full a burst of b1 packets then arrives to the leaky bucket policer for flow 1 these packets remove all of the tokens  without wait  from the leaky bucket and then join the wfq waiting area for flow 1 since file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...0featuring % 20the % 20internet/scheduling_and_policing.htm  9 of 10  20/11/2004 15  52  54 scheduling and policing mechanisms for providing qos guarantees these b1 packets are served at a rate of at least r  wi/  ? wj  packet/sec  the last of these packets will then have a maximum delay  dmax  until its transmission is completed  where dmax = b1/  c  wi/  ? wj   the justification of this formula is that if there are b1 packets in the queue and packets are being serviced  removed  from the queue at a rate of at least c  wi/  ? wj  packets per second  then the amount of time until the last bit of the last packet is transmitted can not be more than b1/  c  wi/  ? wj    a homework problem asks you prove that as long as r1 < c  wi/  ? wj   then dmax is indeed the maximum delay that any packet in flow 1 will ever experience in the wfq queue references  demers 90  a demers  s keshav  and s shenker  analysis and simulation of a fair queuing algorithm  internetworking  research and experience  vol 1  no 1  pp 3-26  1990  cisco 99  cisco systems  " congestion management overview "  parekh 93  a parekh and r gallager  " a generalized processor sharing approach to flow control in integrated services networks  the single-node case  " ieee/acm transactions on networking  vol.1  no 3  june 1993   pp 344-357 copyright james f kurose and keith w ross 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...featuring % 20the % 20internet/scheduling_and_policing.htm  10 of 10  20/11/2004 15  52  54 integrated services 6.7 integrated services in the previous sections  we identified both the principles and the mechanisms used to provide quality of service in the internet in this section we consider how these ideas are exploited in a particular architecture for providing quality of service in the internet  the so-called intserv  integrated services  internet architecture  intserv is a framework developed within the ietf to provide individualized quality of service guarantees to individual application sessions two key features lie at the heart of intserv architecture  l reserved resources a router is required to know what amounts of its resources  buffers  link bandwidth  are already reserved for on-going sessions l call setup a session requiring qos guarantees must first be able to reserve sufficient resources at each network router on its source-to-destination path to ensure that its end-to-end qos requirement is met this call setup  also known as call admission  process requires the participation of each router on the path each router must determine the local resources required by the session  consider the amounts of its resources that are already committed to other on-going sessions  and determine whether it has sufficient resources to satisfy the per-hop qos requirement of the session at this router without violating qos local qos guarantees made to already admitted session file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/intserv.htm  1 of 5  20/11/2004 15  52  55 integrated services figure 6.7-1  the call setup process figure 6.7-1 depicts the call setup process let us now consider the steps involved in call admission in more detail  l traffic characterization and specification of the desired qos in order for a router to determine whether or not its resources are sufficient to meet the qos requirements of a session  that session must first declare its qos requirement  as well as characterize the traffic that it will be sending into the network  and for which it requires a qos guarantee in the intserv architecture  the so-called rspec  r for reserved  defines the specific qos being requested by a connection ; the so-called tspec  t for traffic  characterizes the traffic the sender will be sending into the network  or the receiver will be receiving from the network the specific form of the rspec and tspec will vary  depending on the service requested  as discussed below the tspec and rspec are defined in part in  rfc2210    rfc 2215   l signaling for call setup a session 's tspec and rspec must be carried to the routers at which resources will be reserved for the session in the internet  the rsvp protocol  which is discussed file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/intserv.htm  2 of 5  20/11/2004 15  52  55 integrated services in detail in the next section  is currently the signaling protocol of choice  rfc 2210  describes the use of the rsvp resource reservation protocol with the intserv architecture l per-element call admission once a router receives the tspec and rspec for a session requesting a qos guarantee  it can determine whether or not it can admit the call this call admission decision will depend on the traffic specification  the requested type of service  and the existing resource commitments already made by the router to on-going sessions per-element call admission is shown in figure 6.7-2 figure 6.7-2  per-element call behavior the intserv architecture defines two major classes of service  guaranteed service and controlled-load service we will see shortly that each provides a very different form of a quality of service guarantee 6.7.1 guaranteed quality of service the guaranteed service definition  defined in  rfc 2212  provides firm  mathematically provable  bounds on the queuing delays that a packet will experience in a router while the details behind guaranteed service are rather complicated  the basic idea is really quite simple to a first approximation  a source 's traffic characterization is given by a leaky bucket  see section 6.6  with file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/intserv.htm  3 of 5  20/11/2004 15  52  55 integrated services parameters  r,b  and the requested service is characterized by a transmission rate  r  at which packets will be transmitted in essence  a session requesting guaranteed service is requiring that the bits in its packet be guaranteed a forwarding rate of r bits/sec given that traffic is specified using a leaky bucket characterization  and a guaranteed rate of r is being requested  it is also possible to bound the maximum queuing delay at the router recall that with a leaky bucket traffic characterization  the amount of traffic  in bits  generated over any interval of length t is bounded by rt + b recall also from section 6.6  that when a leaky bucket source is fed into a queue which guarantees that queued traffic will be serviced at least at a rate of r bits per second  then the maximum queuing delay experienced by any packet will be bounded by b/r  as long as r is greater than r the actual delay bound guaranteed under the guaranteed service definition is slightly more complicated  due to packetization effects  the simple b/r bound assumes that data is in the forms of a fluid-like flow rather than discrete packets   the fact that the traffic arrival process is subject to the peak rate limitation of the input link  the simple b/r bound assumes that a burst of b bits can arrive in zero time  and possible additional variations in a packet 's transmission time 6.7.2 control load network service a session receiving controlled-load service will receive " a quality of service closely approximating the qos that same flow would receive from an unloaded network element "  rfc 2211   in other words  the session may assume that a " very high percentage " of its packets will successfully pass through the router without being dropped and will experience a queuing delay in the router that is close to zero interestingly  control load service makes no quantitative guarantees about performance  it does not specify what constitutes a " very high percentage " of packets nor what quality of service closely approximates that of an unloaded network element the controlled load service targets real-time multimedia applications that have been developed for today 's internet these applications perform quite well when the network is unloaded  but rapidly degrade in performance as the network becomes more loaded references  rfc 1633  r braden  d clark & s shenker  " integrated services in the internet architecture  an overview  " rfc 1633  june 1994  rfc 2210  j wroclawski  " the use of rsvp with ietf integrated services  " rfc 2210  sept 1997  rfc 2211  j wroclawski  " specification of the controlled-load network element service  " rfc 2211  sept 1997  rfc 2212  s shenker  c partridge  r guerin  " specification of guaranteed quality of service  " rfc 2212  september 1997  rfc 2215  s shenker  j wroclawski  " general characterization parameters for integrated service network elements  " rfc 2215  sept 1997 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/intserv.htm  4 of 5  20/11/2004 15  52  55 integrated services return to table of contents copyright james f kurose and leith w ross 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...wn % 20approach % 20featuring % 20the % 20internet/intserv.htm  5 of 5  20/11/2004 15  52  55 rsvp 6.8 rsvp as we learned in the previous section  in order for a network to provide qos guarantees  there must be a signaling protocol that allows applications running in hosts to reserve resources in the internet rsvp  rfc 2205   is such a signaling protocol for the internet when people talk about resources in the internet context  they usually mean link bandwidth and router buffers to keep the discussion concrete and focused  however  we shall assume that the word resource is synonymous with bandwidth for our pedagogic purposes  rsvp stands for bandwidth reservation protocol 6.8.1 the essence of rsvp the rsvp protocol allows applications to reserve bandwidth for their data flows it is used by a host  on the behalf of an application data flow  to request a specific amount of bandwidth from the network rsvp is also used by the routers to forward bandwidth reservation requests to implement rsvp  rsvp software must be present in the receivers  senders  and routers the two principle characteristics of rsvp are  1 it provides reservations for bandwidth in multicast trees  unicast is handled as a special case   2 it is receiver-oriented  i.e  the receiver of a data flow initiates and maintains the resource reservation used for that flow these two characteristics are illustrated in figure 6.8-1   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  1 of 12  20/11/2004 15  52  57 rsvp figure 6.8-1  rsvp  multicast and receiver-oriented the above diagram shows a multicast tree with data flowing from the top of the tree to six hosts although data originates from the sender  the reservation messages originate from the receivers when a router forwards a reservation message upstream towards the sender  the router may merge the reservation message with other reservation messages arriving from downstream before discussing rsvp in greater detail  we need to recall the notion of a session as with rtp  a session can consist of multiple multicast data flows each sender in a session is the source of one or more data flows ; for example  a sender might be the source of a video data flow and an audio data flow each data flow in a session has the same multicast address to keep the discussion concrete  we assume that routers and hosts identify the session to which a packet belongs by the packet 's multicast address this assumption is somewhat restrictive ; the actual rsvp specification allows for more general methods to identify a session within a session  the data flow to which a packet belongs also needs to be identified this could be done  for example  with the flow identifier field in ipv6 what rsvp is not we emphasize that the rsvp standard  rfc 2205  does not specify how the network provides the reserved bandwidth to the data flows it is merely a protocol that allows the applications to reserve the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  2 of 12  20/11/2004 15  52  57 rsvp necessary link bandwidth once the reservations are in place  it is up to the routers in the internet to actually provide the reserved bandwidth to the data flows this provisioning is done with the scheduling mechanisms  prirority scheduling  weighted fair queuing  etc  discussed in section 6.6 it is also important to understand that rsvp is not a routing protocol  it does not determine the links in which the reservations are to be made instead it depends on an underlying routing protocol  unicast or multicast  to determine the routes for the flows once the routes are in place  rsvp can reserve bandwidth in the links along these routes  we shall see shortly that when a route changes  rsvp rereserves resources  and once the reservations are in place  the routers ' packet schedulers can actually provide the reserved bandwidth to the data flows thus  rsvp is only one piece  albeit an important piece  in the qos guaranteee puzzle rsvp is sometimes referred to as a signaling protocol by this it is meant that rsvp is a protocol that allows hosts to establish and tear-down reservations for data flows the term " signaling protocol " comes from the jargon of the circuit-switched telephony community heterogeneous receivers some receivers can receive a flow at 28.8 kbps  others at 128 kbps  and yet others at 10 mbps or higher this heterogeneity of the reservers poses an interesting question if a sender is multicasting a video to a group of heterogeneous receivers  should the sender encode the video for low quality at 28.8 kbps  for medium quality at 128 kbps  or for high quality at 10 mbps ? if the video is encoded at 10 mbps  then only the users with 10 mbps access will be able to watch the video on the other hand  if the video is encoded at 28.8 kbps  then the 10 mbps users will have to see a low-quality image when they know they can something much better to resolve this dilemma it is often suggested that video and audio be encoded in layers for example  a video might be encoded into two layers  a base layer and an enhancement layer the base layer could have a rate of 20 kbps whereas the enhancement layer could have a rate of 100 kbps ; in this manner receivers with 28.8 access could receive the low-quality base-layer image  and receivers with 128 kbps could receive both layers to construct a high-quality image we note that the sender does not have to know the receiving rates of all the receivers it only needs to know the maximum rate of the all its receivers the sender encodes the video or audio into multiple layers and sends all the layers up to the maximum rate into multicast tree the receivers pick out the layers that are appropriate for their receiving rates in order to not excessively waste bandwidth in the network 's links  the heterogeneous receivers must communicate to the network the rates they can handle we shall see that rsvp gives foremost attention to the issue of reserving resources for heterogeneous receivers 6.8.2 a few simple examples file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  3 of 12  20/11/2004 15  52  57 rsvp let us first describe rsvp in the context of a concrete one-to-many multicast example suppose there is a source that is transmitting into the internet the video of a major sporting event this session has been assigned a multicast address  and the source stamps all of its outgoing packets with this multicast address also suppose that an underlying multicast routing protocol has established a multicast tree from the sender to four receivers as shown below ; the numbers next to the receivers are the rates at which the receivers want to receive data let us also assume that the video is layered encoded to accommodate this heterogeneity of receiver rates figure 6.9-2  an rsvp example crudely speaking  rsvp operates as follows for this example each receiver sends a reservation message upstream into the multicast tree this reservation message specifies the rate at which the receiver would like to receive the data from the source when the reservation message reaches a router  the router adjusts its packet scheduler to accommodate the reservation it then sends a reservation upstream the amount of bandwidth reserved upstream from the router depends on the bandwidths reserved downstream in the example in figure 6.9-2  receivers r1  r2  r3 and r4 reserve 20 kbps  120 kbps  3 mbps and 3 mbps  respectively thus router d 's downstream receivers request a maximum of 3 mbps for this one-to-many transmission  router d sends a reservation message to router b requesting that router b reserve 3 mbps on the link between the two routers note that only 3 mbps is reserved and not 3 + 3 = 6 mbps ; this is because receivers r3 and r4 are watching the same sporting event  so there reservations may be merged similarly  router c requests that router b reserve 100 kbps on the link between routers b and c ; the layered encoding ensures that receiver r1 's 20 kbps stream is included in file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  4 of 12  20/11/2004 15  52  57 rsvp the 100 mbps stream once router b receives the reservation message from its downstream routers and passes the reservations to its schedulers  it sends a new reservation message to its upstream router  router a this message reserves 3 mbps of bandwidth on the link from router a to router b  which is again the maximum of the downstream reservations we see from this first example that rsvp is receiver-oriented  i.e  the receiver of a data flow initiates and maintains the resource reservation used for that flow note that each router receives a reservation message from each of its downstream links in the multicast tree and sends only one reservation message into its upstream link as another example  suppose that four persons are participating in a video conference  as shown in figure 6.8-3 each person has three windows open on her computer to look at the other three persons suppose that the underlying routing protocol has established the multicast tree among the four hosts as shown in the diagram below finally  suppose each person wants to see each of the videos at 3 mbps then on each of the links in this multicast tree  rsvp would reserve 9 mbps in one direction and 3 mbps in the other direction note that rsvp does not merge reservations in this example  as each person wants to receive three distinct streams figure 6.8-3  an rsvp video conference example now consider an audio conference among the same four persons over the same multicast tree suppose b bps are needed for an isolated audio stream because in an audio conference it is rare that more than two persons speak at the same time  it is not necessary to reserve 3 * b bps into each receiver ; 2 * b should file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  5 of 12  20/11/2004 15  52  57 rsvp suffice thus  in this last application we can conserve bandwidth by merging reservations call admission just as the manager of a restaurant should not accept reservations for more tables than the restaurant has  the amount of bandwidth on a link that a router reserves should not exceed the link 's capacity thus whenever a router receives a new reservation message  it must first determine if its downstream links on the multicast tree can accommodate the reservation this admission test is performed whenever a router receives a reservation message if the admission test fails  the router rejects the reservation and returns an error message to the appropriate receiver  s   rsvp does not define the admission test ; but it assumes that the routers perform such a test and that rsvp can interact with the test 6.8.3 path messages so far we have only discussed the rsvp reservation messages  which originate at the receivers and flow upstream towards the senders path messages are another important rsvp message type ; they originate at the senders and flow downstream towards the receivers the principle purpose of the path messages is to let the routers know on which links they should forward the reservation messages specifically  a path message sent within the multicast tree from a router a to a router b contains router a 's unicast ip address router b puts this address in a path-state table  and when it receives a reservation message from a downstream node it accesses the table and learns that it should send a reservation message up the multicast tree to router a in the future some routing protocols may supply reverse path forwarding information directly  replacing the reverse-routing function of the path state along with some other information  the path messages also contain a sender tspec  which defines the traffic characteristics of the data stream that the sender will generate  see section 6.8   this tspec can be used to prevent over reservation 6.8.4 reservation styles through its reservation style  a reservation message specifies whether merging of reservations from the same session is permissible a reservation style also specifies from which senders in a session the receiver desires to receive data recall that a router can identify the sender of a datagram from the datagram 's source ip address there are currently three reservation styles defined  wildcard-filter style ; fixed-filter style ; and sharedexplicit style file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  6 of 12  20/11/2004 15  52  57 rsvp wildcard-filter style  when a receiver uses the wildcard-filter style in its reservation message  it is telling the network that it wants to receive all flows from all upstream senders in the session and that its bandwidth reservation is to be shared among the senders fixed-filter style  when a receiver uses the fixed-filter style in its reservation message  it specifies a list of senders from which it wants to receive a data flow along with a bandwidth reservation for each of these senders these reservations are distinct  i.e  they are not to be shared shared-explicit style  when a receiver uses the shared-explicit style in its reservation message  it specifies a list of senders from which it wants to receive a data flow along with a single bandwidth reservation this reservation is to be shared among all the senders in the list shared reservations  created by the wildcard filter and the shared-explicit styles  are appropriate for a multicast session whose sources are unlikely to transmit simultaneously packetized audio is an example of an application suitable for shared reservations ; because a limited number of people talk at once  each receiver might issue a wildcard-filter or a shared-explicit reservation request for twice the bandwidth required for one sender  to allow for over speaking   on the other hand  the fixed-filter reservation  which creates distinct reservations for the flows from different senders  is appropriate for video teleconferencing examples of reservation styles following the internet rfc  we now give examples for the three reservation styles in figure 6.8.4  a router has two incoming interfaces  labeled a and b  and two utgoing interfaces  labeled c and d the many-to-many multicast session has three senders  s1  s2 and s3  and three receivers  r1  r2 and r3 figure 6.9-4 also shows that interface d is connected to a lan figure 6.8-4  sample scenario for rsvp reservation styles suppose first that all of the receivers use the wildcard-filter reservation as shown in the figure 689-5  receivers r1  r2  and r3 want to reserve 4b  3b  and 2b  respectively  where b is a given bit rate then the router reserves 4b on interface c and 3b on interface d because of the wildcard-filter reservation  the two reservations from r2 and r3 are merged for interface d  the larger of the two reservations is file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  7 of 12  20/11/2004 15  52  57 rsvp used rather than the sum of reservations the router then sends a reservation message upstream to interface a and another to interface b ; each of these reservation messages requests is 4b  which is the larger of 3b and 4b figure 6.8-5  wildcard filter reservations now suppose that all of the receivers use the fixed-filter reservation as shown in figure 6.8-6  receiver r1 wants to reserve 4b for source s1 and 5b for source s2 ; also shown in the figure are the reservation requests from r2 and r3 because of the fixed-filter style  the router reserves two disjoint chunks of bandwidth on interface c  one chunk of 4b for s1 and another chunk of 5b for s2 similarly  the router reserves two disjoint chunks of bandwidth on interface d  one chunk of 3b for s1  the maximum of b and 3b  and one chunk of b for s3 on interface a  the router sends a message with a reservation for s1 of 4b  the maximum of 3b and 4b   on interface b  the router sends a message with a reservation of 5b for s2 and b for s3 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  8 of 12  20/11/2004 15  52  57 rsvp figure 6.8-6  fixed filter reservations finally suppose that each of the receivers use the shared-explict reservation as shown in tfigure 6.8-7  receiver r1 desires a pipe of 1b which is to be shared between sources s1 and s2  receiver r2 desires a pipe of 3b to be shared between sources s1 and s3  and receiver r3 wants a pipe of 2b for source s2 because of the shared-explicit style  the reservations from r2 and r3 are merged for interface d  only one pipe is reserved on interface d  although it is reserved at the maximum of the reservation rates rsvp will reserve on interface b a pipe of 3b to be shared by s2 and and s3 ; note that 3b is the maximum of the downstream reservations for s2 and s3 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/rsvp.htm  9 of 12  20/11/2004 15  52  57 rsvp figure 6.8-7  shared-explicit reservations in each of the above examples the three receivers used the same reservation style because receivers make independent decisions  the receivers participating in a session could use different styles rsvp does not permit  however  reservations of different styles to be merged 6.8.5 soft state the reservations in the routers and hosts are maintained with soft states by this it is meant that each reservation for bandwidth stored in a router has an associated timer if a reservation 's timer expires  then the reservation is removed if a receiver desires to maintain a reservation  it must periodically refresh the reservation by sending reservation messages a receiver can also change its reservation  e.g  the amount of bandwidth or the senders it wants to receive from  by adjusting its reservation in its stream of refresh messages the senders must also refresh the path state by periodically sending path messages when a route changes  the next path message initializes the path state on the new route  and future reservation messages will establish reservation state in the route the state on the old segments of the route will time out soft state  whereby the state is maintained with refresh messages  is used by many other protocols in data networking for example  as we learned in chapter 5  in the routing tables in transparent bridges  the entries are refreshed by data packets that arrive to the bridge ; entries that are not refreshed are timedout a protocol that takes explicit actions to modify or release state is called a hard-state protocol an example of a hard-state protocol is tcp  whereby the connection does not timeout if it stops being used ; instead one side of the connection must explicitly destroy the connection 6.8.6 transport of reservation messages rsvp messages are sent hop-by-hop directly over ip thus the rsvp message is placed in the information field of the ip datagram ; the protocol number in the ip datagram is set to 46 because ip is unreliable  rsvp messages are not acknowledged upon arrival if an rsvp path or reservation message is lost  a replacement refresh message should arrive soon an rsvp reservation message that originates in a host will have the host 's ip address in the source address field of the encapsulating ip datagram it will have the ip address of the first router along the reserve-path in the multicast tree in destination address in the encapsulating ip datagram  when the ip datagram arrives at the first router  the router strips off the ip fields and passes the reservation message to the router 's rsvp module the rsvp module examines the messages multicast address  i.e  session identifier  and style type  examines its current state  and then acts appropriately ; for example  the rsvp module may merge the reservation with a reservation originating from another interface and then send a file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/rsvp.htm  10 of 12  20/11/2004 15  52  57 rsvp new reservation message to the next router upstream in the multicast tree insufficient resource because a reservation request that fails an admission test may embody a number of requests merged together  a reservation error must be reported to all the concerned receivers these reservation errors are reported within resverror messages the receivers can then reduce the amount of resource that they request and try reserving again the rsvp standard provides mechanisms to allow the backtracking of the reservations when insufficient resources are available ; unfortunately  these mechanisms add significant complexity to the rsvp protocol furthermore  rsvp suffers from the so-called killerreservation problem  whereby a receiver requests over and over again a large reservation  each time getting its reservation rejected due to lack of sufficient resources because this large reservation may have been merged with smaller reservations downstream  the large reservation may be excluding smaller reservations from being established to solve this thorny problem  rsvp uses the resverror messages to establish additional state in routers  called blockade state blockade state in a router modifies the merging procedure to omit the offending reservation from the merge  allowing a smaller request to be forwarded and established the blockade state adds yet further complexity to the rsvp protocol and its implementation references  rfc 2205  r braden  ed  l zhang  s berson  s herzog  s jamin  " resource reservation protocol  rsvp   version 1 functional specification  " rfc 2205  september 1997  rfc 2210  j wroclawski  " the use of rsvp with ietf integrated services  " rfc 2210  sept 1997 rsvp links l rsvp working group  the official ietf working group page l rsvp for the multimedia party  cisco 's point of view of how rsvp relates to multimedia applications l protocol keeps packets in line  a short article from web week magazine l guidelines for deployment of rsvp  at present  many vendors of operating systems and routers are incorporating rsvp and integrated services into their products for near-future availability this rfc describes those uses of the current rsvp specification that are known to be feasible  and to identify areas of limitation and ongoing chartered work addressing some of these limitations search rfcs and internet drafts if you are interested in an internet draft relating to a certain subject or protocol enter the keyword  s  file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/rsvp.htm  11 of 12  20/11/2004 15  52  57 rsvp here query  press button to submit your query or reset the form  query options  case insensitive maximum number of hits  return to table of contents copyright james f kurose and keith w ross 1996-2000  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/rsvp.htm  12 of 12  20/11/2004 15  52  57 differentiated services 6.9 differentiated services in the previous section we saw how rsvp reserves per-flow resources at routers within the network the ability to request and reserve per-flow resources  in turn  makes it possible for the intserv framework to provide quality of service guarantees to individual flows as work on intserv and rsvp proceeded  however  researchers involved with these efforts  e.g   zhang 1998   have begun to uncover some of the difficulties associated with the intserv model and per-flow reservation of resources  l scalability the per-flow resource reservation in rsvp implies the need for a router to process resource reservations and to maintain per-flow state for each flow passing though the router with recent measurements  thompson 1997  suggesting that even for an oc-3 speed link  approximately 256,000 source-destination pairs might be seen in one minute in a backbone router  per-flow reservation processing represents a considerable overhead in large neworks l flexible service models the intserv framework provides for a small number of pre-specified service classes this particular set of service classes does not allow for more qualitative or relative definitions of service distinctions  e.g  " service class a will received preferred treatment over service class b "   these more qualitiative definitions might well better fit our intuitive notion of service distinction  e.g  first class versus coach class in air travel ; " platinum " versus " gold " versus " standard " credit cards   l better-than-best-effort service to applications  without the need for host rsvp signaling few hosts in today 's internet are able to generate rsvp signaling or express the rspec and tspec in the detail needed by the intserv model these considerations have led to the recent so-called " diffserv "  differentiated services  activity  diffserv 1999  within the internet engineering task force the diffserv working group is developing an architecture for providing scalable and flexible service differentiation  i.e  the ability to handle different " classes " of traffic in different ways within the internet the need for scalability arises from the fact that hundreds of thousands simultaneous source-destination traffic flows may be present at a backbone router of the internet we will see shortly that this need is met by placing only simple functionality within the network core  with more complex control operations being implemented towards the " edge " of the network the need for flexibilty arises from the fact that new service classes may arise and old service classes may become obsolete the differentiated services architecture is flexible in the sense that it does not define specific services or service classes  e.g  as is the case with intserv   instead  the differentiated services architecture provides the functional components  i.e  the " pieces " of a network architecture  with which such services can be built let us now examine these components in detail 6.9.1 differentiated services  a simple scenario to set the framework for defining the architectural components of the differentiated service model  let file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  1 of 8  20/11/2004 15  52  58 differentiated services us begin with the simple network shown in figure 6.8-1 in the following  we describe one possible use of the diffserv components many other possible variations are possible  as described in  rfc 2475   our goal here is to provide an introduction to the key aspects of differentiated services  rather than to describe the architecural model in exhaustive detail figure 6.9-1  a simple diffserv network example the differentiated services architecture consists of two sets of functional elements  l edge functions  packet classification and traffic conditioning at the incoming " edge " of the network  i.e  at either a differentiated services capable host that generates traffic or at the first ds-capable router that the traffic passes through   arriving packets are marked more specifically  the diffierentiated service  ds  field of the packet header is set to some value for example  in figure 6.7-1  packets being sent from h1 to h3 might be marked at r1  while packets being sent from h2 to h4 might be marked at r2 the mark that a packet receives identifies the class of file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  2 of 8  20/11/2004 15  52  58 differentiated services traffic to which it belongs different classes of traffic will then receive different service within the core network the rfc defining the differeniated service architecture  rfc 2475  uses the term " behavior aggregate " rather than " class of traffic " after being marked  a packet may then be immediately forwarded into the network  delayed for some time before being forwarded  or may be discarded we will see shortly that many factors can influence how a packet is to be marked  and whether it is to be forwarded immediately  delayed  or dropped l core function  forwarding when a ds-marked packet arrives at a ds-capable router  the packet is forwarded onto its next hop according to the so-called per-hop behavior associated with that packet 's class the per-hop behavior influences how a router 's buffers and link bandwidth are shared among the competing classes of traffic a crucial tenet of the ds architecture is that a router 's per-hop behavior will be based only on packet markings  i.e  the class of traffic to which a packet belongs thus  if packets being sent from h1 to h3 in figure 6.7-1 receive the same marking as packets from h2 to h4  then the network routers treat these packets as a aggregate  without distinguishing whether the packets originated at h1 or h2 for example  r3 would not distinguish between packets from h1 and h2 when forwarding these packets on to r4 thus  the differentiated service architecture obviates the need to keep router state for individial source-destination pairs  an important consideration in meeting the scalability requirement discussed at the beginning of this section an analogy might prove useful here at many large-scale social events  e.g  a large public reception  a large dance club or discoteque  a concert  a football game   people entering the event receive a " pass " of one type or another there are vip passes for very important people ; there are over-18 passes for people who are eighteen years old or older  e.g  if alcoholic drinks are to be served  ; there are backstage passes at concerts ; there are press passes for reporters ; there is an ordinary pass  sometimes simply the lack of a special pass  for the ordinary person these passes are typically distributed on entry to the event  i.e  at the " edge " of the event it is here at the edge where computationally intensive operations such as paying for entry  checking for the appropriate type of invitation  and matching an invitation against a piece of identification  are performed futhermore  there may be a limit on the number of people of a given type that are allowed into an event if there is such a limit  people may have to wait before entering the event once inside the event  one 's pass allows one to receive differentiated service at many locations around the event  a vip is provided with free drinks  a better table  free food  entry to exclusive rooms  and fawning service conversely  an ordinary person is excluded from certain areas  pays for drinks  and receives only basic service in both cases  the service received within the event depends solely on the type of one 's pass moreover  all people within a class are treated alike 6.9.2 traffic classification and conditioning in the differentiated services architecture  a packet 's mark is carried within the so-called differentiated services  ds  field in the ipv4 or ipv6 packet header the definition of the ds field is intended to supersede the earlier definitions of the ipv4 type-of-service field  see section 4.4  and the ipv6 traffic class field  see section 4.7   the structure of this 8-bit field is shown below in figure 6.8-2 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  3 of 8  20/11/2004 15  52  58 differentiated services figure 6.8-2  structure of the ds field in ivv4 and ipv6 header the 6-bit differentiated service code point  dscp  subfield determines the so-called per-hop behavior  see section 6.8.4  that the packet will receive within the network the 2-bit cu subfield of the ds field is currently unused restrictions are placed on the use of half of the dscp values in order to preserve backward compatability with the ipv4 tos field use ; see  rfc 2474  for details for our purposes here  we need only note that a packet 's mark  its " code point " in the ds terminology  is carried in the 8-bit ds field as noted above  a packet is marked  more specificially  its ds field value is set  at the edge of the network this can either happen at a ds-capable host or at the first point at which the packet encounters a ds-capable router for our discussion here  we will assume marking occurs at an edge router that is directly connected to a sender  as shown in figure 6.9-1 figure 6.9-3  simple packet classification and marking figure 6.9-3 provides a logical view of the classification and marking function within the edge router packets arriving to the edge router are first " classified " the classifier selects packets based the values of one or more packet header fields  e.g  source address  destination address  source port  destination port  protocol id  and steers the packet to the appropriate marking function the ds field value is then set accordingly at the marker once packets are marked  they are then forwarded along their route to the destination at each subsequent ds-capable router  these marked packets then receive the service associated with the packets ' marks even this simple marking scheme can be used to support different classes of service within the internet for example  all packets coming from a certain set of source ip addresses  e.g  those ip addresses that have paid for an expensive priority service within their isp  could be marked on entry to the isp  and then receive a specific forwarding service  e.g  a higher priority forwarding  at all subsequent ds-capable routers a question not addressed by the diffserv working group is how the classifier obtains the " rules " for such classification this could be done file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  4 of 8  20/11/2004 15  52  58 differentiated services manually  i.e  the network administrator could load a table of source addresses that are to be marked in a given way into the edge routers  or could be done under the control of some yet-to-be-specified signalling protocol in figure 6.9-3  all packets meeting a given header condition receive the same marking  regardless of the packet arrival rate in some scenarios  it might also be desirable to limit the rate at which packets bearing a given marking are injected into the network for example  an end-user might negotiate a contract with its isp to receive high priority service  but at the same time agree to limit the maximum rate at which it would send packets into the network that is  the end user agrees that its packet sending rate would be within some declared traffic profile the traffic profile might contain a limit on the peak rate  as well as the burstiness of the packet flow  as we saw in section 6.6 with the leaky bucket mechanism as long as the user sends packets into the network in a way that conforms to the negotiated traffic profile  the packets receive their priority marking on the other hand  if the traffic profile is violated  the out-of-profile packets might be marked differently  might be shaped  e.g delayed so that a maximum rate constraint would be observed   or might be dropped at the network edge the role of the metering function  shown in figure 6.9-4  is to compare the incoming packet flow with the negotiated traffic profile and to determine whether a packet is within the negotiated traffic profile the actual decision about whether to immediately re-mark  forward  delay  or drop a packet is not specified in the diffserv architecture the diffserv architecture only provides the framework for performing packet marking and shaping/dropping ; it does not mandate any specific policy for what marking and conditioning  shaping or dropping  is actually to be done the hope  of course  is that the diffserv architectural components are together flexible enough to accomodate a wide and constant evolving set of services to end users figure 6.9-4  logical view of packet classification and traffic conditioning at the edge router 6.9.3 per-hops behavior file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  5 of 8  20/11/2004 15  52  58 differentiated services so far  we have focused on the edge functions in the differentiated services architecture the second key component of the ds architecture involves the per hop behavior  i.e  packet forwarding function  performed by ds-capable routers the per-hop behavior  phb  is rather cryptically  but carefully  defined as " a description of the externally observable forwarding behavior of a ds node applied to a particular ds behavior aggregate "  rfc 2475   digging a little deeper into this definition  we can see several important considerations embedded within  l a phb can result in different classes of traffic  i.e  traffic with different ds field values  receiving different performance  i.e  different externally observable forwarding behavior   l while a phb defines differences in performance  behavior  among classes  it does not mandate any particular mechanism for achieving these behaviors as long as the externally observable performance criteria are met  any implementation mechanism and any buffer/bandwidth allocation policy can be used for example  a phb would not require that a particular packet queueing discipline  e.g  a priority queue versus a weighted-fair-queueing queue versus a firstcome first-served queue  be used to achieve a particular behavior the phb is the " end "  to which resource allocation and implemention mechanisms are the " means " l differences in performance must be observable  and hence measurable an example of a simple phb is one that guarantees that a given class of marked packets receive at least x % of the outgoing link bandwidth over some interval of time another per-hop behavior might specify that one class of traffic will always receive strict priority over another class of traffic  i.e  if a high priority packet and low priority are present in a router 's queue at the same time  the high priority packet will always leave first note that while a priority queueing discipline might be a natural choice for implementing this second phb  any queueing discipline that implements the required observable behavior is acceptable currently  two phb 's are under active discussion within the diffserv working group  an expedited forwarding  ef  phb  jacobson 1999  and an assured forwarding  af  phb  heinanen 1999   l the expedited forwarding phb specifies that the departure rate of a class of traffic from a router must equal or exceed a configured rate that is  during any interval of time  the class of traffic can be guaranteed to receive enough bandwidth so that the output rate of the traffic equals or exceeds this minimum configured rate note that the ef per hop behavior implies some form of isolation among traffic classes  as this guarantee is made independently of the traffic intensity of any other classes that are arriving to a router thus  even if the other classes of traffic are overwhelming router and link resources  enough of those resources must still be made available to the class to ensure that it receives its minimum rate guarantee ef thus provides a class with the simple abstraction of a link with a minumum guaranteed link bandwidth l the assured forwarding phb is more complex af divides traffic into four classes  where each af class is guaranteed to be provided with some minimum amount of bandwidth and file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  6 of 8  20/11/2004 15  52  58 differentiated services buffering within each class  packets are further partitioned into one of three " drop preference " categories when congestion occurs within an af class  a router can then discard  drop  packets based on their drop preference values see  heinanen 1999  for details by varying the amount of resources allocated to each class  an isp can provide different levels of performance to the different af traffic classes the af phb could be used as a building block to provide different levels of service to the end systems  e.g  an olympic-like gold  silver  and bronze classes of service but what would be required to do so ? if gold service is indeed going to be " better "  and presumably more expensive !  than silver service  then the isp must ensure that gold packets receive lower delay and/or loss than silver packets recall  however  that a minimum amount of bandwidth and buffering are to be allocated to eachclass what would happen if gold service was allocated x % of a link 's bandwidth and silver service was allocated x/2 % of the link 's bandwidth  but the traffic intensity of gold packets was 100 times higher than that of silver packets ? in this case  it is likely that silver packets would receive betterperformance than the gold packets !  an outcome that leaves the silver service buyers happy  but the high-spending gold service buyers extremely unhappy !  clearly  when creating a service out of a phb  more than just the phb itself will come into play in this example  the dimensioning of resources  determining how much resources will be allocated to each class of service  must be done hand-in-hand with knowledge about the traffic demands of the various classes of traffic 6.9.4 a beginning the differentiated services architecture is still in the early stages of its development and is rapidly evolving rfc 's 2474 and 2475  rfc1474    rfc2475  define the fundamental framework of the diffserv architecture but themselves are likely to evolve as well the af and ef phb 's discussed above have yet to enter the rfc standards track the ways in which phb 's  edge functionality  and traffic profiles can be combined to provide an end-to-end services  such as a virtual leased line service  nicols 1998  or an olympic-like gold/silver/bronze service  heinanen 1999   are still under investigation in our discussion above  we have assumed that the ds architecture is deployed within a single adminstrative domain the  typical  case where an end-to-end service must be fashioned from a connection that crosses several administrative domains  and through non-ds capable routers  pose additional challenges beyond those described above references  diffserv 1999  the ietf differentiated services working group homepage  http  //www.ietf.org/html charters/diffserv-charter.html  heinanen 1999  juha heinanen  fred baker  walter weiss  john wroclawski  " assured forwarding file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  7 of 8  20/11/2004 15  52  58 differentiated services phb group "  internet draft < draft-ietf-diffserv-af-04.txt >  january 1999  jacobson 1999  v jacobson  kathleen nichols  kedernath poduri  " an expedited forwarding phb "  internet draft < draft-ietf-diffserv-phb-ef-02.txt > feb 1999  nicols 1998  k nicols  v jacobson  l zhang  " a two bit differentiated services architecture for the internet " unpublished draft  rfc 2474  k nicols  s blake  f baker  d black  " definition of the differentiated services field  ds field  in the ipv4 and ipv6 headers "  rfc 2474  december 1998  rfc 2475  s blake  d black  m carlson  e davies  z wang  w weiss  " an architecture for differentiated services "  rfc 2475  dec 1998  thomson 1997  k thomson  g miller  r wilder  " wide area traffic patterns and characteristics  " ieee network magazine  dec 1997  zhang 1998  lixia zhang  r yavatkar  fred baker  peter ford  kathleen nichols  m speer  y bernet  " a framework for use of rsvp with diff-serv networks "  < draft-ietf-diffserv-rsvp-01.txt >  11/20/1998 return to table of contents copyright james f kurose and keith w ross 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/diffserv.htm  8 of 8  20/11/2004 15  52  58 chapter 6 summary 6.10 summary multimedia networking is perhaps the most exciting development in the internet today people throughout the world are spending less time in front their radios and televisions and are instead turning to the internet to receive audio and video emissions  both live and prerecorded as high-speed access penetrates more residences  this trend will continue  couch potatoes throughout the world will access their favorite video programs through the internet rather then through the traditional microwave and satellite channels in addition to audio and video distribution  the internet is also being used to transport phone calls in fact  over the next ten years the internet mayl render the traditional circuit-switched telephone system obsolete in many countries the internet will not only provide phone service for less money  but will also provide numerous value-added services  such as video conferencing  online directory services  and voice messaging services in section 6.1 we classified multimedia applications into three categories  streaming stored audio and video ; one-to-many transmission of real-time audio and video ; and real-time interactive audio and video we emphasized that multimedia applications are delay sensitive and loss tolerant  which is very different from static-content applications  which are delay tolerant and loss intolerant we also discussed some of the hurdles that today 's best-effort internet places before multimedia applications we surveyed several proposals to overcome these hurdles  including simply improving the existing networking infrastructure  by adding more bandwidth  more network caches  and deploying multicast   adding functionality to the internet so that applications can reserve end-to-end resources  and so that the network can honor these reservations   and finally introducing service classes to provide service differentiation in sections 6.2-6.4 we examined architectures and mechanisms for multimedia networking in a besteffort network in section 6.2 we surveyed several architectures for streaming stored audio and video we discussed user interaction  such as pause/resume  repositioning  and visual fast forward  and provided an introduction to rtsp  a protocol that provides client-server interaction to streaming applications in section 6.3 we examined how interactive real-time applications can be designed to run over a best effort network we saw how a combination of client buffers  packet sequence numbers and timestamps can greatly alleviate the effects of network induced jitter we also studied how forward error correction and packet interleaving can improve user perceived performance when a fraction of the packets are lost or are significantly delayed in section 6.4 we explored media chunk encapsulation  and we investigated in some detail one of the more important standards for media encapsulation  namely  rtp we also looked at how rtp fits into the emerging h.323 architecture for interactive real-time conferencing sections 6.5-6.9 looked at how the internet can evolve to provide guaranteed qos to its applications in section 6.5 we identified several principles for providing qos to multimedia applications these principles include packet marking and classification  isolation of packet flows  efficient use of resources  and call admission in section 6.6 we surveyed a variety scheduling policies and policing mechanisms that can provide the foundation of a qos networking architecture the scheduling policies include file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/6sum.htm  1 of 2  20/11/2004 15  52  58 chapter 6 summary priority scheduling  round-robin scheduling  and weighted-fair queuing we then explored the leaky bucket as a policing mechanism  and showed how the leaky bucket and weighted-fair queuing can be combined to bound the maximum delay a packet experiences at the output queue of a router in sections 6.7-6.9 we showed how these principles and mechanisms have led to the definitions of new standards for providing qos in the internet the first class of these standards is the so-called intserv standard  which includes two services  the guaranteed qos service and the controlled load service the guaranteed qos service provides hard  mathematical provable guarantees on the delay of each of the individual packets in a flow the control-load service does not provide any hard guarantees  but instead ensures that most of an application 's packets will pass through a seemingly uncongested internet the intserv architecture requires a signaling protocol for reserving bandwidth and buffer resources within the network in section 6.8 we examined in some detail an internet signaling protocol for reservations  namely  rsvp we indicated that one of the drawbacks of rsvp  and hence the intserv architecture  is the need for routers to maintain per-flow state  which may not scale we concluded the chapter in section 6.9 by outlining a recent and promising proposal for providing qos in the internet  namely  the diffserv architecture the diffserv architecture does not require routers to maintain per-flow state ; it instead classifies packets into a small number of aggregate classes  to which routers provide per-hop behavior the diffserv architecture is still in its infancy  but because the architecture requires relatively minor changes to the existing internet protocols and infrastructure  it could be deployed relatively quickly now that we have finished our study of multimedia networking  it is time to move on to another exciting topic in networking  namely  network security recent advances in multimedia networking may displace the distribution of audio and video information to the internet ; as we shall see in the next chapter  recent advances in network security may displace the majority of economic transactions to the internet copyright 1996-2000 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/6sum.htm  2 of 2  20/11/2004 15  52  58 homework problems  multimedia netowrking homework problems and discussion questions chapter 6 review questions sections 6.1-6.2 1  what is meant by interactivity for streaming stored audio/video ? what is meant by interactivity for real-time interactive audio/video ? 2  three " camps " were discussed for evolving the internet so that it better supports multimedia applications briefly summarize the views of each camp in which camp do you belong ? 3  figures 6.2-2  6.2-3 and 6.2-4 present three schemes for streaming stored media what are the advantages and disadvantages of each scheme ? sections 6.3-6.4 4  what is the difference between end-to-end delay and delay jitter ? what are the causes of delay jitter ? 5  why is a packet that is received after its scheduled playout time considered lost ? 6  section 6.3 describes two fec schemes briefly summarize them both schemes increase the transmission of the stream by adding overhead does interleaving also increase the transmission rate ? 7  how are different rtp streams in different sessions identified by a receiver ? how are different streams from within the same session identified ? how are rtp and rtpc packets  as part of the same session  distinguished 8  three rtcp packet types are described in section 6.4 briefly summarize the information contained in each of these packet types 9  in figure 6.4-9  which of the h.323 channels run over tcp and which over udp ? why ? sections 6.5-6.9 10  in section 6.6  we discussed non-preemptive priority queuing what would be preemptive priority file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/mmhw.htm  1 of 5  20/11/2004 15  52  59 homework problems  multimedia netowrking queueing ? does preemptive priority queueing make sense for computer networks ? 11  give an example of scheduling discipline that is not work conserving 12  guaranteed service provides an application no loss and firm bounds on delay referring back to figure 2.1-2  are there any applications that require both no loss and firm bounds on delay ? 13  what are some of the difficulties associated with the intserv model and per-flow reservation of resources ? problems 1  surf the web and find three products for streaming stored audio and/or video for each product  determine   a  whether meta files are used ;  b  whether the audio/video is sent over udp or tcp ;  c  whether rtp is used ;  d  and whether rtsp is used 2  write a poem  a short story  a description of a recent vacation  or any other piece which takes 2-5 minutes to recite recite and record your piece convert your recording to one of the realnetworks audio formats using one of the realnetworks free encoders upload the file to the same server that holds your personal homepage also upload the corresponding meta file to the server finally create a link from your homepage to the meta file 3  consider the client buffer shown in figure 6.2-4 suppose that the streaming system uses the fourth option  that is  the server pushes the media into the socket as quickly as possible suppose the available tcp bandwidth > > d most of the time also suppose that the client buffer can only hold about one third of the media describe how x  t  and the contents of the client buffer will evolve over time 4  are the tcp receive buffer and the media player 's client buffer the same thing ? if not  how do they interact ? 5  in the internet phone example in section 6.3  let h be the total number header bytes added to each chunk  including udp and ip header  a  assuming an ip datagram is emitted every 20 msec  find the transmission in bits in second for the datagrams generated by one side of this application  b  5  consider the procedure described in section 6.3 for estimating average delay di suppose that u = .1 let r1  t1 be the most recent sample delay  let r2  t2 be the next most recent sample delay  etc file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/mmhw.htm  2 of 5  20/11/2004 15  52  59 homework problems  multimedia netowrking  a  for a given audio application suppose four packets have arrived at the receiver with sample delays r4  t4  r3  t3  r2  t2  r1  t1  express the estimate of delay d in terms of the four samples  b  generalize your formula for n sample delays  c  for the formula in part  b  let n approach infinity and give the resulting formula omment on why this averaging procedure is called an exponential moving average 6  repeat the above question for the estimate of average delay deviation 7  compare the procedure described in section 6.3 for estimating average delay with the procedure in section 3.5 for estimating round-trip time what do the procedures have in common ? how are they different ? 8  consider the adaptive playout strategy described in section 6.3  a  how can two successive packets received at the destination have timestamps that differ by more than 20 msecs when the two packets belong to the same talkspurt ?  b  how can the receiver use sequence numbers to determine whether a packet is the first packet in a talkspurt ? be specific 9  recall the two fec schemes for internet phone described in section 6.3 suppose that the first scheme generates a redundant chunk for every four original chunks suppose the second scheme uses a low-bit-rate encoding whose transmission rate is 25 % the transmission rate of nominal stream  a  how much additional bandwidth does each scheme require ? how much playback delay does each scheme add ?  b  how do the two schemes perform if at most one packet is lost in every group of five packets ? which scheme will have better audio quality ?  c  how do the two schemes perform if at most one packet is lost in every group of two packets ? which scheme will have better audio quality ? 10  how is the interarrival time jitter calculated in the rtcp reception report ? hint  read the rtp rfc 11  suppose in a rtp session there are s senders and r receivers use the formulas at the end of section 6.4 to show that rtcp limits its traffic to 5 % of the session bandwidth 12   a  how is rstp similar to http ? does rstp have methods ? can http be used to file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/mmhw.htm  3 of 5  20/11/2004 15  52  59 homework problems  multimedia netowrking request a stream ?  b  how is rstp different from http for example  is http in-band or out-of-band ? does rtsp require state information about the client  consider the pause/resume function  ? 13  what are the current microsoft products for audio/video real-time conferencing do these products use any of the protocols discussed in this chapter  e.g  rtp or rtsp  ? 14  suppose that the wfq scheduling policy is applied to a buffer that supports three classes  and suppose the weights are .5  .25 and .25 for the three classes a  suppose that each class has a large number of packets in the buffer in what sequence might the three classes be served in to achieve the wfq weights ?  for round-robin scheduling  a natural sequence is 123123123   b  suppose that classes 1 and 2 have a large number of packets in the buffer  and there are no class 2 packets in the buffer in what sequence might the three classes be served in to achieve the wfq weights ? 15  consider the leaky bucket policer  discussed in section 6.6  that polices the average rate and burst size of a packet flow we now want to police the peak rate  p  as well show how the output of this leaky bucket policer can be fed into a second leaky bucket policer so that the two leaky buckets in series police the average rate  peak rate  and burst size be sure to give the bucket size and token generation rate for the second policer 16  a packet flow is said to conform to a leaky bucket specification  r,b  with burst size b and average rate r if the number of packets that arrive to the leaky bucket is less than rt + b packets in every interval of time of length t for all t will a packet flow that conforms to a leaky bucket specification  r,b  ever have to wait at a leaky bucket policer with parameters r and b ? justify your answer 17  show that as long as r1 < r  wi/  ? wj   then dmax is indeed the maximum delay that any packet in flow 1 will ever experience in the wfq queue discussion questions 1  how can a host use rtcp feedback information to determine whether problems are local  regional  or global ? 2  do you think it is better to stream stored audio/video on top of tcp or udp ? 3  in rsvp  are reservation sytles relevant for one-to-many multicast sessions ? file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/mmhw.htm  4 of 5  20/11/2004 15  52  59 homework problems  multimedia netowrking 4  write a one-page report on prospects for internet phone in the market place 5  can the problem of providing qos guarantees be solved simply by " throwing enough bandwidth " at the problem  i.e  by upgrading all link capacities so that bandwidth limitations are no longer a concern ? 6  an interesting emerging market is using internet phone and a company 's high-speed lan to replace the same company 's pbx  private branch exchange   write a one-page report on this issue cover the following questions in your report   a  what is a traditional pbx ? who uses them ?  b  consider a call between a user in the company and another user out of the company  who is connected to the traditional telephone network what sort of technology is needed at the interface between the lan and the traditional telephone network ?  c  in addition to internet phone software and the interface of question  b   what else is needed to replace the pbx ? 7  consider the four " pillars " of providing qos support in section 6.5 describe the circumstances  if any  under which each of these pillars can be removed 8  use the web to find three companies that manufacture h.323 gatekeepers describe their products file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/mmhw.htm  5 of 5  20/11/2004 15  52  59 what is network security ? 7.1 what is network security ? let us introduce alice and bob  two people who want to communicate " securely " this being a networking text  we should remark that alice and bob may be two routers that want to securely exchange routing tables  two hosts that want to establish a secure transport connection  or two email applications that want to exchange secure e-mail  all case studies that we will consider later in this chapter alice and bob are well-known fixtures in the security community  perhaps because their names are more fun than a generic entity named " a " that wants to securely communicate with a generic entity named " b " illicit love affairs  wartime communication  and business transactions are the commonly cited human needs for secure communications ; preferring the first to the latter two  we 're happy to use alice and bob as our sender and receiver  and imagine them in this first scenario 7.1.1 secure communication we said that alice and bob want to communicate " securely  " but what precisely does this mean ? certainly  alice wants only bob to be able to understand a message that she has sent  even though they are communicating over an " insecure " medium where an intruder  trudy  the intruder  may intercept  read  and perform computations on whatever is transmitted from alice to bob bob also wants to be sure that the message that he receives from alice was indeed sent by alice  and alice wants to make sure that the person with whom she is communicating is indeed bob alice and bob also want to make sure that the contents of alice 's message have not been altered in transit given these considerations  we can identify the following desirable properties of secure communication  l secrecy only the sender and intended receiver should be able to understand the contents of the transmitted message because eavesdroppers may intercept the message  this necessarily requires that the message be somehow encrypted  disguise data  so that an intercepted message can not be decrypted  understood  by an interceptor this aspect of secrecy is probably the most commonly perceived meaning of the term " secure communication " note  however  that this is not only a restricted definition of secure communication  we list additional aspects of secure communication below   but a rather restricted definition of secrecy as well for example  alice might also want the mere fact that she is communicating with bob  or the timing or frequency of her communications  to be a secret ! we will study cryptographic techniques for encrypting and decrypting data in section 7.2 l authentication both the sender and receiver need to confirm the identity of other party involved in the communication  to confirm that the other party is indeed who or what they claim to be face-to-face human communication solves this problem easily by visual recognition when communicating entities exchange messages over a medium where they can not " see " the other party  authentication is not so simple why  for instance  should you believe that a received email containing a text string saying that the email came from a friend of yours indeed came from that friend ? if someone calls on the phone claiming to be your bank and asking for your account number  secret pin  and account balances for verification purposes  would you give that information out over the phone ? hopefully not we will examine authentication techniques in section 7.3  including several that  perhaps surprisingly  also rely on the cryptographic techniques we study in section 7.2 l message integrity even if the sender and receiver are able to authenticate each other  they also want to insure file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/security_intro.htm  1 of 4  20/11/2004 15  53  00 what is network security ? that the content of their communication is not altered  either malicously or by accident  in transmission extensions to the checksumming techniques that we encountered in reliable transport and data link protocols will also be studied in section 7.3 ; these techniques also rely on cryptographic concepts in section 7.2 having established what we mean by secure communication  let us next consider exactly what is meant by an " insecure channel " what information does an intruder have access to  and what actions can be taken on the transmitted data ? figure 7.1-1 illustrates the scenario figure 7.1-1  sender  receiver and intruder  alice  bob  and trudy  alice  the sender  wants to send data to bob  the receiver in order to securely exchange data  while meeting the requirements of secrecy  authentication  and message integrity  alice and bob will exchange both control message and data messages  in much the same way that tcp senders and receivers exchange both control segments and data segments   all  or some of these message will typically be encrypted a passive intruder can listen to and record the control and data messages on the channel ; an active intruder can remove messages from the channel and/or itself add messages into the channel 7.1.2 network security considerations in the internet before delving into the technical aspects of network security in the following sections  let 's conclude our introduction by relating our fictitious characters  alice  bob  and trudy  to " real world " scenarios in today 's internet let 's begin with trudy  the network intruder can a " real world " network intruder really listen to and record network messages ? is it easy to do so ? can an intruder actively inject or remove messages from the network ? the answer to all of these questions is an emphatic " yes " a packet sniffer is a program running in a network attached device that file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/security_intro.htm  2 of 4  20/11/2004 15  53  00 what is network security ? passively receives all data-link-layer frames passing by the device 's network interface in a broadcast environment such as an ethernet lan  this means that the packet sniffer receives all frames being transmitted from or to all hosts on the local area network any host with an ethernet card can easily serve as a packet sniffer  as the ethernet interface card needs only be set to " promiscuous mode " to receive all passing ethernet frames these frames can then be passed on to application programs that extract application-level data for example  in the telnet scenario shown in figure 7.1 2  the login password prompt sent from a to b  as well as the password entered at b are " sniffed " at host c packet sniffing is a double-edged sword  it can be invaluable to a network administrator for network monitoring and management  see chapter 8  but also used by the unethical hacker packet-sniffing software is freely available at various www sites  and as commercial products professors teaching a networking course have been known to assign lab exercises that involve writing a packet-sniffing and application-level-data-reconstruction program figure 7.1-2  packet sniffing any internet-connected device  e.g  a host  necessarily sends ip datagrams into the network recall from chapter 4 that these datagrams carry the sender 's ip address  as well as application-layer data a user with complete control over that device 's software  in particular its operating system  can easily modify the device 's protocols to place an arbitrary ip address into a datagram 's source address field this is known as ip spoofing a user can thus craft an ip packet containing any payload  application-level  data it desires and make it appear as if that data was sent from an arbitrary ip host packet sniffing and ip spoofing are just two of the more common forms of security " attacks " on the internet these and other network attacks are discussed in the collection of essays  denning 1997   a summary of reported attacks is maintained at the cert coordination center  cert 1999   having established that there are indeed real bogeymen  a.k.a " trudy "  loose in the internet  what are the internet equivalents of alice and bob  our two friends who need to communicate securely ? certainly  " bob " and " alice " might be human user at two end systems  e.g  a real alice and a real bob who really do want to exchange secure email  e g  a user wanting to enter a credit card in a www form for an electronic purchase   they might also be participants in an electronic commerce transaction  e.g  a real alice might want to securely transfer her credit card number to a www server to purchase an item on-line similarly  a real alice might want to interact with her back on-line as noted in  rfc 1636   however  the parties needing secure communication might also themselves be part of the network infrastructure recall that the domain name system  dns  see section 2.5   or routing daemons that exchange routing tables  see section 4.5  require secure communication between two parties the same is true for network management applications  a topic we examine in the following chapter an intruder that could actively interfere with  control  or file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/security_intro.htm  3 of 4  20/11/2004 15  53  00 what is network security ? corrupt dns lookups and updates  routing computations  or network management functions could wreak havoc in the internet having now established the framework  a few of the most important definitions  and the need for network security  let us next delve into cryptography  a topic of central importance to many aspects of network security references  cert 1999  cert  " cert summaries  " http  //www.cert.org/summaries/  denning 1997  d denning  editor   p denning  preface   internet besieged  countering cyberspace scofflaws  addison-wesley pub co   reading ma  1997    kessler 1998  g.c kessler  an overview of cryptography  may 1998  hill associates  http  //www.hill.com/ techlibrary/index.htm  netscapepk 1998  introduction to public-key cryptography  netscape communications corporation  1998  http  // developer.netscape.com/docs/manuals/security/pkin/contents.htm  gutmannlinks 1999  p gutman  security resource link farm  http  //www.cs.auckland.ac.nz/ ~ pgut001/links.html  gutmanntutorial 1999  p.gutmann  godzilla crypto tutorial  http  //www.cs.auckland.ac.nz/ ~ pgut001/tutorial/ index.html  rfc 1636  r braden  d clark  s crocker  c huitema  " report of iab workshop on security in the internet architecture  " rfc 1636  nov 1994  rsa 1999  rsa 's cryptography faq  http  //www.rsa.com/rsalabs/faq/  punks 1999  cypherpunks web page  ftp  //ftp.csua.berkeley.edu/pub/cypherpunks/home.html copyright 1999-2000  keith w ross and jim kurose all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/security_intro.htm  4 of 4  20/11/2004 15  53  00 cryptogrpahy 7.2 principles of cryptography although cryptography has a long history dating back to julius caesar  we will look at the so-called caesar cipher shortly   modern cryptographic techniques  including many of those used in today 's internet  are based on advances made in past twenty years the books  kahn 1967  singh 1999  provide a fascinating look at this long history a detailed  but entertaining and readable  technical discussion of cryptography  particularly from a network standpoint  is  kaufman 1995    diffie 1998  provides a compelling and up-to-date examination of the political and social  e.g  privacy  issues that are now inextricably intertwined with cryptography a complete discussion of cryptography itself requires a complete book  kaufman 1995  schneier 1996  and so below we only touch on the essential aspects of cryptography  particularly as they are practiced in today 's internet two excellent on-line sites are  kessler 99  and the rsa labs faq page  rsa 1999c   cryptographic techniques allow a sender to disguise data so that an intruder can gain no information from the intercepted data the receiver  of course must be able to recover the original data from the disguised data figure 7.2-1 illustrates some of the important terminology  figure 7.2-1  cryptographic components suppose now that alice wants to send a message to bob alice 's message in its original form  e.g  " bob  i love you alice "  is known as plaintext  or cleartext alice encrypts her plaintext message using an encryption algorithm so that the encrypted message  known as ciphertext  looks unintelligible to any intruder interestingly  in many modern cryptographic systems  including those used in the internet  the encryption technique itself is known  published  standardized  and available to everyone  e.g   rfc 1321  rfc 2437,rfc 2420   even a potential intruder ! clearly  if everyone knows the method for encoding data  then there must be some bit of secret information that prevents an intruder from decrypting the transmitted file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  1 of 12  20/11/2004 15  53  02 cryptogrpahy data this is where keys come in in figure 7.2-1 alice provides a key  ka   a string of numbers or characters  as input to the encryption algorithm the encryption algorithm takes the key and the plaintext as input and produces ciphertext as output similarly  bob will provide a key kb  to the decryption algorithm  that takes the ciphertext and bob 's key as input and produces the original plaintext as output in so-called symmetric key systems  alice and bob 's keys are identical and are secret in public key systems  the key that alice uses is known to all  !   while bob 's key is secret in the following two subsections  we consider symmetric key and public key systems in more detail 7.2.1 symmetric key cryptography all cryptographic algorithms involve substituting one thing for another  e.g  taking a piece of plaintext and computing the appropriate ciphertext that forms the encrypted message before studying a modern key-based cryptographic system  let us first " get our feet wet " by studying a very old simple symmetric key algorithm attributed to julius caesar  known as the caesar cipher  a " cipher " is a method for encrypting data   for english text  the caesar cipher would work by taking each letter in the plaintext message and substituting the letter that is k letters later  allowing wraparound  i.e  having the letter " a " follow the letter " z "  in the alphabet for example if k = 4  then the letter " a " in plaintext becomes " d " in ciphertext ; " b " in plaintext becomes " e " in ciphertext  and so on here  the value of k serves as the key as an example  the plaintext message " bob  i love you alice " becomes " yly  f ilsb vlr xifzb " in ciphertext while the ciphertext does indeed look like gibberish  it would n't take long to break the code if you knew that the caesar cipher was being used  as there are only 25 possible key values an improvement to the caesar cipher is the so-called monoalphabetic cipher that also substitutes one letter in the alphabet with another letter in the alphabet however  rather than substituting according to a regular pattern  e.g  substitution with an offset of k for all letters   any letter can be substituted for any other letter  as long as each letter has a unique substitute letter and vice versa many newspaers in the us carry cryptographic puzzles based on this cipher the substitution rule in figure 7.2-2 shows one possible rule for encoding plaintext plaintext letter  a b c d e f g h i f k l m n o p q r s t u v w x y z ciphertext letter  m n b v c x z a s d f g h j k l p o i u y t r e w q figure 7.2-2  a monoalphabetic cipher the plaintext message " bob  i love you alice " becomes " nkn  s gktc wky mgsbc " thus  as in the case of the caesar cipher  this looks like gibberish a monoalphabetic cipher would also appear to be better than the caesar cipher in that there are 26 !  on the order of 1026  possible pairings of letters rather than 25 possible pairings a brute force approach of trying all 1026 possible pairings would require far too much work to be a feasible way of breaking the encryption algorithm and decoding the message however  by statistical analysis file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  2 of 12  20/11/2004 15  53  02 cryptogrpahy of the plaintext language  e.g  knowing that the letters " e " and " t " are the most frequently occurring letters in typical text  accounting for 13 % and 9 % of letter occurrences   and knowing that particular two and threeletter occurrences of letters appear quite often together  e.g  " in "  " it "  " the " " ion "  " ing "  etc  make it relatively easy to break this code if the intruder has some knowledge about the possible contents of the message  then it is even easier to break the code for example  if trudy the intruder is bob 's wife and suspects bob of having an affair with alice  then she might suspect that the names " bob " and " alice " appear in the text " if trudy knew for certain that those two names appeared in the ciphertext and had a copy of the example ciphertext message above  then she could immediately determine 7 of the 26 letter pairings  since " alice " is the only five-letter word in the message  and " bob " is the only three-letter word that has an identical first and last letter thus  trudy requires 109 fewer possibilities to be checked a by brute force method indeed  if trudy suspected bob of having an affair  she might well expect to find some other choice words in the message as well when considering how easy it might be for trudy to break bob and alice 's encryption scheme  one can distinguish three different scenarios  depending on what information the intruder has  l ciphertext only attack in some cases  the intruder may only have access to the intercepted ciphertext  with no certain information about the contents of the plaintext message we have seen how statistical analysis can help in a ciphertext only attack on an encryption scheme l known plaintext attack we saw above that if trudy somehow knew for sure that " bob " and " alice " appeared in the ciphertext message then she could have determined the  plaintext  ciphertext  pairings for the letters a  l  i  c  e  b  and o trudy might also have been fortunate enough to have recorded all of the ciphertext transmissions and then found bob 's own decrypted version of one of transmissions scribbled on a piece of paper when an intruder knows some of the  plaintext  ciphertext  pairings  we refer to this as a known plaintext attack on the encryption scheme l chosen plaintext attack in a chosen plaintext attack  the intruder is able to choose the plaintext message and obtain its corresponding ciphertext form for the simple encryption algorithms we 've seen so far  if trudy could get alice to send the message  " the quick fox jumps over the lazy brown dog  " she can completely break the encryption scheme we 'll see shortly that for more sophisticated encryption techniques  a chosen plaintext attack does not necessarily mean that the encryption technique can be broken five hundred years ago  techniques improving on monoalphabetic encryption  known as polyalphabetic encryption were invented these techniques  incorrectly attributed to blaise de vigenere  kahn 1967  have come to be known as vigenere ciphers the idea behind vigenere ciphers is to use multiple monoalphabetic ciphers  with a specific monoalphabetic cipher to encode a letter in a specific position in the plaintext message thus  the same letter  appearing in different positions in the plaintext message might be encoded differently the vigenere cipher shown in figure 7.2-3 has two different caesar ciphers  with k = 6 and k = 20   shown as rows in figure 7-2-3 one might choose to use these two caesar ciphers  c1 and c2  in the repeating pattern c1  c2  c2  c1  c2 that is  the first letter of plaintext is to encoded using c1  the second and third using c2  the fourth using c1  and the fifth using c2 the pattern then repeats  with the sixth letter being encoded using c1  the seventh with c2  and so on the plaintext message " bob  i love you alice " is thus file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  3 of 12  20/11/2004 15  53  02 cryptogrpahy encrypted " ghu  n etox dhz " note that the first " b " in the plaintext message is encrypted using c1  while the second " b " is encrypted using c2 in this example  the encryption and decryption " key " is the knowledge of the two caesar keys  k = 4  k = 20  and the pattern c1  c2  c1  c2  c2 plaintext letter  a b c d e f g h i f k l m n o p q r s t u v w x y z c1  k = 6   f g h i j k l m n o p q r s t u v w x y z a b c d e c2  k = 20   t u v w x y z a b c d e f g h i j k l m n o p q r s figure 7.2-3  a vigenere cipher using two caesar ciphers data encryption standard  des  let us now fast forward to modern time and examine the data encryption standard  des   nist 1993   a symmetric key encryption standard published in 1977 and updated most recently in 1993 by the us national bureau of standards for commercial and non-classified us government use des encodes plaintext in 64 bit chunks using a 64-bit key actually  8 of these 64 bits are odd parity bits  one bit in each of the 8 bytes is an odd partity bit for that byte   so the des key is effectively 56 bits long the national institute of standards  the successor to the national bureau of standards  states the goal of des as follows  " the goal is to completely scramble the data and key so that every bit of the ciphertext depends on every bit of the data and every bit of the key  with a good algorithm  there should be no correlation between the ciphertext and either the original data or key "  nist 1999   the basic operation of des is illustrated in figure 7.2-4 in our discussion we will overview des operation  leaving the nitty-gritty bit-level details  there are many !  to those wishing to consult  kaufman 1995  schneier 1995   with  schneier 1995  including a c implementation as well   the des consists of two permutation steps  the first and last steps of the algorithm  in which all 64 bits are permuted  and 16 identical " rounds " of operation in between the operation of each round is identical  taking the output of the previous round as input during each round  the rightmost 32 bits of the input are moved to the left 32 bits of the output the entire 64-bit input to the ith round and the 48 bit key for the ith round  derived from the larger des 56-bit  are taken as input to a function that involves expansion of four-bit input chunks into six-bit chunks  exclusive or-ing with the expanded six bit chunks of the 48-bit key ki  a substitution operation and further exclusive or-ing with the leftmost 32 bits of the input ; see  kaufman 1995  schneier 1995  for details the resulting 32-bit output of the function is then used as the rightmost 32 bits of the rounds 64-bit output  as shown in figure 7.2-4 decryption works by reversing the algorithm 's operations file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  4 of 12  20/11/2004 15  53  02 cryptogrpahy figure 7.2-4  basic operation of the des how well does des work ? how secure is it ? no one can tell for sure  although recent speculation is that one could build a special purpose machine that exhaustively searched through the 56-bit key space for under a million dollars  kaufman 1995   in 1997  a network security company  rsa data security inc  launched a des challenge contest to " crack "  decode  a short phrase it had encrypted using 56-bit des the unencoded phrase  ? strong cryptography makes the world a safer place ?  was determined only 140 days later by a team that used volunteers throughout the internet to systematically explore the key space the team claimed the $ 10,000 prize after testing only a quarter of the key space  about 18 quadrillion keys  rsa 1997   the most recent 1999 des challenge iii was won in a record time of a little over 22 hours  with a network of volunteers and a special purpose computer that was built for less that $ 250,000  nick-named " des cracker "  and is documented on-line  eff 1999   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  5 of 12  20/11/2004 15  53  02 cryptogrpahy if 56-bit des is considered too insecure  one can simply run the 56-bit algorithm multiple times  taking the 64 bit output from one iteration of des as the input to the next des iteration  using a different encryption key each time for example  so-called triple-des  3des   is a proposed us government standard  nist 1999b  and has been proposed as the encryption standard for the point-to-point protocol  rfc 2420   ppp  for the data link layer  see section 5.7   a detailed discussion of key lengths and the estimated time and budget needed to crack des can be found in  blaze 1996   we should also note that our description above has only considered the encryption of a 64-bit quantity when longer messages are encrypted  which is typically the case  des is often used with a technique known as cipher-block chaining  in which the encrypted version of the jth 64-bit quantity of data is xor'ed with the  j + 1  st unit of data before the  j + 1  st unit of data is encrypted 7.2.2 public key encryption for more than 2000 years  since the time of the caesar cipher and up to the 1970 's   encrypted communication required that the two communicating parties share a common secret  the symmetric key used for encryption and decryption one difficulty with this approach is that the two parties must somehow agree on the shared key ; but to do so requires  presumably secure  communication ! perhaps the parties could first meet and agree on the key in person  e.g  two of caesar 's centurions might meet at the roman baths  and thereafter communicate with encryption in a networked world  however  communicating parties may never meet and may never converse except over the network is it possible for two parties to communicate with encryption without having a shared secret key that is known in advance ? in 1976  diffie and hellman  diffie 1976  demonstrated an algorithm  known now as diffie-hellman key exchange  to do just that  a radically different and marvelously elegant approach towards secure communication that has led to the development of today 's public key cryptography systems we will see shortly that public key cryptography systems also have several wonderful properties that make them useful not only for encryption  but for authentication and digital signatures as well the ideas begun with  diffie 1976  have evolved  with a significant milestone being  rsa 1978   into the public key systems in use today file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  6 of 12  20/11/2004 15  53  02 cryptogrpahy figure 7.2-5  public key cryptography the use of public key cryptography is quite simple suppose alice wants to communicate with bob as shown in figure 7.2-5  rather than bob and alice sharing a single secret key  as in the case of symmetric key systems   bob  the recipient of alice 's messages  instead has two keys  a public key that is available to everyone in the world  including trudy the intruder !  and a private key that is known only to bob in order to communicate with bob  alice first fetches bob 's public key alice then encrypts her message to bob using bob 's public key and a known  e.g  standardized  encryption algorithm bob receives alice 's encrypted message and uses his private key and a known  e.g  standardized  decryption algorithm to decrypt alice 's message in this manner  alice can send a secret message to bob without either of them having to have to distribute any secret keys ! using the notation of figure 7.2-5  for any message m  db  eb  m   = m  i.e  applying bob 's public key then bob 's private key to the message m gives back m we will see shortly that we can interchange the public key and private key encryption and get the same result  that is  eb  db  m   = db  eb  m   = m the use of public key cryptography is thus conceptually simple but two immediate worries may spring to mind a first concern is that although an intruder intercepting alice 's encrypted message will only see gibberish  the intruder knows both the key  bob 's public key  which is available for all the world to see  and the algorithm that alice used for encryption trudy can thus mount a chosen plaintext attack  using the known standardized encryption algorithm and bob 's publicly available encryption key to encode any message she chooses ! trudy might well try  for example  to encode messages  or parts of messages  that she suspects that alice might send clearly  if public key cryptography is to work  key selection and encryption/decryption must be done in such a way that it is impossible  or at least so hard to be impossible for all practical purposes  for an intruder to either determine bob 's private key or somehow otherwise decrypt or guess alice 's message to bob a second concern is that since bob 's encryption key is public  anyone can send an encrypted message to bob  including alice or someone claiming to be alice in the case of a single shared secret key  the fact that the sender knows the secret key implicitly identifies the sender to the receiver in the case of public key cryptography  however  this is no longer the case since anyone can send an encrypted message to bob using file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  7 of 12  20/11/2004 15  53  02 cryptogrpahy bob 's publicly available key certificates  which we will study in section 7.5  are needed to bind an entity  such as bob  to a specific public key while there may be many algorithms and keys that have this property  the rsa algorithm  named after its founders  ron rivest  adi shamir  and leonard adleman  has become almost synonymous with public key cryptography let 's first see how rsa works and then examine why it works suppose that bob wants to receive encrypted messages  as shown in figure 7.2-5 the are two inter-related components of rsa  l choice of the public key and the private key l the encryption and decryption algorithm in order to choose the public and private keys  bob must do the following  l choose two large prime numbers  p and q how large should p and q be ? the larger the values  the more difficult it is to break rsa but the longer it takes to perform the encoding and decoding rsa laboratories recommends that the product of p and q be on the order of 768 bits for personal use and 1024 bits for corporate use  rsa 1999    which leads one to wonder why corporate use is deemed so much more important than personal use !   l compute n = pq and z =  p-1   q-1   l choose a number  e  less than n  which has no common factors  other than 1  with z  in this case  e and z are said to be relatively prime   the letter 'e ' is used since this value will be used in encryption l find a number  d  such that ed -1 is exactly divisible  i.e  with no remainder  by z the letter 'd ' is used because this value will be used in decryption put another way  given e  we choose d such that the integer remainder when ed is divided by z is 1  the integer remainder when an integer x is divided by the integer n  is denoted x mod n   l the public key that bob makes available to the world is the pair of numbers  n,e  ; his private key is the pair of numbers  n,d   the encryption by alice  and the decryption by bob is done as follows  l suppose alice wants to send bob a bit pattern  or number  m  such that m < n to encode  alice performs the exponentiation  me  and then computes the integer remainder when meis divided by n thus  the encrypted value  c  of the plaintext message  m  that alice sends is  c = me mod n l to decrypt the received ciphertext message  c  bob computes m = cd mod n which requires the use of his secret key   n,d   as a simple example of rsa  suppose bob chooses p = 5 and q = 7  admittedly  these values are far too small to be secure   then n = 35 and z = 24 bob chooses e = 5  since 5 and 24 have no common factors finally  bob file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  8 of 12  20/11/2004 15  53  02 cryptogrpahy chooses d = 29  since 5 * 29  1  i.e  ed -1  is exactly divisible by 24 bob makes the two values  n = 35 and e = 5  public and keeps the value d = 29 secret observing these two public values  suppose alice now wants to send the letters 'l ' 'o ' 'v ' and 'e ' to bob interpreting each letter as a number between 1 and 26  with 'a ' being 1  and 'z ' being 26   alice and bob perform the encryption and decryption shown in figures 7.2-6 and 7.2-7  respectively  plaintext letter m  numeric representation me ciphertext c = me mod n l 12 248832 17 o 15 759375 15 v 22 5153632 22 e 5 3125 10 figure 7.2-6  alice 's rsa encryption  e = 5  n = 35 ciphertext c cd m = cd mod n plaintext letter 17 481968572106750915091411825223072000 12 l 15 12783403948858939111232757568359400 15 o 22 8.5164331908653770195619449972111e + 38 22 v 10 100000000000000000000000000000 5 e figure 7.2-7  bob 's rsa decryption  d = 29  n = 35 given that " toy " example in figures 7-7 and 7-8 has already produced some extremely large numbers  and given that we know that we saw earlier that p and q should each be several hundred bits long  several practical issues regarding rsa come to mind how does one choose large prime numbers ? how does one then choose e and d ? how does one perform exponentiation with large numbers ? a discussion of these important issues is beyond the scope of this book ; see  kaufman 1995  and the references therein for details we do note here that the exponentiation required by rsa is a rather time consuming process rsa data security  rsa 1999b  says its software toolkit can encrypt/decrypt at a throughput of 21.6 kbits per second with a 512-bit value for n and 7.4 kbits per second with a 1024-bit value des is at least one hundred times fast in software and between 1000 and 10000 times faster in hardware as a result  rsa is often used in practice in combination with des for example  if alice wants to send bob a large amount of encrypted data at high speed  she could do the following first alice chooses a des key that will be used to encode the data file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  9 of 12  20/11/2004 15  53  02 cryptogrpahy itself ; this key is sometimes referred to as a session key  ks alice must inform bob of the session key  since this is the shared secret key they will use for des alice thus encrypts the session key value using bob 's public rsa key  i.e  computes c =  ks  e mod n bob receives the rsa-encrypted session key  c  and decrypts to obtain the session key  ks bob now knows the session key that alice will use for her desencrypted data transfer why does rsa work ? the rsa encryption/decryption above appears rather magical why should it be that by applying the encryption algorithm and then the decryption algorithm  one recovers the original message ? in order to understand why rsa works  we 'll need to perform arithmetic operations using so-called modulo-n arithmetic in modular arithmetic  one performs the usual operations of addition  multiplication and exponentiation however  the result of each operation is replaced by the integer remainder that is left when the result is divided by n we will take n = pq  where p and q are the large prime numbers used in the rsa algorithm recall that under rsa encryption  a message  represented by an integer   m  is first exponentiated to the power e using modulo-n arithmetic to encrypt decryption is performed by raising this value to the power d  again using modulo n arithmetic the result of an encryption step  followed by a decryption step is thus  me  d let 's now see what we can say about this quantity we have   me  d mod n = med mod n although we 're trying to remove some of the " magic " about why rsa works  we 'll need to use a rather magical result from number theory here specifically  we 'll need the result that says if p and q are prime  and n = pq  then xy mod n is the same as x  y mod  p-1   q-1   mod n  kaufman 1995   applying this result  we have  me  d mod n = m  ed mod  p-1   q-1   mod n but remember that we chose e and d such that ed -1 is exactly divisible  i.e  with no remainder  by  p-1   q 1   or equivalently that ed is divisible by  p-1   q-1  with a reminder of 1  and thus ed mod  p-1   q-1  = 1 this gives us  me  d mod n = m 1mod n = m i.e  that  me  d mod n = m this is the result we were hoping for ! by first exponentiating to the power of e  i.e  encrypting  and then exponentiating to the power of d  i.e  decrypting   we obtain the original value  m even more remarkable is the fact that if we first exponentiate to the power of d and then exponentiate to the power of e  i.e  we reverse the order of encryption and decryption  performing the decryption operation first and then applying the encryption operation  we also obtain the original value  m !  the proof for this result follows the exact same reasoning as above   we will see shortly that this wonderful property of the rsa algorithm   me  d mod n = m =  md  e mod n will be of great use the security of rsa relies on the fact that there are no known algorithms for quickly factoring a number  in this case the public value n  into the primes p and q if one knew p and q  then given the public value e  one file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  10 of 12  20/11/2004 15  53  02 cryptogrpahy could then easily compute the secret key  d on the other hand  it is not know whether or not there exist fast algorithms for factoring a number  and in this sense the security of rsa is not " guaranteed " references  blaze 1996  m blaze  w diffie  r rivest  b schneier  t shimomura  e thompson  and m weiner  " minimal key lengths for symmetric ciphers to provide adequate commercial security  " http  //www counterpane.com/keylength.html  diffie 1998  w diffie and s landau  privacy on the line  the politics of wiretapping and encryption  mit press  1998  eff 1999  electronic frontier foundation  " cracking des  " http  //www.eff.org/descracker/  fips-46-1  us national bureau of standards  " data encryption standard "  federal information processing standard  fips  publication 46-1  january 1988  kahn 1967  d kahn  the codebreakers  the story of secret writing  the macmillan company  1967  kaufman 1995  c kaufman  r perlman  m speciner  network security  private communication in a public world  prentice hall  1995  kessler 1999  g kessler  " an overview of cryptography  " hill associates inc  http  //www.hill.com/library/ crypto.html  nist 1993  national institute of standards and technology  federal information data encryption standard  processing standards publication 46-2  1993  nist 1999  national institute of standards and technology  " dat encryption standard fact sheet  " http  // csrc.nist.gov/cryptval/des/des.txt  nist 1999b  national institute of standards and technology  " draft federal information processing standard  fips  46-3  data encryption standard  des   and request for comments  " http  //csrc.nist.gov/ cryptval/des/fr990115.htm  rfc 1321  r rivest  " the md5 message-digest algorithm  " rfc 1321  april 1992  rfc 2437  b kaliski  j staddon  " pkcs # 1  rsa cryptography specifications  version 2  " rfc 2437  october 1998  rfc 2420  h kummert  " the ppp triple-des encryption protocol  3dese   " rfc 2420  sept 1998  rsa 1978  r.l rivest  a shamir  and l.m adleman  " a method for obtaining digital signatures and public-key cryptosystems  " communications of the acm  21  2   120-126  february 1978  rsa 1997  rsa data security inc  " des rsa challege cracked  government encryption standard des takes a fall  " http  //www.rsa.com/des/  rsa 1999  rsa laboratories  " how large a key should be used in rsa ? " http  //www.rsa.com/rsalabs/faq/ html/3-1-5.html  rsa 1999b  rsa laboratories  " how fast is rsa  " http  //www.rsa.com/rsalabs/faq/html/3-1-2.html  rsa 1999c  rsa laboratories  " rsa labs faq  " http  //www.rsa.com/rsalabs/faq/index.html  schneier 1995  b schneier  applied cryptography  protocols  algorithms  and source code in c  john wiley and sons  1995  singh 1999  s singh  " the code book  the evolution of secrecy from mary  queen of scots to quantum cryptography  " doubleday press  1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  11 of 12  20/11/2004 15  53  02 cryptogrpahy return to table of contents copyright keith w ross and james f kurose 1996-2000 all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...wn % 20approach % 20featuring % 20the % 20internet/crypto.htm  12 of 12  20/11/2004 15  53  02 authentication 7.3 authentication  who are you ? authentication is the process of proving one 's identity to someone else as humans  we authenticate each other in many ways  we recognize each others ' faces when we meet ; we recognize each others ' voices on the telephone ; we are authenticated by the customs official who checks us against the picture on our passport in this section we consider how one party can authenticate another party when the two are communicating over a network we focus here on authenticating a " live " party  at the point in time when communication is actually occurring we will see that this is a subtly different problem from proving that a message received at some point in the past  e.g  that may have been archived  did indeed come from that claimed sender this latter problem is referred to as the digital signature problem  which we explore in section 7.4 when performing authentication over the network  the communicating parties can not rely on biometric information  such as a visual appearance or a voiceprint indeed  we will see in our later case studies that it is often network elements such as routers and client/server processes that must authenticate each other here  authentication must be done solely on the basis of messages and data exchanged as part of an authentication protocol typically  an authentication protocol would run before the two communicating parties run some other protocol  e.g  a reliable data transfer protocol  a routing table exchange protocol  or an email protocol   the authentication protocol first establishes the identities of the parties to each others ' satisfaction ; only after authentication do the parties get down to the work at hand as in the case of our development of a reliable data transfer protocol  rdt  in chapter 3  we will find it instructive here to develop various versions of an authentication protocol  which we will call ap  " authentication protocol "   and poke holes  i.e  find security flaws  in each version as we proceed let 's begin by assuming that alice needs to authenticate herself to bob authentication protocol ap1.0 perhaps the simplest authentication protocol we can imagine is one where alice simply sends a message to bob saying she is alice this protocol is shown in figure 7.3-1 the flaw here is obvious  there is no way for bob to actually know that the person sending the message  " i am alice " is indeed alice for example  trudy  the intruder  could just as well send such a message file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  1 of 9  20/11/2004 15  53  05 authentication figure 7.3-1  protocol ap1.0 and a failure scenario authentication protocol ap2.0 in the case that alice has a well-known network address  e.g  ip address  from which she always communicates  bob could attempt to authenticate alice by verifying that the source address on the ip datagram carrying the authentication message matches alice 's well-known address if so  then alice would be authenticated this might stop a very network-naive intruder from impersonating alice but it would n't stop the determined student studying this book  or many others ! figure 7.3-2  protocol ap2.0 and a failure scenario given that we have now studied both the network and data link layers  we know that it is not that hard  e.g  if one had access to the operating system code and could build one 's own operating system kernel  as is the case with linux and several other freely available operating systems  to create an ip datagram  put whatever ip source address we want  e.g  including alice 's well-known ip address  into the ip datagram and send the datagram over the link layer protocol to the first hop router from then on  the incorrectly-source-addressed datagram would be dutifully forwarded to bob this approach is a form of ip spoofing  a well-known security attack technique  cert 96   ip spoofing can be avoided if a router is configured to refuse ip datagrams that do not have a given source address for file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  2 of 9  20/11/2004 15  53  05 authentication example  trudy 's first hop router could be configured to only forward datagrams containing trudy 's ip source address however  this capability is not universally deployed or enforced bob would thus be foolish to assume that trudy 's network manager  who might be trudy herself !  had configured trudy 's first hop router to only forward appropriately-addressed datagrams authentication protocol ap3.0 one classical approach to authentication is to use a secret password we have pin numbers to identify ourselves to automatic teller machines and login passwords for operating systems the password is a shared secret between the authenticator and the person being authenticated we saw in section 2.2.5 that http uses a password-based authentication scheme telnet and ftp use password authentication as well in protocol ap3.0  alice thus sends her secret password to bob  as shown in figure 7.3-3 figure 7.3-3  protocol ap3.0 and a failure scenario the security flaw here is clear if trudy eavesdrops on alice 's communication  then she can learn alice 's password lest you think this is unlikely  consider the fact that when one telnet 's to another machine and logs in  the login password is sent unencrypted to the telnet server  someone connected to the telnet client or server 's lan can possibly " sniff "  read and store  all packets transmitted on the lan and thus steal the login password in fact  this is a well-known approach for stealing passwords  see  e.g   jimenez 1997   such a threat is obviously very real  so ap3.0 clearly wo n't do authentication protocol ap3.1 having just studied the previous section on cryptography  our next idea for fixing ap3.0 is naturally to use encryption by encrypting the password  trudy will not be able to learn alice 's password ! if we assume that alice and bob share a symmetric secret key  ka-b  then alice can encrypt the password  send her identification message  " i am alice  " and her encrypted password to bob bob then decrypts the password and  assuming the password is correct  authenticates alice bob feels comfortable in authenticating alice since not only does alice know the password  but she also knows the shared secret key value needed to encrypt the password let 's call this protocol ap3.1 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  3 of 9  20/11/2004 15  53  05 authentication while it is true that ap3.1 prevents trudy from learning alice 's password  the use of cryptography here does not solve the authentication problem ! bob is again subject to a so-called playback attack  trudy needs only eavesdrop on alice 's communication  record the encrypted version of the password  and then later play back the encrypted version of the password to bob to pretend that she is alice the use of an encrypted password does n't make the situation manifestly different from that in figure 7.3-3 authentication protocol ap4.0 the problem with ap3.1 is that the same password is used over and over again one way to solve this problem would be to use a different password each time alice and bob could agree on a sequence of passwords  or on an algorithm for generating passwords  and use each password only once  in sequence this idea is used in the s/key system  rfc 1760   adopting an approach due to lamport  lamport 81  for generating a sequence of passwords rather than just stop here with this solution  however  let us consider a more general approach for combating the playback attack the failure scenario in figure 7.3-3 resulted from the fact that bob could not distinguish between the original authentication of alice and the later playback of alice 's original authentication that is  bob could not tell if alice was " live "  i.e  was currently really on the other end of the connection  or whether the messages he was receiving were a recorded playback of a previous authentication of alice the very  very !  observant reader will recall that the 3-way tcp handshake protocol needed to address the same problem  the server side of a tcp connection did not want to accept a connection if the received syn segment was an old copy  retransmission  of a syn segment from an earlier connection how did the tcp server side solve the problem of determining if the client was really " live " ? it chose an initial sequence number  which had not been used in a very long time   sent that number to the client  and then waited for the client to respond back with an ack segment containing that number we can adopt the same idea here for authentication purposes a nonce is a number that a protocol will only ever use once-in-a-lifetime that is  once a protocol uses a nonce  it will never use that number again our ap4.0 protocol uses a nonce as follows  ap4.0  l alice sends the message  " i am alice  " to bob l bob chooses a nonce  r  and sends it to alice l alice encrypts the nonce using alice and bob 's symmetric secret key  ka-b  and sends the encrypted nonce  ka-b  r  back to bob as in protocol ap3.1  it is the fact that alice knows ka-b and uses it to encrypt a value that lets bob know that the message he receives was generated by alice the nonce is used to insure that alice is " live " l bob decrypts the received message if the decrypted nonce equals the nonce he sent alice  then alice is authenticated protocol ap4.0 is illustrated in figure 7.3-4 by using the once-in-a-lifetime value  r  and then checking the returned value  ka-b  r   bob can be sure that both alice is who she says she is  since she knows the secret key value needed to encrypt r  and is " live "  since she has encrypted the nonce  r  that bob just created   file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  4 of 9  20/11/2004 15  53  05 authentication figure 7.3-4  protocol ap 4.0  no failure scenario authentication protocol ap5.0 the use of a nonce and symmetric key cryptography formed the basis of our successful authentication protocol  ap4.0 a natural question is whether we can use a nonce and public key cryptography  rather than symmetric key cryptography  to solve the authentication problem the use of a public key approach would obviate a difficulty in any shared key system  worrying about how the two parties learn the secret shared key value in the first place a protocol that uses public key cryptography in a manner analogous to the use of symmetric key cryptography in protocol ap4.0 is protocol ap5.0  ap5.0  l alice sends the message  " i am alice  " to bob l bob chooses a nonce  r  and sends it to alice once again  the nonce will be used to insure that alice is " live " l alice uses her decryption algorithm with her private key  da  to the nonce and sends the resulting value da  r  to bob since only alice knows her decryption key  no one except alice can generate da  r   l bob applies alice 's public encryption algorithm  ea to the received message  i.e  bob computes ea  da  r    recall from our discussion of rsa public key cryptography in section 7.2 that ea  da  r   = r = da  ea  r    thus bob computes r and authenticates alice file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  5 of 9  20/11/2004 15  53  05 authentication figure 7.3-5  protocol ap 5.0 working correctly the operation of protocol ap5.0 is illustrated in figure 7.3-5 is protocol ap5.0 as secure as protocol ap4.0 ? both use nonces since ap5.0 uses public key techniques  it requires that bob retrieve alice 's public key this leads to an interesting scenario  shown in figure 7.3-6  in which trudy may be able to impersonate alice to bob  l trudy sends the message  " i am alice " to bob l bob chooses a nonce  r  and sends it to alice  but the message is intercepted by trudy l trudy applies her decryption algorithm with her private key  dt  to the nonce and sends the resulting value  dt  r   to bob to bob  dt  r  is just a bunch of bits and he does n't know whether the bits represent dt  r  or da  r   l bob must now get alice 's public key in order to apply ea to the value he just received he sends a message to alice asking her for ea trudy intercepts this message as well  and replies back to bob with et  that is trudy 's public key bob computes et  dt  r   = r  and thus authenticates trudy as alice ! from the above scenario  it is clear that protocol ap5.0 is only as " secure " as is the distribution of public keys there are secure ways of distributing public keys  a topic we will examine soon in section 7.5 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  6 of 9  20/11/2004 15  53  05 authentication figure 7.3-6  a security hole in protocol ap5.0 in the scenario in figure 7.3-6  bob and alice might together eventually discover that something is amiss  as bob will claim to have interacted with alice  but alice knows that she has never interacted with bob there is an even more insidious attack that would avoid this detection in the scenario in figure 7.3-7  both alice and bob are talking to each other  but by exploiting the same hole in the authentication protocol  trudy is able to transparently interpose herself between alice and bob in particular  if bob begins sending encrypted data to alice using the encryption key he receives from trudy  trudy can recover the plaintext of the communication from bob to alice at the same time  trudy can forward bob 's data to alice  after re-encrypting data using alice 's real public key   file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  7 of 9  20/11/2004 15  53  05 authentication figure 7.3-7  a " man-in-the-middle " attack bob is happy to be sending encrypted data  and alice is happy to be receiving data encrypted using her own public key ; both are unaware of trudy 's presence should bob and alice meet later and discuss their interaction  alice will have received exactly what bob sent  so nothing will be detected as being amiss this is one example of the so-called man-in-the-middle attack  more appropriately here  a " woman-in-the-middle " attack   it is also sometimes known as a bucket-brigade attack  since trudy 's passing of data between alice and bob resembles the passing of buckets of water along a chain of people  a so-called " bucket brigade "  who are putting out a fire using a remote source of water references  cert 96  cert  " advisory ca-96.21  tcp syn flooding and ip spoofing attacks  " http  //www.cert.org/ advisories/index.html file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  8 of 9  20/11/2004 15  53  05 authentication  jimenez 1997  d jimenez  " outside hackers infiltrate mit network  compromise security  " the tech  volume 117  number 49  oct 1997   pp 1  lamport 1981  lamport  l  " password authentication with insecure communication "  communications of the acm  vol 24  no 11  november 1981  770-772  rfc 1760  n haller  " the s/key one-time password system  " rfc 1760  feb 1995 return to table of contents copyright keith w ross and james f kurose 1996-1999  all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/authentication.htm  9 of 9  20/11/2004 15  53  05 integrity 7.4 integrity think of the number of the times you 've signed your name to a piece of paper during the last week you sign checks  credit card statements  legal documents  and letters your signature attests to the fact that you  as opposed to someone else  have acknowledged and/or agreed with the document 's contents in a digital world  one often want to indicate the owner or creator of a document  or to signify one 's agreement with a document 's content a digital signature is a cryptographic technique for achieving these goals in a digital world just as with human signatures  digital signing should be done in such a way that a digital signatures are verifiable  non-forgible  and non-repudiable that is  it must be possible to " prove " that a document signed by an individual was indeed signed by that individual  the signature must be verifiable  and that only that individual could have signed the document  the signature can not be forged  and a signer can not later repudiate or deny having signed the document   this is easily accomplished with public key cryptography 7.4.1 generating digital signatures suppose that bob wants to digitally sign a " document  " m we can think of the document as a file or a message that bob is going to sign and send as shown in figure 7.4-1  to sign this document  bob simply uses his private decryption key  db  to compute db  m   at first  it might seem odd that bob is running a decryption algorithm over a document that has n't been encrypted but recall that " decryption " is nothing more than a mathematical operation  exponentiation to the power of d in rsa ; see section 7.2  and recall that bob 's goal is not to scramble or obscure the contents of the document  but rather to sign the document in a manner that is verifiable  non-forgible  and non-repudiable bob has the document  m  and his digital signature of the document  db  m   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  1 of 7  20/11/2004 15  53  06 integrity figure 7.4-1  creating a digital signature for a document does the digital signature  db  m   meet our requirements of being verifiable  non-forgible  and nonrepudiable ? suppose alice has m and db  m   she wants to prove in court  being litigious  that bob had indeed signed the document and was the only person who could have possibly signed the document alice takes bob 's public key  eb  and applies it to the digital signature  db  m   associated with the document  m that is  she computes eb  db  m    and voila  with a dramatic flurry  she produces m  which exactly matches the original document ! alice then argues that only bob could have signed the document because  l whoever signed the message must have used the private encryption key  db in computing the signature db  m   such that eb  db  m   = m l the only person who could known the private key  db  is bob recall from our discussion of rsa in section 7.2 that knowing the public key eb is of no help in learning the private key db therefore  the only person who could know db is the person who generated the pair of keys   eb  db  in the firstplace  bob it is also important to note that if the original document  m  is ever modified to some alternate form  m '  the signature that bob created for m will not be valid for m '  since eb  db  m   does not equal m' thus we see that public key cryptography techniques provide a simple and elegant way to digitally sign documents that is verifiable  non-forgible  and non-repudiable  and that protects against later modification of the document 7.4.2 message digests we have seen above that public key encryption technology can be used to create a digital signature one concern with signing data by encryption  however  is that encryption and decryption are computationally expensive when digitally signing a really important document  say a merger between two large multinational corporations or an agreement with a child to have him/her clean her room weekly  computational cost may not may be important however  many network devices and processes  e.g  routers exchanging routing table information and email user agents exchanging email  routinely exchange data that may not need to be encrypted nonetheless  they do want to ensure that  l the sender of the data is as claimed  i.e  that the sender has signed the data and this signature can be checked l the transmitted data has not been changed since the sender created and signed the data given the overheads of encryption and decryption  signing data via complete encryption/decryption can file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  2 of 7  20/11/2004 15  53  06 integrity be overkill a more efficient approach using so-called message digests can accomplish these two goals without full message encryption a message digest is in many ways like a checksum message digest algorithms take a message  m  of arbitrary length and compute a fixed length " fingerprint " of the data known as a message digest  h  m   the message digest protects the data in the sense that if m is changed to m '  either maliciously or by accident  then h  m   computed for the original data  and transmitted with that data   will not match the h  m  computed over the changed data while the message digest provides for data integrity  how does it help with signing the message m ? the goal here is that rather than having bob digitally sign  encrypt  the entire message by computing db  m   he should be able to sign just the message digest by compting db  h  m    that is  having m and db  h  m   together  note that m is not typically encrypted  should be " just as good as " having a signed complete message  db  m  ; this means that m and db  h  m   together should be non-forgible  verifiable  and non-repudiable nonforgible will require that the message digest algorithm that computes the message digest have some special properties  as we will see below figure 7.4-2  hash functions are used to create message digests our definition of a message digest may seem quite similar to the definition of a checksum  e.g  the internet checksum  see section 4.4  or a more powerful error detection code such as a cyclic redundancy check  see section 5.1   is it really any different ? checksums  cyclic redundancy checks  and message digests are all examples of so-called hash functions as shown in figure 7.4-2  a hash function takes an input  m  and computes a fixed-size string known as a hash the internet checksum  crc 's and message digests all meet this definition if signing a message digest is going to be " just as good as " signing the entire message  in particular if it is going to satisfy the non-forgibility requirement  then a message digest algorithm must have the following additional properties  1 given a message digest value  x  it is computationally infeasible to find a message  y  such that h  y  = x ; 2 it is computationally infeasible to find any two messages x and y such that h  x  = h  y   informally  these two properties mean that it is computationally infeasible for an intruder to substitute one message for another message that is protected by a message digest that is  if  m,h  m   are the message and message digest pair created by the sender  then an intruder can not forge the contents of another message  y  that has the same message digest value as the original message when bob signs m file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  3 of 7  20/11/2004 15  53  06 integrity by computing db  h  m    we know that no other message can be substituted for m furthermore  bob 's digital signature of h  m  uniquely identifies bob as the verifiable  non-repudiable signer of h  m   and as a consequence  m as well  as discussed above in section 7.4.1 figure 7.4-3  sending a digitally signed message in the context of bob sending a message to alice  figure 7.4-3 provides a summary of the operational procedure of creating a digital signature bob puts his original long message through a hash function to create a messge digest he then encrypts the message digest with his own private key the original message  in clear text  along with the digitally signed message digest  henceforth referred to as the digital signature  is then sent to alice figure 7.4-4 provides a summary of the operational procedure of verifying message integrity alice applies the bob 's public key to the message to recover the message digest alice also applies the hash function to the clear text message to obtain a second message digest if the two message digests match  then the recipientalice can be sure about the integrity of the message  and sure that bob sent the message file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  4 of 7  20/11/2004 15  53  06 integrity figure 7.4-4  verifying the integrity of a signed message 7.4.3 hash function algorithms let 's convince ourselves that a simple checksum  such as the internet checksum  would make a poor message digest algorithm rather than performing 1 complement 's arithmetic  as in the internet checksum   let us compute a checksum by treating each character as a byte and adding the bytes together using 4-byte chunks at a time suppose bob owes alice $ 100.99 " and sends an iou to alice consisting of the text string " iou100.99bob "  the ascii representation  in hexadecimal notation  for these letters is 49  4f  55  31  30  30  2e  39  39  42  4f  42 figure 7.4-5  top  shows that the 4-byte checksum for this message is b2 c1 d2 ac a slightly different message  and a much more costly one for bob  is shown in the bottom half of figure 7.5-1 the message " iou100.99bob " and " iou900.19bob " have the same checksum ! thus  this simple checksum algorithm violates the two required requirements above given the original data  it is simple to find another set of data with the same checksum clearly  for security purposes we are going to need a more powerful hash function than a checksum file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  5 of 7  20/11/2004 15  53  06 integrity figure 7.4-5  initial message and fraudulent message have the same checksum ! the md5 message digest algorithm by ron rivest  rfc 1321  is in wide use today it computes a 128 bit message digest in a four-step process consisting of a padding step  adding a 1 followed by enough zero 's so that the length of the message satisfies certain conditions   an append step  appending a 64-bit representation of the message length before padding   an initialization of an accumulator  and a final looping step in which the message 's 16-word blocks are processed  mangled  in four rounds of processing it is not known whether md5 actually satisfies the requirements listed above the author of md5 claims " it is conjectured that the difficulty of coming up with two messages having the same message digest is on the order of 264 operations  and that the difficulty of coming up with any message having a given message digest is on the order of 2128 operations "  rfc 1321   no one has argued with this claim for a description of md5  including a c source code implementation  see  rfc 1321   computational aspects of md5 are discussed in  rfc 1810   the second major message digest algorithm in use today is sha-1  the secure hash algorithm  fips 1995   this algorithm is based on principles similar to those used in the design of md4  rfc 1320   the predecessor to md5 the secure hash algorithm  sha-1   a us federal standard  is required for use file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  6 of 7  20/11/2004 15  53  06 integrity whenever a secure message digest algorithm is required for federal applications it produces a 160-bit message digest references  fips 95  federal information processing standard  " secure hash standard "  fips publication 180-1  rfc 1320  r rivest  the md4 message-digest algorithm  rfc 1320  april 1992  rfc 1321  r.l rivest  the md5 message-digest algorithm  rfc 1321  april 1992  rfc 1810  j touch  " report on md5 performance  " rfc 1810  june 1995 file  ///d | /downloads/livros/computa ? ? o/computer % 20netw % 20approach % 20featuring % 20the % 20internet/integrity.htm  7 of 7  20/11/2004 15  53  06 key distribution 7.5 key distribution and certification in section 7.2 we saw that a drawback of symmetric key cryptography was the need for the two communicating parties to have agreed upon their secret key ahead of time with public key cryptography  this a priori agreement on a secret value is not needed however  as we saw in our discussion of authentication protocol ap5.0 in section 7.3  public key encryption has its own difficulties  in particular the problem of obtaining someone 's true public key both of these problems  determining a shared key for symmetric key cryptography  and securely obtaining the public key for public key cryptography  can be solved using a trusted intermediary for symmetric key cryptograghy  the trusted intermediary is called a key distribution center  kdc   which is a single  trusted network entity with whom one has established a shared secret key we will see that one can use the kdc to obtain the shared keys needed to communicate securely with all other network entities for public key cryptography  the trusted intermediary is called a certification authority  ca   a certification authority certifies that a public key belongs to a particular entity  a person or a network entity   for a certified public key  if one can safely trust the ca that the certified the key  then one can be sure about to whom the public key belongs once a public key is certified  then it can be distributed from just about anywhere  including a public key server  a personal web page or a diskette 7.5.1 the key distribution center suppose once again that bob and alice want to communicate using symmetric key cryptography they have never met  perhaps they just met in an on-line chat room  and thus have not established a shared secret key in advance how can they now agree on a secret key  given that they can only communicate with each other over the network ? a solution often adopted in practice is to use a trusted key distribution center  kdc   the kdc is a server that shares a different secret symmetric key with each registered user this key might be manually installed at the server when a user first registers the kdc knows the secret key of each user and each user can communicate securely with the kdc using this key let 's see how knowledge of this one key allows a user to securely obtain a key for communicating with any other registered user suppose that alice and bob are users of the kdc ; they only know their individual key  ka-kdc and kb-kdc  respectively  for communicating securely with the kdc alice takes the first step  and they proceed as illustrated in figure 7.5-1 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  1 of 9  20/11/2004 15  53  07 key distribution figure 7.5-1  setting up a one-time session key using a key distribution center l using ka-kdc to encrypt her communication with the kdc  alice sends a message to the kdc saying she  a  wants to communicate with bob  b   we denote this message  ka-kdc  a,b   as part of this exchange  alice should authenticate the kdc  see homework problems   e.g  using an authentication protocol  e.g  our protocol ap4.0  and the shared key ka-kdc  l the kdc  knowing ka-kdc  decrypts ka-kdc  a,b   the kdc then authenticates alice the kdc then generates a random number  r1 this is the shared key value that alice and bob will use to perform symmetric encryption when they communicate with each other this key is referred to as a one-time session key  see section 7.5.3 below   as alice and bob will use this key for only this one session that they are currently setting up the kdc now needs to inform alice and bob of the value of r1 the kdc thus sends back an encrypted message to alice containing the following  m r1  the one-time session key that alice and bob will use to communicate ; m a pair of values  a  and r1  encrypted by the kdc using bob 's key  kb-kdc  we denote this kb-kdc  a,r1   it is important to note that kdc is sending alice not only the value of r1 for her own use  but also an encrypted version of r1 and alice 's name encrypted using bob 's key alice ca n't decrypt this pair of values in the message  she does n't know bob 's encryption key   but then she does n't really need to we 'll see shortly that alice will simply forward this encrypted pair of values to bob  who can decrypt them   these items are put into a message and encrypted using alice 's shared key the message from the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  2 of 9  20/11/2004 15  53  07 key distribution kdc to alice is thus ka-kdc  r1,kb-kdc  r1    l alice receives the message from the kdc  verifies the nonce  extracts r1 from the message and saves it alice now knows the one-time session key  r1 alice also extracts kb-kdc  a,r1  and forwards this to bob l bob decrypts the received message  kb-kdc  a,r1   using kb-kdc and extracts a and r1 bob now knows the one-time session key  r1  and the person with whom he is sharing this key  a of course  he takes care to authenticate alice using r1 before proceeding any further 7.5.2 kerberos kerberos  rfc 1510  neuman 1994  is an authentication service developed at mit that uses symmetric key encryption techniques and a key distribution center although it is conceptually the same as the generic kdc we described in section 7.5.1  its vocabulary is slightly different kerberos also contains several nice variations and extensions of the basic kdc mechanisms kerberos was designed to authenticate users accessing network servers and was initially targeted for use within a single administrative domain such as a campus or company thus  kerberos is framed in the language of users who want to access network services  servers  using application-level network programs such as telnet  for remote login  and nfs  for access to remote files   rather than than human-to-human conversants who want to authenticate themselves to each other  as in our examples above nonetheless  the key  pun intended  underlying techniques remains the same the kerberos authentication server  as  plays the role of the kdc the as is the repository of not only the secret keys of all users  so that each user can communicate securely with the as  but also information about which users have access privileges to which services on which network servers when alice wants to access a service on bob  who we now think of as a server   the protocol closely follows our example in figure 7.5-1  l alice contacts the kerberos as  indicating that she wants to use bob all communication between alice and the as is encrypted using a secret key that is shared between alice and the as in kerberos  alice first provides her name and password to her local host alice 's local host and the as then determine the one-time secret session key for encrypting communication between alice and the as l the as authenticates alice  checks that she has access privileges to bob  and generates a onetime symmetric session key  r1  for communication between alice and bob the authentication server  in kerberos parlance  now referred to as the ticket granting server  sends alice the value of r1  and also a ticket to bob 's services the ticket contains alice 's name  the one-time session key  r1  and an expiration time  all encrypted using bob 's secret key  known only by bob and the as   as in figure 7.5-1 alice 's ticket is valid only until its expiration time  and will be rejected by bob is presented after that time for kerberos v4  the maximum lifetime of a ticket is about 21 hours in kerberos v5  the lifetime must expire before the end of year 9999  a definite y10k problem ! l alice then sends her ticket to bob she also sends along an r1-encrypted timestamp that is used file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  3 of 9  20/11/2004 15  53  07 key distribution as a nonce bob decrypts the ticket using his secret key  obtains the session key  decrypts the timestamp using the just-learned session key bob sends back the timestamp value plus one  in kerberos v5  or simply the timestamp itself  in kerberos v5   the most recent version of kerberos  v5  provides support for multiple authentication servers  delegation of access rights  and renewable tickets  kaufman 95   rfc 1510  provide ample details 7.5.3 public key certification one of the principle features of public key encryption is that it is possible for two entities to exchange secret messages without having to exchange secret keys for example  when alice wants to send a secret message to bob  she simply encrypts the message with bob 's public key and sends the encrypted message to bob ; she does n't need to know bob 's secret  i.e  private  key  nor does bob need to know her secrect key thus  public key cryptography obviates the need for kdc infrastructure  such as kerberos of course  with public key encryption  the communicating entities still have to exchange public keys a user can make its public key pubicly available in many ways  e.g  by posting the key on the user 's personal web page  placing the key in a public key server  or by sending the key to a correspondent by email a web commerce site can place its public key on its server in a manner that browsers automatically download the public key when connecting to the site routers can place their public keys on public key servers  thereby allowing other browsers and network entities to retrieve them there is  however  a subtle  yet critical  problem with public key cryptography to gain insight to this problem  let 's consider an internet commerce example suppose that alice is in the pizza delivery business and she accepts orders over the internet bob  a pizza lover  sends alice a plaintext message which includes his home address and the type of pizza he wants in this message  bob also includes a digital signature  e.g.  an encrypted message digest for the original plaintext message   as discussed in section 7.4  alice can obtain bob 's public key  from his personal web page  a public key server  or from an e-mail message  and verify the digital signature in this manner alice makes sure that bob  rather than some adolescent prankster  indeed made the order this all sounds fine until clever trudy comes along as shown in figure 7.5-2  trudy decides to play a prank trudy sends a message to alice in which she says she is bob  gives bob 's home address  and orders a pizza she also attaches a digital signature  but she attaches the signature by signing the message digest with her  i.e  trudy 's  private key trudy also masquerades as bob by sending alice trudy 's public key but saying that it belongs to bob in this example  also will apply trudy 's public key  thinking that it is bob 's  to the digital signature and conclude that the plaintext message was indeed created by bob bob will be very surprised when the delivery person brings to his home a pizza with everything on it ! here  as in the flawed authentication scenario in figure 7.3-7  the man-in-the-middle attack is the room cause of our difficulties file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  4 of 9  20/11/2004 15  53  07 key distribution figure 7.5-2  trudy masquerades as bob using public key cryptography we see from this example that in order for public key cryptography to be useful  entities  users  browsers  routers  etc  need to know for sure that they have the public key of the entity with which they are communicating for example  when alice is communicating with bob using public key cryptography  she needs to know for sure that the public key that is supposed to be bob 's is indeed bob 's binding a public key to a particular entity is typically done by a certification authority  ca   which validates identities and issue certificates a ca has the following roles  l first to verify that entity  a person  a router  etc  is who it says it is there are no mandated procedures for how certification is done when dealing with a ca  one must trust the ca to have performed a suitably rigorous identity verification for example  if trudy were able to walk into fly-by-night certificate authority and simply announce " i am alice " and receive keys associated with the identity of " alice  " then one should n't put much faith in public keys offered by the fly-by-night certificate authority on the other hand  one might  or might not !  be more willing to trust a ca that is part of a federal or state-sponsored program  e.g   utah 1999    one can trust the " identify " associated with a public key only to the extent that one can trust a ca and its identity verification techniques what a tangled web of trust we spin ! l once the ca verifies the entity of the entity  the ca creates a certificate that binds the public key of the identiy to the identity the certificate contains the public key and identifying information about the owner of the public key  for example a human name or an ip address   the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  5 of 9  20/11/2004 15  53  07 key distribution certificate is digitally signed by the ca these steps are shown in figure 7.5-3 figure 7.5-3  bob obtains a certificate from the certification authority let us now see how certificates can be used to combat pizza-ordering pranksters  like trudy  and other undesirables when alice recieves bob 's order  she gets bob 's certificate  which may be on his web page  in an e-mail message or in a certificate server alice uses the ca 's public key to verify that the public key in the certificate is indeed bob 's if we assume that the public key of the ca itself is known to all  for example  it could published in a trusted  public  and well-known place  such as the new york times  so that it is known to all and can not be spoofed   then alice can be sure that she is indeed dealing with bob both the international telecommunication union and the ietf have developed standards for certification authorities itu x.509  itu 1993  specifies an authentication service as well as a specific syntax for certificates rfc 1422  rfc 1422  describes ca-based key management for use with secure internet e-mail it is compatible with x.509 but goes beyond x.509 by establishing procedures and conventions for a key management architecture figure 7.5-4 describes some of the important field in a certificate field name description version version number of x.509 specification serial number ca-issued unique identifier for a certificate file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  6 of 9  20/11/2004 15  53  07 key distribution signature specifies the algorithm used by ca to " sign " this certificate issuer name identity of ca issuing this certificate  in so-called distinguished name  dn   rfc 1779  format validity period start and end of period of validity for certificate subject name identity of entity whose public key is associated with this certificate  in dn format subject public key the subject 's public key as well as an indication of the public key algorithm  and algorithm parameters  to be used with this key figure 7.5-4  selected fields in a x.509 and rfc 1422 public key certificate with the recent boom in electronic commerce and the consequent widespread need for secure transactions  there has been increased interest in certification authorities among the companies providing ca services are cybertrust  cybertrust 1990  verisign  verisign 1999  and netscape  netscape 1999   a certificate issued by the us postal service  as viewed through a netscape browser  is shown in figure 7.5-5 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  7 of 9  20/11/2004 15  53  07 key distribution figure 7.5-5  a us postal service issued certificate 7.5.4 one-time session keys we have seen above that a one-time session key is generated by a kdc for use in symmetric key encryption of a single session between two parties by using the one-time session keys from the kdc  a user is freed from having to establish a priori its own shared key for each and every network entity with whom it wishes to communicate instead  a user need only have one shared secret key for communicating with the kdc  and will receive one-time session keys from the kdc for all of its communication with other network entities one time session keys are also used in public key cryptography recall from our discussion in section 7.2.2  that a public key encryption technique such as rsa is orders of magnitude more computationally expensive that a symmetric key system such as des thus  public key systems are often used for authentication purposes once two parties have authenticated each other  they then use public-keyencrypted communication to agree on a shared one-time symmetric session key this symmetric session key is then used to encrypt the remainder of the communication using a more efficient symmetric file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  8 of 9  20/11/2004 15  53  07 key distribution encryption technique  such as des references  cybertrust 1999  cybertrust solutions homepage  http  //www.cybertrust.com  itu 1993  international telecommunication union  recommendation x.509  11/93  the directory  authentication framework  kaufman 1995  c kaufman  r perlman  m speciner  network security  private communication in a public world  prentice hall  1995  netscape 1999  netscape certificate server faq  http  //sitesearch.netscape.com/certificate/v1.0/faq/ index.html  neuman 1994  b neuman and t tso  " kerberos  an authentication service for computer networks  " ieee communication magazine  vol 32  no 9   sept 1994   pp 33-38  rfc 1422  s kent  " privacy enhancement for internet electronic mail  part ii  certificate-based key management "  rfc 1422  feb  1993  rfc 1510  j kohl  c neuman  " the kerberos network authentication service  v5   " rfc 1510  sept 1993  rfc 1779  s kille  " a string representation of distinguished names  " rfc 1779  march 1995  utah 1999  state of utah department of commerce  utah digital signature program  http  //www commerce.state.ut.us/web/commerce/digsig/dsmain.htm  verisign 1999  verisign home page  http  //www.verisign.com/ file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/keydist.htm  9 of 9  20/11/2004 15  53  07 secure e-mail 7.6 secure e-mail in previous sections of this chapter  we have examined fundamental issues in network security  including symmetric key and public key encryption  authentication  key distribution  message integrity and digital signatures in this section and the following two sections  we 'll next examine how these techniques are being used to provide security in the internet being consistent with the general structure of this book  we begin at the top of the protocol stack and discuss application-layer security our approach here is use a specific application  namely  e-mail  as a case study for application-layer security we then move down the protocol stack in section 7.7 we examine the ssl protocol  which provides security at the transport layer for tcp and in section 7.8  we 'll consider ipsec  which provides security at the network layer interestingly  it is possible to provide security services in any of the top four layers of the internet protocol stack  molva 1999   when security is provided for a specific application-layer protocol  then the application using the protocol will enjoy one or more security services  such as secrecy  authentication or integrity when security is provided for a transport-layer protocol  then all applications that use that protocol enjoy the security services of the transport protocol when security is provided at the network layer on a host-to-host basis  then all transport layer segments  and hence all application-layer data  enjoy the security services of the network layer when security is provided on a link basis  then all ip datagrams traveling over the link receive security services of the link one might wonder why security functionality is being provided at multiple layers in the internet ? would n't it suffice to simply provide the security functionality at the network layer  and be done with it ? there are two answers to this question first  although security at the network layer can offer " blanket coverage " by encrypting all the data in the datagrams  i.e  all the transport-layer segments  and by authenticating all source ip addresses  it ca n't provide userlevel security for example  a commerce site can not rely on ip-layer security to authenticate a customer who is purchasing goods at the commerce site thus  there is a need for security functionality at higher layers as well as blanket coverage at lower layers second  in the internet it is generally easier to deploy new services  including security services  at the higher-layers of the protocol stack while waiting for security to be broadly deployed at the network layer  which is arguably still many years in the future  many application developers " just do it " and introduce security functionality into to their favorite applications a classic example is pgp  which provides for encryption of email  and will be discussed later in this section   requiring only client and server application code  pgp was one the first security technologies to be broadly used in the internet similarly  transport-layer security with ssl was broadly introduced into the internet  as it too only required new code in the end systems however  ip-layer security  socalled ipsec  is taking much longer to broadly deploy  as it requires significant changes in the routers in the network core 7.6.1 principle of secure e-mail in this section we use many of the tools introduced in the previous section to create a high-level design of a secure email system we create this high-level design in an incremental manner  at each step introducing new security services when designing a secure e-mail system  let us keep in mind the racy example introduced in section 7.1  the illicit love affair between alice and bob in the context of e-mail  alice wants to send an e-mail message to bob  and trudy wants to intrude before plowing ahead and designing a secure e-mail system for alice and bob  we should first consider which security features would be most desirable for them first and foremost is secrecy as discussed in section 7.1  neither alice nor bob wants trudy to read alice 's e-mail message the second feature that alice and bob would most likely want to see file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  1 of 6  20/11/2004 15  53  08 secure e-mail in the secure e-mail system is sender authentication in particular  when bob receives the message from alice  " i do n't love you anymore i never want to see you again formerly yours  alice "  bob would naturally want to be sure that the message came from alice and not from trudy another feature that the two lovers would appreciate is message integrity  i.e  assurance that the message alice sends is not modified while enroute to bob finally  the e-mail system should provide receiver authentication  i.e  alice wants to make sure that she is indeed sending the letter to bob and not to someone else  e.g  trudy  who is impersonating as bob so let 's begin by addressing the foremost concern of alice and bob  namely  secrecy the most straightforward way to provide secrecy is for alice to encrypt the message with symmetric key technology  such as des  and for bob to decrypt the message upon message receipt as discussed in section 7.2  if the symmetric key is long enough  and if only alice and bob have the key  then it is extremely difficult for anyone else  including trudy  to read the message although this approach is straightforward  it has a fundamental problem as we discussed in section 7.2  it is difficult to distribute a symmetric key so that only alice and bob have copies of the key so we naturally consider an alternative approach  namely  public key cryptography  using  for example  rsa   in the public-key approach  bob makes his public key publicly available  for example  in a public-key server or on his personal web page   alice encrypts her message with bob 's public key  and sends the encrypted message to bob 's e-mail address  the encrypted message is encapsulated with mime headers and sent over ordinary smtp  as discussed in section 2.4  when bob receives the message  he simply decrypts it with his private key assuming that alice knows for sure that the public key is bob 's public key  and that the key is long enough   then this approach is an excellent means to provide the desired secrecy one problem  however  is that public-key encryption is relatively inefficient  particularly for long messages  long e-mail messages are now commonplace in the internet  due to increasing use of attachments  images  audio and video  to overcome the efficiency problem  let 's make use of a session key  discussed in section 7.4   in particular  alice  1  selects a symmetric key  ks  at random   2  encrypts her message  m  with the symmetric key  ks   3  encrypts the symmetric key with bob 's public key  eb   4  concatenates the encrypted message and the encrypted symmetric key to form a " package "  and  5  sends the package to bob 's e-mail address the steps are illustrated in figure 7.6-1  in this and the subsequent figures  the " + " represents concatenation and the "  " represents deconcatenation  when bob receives the package  he  1  uses his private key db to obtain the symmetric key  s  and  2  uses the symmetric key s to decrypt the message m figure 7.6-1  alice uses a symmetric session key  ks  to send a secret e-mail to bob having designed a secure e-mail system that provides secrecy  let 's now design another system that provides both sender authentication and integrity we 'll suppose  for the moment  that alice and bob are no longer concerned with secrecy  they what to share their feelings with everyone !   and are only concerned about sender authentication and file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  2 of 6  20/11/2004 15  53  08 secure e-mail message integrity to accomplish this task  we use digital signatures and message digests  as described in section 7.4 specifically  alice  1  applies a hash function  h  e.g  md5   to her message m to obtain a message digest   2  encrypts the result of the hash function with her private key  da  to create a digital signature   3  concatenates the original  unencrypted message  with the signature to create a package   4  and sends the package to bob 's e-mail address when bob receives the package  he  1  he applies alice 's public key  ea  to the electronic signature and  2  compares the result of this operation to his own hash  h  of the message the steps are illustrated in figure 7.6-2 as discussed in section 7.4  if the two results are the same  bob can be pretty confident that message came from alice and is unaltered figure 7.6-2  using hash functions and digital signatures to provide sender authentication and message integrity now lets consider designing an e-mail system that provides secrecy  sender authentication and message integrity this can be done by combining the procedures in figure 7.6-1 and 7.6-2 alice first creates a preliminary package  exactly as in figure 7.6-2  which consists of her original message along with a digitally-signed hash of the message she then treats this preliminary package as a message in itself  and sends this new message through the sender steps in figure 7.6-1  creating a new package that is sent to bob the steps applied by alice are shown in figure 7.6-3 when bob receives the package  he first applies his side of figure 7.6-1 and then his side of figure 7.6-2 it should be clear that this design achieves the goal of providing secrecy  sender authentication and message integrity note in this scheme that alice applies public key encryption twice  once with her own private key and once with bob 's public key similarly  bob applies public key encryption twice  once with his private key and once with alice 's public key file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  3 of 6  20/11/2004 15  53  08 secure e-mail figure 7.6-3  alice uses symmetric-key cryptography  public-key cryptography  a hash function and a digital signature to provide secrecy  sender authentication and message integrity the secure e-mail design outlined in figure 7.6-3 probably provides satisfactory security for most e-mail users for most occasions but there is still one important issue that remains to be addressed the design in figure 7.6-3 requires alice to obtain bob 's public key  and requires bob to obtain alice 's public key the distribution of these public keys is a non-trivial problem for example  trudy might masquerade as bob and give alice her own public key while saying that it is bob 's public key as we learned in section 7.5  a popular approach for securely distributing public keys is to certify the public keys 7.6.2 pgp originally written by phil zimmerman in 1991  pretty good privacy  pgp  is e-mail an encryption scheme that has become a de-facto standard  with thousands of users all over the globe versions of pgp are available in the public domain ; for example  you can find the pgp software for your favorite platform as well as lots of interesting reading at the international pgp home page  pgpi 1999    a particularly interesting essay by the author of pgp is  zimmerman 1999    pgp is also commercially available  network associates 1999   and is also available as a plug-in for many email user agents  including microsoft 's exchange and outlook  and qualcomm 's eudora the pgp design is  in essence  the same as the design shown in figure 7.6-3 depending on the version  the pgp software uses md5 or sha for calculating the message digest ; cast  triple-des or idea for symmetric key encryption ; and rsa for the public key encryption in addition  pgp provides data compression when pgp is installed  the software creates a public key pair for the user the public key can be posted on the user 's web site or placed in a public key server the private key is protected by the use of a password the password has to be entered every time the user accesses the private key pgp gives the user the option of digitally signing the message  encrypting the message  or both digitally signing and encrypting figure 7.6-4 shows a pgp signed message this message appears after the mime header the encoded data in the message is da  h  m    i.e  the digitally signed message digest as we discussed above  in order for bob to verify the integrity of the message  he needs to have access to alice 's public key file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  4 of 6  20/11/2004 15  53  08 secure e-mail -----begin pgp signed message hash  sha1 bob  my husband is out of town tonight passionately yours  alice -----begin pgp signature version  pgp for personal privacy 5.0 charset  noconv yhhjrhhgjghgg/12epj + lo8ge4vb3mqjhfevzp9t6n7g6m5gw2 -----end pgp signature figure 7.6-4  a pgp signed message figure 7.6-5  shows a pgp secret message this message also appears after the mime header of course  the plaintext message is not included within the secret e-mail message when a sender  such as alice  wants both secrecy and integrity  the pgp would contain a message like that of figure 7.6-5 contained within the message of figure 7.6-4 -----begin pgp message version  pgp for personal privacy 5.0 u2r4d + /jkmn8bc5 + hgdsqaewsdfrgdszx68likm5f6gc4sdfcxyt rfdslojuhgbcfdsswe7/k = lkhnmiklo0 + l/bvcx4t = = ujk9pbcd4 thdf2awqfghbnmklok8iy6gthlp -----end pgp message figure 7.6-5  a secrect pgp message pgp also provides a mechanism for public key certification  but the mechanism is quite different from the conventional certification authority tath we examined in section 7.5 pgp public keys are certified by a web of trust alice can certify any pair of key and user name for which she believes the pair really belongs together in addition  pgp permits alice to say that she trusts another user to vouch for the authenticiy of more keys some pgp users sign each other 's keys is by holding key signing parties users physically gather  exchange floppy disks containing public keys  and certify each other 's keys by signing them with their private keys pgp public keys are also distributed by pgp public key servers on the internet when a user submits a public key to such a server  the server stores a copy of the key  sends a copy of the key to all the other public-key servers  and serves the key to anyone who requests it although key signing parties and pgp public key servers actually exist  by far the most common way for users to distribute their public keys is posting them on their personal web pages of course  keys on personal web pages are not certified by anyone  but they are easy to access file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  5 of 6  20/11/2004 15  53  08 secure e-mail references  molva 1999  r molva  internet security architecture  computer networks  1999  pgpi 1999  the international pgp home page  http  //www.pgpi.com   network associates 1999  network associates  http  //www.nai.com/default_pgp.asp   zimmerman 1999  p zimmerman  " why do you need pgp ? " http  //www.pgpi.org/doc/whypgp/en/ copyright keith w ross and james f kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...-down % 20approach % 20featuring % 20the % 20internet/pgp.htm  6 of 6  20/11/2004 15  53  08 internet commerce 7.7 internet commerce in the previous section  we considered the application-layer use  in secure e-mail  of the various security technologies that we studied earlier in this chapter  encryption  authentication  key distribution  message integrity and digital signatures in this section we 'll continue our case study of various security mechanisms by dropping down a layer in the protocol stack an covering secure sockets and a secure transport layer we 'll take internet commerce as a motivating application  since business and financial transactions are an important driver for internet security we consider internet commerce to be the purchasing of " goods " over the internet here we 'll use the term " goods " in a very broad sense to include books  cds  hardware  software  airline tickets  stocks and bonds  consulting services  etc in the 1990s many schemes were designed for internet commerce  some providing minimal levels of security and others providing a high-level of security along with customer anonymity  similar to the anonymity provided by ordinary person-to-person cash transactions  loshin 1997    in the late 1990s  however  there was a major shake out  as only a few of these schemes were widely implemented in web browsers and servers as of this writing  two schemes have taken hold  ssl  which is currently used by the vast majority of internet transactions ; and set  which is to expected to fiercely compete with ssl in the upcoming years there are three major players in this infrastructure  the customer who is purchasing a good  the merchant who is selling the good  and the merchant 's bank  which authorizes the purchase we shall see in our discussion below that internet commerce with ssl provides security for communication between the first two of these three players  i.e  the customer and the merchant   whereas set provides security for communication among all three players 7.7.1 internet commerce using ssl let 's walk through a typical internet commerce scenario bob is surfing the web and arrives at the alice incorporated site which is selling some durable good the alice incorporated site displays a form in which bob is supposed to enter the quantity desired  his address and his payment card number bob enters this information  clicks on " submit "  and then expects to receive  say  from  ordinary mail  the good ; he also expects to receive a charge for the good in his next payment card statement this all sounds good  but if no security measures are taken  such as encryption or authentication  bob could be in for a few surprises  l an intruder could intercept the order and obtain bob 's payment card information the intruder could then make purchases at bob 's expense l the site could display alice incorporated famous logo  but actually be a site maintained by trudy  who is masquerading as alice incorporated trudy could take bob 's money and run or trudy could make her own purchases and have them billed to bob 's account file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  1 of 9  20/11/2004 15  53  09 internet commerce many other surprises are possible  and we will discuss a few of these in the next subsection but the two problems listed above are among the most serious internet commerce using the ssl protocol can address both these problems secure sockets layer  ssl   originally developed by netscape  is a protocol designed to provide data encryption and authentication between a web client and a web server the protocol begins with a handshake phase that negotiates an encryption algorithm  e.g  des or rsa  and keys  and authenticates the server to the client optionally  the client can also be authenticated to the server once the handshake is complete and the transmission of application data begins  and all data is encrypted using session keys negotiated during the handshake phase ssl is widely used in internet commerce  being implemented in almost all popular browsers and web servers furthermore  it is also the basis of the transport layer security  tls  protocol  rfc 2246   figure 7.7-1  secure socket layer ssl and tls are not limited to the web application ; for example  they are also used for authentication and data encryption for imap mail access ssl can be viewed as a layer that sits between the application layer and the transport layer  as shown in figure 7.7-1 on the sending side  ssl receives from the application raw application data  such as an http or imap message   encrypts the data and directs the encrypted data to a tcp socket on the receiving side  ssl reads from the tcp socket  decrypts the data  and directs the data to the application although ssl can be used with many internet applications  we shall discuss it in the context of the web  where it is principally being used today for internet commerce ssl provides the following features  l ssl server authentication  allowing a user to confirm a server 's identity an ssl-enabled browser maintains a list of trusted certifying authorities  cas  along with the public keys of the cas when the browser wants to do business with an ssl-enabled web server  the browser obtains from the server a certificate containing the server 's public key the certificate is issued  i file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  2 of 9  20/11/2004 15  53  09 internet commerce e  digitally signed  by a certificate authority  ca  listed in the client 's list of trusted cas this feature allows the browser to authenticate the server before the user submits a payment card number in the context of the earlier example  this server authentication enables bob to verify that he is indeed sending his payment card number to alice incorporated  and not to someone else who might be masquerading as alice incorporated l an encrypted ssl session  in which all information sent between browser and server is encrypted by sending software  browser or web server  and decrypted by the receiving software  browser or web server   this confidentially may be important to both the customer and the merchant also  ssl provides a mechanism for detecting tampering of the information by an intruder l ssl client authentication  allowing a server to confirm a user 's identity analogous to server authentication  client authentication makes use of client certificates  which have also been issued by cas this authentication is important if the server  for example  is a bank sending confidential financial information to a customer and wants to check the recipient 's identity client authentication  although supported by ssl  is optional to keep our discussion focused  we will henceforth ignore it how ssl works a user  say bob  surfs the web and clicks on a link that takes him to a secure page housed by alice 's ssl-enabled server the protocol part of the url for this page is " https " rather than the ordinary " http "  the browser and server then run the ssl handshake protocol  which  1  authenticates the server and  2  generates a shared symmetric key both of these tasks make use of the rsa public-key technology the main flow of events in the handshake phase is shown in figure 7.7-2 during this phase  alice sends bob her certificate  from which bob obtains alice 's public key bob then creates a random symmetric key  encrypts it with alice 's public key  and sends the encrypted key to alice bob and alice now share a symmetric session key once this handshake protocol is complete  all data sent between the browser and server  over tcp connections  is encrypted using the symmetric session key file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  3 of 9  20/11/2004 15  53  09 internet commerce figure 7.7-2  high-level overview of the handshake phase of ssl having given a high-level overview of ssl  let 's take a closer look at some of more important details the ssl handshake performs the following steps  1 the browser sends the server the browser 's ssl version number and cryptography preferences the browser sends its cryptography preferences because the browser and server negotiate which symmetric key algorithm they are going to use 2 the server sends the browser the server 's ssl version number  cryptography preferences and its certificate recall that the certificate includes the server 's rsa public key and is certified by some ca  that is  the certificate has been encrypted by a ca 's private key 3 the browser has an entrusted list of cas and a public key for each ca on the list when the browser receives the certificate from the server  it checks to see if the ca is on the list if no  the user is warned of the problem and informed that an encrypted and authenticated connection can not be established if yes  the browser uses the ca 's public key to decrypt the certificate and obtain the server 's public key 4 the browser generates a symmetric session key  encrypts it with the server 's public key  and sends the encrypted session key to the server file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  4 of 9  20/11/2004 15  53  09 internet commerce 5 the browser sends a message to the server informing it that future messages from the client will be encrypted with the session key it then sends a separate  encrypted  message indicating that the browser portion of the handshake is finished 6 the server sends a message to the browser informing it that future messages from the server will be encrypted with the session key it then sends a separate  encrypted  message indicating that the server portion of the handshake is finished 7 the ssl handshake is now complete  and the ssl session has begun the browser and the server use the session keys to encrypt and decrypt the data they send to each other and to validate its integrity ssl handshake actually has many more steps than listed above you can find more information about ssl at netscape 's security developer central  netscapesecurity 1999   in addition to payment card purchases  we point out here that ssl can  and is  used for other financial transactions including online banking and stock trading ssl in action we recommend that you visit a secure web site  such as a quebec maple syrup site  quebec 1999   when you enter a secure section of such a site  ssl will perform the handshake protocol assuming that the server 's certificate checks out  the browser will notify you  for example by displaying a special icon all information sent between you and the server will now be encrypted your browser should let you actually see the certificate for the merchant  for example  with internet explorer  go to file  properties  certificates  in april 1999  the maple syrup site 's certificate included the following information  company  netfarmers enterprises inc certification authority  thawte certification public key  in hexadecimal   88  79  85  d5  d0  7d  60  39  10  51  31  ec  17  de  e7  80 if your browser lets you do secure transactions with the merchant  then you should also be able to see the certificate for ca  i.e  thawte certification  for example  with internet explorer  go to view  internet options  content  certificate authorities  the limitations of ssl in internet commerce due to its simplicity and early development  ssl is widely implemented in browsers  servers and internet commerce products these ssl-enabled servers and browsers provide a popular platform for payment card transactions nevertheless  we should keep in mind that ssl was not specifically tailored for payment card transactions  but instead for generic secure communication between a client and server because of this generic design  ssl lacks many features that payment-card industry would like to see in an internet commerce protocol consider once again what happens when bob makes a purchase from alice incorporated over ssl the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  5 of 9  20/11/2004 15  53  09 internet commerce signed certificate that bob receives from alice assures bob that he is really dealing with alice incorporated  and that alice incorporated is a bona fide company however  the generic certificate does not indicate whether alice incorporated is authorized to accept payment-card purchases nor if the company is a reliable merchant this opens the door for merchant fraud and there is a similar problem for client authorization even if ssl client authentication is used  the client certificate does not tie bob to a specific authorized payment card ; thus  alice incorporated has no assurance about whether bob is authorized to make a payment-card purchase this opens the door to all kinds of fraud  including purchases with stolen credit cards and customer repudiation of purchased goods  abbott 1999   of course  this kind of fraud is already rampant in mail order and telephone order  moto  purchases with moto transactions  the law dictates that the merchant accepts liability for fraudulent transactions thus  if a customer makes a moto purchase with a payment card and claims to have never made the purchase  then the merchant is liable  that is  the merchant is legally bound to return the money to the customer  unless the merchant can prove that the customer actually ordered and received the goods   similarly  if a moto purchase is made with a stolen payment card  the merchant is again liable on the other hand  with physically-present transactions  the merchant 's bank accepts the liability ; as you might expect  it is more difficult for a customer to repudiate a physcially-present purchase which involves a hand-written signature or a pin  personal identification number   ssl purchases are similar to moto purchases  and naturally the merchant is liable for a fraudulent ssl purchase it would be preferable  of course  to use a protocol that provides superior authentication of the customer and of the merchant  something that is as good or better than a physically-present transaction authentication involving payment-card authorization would reduce fraud and merchant liability 7.7.2 internet commerce using set set  secure electronic transactions  is a protocol specifically designed to secure payment-card transactions over the internet it was originally developed by visa international and mastercard international in february 1996 with participation from leading technology companies around the world set secure electronic transaction llc  commonly referred to as setco  was established in december 1997 as a legal entity to manage and promote the global adoption of set  setco 1999   some of the principle characteristics of set include  l set is designed to encrypt specific kinds of payment-related messages ; it can not be used to encrypt arbitrary data  such as text and images  as can ssl l the set protocol involves all three players mentioned at the beginning of this section  namely  the customer  the merchant and the merchant 's bank all sensitive information sent between the three parties is encrypted l set requires all three players to have certificates the customer 's and merchant 's certificates are issued by their banks  thereby assuring that these players are permitted to make and receive payment-card purchases the customer certificate provides merchants with assurance that transactions will not be fraudulently charged back it is an electronic representation of the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  6 of 9  20/11/2004 15  53  09 internet commerce customer 's payment card it basically contains information about the account  the issuing financial institution  and other cryptographic information the merchant certificate assures the consumer that merchant is authorized to accept payment-card purchases it contains information about the merchant  the merchant 's bank  and the financial institution issuing the certificate l set specifies the legal meaning of the certificates held by each party and the apportionment of liabilities connected with a transaction  abbott 1999   l in a set transaction  the customer 's payment-card number is passed to the merchant 's bank without the merchant ever seeing the number in plain text this feature prevents fraudulent or careless merchants from stealing or accidentally leaking the payment-card number a set transaction uses three software components  l browser wallet  the browser wallet application is integrated with the browser and provides the customer with storage and management of payment cards and certificates while shopping it responds to set messages from the merchant  prompting the customer to select a payment card for payment l merchant server  the merchant server is the merchandizing and fulfillment engine for merchants selling on the web for payments  it processes cardholder transactions and communicates with the merchant 's bank or approval and subsequent payment capture l acquirer gateway  the acquirer gateway is the software component at the merchant 's bank it processes the merchant 's payment card transaction for authorization and payment in what follows  we give a highly simplified overview of the set protocol in reality  the protocol is substantially more complex steps in making a purchase suppose bob wants to purchase a good over the internet from alice incorporated 1 bob indicates to alice that he is interested in making a credit card purchase 2 alice sends the customer an invoice and a unique transaction identifier 3 alice sends bob the merchant 's certificate which includes the merchant 's public key alice also sends the certificate for her bank  which includes the bank 's public key both of these certificates are encrypted with the private key of a certifying authority 4 bob uses the certifying authority 's public key to decrypt the two certificates bob now has alice 's public key and the bank 's public key 5 bob generates two packages of information  the order information  oi  package and the purchase instructions  pi  package the oi  destined for alice  contains the transaction identifier and brand of card being used ; it does not include bob 's card number the pi  destined for alice 's bank  contains the transaction identifier  the card number and the purchase amount agreed to bob the oi and pi are dual encrypted  the oi is encrypted with alice 's public key ; the pi is encrypted with alice 's bank 's public key  we are bending the truth here in order to see the big file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  7 of 9  20/11/2004 15  53  09 internet commerce picture in reality  the oi and pi are encrypted with a customer-merchant session key and a customer-bank session key  bob sends the oi and the pi to alice 6 alice generates an authorization request for the card payment request  which includes the transaction identifier 7 alice sends to her bank a message encrypted with the bank 's public key  actually  a session key is used  this message includes the authorization request  the pi package received from bob  and alice 's certificate 8 alice 's bank receives the message and unravels it the bank checks for tampering it also makes sure that the transaction identifier in the authorization request matches the one in bob 's pi package 9 alice 's bank then sends a request for payment authorization to bob 's payment-card bank through traditional bank-card channels  just as alice 's bank would request authorization for any normal payment-card transaction 10 once bob 's bank authorizes the payment  alice 's bank sends a response to the alice  which is  of course  encrypted the response includes the transaction identifier 11 if the transaction is approved  alice sends its own response message to bob this message serves as a receipt and informs bob that the payment was accepted and that the goods will be delivered one of the key features of set is the non-exposure of the credit number to the merchant this feature is provided in step 5  in which the customer encrypts the credit card number with the bank 's key encrypting the number with the bank 's key prevents the merchant from seeing the credit card note that the set protocol closely parallels the steps taken in a standard payment-card transaction to handle all the set tasks  the customer will have a so-called digital wallet that runs the client-side of the set protocol and stores customer payment-card information  card number  expiration date  etc   readers interested in learning more about set are encouraged to see setco page  setco 1999  or the set documentation at the mastercard site  master 1999   there are also several good books on set  merkow 1998   loeb 1998   references  abbott 1999  s abbott  " the debate for secure e-commerce  " performance computing  february 1999  http  //www.performancecomputing.com/features/9902f1.shtml  loeb 1998  l loeb  secure electronic transactions  introduction and technical reference  " artech house  new york  1998  loshin 1997  p loshin  p murphy  " electronic commerce  on-line ordering and digital money "  charles river media  august 1997  merkow 1998  m merkow  k wheeler  and j breithaupt  " building set applications for secure transactions  " john wiley and sons  new york  1998  master 1999  set secure electronic transaction  mastercard web site  http  //www.mastercard.com/ shoponline/set/  netscapesecurity 1999  security developer central  netscape site  http  //developer.netscape.com/tech/ security/ file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  8 of 9  20/11/2004 15  53  09 internet commerce  quebec 1999  quebec maple syrup homepage  http  //www.jam.ca/syrup/  rfc 2246  t dierks and c allen  the tls protocol   rfc 22246   january 1999  setco1999  setco llc website  http  //www.setco.org/ return to table of contents copyright keith w ross and jim kurose 1996-2000 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/icommerce.htm  9 of 9  20/11/2004 15  53  09 what is network security ? 7.8 network layer security  ipsec having examined case studies of the use of various security mechanisms at the application  socket  and transport layers  our final case study naturally takes us down to the network layer here  we 'll examine the the ip security protocol  more commonly known as ipsec  a suite of protocols that provides security at the network layer ipsec is a rather complex animal  and different parts of it are described in more than a dozen rfcs in this section  we 'll discuss ipsec in a specific context  namely  in the context that all hosts in the internet support ipsec although this context is many years away  the context will simplify the discussion and help us understand the key features of ipsec two key rfcs are  rfc 2401   which describes the overall ip security architecture and  rfc 2411   which provides an overview of the ipsec protocol suite and the documents describing it a nice introduction to ipsec is given in  kessler   before getting into the specifics of ipsec  let 's step back and consider what it means to provide security at the network layer consider first what it means to provide network layer secrecy the network layer would provide secrecy if all data carried by all ip datagrams were encrypted this means that whenever a host wants to send a datagram  it encrypts the data field of the datagram before shipping it out into the network in principle  the encryption could be done with symmetric key encryption  public key encryption or with session keys that have are negotiated using public key encryption the data field could be a tcp segment  a udp segment  an icmp message  etc if such a network layer service were in place  all data sent by hosts  including e-mail  web pages  control and management messages  such as icmp and snmp   would be hidden from any third party that is " wire tapping " the network  however  the unencrypted data could be snooped at points in the source or destination hosts  thus  such a service would provide a certain " blanket coverage " for all internet traffic  thereby giving all of us a certain sense of security in addition to secrecy  one might want the network layer to also provide source authentication when a destination host receives an ip datagram with a particular ip source address  it might authenticate the source by making sure that the ip datagram was indeed generated by the host with that ip source address such a service prevents attackers from spoofing ip addresses in the ipsec protocol suite there are two principal protocols  the authentication header  ah  protocol and the encapsulation security payload  esp  protocol when a source host sends secure datagrams to a destination host  it does so with either the ah protocol or with the esp protocol.the ah protocol provides source authentication and data integrity but does not provide secrecy the esp protocol provides data integrity and secrecy providing more services  the esp protocol is naturally more complicated and requires more processing than the ah protocol we 'll discuss both of these protocols below for both the ah and the esp protocols  before sending secured datagrams from a source host to a destination host  the source and network hosts handshake and create a network layer logical connection this logical channel is called a security agreement  sa   thus  ipsec transforms the traditional file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/ipsec.htm  1 of 5  20/11/2004 15  53  10 what is network security ? connectionless network layer of the internet to a layer with logical connections ! the logical connection defined by a sa is a simplex connection  that is  it is unidirectional if both hosts want to send secure datagrams to each other  then two sas  i.e  logical connections  need to be established  one in each direction a sa is uniquely identified by a 3-tuple consisting of  l a security protocol  ah or esp  identifier ; l the source ip address for the simplex connection ; l a 32-bit connection identifier called the security paramter index  spi   for a given sa  that is  a given logical connection from source host to destination host   each ipsec datagram will have a special field for the spi all of the datagrams in the sa will use the same spi value in this field authentication header  ah  protocol as mentioned above  the ah protocol provides source host identification and data integrity but not secrecy when a particular source host wants to send one or more datagrams to a particular destination  it first establishes an sa with the destination after having established the sa  the source can send secured datagrams to the destination host the secured datagrams include the ah header  which is inserted between the original ip datagram data  e.g  a tcp or udp segment  and the ip header  as shown in figure 7.8-1 thus the ah header augments the original data field  and this augmented data field is encapsulated as a standard ip datagram for the protocol field in the ip header  the value 51 is used to indicate that the datagram includes an ah header when the destination host recieves the ip datagram  it takes note of the 51 in the protocol field  and processes the datagram using the ah protocol  recall that the protocol field in the ip datagram is traditionally used to distinguish between udp  tcp  icmp  etc  intermediate routers process the datagrams just as they always have  they examine the destination ip address and route the datagrams accordingly figure 7.8-1  position of the ah header in the ip datagram the ah header includes several fields  including  l next header field  which has the role that the protocol field has for an ordinary datagram it indicates if the data following the ah header is a tcp segment  udp segment  icmp segment  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/ipsec.htm  2 of 5  20/11/2004 15  53  10 what is network security ? etc  recall that protocol field in the datagram is now being used to indicate the ah protocol  so it can no longer be used to indicate the transport-layer protocol  l security parameter index  spi  field  an arbitrary 32-bit value that  in combination with the destination ip address and the security protocol  uniquely identifies the sa for the datagram l sequence number field  a 32-bit field containing a sequence number for each datagram it is initally set to 0 at the establishment of an sa the ah protocol uses the sequence numbers to prevent playback and man-in-the-middle attacks  see section 7.3   l authentication data field  a variable-length field containing signed message digest  i.e  a digital signature  for this packet the message digist is calculated over the original ip datagram  thereby providing source host authentication and ip datagram integrity the digital signature is computed using the authentication algorithm specified by the sa  such as des  md5 or sha when the destination host receives an ip datagram with an ah header  it determines the sa for the packet and then authenticates the integrity of the datagram by processing the authentication data field the ipsec authentication scheme  for both the ah and esp protocols  uses a scheme called hmac  which is an encrypted message digest described in  rfc 2104   hmac uses a shared secret key between two parties rather than public key methods for message authentication further details about the ah protocol can be found in  rfc 2402   the esp protocol the esp protocol provides network layer secrecy as well as source host authentication once again  it all begins with a source host establishing a sa with a destination host then the source host can send secured datagrams to the destination host as shown in figure 7.8-2  a secured datagram is created by surrounding the original ip datagram data with header and trailer fields  and then inserting this encapsulated data into the data field of an ip datagram for the protocol field in the header of the ip datagram  the value 50 is used to indicate that the datagram includes an esp header and trailer when the destination host recieves the ip datagram  it takes note of the 50 in the protocol field  and processes the datagram using the esp protocol as shown in figure 7.8-2  the original ip datagram data along with the esp trailer field are encrypted secrecy is provided with des-cbc encryption  rfc 2405   the esp header consists of a 32 bit field for the spi and 32-bit field for the sequence number  which have exactly the same role as in the ah protocol the trailer includes the next header field  which also has exactly the same role note that because the next header field is encrypted along with the original data  an intruder will not be able to determine the transport protocol that is being used following the trailer there is the authentication data field  which again serves the same role as in the ah protocol further details about the ah protocol can be found in  rfc 2406   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/ipsec.htm  3 of 5  20/11/2004 15  53  10 what is network security ? figure 7.8-2  the esp fields in the ip datagram sa and key management for sucessful deployment of ipsec  a scalable and automated sa and key management scheme is necessary several protocols have been defined for these tasks  including  l the internet key exchange  ike  algorithm  rfc 2409  is the default key management protocol for ipsec l the internet security assoication and key management protocol  iskmp  defines procedures for establishing and tearing down sas  rfc 2407   rfc 2408   iskmp 's security association is completely separate from ike key exchange this wraps up our summary of ipsec we have discussed ipsec in the context of ipv4 and the " transport mode "  ipsec also defines a " tunnel mode  " in which routers introduce the security functionality rather than the hosts finally  ipsec describes encryption procedures for ipv6 as well as ipv4 references  kessler  g.c kessler  an overview of cryptography  may 1998  hill associates  http  //www.hill.com/ techlibrary/index.htm  rfc 2104  h krawczyk  m.bellare  r canetti  hmac  keyed-hashing for message authentication   rfc 2104   february 1997  rfc 2401  s kent and r atkinson  security architecture for the internet protocol   rfc 2401   november 1998 file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/ipsec.htm  4 of 5  20/11/2004 15  53  10 what is network security ?  rfc 2402  s kent and r atkinson  ip authentication header   rfc 2402   november 1998  rfc 2405  c madson and n.doraswamy  the esp des-cbc cipher algorithm with explicit iv   rfc 2405   november 1998  rfc 2406  s kent and r atkinson  ip authentication header   rfc 2406   november 1998  rfc 2407  d piper  the internet ip security domain of interpretation for isakmp   rfc 2407   november 1998  rfc 2408  d maughan  m schertler  m schneider and j turner  internet security association and key management protocol  isakmp    rfc 2408   november 1998  rfc 2409  d harkins and d carrel  the internet key exchange  ike    rfc 2409   november 1998  rfc 2411  r thayer  n doraswamy and r glenn  " ip security document road map  "  rfc 2411   november 1998 copyright 1999-2000  keith w ross and jim kurose all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...own % 20approach % 20featuring % 20the % 20internet/ipsec.htm  5 of 5  20/11/2004 15  53  10 chapter 7 summary 7.9 summary in this chapter  we 've examined the various mechanisms that our secret lovers  bob and alice  can use to communicate " securely " we 've seen that bob and alice are interested in secrecy  so that they alone are able to understand the contents of a transmitted message   authentication  so that they are sure that they are talking with each other   and message integrity  so that they are sure that their messages are not altered in transit   of course  the need for secure communication is not confined to secret lovers indeed  we saw in section 7.1 that security is needed at various layers in a network architecture to protect against " bad guys " who may sniff packets  remove packets from the network  or inject falsely addressed packets into the network the first part of this chapter presented various principles underlying secure communication we covered cryptographic techniques for coding and decoding data in section 7.2  including both symmetric key cryptography and public key cryptography des and rsa were examined as specific case studies of these two major classes of cryptographic techniques in use in today 's networks in section 7.3 we turned our attention to authentication  and developed a series of increasingly sophisticated authentication protocols to ensure that a conversant is indeed who he/she claims to be  and is " live " we saw that both symmetric key cryptography and public key cryptography can play an important role not only in disguising data  encryption/decryption   but also in performing authentication techniques for " signing " a digital document in a manner that is verifiable  non-forgible  and non-repudiable were covered in section 7.4 once again  the application of cryptographic techniques proved essential we examined both digital signatures and message digests  a shorthand way of signing a digital document in section 7.5 we examined key distribution protocols we saw that for symmetric key encryption  a key distribution center  a single trusted network entity  can be used to distribute a shared symmetric key among communicating parties for public key encryption  a certification authority distributes certificates to validate public keys armed with the techniques covered in sections 7.2 through 7.5  bob and alice can communicate securely  one can only hope that they are networking students who have learned this material and can thus avoid having their tryst uncovered by trudy !   in the second part of this chapter we thus turned our attention to the use of various security techniques in networks in section 7.6  we used e-mail as a case study for application-layer security  designing an e-mail system that provided secrecy  sender authentication and message integrity we also examined the use of pgp as a public-key e-mail encryption scheme our cases studies continued as we headed down the protocol stack and examined the secure sockets layer  ssl  and secure electronic transactions  the two primary protocols in use today for secure electronic commerce both are based on public key techniques finally  in section 7.8 we examined a suite of security protocols for the ip layer of the internet  the so-called ipsec protocols these can be used to provide secrecy  authentication and message integrity between two communication ip devices file  ///d | /downloads/livros/computa ? ? o/computer % 20networki...approach % 20featuring % 20the % 20internet/security_summary.htm20/11/2004 15  53  10 network security  homework problems homework problems and discussion questions review questions 1  what are the differences between message secrecy and message integrity ? can you have one without the other ? justify your answer 2  what is the difference between an active and a passive intruder ? 3  what is an important difference between a symmetric key system and a public key system ? 4  suppose that an intruder has an encrypted message as well as the decrypted version of that message can the intruder mount a cipher-text only attack  a known-plaintext or a chosen-plaintext attack ? 5  suppose n people want to communicate with each of the n-1 other people using symmetric key encryption all communication between any to people  i and j  is visible to all other people  and no other person should be able to decode their communication how many keys are required in the system as a whole ? now suppose that public key encryption is used how many keys are required in this case ? 6  what is the purpose of a nonce in an authentication protocol ? 7  what does it mean to say that a nonce is a once-in-a-lifetime value ? in whose lifetime ? 8  what is the man-in-the-middle attack ? can this attack occur when symmetric keys are used ? 9  what does it mean for a signed document to be verifiable  non-forgible  and non-repudiable ? 10  in what way does a message digest provide a better message integrity check than a checksum such as the internet checksum ? 11  in what way does a message digest provide a " better " digital signature than using a public key digital signature ? 12  is the message associated with a message digested encrypted ? since either " yes " or " no " are acceptable answers here  you should explain your answer 13  what is a key distribution center ? what is a certification authority ? 14  summarize the key differences in the services provided by the authentication header protocol and file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ach % 20featuring % 20the % 20internet/security_homework.htm  1 of 3  20/11/2004 15  53  11 network security  homework problems the encapsulation security payload  esp  protocol in ipsec problems 1  using the monoalphabetic cipher in figure 7-3 encode the message " this is an easy problem " decode the message " rmij'u uamu xyj " 2  show that eve 's known plaintext attack in which she knows the  ciphertext  plaintext  translation pairs for seven letters reduces the number of possible substitutions to be checked by approximately 109 3  consider the vigenere system shown in figure 7-4 will a chosen plaintext attack that is able to get the plaintext encoding of the message  " the quick fox jumps over the lazy brown dog " be sufficient to decode all messages ? why ? 4  using rsa  choose p = 3 and q = 11  and encode the phrase " hello "  apply the decryption algorithm  to the encrypted version to recover the original plaintext message 5  in the man-in-the-middle attack in figure 7.3-7  alice has not authenticated bob if alice were to require bob to authenticate himself using ap5.0  would the man-in-the-middle attack be avoided ? explain your reasoning 6  the internet bgp routing protocol uses the md5 message digest rather than public key encryption to sign bgp messages why do you think md5 was chosen over public key encryption ? 7  compute a third message  different than the two messages in figure 7.4-5  that has the same checksum as the messages in figure 7.4-5 8  augment the kdc protocol shown in figure 7.5-1 to include the necessary authentication messages be sure to show the use of nonces and indicate which key values are used to encrypt which messages 9  in the protocol and discussion of figure 7.5-1  why does n't alice have to explicitly authenticate bob ? 10  in the protocol in figure 7.5-2  alice did not include her own identity in the message to the ca anyone could thus spoof a message from alice to the ca does this compromise the integrity of the ca 's public key distribution ? justify your answer 11  why is there no explicit authentication in the protocol in figure 7.5-2 ? is authentication needed ? why ? 12  consider the kdc and the ca servers suppose a kdc goes down ? what is the impact on the ability of parties to communicate securely  i.e  who can  and can not  communicate ? justify your file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ach % 20featuring % 20the % 20internet/security_homework.htm  2 of 3  20/11/2004 15  53  11 network security  homework problems answer suppose now that a ca goes down what is the impact of this failure ? discussion questions 1  suppose that an intruder could both insert and remove dns messages into the network give three scenarios showing the problems that such an intruder could cause 2  no one has formally " proven " that 3-des or rsa are " secure " given this  what evidence do we have they are indeed secure ? 3  if ipsec provides security at the network layer  why is it that security mechanisms are still needed at layers above ip ? 4  go to the international pgp homepage  http  //www.pgpi.org/   what version of pgp are you legally allowed to download  given the country you are in ? file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...ach % 20featuring % 20the % 20internet/security_homework.htm  3 of 3  20/11/2004 15  53  11 network managment  introduction 8.1 what is network management ? having made our way through the first seven chapters of this text  we 're now well aware that a network consists of many complex  interacting pieces of hardware and software  from the links  bridges  routers  hosts and other devices that comprise the physical components of the network to the many protocols  in both hardware and software  that control and coordinate these devices when hundreds or thousands of such components are cobbled together by an organization to form a network  it is not surprising that components will occasionally malfunction  that network elements will be misconfigured  that network resources will be overutilized  or that network components will simply " break "  e.g  a cable will be cut  a can of soda will be spilled on top of router   the network administrator  whose job it is to keep the network " up and running  " must be able to respond to  and better yet  avoid  such mishaps with potentially thousands of network components spread out over a wide area  the network administrator in a network operations center  noc  clearly needs tools to help monitor  manage  and control the network in this chapter  we 'll examine the architecture  protocols  and information base used by a network administrator in this task before diving in to network management itself  let 's first consider a few illustrative " real-world " nonnetworking scenarios in which a complex system with many interacting components must monitored  managed  and controlled by an administrator electrical power-generation plants  at least as portrayed in the popular media  e.g  movies such as the china syndrome  have a control room where dials  gauges  and lights monitor the status  temperature  pressure  flow  of remote valves  pipes  vessels  and other plant components these devices allow the operator to monitor the plant 's many components  and may alert the operator  the famous flashing red warning light  when trouble is imminent actions are taken by the plant operator to control these components similarly  an airplane cockpit is instrumented to allow a pilot to monitor and control the many components that make up an airplane in these two examples  the " administrator " monitors remote devices and analyzes their data to ensure that they are operational and operating within prescribed limits  e.g  that a core meltdown of a nuclear power plant is not imminent  or that the plane is not about to run out of fuel   reactively controls the system by making adjustments in response the changes within the system or its environment  and proactively manages the system  e.g  by detecting trends or anomalous behavior that allows action to be taken before serious problems arise in a similar sense  the network administrator will actively monitor  manage and control the system with which s/he is entrusted in the early days of networking  when computer networks were research artifacts rather than a critical infrastructure used by millions of people a day  " network management " was an unheard of thing if one encountered a network problem  one might run a few pings to locate the source of the problem and then modify system settings  reboot hardware or software  or call a remote colleague to do so  a very readable discussion of the first major " crash " of the arpanet on october 27  1980  long before network management tools were available  and the efforts taken to recover from and understand the crash is  rfc 789    as the public internet and private intranets have grown from small networks into a large global infrastructure  the need to more systematically manage the huge number of hardware and file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/netman_intro.html  1 of 5  20/11/2004 15  53  11 network managment  introduction software components within these networks has grown more important as well figure 8.1-1  a simple scenario illustrating the uses of network management in order to motivate our study of network management  let 's begin with a simple example figure 8.1-1 illustrates a small network consisting of three routers  and a number of hosts and servers even in such a simple network  there are many scenarios in which a network administrator might benefit tremendously from having appropriate network management tools  l failure of an interface card at a host  e.g  h1  or a router  e.g  a   with appropriate network management tools  a network entity  e.g router a  may report to the network administrator that one of its interfaces has gone down  which is certainly preferable than a phone call to the noc from an irate user who says the network connection is down   a network administrator who actively monitors and analyzes network traffic may be able to really impress the would-be irate user by actually detecting problems in the interface ahead of time and replacing the interface card before it fails this could be done  for example  if the administrator noted an increase in checksum errors in frames being sent by the soon-to-die interface l monitoring traffic to aid in resource deployment a network administrator might monitor sourceto destination traffic patterns and notice  for example  that by switching servers between lan segments  the amount of traffic that crosses multiple lans could be significantly decreased imagine the happiness all around  especially in higher administration  when better performance is achieved with no new equipment costs similarly  by monitoring link utilization  a network administrator might determine that a lan segment  or the external link to the outside world is overloaded and a higher-bandwidth link should thus be provisioned  alas  at an increased cost   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/netman_intro.html  2 of 5  20/11/2004 15  53  11 network managment  introduction the network administrator might also want to be notified automatically when congestion levels on a link exceed a given threshold value in order to address a provisioning problem before it becomes serious l detecting rapid changes in routing tables route flapping  frequent changes in the routing tables  may indicate instabilities in the routing or a misconfigured router certainly  the network administrator who has improperly configured a router would prefer to discover the error his/ herself  before the network goes down l monitoring for slas with the advent of service level agreements  sla   contracts that define specific performance metrics and acceptable levels of network provider performance with respect to these metrics  interest in traffic monitoring has increased significantly over the past few years  larsen 1997   uunet and at&t are just two of many many network providers that guarantee slas  uunet 1999  at&t 1998  to their customers these slas include service availability  outage   latency  throughput and outage notification requirements clearly  if performance criteria are to be part of a service agreement between a network provider and its users  then measuring and managing performance will be of great importance to the network administrator l intrusion detection a network administrator may want to be notified when network traffic arrives from  or is destined to  a suspicious source  e.g  host or port number   similarly  a network administrator may want to detect  and in many cases filter  the existence of certain types of traffic  e.g  source-routed packets  or a large number of syn packets directed to a given host  that are known to be characteristic of certain attacks the iso  the organization that gave us the well-known 7-layer iso reference model  see chapter 1   has also created a network management model  that is useful for placing the above anecdotal scenarios in a more structured framework five areas of network management are defined  l performance management the goal of performance management is to quantify  measure  report  analyze and control the performance  e.g  utilization  throughput  of different network components these components include individual devices  e.g  links  routers  and hosts  as well as end-end abstractions such as a path through the network we will see shortly that protocol standards such as the simple network management protocol  snmp   rfc 2570  play a central role in performance management l fault management the goal of fault management is to log  detect  and respond to fault conditions in the network the line between fault management and performance management is rather blurred we can think of fault management as the immediate handling of transient network failures  e.g  link  host or router hardware or software outages   while performance management takes the longer term view of providing acceptable levels of performance in the face of varying traffic demands and  hopefully rare  network device failures as with performance management  file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/netman_intro.html  3 of 5  20/11/2004 15  53  11 network managment  introduction the snmp protocol plays a central role in fault management of ip networks l configuration management configuration management allows a network manager to track which devices are on the managed network and the hardware and software configurations of these devices l accounting management accounting management allows the network manager to specify  log  and control user and device access to network resources usage quotas  usage-based charging  and the allocation of resource access privileges all fall under accounting management l security management the goal of security management is to control access to network resources according to some well-defined policy the key distribution centers and certificate authorities that we studied in section 7.4 are components of security management the use of firewalls to monitor and control external access points to one 's network  a topic we will study in section 8.4  is another crucial component in this chapter  we 'll cover only the rudiments of network management our focus will be purposefully narrow  we 'll examine only the infrastructure for network management  the overall architecture  network management protocols  and information base through which a network administrator " keeps the network up and running " we 'll not cover the decision making processes of the network administrator  who must plan  analyze  and respond to the management information that is conveyed to the noc in this area  topics such as fault identification and management  katzela 1995  mehdi 1997   proactive anomaly detection  thottan 1998   alarm correlation  jakobson 1993   and more come into consideration nor will we cover the broader topic of service management  saydam 1996   the provisioning of resources such as bandwidth  server capacity and the other computational/ communication resources needed to meet the mission-specific service requirements of an enterprise in this latter area  standards such as tmn  glitho 1995  sidor 98  and tina  hamada 1997  are larger  more encompassing  and arguably much more cumbersome  standards that address this larger issue tina  for example  is described as " a set of common goals  principles  and concepts cover the management of services  resources  and parts of the distributed processing environment "  hamada 1997   clearly  all of these topics are enough for a separate text  and would take us a bit far afield from the more technical aspects of computer networking so  as noted above  our more modest goal here will be cover the important " nuts and bolts " of the infrastructure through which the network administrator keeps the bits flowing smoothly an often-asked question is " what is network management ? " our discussion above has motivated the need for  and illustrated a few of the uses of  network management we 'll conclude this section with a single-sentence  albeit a rather long  run-on sentence  definition of network management from  saydam 1996   " network management includes the deployment  integration and coordination of the hardware  software and human elements to monitor  test  poll  configure  analyze  evaluate and control the file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/netman_intro.html  4 of 5  20/11/2004 15  53  11 network managment  introduction network and element resources to meet the real-time  operational performance  and quality of service requirements at a reasonable cost " it 's a mouthful  but it 's a good workable definition in the following sections  we 'll add some meat to this rather bare-bones definition of network management references  at&t 1999  at&t  " at&t raises the bar on data networking guarantees  " http  //www.att.com/ press/0198/980127.bsc.html  glitho 1995  r glitho and s hayes  eds   special issue on telecommunications management network  ieee communications magazine  vol 33  no 3   march 1995    hamada 1997  t hamada  h kamata  s hogg  " an overview of the tina management architecture  " journal of network and systems management  vol 5 no 4  dec 1997   pp 411-435  jakobson 1993  g jacobson and m weissman  " alarm correlation  " ieee network magazine  1993  pp 52-59  katzela 1995  i katzela  and m schwartz " schemes for fault identification in communication networks  " ieee/acm transactions on networking  vol 3  no 6  dec 1995   pp 753-764  larsen 1997  a larsen  " guaranteed service  monitoring tools  " data communications  june 1997  pp 85-94  mehdi 1997  d mehdi and d tipper  eds   special issue  fault management in communication networks  journal of network and systems management  vol 5 no 2  june 1997    rfc 789  e rosen  " vulnerabilities of network control protocols  " rfc 789  rfc 2570  j case  r mundy  d partain  b stewart  " introduction to version 3 of the internetstandard network management framework " rfc 2570  may 1999  saydam 1996  t saydam and t magedanz  " from networks and network management into service and service management  " journal of networks and system management  vol 4  no 4  dec 1996   pp 345-348  sidor 1998  d sidor  tmn standards  satisfying today 's needs while preparing for tomorrow  ieee communications magazine  vol 36  no 3  march 1998   pp 54-64  thottan 1998  m thottan and c ji  " proactive anomaly detection using distributed intelligent agents  " ieee network magazine  vol 12  no 5  sept./oct 1998   pp 21-28  uunet 1999  uunet  " service level agreement  " http  //www.uk.uu.net/support/sla/ copyright 1999 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...pproach % 20featuring % 20the % 20internet/netman_intro.html  5 of 5  20/11/2004 15  53  11 the infrastrcuture for network management 8.2 the infrastructure for network management we 've seen in the previous section that network management requires the ability to " monitor  test  poll  configure   and control " the hardware and software and components in a network because the network devices are distributed  this will minimally require that the network administrator be able to gather data  e.g  for monitoring purposes  from a remote entity and be able to affect changes  e.g  control  at that remote entity a human analogy will prove useful here for understanding the infrastructure needed for network management imagine that you 're the head of a large organization that has branch offices around the world it 's your job to make sure that the pieces of your organization are operating smoothly how would you do so ? at a minimum  you 'll periodically gather data from your branch offices in the form of reports and various quantitative measures of activity  productivity  and budget you 'll occasionally  but not always  be explicitly notified when there 's a problem in one of the branch offices ; the branch manager who wants to climb the corporate ladder  perhaps to get your job  may send you unsolicited reports indicating how smoothly things are running at his/her branch you 'll sift through the reports you receive  hoping to find smooth operations everywhere  but no doubt finding problems in need of your attention you might initiate a one-on-one dialogue with one of your problem branch offices  gather more data in order to understand the problem  and then pass down an executive order  " make this change ! "  to the branch office manager implicit in this very common human scenario is an infrastructure for controlling the organization  the boss  you   the remotes sites being controlled  the branch offices   your remote agents  the branch office managers   communication protocols  for transmitting standard reports and data  and for one-on-one dialogues   and data  the report contents and the quantitative measures of activity  productivity  and budget   each of these components in human organizational management has an exact counterpart in network management the architecture of a network management system is conceptually identical to this simple human organizational analogy the network management field has its own specific terminology for the various components of a network management architecture  and so we adopt that terminology here as shown in figure 8.2-1  there are three principle components of a network management architecture  a managing entity  e.g  the boss in our above analogy  you   the managed devices  the branch office   and a network management protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/infrastructure.htm  1 of 4  20/11/2004 15  53  12 the infrastrcuture for network management figure 8.2-1  principal components of a network management architecture l the managing entity is an application  typically with a human-in-the-loop  running in a centralized network management station in the network operations center  noc   the managing entity is the central locus of activity for network management  it controls the collection  processing  analysis  and/or display of network management information it is here that actions are initiated to control network behavior and here that the human network administrator interacts with the network devices l a managed device is a piece of network equipment  including its software  that resides on a managed network this is the branch office in our human analogy a managed device might be a host  router  bridge  hub  printer  or modem device within a managed device  there may be several so-called managed objects these managed objects are the actual pieces of hardware within the managed device  e.g  a network interface card   and the sets of configuration parameters for the pieces of hardware and software  e.g  an intradomain routing protocol such as rip   in our human analogy  the managed objects might be the departments within the branch office these managed objects have pieces information associated with them that are collected into a management information base  mib  ; we 'll see that the values of these pieces of information are available to  and in many cases setable by  the managing entity in our human file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/infrastructure.htm  2 of 4  20/11/2004 15  53  12 the infrastrcuture for network management analogy  the mib corresponds to quantitative data  measures of activity  productivity  and budget  with the latter being setable by the managing entity !  exchanged between the branch office and the main office we 'll study mibs in detail in section 8.3 finally  also resident in each managed device is a network management agent  a process running in the managed device that communicates with the managing entity  taking local actions on the managed device under the command and control of the managing entity the network management agent is the branch manager in our human analogy l the third piece of a network management architecture is the network management protocol the protocol runs between the managing entity and the managed devices  allowing the managing entity to query the status of managed devices and indirectly effect actions in these devices via its agents agents can use the the network management protocol to inform the managing entity of exceptional events  e.g  component failures or violation of performance thresholds   although the infrastructure for network management is conceptually simple  one can often get bogged down with the network-management-speak vocabulary of " managing entity  " " managed device  " " managing agent  " and " management information base " hopefully  keeping the human organizational analogy and its obvious parallels with network management in mind will be of help as we continue through this chapter our discussion of network management architecture above has been generic  and broadly applied to a number of the network management standards and efforts that have been proposed over the years network management standards began maturing in the late 1980 's  with osi cmise/cmip  the common management service element/common management information protocol   piscatello 1993  stallings 1993  glitho 1998  and the internet snmp  simple network management protocol   stallings 1993  rfc 2570  stallings 1999  rose 1996  emerging as the two most important standards both are designed to be independent of vendor-specific products or networks because snmp was quickly designed and deployed at a time when the need for network management was becoming painfully clear  snmp found widespread use and acceptance today  snmp has emerged as the most widely used and deployed network management framework we cover snmp in detail in the following section references  glitho 1998  r glitho  " contrasting osi systems management to snmp and tmn  " journal of network and systems management  vol 6  no 2   june 1998   pp 113-131  piscatello 1993  d piscatello and a lyman chapin  " open systems networking "  addison wesley  1993  rfc 2570  j case  r mundy  d partain  b stewart  " introduction to version 3 of the internetstandard network management framework " rfc 2570  may 1999  rose 1996  m rose  " simple book  the  an introduction to internet management  revised second edition  " prentice hall  1996 file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/infrastructure.htm  3 of 4  20/11/2004 15  53  12 the infrastrcuture for network management  stallings 1993  w stallings  " snmp snmp v2 and cmip the practical guide to network management standards  " addison wesley 1993  stallings 1999  w stallings  " snmp  snmpv2  snmpv3  and rmon 1 and 2  " addison wesley  1999 copyright 1999 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netwo...pproach % 20featuring % 20the % 20internet/infrastructure.htm  4 of 4  20/11/2004 15  53  12 the internet network management framework 8.3 the internet network management framework contrary to what the name snmp  simple network management protocol  might suggest  network management in the internet is much more than just a protocol for moving management data between a management entity and its agents  and has grown to be more complex than the word " simple " might suggest the current internet standard management framework traces it roots back to the simple gateway monitoring protocol  sgmp  rfc 1028   that was designed by a group of university network researchers  users  and manager ; their experience with sgmp allowed them to design  implement  and deploy snmp in just a few months  lynch 1993   a far cry from today 's rather drawn out standardization process since then  snmp has evolved from snmpv1 through snmpv2 to the most recent version  snmpv3  rfc2570   released in april 1999 when describing any framework for network management  certain questions must inevitably be addressed  l what  from a semantic viewpoint  is being monitored ? and what form of control can be exercised by the network administrator ? l what is the specific form of the information that will be reported and/or exchanged ? l what is the protocol for communication protocol for exchanging this information ? recall our human organizational analogy from the previous section the boss and the branch managers will need to agree on the measures of activity  productivity and budget used to report the branch office 's status similarly  they 'll need to agree on the actions the boss can take  e.g  cut budget  order the branch manager to change some aspect of the office 's operation   at a lower level of detail  they 'll need to agree on the form in which this data is reported  e.g  in what currency  dollars  euros ?  will the budget be reported ? in what units will productivity be measured ?   while these are trivial details  but they be agreed upon  nonetheless finally  the manner in which information is conveyed between the main office and the branch offices  i.e  their communication protocol  must be specified the internet network management framework exactly addresses the the questions posed above the framework consists of four parts  l definitions of network management objects known as mib objects in the internet network management framework  management information is represented a collection of managed objects that together form a virtual information store  known as the management information base  mib   a mib object might be a counter  such as the number of ip datagrams discarded at a router due to errors in an ip datagram header or the number of carrier sense errors in an ethernet interface  descriptive information such as the server software running on a dns server ; status information such as whether a particular device is functioning correctly or not  or protocol-specific information such as a routing path to a destination mib objects thus define the management information maintained by a managed node related mib objects are gathered into so-called mib modules in our human organization analogy  the mib defines the information conveyed between the branch office and the main office l a data definition language  known as smi  structure of management information  that defines the file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  1 of 15  20/11/2004 15  53  15 the internet network management framework data types  an object model  and rules for writing and revising management information ; mib objects are specified in this data definition language in our human organizational analogy  the smi is used to define the details of the format of the information to be exchanged l a protocol  snmp  for conveying information and commands between a managing entity and an agent executing on behalf of that entity within a managed network device ; l security and administration capabilities the addition of these capabilities represents the major enhancement in snmpv3 over snmpv2 the internet network management architecture is thus modular by design  with a protocol-independent data definition language and mib  and a mib-independent protocol interestingly  this modular architecture was first put in place to ease the transition from an snmp-based network management to a network management framework being developed by the international organization for standardization  iso   the competing network management architecture when snmp was first conceived  a transition that never occurred over time  however  snmp 's design modularity has allowed it to evolve through three major revisions  with each of the four majors parts of snmp discussed above evolving independently clearly  the right decision about modularity was made  if even for the wrong reason ! in the following four sections  we cover the four major components of the internet network management framework in more detail 8.3.1 structure of management information  smi the structure of management information  smi   a rather oddly named component of the network management framework whose name gives no hint of its functionality  is the language used to define the management information residing in a managed network entity such a definition language is needed to ensure that the syntax and semantics of the defined network management data are well-defined and unambiguous note that the smi does not define a specific instance the data in a managed network entity  but rather the language in which such information is specified the documents describing the smi for snmpv3  which rather confusingly  is called smiv2  are  rfc 2578  rfc 2579  rfc 2580   let us examine the smi in a bottom-up manner  starting with the base data types in the smi we 'll then look at how managed objects are described in smi  and then how related managed managed objects are grouped into modules smi base data types rfc 2578  rfc 2578  specifies the basic data types in the smi mib module-definition language although the smi is based on the asn.1  abstract syntax notation one   iso 1987  iso x.680  object definition language  see section 8.4  developed by the iso in the 1980  enough smi-specific data types have been added that smi should be considered a data definition language in its own right the eleven basic data types defined in rfc 2578 are shown in table 8.3-1 in addition to these scalar objects  it is also possible to impose a tabular structure on an ordered collection of mib objects using the sequence of construct ; see  rfc 2578  for details most of the data types in table 8.3-1 will be familiar  or self-explanatory  to most readers the one data type we will discuss in more detail shortly is the object identifier data type  which is used to name an object file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  2 of 15  20/11/2004 15  53  15 the internet network management framework data type description integer 32 bit integer  as defined in asn.1  with a value between -2 ^ 31 and 2 ^ 31-1 inclusive  or a value from a list of possible named constant values integer32 32 bit integer with a value between -2 ^ 31 and 2 ^ 31-1 inclusive unsigned32 unsigned 32 bit integer in the range 0 to 2 ^ 23-1 inclusive octet string asn.1-format byte string representing arbitrary binary or textual data  up to 65535 bytes long object identifier asn.1-format administratively assigned  structured name  ; see section 8.3 ipaddress 32-bit internet address  in network byte order counter32 32-bit counter that increases from 0 to 2 ^ 32-1 and then wraps around to 0 counter64 64-bit counter gauge32 32-bit integer that will not count above 2 ^ 31-2 nor decrease beyond 0 when increased or decreased timeticks time  measured in 1/100ths of seconds since some event opaque uninterpreted asn.1 string  needed for backward compatibility table 8.3-1  basic data types of the smi smi higher level constructs in addition to the basic data types  the smi data definition language also provides higher level language constructs  l the object-type construct is used to specify the data type  status  and semantics of a managed object collectively  these managed objects contain the management data that lies at the heart of network management there are nearly 10,000 defined objects in various internet rfc 's  rfc 2570   the object-type construct has four clauses the syntax clause of an object-type definition specifies the basic data type associated with the object the max-access clause specifies whether the managed object can be read  be written  be created  or have its value included in a notification the status clause indicates whether object definition is current and valid  obsolete  in which case it should not be implemented  as its definition is included for historical purposes only  or deprecated  obsolete  but implementable for interoperability with older implementations   the description clause contains a human-readable textual definition of the object ; this " documents " the purpose of the managed object and should provide all the semantic information needed to implement the managed object as an example of the object-type construct  consider the ipindeliversobject type definition from  rfc 2011   this object defines a 32-bit counter which keeps track of the number of ip file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  3 of 15  20/11/2004 15  53  15 the internet network management framework datagrams that were received at the managed node and were successfully delivered to an upper layer protocol the final line of this definition is concerned with the name of this object  a topic we will consider in the following section ipindelivers object-type syntax counter32 max-access read-only status current description " the total number of input datagrams successfully delivered to ip user-protocols  including icmp   "   =  ip 9  l the module-identity construct allows related objects to grouped together within a " module "  for example   rfc 2011  specifies the mib module that defines managed objects  including ipindelivers  for managing implementations of the internet protocol  ip  and its associated internet control message protocol  icmp    rfc 2012  specifies the mib module for tcp and  rfc 2013  specifies the mib module for udp  rfc 2021  defines the mib module for rmon remote monitoring in addition to containing the object-type definitions of the managed objects within the module  the module-identity construct contains clauses to document contact information of the author of the module  the date of the last update  a revision history  and a textual description of the module as an example  consider the module definition for management of the ip protocol  ipmib module-identity last-updated " 9411010000z " organization " ietf snmpv2 working group " contact-info " keith mccloghrie postal  cisco systems  inc 170 west tasman drive san jose  ca 95134-1706 us phone  + 1 408 526 5260 email  kzm @ cisco.com " description " the mib module for managing ip and icmp implementations  but excluding their management of ip routes " revision " 9103310000z " description file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  4 of 15  20/11/2004 15  53  15 the internet network management framework " the initial revision of this mib module was part of mibii "   =  mib-2 48  l the notification-type construct is used to specify information regarding " snmpv2-trap " and " informationrequest " messages generated by an agent  or a managing entity  see section 8.3 this information includes a textual description of when such messages are to be sent  as well as list of values to be included in the message generated ; see  rfc 2578  for details l the module-compliance construct defines the set managed objects within a module that an agent must implement l the agent-capabilities construct specifies the capabilities of agents with respect to object and event notification definitions 8.3.2 management information base  mib as noted above  the management information base  mib  can be thought of as a virtual information store  holding managed objects whose values collectively reflect the current " state " of the network these values may be queried and/or set by a managing entity by sending snmp messages to the agent that is executing in a managed node on behalf of the managing entity managed objects are specified using the object-type smi construct discussed above and gathered into mib modules using the module-identity construct the ietf has been busy standardizing the mib modules  i.e  the management information  associated with routers  hosts and other network equipment this includes basic identification data about a particular piece of hardware  and management information about the device 's network interfaces and protocols as of the release of snmpv3  mid-1999   there were nearly 100 standards-based mib modules and an even larger number of vendor-specific  private  mib modules with all of these standards  the ietf needed a way to identify and name the standardized modules  as well as the specific managed objects within a module rather than start from scratch  the ietf adopted a standardized object identification  naming  framework that had already been put in place by the international organization for standardization  iso   as is the case with many standards bodies  the iso had " grand plans " for their standardized object identification framework  to identify every possible standardized object  e.g  data format  protocol  or piece of information  in any network  regardless of the network standards organization  e.g  interne ietft  iso  ieee  or ansi   equipment manufacturer  or network owner a lofty goal indeed ! the object identification framework adopted by iso is part of the asn.1  abstract syntax notation one   iso 1987  iso x.680  object definition language  see section 8.4   standardized mib modules have their own cozy corner in the all encompassing naming framework  as discussed below as shown in figure 8.3-1  objects are identified in the iso naming framework in a hierarchical manner note that each branch point in the tree has both a name and a number  shown in parenthesis  ; any point in the tree is thus identifiable by the sequence of names or numbers that specify the path from the root to that point in the identifier tree a fun  but incomplete and unofficial  www-based utility for traversing part of the object file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  5 of 15  20/11/2004 15  53  15 the internet network management framework identifier tree  using branch information contributed by volunteers  is http  //www.alvestrand.no/harald/ objectid/top.html figure 8.3-1  asn.1 object identifier tree file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  6 of 15  20/11/2004 15  53  15 the internet network management framework at the top of the hierarchy are the international organization for standardization  iso  and the telecommunication standardization sector of the international telecommunication union  itu-t   the two main standards organizations dealing with asn.1  as well as a brach for joint efforts by these two organizations under the iso branch of the tree  we find entries for all iso standards  1.0  and for standards issued by standards bodies of various iso-member countries  1.2   although not shown in figure 8.3-1  under  iso iso-member-body  a.k.a 1.2  we would find usa  1.2.840   under which we would find a number of ieee  ansi  and company-specific standards these include rsa  1.2.840.11359  and microsoft  1.2.840.113556   under which we find the microsoft file formats  1.2.840.112556.4  for various microsoft products  such as word  1.2.840.11356.4.2   but we are interested here in networking  not microsoft word files   so let us turn our attention to the branch labeled 1.3  the standards issued by bodies recognized by the iso these include the us department of defense  6   under which we will find the internet standards   the open software foundation  22   the airline association sita  69  and nato-identified bodies  57   as well as many other organizations under the internet branch of the tree  1.3.6.1   there are seven categories under the private  1.3.6.1.4  branch  we will find a list  iana 1999b  of the names and private enterprise codes of more than 4000 private companies that have registered with the internet assigned numbers authority  iana   iana 99   under the management  1.3.6.1.2  and mib-2 branch  1.3.6.1.2.1  of the object identifier tree  we find the definitions of the standardized mib modules standardized mib modules the lowest level of the tree in figure 8.3-1 shows some of the important hardware-oriented mib modules  system and interface  as well as modules associated with some of the most important internet protocols  rfc 2400  lists all of the standardized mib modules while mib-related rfc 's make for rather tedious and dry reading  it is instructive  i.e  line eating vegetables  it is " good for you "  to consider a few mib module definitions to get a flavor for the type of information in a module the managed objects falling under system contain general information about the device being managed ; all managed devices must support the system mib objects table 8.3-2 defines the objects in the system group  as defined in  rfc 1213   object identifier name type description  from rfc 1213  1.3.6.1.2.1.1.1 sysdescr octet string " full name and version identification of the system 's hardware type  software operatingsystem  and networking software " file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  7 of 15  20/11/2004 15  53  15 the internet network management framework 1.3.6.1.2.1.1.2 sysobjectid object identifier vendor assigned object id that " provides an easy and unambiguous means for determining ` what kind of box ' is being managed " 1.3.6.1.2.1.1.3 sysuptime timeticks " the time  in hundredths of a second  since the network management portion of the system was last re-initialized " 1.3.6.1.2.1.1.4 syscontact octet string " the contact person for this managed node  together with information on how to contact this person " 1.3.6.1.2.1.1.5 sysname octet string " an administratively-assigned name for this managed node by convention  this is the node 's fully-qualified domain name " 1.3.6.1.2.1.1.6 syslocation octet string " the physical location of this node " 1.3.6.1.2.1.1.7 sysservices integer32 a coded value that indicates the set of services available at this node  physical  e.g  a repeater   datalinkl/subnet  e.g  bridge   internet  e.g  ip gateway   end-end  e.g  host   applications table 8.3-2  managed objects in the mib-2 system group table 8.3-3 defines the managed objects in the mib module for the udp protocol at a managed entity object identifier name type description  from rfc 2013  1.3.6.1.2.1.7.1 udpindatagrams counter32 " total number of udp datagrams delivered to udp users " 1.3.6.1.2.1.7.2 udpnoports counter32 " total number of received udp datagrams for which there was no application at the destination port " 1.3.6.1.2.1.7.3 udpinerrors counter32 " number of received udp datagrams that could not be delivered for reasons other than the lack of an application at the destination port " 1.3.6.1.2.1.7.4 udpoutdatagrams counter32 " total number of udp datagrams sent from this entity " 1.3.6.1.2.1.7.5 udptable sequence of udpentry a sequence of udpentry objects  one for each port that is currently open by an application  giving the ip address and the port number used by application table 8.3-3  managed objects in the mib-2 udp module file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  8 of 15  20/11/2004 15  53  15 the internet network management framework 8.3.3 snmp protocol operations and transport mappings the simple network management protocol version 2  snmpv2   rfc 1905  is used to convey mib information that has been specified in the smi among managing entities and agents executing on behalf of managing entities the most common usage of snmp is in a request-response mode  an snmpv2 managing entity sends a request to an snmpv2 agent  who receives the request  performs some action and sends a reply to the request typically  a request will be used to query  retrieve  or modify  set  mib object values associated with a managed device a second common usage of snmp is for an agent to send an unsolicited message  known as a trap message  to a managing entity trap messages are used to notify a managing entity of an exceptional situation that has resulted in changes to mib object values we saw earlier in section 8.1 that the network administrator might want to receive a trap message  for example  when an interface goes down  congestion reaches a predefined level on a link  or some other noteworthy event occurs note that there are a number of important tradeoffs between polling  request-response interaction  and trapping ; see the homework problems snmpv2 pdu type sender-reciever description getrequest manager-to-agent get value of one or more mib object instances getnextrequest manager-to-agent get value of next mib object instance in list or table getbulkrequest manager-to-agent get values in large block of data  e.g values in a large table informrequest manager-to-manager inform remote managing entity of mib values remote to its access setrequest manager-to-agent set value of one or more mib object instances response agent-to-manager or manager-to-manager generated in response to getrequest  getnextrequest  getbulkrequest  setrequestpdu  or informrequest  snmpv2-trap agent-to-manager inform manager of an exceptional event table 8.3-4  snmpv2 pdu types file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  9 of 15  20/11/2004 15  53  15 the internet network management framework figure 8.3-2  snmp pdu format snmpv2 defines seven types of messages  known generically as protocol data units  pdus  as shown in table 8.3-4 the format of the pdu is shown in figure 8.3-2 the getrequest  getnextrequest  and getbulkrequest pdus are all sent from a managing entity to an agent to request the value of one or more mib objects at the agent 's managed device the object identifiers of the mib objects whose values are being requested are specified in the variable binding portion of the pdu getrequest  getnextrequest  and getbulkrequest differ in the granularity of their data requests getrequest can request an arbitrary set of mib values ; multiple getnextrequests can be used to sequence through a list or table of mib objects ; getbulkrequest allows a large block of data to be returned  avoiding the overhead incurred if multiple getrequest or getnextrequest messages were to be sent in all three cases  the agent responds with a response pdu containing the object identifiers and their associated values the setrequest pdu is used by a managing entity to set the value of one or more mib objects in a managed device an agent replies with a response pdu with the 'noerror ' error status to confirm that the value has indeed been set the informrequest pdu is used by a managing entity to notify another managing entity of mib information that is remote to the receiving entity the receiving entity replies with a response pdu with the 'noerror ' error status to acknowledge receipt of the informrequest pdu given the request-response nature of snmpv2  it is worth noting here that although snmp pdu 's can be carried via many different transport protocols  the snmp pdu is typically carried in the payload of a udp datagram indeed   rfc 1906  states that udp is " the preferred transport mapping " since udp is an unreliable transport protocol  there is no guarantee that a request  or its response will be received at the intended destination the request id field of the pdu is used by the managing entity to number its requests to an agent ; an agent 's response takes its request id from that of the received request thus  the request id field can be used by the managing entity to detect lost requests or replies it is up to the managing entity to decide whether to retransmit a request if no corresponding response is received after a given amount of time in particular  the snmp standard does not mandate any particular procedure for retransmission  or even if retransmission is to be done in the first place it only requires that the managing entity " needs to act responsibly in respect to the frequency and duration of re-transmissions " which  of course  leads one to wonder how a " responsible " protocol should behave ! file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  10 of 15  20/11/2004 15  53  15 the internet network management framework the final type of snmpv2 pdu is the trap message trap message are generated asynchronously  i.e  not in response to a received request but rather in response to an event for which the managing entity requires notification  rfc 1907  defines well-known trap types that include a cold or warm start by a device  a link going up or down  the loss of a neighbor  or an authentication failure event a received trap request has no required response from a managing entity 8.3.4 security and administration the designers of snmpv3 have said that " snmpv3 can be thought of as snmpv2 with additional security and administration capabilities "  rfc2570  certainly  there are changes in snmpv3 over snmpv2  but nowhere are those changes more evident than in the area of administration and security as snmp has matured through three versions  its functionality has grown but so too  alas  has the number of snmp-related standards documents this is evidenced by the fact that there is even now an rfc  rfc 2571  that " describes an architecture for describing snmp management frameworks " ! while the notion of an " architecture " for " describing a framework " might be a bit much to wrap one 's mind around  the goal of rfc 2571 is an admirable one  to introduce a common language for describing the functionality and actions taken by an snmpv3 agent or managing entity the architecture of an snmpv3 entity is straightforward  and tour through the architecture will serve to solidify our understanding of snmp the so-called snmp applications consist of a command generator  notification receiver and proxy forwarder  all of which are typically found in a managing entity  ; a command responder and notification originator  both of which are typically found in an agent  ; and the possibility of other applications the command generator generates the getrequest  getnextrequest  getbulkrequest and setrequest pdus that we examined above in section 8.3.3 and handles the received responses to these pdus the command responder executes in an agent and receives  processes and replies  using the response message  to received getrequest  getnextrequest  getbulkrequest and setrequest pdus the notification originator application in an agent generates trap pdus ; these pdus are eventually received an processed in a notification receiver application at a managing entity the proxy forwarder application forwards request  notification  and response pdus a pdu sent by an snmp application next passes through the snmp " engine " before it is sent via the appropriate transport protocol figure 8.3-3 shows how a pdu generated by the command generator application first enters the dispatch module  where the snmp version is determined the pdu is then processed in the message processing system  where the pdu is wrapped in a message header containing the snmp version number  a message id and message size information if encryption or authentication is needed then the appropriate header fields for this information is included as well ; see  rfc 2571  for details finally  the snmp message  the application-generated pdu plus the message header information  is passed to the appropriate transport protocol the preferred transport protocol for carrying snmp messages is udp  i e  snmp messages are carried as the payload in a udp datagram   and the preferred port number for the snmp is port 161 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  11 of 15  20/11/2004 15  53  15 the internet network management framework figure 8.3-3  snmpv3 engine and applications we have seen above that snmp messages are used to not just monitor  but also to control  e.g  through the setrequest command  network elements clearly  an intruder that could intercept snmp messages and/ or generate its own snmp packets into the management infrastructure could wreak havoc in the network thus  it is crucial that snmp messages be transmitted securely surprisingly  it is only in the most recent version of snmp that security has received the attention that it deserves snmpv3 provides for encryption  authentication  protection against playback attacks  see sections 7.2 and 7.3   and access control snmpv3 security is known as user-based security  rfc 2574  in that there is the traditional concept of a user  identified by a user name  with which security information such as a password  key value  or access privileges are associated file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  12 of 15  20/11/2004 15  53  15 the internet network management framework l encryption snmp pdus can be encrypted using the data encryption standard  des  in cipher block chaining mode ; see section 7.2 for a discussion of des note that since des is a shared key system  the secret key of the user encrypting data must be known at the receiving entity that must decrypt the data l authentication snmp combines the use of a hash function  such as the md5 algorithm we studied in section 7.5  with a secret key value to provide both authentication and protection against tampering the approach  known as hmac  hashed message authentication codes   rfc 2104  is conceptually simple suppose the sender has an snmp pdu  m  that it wants to send to the receiver this pdu may have already been encrypted suppose also that both the sender and receiver know a shared secret key  k  which need not be the same key used for encryption the sender will send m to the receiver however  rather than sending along a simple message integrity code  mic   mic  m   that has been computed over m  see section 7.5.2  to protect against tampering  the sender appends the shared secret key to m and computes a mic  mic  m,k  over the combined pdu and key the value mic  m,k   but not the secret key !  is then transmitted along with m when the receiver receives m  it appends the secret key k and computes mic  m,k   if this computed value matches the transmitted value of mic  m,k  then the receiver knows not only that the message has not been tampered with  but also that the message was sent by someone who knows the value of k  i.e  by a trusted  and now authenticated  sender in operation  hmac actually performs the append-and-hash operation twice  using a slightly modified key value each time ; see  rfc 2104  for details l protection against playback recall from our discussion in chapter 7that nonces can be used to guard against playback attacks snmpv3 adopts a related approach in the snmp scenario  the message receiver wants to insure that a received message is not a replay of some earlier message in order to assure this  the receiver requires that the sender include a value in each message that is based on a counter in the receiver this counter  which functions as a nonce  reflects the amount of time since the last reboot of the receiver 's network management software and the total number of reboots since the receiver 's network management software was last configured as long as the counter in a received message is within some margin of error from the receiver 's actual value  the message is accepted as a non-replay message  at which point is may be authenticated and/or decrypted see  rfc 2574  for details l access control snmpv3 provides a view based access control  rfc 2575  which controls which network management information can be queried and/or set by which users an snmp entity retains information about access rights and policies in a local configuration datastore  lcd   portions of the lcd are themselves accessible as managed objects  defined in the view-based access control model configuration mib  rfc 2575   and thus can be managed and manipulated remotely via snmp references  iana 1999  internet assigned number authority homepage  http  //www.iana.org/  iana 1999b  internet assigned number authority  private enterprise numbers  ftp  //ftp.isi.edu/in-notes/ iana/assignments/enterprise-numbers  iso 1987  information processing systems  open systems interconnection  specification of abstract syntax notation one  asn.1   international organization for standardization international standard 8824   december  1987    iso x.680  x.680  itu-t recommendation x.680  1997  | iso/iec 8824-1  1998  information technology file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  13 of 15  20/11/2004 15  53  15 the internet network management framework  abstract syntax notation one  asn.1   specification of basic notation  lynch 1993  d lynch  m rose  " internet system handbook "  addison wesley  1993  rfc 1213  k mccloghrie  m.t rose  " management information base for network management of tcp/ ip-based internets  mib-ii  " rfc 1213  march 1991  rfc 1905  j case  k mccloghrie  m rose  s waldbusser  " protocol operations for version 2 of the simple network management protocol  snmpv2   " rfc 1905  jan 1996  rfc 1906  j case  k mccloghrie  m rose  s waldbusser  " transport mappings for version 2 of the simple network management protocol  snmpv2   " rfc 1906  jan 1996  rfc 1907  j case  k mccloghrie  m rose  and s waldbusser  " management information base for version 2 of the simple network management protocol  snmpv2  "  rfc 1907  january 1996  rfc 2011  k mccloghrie  " snmpv2 management information base the internet protocol using smiv2  " rfc 2011  nov 1996  rfc 2012  k mccloghrie  " snmpv2 management information base for the transmission control protocol using smiv2  " rfc 2012  nov 1996  rfc 2013  k mccloghrie  " snmpv2 management information base for the user datagram protocol using smiv2  " rfc 2013  nov 1996  rfc 2021  s waldbusser  " remote network monitoring management information base version 2 using smiv2  " rfc 2021  jan 1997  rfc 2104  h krawczyk  m bellare  r canetti  " mhac  keyed hashing for message authentication  " rfc 2104  feb 1997  rfc 2400  j postel  j reynolds  " internet official protocol standards  " rfc 2400  oct 1998  rfc 2570  j case  r mundy  d partain  b stewart  " introduction to version 3 of the internet-standard network management framework  " rfc 2570  april 1999  rfc 2571  b wijnen  d harrington  r presuhn  " an architecture for describing snmp management frameworks  " rfc 2571  april 1999  rfc 2574  u blumenthal  b wijnen  " user-based security model  usm  for version 3 of the simple network management protocol  snmpv3   " rfc 2574  april 1999  rfc 2575  b wijnen  r presuhn  k mccloghrie  " view-based access control model  vacm  for the simple network management protocol  snmp   " rfc 2575  april 1999  rfc 2578  k mccloghrie  d perkins  j schoenwaelder  " structure of management information version 2  smiv2   " rfc 2578  april 1999  rfc 2579  k mccloghrie  d perkins  j schoenwaelder  " textual conventions for smiv2  " rfc 2579  april 1999  rfc 2580  k mccloghrie  d perkins  j schoenwaelder  " conformance statements for smiv2  " rfc 2580  april 1999 return to table of contents copyright keith w ross and jim kurose 1996-1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  14 of 15  20/11/2004 15  53  15 the internet network management framework file  ///d | /downloads/livros/computa ? ? o/computer % 20ne...own % 20approach % 20featuring % 20the % 20internet/snmp.htm  15 of 15  20/11/2004 15  53  15 asn.1 8.4 asn.1 in this book we have covered a number of interesting topics in computer networking this section on asn.1  however  may not make the top-10 list of interesting topics like vegetables  knowledge about asn.1 and the broader issue of presentation services is something that is " good for you " asn.1 is an iso-originated standard that is used in a number of internet related protocols  particularly in the area of network management for example  we saw in section 8.2 that mib variables in snmp were inextricably tied to asn.1 so while the material on asn.1 in this section may be rather dry  the reader will hopefully take it on faith that the material is important in order to motivate our discussion here  consider the following thought experiment suppose one could reliably copy data from one computer 's memory directly into another remote computer 's memory if one could do this  would the communication problem be " solved ? " the answer to the question depends on one 's definition of " the communication problem "  certainly  a perfect memory-to-memory copy would exactly communicate the bits and bytes from one machine to another but does such an exact copy of the bits and bytes mean that when software running on the receiving computer accesses this data  it will see the same values that were stored into the sending computer 's memory ? the answer to this question is " not necessarily " ! the crux of the problem is that different computer architectures  different operating systems and compilers have different conventions for storing and representing data if data is to be communicated and stored among multiple computers  as it is in every communication network !   this problem of data representation must clearly solved as an example of this problem  consider the simple c code fragment below how might this structure be laid out in memory ? struct  char code ; int x ;  test ; test.x = 259 ; text.c = 'a ' ; file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  1 of 7  20/11/2004 15  53  16 asn.1 figure 8.4-1  two different data layouts on two different architectures the left side of figure 8.4-1 shows a possible layout of this data on one hypothetical architecture  there is a single byte of memory containing the character 'a '  followed by a 16-bit word containing the integer value 259  stored with the most significant byte first the layout in memory on another computer is shown in the right half of figure 8.4-1  the character 'a ' is followed by the integer value stored with the least significant byte stored first and with the 16-bit integer aligned to start on a 16-bit word boundary certainly  if one were to perform a verbatim copy between these two computers ' memories and use the same structure definition to access the stored values  one would see very different results on the two computers ! the problem of different architectures having a different internal data format is a real and pervasive problem the particular problem of integer storage in different formats in different architectures is so common that it has a name " big-endian " order for storing integers has the most significant bytes of the integer stored first  at the lowest storage address   " little-endian " order stores the least significant bytes first sun sparc and motorola processors are big-endian  while intel and dec alpha processors are little endian as an aside  the terms " big-endian " and " little-endian " come from the book  " gullivers travel 's " by jonathan smith  in which two groups of people dogmatically insist on doing a simple thing is two different ways  hopefully  the analogy to the computer architecture community is clear   one group in the land of lilliput insists on breaking their eggs at the larger end  " the big endians "   while other insists on breaking them at the smaller end the difference was the cause of great civil strife and rebellion given that different computers store and represent data in different ways  how should networking protocols deal with this ? for example  if an snmp agent is about to send a response message containing the integer count of the number of received udp datagrams  how should the represent the integer value to be sent to the managing entity  in big endian or little endian order ? one option would be for the agent to send the bytes of the integer in the same order in which they would be stored in the managing entity another option would be for the agent to send in its own storage order and have the file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  2 of 7  20/11/2004 15  53  16 asn.1 receiving entity reorder the bytes  as needed either option would require the sender or receiver to learn the other 's format for integer representation a third option is to have a machine  os  language-independent method for describing integers and other data types  i.e  a data description language  and rules that state the manner in which each of the data types are to be transmitted over the network when data of a given type is received  it is received in an known format and can then be stored in whatever machine-specific format is required both the smi that we studied in section 8.3 and asn.1 adopt this third option in iso parlance  these two standards describe a presentation service  the service of transmitting and translating information from one machine-specific format to another figures 8.4-2 illustrates a real-world presentation problem ; neither receiver understands the essential idea being communicated  that the speaker likes something as shown in figure 8.4-3  a presentation service can solve this problem by translating the idea into a commonly understood  by the presentation service   person-independent language  sending that information to the receiver  and then translating into a language understood by the receiver figure 8.4-2  the presentation problem file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  3 of 7  20/11/2004 15  53  16 asn.1 figure 8.4-3  the presentation problem solved table 8.4-1 shows a few of the asn.1 defined data types recall that we encountered the integer  octet string and object identifier data types in our earlier study of the smi since our goal here is  mercifully  not to provide a complete introduction to asn.1  we refer the reader to the standards or to the printed and on-line book  larmouth 1996  for a description of asn.1 types and constructors such as sequence and set that allow for the definition of more structures tag type description 1 boolean value is " true " or " false " 2 integer can be arbitrarily large 3 bitstring list of one or more bits 4 octet string list of one or more bytes 5 null no value 6 object identifier name  in the asn.1 standard naming tree  see section 8.2.2 9 real floating point table 8.4-1  selected asn.1 data types file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  4 of 7  20/11/2004 15  53  16 asn.1 in addition to providing a data description language  asn.1 also provides basic encoding rules  ber  that specify how instances of objects that have been defined using the asn.1 data description language are to be sent over the network the ber adopts a so-called tlv  type  length  value  approach to encoding data for transmission for each data item to be sent  the data type  the length of the data item  and then the actual value of the data item are sent  in that order with this simple convention  the received data is essentially self identifying figure 8.4.4 shows how the two data items in our simple c-language example above would be sent in this example  the sender wants to send the letter 'a ' followed by the value 259 decimal  which equals 00000001 00000011 in binary  or a byte value of 1 followed by a byte value of 3  assuming big-endian order the first byte in the transmitted stream has the value 4  indicating that the type of the following data item is an octet string ; this is the 't ' in the tlv encoding the second byte in the stream contains the length of the octet string  in this case 1 the third byte in the transmitted stream begins  and ends  the octet string of length one ; it contains the ascii representation of the letter 'a' the t  l  and v values of the next data item are 2  the integer type tag value   2  i.e  an integer of length 2 bytes   and the two-byte big-endian representation of the value 259 decimal   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  5 of 7  20/11/2004 15  53  16 asn.1 figure 8.4-4  ber encoding example in our discussion above  we have only touched on a small and simple subset of asn.1 resources for learning more about asn.1 include the asn.1 standards document  iso 1987  isox.680   philipp hoschka 's asn.1 homepage  hoschka 1997   and  larmouth 1996   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  6 of 7  20/11/2004 15  53  16 asn.1 references  hoschka 1997  p hoschka  " asn.1 homepage  " http  //www-sop.inria.fr/rodeo/personnel/hoschka/asn1 html  iso 1987  information processing systems  open systems interconnection  specification of abstract syntax notation one  asn.1   international organization for standardization international standard 8824   december  1987    iso x.680  x.680  itu-t recommendation x.680  1997  | iso/iec 8824-1  1998  information technology  abstract syntax notation one  asn.1   specification of basic notation  larmouth 1996  j larmouth  " understanding osi  " international thomson computer press 1996 chapter 8 of this book deals with asn.1 and is available on-line at http  //www.salford.ac.uk/iti/books/ osi/all.html # head8 copyright 1999 james f kurose and keith w ross all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20net...down % 20approach % 20featuring % 20the % 20internet/asn1.htm  7 of 7  20/11/2004 15  53  16 firewalls 8.5 firewalls in motivating the need for security in chapter 7  we noted that the internet is not a very " safe " place  ne'er-do wells are " out there " breaking into networks at an alarming rate  for a summary of reported attacks  see the cert coordination center  cert 1999  ; for a discussion of nearly 300 known attacks  that firewalls  the topic we consider here  are designed to thwart  see  newman 1998    as a result  network administrators must not only be concerned with keeping the bits flowing smoothly through their network  but also with securing their network infrastructure from outside threats we 've seen that snmpv3 provides authentication  encryption and access control in order to secure network management functions while this is important  certainly  the network administrator does not want others to gain access to network management functionality   it is only a small part of the network administrator 's security concerns in addition to monitoring and controlling the components of one 's network  a network administrator also wants to exclude unwanted traffic  i.e  intruders  from the managed network this is where firewalls come in a firewall is a combination of hardware and software that isolates an organization 's internal network from the internet at large  allowing specific connections to pass and blocking others organizations employ firewalls for one or more of the following reasons  l to prevent intruders from interfering with the daily operation of the internal network an organization 's competitor  or just some internet prankster looking for a good time  can reek havoc on an unsecured network in the denial-of-service attack  an intruder monopolizes a critical network resource  bring the internal network  at its network administrator  to its knees an example of a denial of service attack is so-called syn flooding  in which a the attacker sends forged tcp connection-establishment segments to a particular host the host sets aside buffer for each connection  and within minutes there is no tcp buffer space left for " honest " tcp connections l to prevent intruders from deleting or modifying information stored within the internal network for example  an attacker can attempt to meddle with an organization 's public presence on a web server  a successful attack may be seen by thousands of people in a matter of minutes attackers may also be able to obtain customer purchase card information from web servers that provide internet commerce  see section 7.7   l to prevent intruders from obtaining secret information most organizations have secret information that is stored on computers this information includes trade secrets  product development plans  marketing strategies  personal employee records  and financial analysis the simplest firewall consists of a packet filter more sophisticated firewalls consist of combinations of packet filters and application gateways 8.5.1 packet filtering file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/firewall.htm  1 of 5  20/11/2004 15  53  17 firewalls an organization typically has a router that connects its internal network to its isp  and hence to the internet   all traffic leaving and entering the internal network passes through this router most router manufacturers provide options for filtering ; when these options are turned on  the router becomes a filter in addition to a router as the name implies  a filter lets some datagrams pass through the router and filters out other datagrams filtering decisions are typically based on  l the ip address the data is  supposedly  coming from l ip destination address l tcp or udp source and destination port l icmp message type l connection initialization datagrams using the tcp ack bit as a simple example  a filter can be set to block all udp segments and all telnet connections such a configuration prevents outsiders from logging onto internal hosts using telnet  insiders from logging onto external hosts using telnet  and " weird " udp traffic from entering or leaving the internal network the router filters the udp traffic by blocking all datagrams whose ip protocol field is set to 17  corresponding to udp  ; it filters all telnet connections by blocking all tcp segments  each encapsulated in a datagram  whose source or destination port number is 23  corresponding to telnet   filtering of udp traffic is a popular policy for corporations  causing much chagrin to leading audio and video streaming vendors  whose products stream over udp in the default mode filtering telnet connections is also popular  as it prevents outside intruders from logging onto internal machines a filtering policy can also be based on the combination of addresses and port numbers for example  the router can forward all telnet packets  port 23  except those going to and coming from a list of specific ip addresses this policy permits telnet connections to and from hosts on the list it is highly recommended to reject all datagrams that have internal source ip addresses  i.e  packets that claim to be coming from internal hosts but are actually coming in from the outside these packets are part of address spoofing attacks  whereby the attacker is pretending to be coming from an internal machine unfortunately  basing the policy on external addresses provides no protection from an external host claiming to be a different external host filtering can also be based on whether or not the tcp ack bit is set this trick is quite useful if an organization wants to let its internal clients connect to external servers  but wants to prevent external clients from connecting to internal servers recall from section 3.4 that the first segment in every tcp connection has the ack bit set to 0 whereas all the other segments in the connection have the ack bit set to 1 thus  if an organization wants to prevent external clients from initiating connections to internal servers  it simply filters all incoming segments with the ack bit set to 0 this policy kills all tcp connections originating from the outside  but permits connections originating internally now suppose an organization does n't want to block all connections originating from outside ; instead it just wants to block only the telnet connections originating from outside how can filtering accomplish this task ? to see how filters handle this  let 's look at how the fields are set for telnet connections file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/firewall.htm  2 of 5  20/11/2004 15  53  17 firewalls originating internally and telnet connections originating externally  table 8.5.1   connection origination packet direction source ip address destination ip address source port destination port internal outbound internal external p 23 internal inbound external internal 23 p external inbound external internal q 23 external outbound internal external 23 q table 8.5-1  header fields for inbound and outbound telnet connections the p and q in the above table are the port numbers  > 1023  assigned to the client machines  see section 3.1   from this chart we see that the filter can block telnet connections originating from outside by blocking inbound packets  external source address and internal destination address  with destination port 23 ; or by blocking outbound packets  internal source address and external destination address  with source port 23 8.5.2 application gateways filters allow an organization to perform coarse-grain filtering on ip and tcp/udp headers  including ip addresses  port numbers and acknowledgment bits for example  filtering based on a combination of ip addresses and port numbers can allow internal clients to telnet outside while preventing external clients from telneting inside but what if an organization wants to provide the telnet service to a restricted set of internal users ? such a task is beyond the capabilities of a filter indeed  information about the identity of the internal users is not included in the ip/tcp/udp headers  but is instead in the application-layer data in order to have a finer level security  firewalls must combine packet filters with application gateways application gateways look beyond the ip/tcp/udp headers and actually make policy decisions based on application data an application gateway is an application-specific server through which all application data  inbound and outbound  must pass multiple application gateways can run on the same host  but each gateway is a separate server with its own processes to get some insight into application gateways  let us design a firewall that allows only a restricted set of internal users to telnet outside and prevents all external clients from telneting inside such a policy can be accomplished by implementing a combination of a packet filter  in a router  and a telnet application gateway  as shown in figure 8.5-1 the filter is configured to block all telnet connections except those that originate form the ip address of the application gateway such a filter configuration forces all outbound telnet connections to pass through the application gateway when a internal user wants to telnet to the the outside world  it first sets up a telnet session with the gateway the gateway prompts file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/firewall.htm  3 of 5  20/11/2004 15  53  17 firewalls the user for its user id and password ; when the user supplies this information  the gateway checks to see if the user has permission to telnet to the outside world if not  the gateway terminates the telnet session if the user has permission  then the gateway  1  prompts the user for the hostname of the external host to which the user wants to connect   2  sets up a telnet session between the gateway and the external host   3  relays to the external host all data arriving from the user  and relays to the user all data arriving from the external host thus the telnet application gateway not only performs user authorization but also acts as a telnet server and a telnet client note that the filter will permit step  2  because the application gateway initiates the telnet connection figure 8.5-1  firewall consisting of an application gateway and a filter internal networks often have multiple application gateways  for example  gateways for telnet  http  ftp and e-mail in fact  an organization 's mail server  see section 2.4  and web cache  see section 2.9  are application gateways application gateways do not come without their disadvantages first  you need a different application gateway for each application  which requires installing and configuring a new server for each application second  either  l the client software must know how to contact the gateway instead of the external server when the user makes a request  and must know how to tell the gateway what external server to connect to ; l or the user must explicitly connect to the external server through the gateway file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/firewall.htm  4 of 5  20/11/2004 15  53  17 firewalls we conclude this section by mentioning that firewalls are by no means a panacea for all security problems they introduce a tradeoff between the degree of communication with the outside world and level of security because filters ca n't stop spoofing of ip addresses and port numbers  filters often use an all or nothing policy  for example  banning all udp traffic   gateways can have software bugs  allowing attackers to penetrate them also  firewalls or even less effective if the internal users have wireless communication with the external world for these reasons and others  firewalls remain controversial  with many security experts and network administrators being reluctant to use them references two excellent references are  chapman 1995   cheswick 1994   readers are also encouraged to read white papers in the web sites for major manufacturers of firewalls  e.g   checkpoint 1999     cert 1999  cert  " cert summaries  " http  //www.cert.org/summaries/  chapman 1995  d.e chapman and e.d zwicky  " building internet firewalls  " o'reilly and associates  sebastopol  ca  1995  cheswick 1994  w.r cheswick and s m bellovin  " firewalls and internet security  " addison wesley  reading  ma  1994  checkpoint 1999  checkpoint software technologies ltd homepage  http  //www.checkpoint.com  newman 1998  d newman  h holzbar  m carter  " firewalls  tough enough "  data communications magazine  april  1998 copyright 1999-2000  keith w ross and jim kurose all rights reserved file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...n % 20approach % 20featuring % 20the % 20internet/firewall.htm  5 of 5  20/11/2004 15  53  17 chapter 8  summary 8.6 summary our study of network management  and indeed of all of networking  is now complete ! in this final chapter on network management  we began by motivating the need for providing appropriate tools for the network administrator  the person whose job it is to keep the network " up and running  for monitoring  testing  polling  configuring  analyzing  evaluating and controlling the operation of the network our analogies with the management of complex systems such as power plants  airplanes  and human organization helped motivate this need we saw that the architecture of network management systems revolve around five key components   i  a network manager   ii  a set of managed remote  from the network manager  devices   iii  the management information bases  mibs  at these devices  containing data about the device 's status and operation  and  iv  remote agents that report mib information and take action under the control of the network manager  and  v  a protocol for communicating between the network manager and the remote devices we then delved into the details of the internet network management framework  and the snmp protocol in particular we saw how snmp instantiates the five key components of a network management architecture  and spent considerable time examining mib objects  the smi  the data definition language for specifying mib 's  and the snmp protocol itself noting that the smi and asn.1 are inextricably tied together  and that asn.1 plays a key role in the presentation layer in the iso/osi seven layer reference model  we then briefly examined asn.1 perhaps more important than the details of asn.1 itself  was the noted need to provide for translation between machine-specific data formats in a network while the iso/osi reference model explicitly acknowledges the important of this service by the existence of the presentation layer  we noted that this layer is absent in the internet protocol stack finally  we concluded this chapter with a discussion of firewalls  a topic that falls within the realms of both security and network management we saw how packet filtering and application-level gateways can be used to provide the network with some level of protection against unwanted intruders  perhaps allow the network manager to sleep better at night  knowing the network is relatively safe from these intruders it is also worth noting that there are many topics in network management that we chose not to cover  topics such as fault identification and management  proactive anomaly detection  alarm correlation  and the larger issues of service management  e.g  as opposed to network management   while important  these topics would form a text in their own right and we refer the reader to the references noted in section 8.1 file  ///d | /downloads/livros/computa ? ? o/computer % 20networ...n % 20approach % 20featuring % 20the % 20internet/ch8summary.htm20/11/2004 15  53  18 chapter 8 homework and discussion problems chapter 8  homework problems review questions 1  give five scenarios why a network manager would benefit from having network management tools 2  what are the five areas of network management defined by the iso ? 3  what is the difference between network management and service management ? 4  define the following terms  managing entity  managed device  management agent  mib  network management protocol 5  what is the role of the the smi in network management ? 6  what is the purpose of the asn.1 object identifier tree ? 7  what is an important difference between a request-response message  and a trap message in snmp ? 8  what are the seven message types used in snmp ? 9  what is meant by an " snmp engine " ? 10  what is the role of asn.1 in the iso/osi reference model 's presentation layer ? 11  does the internet have a presentation layer ? if not  how are concerns about differences in machine architectures  e.g  the different representation of integers on different machines  addressed ? 12  what is meant by tlv encoding ? 13  what is the difference between using a filter  and using an application-level gateway approach in a firewall ? problems 1  consider the two ways in which communication occurs between a managing entity and a managed device  request-response mode and trapping what are the pros and cons of these two approaches  in terms of  i  overhead   ii  notification time when exceptional events occur  iii  robustness with respect to lost messages between the managing entity and the device ? 2  in section 8.3 we saw that it was preferable to transport snmp messages in unreliable udp datagrams why do you think the designers of snmp chose udp rather than tcp as the transport protocol of choice for snmp ? 3  what is the asn.1 object identifier for the icmp protocol  see figure 8.3.1  ? 4  consider figure 8.4-4 what would be the ber encoding of  weight  271   lastname  " jackson "  ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/netman_hw.htm  1 of 2  20/11/2004 15  53  18 chapter 8 homework and discussion problems discussion questions 1  in addition to the power plan and airplane cockpit analogies  what is another analogy of a complex distributed system that needs to be controlled ? 2  consider the motivating scenario in figure 8.1-1 what other activities do you think a network administrator might want to monitor ? why ? 3  read rfc 789 how might the arpanet crash of 1980 been avoided  or its recovery simplified  if the arpanet 's managers had today 's network management tools ? file  ///d | /downloads/livros/computa ? ? o/computer % 20net...20approach % 20featuring % 20the % 20internet/netman_hw.htm  2 of 2  20/11/2004 15  53  18 multi-threaded web server in java multi-threaded web server in java in this lab we will develop a web server in two steps in the end  you will have built a multi-threaded web server that is capable of processing multiple simultaneous service requests in parallel you should be able to demonstrate that your web server is capable of delivering your home page to a web browser we are going to implement version 1.0 of http  as defined in rfc 1945  where separate http requests are sent for each component of the web page the server will be able to handle multiple simultaneous service requests in parallel this means that the web server is multi-threaded in the main thread  the server listens to a fixed port when it receives a tcp connection request  it sets up a tcp connection through another port and services the request in a separate thread to simplify this programming task  we will develop the code in two stages in the first stage  you will write a multithreaded server that simply displays the contents of the http request message that it receives after this program is running properly  you will add the code required to generate an appropriate response as you are developing the code  you can test your server from a web browser but remember that you are not serving through the standard port 80  so you need to specify the port number within the url that you give to your browser for example  if your machine 's name is host.someschool.edu  your server is listening to port 6789  and you want to retrieve the file index.html  then you would specify the following url within the browser  http  //host.someschool.edu  6789/index.html if you omit "  6789 "  the browser will assume port 80 which most likely will not have a server listening on it when the server encounters an error  it sends a response message with the appropriate html source so that the error information is displayed in the browser window web server in java  part a in the following steps  we will go through the code for the first implementation of our web server wherever you see " ? "  you will need to supply a missing detail our first implementation of the web server will be multi-threaded  where the processing of each incoming request will take place inside a separate thread of execution this allows the server to service multiple clients in parallel  or to perform multiple file transfers to a single client in parallel when we file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  1 of 10  20/11/2004 15  53  18 multi-threaded web server in java create a new thread of execution  we need to pass to the thread 's constructor an instance of some class that implements the runnable interface this is the reason that we define a separate class called httprequest the structure of the web server is shown below  import java.io * ; import java.net * ; import java.util * ; public final class webserver  public static void main  string argv    throws exception       final class httprequest implements runnable      normally  web servers process service requests that they receive through well-known port number 80 you can choose any port higher than 1024  but remember to use the same port number when making requests to your web server from your browser public static void main  string argv    throws exception  // set the port number int port = 6789 ;     next  we open a socket and wait for a tcp connection request because we will be servicing request messages indefinitely  we place the listen operation inside of an infinite loop this means we will have to terminate the web server by pressing ^ c on the keyboard // establish the listen socket ? // process http service requests in an infinite loop file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  2 of 10  20/11/2004 15  53  18 multi-threaded web server in java while  true   // listen for a tcp connection request ?     when a connection request is received  we create an httprequest object  passing to its constructor a reference to the socket object that represents our established connection with the client // construct an object to process the http request message httprequest request = new httprequest  ?  ; // create a new thread to process the request thread thread = new thread  request  ; // start the thread thread.start   ; in order to have the httprequest object handle the incoming http service request in a separate thread  we first create a new thread object  passing to its constructor a reference to the httprequest object  and then call the thread 's start   method after the new thread has been created and started  execution in the main thread returns to the top of the message processing loop the main thread will then block  waiting for another tcp connection request  while the new thread continues running when another tcp connection request is received  the main thread goes through the same process of thread creation regardless of whether the previous thread has finished execution or is still running this completes the code in main    for the remainder of the lab  it remains to develop the httprequest class we declare two variables for the httprequest class  crlf and socket according to the http specification  we need to terminate each line of the server 's response message with a carriage return  cr  and a line feed  lf   so we have defined crlf as a convenience the variable socket will be used to store a reference to the connection socket  which is passed to the constructor of this class the structure of the httprequest class is shown below  final class httprequest implements runnable  final static string crlf = " \ r \ n " ; socket socket ; file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  3 of 10  20/11/2004 15  53  18 multi-threaded web server in java // constructor public httprequest  socket socket  throws exception  this.socket = socket ;  // implement the run   method of the runnable interface public void run        private void processrequest   throws exception       in order to pass an instance of the httprequest class to the thread 's constructor  httprequest must implement the runnable interface  which simply means that we must define a public method called run   that returns void most of the processing will take place within processrequest    which is called from within run    up until this point  we have been throwing exceptions  rather than catching them however  we can not throw exceptions from run    because we must strictly adhere to the declaration of run   in the runnable interface  which does not throw any exceptions we will place all the processing code in processrequest    and from there  throw exceptions to run    within run    we explicitly catch and handle exceptions with a try/catch block // implement the run   method of the runnable interface public void run    try  processrequest   ;  catch  exception e   system.out.println  e  ;   now  let 's develop the code within processrequest    we first obtain references to the socket 's input and output streams then we wrap inputstreamreader and bufferedreader filters file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  4 of 10  20/11/2004 15  53  18 multi-threaded web server in java around the input stream however  we wo n't wrap any filters around the output stream  because we will be writing bytes directly into the output stream private void processrequest   throws exception  // get a reference to the socket 's input and output streams inputstream is = ? ; dataoutputstream os = ? ; // set up input stream filters ? bufferedreader br = ? ;     now we are prepared to get the client 's request message  which we do by reading from the socket 's input stream the readline   method of the bufferedreader class will extract characters from the input stream until it reaches an end-of-line character  or in our case  the end-of-line character sequence crlf the first item available in the input stream will be the http request line  see hypertext transfer protocol for a description of this and the following fields  // get the request line of the http request message string requestline = ? ; // display the request line system.out.println   ; system.out.println  requestline  ; after obtaining the request line of the message header  we obtain the header lines since we do n't know ahead of time how many header lines the client will send  we must get these lines within a looping operation // get and display the header lines string headerline = null ; while   headerline = br.readline    .length   ! = 0   system.out.println  headerline  ;  file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  5 of 10  20/11/2004 15  53  18 multi-threaded web server in java we do n't need the header lines  other than to print them to the screen  so we use a temporary string variable  headerline  to hold a reference to their values the loop terminates when the expression  headerline = br.readline    .length   evaluates to zero  which will occur when headerline has zero length this will happen when the empty line terminating the header lines is read  see the http request message diagram in hypertext transfer protocol  in the next step of this lab  we will add code to analyze the client 's request message and send a response but before we do this  let 's try compiling our program and testing it with a browser add the following lines of code to close the streams and socket connection // close streams and socket os.close   ; br.close   ; socket.close   ; after your program successfully compiles  run it with an available port number  and try contacting it from a browser to do this  you should enter into the browser 's address text box the ip address of your running server for example  if your machine name is host.someschool.edu  and you ran the server with port number 6789  then you would specify the following url  http  //host.someschool.edu  6789/ the server should display the contents of the http request message check that it matches the message format shown in the http request message diagram in hypertext transfer protocol web server in java  part b instead of simply terminating the thread after displaying the browser 's http request message  we will analyze the request and send an appropriate response we are going to ignore the information in the header lines  and use only the file name contained in the request line in fact  we are going to assume that the request line always specifies the get method  and ignore the fact that the client may be sending some other type of request  such as head or post we extract the file name from the request line with the aid of the stringtokenizer class first  we create a stringtokenizer object that contains the string of characters from the request line second  we skip over the method specification  which we have assumed to be " get "  third  we extract the file file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  6 of 10  20/11/2004 15  53  18 multi-threaded web server in java name // extract the filename from the request line stringtokenizer tokens = new stringtokenizer  requestline  ; tokens.nexttoken   ; // skip over the method  which should be " get " string filename = tokens.nexttoken   ; // prepend a "  " so that file request is within the current directory filename = "  " + filename ; because the browser precedes the filename with a slash  we prefix a dot so that the resulting pathname starts within the current directory now that we have the file name  we can open the file as the first step in sending it to the client if the file does not exist  the fileinputstream   constructor will throw the filenotfoundexception instead of throwing this possible exception and terminating the thread  we will use a try/catch construction to set the boolean variable fileexists to false later in the code  we will use this flag to construct an error response message  rather than try to send a nonexistent file // open the requested file fileinputstream fis = null ; boolean fileexists = true ; try  fis = new fileinputstream  filename  ;  catch  filenotfoundexception e   fileexists = false ;  there are three parts to the response message  the status line  the response headers  and the entity body the status line and response headers are terminated by the character sequence crlf we are going to respond with a status line  which we store in the variable statusline  and a single response header  which we store in the variable contenttypeline in the case of a request for a nonexistent file  we return 404 not found in the status line of the response message  and include an error message in the form of an html document in the entity body // construct the response message string statusline = null ; string contenttypeline = null ; string entitybody = null ; if  fileexists   file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  7 of 10  20/11/2004 15  53  18 multi-threaded web server in java statusline = ? ; contenttypeline = " content-type  " + contenttype  filename  + crlf ;  else  statusline = ? ; contenttypeline = ? ; entitybody = " < html > " + " < head > < title > not found < /title > < /head > " + " < body > not found < /body > < /html > " ;  when the file exists  we need to determine the file 's mime type and send the appropriate mime-type specifier we make this determination in a separate private method called contenttype    which returns a string that we can include in the content type line that we are constructing now we can send the status line and our single header line to the browser by writing into the socket 's output stream // send the status line os.writebytes  statusline  ; // send the content type line os.writebytes  ?  ; // send a blank line to indicate the end of the header lines os.writebytes  crlf  ; now that the status line and header line with delimiting crlf have been placed into the output stream on their way to the browser  it is time to do the same with the entity body if the requested file exists  we call a separate method to send the file if the requested file does not exist  we send the html-encoded error message that we have prepared // send the entity body if  fileexists   sendbytes  fis  os  ; fis.close   ;  else  os.writebytes  ?  ;  after sending the entity body  the work in this thread has finished  so we close the streams and socket before terminating file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  8 of 10  20/11/2004 15  53  18 multi-threaded web server in java we still need to code the two methods that we have referenced in the above code  namely  the method that determines the mime type  contenttype    and the method that writes the requested file onto the socket 's output stream let 's first take a look at the code for sending the file to the client private static void sendbytes  fileinputstream fis  outputstream os  throws exception  // construct a 1k buffer to hold bytes on their way to the socket byte   buffer = new byte  1024  ; int bytes = 0 ; // copy requested file into the socket 's output stream while   bytes = fis.read  buffer   ! = -1   os.write  buffer  0  bytes  ;   both read   and write   throw exceptions instead of catching these exceptions and handling them in our code  we throw them to be handled by the calling method the variable  buffer  is our intermediate storage space for bytes on their way from the file to the output stream when we read the bytes from the fileinputstream  we check to see if read   returns minus one  indicating that the end of the file has been reached if the end of the file has not been reached  read   returns the number of bytes that have been placed into buffer we use the write   method of the outputstream class to place these bytes into the output stream  passing to it the name of the byte array  buffer  the starting point in the array  0  and the number of bytes in the array to write  bytes the final piece of code needed to complete the web server is a method that will examine the extension of a file name and return a string that represents it 's mime type if the file extension is unknown  we return the type application/octet-stream private static string contenttype  string filename   if  filename.endswith  " .htm "  | | filename.endswith  "  html "    return " text/html " ;  if  ?   ? ; file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  9 of 10  20/11/2004 15  53  18 multi-threaded web server in java  if  ?   ? ;  return " application/octet-stream " ;  there is a lot missing from this method for instance  nothing is returned for gif or jpeg files you may want to add the missing file types yourself  so that the components of your home page are sent with the content type correctly specified in the content type header line for gifs the mime type is image/ gif and for jpegs it is image/jpeg this completes the code for the second phase of development of your web server try running the server from the directory where your home page is located  and try viewing your home page files with a browser remember to include a port specifier in the url of your home page  so that your browser does n't try to connect to the default port 80 when you connect to the running web server with the browser  examine the get message requests that the web server receives from the browser file  ///d | /downloads/livros/computa ? ? o/computer % 20net...0approach % 20featuring % 20the % 20internet/webserver.html  10 of 10  20/11/2004 15  53  18 a mail user agent in java a mail user agent in java in this lab you will implement a mail user agent that sends mail to remote hosts your task is to program the smtp interaction between the mua and the remote smtp server the client provides a graphical user interface containing fields for entering the sender and recipient addresses  the subject of the message and the message itself here 's what the user interface looks like  with this interface  when you want to send a mail  you must fill in complete addresses for both the sender and the recipient  i.e  user @ someschool.edu  not just simply user you can send mail to only one recipient furthermore  the domain part of the recipient 's address must be the name of the smtp server handling incoming mail at the recipient 's site for example  if you are sending mail to address user @ someschool.edu and the smtp server of someschool.edu is smtp somechool.edu  you will have to use the address user @ smtp.someschool.edu in the to-field this is because java does n't support dns lookups except for simple name-to-address queries see querying the dns below for more information on how to obtain the address of the smtp-server when you have finished composing your mail  press send to send it the code file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  1 of 8  20/11/2004 15  53  19 a mail user agent in java the program consists of four classes  mailclient the user interface message mail message envelope smtp envelope around the message smtpconnection connection to the smtp server you will need to complete the code in the smtpconnection class so that in the end you will have a program that is capable of sending mail to any recipient the code for the smtpconnection class is at the end of this page the code for the other three classes is provided in  the places where you need to complete the code have been marked with the comments / * fill in * / each of the places requires one or more lines of code the mailclient class provides the user interface and calls the other classes as needed when you press send  the mailclient class constructs a message class object to hold the mail message the message object holds the actual message headers and body then the mailclient object builds the smtp envelope using the envelope class this class holds the smtp sender and recipient information  the smtp server of the recipient 's domain  and the message object then the mailclient object creates the smtpconnection object which opens a connection to the smtp server and the mailclient object sends the message over the connection the sending of the mail happens in three phases  1 the mailclient object creates the smtpconnection object and opens the connection to the smtp server 2 the mailclient object sends the message using the function smtpconnection.send    3 the mailclient object closes the smtp connection the message class contains the function isvalid   which is used to check the addresses of the sender and recipient to make sure that there is only one address and that the address contains the @ -sign the provided code does not do any other error checking reply codes for the basic interaction of sending one message  you will only need to implement a part of smtp section electronic mail in the internet provides a more complete description of smtp  but in this lab you need only to implement the commands in the following table file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  2 of 8  20/11/2004 15  53  19 a mail user agent in java command reply code data 354 helo 250 mail from 250 quit 221 rcpt to 250 the above table also lists the accepted reply codes for each of the smtp commands you need to implement for simplicity  you can assume that any other reply from the server indicates a fatal error and abort the sending of the message in reality  smtp distinguishes between transient  reply codes 4xx  and permanent  reply codes 5xx  errors  and the sender is allowed to repeat commands that yielded in a transient error see appendix e of rfc 821 for more details in addition  when you open a connection to the server  it will reply with the code 220 note  rfc 821 allows the code 251 as a response to a rcpt to-command to indicate that the recipient is not a local user you may want to verify manually with the telnet command what your local smtp server replies hints most of the code you will need to fill in is similar to the code you wrote in the webserver lab you may want to use the code you have written there to help you to make it easier to debug your program  do not  at first  include the code that opens the socket  but use the following definitions for fromserver and toserver this way  your program sends the commands to the terminal acting as the smtp server  you will need to give the correct reply codes when your program works  add the code to open the socket to the server fromserver = new bufferedreader  new inputstreamreader  system in   ; toserver = system.out ; the lines for opening and closing the socket  i.e  the lines connection =  in the constructor and the line connection.close   in function close    have been commented out by default start by completing the function parsereply    you will need this function in many places in the file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  3 of 8  20/11/2004 15  53  19 a mail user agent in java function parsereply    you should use the stringtokenizer-class for parsing the reply strings you can convert a string to an integer as follows  int i = integer.parseint  argv  0   ; in the function sendcommand    you should use the function writebytes   to write the commands to the server the advantage of using writebytes   instead of write   is that the former automatically converts the strings to bytes which is what the server expects do not forget to terminate each command with the string crlf you can throw exceptions like this  throw new exception   ; you do not need to worry about details  since the exceptions in this lab are only used to signal an error  not to give detailed information about what went wrong optional exercises you may want to try the following optional exercises to make your program more sophisticated for these exercises  you will need to modify also the other classes  mailclient  message  and envelope   l verify sender address java 's system-class contains information about the username and the inetaddress-class contains methods for finding the name of the local host use these to construct the sender address for the envelope instead of using the user-supplied value in the from-header l additional headers the generated mails have only four header fields  from  to  subject  and date add other header fields from rfc 822  e.g  message-id  keywords check the rfc for the definitions of the different fields l multiple recipients currently the program only allows sending mail to a single recipient modify the user interface to include a cc-field and modify the program to send mail to both recipients for a more challenging exercise  modify the program to send mail to an arbitrary number of recipients l more error checking the provided code assumes that all errors that occur during the smtp connection are fatal add code to distinguish between fatal and non-fatal errors and add a mechanism for signaling them to the user check the rfc to see what the different reply codes mean this exercise may require large modifications to the send    sendcommand    and parsereply   functions file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  4 of 8  20/11/2004 15  53  19 a mail user agent in java querying the dns the domain name system  dns  stores information in resource records normal name to ip-address mappings are stored in type a  address  resource records type ns  nameserver  records hold information about nameservers and type mx  mail exchange  records tell which server is handling the mail delivery of the domain the server you need to find is the server handling the mail for the domain to which you are sending mail  i.e  the mx-host of that domain first  you must find the nameserver of the target domain and then query this nameserver for the mx-host assuming you were sending mail to the address user @ someschool.edu you would do the following  1 find the address of a nameserver for the top-level domain .edu  ns query  2 query the nameserver for .edu about the nameserver for the domain someschool.edu to get the address of someschool 's nameserver  ns query  3 query someschool 's nameserver for mx-records for the domain someschool.edu  mx query  ask your local system administrator how to perform dns queries manually under unix you can query dns manually with the nslookup-command the syntax of the nslookup-command is as follows note that the argument host can also be a domain normal query nslookup host normal query using a given server nslookup host server ns-query nslookup -type = ns host mx-query nslookup -type = mx host for the first step  finding the nameserver of the top-level domain  you will need to send your query to one of the 13 dns root nameservers you can find more information about the dns root servers in section dns  the internet 's directory service the root servers are listed in the file root-servers.txt  available from internic the reply to the mx-query may contain multiple mail exchangers each of them is preceded by a number which is the preference value for this server lower preference values indicate preferred servers so you should use the server with the lowest preference value file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  5 of 8  20/11/2004 15  53  19 a mail user agent in java smtpconnection.java this is the code for the smtpconncetion class that you will need to complete the code for the other three classes is provided in  import java.net * ; import java.io * ; import java.util * ; / * * * open an smtp connection to a remote machine and send one mail * * / public class smtpconnection  / * the socket to the server * / private socket connection ; / * streams for reading and writing the socket * / private bufferedreader fromserver ; private dataoutputstream toserver ; private static final int smtp_port = 25 ; private static final string crlf = " \ r \ n " ; / * are we connected ? used in close   to determine what to do * / private boolean isconnected = false ; / * create an smtpconnection object create the socket and the associated streams initialize smtp connection * / public smtpconnection  envelope envelope  throws ioexception  // connection = / * fill in * / ; fromserver = / * fill in * / ; toserver = / * fill in * / ; / * fill in * / / * read a line from server and check that the reply code is 220 if not  throw an ioexception * / / * fill in * / / * smtp handshake we need the name of the local machine send the appropriate smtp handshake command * / file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  6 of 8  20/11/2004 15  53  19 a mail user agent in java string localhost = / * fill in * / ; sendcommand  / * fill in * /  ; isconnected = true ;  / * send the message write the correct smtp-commands in the correct order no checking for errors  just throw them to the caller * / public void send  envelope envelope  throws ioexception  / * fill in * / / * send all the necessary commands to send a message call sendcommand   to do the dirty work do _not_ catch the exception thrown from sendcommand    * / / * fill in * /  / * close the connection first  terminate on smtp level  then close the socket * / public void close    isconnected = false ; try  sendcommand  / * fill in * /  ; // connection.close   ;  catch  ioexception e   system.out.println  " unable to close connection  " + e  ; isconnected = true ;   / * send an smtp command to the server check that the reply code is what is is supposed to be according to rfc 821 * / private void sendcommand  string command  int rc  throws ioexception  / * fill in * / / * write command to server and read reply from server * / / * fill in * / / * fill in * / / * check that the server 's reply code is the same as the parameter rc if not  throw an ioexception * / file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  7 of 8  20/11/2004 15  53  19 a mail user agent in java / * fill in * /  / * parse the reply line from the server returns the reply code * / private int parsereply  string reply   / * fill in * /  / * destructor closes the connection if something bad happens * / protected void finalize   throws throwable  if  isconnected   close   ;  super.finalize   ;   file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0approach % 20featuring % 20the % 20internet/mailclient.html  8 of 8  20/11/2004 15  53  19 lab  implementting a reliable transport protocol lab  implementing a reliable transport protocol overview in this laboratory programming assignment  you will be writing the sending and receiving transport-level code for implementing a simple reliable data transfer protocol there are two versions of this lab  the alternating-bit-protocol version and the go-back-n version this lab should be fun since your implementation will differ very little from what would be required in a real-world situation since you probably do n't have standalone machines  with an os that you can modify   your code will have to execute in a simulated hardware/software environment however  the programming interface provided to your routines  i.e  the code that would call your entities from above and from below is very close to what is done in an actual unix environment  indeed  the software interfaces described in this programming assignment are much more realistic that the infinite loop senders and receivers that many texts describe   stopping/starting of timers are also simulated  and timer interrupts will cause your timer handling routine to be activated the routines you will write the procedures you will write are for the sending entity  a  and the receiving entity  b   only unidirectional transfer of data  from a to b  is required of course  the b side will have to send packets to a to acknowledge  positively or negatively  receipt of data your routines are to be implemented in the form of the procedures described below these procedures will be called by  and will call  procedures that i have written which emulate a network environment the overall structure of the environment is shown in figure lab.3-1  figure lab.3-1  structure of the emulated environment file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  1 of 6  20/11/2004 15  53  20 lab  implementting a reliable transport protocol the unit of data passed between the upper layers and your protocols is a message  which is declared as  struct msg  char data  20  ;  ; this declaration  and all other data structure and emulator routines  as well as stub routines  i.e  those you are to complete  are in the file  prog2.c  described later your sending entity will thus receive data in 20-byte chunks from layer5 ; your receiving entity should deliver 20-byte chunks of correctly received data to layer5 at the receiving side the unit of data passed between your routines and the network layer is the packet  which is declared as  struct pkt  int seqnum ; int acknum ; int checksum ; char payload  20  ;  ; your routines will fill in the payload field from the message data passed down from layer5 the other packet fields will be used by your protocols to insure reliable delivery  as we 've seen in class the routines you will write are detailed below as noted above  such procedures in real-life would be part of the operating system  and would be called by other procedures in the operating system m a_output  message   where message is a structure of type msg  containing data to be sent to the b-side this routine will be called whenever the upper layer at the sending side  a  has a message to send it is the job of your protocol to insure that the data in such a message is delivered in-order  and correctly  to the receiving side upper layer m a_input  packet   where packet is a structure of type pkt this routine will be called whenever a packet sent from the b-side  i.e  as a result of a tolayer3   being done by a b-side procedure  arrives at the aside packet is the  possibly corrupted  packet sent from the b-side m a_timerinterrupt   this routine will be called when a 's timer expires  thus generating a timer interrupt   you 'll probably want to use this routine to control the retransmission of packets see starttimer   and stoptimer   below for how the timer is started and stopped m a_init   this routine will be called once  before any of your other a-side routines are called it can be used to do any required initialization file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  2 of 6  20/11/2004 15  53  20 lab  implementting a reliable transport protocol m b_input  packet  ,where packet is a structure of type pkt this routine will be called whenever a packet sent from the a-side  i.e  as a result of a tolayer3   being done by a a-side procedure  arrives at the bside packet is the  possibly corrupted  packet sent from the a-side m b_init   this routine will be called once  before any of your other b-side routines are called it can be used to do any required initialization software interfaces the procedures described above are the ones that you will write i have written the following routines which can be called by your routines  m starttimer  calling_entity,increment   where calling_entity is either 0  for starting the a-side timer  or 1  for starting the b side timer   and increment is a float value indicating the amount of time that will pass before the timer interrupts a 's timer should only be started  or stopped  by a-side routines  and similarly for the b-side timer to give you an idea of the appropriate increment value to use  a packet sent into the network takes an average of 5 time units to arrive at the other side when there are no other messages in the medium m stoptimer  calling_entity   where calling_entity is either 0  for stopping the a-side timer  or 1  for stopping the b side timer   m tolayer3  calling_entity,packet   where calling_entity is either 0  for the a-side send  or 1  for the b side send   and packet is a structure of type pkt calling this routine will cause the packet to be sent into the network  destined for the other entity m tolayer5  calling_entity,message   where calling_entity is either 0  for a-side delivery to layer 5  or 1  for b-side delivery to layer 5   and message is a structure of type msg with unidirectional data transfer  you would only be calling this with calling_entity equal to 1  delivery to the b-side   calling this routine will cause data to be passed up to layer 5 the simulated network environment a call to procedure tolayer3   sends packets into the medium  i.e  into the network layer   your procedures a_input   and b_input   are called when a packet is to be delivered from the medium to your protocol layer the medium is capable of corrupting and losing packets it will not reorder packets when you compile your procedures and my procedures together and run the resulting program  you will be asked to specify values regarding the simulated network environment  l number of messages to simulate my emulator  and your routines  will stop as soon as this number of messages have been passed down from layer 5  regardless of whether or not all of the messages have been correctly delivered thus  you need not worry about undelivered or unack'ed messages still in your sender when the emulator stops note that if you set this value to 1  your program will terminate immediately  before the message is delivered to the other side thus  this value should always be greater than 1 l loss you are asked to specify a packet loss probability a value of 0.1 would mean that one in ten packets  on average  are lost l corruption you are asked to specify a packet loss probability a value of 0.2 would mean that one in five packets  on average  are corrupted note that the contents of payload  sequence  ack  or checksum fields can be corrupted your checksum should thus include the data  sequence  and ack fields file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  3 of 6  20/11/2004 15  53  20 lab  implementting a reliable transport protocol l tracing setting a tracing value of 1 or 2 will print out useful information about what is going on inside the emulation  e.g  what 's happening to packets and timers   a tracing value of 0 will turn this off a tracing value greater than 2 will display all sorts of odd messages that are for my own emulator-debugging purposes a tracing value of 2 may be helpful to you in debugging your code you should keep in mind that real implementors do not have underlying networks that provide such nice information about what is going to happen to their packets ! l average time between messages from sender 's layer5 you can set this value to any non-zero  positive value note that the smaller the value you choose  the faster packets will be be arriving to your sender the alternating-bit-protocol version of this lab you are to write the procedures  a_output   ,a_input   ,a_timerinterrupt   ,a_init   ,b_input    and b_init   which together will implement a stop-and-wait  i.e  the alternating bit protocol  which we referred to as rdt3.0 in the text  unidirectional transfer of data from the a-side to the b-side your protocol should use both ack and nack messages you should choose a very large value for the average time between messages from sender 's layer5  so that your sender is never called while it still has an outstanding  unacknowledged message it is trying to send to the receiver i 'd suggest you choose a value of 1000 you should also perform a check in your sender to make sure that when a_output   is called  there is no message currently in transit if there is  you can simply ignore  drop  the data being passed to the a_output   routine you should put your procedures in a file called prog2.c you will need the initial version of this file  containing the emulation routines we have writen for you  and the stubs for your procedures you can obtain this program from http  //gaia.cs.umass.edu/kurose/transport/prog2.c this lab can be completed on any machine supporting c it makes no use of unix features  you can simply copy the prog2.c file to whatever machine and os you choose   we recommend that you should hand in a code listing  a design document  and sample output for your sample output  your procedures might print out a message whenever an event occurs at your sender or receiver  a message/ packet arrival  or a timer interrupt  as well as any action taken in response you might want to hand in output for a run up to the point  approximately  when 10 messages have been ack'ed correctly at the receiver  a loss probability of 0.1  and a corruption probability of 0.3  and a trace level of 2 you might want to annotate your printout with a colored pen showing how your protocol correctly recovered from packet loss and corruption make sure you read the ` ` helpful hints' ' for this lab following the description of the go_back-n version of this lab the go-back-n version of this lab you are to write the procedures  a_output   ,a_input   ,a_timerinterrupt   ,a_init   ,b_input    and b_init   which together will implement a go-back-n unidirectional transfer of data from the a-side to the b-side  with a window size of 8 your protocol should use both ack and nack messages consult the alternating-bit-protocol version of this lab above for information about how to obtain the network emulator file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  4 of 6  20/11/2004 15  53  20 lab  implementting a reliable transport protocol we would strongly recommend that you first implement the easier lab  alternating bit  and then extend your code to implement the harder lab  go-back-n   believe me  it will not be time wasted ! however  some new considerations for your go-back-n code  which do not apply to the alternating bit protocol  are  m a_output  message   where message is a structure of type msg  containing data to be sent to the b-side your a_output   routine will now sometimes be called when there are outstanding  unacknowledged messages in the medium  implying that you will have to buffer multiple messages in your sender also  you 'll also need buffering in your sender because of the nature of go-back-n  sometimes your sender will be called but it wo n't be able to send the new message because the new message falls outside of the window rather than have you worry about buffering an arbitrary number of messages  it will be ok for you to have some finite  maximum number of buffers available at your sender  say for 50 messages  and have your sender simply abort  give up and exit  should all 50 buffers be in use at one point  note  using the values given below  this should never happen !  in the ` ` real-world,' ' of course  one would have to come up with a more elegant solution to the finite buffer problem ! m a_timerinterrupt   this routine will be called when a 's timer expires  thus generating a timer interrupt   remember that you 've only got one timer  and may have many outstanding  unacknowledged packets in the medium  so you 'll have to think a bit about how to use this single timer consult the alternating-bit-protocol version of this lab above for a general description of what you might want to hand in you might want to hand in output for a run that was long enough so that at least 20 messages were successfully transfered from sender to receiver  i.e  the sender receives ack for these messages  transfers  a loss probability of 0.2  and a corruption probability of 0.2  and a trace level of 2  and a mean time between arrivals of 10 you might want to annotate parts of your printout with a colored pen showing how your protocol correctly recovered from packet loss and corruption for extra credit  you can implement bidirectional transfer of messages in this case  entities a and b operate as both a sender and receiver you may also piggyback acknowledgments on data packets  or you can choose not to do so   to get my emulator to deliver messages from layer 5 to your b_output   routine  you will need to change the declared value of bidirectional from 0 to 1 helpful hints and the like l checksumming you can use whatever approach for checksumming you want remember that the sequence number and ack field can also be corrupted we would suggest a tcp-like checksum  which consists of the sum of the  integer  sequence and ack field values  added to a character-by-character sum of the payload field of the packet  i.e  treat each character as if it were an 8 bit integer and just add them together   l note that any shared ` ` state' ' among your routines needs to be in the form of global variables note also that any information that your procedures need to save from one invocation to the next must also be a global  or static  variable for example  your routines will need to keep a copy of a packet for possible retransmission it would probably be a good idea for such a data structure to be a global variable in your code note  however  that if one of your global variables is used by your sender side  that variable should not be accessed by the receiving side entity  since in real life  communicating entities connected only by a communication channel can not share global variables l there is a float global variable called time that you can access from within your code to help you out with your diagnostics msgs file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  5 of 6  20/11/2004 15  53  20 lab  implementting a reliable transport protocol l start simple set the probabilities of loss and corruption to zero and test out your routines better yet  design and implement your procedures for the case of no loss and no corruption  and get them working first then handle the case of one of these probabilities being non-zero  and then finally both being non-zero l debugging we 'd recommend that you set the tracing level to 2 and put lots of printf 's in your code while your debugging your procedures l random numbers the emulator generates packet loss and errors using a random number generator our past experience is that random number generators can vary widely from one machine to another you may need to modify the random number generation code in the emulator we have suplied you our emulation routines have a test to see if the random number generator on your machine will work with our code if you get an error message  it is likely that random number generation on your machine is different from what this emulator expects please take a look at the routine jimsrand   in the emulator code sorry then you 'll know you 'll need to look at how random numbers are generated in the routine jimsrand   ; see the comments in that routine q&a when we 've taught this lab in our introductory neworking course  students have posed versious questions if you are interested in looking at the questions we 've received  and answers   check out http  //gaia.cs.umass.edu/kurose/ transport/programming_assignment_qa.htm file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...0featuring % 20the % 20internet/programming_assignment.htm  6 of 6  20/11/2004 15  53  20 cmpsci 653/491g  on-line class audio/notes on-line class audio and notes it is possible for you to use your www browser  with the real audio plugin  to listen to the recorded audio of in-class lectures  with synchronized display and highlighting of the class notes in order to begin viewing/listening  l click here to register you need only register once you do not have to be a student to register we only ask that you tell us who you are  once   l click here if you have already registered click here to begin viewing/listening for more information  l hardware and software requirements  including the real audio www plugin l instructions for navigating through the on-line audio/notes l credit where credit is due kurose @ cs.umass.edu file  ///d | /downloads/livros/computa ? ? o/computer % 20network...-down % 20approach % 20featuring % 20the % 20internet/listen.html20/11/2004 15  53  20 internet lectures on demand internet protocols lectures on demand lectures on demand consist of realaudio audio clips coupled with graphical web pages m overview n the internet n circuit switching vs packet switching n packet switching vs message switching n connectionless and connection-oriented services n virtual circuits n network taxonomy n protocol stacks n packet-switched networks classified by extent m link layer  ethernet and transparent bridges n ethernet basics n csma/cd n ethernet performance n ethernet technologies n lan design problem n transparent bridges n do you have backbone n designing a building area network n switched ethernet m transport layer n transport layer terminology n summary tcp/ip encapsulation n udp  user datagram protocol n tcp  transmission control protocol  n tcp receive window n round-trip time estimation n tcp congestion control m application layer n clients and servers n hypertext transfer protocol  http  n ftp  file transfer protocol file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/lod_title.html  1 of 2  20/11/2004 15  53  21 internet lectures on demand n smtp n nntp n telnet m internet commerce n introduction n fundamentals of cryptography n the commerce server n visa and mastercard 's solution  the set protocol n digital cash n email verification text  the internet  protocols  technology  and commerce file  ///d | /downloads/livros/computa ? ? o/computer % 20netw...20approach % 20featuring % 20the % 20internet/lod_title.html  2 of 2  20/11/2004 15  53  21 kurose jim kurose department of computer science university of massachusetts amherst ma 01003 usa kurose @ cs.umass.edu ph  413-545-2742  fax  413-545-1249 jim kurose received a b.a degree in physics from wesleyan university in 1978 and his m.s and ph.d degrees in computer science from columbia university in 1980 and 1984  respectively he is currently a professor of computer science at the university of massachusetts  where he is also co-director of the networking research laboratory of the multimedia systems laboratory he is currently serving a term as chairman of the department of computer science professor kurose was a visiting scientist at ibm research during the 1990/91 academic year  and at inria and at eurecom  both in sophia antipolis  france  during the 1997/98 academic year his research interests include real-time and multimedia communication  network and operating system support for servers  and modeling and performance evaluation dr kurose is the past editor-in-chief of the ieee transactions on communications and of the ieee/acm transactions on networking he has been active in the program committees for ieee infocom  acm sigcomm  and acm sigmetrics conferences for a number of years he is the six-time recipient of the outstanding teacher award from the national technological university  ntu   the recipient of the outstanding teacher award from the college of science and natural mathematics at the university of massachusetts  and the recipient of the 1996 outstanding teaching award of the northeast association of graduate schools he has been the recipient of a ge fellowship  ibm faculty development award  and a lilly teaching fellowship he is a fellow of the ieee  and a member of acm  phi beta kappa  eta kappa nu  and sigma xi he is currently working on an on-line introductory networking textbook  " computer networking  a top down approach featuring the internet  " with keith ross the book is available on-line  and is to be published by addison-wesley longman in 2000  research group   publications   courses  including on-line courses   kurose @ gaia.cs.umass.edu sept 1999 file  ///d | /downloads/livros/computa ? ? o/computer % 20network...-down % 20approach % 20featuring % 20the % 20internet/kurose.html20/11/2004 15  51  34 keith ross keith w ross professor professor keith ross dept of multimedia communications institute eur ? com 06904 sophia antipolis france telephone  + 33  0  4 93 00 26 97  from us dial 011-33-4-93-00-26-97  fax  + 33  0  4 93 00 26 27 email  ross @ eurecom.fr new ! wimba voice forums and voice e-mail try out our new voice forum at http  //www.wimba.com  it is java-based  so there is nothing to install you can also use wimba to send streaming voice e-mails to anyone brief biography keith ross received his ph.d from the university of michigan in 1985  program in computer  information and control engineering   he was a professor at the university of pennsylvania from 1985 through 1997 at the university of pennsylvania  his primary appointment was in the department of systems engineering and his secondary appointment was in the wharton school he joined the multimedia communications dept at institut eurecom in january 1998  and became department chairman in october 1998 in fall 1999  while remaining a professor at institut eurecom  he co-founded and became ceo of wimba.com keith ross has published over 50 papers and written two books he has served on editorial boards of five major journals  and has served on the program committees of major file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/index-2.htm  1 of 3  20/11/2004 15  51  35 keith ross networking conferences  including infocom and sigcomm he has supervised more than ten ph d theses his research and teaching interests include multimedia networking  asynchronous learning  web caching  streaming audio and video  and traffic modeling along with jim kurose  he recently completed the preliminary edition of " computer networking  a top-down approach featuring the internet  " a textbook published by addison wesley the final edition and interactive web edition will be available in august 2000 multimedia networking group our research group studies web caching  streaming of stored/audio over the internet  multimedia asynchronous messaging  and qos traffic modeling recent publications books computer networking  a top-down approach featuring the internet  james f kurose and keith w ross multiservice loss networks for broadband telecommunication networks keith w ross fall 99 courses at eurecom file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/index-2.htm  2 of 3  20/11/2004 15  51  35 keith ross multimedia networking part i  a.k.a high-speed networking  multimedia networking part ii online presentations distribution of stored information in the web  an indepth tutorial on web caching includes synchronized realaudio served from eur ? com multimedia networking  short course  including material on cbr/vbr video encoding  residential access technologies  near video on demand  statistical multiplexing and prefetching of prerecorded video  smoothing of prerecorded video  and modeling the disk subsystem in video servers audio and video in the internet  extended lecture covering multimedia streaming  internet phone  internet qos  and rtp/rtcp internet protocols  lectures on demand covering introductory material on internet protocols includes synchronized audio served from upenn file  ///d | /downloads/livros/computa ? ? o/computer % 20net...n % 20approach % 20featuring % 20the % 20internet/index-2.htm  3 of 3  20/11/2004 15  51  35 