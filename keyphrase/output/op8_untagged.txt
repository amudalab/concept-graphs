an operating system is a program that manages the computer hardware it also provides a basis for application programs and acts as an intermediary between the computer user and the computer hardware an amazing aspect of operating systems is how varied they are in accomplishing these tasks mainframe operating systems are designed primarily to optimize utilization of hardware personal computer  pc  operating systems support complex games  business applications  and everything in between operating systems for handheld computers are designed to provide an environment in which a user can easily interface with the computer to execute programs thus  some operating systems are designed to be convenient  others to be efficient  and others some combination of the two before we can explore the details of computer system operation  we need to know something about system structure we begin by discussing the basic functions of system startup  i/o  and storage we also describe the basic computer architecture that makes it possible to write a functional operating system because an operating system is large and complex  it must be created piece by piece each of these pieces should be a well-delineated portion of the system  with carefully defined inputs  outputs  and functions in this we provide a general overview of the major components of an operating system objectives to provide a grand tour of the major operating systems components to provide coverage of basic computer system organization 1.1 what operating systems do we begin our discussion by looking at the operating system 's role in the overall computer system a computer system can be divided roughly into four components  the hardware  the operating system  the application programs  and the users  1.1   1.1 abstract view of the components of a computer system the hardware the central processing unit  cpu   the memory  and the input/output  i/o  devices provides the basic computing resources for the system the application programs such as word processors  spreadsheets  compilers  and web browsers define the ways in which these resources are used to solve users ' computing problems the operating system controls and coordinates the use of the hardware among the various application programs for the various users we can also view a computer system as consisting of hardware  software  and data the operating system provides the means for proper use of these resources in the operation of the computer system an operating system is similar to a government like a government  it performs no useful function by itself it simply provides an environment within which other programs can do useful work to understand more fully the operating system 's role  we next explore operating systems from two viewpoints  that of the user and that of the system 1.1.1 user view the user 's view of the computer varies according to the interface being used most computer users sit in front of a pc  consisting of a monitor  keyboard  mouse  and system unit such a system is designed for one user to monopolize its resources the goal is to maximize the work  or play  that the user is performing in this case  the operating system is designed mostly for ease of use  with some attention paid to performance and none paid to resource utilization how various hardware and software resources are shared performance is  of course  important to the user ; but rather than resource utilization  such systems are optimized for the single-user experience 1.1 what operating systems do 5 in other cases  a user sits at a terminal connected to a mainframe or minicomputer other users are accessing the same computer through other terminals these users share resources and may exchange information the operating system in such cases is designed to maximize resource utilization to assure that all available cpu time  memory  and i/o are used efficiently and that no individual user takes more than her fair share in still other cases  users sit at workstations connected to networks of other workstations and servers these users have dedicated resources at their disposal  but they also share resources such as networking and servers file  compute  and print servers therefore  their operating system is designed to compromise between individual usability and resource utilization recently  many varieties of handheld computers have come into fashion most of these devices are standalone units for individual users some are connected to networks  either directly by wire or  more often  through wireless modems and networking because of power  speed  and interface limitations  they perform relatively few remote operations their operating systems are designed mostly for individual usability  but performance per amount of battery life is important as well some computers have little or no user view for example  embedded computers in home devices and automobiles may have numeric keypads and may turn indicator lights on or off to show status  but they and their operating systems are designed primarily to run without user intervention 1.1.2 system view from the computer 's point of view  the operating system is the program most intimately involved with the hardware in this context  we can view an operating system as a resource allocator a computer system has many resources that may be required to solve a problem  cpu time  memory space  file-storage space  i/o devices  and so on the operating system acts as the manager of these resources facing numerous and possibly conflicting requests for resources  the operating system must decide how to allocate them to specific programs and users so that it can operate the computer system efficiently and fairly as we have seen  resource allocation is especially important where many users access the same mainframe or minicomputer a slightly different view of an operating system emphasizes the need to control the various i/o devices and user programs an operating system is a control program a control program manages the execution of user programs to prevent errors and improper use of the computer it is especially concerned with the operation and control of i/o devices 1.1.3 defining operating systems we have looked at the operating system 's role from the views of the user and of the system how  though  can we define what an operating system is in general  we have no completely adequate definition of an operating system operating systems exist because they offer a reasonable way to solve the problem of creating a usable computing system the fundamental goal of computer systems is to execute user programs and to make solving user problems easier toward this goal  computer hardware is constructed since bare hardware alone is not particularly easy to use  application programs are developed these programs require certain common operations  such as those controlling the i/o devices the common functions of controlling and allocating resources are then brought together into one piece of software  the operating system in addition  we have no universally accepted definition of what is part of the operating system a simple viewpoint is that it includes everything a vendor ships when you order " the operating system " the features included  however  vary greatly across systems some systems take up less than 1 megabyte of space and lack even a full-screen editor  whereas others require gigabytes of space and are entirely based on graphical windowing systems  a kilobyte  or kb  is 1,024 bytes ; a megabyte  or mb  is l,0242 bytes ; and a gigabyte  or gb  is l,0243 bytes computer manufacturers often round off these numbers and say that a megabyte is 1 million bytes and a gigabyte is 1 billion bytes  a more common definition is that the operating system is the one program running at all times on the computer  usually called the kernel   with all else being systems programs and application programs this last definition is the one that we generally follow the matter of what constitutes an operating system has become increasingly important in 1998  the united states department of justice filed suit against microsoft  in essence claiming that microsoft included too much functionality in its operating systems and thus prevented application vendors from competing for example  a web browser was an integral part of the operating system as a result  microsoft was found guilty of using its operating system monopoly to limit competition 1.2 computer-system organization before we can explore the details of how computer systems operate  we need a general knowledge of the structure of a computer system in this section  we look at several parts of this structure to round out our background knowledge the section is mostly concerned with computer-system organization  so you can skim or skip it if you already understand the concepts 1.2.1 computer-system operation a modern general-purpose computer system consists of one or more cpus and a number of device controllers connected through a common bus that provides access to shared memory  1.2   each device controller is in charge of a specific type of device  for example  disk drives  audio devices  and video displays   the cpu and the device controllers can execute concurrently  competing for memory cycles to ensure orderly access to the shared memory  a memory controller is provided whose function is to synchronize access to the memory for a computer to start running for instance  when it is powered up or rebooted it needs to have an initial program to run this initial program  or bootstrap program  tends to be simple typically  it is stored in read-only memory  rom  or electrically erasable programmable read-only memory  eeprom   known by the general term firmware  within the computer hardware it initializes all aspects of the system  from cpu registers to device 1.2 computer-system organization 7 controllers to memory contents the bootstrap program must know how to load the operating system and to start executing that system to accomplish this goal  the bootstrap program must locate and load into memory the operatingsystem kernel the operating system then starts executing the first process  such as " init  " and waits for some event to occur the occurrence of an event is usually signaled by an interrupt from either the hardware or the software hardware may trigger an interrupt at any time by sending a signal to the cpu  usually by way of the system bus software may trigger an interrupt by executing a special operation called a system call  also called a monitor call   when the cpu is interrupted  it stops what it is doing and immediately transfers execution to a fixed location the fixed location usually contains the starting address where the service routine for the interrupt is located the interrupt service routine executes ; on completion  the cpu resumes the interrupted computation a time line of this operation is shown in 1.3 interrupts are an important part of a computer architecture each computer design has its own interrupt mechanism  but several functions are common the interrupt must transfer control to the appropriate interrupt service routine the straightforward method for handling this transfer would be to invoke a generic routine to examine the interrupt information ; the routine  in turn  would call the interrupt-specific handler however  interrupts must be handled quickly since only a predefined number of interrupts is possible  a table of pointers to interrupt routines can be used instead to provide the necessary speed the interrupt routine is called indirectly through the table  with no intermediate routine needed generally  the table of pointers is stored in low memory  the first 100 or so locations   these locations hold the addresses of the interrupt service routines for the various devices this array  or interrupt vector  of addresses is then indexed by a unique device number  given with the interrupt request  to provide the address of the interrupt service routine for the interrupting device operating systems as different as windows and unix dispatch interrupts in this manner the interrupt architecture must also save the address of the interrupted instruction many old designs simply stored the interrupt address in a fixed location or in a location indexed by the device number more recent architectures store the return address on the system stack if the interrupt routine needs to modify the processor state for instance  by modifying register values it must explicitly save the current state and then restore that state before returning after the interrupt is serviced  the saved return address is loaded into the program counter  and the interrupted computation resumes as though the interrupt had not occurred 1.2.2 storage structure computer programs must be in main memory  also called random-access memory or ram  to be executed main memory is the only large storage area  millions to billions of bytes  that the processor can access directly it commonly is implemented in a semiconductor technology called dynamic random-access memory  dram   which forms an array of memory words each word has its own address interaction is achieved through a sequence of load or store instructions to specific memory addresses the load instruction moves a word from main memory to an internal register within the cpu  whereas the store instruction moves the content of a register to main memory aside from explicit loads and stores  the cpu automatically loads instructions from main memory for execution a typical instruction-execution cycle  as executed on a system with a von neumann architecture  first fetches an instruction from memory and stores that instruction in the instruction register the instruction is then decoded and may cause operands to be fetched from memory and stored in some internal register after the instruction on the operands has been executed  the result may be stored back in memory notice that the memory unit sees only a stream of memory addresses ; it does not know how they are generated  by the instruction counter  indexing  indirection  literal addresses  or some other means  or what they are for  instructions or data   accordingly  we can ignore hoio a memory address is generated by a program we are interested only in the sequence of memory addresses generated by the running program ideally  we want the programs and data to reside in main memory permanently this arrangement usually is not possible for the following two reasons  1.2 computer-system organization 9 1 main memory is usually too small to store all needed programs and data permanently 2 main memory is a volatile storage device that loses its contents when power is turned off or otherwise lost thus  most computer systems provide secondary storage as an extension of main memory the main requirement for secondary storage is that it be able to hold large quantities of data permanently the most common secondary-storage device is a magnetic disk  which provides storage for both programs and data most programs  web browsers  compilers  word processors  spreadsheets  and so on  are stored on a disk until they are loaded into memory many programs then use the disk as both a source and a destination of the information for their processing hence  the proper management of disk storage is of central importance to a computer system  as we discuss in 12 in a larger sense  however  the storage structure that we have described consisting of registers  main memory  and magnetic disks is only one of many possible storage systems others include cache memory  cd-rom  magnetic tapes  and so on each storage system provides the basic functions of storing a datum and of holding that datum until it is retrieved at a later time the main differences among the various storage systems lie in speed  cost  size  and volatility the wide variety of storage systems in a computer system can be organized in a hierarchy  1.4  according to speed and cost the higher levels are expensive  but they are fast as we move down the hierarchy  the cost per bit leqislorr  cache  generally decreases  whereas the access time generally increases this trade-off is reasonable ; if a given storage system were both faster and less expensive than another other properties being the same then there would be no reason to use the slower  more expensive memory in fact  many early storage devices  including paper tape and core memories  are relegated to museums now that magnetic tape and semiconductor memory have become faster and cheaper the top four levels of memory in 1.4 may be constructed using semiconductor memory in addition to differing in speed and cost  the various storage systems are either volatile or nonvolatile as mentioned earlier  volatile storage loses its contents when the power to the device is removed in the absence of expensive battery and generator backup systems  data must be written to nonvolatile storage for safekeeping in the hierarchy shown in 1.4  the storage systems above the electronic disk are volatile  whereas those below are nonvolatile an electronic disk can be designed to be either volatile or nonvolatile during normal operation  the electronic disk stores data in a large dram array  which is volatile but many electronic-disk devices contain a hidden magnetic hard disk and a battery for backup power if external power is interrupted  the electronic-disk controller copies the data from ram to the magnetic disk when external power is restored  the controller copies the data back into the ram another form of electronic disk is flash memory  which is popular in cameras and personal digital assistants  pdas   in robots  and increasingly as removable storage on general-purpose computers flash memory is slower than dram but needs no power to retain its contents another form of nonvolatile storage is nvram  which is dram with battery backup power this memory can be as fast as dram but has a limited duration in which it is nonvolatile the design of a complete memory system must balance all the factors just discussed  it must use only as much expensive memory as necessary while providing as much inexpensive  nonvolatile memory as possible caches can be installed to improve performance where a large access-time or transfer-rate disparity exists between two components 1.2.3 i/o structure storage is only one of many types of i/o devices within a computer a large portion of operating system code is dedicated to managing i/o  both because of its importance to the reliability and performance of a system and because of the varying nature of the devices therefore  we now provide an overview of i/o a general-purpose computer system consists of cpus and multiple device controllers that are connected through a common bus each device controller is in charge of a specific type of device depending on the controller  there may be more than one attached device for instance  seven or more devices can be attached to the small computer-systems interface  scsi  controller a device controller maintains some local buffer storage and a set of special-purpose registers the device controller is responsible for moving the data between the peripheral devices that it controls and its local buffer storage typically  operating systems have a device driver for each device controller this device 1.2 computer-system organization 11 thread of execution cpu  * n  < 3 5 1c a instruction execution cycle data movement dma instructions and data memory 1.5 how a modern computer system works driver understands the device controller and presents a uniform interface to the device to the rest of the operating system to start an i/o operation  the device driver loads the appropriate registers within the device controller the device controller  in turn  examines the contents of these registers to determine what action to take  such as " read a character from the keyboard "   the controller starts the transfer of data from the device to its local buffer once the transfer of data is complete  the device controller informs the device driver via an interrupt that it has finished its operation the device driver then returns control to the operating system  possibly returning the data or a pointer to the data if the operation was a read for other operations  the device driver returns status information this form of interrupt-driven i/o is fine for moving small amounts of data but can produce high overhead when used for bulk data movement such as disk i/o to solve this problem  direct memory access  dma  is used after setting up buffers  pointers  and counters for the i/o device  the device controller transfers an entire block of data directly to or from its own buffer storage to memory  with no intervention by the cpu only one interrupt is generated per block  to tell the device driver that the operation has completed  rather than the one interrupt per byte generated for low-speed devices while the device controller is performing these operations  the cpu is available to accomplish other work some high-end systems use switch rather than bus architecture on these systems  multiple components can talk to other components concurrently  rather than competing for cycles on a shared bus in this case  dma is even more effective 1.5 shows the interplay of all components of a computer system 12 1 1.3 computer-system architecture in section 1.2 we introduced the general structure of a typical computer system a computer system may be organized in a number of different ways  which we can categorize roughly according to the number of general-purpose processors used 1.3.1 single-processor systems most systems vise a single processor the variety of single-processor systems may be surprising  however  since these systems range from pdas through mainframes on a single-processor system  there is one main cpu capable of executing a general-purpose instruction set  including instructions from user processes almost all systems have other special-purpose processors as well they may come in the form of device-specific processors  such as disk  keyboard  and graphics controllers ; or  on mainframes  they may come in the form of more general-purpose processors  such as i/o processors that move data rapidly among the components of the system all of these special-purpose processors run a limited instruction set and do not run user processes sometimes they are managed by the operating system  in that the operating system sends them information about their next task and monitors their status for example  a disk-controller microprocessor receives a sequence of requests from the main cpu and implements its own disk queue and scheduling algorithm this arrangement relieves the main cpu of the overhead of disk scheduling pcs contain a microprocessor in the keyboard to convert the keystrokes into codes to be sent to the cpu in other systems or circumstances  special-purpose processors are low-level components built into the hardware the operating system can not communicate with these processors ; they do their jobs autonomously the use of special-purpose microprocessors is common and does not turn a single-processor system into a multiprocessor if there is only one general-purpose cpu  then the system is a single-processor system 1.3.2 multiprocessor systems although single-processor systems are most common  multiprocessor systems  also known as parallel systems or tightly coupled systems  are growing in importance such systems have two or more processors in close communication  sharing the computer bus and sometimes the clock  memory  and peripheral devices multiprocessor systems have three main advantages  1 increased throughput by increasing the number of processors  we expect to get more work done in less time the speed-up ratio with n processors is not n  however ; rather  it is less than n when multiple processors cooperate on a task  a certain amount of overhead is incurred in keeping all the parts working correctly this overhead  plus contention for shared resources  lowers the expected gain from additional processors similarly  n programmers working closely together do not produce n times the amount of work a single programmer would produce 1.3 computer-system architecture 13 2 economy of scale multiprocessor systems can cost less than equivalent multiple single-processor systems  because they can share peripherals  mass storage  and power supplies if several programs operate on the same set of data  it is cheaper to store those data on one disk and to have all the processors share them than to have many computers with local disks and many copies of the data 3 increased reliability if functions can be distributed properly among several processors  then the failure of one processor will not halt the system  only slow it down if we have ten processors and one fails  then each of the remaining nine processors can pick up a share of the work of the failed processor thus  the entire system runs only 10 percent slower  rather than failing altogether increased reliability of a computer system is crucial in many applications the ability to continue providing service proportional to the level of surviving hardware is called graceful degradation some systems go beyond graceful degradation and are called fault tolerant  because they can suffer a failure of any single component and still continue operation note that fault tolerance requires a mechanism to allow the failure to be detected  diagnosed  and  if possible  corrected the hp nonstop system  formerly tandem  system uses both hardware and software duplication to ensure continued operation despite faults the system consists of multiple pairs of cpus  working in lockstep both processors in the pair execute each instruction and compare the results if the results differ  then one cpu of the pair is at fault  and both are halted the process that was being executed is then moved to another pair of cpus  and the instruction that failed is restarted this solution is expensive  since it involves special hardware and considerable hardware duplication the multiple-processor systems in use today are of two types some systems use asymmetric multiprocessing  in which each processor is assigned a specific task a master processor controls the system ; the other processors either look to the master for instruction or have predefined tasks this scheme defines a master-slave relationship the master processor schedules and allocates work to the slave processors the most common systems use symmetric multiprocessing  smp   in which each processor performs all tasks within the operating system smp means that all processors are peers ; no master-slave relationship exists between processors 1.6 illustrates a typical smp architecture an example of the smp system is solaris  a commercial version of unix designed by sun microsystems a solaris system can be con d to employ dozens of processors  all running solaris the benefit of this model is that many processes gpu gpu cpu memory 1.6 symmetric multiprocessing architecture 14 1 can run simultaneously n processes can run if there are n cpus without causing a significant deterioration of performance however  we must carefully control i/o to ensure that the data reach the appropriate processor also  since the cpus are separate  one may be sitting idle while another is overloaded  resulting in inefficiencies these inefficiencies can be avoided if the processors share certain data structures a multiprocessor system of this form will allow processes and resources such as memory to be shared dynamically among the various processors and can lower the variance among the processors such a system must be written carefully  as we shall see in 6 virtually all modern operating systems including windows  windows xp  mac os x  and linux now provide support for smp the difference between symmetric and asymmetric multiprocessing may result from either hardware or software special hardware can differentiate the multiple processors  or the software can be written to allow only one master and multiple slaves for instance  sun 's operating system sunos version 4 provided asymmetric multiprocessing  whereas version 5  solaris  is symmetric on the same hardware a recent trend in cpu design is to include multiple compute cores on a single chip in essence  these are multiprocessor chips two-way chips are becoming mainstream  while n-way chips are going to be common in high-end systems aside from architectural considerations such as cache  memory  and bus contention  these multi-core cpus look to the operating system just as n standard processors lastly  blade servers are a recent development in which multiple processor boards  i/o boards  and networking boards are placed in the same chassis the difference between these and traditional multiprocessor systems is that each blade-processor board boots independently and runs its own operating system some blade-server boards are multiprocessor as well  which blurs the lines between types of computers in essence  those servers consist of multiple independent multiprocessor systems 1.3.3 clustered systems another type of multiple-cpu system is the clustered system like multiprocessor systems  clustered systems gather together multiple cpus to accomplish computational work clustered systems differ from multiprocessor systems  however  in that they are composed of two or more individual systems coupled together the definition of the term clustered is not concrete ; many commercial packages wrestle with what a clustered system is and why one form is better than another the generally accepted definition is that clustered computers share storage and are closely linked via a local-area network  lan   as described in section 1.10  or a faster interconnect such as infiniband clustering is usually used to provide high-availability service ; that is  service will continue even if one or more systems in the cluster fail high availability is generally obtained by adding a level of redundancy in the system a layer of cluster software runs on the cluster nodes each node can monitor one or more of the others  over the lan   if the monitored machine fails  the monitoring machine can take ownership of its storage and restart the applications that were running on the failed machine the users and clients of the applications see only a brief interruption of service 1.4 operating-system structure 15 clustering can be structured asymmetrically or symmetrically in asymmetric clustering  one machine is in hot-standby mode while the other is running the applications the hot-standby host machine does nothing but monitor the active server if that server fails  the hot-standby host becomes the active server in symmetric mode  two or more hosts are running applications  and are monitoring each other this mode is obviously more efficient  as it uses all of the available hardware it does require that more than one application be available to run other forms of clusters include parallel clusters and clustering over a wide-area network  wan   as described in section 1.10   parallel clusters allow multiple hosts to access the same data on the shared storage because most operating systems lack support for simultaneous data access by multiple hosts  parallel clusters are usually accomplished by use of special versions of software and special releases of applications for example  oracle parallel server is a version of oracle 's database that has been designed to run on a parallel cluster each machine runs oracle  and a layer of software tracks access to the shared disk each machine has full access to all data in the database to provide this shared access to data  the system must also supply access control and locking to ensure that no conflicting operations occur this function  commonly known as a distributed lock manager  dlm   is included in some cluster technology cluster technology is changing rapidly some cluster products support dozens of systems in a cluster  as well as clustered nodes that are separated by miles many of these improvements are made possible by storage-area networks  sans   as described in section 12.3.3  which allow many systems to attach to a pool of storage if the applications and their data are stored on the san  then the cluster software can assign the application to run on any host that is attached to the san if the host fails  then any other host can take over in a database cluster  dozens of hosts can share the same database  greatlyincreasing performance and reliability 1.4 operating-system structure now that we have discussed basic information about computer-system organization and architecture  we are ready to talk about operating systems an operating system provides the environment within which programs are executed internally  operating systems vary greatly in their makeup  since they are organized along many different lines there are  however  many commonalities  which we consider in this section one of the most important aspects of operating systems is the ability to multiprogram a single user can not  in general  keep either the cpu or the i/o devices busy at all times multiprogramming increases cpu utilization by organizing jobs  code and data  so that the cpu always has one to execute the idea is as follows  the operating system keeps several jobs in memory simultaneously  1.7   this set of jobs can be a subset of the jobs kept in the job pool which contains all jobs that enter the system since the number of jobs that can be kept simultaneously in memory is usually smaller than the number of jobs that can be kept in the job pool the operating system picks and begins to execute one of the jobs in memory eventually  the job may have to wait for some task  such as an i/o operation  to complete in a 16 1 512m operating job system 1 job 2 job job 3 4 1.7 memory layout for a multiprogramming system non-multiprogrammed system  the cpu would sit idle in a multiprogrammed system  the operating system simply switches to  and executes  another job when that job needs to wait  the cpu is switched to another job  and so on eventually  the first job finishes waiting and gets the cpu back as long as at least one job needs to execute  the cpu is never idle this idea is common in other life situations a lawyer does not work for only one client at a time  for example while one case is waiting to go to trial or have papers typed  the lawyer can work on another case if he has enough clients  the lawyer will never be idle for lack of work  idle lawyers tend to become politicians  so there is a certain social value in keeping lawyers busy  multiprogrammed systems provide an environment in which the various system resources  for example  cpu  memory  and peripheral devices  are utilized effectively  but they do not provide for user interaction with the computer system time sharing  or multitasking  is a logical extension of multiprogramming in time-sharing systems  the cpu executes multiple jobs by switching among them  but the switches occur so frequently that the users can interact with each program while it is running time sharing requires an interactive  or hands-on  computer system  which provides direct communication between the user and the system the user gives instructions to the operating system or to a program directly  using a input device such as a keyboard or a mouse  and waits for immediate results on an output device accordingly  the response time should be short typically less than one second a time-shared operating system allows many users to share the computer simultaneously since each action or command in a time-shared system tends to be short  only a little cpu time is needed for each user as the system switches rapidly from one user to the next  each user is given the impression that the entire computer system is dedicated to his use  even though it is being shared among many users a time-shared operating system uses cpu scheduling and multiprogramming to provide each user with a small portion of a time-shared computer each user has at least one separate program in memory a program loaded into 1.5 operating-system operations 17 memory and executing is called a process when a process executes  it typically executes for only a short time before it either finishes or needs to perform i/o i/o may be interactive ; that is  output goes to a display for the user  and input comes from a user keyboard  mouse  or other device since interactive i/o typically runs at " people speeds  " it may take a long time to complete input  for example  may be bounded by the user 's typing speed ; seven characters per second is fast for people but incredibly slow for computers rather than let the cpu sit idle as this interactive input takes place  the operating system will rapidly switch the cpu to the program of some other user time-sharing and multiprogramming require several jobs to be kept simultaneously in memory since in general main memory is too small to accommodate all jobs  the jobs are kept initially on the disk in the job pool this pool consists of all processes residing on disk awaiting allocation of main memory if several jobs are ready to be brought into memory  and if there is not enough room for all of them  then the system must choose among them making this decision is job scheduling  which is discussed in 5 when the operating system selects a job from the job pool  it loads that job into memory for execution having several programs in memory at the same time requires some form of memory management  which is covered in s 8 and 9 in addition  if several jobs are ready to run at the same time  the system must choose among them making this decision is cpu scheduling  which is discussed in 5 finally  running multiple jobs concurrently requires that their ability to affect one another be limited in all phases of the operating system  including process scheduling  disk storage  and memory management these considerations are discussed throughout the text in a time-sharing system  the operating system must ensure reasonable response time  which is sometimes accomplished through swapping  where processes are swapped in and out of main memory to the disk a more common method for achieving this goal is virtual memory  a technique that allows the execution of a process that is not completely in memory  9   the main advantage of the virtual-memory scheme is that it enables users to run programs that are larger than actual physical memory further  it abstracts main memory into a large  uniform array of storage  separating logical memory as viewed by the user from physical memory this arrangement frees programmers from concern over memory-storage limitations time-sharing systems must also provide a file system  s 10 and 11   the file system resides on a collection of disks ; hence  disk management must be provided  12   also  time-sharing systems provide a mechanism for protecting resources from inappropriate use  14   to ensure orderly execution  the system must provide mechanisms for job synchronization and communication  6   and it may ensure that jobs do not get stuck in a deadlock  forever waiting for one another  7   1.5 operating-system operations as mentioned earlier  modern operating systems are interrupt driven if there are no processes to execute  no i/o devices to service  and no users to whom to respond  an operating system will sit quietly  waiting for something to happen events are almost always signaled by the occurrence of an interrupt or a trap a trap  or an exception  is a software-generated interrupt caused either by an error  for example  division by zero or invalid memory access  or by a specific request from a user program that an operating-system service be performed the interrupt-driven nature of an operating system defines that system 's general structure for each type of interrupt  separate segments of code in the operating system determine what action should be taken an interrupt service routine is provided that is responsible for dealing with the interrupt since the operating system and the users share the hardware and software resources of the computer system  we need to make sure that an error in a user program could cause problems only for the one program that was running with sharing  many processes could be adversely affected by a bug in one program for example  if a process gets stuck in an infinite loop  this loop could prevent the correct operation of many other processes more subtle errors can occur in a multiprogramming system  where one erroneous program might modify another program  the data of another program  or even the operating system itself without protection against these sorts of errors  either the computer must execute only one process at a time or all output must be suspect a properly designed operating system must ensure that an incorrect  or malicious  program can not cause other programs to execute incorrectly 1.5.1 dual-mode operation in order to ensure the proper execution of the operating system  we must be able to distinguish between the execution of operating-system code and userdefined code the approach taken by most computer systems is to provide hardware support that allows us to differentiate among various modes of execution at the very least  we need two separate modes of operation  user mode and kernel mode  also called supervisor mode  system mode  or privileged mode   a bit  called the mode bit  is added to the hardware of the computer to indicate the current mode  kernel  0  or user  1   with the mode bit  we are able to distinguish between a task that is executed on behalf of the operating system and one that is executed on behalf of the user when the computer system is executing on behalf of a user application  the system is in user mode however  when a user application requests a service from the operating system  via a system call   it must transition from user to kernel mode to fulfill the request this is shown in 1.8 as we shall see  this architectural enhancement is useful for many other aspects of system operation as well at system boot time  the hardware starts in kernel mode the operating system is then loaded and starts user applications in user mode whenever a trap or interrupt occurs  the hardware switches from user mode to kernel mode  that is  changes the state of the mode bit to 0   thus  whenever the operating system gains control of the computer  it is in kernel mode the system always switches to user mode  by setting the mode bit to 1  before passing control to a user program the dual mode of operation provides us with the means for protecting the operating system from errant users and errant users from one another we accomplish this protection by designating some of the machine instructions that 1.5 operating-system operations 19 user process executing calls system call return from system call user mode  mode bit = 1  k e m e l mode bit = 0 ; mode bit = 1 kernel mode execute system call i  mode bit = 0  1.8 transition from user to kernel mode may cause harm as privileged instructions the hardware allows privileged instructions to be executed only in kernel mode if an attempt is made to execute a privileged instruction in user mode  the hardware does not execute the instruction but rather treats it as illegal and traps it to the operating system the instruction to switch to user mode is an example of a privileged instruction some other examples include i/o control  timer management  and interrupt management as we shall see throughout the text  there are many additional privileged instructions we can now see the life cycle of instruction execution in a computer system initial control is within the operating system  where instructions are executed in kernel mode when control is given to a user application  the mode is set to user mode eventually  control is switched back to the operating system via an interrupt  a trap  or a system call system calls provide the means for a user program to ask the operating system to perform tasks reserved for the operating system on the user program 's behalf a system call is invoked in a variety of ways  depending on the functionality provided by the underlying processor in all forms  it is the method used by a process to request action by the operating system a system call usually takes the form of a trap to a specific location in the interrupt vector this trap can be executed by a generic t r a p instruction  although some systems  such as the mips r2000 family  have a specific syscall instruction when a system call is executed  it is treated by the hardware as a software interrupt control passes through the interrupt vector to a service routine in the operating system  and the mode bit is set to kernel mode the systemcall service routine is a part of the operating system the kernel examines the interrupting instruction to determine what system call has occurred ; a parameter indicates what type of service the user program is requesting additional information needed for the request may be passed in registers  on the stack  or in memory  with pointers to the memory locations passed in registers   the kernel verifies that the parameters are correct and legal  executes the request  and returns control to the instruction following the system call we describe system calls more fully in section 2.3 the lack of a hardware-supported dual mode can cause serious shortcomings in an operating system for instance  ms-dos was written for the intel 8088 architecture  which has no mode bit and therefore no dual mode a user program running awry can wipe out the operating system by writing over it with data ; and multiple programs are able to write to a device at the same time  20 1 with possibly disastrous results recent versions of the intel cpu  such is the pentium  do provide dual-mode operation accordingly  most contemporary operating systems  such as microsoft windows 2000 and windows xp  and linux and solaris for x86 systems  take advantage of this feature and provide greater protection for the operating system once hardware protection is in place  errors violating modes are detected by the hardware these errors are normally handled by the operating system if a user program fails in some way such as by making an attempt either to execute an illegal instruction or to access memory that is not in the user 's address space then the hardware will trap to the operating system the trap transfers control through the interrupt vector to the operating system  just as an interrupt does when a program error occurs  the operating system must terminate the program abnormally this situation is handled by the same code as is a user-requested abnormal termination an appropriate error message is given  and the memory of the program may be dumped the memory dump is usually written to a file so that the user or programmer can examine it and perhaps correct it and restart the program 1.5.2 timer we must ensure that the operating system maintains control over the cpu we must prevent a user program from getting stuck in an infinite loop or not calling system services and never returning control to the operating system to accomplish this goal  we can use a timer a timer can be set to interrupt the computer after a specified period the period may be fixed  for example  1/60 second  or variable  for example  from 1 millisecond to 1 second   a variable timer is generally implemented by a fixed-rate clock and a counter the operating system sets the counter every time the clock ticks  the counter is decremented when the counter reaches 0  an interrupt occurs for instance  a 10-bit counter with a 1-millisecond clock allows interrupts at intervals from 1 millisecond to 1,024 milliseconds  in steps of 1 millisecond before turning over control to the user  the operating system ensures that the timer is set to interrupt if the timer interrupts  control transfers automatically to the operating system  which may treat the interrupt as a fatal error or may give the program more time clearly  instructions that modify the content of the timer are privileged thus  we can use the timer to prevent a user program from running too long a simple technique is to initialize a counter with the amount of time that a program is allowed to run a program with a 7-minute time limit  for example  would have its counter initialized to 420 every second  the timer interrupts and the counter is decremented by 1 as long as the counter is positive  control is returned to the user program when the counter becomes negative  the operating system terminates the program for exceeding the assigned time limit 1.6 process management a program does nothing unless its instructions are executed by a cpu a program in execution  as mentioned  is a process a time-shared user program such as a compiler is a process a word-processing program being run by an 1.7 memory management 21 individual user on a pc is a process a system task  such as sending utput to a printer  can also be a process  or at least part of one   for now  you can consider a process to be a job or a time-shared program  but later you will learn that the concept is more general as we shall see in 3  it is possible to provide system calls that allow processes to create subprocesses to execute concurrently a process needs certain resources including cpu time  memory  files  and i/o devices to accomplish its task these resources are either given to the process when it is created or allocated to it while it is running in addition to the various physical and logical resources that a process obtains when it is created  various initialization data  input  may be passed along for example  consider a process whose function is to display the status of a file on the screen of a terminal the process will be given as an input the name of the file and will execute the appropriate instructions and system calls to obtain and display on the terminal the desired information when the process terminates  the operating system will reclaim any reusable resources we emphasize that a program by itself is not a process ; a program is a passive entity  such as the contents of a file stored on disk  whereas a process is an active entity a single-threaded process has one program counter specifying the next instruction to execute  threads will be covered in 4  the execution of such a process must be sequential the cpu executes one instruction of the process after another  until the process completes further  at any time  one instruction at most is executed on behalf of the process thus  although two processes may be associated with the same program  they are nevertheless considered two separate execution sequences a multithreaded process has multiple program counters  each pointing to the next instruction to execute for a given thread a process is the unit of work in a system such a system consists of a collection of processes  some of which are operating-system processes  those that execute system code  and the rest of which are user processes  those that execute user code   all these processes can potentially execute concurrently by multiplexing the cpu among them on a single cpu  for example the operating system is responsible for the following activities in connection with process management  creating and deleting both user and system processes suspending and resuming processes providing mechanisms for process synchronization providing mechanisms for process communication providing mechanisms for deadlock handling we discuss process-management techniques in s 3 through 6 1.7 memory management as we discussed in section 1.2.2  the main memory is central to the operation of a modern computer system main memory is a large array of words or bytes  22 1 ranging in size from hundreds of thousands to billions each word or byte has its own address main memory is a repository of quickly accessible data shared by the cpu and i/o devices the central processor reads instructions from main memory during the instruction-fetch cycle and both reads and writes data from main memory during the data-fetch cycle  on a von neumann architecture   the main memory is generally the only large storage device that the cpu is able to address and access directly for example  for the cpu to process data from disk  those data must first be transferred to main memory by cpu-generated i/o calls in the same way  instructions must be in memory for the cpu to execute them for a program to be executed  it must be mapped to absolute addresses and loaded into memory as the program executes  it accesses program instructions and data from memory by generating these absolute addresses eventually  the program terminates  its memory space is declared available  and the next program can be loaded and executed to improve both the utilization of the cpu and the speed of the computer 's response to its users  general-purpose computers must keep several programs in memory  creating a need for memory management many different memorymanagement schemes are used these schemes reflect various approaches  and the effectiveness of any given algorithm depends on the situation in selecting a memory-management scheme for a specific system  we must take into account many factors especially on the hardware design of the system each algorithm requires its own hardware support the operating system is responsible for the following activities in connection with memory management  keeping track of which parts of memory are currently being used and by whom deciding which processes  or parts thereof  and data to move into and out of memory allocating and deallocating memory space as needed memory-management techniques will be discussed in s 8 and 9 1.8 storage management to make the computer system convenient for users  the operating system provides a uniform  logical view of information storage the operating system abstracts from the physical properties of its storage devices to define a logical storage unit  the file the operating system maps files onto physical media and accesses these files via the storage devices 1.8.1 file-system management file management is one of the most visible components of an operating system computers can store information on several different types of physical media magnetic disk  optical disk  and magnetic tape are the most common each of these media has its own characteristics and physical organization each medium is controlled by a device  such as a disk drive or tape drive  that 1.8 storage management 23 also has its own unique characteristics these properties include accessspeed  capacity '  data-transfer rate  and access method  sequential or random   a file is a collection of related information defined by its creator commonly  files represent programs  both source and object forms  and data data files may be numeric  alphabetic  alphanumeric  or binary files may be free-form  for example  text files   or they may be formatted rigidly  for example  fixed fields   clearly  the concept of a file is an extremely general one the operating system implements the abstract concept of a file by managing mass storage media  such as tapes and disks  and the devices that control them also  files are normally organized into directories to make them easier to use finally  when multiple users have access to files  it may be desirable to control by whom and in what ways  for example  read  write  append  files may be accessed the operating system is responsible for the following activities in connection with file management  creating and deleting files creating and deleting directories to organize files supporting primitives for manipulating files and directories mapping files onto secondary storage backing up files on stable  nonvolatile  storage media file-management techniques will be discussed in s 10 and 11 1.8.2 mass-storage management as we have already seen  because main memory is too small to accommodate all data and programs  and because the data that it holds are lost when power is lost  the computer system must provide secondary storage to back up main memory most modern computer systems use disks as the principal on-line storage medium for both programs and data most programs including compilers  assemblers  word processors  editors  and formatters are stored on a disk until loaded into memory and then use the disk as both the source and destination of their processing hence  the proper management of disk storage is of central importance to a computer system the operating system is responsible for the following activities in connection with disk management  free-space management storage allocation disk scheduling because secondary storage is used frequently  it must be used efficiently the entire speed of operation of a computer may hinge on the speeds of the disk subsystem and of the algorithms that manipulate that subsystem there are  however  many uses for storage that is slower and lower in cost  and sometimes of higher capacity  than secondary storage backups of disk data  seldom-used data  and long-term archival storage are some examples 24 1 magnetic tape drives and their tapes and cd and dvd drives and platters are typical tertiary storage devices the media  tapes and optical platters  vary between worm  write-once  read-many-times  and rw  read-write  formats tertiary storage is not crucial to system performance  but it still must be managed some operating systems take on this task  while others leave tertiary-storage management to application programs some of the functions that operating systems can provide include mounting and unmounting media in devices  allocating and freeing the devices for exclusive use by processes  and migrating data from secondary to tertiary storage techniques for secondary and tertiary storage management will be discussed in 12 1.8.3 caching caching is an important principle of computer systems information is normally kept in some storage system  such as main memory   as it is used  it is copied into a faster storage system the cache on a temporary basis when we need a particular piece of information  we first check whether it is in the cache if it is  we use the information directly from the cache ; if it is not  we use the information from the source  putting a copy in the cache under the assumption that we will need it again soon in addition  internal programmable registers  such as index registers  provide a high-speed cache for main memory the programmer  or compiler  implements the register-allocation and register-replacement algorithms to decide which information to keep in registers and which to keep in main memory there are also caches that are implemented totally in hardware for instance  most systems have an instruction cache to hold the next instructions expected to be executed without this cache  the cpu would have to wait several cycles while an instruction was fetched from main memory for similar reasons  most systems have one or more high-speed data caches in the memory hierarchy we are not concerned with these hardware-only caches in this text  since they are outside the control of the operating system because caches have limited size  cache management is an important design problem careful selection of the cache size and of a replacement policy can result in greatly increased performance see 1.9 for a storage performance comparison in large workstations and small servers that shows the need for caching various replacement algorithms for software-controlled caches are discussed in 9 main memory can be viewed as a fast cache for secondary storage  since data in secondary storage must be copied into main memory for use  and data must be in main memory before being moved to secondary storage for safekeeping the file-system data  which resides permanently on secondary storage  may appear on several levels in the storage hierarchy at the highest level  the operating system may maintain a cache of file-system data in main memory also  electronic ram disks  also known as solid-state disks  may be used for high-speed storage that is accessed through the file-system interface the bulk of secondary storage is on magnetic disks the magnetic-disk storage  in turn  is often backed up onto magnetic tapes or removable disks to protect against data loss in case of a hard-disk failure some systems automatically 1.8 storage management 25 level $ ! $ r # $ $ f3 'll ^ cqess time insji ;  ;  j lanaielf ;  ;  ;  |  i s a e k e i f l i s y  ; 1   ;  ; ;  i ;  \ z    ' " ;  isgistprs ; ;  %  % % %   ; eacn um  u  j ifflfflif '  mul ^ ll ; pm,ttfejis cfoffipifer  ;  |  ;  |  ;  6sflher ;  "   " i  " ; '1 ;  ' "  ;  ' 0 s  2 s ;  s ;  ;   ; ;  ;  5q0 | | #  i  | 1 ! iriafpari   | f  |   i rilaiji memory   ;   3     '   '   ; raajft njenwjy ; j i otjemini sysfew  disl <  !  ;  ; ;  | ;  ;  ;   4  ;     cfisk  sti3fgge ; i ;  ; i  s.0 | 3 ; gl ;    ; ^ " riaihltiebsi  ;   m ^ sk ; ; m ;  opep ! ti |  sii si ; etti   dpi5fia |  e ; j ; ; f 1.9 performance of various levels of storage archive old file data from secondary storage to tertiary storage  such as tape jukeboxes  to lower the storage cost  see 12   the movement of information between levels of a storage hierarchy may be either explicit or implicit  depending on the hardware design and the controlling operating-system software for instance  data transfer from cache to cpu and registers is usually a hardware function  with no operating-system intervention in contrast  transfer of data from disk to memory is usually controlled by the operating system in a hierarchical storage structure  the same data may appear in different levels of the storage system for example  suppose that an integer a that is to be incremented by 1 is located in file b  and file b resides on magnetic disk the increment operation proceeds by first issuing an i/o operation to copy the disk block on which a resides to main memory this operation is followed by copying a to the cache and to an internal register thus  the copy of a appears in several places  on the magnetic disk  in main memory  in the cache  and in an internal register  see 1.10   once the increment takes place in the internal register  the value of a differs in the various storage systems the value of a becomes the same only after the new value of a is written from the internal register back to the magnetic disk in a computing environment where only one process executes at a time  this arrangement poses no difficulties  since an access to integer a will always be to the copy at the highest level of the hierarchy however  in a multitasking environment  where the cpu is switched back and forth among various processes  extreme care must be taken to ensure that  if several processes wish to access a  then each of these processes will obtain the most recently updated value of a magnetic disk main memory hardware register 1.10 migration of integer a from disk to register 26 1 the situation becomes more complicated in a multiprocessor environment where  in addition to maintaining internal registers  each of the cpus also contains a local cache in such an environment  a copy of a may exist simultaneously in several caches since the various cpus can all execute concurrently  we must make sure that an update to the value of a in one cache is immediately reflected in all other caches where a resides this situation is called cache coherency  and it is usually a hardware problem  handled below the operating-system level   in a distributed environment  the situation becomes even more complex in this environment  several copies  or replicas  of the same file can be kept on different computers that are distributed in space since the various replicas may be accessed and updated concurrently  some distributed systems ensure that  when a replica is updated in one place  all other replicas are brought up to date as soon as possible there are various ways to achieve this guarantee  as we discuss in 17 1.8.4 i/o systems one of the purposes of an operating system is to hide the peculiarities of specific hardware devices from the user for example  in unix  the peculiarities of i/o devices are hidden from the bulk of the operating system itself by the i/o subsystem the i/o subsystem consists of several components  a memory-management component that includes buffering  caching  and spooling a general device-driver interface drivers for specific hardware devices only the device driver knows the peculiarities of the specific device to which it is assigned we discussed in section 1.2.3 how interrupt handlers and device drivers are used in the construction of efficient i/o subsystems in 13  we discuss how the i/o subsystem interfaces to the other system components  manages devices  transfers data  and detects i/o completion 1.9 protection and security if a computer system has multiple users and allows the concurrent execution of multiple processes  then access to data must be regulated for that purpose  mechanisms ensure that files  memory segments  cpu  and other resources can be operated on by only those processes that have gained proper authorization from the operating system for example  memory-addressing hardware ensures that a process can execute only within its own address space the timer ensures that no process can gain control of the cpu without eventually relinquishing control device-control registers are not accessible to users  so the integrity of the various peripheral devices is protected protection  then  is any mechanism for controlling the access of processes or users to the resources defined by a computer system this mechanism must 1.9 protection and security 27 provide means for specification of the controls to be imposed and means for enforcement protection can improve reliability by detecting latent errors at the interfaces between component subsystems early detection of interface errors can often prevent contamination of a healthy subsystem by another subsystem that is malfunctioning an unprotected resource can not defend against use  or misuse  by an unauthorized or incompetent user a protection-oriented system provides a means to distinguish between authorized and unauthorized usage  as we discuss in 14 a system can have adequate protection but still be prone to failure and allow inappropriate access consider a user whose authentication information  her means of identifying herself to the system  is stolen her data could be copied or deleted  even though file and memory protection are working it is the job of security to defend a system from external and internal attacks such attacks spread across a huge range and include viruses and worms  denial-ofservice attacks  which use all of a system 's resources and so keep legitimate users out of the system   identity theft  and theft of service  unauthorized use of a system   prevention of some of these attacks is consider an operatingsystem function on some systems  while others leave the prevention to policy or additional software due to the alarming rise in security incidents  operatingsystem security features represent a fast-growing area of research and of implementation security is discussed in 15 protection and security require the system to be able to distinguish among all its users most operating systems maintain a list of user names and associated user identifiers  user ids   in windows nt parlance  this is a security id  sid   these numerical ids are unique  one per user when a user logs in to the system  the authentication stage determines the appropriate user id for the user that user id is associated with all of the user 's processes and threads when an id needs to be user readable  it is translated back to the user name via the user name list in some circumstances  we wish to distinguish among sets of users rather than individual users for example  the owner of a file on a unix system may be allowed to issue all operations on that file  whereas a selected set of users may only be allowed to read the file to accomplish this  we need to define a group name and the set of users belonging to that group group functionality can be implemented as a system-wide list of group names and group identifiers a user can be in one or more groups  depending on operating-system design decisions the user 's group ids are also included in every associated process and thread in the course of normal use of a system  the user id and group id for a user are sufficient however  a user sometimes needs to escalate privileges to gain extra permissions for an activity the user may need access to a device that is restricted  for example operating systems provide various methods to allow privilege escalation on unix  for example  the setuid attribute on a program causes that program to run with the user id of the owner of the file  rather than the current user 's id the process runs with this effective uid until it turns off the extra privileges or terminates consider an example of how this is done in solaris 10 user pbg has user id 101 and group id 14  which are assigned via /etc/passwd  pbg  x  101  14   /export/home/pbg  /usr/bin/bash 28 1 1.10 distributed systems * a distributed system is a collection of physically separate  possibly heterogeneous computer systems that are networked to provide the users with access to the various resources that the system maintains access to a shared resource increases computation speed  functionality  data availability  and reliability some operating systems generalize network access as a form of file access  with the details of networking contained in the network interface 's device driver others make users specifically invoke network functions generally  systems contain a mix of the two modes for example ftp and nfs the protocols that create a distributed system can greatly affect that system 's utility and popularity a network  in the simplest terms  is a communication path between two or more systems distributed systems depend on networking for their functionality networks vary by the protocols used  the distances between nodes  and the transport media tcp/ip is the most common network protocol  although atm and other protocols are in widespread use likewise  operatingsystem support of protocols varies most operating systems support tcp/ip  including the windows and unix operating systems some systems support proprietary protocols to suit their needs to an operating system  a network protocol simply needs an interface device a network adapter  for example with a device driver to manage it  as well as software to handle data these concepts are discussed throughout this book networks are characterized based on the distances between their nodes a local-area network  lan  connects computers within a room  a floor  or a building a wide-area network  wan  usually links buildings  cities  or countries a global company may have a wan to connect its offices worldwide these networks may run one protocol or several protocols the continuing advent of new technologies brings about new forms of networks for example  a metropolitan-area network  man  could link buildings within a city bluetooth and 802.11 devices use wireless technology to communicate over a distance of several feet  in essence creating a small-area network such as might be found in a home the media to carry networks are equally varied they include copper wires  fiber strands  and wireless transmissions between satellites  microwave dishes  and radios when computing devices are connected to cellular phones  they create a network even very short-range infrared communication can be used for networking at a rudimentary level  whenever computers communicate  they use or create a network these networks also vary in their performance and reliability some operating systems have taken the concept of networks and distributed systems further than the notion of providing network connectivity a network operating system is an operating system that provides features such as file sharing across the network and that includes a communication scheme that allows different processes on different computers to exchange messages a computer running a network operating system acts autonomously from all other computers on the network  although it is aware of the network and is able to communicate with other networked computers a distributed operating system provides a less autonomous environment  the different operating 1.11 special-purpose systems 29 systems communicate closely enough to provide the illusion that only a single operating system controls the network we cover computer networks and distributed systems in s 16 through 18 1.11 special-purpose systems the discussion thus far has focused on general-purpose computer systems that we are all familiar with there are  however  different classes of computer systems whose functions are more limited and whose objective is to deal with limited computation domains 1.11.1 real-time embedded systems embedded computers are the most prevalent form of computers in existence these devices are found everywhere  from car engines and manufacturing robots to vcrs and microwave ovens they tend to have very specific tasks the systems they run on are usually primitive  and so the operating systems provide limited features usually  they have little or no user interface  preferring to spend their time monitoring and managing hardware devices  such as automobile engines and robotic arms these embedded systems vary considerably some are general-purpose computers  running standard operating systems such as unix with special-purpose applications to implement the functionality others are hardware devices with a special-purpose embedded operating system providing just the functionality desired yet others are hardware devices with application-specific integrated circuits  asics  that perform their tasks without an operating system the use of embedded systems continues to expand the power of these devices  both as standalone units and as members of networks and the web  is sure to increase as well even now  entire houses can be computerized  so that a central computer either a general-purpose computer or an embedded system can control heating and lighting  alarm systems  and even coffee makers web access can enable a home owner to tell the house to heat up before she arrives home someday  the refrigerator may call the grocery store when it notices the milk is gone embedded systems almost always run real-time operating systems a real-time system is used when rigid time requirements have been placed on the operation of a processor or the flow of data ; thus  it is often used as a control device in a dedicated application sensors bring data to the computer the computer must analyze the data and possibly adjust controls to modify the sensor inputs systems that control scientific experiments  medical imaging systems  industrial control systems  and certain display systems are realtime systems some automobile-engine fuel-injection systems  home-appliance controllers  and weapon systems are also real-time systems a real-time system has well-defined  fixed time constraints processing mustbe done within the defined constraints  or the system will fail for instance  it would not do for a robot arm to be instructed to halt after it had smashed into the car it was building a real-time system functions correctly only if it 30 1 returns the correct result within its time constraints contrast this system with a time-sharing system  where it is desirable  but not mandatory  to respond quickly  or a batch system  which may have no time constraints at all in 19  we cover real-time embedded systems in great detail in 5  we consider the scheduling facility needed to implement real-time functionality in an operating system in 9  we describe the design of memory management for real-time computing finally  in 22  we describe the real-time components of the windows xp operating system 1.11.2 multimedia systems most operating systems are designed to handle conventional data such as text files  programs  word-processing documents  and spreadsheets however  a recent trend in technology is the incorporation of multimedia data into computer systems multimedia data consist of audio and video files as well as conventional files these data differ from conventional data in that multimedia data such as frames of video must be delivered  streamed  according to certain time restrictions  for example  30 frames per second   multimedia describes a wide range of applications that are in popular use today these include audio files such as mp3 dvd movies  video conferencing  and short video clips of movie previews or news stories downloaded over the internet multimedia applications may also include live webcasts  broadcasting over the world wide web  of speeches or sporting events and even live webcams that allow a viewer in manhattan to observe customers at a cafe in paris multimedia applications need not be either audio or video ; rather  a multimedia application often includes a combination of both for example  a movie may consist of separate audio and video tracks nor must multimedia applications be delivered only to desktop personal computers increasingly  they are being directed toward smaller devices  including pdas and cellular telephones for example  a stock trader may have stock quotes delivered wirelessly and in real time to his pda in 20  we explore the demands of multimedia applications  how multimedia data differ from conventional data  and how the nature of these data affects the desigii of operating systems that support the requirements of multimedia systems 1.11.3 handheld systems handheld systems include personal digital assistants  pdas   such as palm and pocket-pcs  and cellular telephones  many of which use special-purpose embedded operating systems developers of handheld systems and applications face many challenges  most of which are due to the limited size of such devices for example  a pda is typically about 5 inches in height and 3 inches in width  and it weighs less than one-half pound because of their size  most handheld devices have a small amount of memory  slow processors  and small display screens we will take a look now at each of these limitations the amount of physical memory in a handheld depends upon the device  but typically is is somewhere between 512 kb and 128 mb  contrast this with a typical pc or workstation  which may have several gigabytes of memory !  as a result  the operating system and applications must manage memory efficiently this includes returning all allocated memory back to the memory 1.12 computing environments 31 manager when the memory is not being used in 9  we will explore virtual memory  which allows developers to write programs that behave as if the system has more memory than is physically available currently  not many handheld devices use virtual memory techniques  so program developers must work within the confines of limited physical memory a second issue of concern to developers of handheld devices is the speed of the processor used in the devices processors for most handheld devices run at a fraction of the speed of a processor in a pc faster processors require more power to include a faster processor in a handheld device would require a larger battery  which would take up more space and would have to be replaced  or recharged  more frequently most handheld devices use smaller  slower processors that consume less power therefore  the operating system and applications must be designed not to tax the processor the last issue confronting program designers for handheld devices is i/o a lack of physical space limits input methods to small keyboards  handwriting recognition  or small screen-based keyboards the small display screens limit output options whereas a monitor for a home computer may measure up to 30 inches  the display for a handheld device is often no more than 3 inches square familiar tasks  such as reading e-mail and browsing web pages  must be condensed into smaller displays one approach for displaying the content in web pages is web clipping  where only a small subset of a web page is delivered and displayed on the handheld device some handheld devices use wireless technology  such as bluetooth or 802.11  allowing remote access to e-mail and web browsing cellular telephones with connectivity to the internet fall into this category however  for pdas that do not provide wireless access  downloading data typically requires the user to first download the data to a pc or workstation and then download the data to the pda some pdas allow data to be directly copied from one device to another using an infrared link generally  the limitations in the functionality of pdas are balanced by their convenience and portability their use continues to expand as network connections become more available and other options  such as digital cameras and mp3 players  expand their utility 1.12 computing environments so far  we have provided an overview of computer-system organization and major operating-system components we conclude with a brief overview of how these are used in a variety of computing environments 1.12.1 traditional computing as computing matures  the lines separating many of the traditional computing environments are blurring consider the " typical office environment " just a few years ago  this environment consisted of pcs connected to a network  with servers providing file and print services remote access was awkward  and portability was achieved by use of laptop computers terminals attached to mainframes were prevalent at many companies as well  with even fewer remote access and portability options 32 1 the current trend is toward providing more ways to access these computing environments web technologies are stretching the boundaries of traditional computing companies establish portals  which provide web accessibility to their internal servers network computers are essentially terminals that understand web-based computing handheld computers can synchronize with pcs to allow very portable use of company information handheld pdas can also connect to wireless networks to use the company 's web portal  as well as the myriad other web resources   at home  most users had a single computer with a slow modem connection to the office  the internet  or both today  network-connection speeds once available only at great cost are relatively inexpensive  giving home users more access to more data these fast data connections are allowing home computers to serve up web pages and to run networks that include printers  client pcs  and servers some homes even have firewalls to protect their networks from security breaches those firewalls cost thousands of dollars a few years ago and did not even exist a decade ago in the latter half of the previous century  computing resources were scarce  before that  they were nonexistent !  for a period of time  systems were either batch or interactive batch system processed jobs in bulk  with predetermined input  from files or other sources of data   interactive systems waited for input from users to optimize the use of the computing resources  multiple users shared time on these systems time-sharing systems used a timer and scheduling algorithms to rapidly cycle processes through the cpu  giving each user a share of the resources today  traditional time-sharing systems are uncommon the same scheduling technique is still in use on workstations and servers  but frequently the processes are all owned by the same user  or a single user and the operating system   user processes  and system processes that provide services to the user  are managed so that each frequently gets a slice of computer time consider the windows created while a user is working on a pc  for example  and the fact that they may be performing different tasks at the same time 1.12.2 client-server computing as pcs have become faster  more powerful  and cheaper  designers have shifted away from centralized system architecture terminals connected to centralized systems are now being supplanted by pcs correspondingly  userinterface functionality once handled directly by the centralized systems is increasingly being handled by the pcs as a result  many of todays systems act as server systems to satisfy requests generated by client systems this form of specialized distributed system  called client-server system  has the general structure depicted in 1.11 server systems can be broadly categorized as compute servers and file servers  the compute-server system provides an interface to which a client can send a request to perform an action  for example  read data  ; in response  the server executes the action and sends back results to the client a server running a database that responds to client requests for data is an example of such a svstem 1.12 computing environments 33 client client ! i client client  network server 1.11 general structure of a client-server system the file-server system provides a file-system interface where clients can create  update  read  and delete files an example of such a system is a web server that delivers files to clients running web browsers ' 1.12.3 peer-to-peer computing another structure for a distributed system is the peer-to-peer  p2p  system model in this model  clients and servers are not distinguished from one another ; instead  all nodes within the system are considered peers  and each may act as either a client or a server  depending on whether it is requesting or providing a service peer-to-peer systems offer an advantage over traditional client-server systems in a client-server system  the server is a bottleneck ; but in a peer-to-peer system  services can be provided by several nodes distributed throughout the network to participate in a peer-to-peer system  a node must first join the network of peers once a node has joined the network  it can begin providing services to and requesting services from other nodes in the network determining what services are available is accomplished in one of two general ways  when a node joins a network  it registers its service with a centralized lookup service on the network any node desiring a specific service first contacts this centralized lookup service to determine which node provides the service the remainder of the communication takes place between the client and the service provider a peer acting as a client must first discover what node provides a desired service by broadcasting a request for the service to all other nodes in the network the node  or nodes  providing that service responds to the peer making the request to support this approach  a discovery protocol must be provided that allows peers to discover services provided by other peers in the network peer-to-peer networks gained widespread popularity in the late 1990s with several file-sharing services  such as napster and gnutella  that enable peers to exchange files with one another the napster system uses an approach similar to the first type described above  a centralized server maintains an index of all files stored on peer nodes in the napster network  and the actual exchanging of files takes place between the peer nodes the gnutella system uses a technique similar to the second type  a client broadcasts file requests to other nodes in the system  and nodes that can service the request respond directly to the client the future of exchanging files remains uncertain because 34 1 many of the files are copyrighted  music  for example   and there are * laws governing the distribution of copyrighted material in any case  though  peerto peer technology undoubtedly will play a role in the future of many sendees  such as searching  file exchange  and e-mail 1.12.4 web-based computing the web has become ubiquitous  leading to more access by a wider variety of devices than was dreamt of a few years ago pcs are still the most prevalent access devices  with workstations  handheld pdas  and even cell phones also providing access web computing has increased the emphasis on networking devices that were not previously networked now include wired or wireless access devices that were networked now have faster network connectivity  provided by either improved networking technology  optimized network implementation code  or both the implementation of web-based computing has given rise to new categories of devices  such as load balancers  which distribute network connections among a pool of similar servers operating systems like windows 95  which acted as web clients  have evolved into linux and windows xp  which can act as web servers as well as clients generally  the web has increased the complexity of devices  because their users require them to be web-enabled 1.13 summary an operating system is software that manages the computer hardware as well as providing an environment for application programs to run perhaps the most visible aspect of an operating system is the interface to the computer system  it provides to the human user for a computer to do its job of executing programs  the programs must be in main memory main memory is the only large storage area that the processor can access directly it is an array of words or bytes  ranging in size from millions to billions each word in memory has its own address the main memory is usually a volatile storage device that loses its contents when power is turned off or lost most computer systems provide secondary storage as an extension of main memory secondary storage provides a form of non-volatile storage that is capable of holding large quantities of data permanently the most common secondary-storage device is a magnetic disk  which provides storage of both programs and data the wide variety of storage systems in a computer system can be organized in a hierarchy according to speed and cost the higher levels are expensive  but they are fast as we move down the hierarchy  the cost per bit generallydecreases  whereas the access time generally increases there are several different strategies for designing a computer system uniprocessor systems have only a single processor while multiprocessor systems contain two or more processors that share physical memory and peripheral devices the most common multiprocessor design is symmetric multiprocessing  or smp   where all processors are considered peers and run 1.13 summary 35 independently of one another clustered systems are a specialized form of multiprocessor systems and consist of multiple computer systems connected by a local area network to best utilize the cpu  modern operating systems employ multiprogramming/ which allows several jobs to be in memory at the same time  thus ensuring the cpu always has a job to execute timesharing systems are an extension of multiprogramming whereby cpu scheduling algorithms rapidly switch between jobs  thus providing the illusion each job is running concurrently the operating system must ensure correct operation of the computer system to prevent user programs from interfering with the proper operation of the system  the hardware has two modes  user mode and kernel mode various instructions  such as i/o instructions and halt instructions  are privileged and can be executed only in kernel mode the memory in which the operating system resides must also be protected from modification by the user a timer prevents infinite loops these facilities  dual mode  privileged instructions  memory protection  and timer interrupt  are basic building blocks used by operating systems to achieve correct operation a process  or job  is the fundamental unit of work in an operating system process management includes creating and deleting processes and providing mechanisms for processes to communicate and synchronize with another an operating system manages memory by keeping track of what parts of memory are being used and by whom the operating system is also responsible for dynamically allocating and freeing memory space storage space is also managed by the operating system and this includes providing file systems for representing files and directories and managing space on mass storage devices operating systems must also be concerned with protecting and securing the operating system and users protection are mechanisms that control the access of processes or users to the resources made available by the computer system security measures are responsible for defending a computer system from external or internal attacks distributed systems allow users to share resources on geographically dispersed hosts connected via a computer network services may be provided through either the client-server model or the peer-to-peer model in a clustered system  multiple machines can perform computations on data residing on shared storage  and computing can continue even when some subset of cluster members fails lans and wans are the two basic types of networks lans enable processors distributed over a small geographical area to communicate  whereas wans allow processors distributed over a larger area to communicate lans typically are faster than wans there are several computer systems that serve specific purposes these include real-time operating systems designed for embedded environments such as consumer devices  automobiles  and robotics real-time operating systems have well defined  fixed time constraints processing must be done within the defined constraints  or the system will fail multimedia systems involve the delivery of multimedia data and often have special requirements of displaying or playing audio  video  or synchronized audio and video streams recently  the influence of the internet and the world wide web has encouraged the development of modern operating systems that include web browsers and networking and communication software as integral features 