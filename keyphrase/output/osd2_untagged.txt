memory management is the functionality of an operating system which handles or manages primary memory memory management keeps track of each and every memory location either it is allocated to some process or it is free it checks how much memory is to be allocated to processes it decides which process will get memory at what time it tracks whenever some memory gets freed or unallocated and correspondingly it updates the status memory management provides protection by using two registers  a base register and a limit register the base register holds the smallest legal physical memory address and the limit register specifies the size of the range for example  if the base register holds 300000 and the limit register is 1209000  then the program can legally access all addresses from 300000 through 411999 memory management instructions and data to memory addresses can be done in following ways compile time  when it is known at compile time where the process will reside  compile time binding is used to generate the absolute code load time  when it is not known at compile time where the process will reside in memory  then the compiler generates re-locatable code execution time  if the process can be moved during its execution from one memory segment to another  then binding must be delayed to be done at run time dynamic loading in dynamic loading  a routine of a program is not loaded until it is called by the program all routines are kept on disk in a re-locatable load format the main program is loaded into memory and is executed other routines methods or modules are loaded on request dynamic loading makes better memory space utilization and unused routines are never loaded dynamic linking linking is the process of collecting and combining various modules of code and data into a executable file that can be loaded into memory and executed operating system can link system level libraries to a program when it combines the libraries at load time  the linking is called static linking and when this linking is done at the time of execution  it is called as dynamic linking in static linking  libraries linked at compile time  so program code size becomes bigger whereas in dynamic linking libraries linked at execution time so program code size remains smaller logical versus physical address space an address generated by the cpu is a logical address whereas address actually available on memory unit is a physical address logical address is also known a virtual address virtual and physical addresses are the same in compile-time and load-time address-binding schemes virtual and physical addresses differ in execution-time address-binding scheme the set of all logical addresses generated by a program is referred to as a logical address space the set of all physical addresses corresponding to these logical addresses is referred to as a physical address space the run-time mapping from virtual to physical address is done by the memory management unit  mmu  which is a hardware device mmu uses following mechanism to convert virtual address to physical address the value in the base register is added to every address generated by a user process which is treated as offset at the time it is sent to memory for example  if the base register value is 10000  then an attempt by the user to use address location 100 will be dynamically reallocated to location 10100 the user program deals with virtual addresses ; it never sees the real physical addresses swapping swapping is a mechanism in which a process can be swapped temporarily out of main memory to a backing store  and then brought back into memory for continued execution backing store is a usually a hard disk drive or any other secondary storage which fast in access and large enough to accommodate copies of all memory images for all users it must be capable of providing direct access to these memory images major time consuming part of swapping is transfer time total transfer time is directly proportional to the amount of memory swapped let us assume that the user process is of size 100kb and the backing store is a standard hard disk with transfer rate of 1 mb per second the actual transfer of the 100k process to or from memory will take 100kb / 1000kb per second = 1/10 second = 100 milliseconds process swapping memory allocation main memory usually has two partitions low memory  operating system resides in this memory high memory  user processes then held in high memory operating system uses the following memory allocation mechanism s.n memory allocation description 1 single-partition allocation in this type of allocation  relocation-register scheme is used to protect user processes from each other  and from changing operating-system code and data relocation register contains value of smallest physical address whereas limit register contains range of logical addresses each logical address must be less than the limit register 2 multiple-partition allocation in this type of allocation  main memory is divided into a number of fixed-sized partitions where each partition should contain only one process when a partition is free  a process is selected from the input queue and is loaded into the free partition when the process terminates  the partition becomes available for another process fragmentation as processes are loaded and removed from memory  the free memory space is broken into little pieces it happens after sometimes that processes can not be allocated to memory blocks considering their small size and memory blocks remains unused this problem is known as fragmentation fragmentation is of two types s.n fragmentation description 1 external fragmentation total memory space is enough to satisfy a request or to reside a process in it  but it is not contiguous so it can not be used 2 internal fragmentation memory block assigned to process is bigger some portion of memory is left unused as it can not be used by another process external fragmentation can be reduced by compaction or shuffle memory contents to place all free memory together in one large block to make compaction feasible  relocation should be dynamic paging external fragmentation is avoided by using paging technique paging is a technique in which physical memory is broken into blocks of the same size called pages  size is power of 2  between 512 bytes and 8192 bytes   when a process is to be executed  it 's corresponding pages are loaded into any available memory frames logical address space of a process can be non-contiguous and a process is allocated physical memory whenever the free memory frame is available operating system keeps track of all free frames operating system needs n free frames to run a program of size n pages address generated by cpu is divided into page number  p   page number is used as an index into a page table which contains base address of each page in physical memory page offset  d   page offset is combined with base address to define the physical memory address paging following figure show the paging table architecture paging example segmentation segmentation is a technique to break memory into logical pieces where each piece represents a group of related information for example ,data segments or code segment for each process  data segment for operating system and so on segmentation can be implemented using or without using paging unlike paging  segment are having varying sizes and thus eliminates internal fragmentation external fragmentation still exists but to lesser extent logical address space address generated by cpu is divided into segment number  s   segment number is used as an index into a segment table which contains base address of each segment in physical memory and a limit of segment segment offset  o   segment offset is first checked against limit and then is combined with base address to define the physical memory address virtual memory is a technique that allows the execution of processes which are not completely available in memory the main visible advantage of this scheme is that programs can be larger than physical memory virtual memory is the separation of user logical memory from physical memory this separation allows an extremely large virtual memory to be provided for programmers when only a smaller physical memory is available following are the situations  when entire program is not required to be loaded fully in main memory user written error handling routines are used only when an error occured in the data or computation certain options and features of a program may be used rarely many tables are assigned a fixed amount of address space even though only a small amount of the table is actually used the ability to execute a program that is only partially in memory would counter many benefits less number of i/o would be needed to load or swap each user program into memory a program would no longer be constrained by the amount of physical memory that is available each user program could take less physical memory  more programs could be run the same time  with a corresponding increase in cpu utilization and throughput virtual memory virtual memory is commonly implemented by demand paging it can also be implemented in a segmentation system demand segmentation can also be used to provide virtual memory demand paging a demand paging system is quite similar to a paging system with swapping when we want to execute a process  we swap it into memory rather than swapping the entire process into memory  however  we use a lazy swapper called pager when a process is to be swapped in  the pager guesses which pages will be used before the process is swapped out again instead of swapping in a whole process  the pager brings only those necessary pages into memory thus  it avoids reading into memory pages that will not be used in anyway  decreasing the swap time and the amount of physical memory needed hardware support is required to distinguish between those pages that are in memory and those pages that are on the disk using the valid-invalid bit scheme where valid and invalid pages can be checked by checking the bit marking a page will have no effect if the process never attempts to access the page while the process executes and accesses pages that are memory resident  execution proceeds normally demand paging access to a page marked invalid causes a page-fault trap this trap is the result of the operating system 's failure to bring the desired page into memory but page fault can be handled as following page fault step description step 1 check an internal table for this process  to determine whether the reference was a valid or it was an invalid memory access step 2 if the reference was invalid  terminate the process if it was valid  but page have not yet brought in  page in the latter step 3 find a free frame step 4 schedule a disk operation to read the desired page into the newly allocated frame step 5 when the disk read is complete  modify the internal table kept with the process and the page table to indicate that the page is now in memory step 6 restart the instruction that was interrupted by the illegal address trap the process can now access the page as though it had always been in memory therefore  the operating system reads the desired page into memory and restarts the process as though the page had always been in memory advantages following are the advantages of demand paging large virtual memory more efficient use of memory unconstrained multiprogramming there is no limit on degree of multiprogramming disadvantages following are the disadvantages of demand paging number of tables and amount of processor overhead for handling page interrupts are greater than in the case of the simple paged management techniques due to the lack of an explicit constraints on a jobs address space size page replacement algorithm page replacement algorithms are the techniques using which operating system decides which memory pages to swap out  write to disk when a page of memory needs to be allocated paging happens whenever a page fault occurs and a free page can not be used for allocation purpose accounting to reason that pages are not available or the number of free pages is lower than required pages when the page that was selected for replacement and was paged out  is referenced again then it has to read in from disk  and this requires for i/o completion this process determines the quality of the page replacement algorithm  the lesser the time waiting for page-ins  the better is the algorithm a page replacement algorithm looks at the limited information about accessing the pages provided by hardware  and tries to select which pages should be replaced to minimize the total number of page misses  while balancing it with the costs of primary storage and processor time of the algorithm itself there are many different page replacement algorithms we evaluate an algorithm by running it on a particular string of memory reference and computing the number of page faults reference string the string of memory references is called reference string reference strings are generated artificially or by tracing a given system and recording the address of each memory reference the latter choice produces a large number of data  where we note two things for a given page size we need to consider only the page number  not the entire address if we have a reference to a page p  then any immediately following references to page p will never cause a page fault page p will be in memory after the first reference ; the immediately following references will not fault for example  consider the following sequence of addresses  123,215,600,1234,76,96 if page size is 100 then the reference string is 1,2,6,12,0,0 first in first out  fifo  algorithm oldest page in main memory is the one which will be selected for replacement easy to implement  keep a list  replace pages from the tail and add new pages at the head first in first out optimal page algorithm an optimal page-replacement algorithm has the lowest page-fault rate of all algorithms an optimal page-replacement algorithm exists  and has been called opt or min replace the page that will not be used for the longest period of time  use the time when a page is to be used optimal page replacement least recently used  lru  algorithm page which has not been used for the longest time in main memory is the one which will be selected for replacement easy to implement  keep a list  replace pages by looking back into time least recently used page buffering algorithm to get process start quickly  keep a pool of free frames on page fault  select a page to be replaced write new page in the frame of free pool  mark the page table and restart the process now write the dirty page out of disk and place the frame holding replaced page in free pool least frequently used  lfu  algorithm page with the smallest count is the one which will be selected for replacement this algorithm suffers from the situation in which a page is used heavily during the initial phase of a process  but then is never used again most frequently used  mfu  algorithm this algorithm is based on the argument that the page with the smallest count was probably just brought in and has yet to be used  