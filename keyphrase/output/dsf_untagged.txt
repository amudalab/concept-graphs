data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 2 stacks let us see about stacks we will mainly see about stacks  besides we will talk about abstract data types  interfaces  exceptions  how stacks are implemented in java and application to the analysis of time series we will also talk about growable stacks  which do a little bit of amortized analysis and then we will talk about stacks in java virtual machine  refer slide time  1  16  what is an abstract data type ? it is basically a specification of the instances and the set of axioms that define the semantics of the operations on those instances what does it all mean ? you know the data types like integer  real numbers and so on you can understand the notion of addition and that is the same way as you add 2 integers in mathematics  refer slide time  1  51  similarly we will define data types and certain operations on those data types those operations would be defined through an interface which basically gives us the signature of the operation that is the parameters that operation requires and so on we will also specify the results of those operations through a set of axioms just as in the case of integers  you know the sum of 2 integers as defined in mathematics for example if you add a variable of type a and another variable of type b if you sum them up  then the answer will be of type variable as you would know it from your mathematics class we will be clear if we see an example the operations that you have been talking about are essentially of three kinds one would be just a constructor operation which is as same as the constructor method in java using this method you can create an instance of that particular data type when you are talking about sophisticated data types  this method has to do a lot of work access functions are the functions which let us to access elements of the data type and manipulation procedure would let us to manipulate or modify the data type why are we talking about data types ? data types help us to identify the requirements for the building blocks of our algorithmic procedure it provides a language which will help us to talk at a higher level of abstraction as just as we are talking in terms of adding up of integers or in terms of stacks or queues or any of the advanced data type  refer slide time  3  17   refer slide time  3  57  they encapsulate the data structure like how the data is organized and the algorithms that work on that data structures also they help us to separate the issues of correctness and efficiency we will see more of this as we see the example of data types let me start by giving a simple example of the data type and that is a dynamic set a set is defined as a collection of objects suppose we also had operations  which would let us modify that collection of objects  which means add or remove an object of that collection such a set we would call it as a dynamic set  refer slide time  4  47  we call it as dynamic  because we are changing the set which is the collection of objects we will create data types for such dynamic sets what are the kinds of methods that you have in a dynamic set ? you would have a method to create a dynamic set  which would be a method new there would be a method insert  to insert an element in to a dynamic set s is the dynamic set and this method has two parameters let us say  the set s and the element the result is an instance of the set itself which gives a new set  another set and also includes the element v in it similarly the delete method removes the element v from the set s these are the two methods for updating the set new method is for creating or constructing the set and isin is one of the access methods all of it is telling us whether the element is in the set or not the return value is of type boolean if v is in the set then it is true otherwise false axioms are the one which define how the operations should behave we can write axioms in the following form when i create a new set and if the set is empty then the answer should be always false  no matter what v is if i have a dynamic set s and i insert an element v in it then the resulting set which has v in it should be true  refer slide time  5  37  if i have a set s and when i insert u in it  then the resulting set has u in it then if i where to ask whether v is in the resulting set  i will know that only if v was in the previous set s thus the answer to this operation isin  delete  s  u   v   should be the same as the answer to this operation isin  s  v   provided v is different from u isin  delete  s  u   v  = isin  s  v   if v u suppose i have a set s and i delete v from it if i ask whether v is in the resulting set  then the answer should be false these are some basic axioms that define the nature of these operations and also the functionality of these operations still we did not specify how to do these operations or we did not talk about an algorithm or any procedure at the least we have talked about the code for implementing the dynamic set when you are talking about abstract data types  we are interested in more of the specification that is what the instances would be like and what are the operations permitted on those instances  and the axioms that govern those operations  refer slide time  6  46  some simple abstract data type that you may be familiar with is queue  but we will be doing it later let us see about stacks  refer slide time  8  52  what is the stack ? it is the collection of elements but this collection follows the last-in-first-out principle what does it mean ? it means that the element which is inserted last would be removed first if i insert an element and then i remove an element from this collection then the element that would be removed was the one which was inserted at the last the operation of inserting an element is called pushing onto the stack and the operation of removing an element is called popping off the stack  refer slide time  9  10  some of you might have seen this kind of toys it has a collection of elements for instance may be stack of trays in your mess what you do is when you put a tray  you put it on the top and when you remove it you would always remove the one which is at the top when you remove or pop of an element  it is always the one which you inserted at the last we are going to define the abstract data type that is supported by four methods which are the key methods the ? new ? is a method to create a stack in the push method when i specify an element o it adds this element to the abstract data type it inserts an object o on to the top of the stack  refer slide time  9  52  pop takes stack as the parameter and it does not take any parameter other than abstract data type when i say pop the stack  it just removes the top element from the stack if the stack is empty  they should flag an error stating that the stack is empty the top operation returns the top element  it does not remove it and that is how it differs from the pop pop operation removes that element but the top tell us only about the top element again if the stack is empty then top does not make any sense  it should flag an error  refer slide time  10  22  we can also have some support methods which will help us do these operations size is one such method size tells us about how many elements are there in the stack and isempty tell us whether the stack is empty or not the 6 methods that we saw are push  pop  new  top  size and isempty these are all the methods and hope you all understood about what these methods are doing  refer slide time  11  34  axiom governs the behavior of these methods if s is the stack  when i push an element on to s and then when i pop it  i should get back s while doing a top operation  when i push an element on to a stack and then when i do a top operation i should get v  because v would be the top element of the stack so far we have defined about the stack abstract data type  the methods and 2 axioms axioms may not be complete but this is what the axioms would look like how do we translate abstract data type into code ? we need 2 constructs for that and they are the interfaces and exceptions what is an interface ? an interface is a way to declare about what a class has to do and what are the various methods associated with the class it does not tell us about how those methods are done that would be a part of the implementation of that interface or a class  refer slide time  12  46  for an interface we just right down the various names of the methods and the parameters it is going to take in fact we do not even specify the names of parameter  we just have to specify the types of the parameter when we write a class for an interface  we will actually provide the code for those various methods  refer slide time  13  16  i might specify an interface for a stack and i am going to ask you to write the classes for that interface different people will write different classes to implement the interface in a completely different ways i can still use your classes or any implementation of the interface  in a program that i have written  provided that must meet the interface specification which i have given to you all i need to know is that the implementation meets the specification so that i can use that in the coding of my own program it helps us to separate the implementation from the specification and that is why it is a very useful programming technique  refer slide time  15  15  let us see about how a stack implementation looks like in java java has a built-in stack data structure but nevertheless we will define a stack interface we just define the various methods that are going to be a part of this interface there is one method called size  in which i need to specify the types of the parameters and the return type of the method i have not specified how these methods are implemented this is just an interface in an interface we need to know the types of the parameter when i am pushing  it takes a parameter of type object object is the generic type in java and all objects are derived from this type the method isempty returns boolean it just tells us whether the stack is empty or not the top gives you the top element in the stack and it returns an object it throws stackemptyexception  if this stack is empty then top   method should somehow signal that the stack is empty we are going to do that using the notion of exceptions void means it does not return any object or any value it does not return a stack but it is a method which is executed on this stack and it modifies the stack thus stack can not be considered as a parameter what is an exception ? exceptions are the mechanisms to handle errors when we have an error or when we reach some exceptional condition or an exceptional case in the execution of program  we throw an exception the term used in java is throw  refer slide time  18  07  as soon as an exception is thrown  the flow of control moves from the current method to the point where the method was called the idea essentially is that  when an exception occurs you delegate the responsibility of handling that exceptional case  to the procedure which called that particular method you will be clear  if you see an example i have two methods  one is an eat pizza method which throws a stomachache exception  also there is some dotted code if you eat too much of pizza  then there is a problem and you throw stomachacheexception the procedure public void eatpizza   throws was called in the method eatpizza    which is inside the stimulate meeting procedure when this stomachacheexception is thrown  the flow of control will come to ta.eatpizza    thus when this stomachacheexception is thrown  we will exist this method eatpizza   and go to ta.eatpizza     refer slide time 19.07  in the coding after  ?  there are bunches of other statements that would not be executed the flow of control would interrupt the dotted point and would reach ta.eatpizza    there is also a notion of try and catch blocks when the exception is thrown what happens to the variable that we have modified ? it depends upon the procedure call  think as if we are returning from this procedure stomachacheexception or a method if those are local variables then you do not want to see them if they are global variables and if it is modified in the if-loop  then those modifications are carried over to the ta.eatpizza   method there is something called as a try and a catch block if you think that there could be possible exception in this  ta.eatpizza    method  then you enclose the method within a try block start it with a try  open a bracket  and then include the method which you are calling and close it with a bracket if there was no exception raised in ta.eatpizza   method or this particular exception stomachacheexception did not get raised in this method  then we will just skip the catch block  then go on to the statement  after the catch block if an exception was raised in this  ta.eatpizza    method  because this method might raise many exceptions if this  stomachacheexception  exception was raised in the method  then we would come in to the catch block and execute the statements if the method raises an exception  then if that exception is caught through a catch block  then we would execute the statements which are written inside the catch block any kind of statements can be written inside the catch block  not necessarily system.out.exception  refer slide time  20  50  what would happen  if i did not write the catch block ? this procedure simulate meeting  would throw the exception to the point from where its parent procedure was called when stomachacheexception throws an exception  the ta.eatpizza   method would also throw an exception  then the control will go to procedure from where simulate meeting is called it is fine if it catches the exception at that point  if not it will throw an exception to the high level procedure and finally your procedure will stop with your exception appearing at your console  refer slide time  22  25  in this manner it is getting propagated all the way up to  where your procedure stops and the exception is shown to the user system.out.println is just the method to print the statement  refer slide time  23  41  an exception is really a java class in which i am creating an object or an instance for this class then i am initializing that instance with any parameter and i can specify some set of parameters in the statement given below stomachacheexception  ? ouch ?  ; stomachacheexception itself is a class and for this class  i am creating an object by making a call to the statement stomachacheexception  ? ouch ?  ; when the catch statement is caught  e in that statement would get assigned to the object that is created by stomachacheexception  ? ouch ?  statement the try and catch block would come together if the method were not enclosed between try and catch  then the exception would just get propagate upwards in the procedural hierarchy stomachacheexception would throw an exception and the calling procedure of simulate meeting would throw an exception  till it is caught at some point if not it reaches the console what does the name of the class followed by brackets and some parameters written would signify in java ? for example  stomachacheexception  ? ouch ?  ; in java it signifies  that you are creating an object for this class and you are invoking the constructor method with ? ouch ? as the parameters  refer slide time  24  07  the try and catch block are a method for listening exceptions and catching them as i mentioned before  a catch block can contain anything it does not mean that it should have only system.out.println  it can also throw an exception in turn  refer slide time  26  16  it also helps us to exit from the program when an exception occurs if you throw an exception in any method  then you need to add a throws class next to the method name when we wrote the method eatpizza   we had  throws stomachacheexception a method can throw more than one exception in java everything is really an object stomachacheexception is the name of the class public class stomachacheexception extends and the statement given below is the constructor method for the class thus the name of the constructor method is the same as the class name public stomachacheexception  string err  the constructor method takes a single parameter  which is a string super means that it is calling the super class with the same parameter  refer slide time  28  00  again as i mentioned before  if you never catch an exception it will propagate upwards  along with the chain of method calls  till it reaches the console since the stomach ache exception is extending a run time exception  it will call the constructor method for the run time exception  refer slide time  28  17  if a particular method throws more than one exception  then you will have to specify all those exceptions which it throws  next to the method name even in the try block you can have many catch statements first we can catch one particular exception followed by some other exception and so on look at your java book for more details  refer slide time  29  10  let us look at the stacks we had created the interface for our stack we are going to implement the methods and there are many ways of implementing a stack first we are going to implement using an array let us say the maximum size of our stack is n and i am going to have an array of n elements of the stack i am going to have a variable t  which will tell about the location of the top element of the stack the variable t gives the index of the top element in the array s the first element will be at location 0 and then when i push another element it will move to the next location and so on  refer slide time  29  43  i have actually listed out an entire implementation for our stack interface my implementation is called array stack because i am using an array to implement the stack the statement mentioned below says that i am implementing the stack interface public class arraystack implements stack implement stack means  it is implementing the stack interface that we provided i have set with a default capacity for the stack which is 1024  otherwise the capacity of the stack would be in the variable n final is just specifying that the value of capacity is always a constant and it can never be changed  refer slide time  30  48  s is an array which is going to hold the elements of the stack thus s is an array of object and t is the index of the top element initially t = -1  because there is nothing inside the t t = 0 means the top element is in the location 0 and when the stack is empty t = -1 public arraystack   public arraystack  int cap  the above two statements are the constructor methods if you do not specify anything or if you just call the array stack without any parameters  then i am going to create a stack whose capacity is 1024 if you call array stack with some number let us say 37  then i am going to create a stack of size 37 what should size do ? size should just return how many elements are there in my stack if t is the index of the top element  then t + 1 elements are there because we just started from zero the stack is empty if t = -1 that is t < 0 if t < 0 then isempty   method would return true  otherwise it returns false  refer slide time  32  42  if i want to push an object ob in to the stack and if the size of the stack already equals n  then i should throw a stack full exception else i should first increment t and then put the object at the new incremented location s  + + t  is the first increment  and then put the object at that location i have to give you the top element of the stack for that  i should check whether the stack is empty or not if the stack is empty then i throw a stack empty exception if the stack is empty then the flow of control would exit from throw new stack empty exception  ? stack is empty ?   and when the stack is not empty it just returns the top element of the stack s  t   if i want to pop the stack  then once again i check if the stack is empty if the stack is not empty then i save the top element in location elem then i decrement t  because i am removing the top element and to the location which i set earlier was set to null that is i dereference it because earlier at the top location t  it was initially 37 and i had an object in that location i need to remove that object and decrement t to36 then i return the top element pop also returns the top element s  t  = null ; return elem  refer slide time  34  02  stack empty exception is a class and i use new to create an object or an instance for this class why should we necessarily dereference the objects ? it is best to deference  because you can remove those objects or you can get rid of those objects otherwise they will lie in your memory thus t is just an integer and it is a private member of this class  private because no one else knows about t and s is an array of objects and s can therefore access the element of this array  refer slide time  36  54  the array implementation is very simple as all the operations were taking constant time none of the operations required time propositional to the virtual dependent upon the number of elements in the array in this stack at that point each of those methods take o  1  time the problem is that we are working with an upper bound on the size of the stack this upper bound may have the default value1024  which we took in our example or it may be specified at the time of creation of stack the problem is because you do not know the size of the stack we might allocate a very large size for the stack  but it might be a waste of memory or we might allocate a very small stack in which we could not be able to run our procedure to complete  because we would soon have a stack full exception stack empty exception is the requirement of the interface  because the top and the pop methods are not defined  if the stack is empty  refer slide time  37  48  it is the requirement of the interface but a stack full exception is an artifact of this implementation if i had some other way of implementation  then i would never have to raise a stack full exception let us look at an example we will see how to implement the stack and never to have a stack full exception  so that we can always grow the stack when needed let us look at an application of stacks we have the daily stock prices of a particular stock if i give you the price on day 0  the price on day 1 and so on  then the span of a stock price on a certain day i is defined as the maximum number of consecutive days that the price of the stock has been less than or equal to its price on day i the following example would make it clear is the span of the stock price on day five and it is equal to the maximum number of days that the price of this stock has been less than or equal to day price for four days the price of this stock was less than or equal to day price and so the span of the stock price on day five equals 4  inclusive of the current day following picture would make it clear hence we are counting 1,2,3,4 and for day six  it is 1  2  3,4,5,6 that is 6 days  refer slide time  39  25  how can you compute the span in an array s  if i give you the stock prices in an array p p is an array of numbers to compute s  i   you are going to look at the price of the stock on day i  i-1  i-2 and so on the index k will start from zero and it will keep going down till the price of the stock on day i k is less than the price of the stock on day i the moment you find a case such that the price of stock on day i k is actually more than the price on day i  you stop the loop which is given below  otherwise you keep incrementing k if p  i-k  p  i  then k ? k + 1 if this quantity p  i-k  p  i  is less  then you increment k else you say done is true done will help us to exist the repeat-until loop it will exit the repeat-until loop if done is true or if k equals i  which means that you have reached day 0 then the span will be determined by the value of k  because k tell us the span of stock price on day i thus s  i  gets the value k   s  i  ? k   this is one way of computing this span  refer slide time  41  07  how much time does it take ? it takes time as we can see on the slide why should it take time ? because we are repeatedly comparing it how many times the repeat-until loop can be executed in the worst case ? it is i times  where i varying itself from 0 through n-1 the total number of times one of this statement get executed might be or  thus the running time of this algorithm is o   in the worst case question is can we do something better ? yes  as we are talking of stacks  we can use a stack to do something better to compute the span  we need to know the closest day preceding i  on which the stock price is greater than the price on day i  refer slide time  43  26  in the example  for day 5 i need to know the closest day preceding day 5  on which the stock price is greater than the price on day 5 on day 1  it was greater for day 5  the span would be 1,2,3,4 i am going to call the quantity h  i   h  i  is the closest day preceding i  on which the price is greater than the price on day i thus h  3  = 2  h  2  = 1  h  1  = 0  h  0  = -1 and h  4  = 3  h  5  = 1  h  6  = 0 once you computed h  how can you determine the span ? the span for the price on day 5 is 5-1 that is 4 if we can compute these h quantities  we can easily compute the span  refer slide time  45  31  how do we compute the h quantities ? suppose those 6 quantities which is in the slide  were the prices that i have given from day 1 through 6 can h  7  be 1 ? i have not told the price on day 7 but through the definition of h  7   it is the closest day preceding 7  on which the stock ? s price is larger than price on day 7 but that day can not be 1 at all  because the price on day 2 is larger than the price on day 1 similarly that day can not be 3 or 4 what are the possible values that h  7  can take ? 2  5 and 6 are the only possible values that h  7  can take we will store the indices 2  5  6 in a stack 2 will be at the bottom of the stack  5 will be above that and 6 on the top to determine h  7   first we need to compare the price on day 7 with price on day 6 suppose the price on day 7 is less than the price on day 6 then what is the h  7   it is 6  but if the price on day 7 was greater than price on day 6  then i will compare with price on day 5 if it is greater than the price on day 5  then i will compare it with 2 if it is greater than 2  then it is minus one that is h  7  = -1  refer slide time  46  41  suppose the new bar i have drawn is the price on day 7 and it is greater than the price on day 6 then h  7  is 5 the first price greater than the price on day 7 in the comparison gives me h  7   but once i know h  7   i should update my stack now what should my stack contain ? earlier it contains the indices 2  5  6 and now it contains 2  5 and 7 it is clear because h  8  can never be 6  i should get rid of 6 by replacing it with 7 you can see that the stack would be the right way to do these things  refer slide time  47  40  let us look at the procedure let d be the stack and initially it is empty when i get a certain price  i am going to compare that price with the price on the top of the stack if it is less than the price on the top of the stack that is on the top of the stack we had 2  5  6 and if the 7th bar is less than the 6 then it is just what is there on the top then we are done  the index on the top of the stack will give the h value if it is more than the price on the top of the stack  then i will pop of or remove the top of the stack  because i need to compare with the next one i pop of because i will not need that quantity any more  refer slide time  48  36  as you recall from the previous slide  since 7th bar was more than 6th bar  i can actually get rid of 6th bar because in the stack  i do not need that next time we are going to go around the loop till either done becomes true when it becomes true it says that i have found a price which is greater than the current day price but if done never becomes true and the stack becomes empty then h = -1  exactly that is being set here in the below statement if d.isempty   then h ? -1 else h ? d.top   when i exit this  p  i  p  d.top     loop  the stack is empty then h = -1 else h is the top value of the stack once i know h  i can compute s  i  and keep it i will push i back in because in my previous slide when i got this 7  i now push 7 in for my next computation how much time does this take ? may be n times while loop might execute a lot of times and why this should take only n time is the worst case or n ? it may be   refer slide time  49  52  how many elements do we pushed on the stack ? each element is pushed once and we have pushed at most n elements on to the stack  if there are n elements to begin with every time when the while loop is executed  we pop of one element from the stack how many times the while loop gets executed ? it is n times every time when the loop executes  we are removing an element from the stack if the total number of elements ever we pushed on the stack was n  then how can we pop of more than n elements from the stack it means that the total number of times the loop executed is not more than n how many times do the statements inside the for-loop execute ? all most n times  because these are all a part of the for-loop if statements execute exactly n times what is the total time it will take ? it is order n and not  i am saying the total number of times the loop executes when all iteration put together is no more than n because every time the loop executes and when we go through the loop  we remove one element stack from the stack we never pushed more than n elements or the total number of elements we pushed on the stack is at most n one problem with our stack implementation is that we had to give maximum size for the stack we are going to look at an implementation in which the stack can grow  if it ever gets filled when we are pushing an element  if the size of the stack is n then i create a new array of length f  n  and i copy all the elements of my original stack s in to a and then i rename it as s it becomes my new stack with f  n  locations in it whose capacity is f  n   thus f  n  will be larger than n for us and so we had to increase the size of the stack i increment the top counter and i am trying to push the new object into my top location how should we should f  n  ? there are two strategies in which one could adopt one could either have a tight strategy or a growth strategy in a tight strategy  we always increment the size of the array by some constant c we just increment that is additive increment in the growth strategy  we double the size of the stack  refer slide time  54  02  we want to compare and see which of these is a better strategy we are going to think push as of two kinds one is regular push in a regular push  there was just space in the stack and you just push the element and it takes one unit of time a special push is one in which the stack is already full and you have to create a larger stack and copy the elements form the earlier stack to this larger stack and then push the element  refer slide time  55  40  you created a stack of size f  n  that costs f  n  units and you copied the n elements that cost n units and then you pushed one more element that cost one more unit the total cost of this special push operation would be f  n  + n + 1 let us see how the tight strategy behaves when we increment the size of the stack by c units for example c is taken as 4 initially i started with the array of size 0 when the first element came to push that was a  then i created a stack of size 4 and i push this first element in and the total cost was 4 + 1 when the second element came  i do not need to enlarge my stack  because i have space it just cost one unit which is a regular push the 3rd and 4th operation is also a regular push which costs 1 unit each the next one is a special push  i am not trying to push e because the stack is already full i need to create an array of size 8 and i need to copy the 4 elements  then i need to push 1 the total cost becomes 8 + 4 + 1 and these are all the 3 regular pushes then once again when i fill it  i will create an array of size 12  because c is 4 i am incrementing the size of the array by 4 units every time  refer slide time  56  07  i create an array of size 12 and i copy the eight elements then i push one more element  so i get 12 + 8 + 1 and so on and finally i have 16 + 12 + 1 when the size of the array was 4  i am going to call it as phase 1 and when the size of the array is 8  i will call it as phase 2 and so on let us see the total cost of the procedure  refer slide time  58  18  the pound symbol in the above slide is a multiplication operator in phase i  the size of the array is c * i in phase 1 it is c  in phase 2 it is 2 c  in phase 3 it is 3c and so on the size of the array is c * i what is the total cost of phase i ? t at the beginning of phase i  i first create an array of size c * i then i copy the elements of the previous array let us look at an example i first create an array of size 8 then i copy the previous 4 elements so i copy c * i-1 elements and it is the cost of copying the elements in to the new array then i will do c more pushes in this phase before the array gets filled c is the total cost of the 4 regular pushes that i have been doing the total cost is c * i + c * i-1 + c which is 2 times ci thus the cost of phase i is 2ci in each phase i am doing c pushes  then if i have to do a total of n pushes then i need phases total cost of phases would be 2c  1 + 2 + 3 + ? +  because the cost of phase is 2ci and this sum is roughly times 2c and that is not t  it is approximately o    so far we have seen the tight strategy we could also take creation as order 1  in that case the analysis would change slightly for the purposes of analysis i am just taking it as  if you are creating an array of size something  you take that much as the cost let us see the growth strategy in the growth strategy  i start with an array of size 0  when i get the first element i create an array of size 1 when i am trying to push an element i would double this array  so i create an array size 2 and i push this element when i try to push the element  i double this array and create an array of size 4 and push the element i have space for one more element and this is the regular push while pushing d when i try to push the 5th element  i will double the size of array again  so i create an array of size 8 and copy these elements and then push the 5th element and so on once again we can analyze the cost 1 is the cost of creating the array and you do not have to copy anything and 1 is the cost for pushing them here we created an array of cost 2  we copied 1 element and 1 was the cost of pushing we created an array of size 4  2 was the cost of copying  1 was the cost of pushing the element c and here was the regular push so it was 1 and so on we define a phase as when the size of the array was 1  we call it as phase 0 when it is 2 we call it as phase 1 when it was 4  we call it phase 2 and when it was 8  we call it as phase 3 and so on in phase i  the array has size  phase 3 it has size 8 and phase 4 it has size 16 and so on in the phase i  since the size is i spent units of time in creating the array then i have to copy elements of the previous array that is elements how many elements are left after copying elements ? elements are still left and they have to be pushed in  in this phase is the cost of pushing in those elements the total cost of phase i is + + which is  if we do n push  we would have log n phases  because the way the array is growing  refer slide time  1  00  55  the total cost of n pushes is going to be 2 + 4 + 8 + ? +  which is 4n the total cost of n pushes is 4n growth strategy and in the tight strategy it is  hence this is clearly a better strategy data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 3 queues and linked lists in the last lecture we looked at stacks as a data type we saw how to implement stacks using an array today we are going to look at queues and linked list and in the later part of the class  we are going to do sequences in particular the first part of the class i am going to do queues  linked list and double ended queues  refer slide time  01  22  what is the queue and how does it differ from the stack ? the stack followed the last-in first-out principle  the element that was inserted last in to stack was the one that was removed first  refer slide time  01  34  queue on the other hand follows the first-in-first-out principle whoever joins the queue earlier is the first to be removed from the queues that is first to be processed you are all familiar with the queues in a queue for instance there is a notion of a first element and the notion of the rear element when an element is inserted in to the queue  it comes at the rear if i remove an element from queue it is the element which is sitting at the front end would be removed we always insert an element at the end and when we remove an element it is always the element at the front is removed the queue is also an abstract data type and we can define a few methods on the queue the methods given in the slide are the standard operations the method new would create a queue and enqueue is the method to add an element to the queue and dequeue is to remove an element from the queue when you dequeue a queue or when you remove an element from the queue  you get another queue  refer slide time  02  48  the front is the method which gives the first element of the queue how it does differ from dequeue ? it does not remove the front element  it only tell us which is the front element of the queue  refer slide time  03  46  we also have some other support methods  to implement the queue one could be size and the other is isempty size would tell us how many elements are there in the queue and isempty would tell us whether the queue is empty or not it would return true if the queue is empty else it would return false just as we defined axioms for the stacks  you can define similar axioms for queues if i create a new queue and i insert an element or enqueue an element v and then when i say what is the element at the front of the queue it should be v and suppose i create a new queue and enqueue an element and then i dequeue an element  then i should get the empty queue which is the same as whatever obtained if i just called new similarly if i had a queue and i enqueued an element w  which means i added an element to the queue then i added another element v to the queue  thus w is ahead of v in the queue if i call front  first i will get all the elements of the queue  followed by w and then followed by v the element in the front of  q  w  is the element at the front of the queue why i have written front of  q  w  and not front of queue ? if i have just written front of queue  then it would not have been defined if a queue is empty then there is no notion of front of the queue that is why i have written front  enqueue  q  w    same thing as before in which i had a queue q  if i insert w in to the queue then i insert a v and then i removed an element the element which was at the front of queue would be removed  if the queue was empty then it would have been w the following operation is the same as in which i had a q  i added w to the queue then i removed an element from the queue  then i added v again the queue that i have obtained as the result of the below mentioned 2 procedures should be the same dequeue  enqueue  enqueue  q,w  ,v   = enqueue  dequeue  enqueue  q,w   ,v  let us check out whether the result is true let us assume that the queue was initially empty what does this statement dequeue  enqueue  enqueue  q  w   v   gives ? first i added w then added v and then i removed an element if i removed an element from the queue i would get w  that is w is removed then i get v as the remaining queue let us look at this enqueue  dequeue  enqueue  q  w    v   queue is empty  i added w to the queue then i removed an element and once again i have left with an empty queue then i enqueue v  thus the queue has v in it if queue is empty then in both the cases the queue will have only v in it at the end of the procedure if queue is not empty then i enqueued w  then i enqueued v again hence i have a queue in which first i have all the elements of q  followed by w  followed by v when i dequeued  i will be left with the original q without the front element  followed by w and then followed by v let us see if we get the same thing in enqueue  dequeue  enqueue  q  w    v   i started with q and i added w to it now i have queue which has q and w then i dequeued which means i removed the front element of queue the queue contains all the elements except the front element  then i have w in that queue and i added v at the end thus i get the same result how do we implement a queue ? we are going to use an array in a circular fashion to implement the queue what does it mean ? suppose someone tells that the queue is never going to be larger than n elements i am going to allocate an array of size n i am going to have 2 variables f and r  f for front and r for rear f is the index of the front element that is f will be referring to the front element of the queue r is an index which is the element following the rear element the blue part is the one which is occupied by the queue  refer slide time  08  11  how did the queue reach the blue colored part ? i would have started with the front that is the first element i inserted must have come to the 0th location then the next element i inserted must have come to the 1st location and the 3rd element must have come to the 2nd location and so on then i also delete the elements when i delete  an element goes away in effect the elements in the queue drift right and hence the front and the rear element has moved to right this implies that we have deleted f-1 elements it is not completely accurate i had said something like in a circular fashion what does the circular fashion mean and why am i saying such a thing ? let us say that we kept inserting the elements in queue i insert another element then i insert another element and at one stage i can not insert anymore elements because i have already reached the end of this array but i have a space available in the front then i will wrap around and start inserting the elements your queue in some point will look like the one which is given in the slide below the front was at the left of the rear but now front is at the right of the rear because we have queue which is now starting from the right side and going to the left side when i insert an element it will still come to the location and then to the next location and so on  refer slide time  10  15  when we started the front was referring to 0th location that is f should have been at minus one  because the front refers to the first element of the queue if there is nothing in the queue then f should be minus one and rear refers to 0  because rear refers to an empty location  refer slide time  10  59  what does if at some point i reach a situation when f = r ? is that empty or full ?  refer slide time  11  41  what will happen when it becomes empty ? suppose if i kept removing the elements starting from the location  i did not add any other element and then i removed all the elements before location where f would be located ? f would be increment to r  so f becomes r when f is r  queue is empty suppose i kept adding the elements to the queue when i add  r will move one step  another step and so on when i add an element close to location  then r would be referring to f again f equals r we will add the element there is an ambiguity and we have to resolve it in some manner f = r means  both empty and full since we will have a problem  if you do not know whether the queue is empty or full we will try and ensure that we never had n elements to the queue when the queue has only n-1 one elements  we will declare it before that is what we are going to do let us look at the code for enqueue this is just pseudo code if the size of the queue or the number of elements in the queue is n-1  then we are going to stop and say that the queue is full and we will return the queue full exception otherwise if it is not the case then add the rear location  put the element that you are trying to insert and increment r  refer slide time  13  30  the modn is required  because we need to do the wrap around since it is circular indices goes from 0 through n-1 only  r is already n-1 and i increment r at this r ?  r + 1  modn point then i do not want it to become n  but i want it to become 0 and hence modn is 0 and i will have it in r in the pseudo-code  size is the method and it should have been enclosed in brackets  refer slide time  14  13  what does the method size do ? it returns  n-f + r  value why it should not return r-f ? r-f is negative in the setting which is given in the slide  refer slide time  15  04   but in the setting which is given in the slide  refer slide time   10  59   r-f tells me exactly the number of elements in the queue r-f is the correct thing except it might be negative  refer slide time  15  04  how many elements are there in the queue which is given in the above slide ? it should be n r + f or n-f + r  which is anyone of these the quantity  n-f + r  would be the number of elements that you would get and this quantity is always positive  because r-f can at worst be minus n thus n + r-f would always be a positive quantity you can return this  n-f + r  as the size  as this will tell you the right number of elements check this out if you are confused isempty   is a method and we said queue is empty if f = r there was an ambiguity and we never had more than n-1 elements into the queue if f = r  that means the queue is empty and it is not full thus f = r returns empty also it returns true for this  algorithm isempty    method  refer slide time  14  35  for front if the queue is empty then it raises an exception  otherwise just return a front element we are not removing the front element as we are doing it in the dequeue method in the case of dequeue method  we will increment the front index and remove the front element by setting q  f  ? null  refer slide time  16  39  you can also implement the queue using a linked list we saw an array to implement our queue the disadvantage of using an array is fixed size if you know the maximum size that the queue can take then it is ok  but if you have no idea about the maximum size  then you could either use the method which we did in the last class were in when the size increases beyond what we have allotted  then we double the size of the queue you could either do that or you could use an implementation which uses a linked list what is essentially a linked list ? it has nodes and it has pointers which are basically referring to the next nodes in the list the first node is referred to as head of the list and the last node is referred to as the tail of list each of the nodes has some element or some data in it if i am going to use a linked list to implement the queue  then the question is which should be the front of the queue  whether the head node should be the front of queue or the tail node should be the front of the queue the head of the list should be the front of the queue  the tail of the list can not be the front of the queue  refer slide time  17  09  why the tail of the list can not be the front of the queue ? why can not i have my queue in which the 1st element is this  the 2nd second element is this and the third element is this ? the problem is with removing  note that i can not remove the torcezo element the linked list does not permit me to do this can i remove the torcezo element from linked list ? not directly  because to remove that element i have to change the 2nd pointer but there is no way of accessing that pointer and hence i can not remove that element i can remove the rome element  there is no problem in it  but i can not remove the torcezo element in a queue the removal is being done at the front that is we remove the element at the front of the queue since i can not remove the element which is sitting at the last place and i can not call this as the front of the queue i would like to have rome as the front of my queue  refer slide time  18  38  let us see how we are going to implement our methods suppose i have to dequeue which means that the front of the queue is the one which is at your left head part is the front of the queue and the tail part is going to be the rear of the queue if i have to remove the element at the front of the queue that is to dequeue  i should point the head to the 2nd node thus the front element will get removed and i just increment or just making the head point to 2nd node in this manner i can delete the head element very easily and also i can insert a new element to the head easily i just create a new node  connect the new node and make the head point to the new node thus inserting at the head is very easy the head is the front of the queue  i can just move the head to one step right and in that manner  remove the front element of the queue  refer slide time  20  44  if i have to add an element  enqueue has to be done at the rear of the queue in the above slide  first diagram is my queue and the last element is the rear of the queue i need to add a new element at the rear end of the queue the pointer should now get modified to point to the newly added element and the tail should be update to the next node because that will become tail and the pointer after the rear element should be null i can always add an element at the tail but it is difficult to remove an element in constant time  because to remove the tail node  i need to access the previous node the only way you can to do in this kind of list is to start from the beginning and move all the way to the right till you get to the tail node then you will be able to access the previous node what is problem in removing in the tail node ? the problem is that after i remove the tail node  what is the new tail of the list it is the last before node  i have to make the tail point to that last before node how do i get to that last before node ? i need to go through the entire list  to get to this node i am not saying that it is not possible  but it is a very expensive operation it is not worth while to remove at the tail and so we will remove at the head and add at the tail  which means the front of our queue will be at the head and the rear of the queue would be the tail so far we have seen the queue data type now i am going to introduce another data type called double-ended queue what is the double-ended queue ? it is a queue in which we support  insert and delete operations at both the ends we have insert first which is to insert at the front of the queue  insert last is to insert at the end of the queue  remove first is to remove at the front of the queue and remove last is to remove an element at the end of the queue also we have the first and the last operations such a thing is called double-ended queue  at both the ends we can do both the operations of insert and delete  refer slide time  22  36  a singly linked list is not a good idea to implement such a double-ended queue why because as i have said repeatedly  we can not remove the element at the tail or it is very expensive what is the good solution to this problem ? we are going to use doubly linked list to implement double-ended queues  refer slide time  23  28  what is the doubly linked list ? a doubly linked list has nodes with two pointers  one is next pointer and the other is the previous pointer we are also going to have two sentinel nodes each node has two pointers  one pointing to the next and one pointing to the previous  refer slide time  24  55  using such a list we can implement all the operations of double-ended queue in constant time the problem earlier was how to delete the node which is at the end the head and the trailer nodes are the 2 sentinel nodes i have a pointer to 2 sentinel nodes and to get to the last element  i just follow the pointer once and get to that element to delete that node  move to the previous port and set its next pointer to trailer and send the previous pointer of trailer to that node  refer slide time  25  15  we need header and trailer nodes in a doubly linked list these nodes are called sentinel nodes or dummy nodes because they do not contain any data inside them and they are just there to mark the start and the end this is useful how do you delete at the end ? i have to delete san francisco out of this list all i have to do is make the sentinel node point to the previous node and make that previous node to point to the sentinel node then the last node is deleted and in the slide  refer slide time  25  52  the last one becomes my new list that was the only thing i could not do in a singly linked list and i have shown it here hence all the other operations can be done in constant time  refer slide time  25  52  thus using a doubly linked list  we can implement all the operations of double-ended queue in constant time we can insert at the front  insert at the end  delete at the front or delete at the end all in constant time what is meant by constant time ? it is the time which is independent of number of elements in the list and your running time will not be depended upon the time double-ended queue is a fairly generic data type  it can used to implement other data types also suppose you had an implementation of double-ended queue and you can use that to make a stack or a queue let us see the implementation of a double-ended queue i can use the methods of this implementation to implement a stack for instance in the method top    the top element of the stack would correspond to the last element of our double-ended queue  refer slide time  27  17  thus the method top   would return the last element of the double-ended queue the method push   would correspond to inserting at the end of my double ended queue and the method pop   would correspond to deleting at the end of my double ended queue i could also make the last   to correspond to the front element of my double ended queue in that case the last   would have been my front and insert last  0  would have been insert front   and remove last   would have been my remove front    you can use it either way you like it size   just corresponds to the size of my double ended queue and isempty   corresponds to isempty of my double-ended queue because these are only dependent upon the number of elements in the queue similarly i can use a double-ended queue to implement the queue front   gives the first element of the double-ended queue  enqueue   corresponds to last that is it inserts at the rear when i say dequeue  it removes the first element of the double-ended queue if i have a dequeue implementation  i can use the methods to implement a stack or a queue or one of these data types  refer slide time  28  59  we have used a double-ended queue to implement a stack or queue and this is an example of an adapter pattern thus adapter patterns implements a class using methods of another class in general  adapter classes specialize general classes and we can have certain applications  refer slide time  29  39  one application is that we can just implement by changing some methods for example we can implement a stack by using a double-ended queue another application would be an implementation of a stack we define an interface called stack and implemented it using an array that implementation is called an array stack what are the contents of array stack ? they are any arbitrary objects and i can adapt arraystack implementation to an implementation called integerarraystack which only uses integer objects in it all i have to do is suitably cast the type of the objects that i am pushing in to the stack or removing out of the stack there is another data structures called circularly linked list and it is very simple in that the last element is pointing to the first element of the list  refer slide time  31  38  there are no 2 pointers head and tail that is there is only one pointer which is pointing to the start of the circular list and you can use the data structure which is given in the above slide to implement both queue and the stack how will you use this data structure to implement a queue ? in a queue we will make the first node as the front of the queue and the last node as the rear of the queue how will i add an element at the rear ? to add an element before the first node  make the pointer point to the first node and make the head point to  it is not straight forward because if you mean the big pointer then how you will make this to point to the new node you have just created we want to create a new node at the end make the element which you are inserting to go into the new node and create a new node and copy the element rome into the new node make the head point to that new node and copying is not costly because here you are copying only the reference think about the circular list and it is a very straight forward in this manner you can insert an element in the queue  if you are using this circular list to implement the queue removing an element corresponds to removing the first one how do you remove the first one ? if i have to just remove the first element in the list  then how do i make the pointer from the last node to point to the 2nd node there is a problem in doing this what do you do again ? let us remove the 2nd node and copy the contents of that node to the 1st node we have to remove the rome how do i remove the rome ? i copy seattle to rome thus rome has seattle in it and i remove the 2nd node copying just means changing the reference hence we discusses about queues and double-ended queues we are going to the second part where we will quickly look at some sequences we are going to talk about vectors  positions  list and general sequences we will be using the data structures like arrays and linked lists to implement these data types  refer slide time  35  06  what is the vector data type ? vector data type is a sequence of n elements that supports the following methods which are given in the slide below these are indicative methods and not all the methods essentially in a vector it is a sequence where there is a notion of rank with every element of the sequence think of sequence of elements right 7,11,13,19 we know that 7 was the 1st element  1l was the 2nd element  13 was the 3rd element and 5 was the 4th element  refer slide time  35  34  with each element there is a notion of rank  and then i can have methods like elematrank r rank here corresponds to let us say rank  r  integers first element was the element at rank 1 and 2nd element was the element at rank 2 and so on suppose if i ask to give the element at rank r or replace the element at rank r by the element e  insert an element e at rank r or delete the element at rank r i could have such methods when i remove the element at rank r  for instance let us say the rank of the students in a particular class there is a departmental rank 1  the departmental rank 2 and departmental rank 3 and so on suppose the departmental rank 4 changes and goes to some other department the department rank 4 is the rank of the one who had the rank 5 before the same notion follows and everyone would move up by 1 rank let us see how to implement the data type using arrays i am going to have an array  in which i will have the element with rank 1  rank 2 and rank 3 and so on if i have to insert an element at rank r  i have to put an element in the location  which means i have to shift all these elements to one step right that is what i am doing and i put an element in that location  refer slide time  37  53  in a for loop  first we are moving n-1 one step to the right by this statement s  i + 1  ? s  i   first we are doing this for n-1  then n-2 where n-2 is moved one step to the right till r is moved to the one step right finally element e is put at position r and the size is increased by 1 where n sores the size of the vector s  r  ? e n ? n + 1 similarly when i am removing an element at rank r  i am essentially shifting the entire elements one step to the left all elements starting from r to n-2 and then s  i  gets s  i + 1   at the location r  i will get the element which was sitting at location r + 1 how expensive are these operations in the worst case ? order n in the worst case because we might have to shift up to n elements to the right or to the left this implementation is expensive from this point of view  if i have to do these two operations insert at a certain rank or remove at a certain rank i have 2 in the worst case spent order n time the other operations are faster how much time does the elematrank  r  takes  because i just go to the location in that array and retrieve the elements sitting there replaceatrank  r  e  again order one  because i just go to the location and replace that element with element e  refer slide time  40  06  the chart given below shows the time complexity of various methods all methods except inserted at rank and remove at rank take constant time but these two methods could take order n time in the worst case  refer slide time  40  33   refer slide time  40  25  can you think of some other way of implementing this list ? we can implement through doubly linked list can you use a doubly linked list to implement a vector ? i am showing you here the operation of inserting at a certain rank there are 3 diagrams in the above slide in the 1st diagram  the 1st node is the header and the next one is the element at rank 1 following one is the element at rank 2 and the next one is the element at rank 3 suppose i want to insert an element at rank 2  i have to make a new node and put it between 1 and 3 how much time does it take ? create the node and to insert it  i make a pointer point to the next node and make the previous pointer point to the previous node this is how i insert newyork and the 3rd diagram is the one which i get after insertion there are 2 issues first if i know where i have to insert  then i take constant time but to find out where i have to insert takes order n times because if i have to insert at rank 17 then i have to step through that linked list till 17th position and then i would know to insert at that location  refer slide time  41  03  once i know to insert at this location then it is easy i will insert the element in 3 or 4 pointer changes the following would be a java code for inserting at a rank i am assuming the existence of the procedure nodeatrank  rank   this is the method that i am going to be defining shortly what does this method do ? given a rank  it tells me which is the node at that rank  refer slide time  42  39  for instance  to insert the node at rank 2  first i will call the procedure with rank 2 it will give me the 2nd node of the 1st diagram because that is the node at rank 2  refer slide time  43  05  i have to get to the previous node of that node if i get to this node  next  at rank 2  then i get to the previous node  next.getprev    and this is the node previous to rank 2 which is at rank 1 the new node that i have to insert has to be between next and prev i create the new node and i set its previous field to refer to the previous node and i set its next field to refer to the next node dlnode next = nodeatrank  rank  ; dlnode prev = next.getprev   ; dlnode node = new dlnode  element  prev  next  ;  refer slide time  43  25  dlnode prev = next.getprev   ; ? this was the node at rank 1 and dlnode next = nodeatrank  rank  ; was the node earlier at rank 2 in this manner i create the new node at the appropriate place and then i also need to check the previous and next field of the prev and next node that is what i am doing here next.setprev  node  ; prev.setnext  node  ; size + + ; do not get intimated by this code  it is just doing what is shown in the picture i am assuming the existence of this procedure dlnode next = nodeatrank  rank  in which  the given rank will tell me which is the node at that rank in the original list  refer slide time  45  07  i will show you the process of deletion if i have to remove the element at rank 3  i will first find out the node which is at this rank so i get to the node which is selected in the 2nd diagram and then i have to go to the next node  go to the previous node and update their next and previous pointers thus the pointer will point to the next node and previous node and in this manner i will get rid of that node and at the end i will get the 3rd diagram as the final node similarly i can write down the java code for doing this once again i am assuming the procedure nodeatrank  which tells me about the node which is sitting at that rank  refer slide time  45  27  how do i implement this procedure nodeatrank ? there is nothing else i can do except that i march to the list and keep incrementing my counter till i reach that rank i have done essentially that except a small improvement  that if the rank is less than the number of the size of the list by 2  then i start from the header and if it is more than size by 2 i start from the tail just to small improvement nothing more you do such a thing  because if your list has hundred elements and you are looking for the element at rank 98  then there is no point to start from the header it is better to start from the tail  refer slide time  45  34  that is as far as the vector abstract data type is concerned except that when i say remove the element at a particular rank or insert the element at a particular rank as you have seen both the implementations we have a problem whether we use an array or a list to do that implementation  we seem to require order n time in the worst case  just to be able to find out where the element correspond to that rank is in an array  we know the element corresponding to that rank is and we have to move the elements when we insert or delete linked lists are better in supporting node based operations i have a linked list and i tell you delete this node  if it is a doubly linked list you can delete that node in constant time if i say this is a node and insert a new node after this node i could insert a new node after that node in constant time or if i say delete the inserted node before this node  again i can insert a node in constant time  refer slide time  47  11  we have the data structure which is very efficient  which can do constant time operations provided that we give access to the node some how i access the particular node at which we want to insert or delete that is what mentioned below removeatnode  node v  and insertafternode  node v  object e  you can remove at a node or you can insert after a node and you can insert before a node all in constant time however when i give you access to a particular node then in some sense  i am also telling you how i have implemented my list whether it is a doubly linked list or a singly linked list and what are the pointers and stuff like that  refer slide time  47  56  suppose i want to hide all those information  so that you can still use node based operation without knowing the actual implementation of how the thing was done so one can have different implementations we are going to do this using a notion of positions position is an abstract data type which intuitively captures the place where a certain element is stored in your data structure  there is only one method which is associated with the position and is the method element  refer slide time  48  57  given an object of this data type position  i can only call this method element on that object and that will tell me about the element which is sitting at that particular position if this is not making much sense  then think of position as reference to a particular node think of it as a pointer  because using that pointer you can access the element which is situated in the node and nothing else you can not use that pointer to update the next or the previous fields  or you do not even know how the node is implemented you do not need to know whether the implementer has used a doubly linked list or singly linked list or a circular list it is an abstract data type which hides all the details and you can only use the method element    on the abstract data type position  refer slide time  49  41  with the notion of position  there will be a relative order of positions jus as in the case of a linked list there is the 1st element in your linked list  2nd element and the position is referring to the 1st element or the 1st node or the 2nd node or the 3rd node of the list  refer slide time  50  35  similarly 1st position  the 2nd position  the 3rd position and so on given a position that  there is the notion of the position before which refers to the node before that position and a position after that position  refer slide time  51  23  we can now define a list abstract datatype which uses the positions what would this abstract datatype have ? it would have generic methods like size   and isempty   and it could have query method  given a particular position i can have a method which asks is this the first position of my list if it is this will say yes and otherwise say no and whether it is the last position of the list i can have excessive methods like first    last    before  p  and after  p    refer slide time  53  11  first will give me the first position  last would give me the last position  before  p  will give me the position before this position p and after will give me after this position p i can have update methods like swapelements  p  q   what does this do ? given a positions p and q  it swaps the contents of these positions whatever may be the elements sitting at these 2 positions it swaps the contents i can replace the element at position p with e  replaceelement  p  e   and similarly i can insert the element e  insertfirst  e   at the very first position i can insert the element e  insertlast  e   at the last position and so on using a doubly linked list you can actually implement all of these methods in constant time the list abstract datatype is just as the same as your linked list data structure except that we are getting an abstract datatype implementation of it we are trying to capture all of those methods that you can do on a linked list as an abstract datatype this datatype can be implemented using a double linked list and it can be implemented using a singly linked list except that it is more efficient if you implement it using a doubly linked list in the doubly linked list all of these methods can be done at a constant time using a singly linked list some of these methods might take linear time in the worst case finally we have the notion of a sequence abstract data type we talked of the vector abstract data type where there is a notion of rank associated with each element then there is a list data type where there is a notion of positions and the sequence abstract data type has both of these it combines the vector and the list abstract data type and it inherits both of these interfaces and that is multiple inheritance  refer slide time  53  19  besides the methods that are listed for vector and list abstract data type  it has two additional methods which helps you to go from one to other given a particular rank r  the method atrank  r  will return me the position corresponding to this rank given a position p the method rankof  p  will tell me the rank corresponding to this position you could have an implementation of the kind which was given in the slide for a sequence in the above slide  given an array in which each element of the array refers to the position and the point 2 is same in both the cases with the given particular location  i can identify the rank which it corresponds to by looking at the element how is the method rankof  p  implemented ? p corresponds to a position  a position here is the thing which is given in the middle of the diagram given a particular position and how do i know the rank corresponding to that position i just look in to the 3rd element that gives me the rank corresponding to that position given a particular rank how do i determine the position corresponding to that rank suppose you gave me rank 1  when i follow 1st reference  1 is the position corresponding to this rank at that position there is an element stored which is newyork at the position besides the element  there is something else stored which is kind of provides cross reference at each of these positions i have an element stored and a rank of that element in my sequence suppose i had to insert an element at rank 2  i am going to create new position and the element would sit in that position and 2 would refer to that position and all of these will have to move to one step right not only have to move to the right  we have to change the ranks and update the position again inserting at the particular rank will take order n time of the worst case and similarly deleting an element if i had given particular position and if i wanted to delete the element at that position  refer slide time  56  07  how do we delete an element at a certain position in the case of a doubly linked list ? you need to think about this so leave it as an exercise this is a comparison of sequence operations  you can implement a sequence using an array in the picture i have shown you previously and you can also implement a sequence using a doubly linked list this would be the worst case of running time you can see in the case of an array implementation  if you want to insert an element at a certain rank or you want to remove an element at a certain rank it will take order n time if you want to insert after or insert before a certain position  this will also take order n time and if you need to remove an element at a certain position  this will also take order n time  refer slide time  57  51  not so in the case of a doubly linked list because then you can just zap out the element from there you can just update the pointers before and after and do these in constant time but then what becomes more expensive is  because in a doubly linked list you can not figure out the rank of an element i have to go to the entire list to figure out the rank any rank based operation will take order n time  whether you want to find the rank of n element or you want to find out the element at a particular rank  find out the position corresponding to certain rank  all of these would take order n time we learnt about queues  double ended queues and also how to use linked list and doubly linked list to implement the these data types then we also looked at the vector abstract data type  the list abstract data type which is essentially a concretization of the linked list data structure and we also looked at sequence data types which is basically inheriting all the methods of your list data type and your vector data type data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 4 dictionaries we are going to look at the dictionary abstract data type we are also going to see how binary search is done  what are all the analysis for binary search and then we will go on to hashing  hash table  how hashing is done  see the collision resolution techniques and then in the next class we will follow up with more hashing techniques  refer slide time  1  17  a dictionary is an abstract data type that stores elements which can be located very quickly one example that we can have for a dictionary is to store bank accounts  refer slide time  1  37  what is the notion of the key  when you store bank accounts ? the notion of a key is your account number  bank account has lots of information associated with it  but you are going to access the bank account or data associated with that account by using the account numbers thus the account number becomes the key  refer slide time  1  53  as i said account stores wealth of information  it could be your current balance  it could be the name and address of the account holder and it could be the list of transactions done in the last few days and so on when you have to access any of the above information you need the notion of the key a dictionary is something that stores the elements when we talk of an element we will mean all of the above additional information which is also given in the slide below when we talk of key  the key would be the account number that helps us to access the particular information any application that wishes to do any kind of operation on an account  will have to provide the account number as key the process can not be continued without a key  refer slide time  2  14  the dictionary is basically an abstract model of a database it is going to store the key-element pairs the key could be an account number or it need not be an account number in all the case suppose if i have the student records then what would be the most natural notion of a key your entry number which is not an integer  you may also have characters and so on anything uniquely identifies particular student or particular account becomes the key  refer slide time  3  03  one of the main operations that is supported by a dictionary is searching by key what are the kinds of method that we have in a dictionary abstract data type ? the standard container methods that we have seen for queues and stacks and so on one is size   which tell us how many elements are there in the dictionary  isempty   tells whether the dictionary is empty or not and elements   which returns all the elements in the dictionary then we will have query methods given a particular key find the element corresponding to this key  findelem  k    in settings you might have the same key associated with many different elements and one could have such a kind of settings we will see example of this kind later then given a particular key  you want to return all elements who have that key you could have update methods given i might want to insert an element e which has a key k  to insert that in to my dictionary  to remove an element with a certain key and to remove all elements which have a key k  refer slide time  3  33  just you would think it as a standard thing  but now you should remember the notion of the key and that is crucial for help in searching without the key it will be very difficult for us to search through the database we will have a special element nil  which will be returned by an unsuccessful search it means that if i am searching for a particular key  there is no such element with that key in my dictionary and then my procedure will just return a nill this is some special element  refer slide time  5  02  one thing that we will keep in mind is that we only require comparison of keys for equality given two particular keys  we are not going to say one key is less than the other and one key is more than the other this is not really required  because all you doing is searching for a certain key all that is required is  given two keys you want to say whether they are the same or not  refer slide time  5  31  for instance again for student record  i could have name as your key in that case you know there is really no notion of taking two names and saying one name is smaller or larger than the other only operation we require is comparing keys for equality we do not need any order on our keys dictionary is the abstract data type then in the next few lectures we will see how this particular abstract data type can be implemented we are actually going to see many different ways of implementing this abstract data type you already have seen some ways of implementing this abstract data type  refer slide time  6  36  for instance you could use an array or a linked list to implement a dictionary suppose if i had student records  how would you use a linked list to implement this dictionary ? every node would have the key which is the entry number and all the data associated with that particular entry number it is a very inefficient but it is the way of doing things there is no notion of a predecessor or successor if we were using a linked list how would we organize it ? that is up to you  you could connect them completely arbitrary manner the nodes could be in completely arbitrary manner or you could might want to organize them some way but you could just throw them arbitrary in to the linked list that is the implementation of the linked list and it is not very efficient today we are going to see the hash table and in later class we are going to look at binary tree  red or black trees  avl trees  b-trees these are all the mechanisms of data structures to implement this dictionary abstract data type which is a very important data type we are going to be spending quite some time on this particular data type in these lectures in java you have an abstract class called java.util.dictionary which lays out the specification also an interface called java.util.map before you get more into dictionary you have to understand about the abstract data type let us look at the problem of searching this is the small aside but we will see why i am making this aside and how it will end up to the subsequent discussions  refer slide time  8  23  the problem of searching is if you are given a sequence of numbers lets say these are your keys in the database i give you a single number which is my query for example i could have 2  4  5,10,7 are the keys in my databases and i query 5 what do you have to return ? you have to return the position of the key 5 in the database where is it sitting index of the found number or nil so 5 is sitting at position 2 and you return 2  while 9 does not appear anywhere and hence return nil this is the problem and we call it as searching let us see how we can do that you are going to see a technique called binary search i think all of you have seen this before but again we are going to recall the technique and do an analysis of it the key idea behind your binary search is divide and conquer this is a design technique that we are going to see in future classes also and applied to different problems in divide and search we really narrow down the range of elements in which we are searching for the query that is the key let me take you through an example  refer slide time  10  14  suppose the elements given in the slide are sitting in an array and these elements have to be in a sorted order  increasing or decreasing for binary search to work suppose i am searching for an element 22 what do i do in binary search ? i will go and look at the middle element  in this case it is the element 14 i will compare 14 and 22 as 22 is larger than 14 that means if that 22 lies in this databases it would lye to the right of 14  because these set of elements are in increasing order this means that the element 22 has to lie between 14 and 37 we use these 2 variables low and high to indicate the part of the array in which we have to search for our element initially we have to search for the element in this entire array but after looking at 14 we have figured out that we should search for the element only after 14 in the 2nd part of the array once again we have to repeat the same thing that is go to the middle element  compare 22 with this middle element as 22 is less than the middle element which means the 22 has to be to the left of 25 this means we are searching for 22 between 17 and 22 which is given in the 3rd part of the diagram in the above slide once again we go to the middle element  we compare the middle element 19 with 22 22 is larger and if 22 is their  then it has to be in the particular location and it is their hence we can say that 22 is at the location which is given in the slide and return this information you all have seen binary search before  this is nothing new perhaps i am going to write down a recursive procedure to do binary search the procedure given below in the slide is just a pseudo code and all of you can read and understand this quickly  refer slide time  12  15  once again we had the notion of low and high low was the lower end of the range and high was the higher end of the range which we have to search in the procedure call a is the array and k is the element or the key which you are searching for  low is for lower end and high is for higher end if low is more than high then basically that means you are invoking something wrong you just return a null that is the key is not there else you go to the middle element which is obtained by taking the average of low and high and check if the middle element is the key you are looking for if it is the key you are looking for then just return the position where you found the key  so you will return mid if the key you are looking for is less than the middle element then you know that you have to search in the left part of the array the left part of the array has a staring location low and the ending location mid-1 you are going to search in that  and this  return binarysearch  a  k  low  mid-1   is your recursive call to that procedure if it is not the case you come to the else and in this case what you have to do is to search in the right part of the array which means the mid + 1 to high else return binarysearch  a  k  mid + 1  high  this is how you can do binary search for small pieces of code and this is recursive you can also write an iterative procedure for this  there are exactly equivalent so that you know how to go from a recursive procedure to an iterative procedure i have just written down an iterative procedure also what is happening in our iterative procedure ? the low to begin with 1 and high to begin with n in the slide below blue color is the element 1 through n  let say in an array and we are doing the same thing roughly except now we are putting it in a loop and updating high and low every time after the first step low becomes mid + 1  because the element was larger than the mid element a  mid  > k  low becomes mid + 1 when the element is smaller than the mid element then high becomes mid-1 and we just go through this loop till we either find the key in that case we just return the location where we found the key or low becomes larger than high in which case you would come out of this do-while loop and return nil  refer slide time  13  54  i have just shown you how to write a binary search in two different ways you can write it in a recursive procedure or in an iterative procedure to do the same thing how much time does binary search take ?  you all know that but why does it takes time exactly the size of the problem is halved at every step range of the items that we have to search in is halved after each comparison if essentially the range of the elements in which i am searching for my key is n then after the first comparison it goes down to  after the second comparison the range goes down to and so on after log n comparison the range would go down to 1 when the range goes down to 1  either it is that element or it is not that element and you can stop you will roughly require comparisons if you have an array implementation that is your elements sitting in an array  then you can go to which ever location you desire in constant time  refer slide time  15  59  then each of these comparisons can be done in one unit of time that is in constant time and you can do the entire process in only o  log n  time when you do not write any base for log n  we will understand that it is base 2 suppose the numbers in that array were not in sorted order till now we assumed that the numbers were in increasing order you can do binary search even if the numbers were in decreasing order but if they were in sorted order you can do binary search  refer slide time  16  52  if they were not in sorted order and still you are searching for a key k there is nothing else you can do  but to go through the entire array one element after the other and compare your key against that that is the only thing you can really do the worst case time  then becomes order n if you are lucky you might get the element at the beginning of your search on an average you will get it  it may be 1st time you got it at the very first position  some other element you searched and got at the 3rd position hence in an average you are going to spend some order n time this is really the best you can do  if the array is sorted you can see there is a huge difference coming up already by sorting  if you were to sort the element to begin with  then you can search much more quickly given in the slide is a small pseudo code which is just saying that you run through the array one element at a time and compare your key against the element in the array  refer slide time  18  16  that ends my aside on searching and i am going to go back to my dictionary problem i am going to look at the setting where you are asked to implement a caller id facility for a large phone company given a particular phone number when a call comes in  based on the phone number you can figure out the name of the person who is making the call  refer slide time  18  30  that is what the company wants to do given the phone number you want to return the callers name let us assume that our phone numbers are all 8 digit numbers as in the case in delhi the range of phone numbers would be that is of 100 million phone numbers the number of different phone numbers is much less than this the range is 100 million  but may be delhi has only about a million phone numbers that is because not all numbers are present there are n phone numbers and n is much smaller than r r is the range which is 100 million because the phone numbers are 8 digit numbers and n is the actual different number of elements in your database you want to do this as efficiently as possible  refer slide time  19  14  you can use an unordered sequence to do this it means suppose the numbers given in the slide below were the phone numbers i have not put down the 8 digit numbers but let say these were the phone numbers and you could just put them in a list in any arbitrary order how much time does searching take ? order n  because you can not do anything else but to traverse through this list in the worst case you might have to go through the entire list hence it will take order n time to search for a particular phone number given a particular phone number  if you have to return the name of the person  you will have to take roughly order n time to do that  refer slide time  21  44  the list in the above slide is an unordered list that is there is no particular order how does one remove an element ? suppose a particular person decides to give up his connection you have to remove that particular data record from this list first you will search for the record then you will remove it searching itself takes order n time then removing also takes at least that much time once you found where the element is then you can do some small modification to do the entire thing in order n time why does inserting take only constant time ? because it is an unordered list  you do not really care for where you are putting the elements you might put at the very first location thus inserting takes very less time it is not clear whether this particular implementation is good for this application but there are certain applications in which  this way of doing things is faliable and one such application is where you have to maintain log files when you have to maintain some kinds of log file for instance any kind of transactions that are happening in the database you try to maintain log files  refer slide time  22  45  if there is any problem you can figure out  you can revert the transaction whatever was done or for instance in your system administration you would keep track of all the various activities that were happening in your system and maintain the log of them for log files  it is very rarely that you need to do search or removals but you need to add data frequently to your file every time when some transaction happens you need to add insertions are very frequent but searches and deletion are much rare in that case this implementation is good because insertion takes only constant time really you have to see between these three operations  search  remove and insert  for which is the operation being performed more frequently  to decide what type of data structure used to implement the dictionary data type  refer slide time  23  24  you can use ordered sequence also in that case let us say the elements were put in an increasing order of the key searching takes log n time log n provided  you had some kind of direct access mechanism into the thing which is used in array or some other thing which let you go to whichever element you wanted to go searching takes only o  log n  time  inserting and removing will take order n time because if all of them were put in an array then if i have to maintain the sorted order and to insert the element in a particular location  i have to shift everything to the right of the element insertion will take order n time in the worst case and similarly deletion you may have to move it back we have seen examples in previous class why does insertion take order n time ? first we have to search for where the element has to be inserted and once we know the position then this is an array in which all the elements were put in an array we have to create space there by moving everything to one step right in the worst case we might have to move order n elements to the right what is order n + log n ? it is order n  you have to recall your big-oh notation  order n + log n is order n this would make sense  when you have to do a lot of searching in your dictionary but not many insertions and deletions from the dictionary there is one other way which will be useful for our subsequent discussion and that is as follows let us say i take an array of size which is a huge array  refer slide time  25  28  ankur had a phone number of ? 9635-8904 ?  i go to location ? 9635-8904 ? in the array and put ankur name there and the additional information associated with that in that array at that very position which corresponds to ankur phone number all operations insert  search and delete will take only constant time why because i just have to insert a caller id capability what does that mean ? given a phone number  i want to know who is that person given the phone number i just go straight in to that location of the array and retrieve the name given a phone number i want to create a new phone connection  so i take the phone number and go to the particular location  put the name of the person who got the connection similarly if i want to delete a particular phone connection  i just go to the particular location and i remove the element all the operations take only constant time what is the bad thing with this implementation ? you are wasting a lot of space it is not that you can not do all of these operations very quickly you can but here space is turning out be an issue we are going to use what is called hashing we are going to use a hash table which will tell us do the things quickly  i have said o  1  excepted time it will not take two much space either and let us see the idea what was the problem with the previous technique ? in the previous technique we had 100 million phone numbers  so we had to create an array of size 100 million but let us say there were only 1 million users  most of the array was getting wasted there was nothing in their  refer slide time  27  18  suppose i could create a smaller array with only 1 million locations in it and mapped those 1 million users to locations in that array that is what we are going to do let us say in a hypothetical setting they were only small number of users i was only trying to keep the phone numbers of 5 of my friends but still i wanted to do something fancy i create an array of 5 elements and i take ankur phone number and i compute this value 96358904 mod 5  which is the size of my array i get a number between 0 and 4 in this particular case i would get 4 depending upon what i get  i put ankur at location 4 in my array i am not using too much space and may get away with constant time for insertion and delete let us see whether we can or we can not do that let me take another example just to make sure that you understand about the idea let us say keys are not phone numbers but entry numbers of students in this class your entry numbers looks something like this ? 2004 or 3 or 2 ?  then you have 2 characters and then you have another 5 digits at the end there are about 100 students in this class  the range of this numbers is huge this is infact  i do not even know the range because they can take different set of values but i would like to create a table of size of about 100  because there only 100 people in the class  why should i spend more space than that  refer slide time  29  37  let me pick up a hash function this function which i was using in the previous example mod 5 is also called as a hash function i am going to pick up a hash function which does the following it takes the last 2 digits of your entry number in this case ? 2004cs10110 ? would get mapped to location 10 it just picks up the last 2 digits of the entry number that is what i am going to do i am going to take each one of your entry numbers  going to look at that last 2 digits and i just have a table of size 100 i am just going to put you in that location  depending upon the last 2 digits what if i had a clash ? suppose i had another person with this entry number 2004cs50310 i do not know if they are in this class  there could be another person also the problem is these 2 are going to the same location number 10 we will come to this problem but if this problem did not arise then did you see that we are in very grade shape then you can do insert  delete and search all in constant time because it is very much like the array implementation that i showed you except that it does not waste all the space  refer slide time  31  12  let us see how we can address the problem of clash if 2 elements are getting mapped to the same location in our hash table  this is called the collision we have to find a way to address this issue how do we deal with the 2 keys which mapped to the same spot in our hash table ? we use the concept called chaining there are many ways of addressing this issue and today in our class we are going to look at the very first  simple technique called chaining  refer slide time  32  07  the blue color thing in the slide below is my hash table i am not going to put the elements in this hash table but i am going to have a linked list starting at each of the locations i am going to put the elements in the linked list suppose my hash table had only 5 locations in it may be i was just using the hash function which was taking the key and computing modulo 5 or some other thing if 2 or more keys were mapped to the 2nd location  i will just keep adding them to the linked list as you can seen from the picture given in the slide below  it was the case 3 keys were getting mapped to location 2 and 1 key was getting mapped to location 4 there were no keys getting mapped to locations 1 and 3 this does address the problem of collision but what is the other problem does it create  refer slide time  32  34  while we have resolved the collision problem and we are not able to do things in constant time any more in the worst case all the keys get mapped to 1 location in this hash table if all of them get mapped to the same location in the hash table then your data structure reduces to a linked list data structure which we know has the worst case time of order n for search and delete still insert has constant time whether each of the nodes in the linked list will contain both the identity in the phone number  caller id example ? each node will have both the phone number and all the data associated with that person who sits there  refer slide time  34  07  this is quick recap about how we are going to insert and delete of an element for all of these three operations you have to do essentially the same thing you have to use your hash function h  to determine where that key is in this table we have seen 2 examples of hash functions in one case we said we will just take the key modulo 5  in the other case we said we just take the last 2 digits of the key but they could be many different kinds of hash function and in the next class we are going to see what are the different kinds of typically used hash functions the last 2 digits can also be regarded as modulo 100 the reason i did not write modulo 100 because that was not an integer at all it was your entry number and it had some characters in it you are going to use your hash function to find the position of the key in the table then if you are going to search or insert or delete  do that in the linked list associated with that position there are options that you might want to maintain the list which is in 2nd position in a sorted order  you might want to keep it in unordered if you want to maintain in a sorted order then insertion is going to take more than a constant amount of time if you want to keep it in unordered then insertion is going to take only constant amount of time because you can just insert at the very beginning or at very end of the linked list  refer slide time  35  46  if you want to insert an element at the very end of linked list then you do not need to traverse the entire list to reach the end you can always have another pointer which always points to the end of the linked list and use that to update although there is no reason why you want to insert at the end suppose if you want to insert at the end  you could also do that in constant time always by maintaining one pointer we will have two pointers from the 2nd location  one going to the front of this linked list and one were going to the tail of the linked list use that pointer to add an element at the end of the linked list you can do ordering if you want to keep it ordered we are not saying that in the hash table you have to keep anything ordered if you want to keep it ordered you can do whichever if there is a notion of order on your keys then you can use that notion to order the elements an element with key k is stored in the slot h  k  in which h is the hash function and h  k  is the value of hash function the hash function is mapping the universe of all keys  let us say u to slots of the hash table if the hash table was of size m  so it is a function which is mapping from u the universe to 0 through m-1 we are going to assume for the rest of the discussion that the time to compute the hash function for given key k is a constant time because quite often we just have to do simple arithmetic operations to compute the value of the hash function we are going to assume that the time taken to compute the hash function is independent of the number of elements in the table  refer slide time  37  36  as far as the choice of hash functions are concerned  we are going to see in the next class what are good choices of hash function lot of research has done in this and then we will see what are the kinds of hash function that people typically use i just gave you 2 simple examples of hash function so as to motivate the concept what is the good hash function ? a good hash function is one which tries to distribute the keys uniformly over the table it should not map all the keys to location 1 or location 2 or any such thing  because then there would be too many collisions  your data structure would start looking like a single linked list and that is not what you want to have you want to have a hash function which distributes things uniformly over the table why uniformly  so that each of the list is small  refer slide time  38  53  an ideal hash function would do something like the following it would take an element and let us say i have a table of 100 locations it will pick at random one of those 100 locations then throw the element there this kind of it shows that every location would have roughly the same number of elements but this is not a hash function what i just said  you can not have a hash function which takes a key and puts it at a random location why this is not a hash function ? because when i am searching for the element  where am i going to go and look i do not know what random location it had picked at that point while this is an ideal hash function  it is not really a hash function but for our analysis we are going to assume such a hash function the hash function is just essentially does the following that it takes the element and throws it randomly  uniformly with same probability in one of those locations of the table we will call this as simple uniform hash function and we are going to use this for analysis we will use another term called the load factor of the table which is just a number of elements in the table divided by the number of slots  the size of the table and we will call this load factor alpha what is going to happen when we are trying to search and our search is unsuccessful ? it means that i took the element i computed the value of the hash function and i went to the particular slot in the hash table i went through the entire linked list and did not find the element at all  refer slide time  40  52  how much time do you spend ? i spend time propositional to the size of the linked list that i have to go through because i said computing the hash function takes constant time  you did not take any time to go to the right linked list but once you went to the right linked list you still have to step through the entire linked list  follow pointer by pointer till you reach the end the time is propositional to the size of the linked list what is the average size of your linked list ? if there are n elements that are thrown in my table and m is the number of slots and if i had this simple hash function which was essentially distributing the things uniformly then on an average you would except that each linked list is of size which was the load factor of the table the excepted number of elements that need to be examined is and the total search time where i am using this 1  2 denote the time taken to compute the hash function is roughly 1 +  this tells you that if your is let us say only a half than the excepted search time would be roughly a constant o  1 +  is excepted under the ideal hash functions you can always create a bad hash function for which the time taken will be order n o  1 +  represents the time that is spent in computing the hash function  refer slide time  42  57  we would not want a hash function for which every thing is getting mapped to one location because that is a linked list  why would you want to do something like that this again brings back to the same question  the efficiency of this data structure relies critically on the hash function we choose we will see what are the good hash functions in the next class designing hash function is much more of an art than science you have to really look at the data to design a good hash function i am going to show you in the next class some principle behind the hash function that is what kind of hash functions one should use but there is no theorem which says that this is the best hash function and you should always use this what happens when we make a successful search ? that was for unsuccessful search but when i make a successful search  it means once again i took the key  computed the value of the hash function  went in to the appropriate linked list and then i am walking through the linked list but i do not have to reach till the end of the linked list  at some point in the middle itself i may be able to find my element how many elements do i have to traverse in this process ? the position at which it was found but how do i know that what is the excepted time i would take overall ? excepted time i mean  the average time i would take to search all those n elements that are there in the database you can have many different ways of arguing it but let us do it in the following way suppose i was searching for the element which was inserted in to my database the element or the key that i am looking for was inserted in to the hash table when there were only 9 elements this was the element  if it was the element that was inserted then the excepted length of the list in which it was inserted was  that is what we argued just now  refer slide time  45  17  exactly m is the number of slots in the hash table in the case of successful search excepted number of elements examined is 1 more then the number of elements examined when that particular element was inserted when the element was inserted i = 10  i went through the linked list in which the element was inserted and appended at the very end i had to compare that element with all the various elements when i insert the element basically it is same as that the number of comparisons i have done is  1 more than the number of comparisons i would have done in an unsuccessful search we have to go through the entire linked list when we are inserting because to make sure that the element is not already their then we might insert at the end we could also insert at the beginning but it is the same thing  refer slide time  47  15  one could have an analysis which looks like the following this is not critical you can all prove it in different manners i am looking at the element 1 through n  there were n elements in my database when the element was inserted  then the excepted length of the linked list at the end of which it was inserted is roughly and the 1 is for our hash function computation this is  1 +  roughly the excepted time required to insert at the element we are just summing this quantity up over all the n elements and taking the average if you just go through this math  you will get something like the following and many of you could have figured this out on your own 1 + the average time would be roughly the excepted length of the list divided by 2 whenever we are doing average time computations  when i said take a linked list and what is the average time to search for an element you said i might have to go till the end of the linked list or find the element right at the beginning  on an average i will take half the length of the linked list  refer slide time  48  27  you are seeing a similar kind of behavior in this  1 +   in which is the very low order term which you can just ignore what you are seeing is something like  we do not really have to go through this math but you can also follow it  this is more intuitive one could just say that the average time for successful search would be more like  again it is o  1 +  where 2 is not important both for successful and unsuccessful search we are taking a similar kind of time what should be that is what should be a good choice of ? thus the is the load factor of the table that is the number of elements in the table divided by the number of slots in the table  refer slide time  48  52  if i pick the size of hash table to be the number of elements that i am going to be inserting in the hash table  then would be roughly a constant o  1   all your searching  insert and delete would take constant amount of time in the excepted sense i mean when you have an ideal hash function which you can not really have what if we did not know how many elements we have to insert then what should we do ? with what size our hash table should start ? we used a concept of growable stack  so the same idea is used in many of this data structures you start with some thing small and if the number of elements you inserting becomes so large that the sizes of linked list become very large  then it perhaps time to move the entire set of element in to a larger hash table  refer slide time  49  15  either you have to compute a new hash function or we will see how to modify these things how you can do small modification to the hash function so that you can put it in the larger hash table one should design your hash function keeping in mind that you might have to go from a smaller table to a larger table and even to a larger table and so on what will happen to the space when the number of hash table slots was propositional to the number of elements ? it depends upon the big-oh let us say we pick the number of hash table slots to be equal to the number of elements there is no problem  suppose n was a 1000 and m was also a 1000  this hash table can accommodate any number of elements it not just that it can accommodate only 1000 elements why because in the linked list you can attach any number of elements that come it is just that performance of the hash table would deteriorate if you had 10,000 elements coming because then each linked list would be of size 10 roughly  may be more or may be less on an average the linked list length would be 10 in that case it make sense to move to a larger hash table  refer slide time  51  25  if you know that the number of elements is only 1000 and you create a hash table of size 10,000 then there is wastage of space you should always start with a small hash table and if need be grow it  rather than starting with a very large hash table and having wastage of space today we saw binary search which many of you have seen before  we also saw a little bit of hashing and we saw the dictionary abstract data type in the next class we are going to continue with hashing c concepts of good hash function and see other ways of resolving collision data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 5 hashing  contd  today we are going to continue our discussion on hashing in the last class we saw about the hash table  the concept of hashing and also saw how to resolve collision in hashing using linked list that method of collision is also called chaining today we are going to look at 2 other methods for collision resolution  linear probing and double hashing we are also going to spend some more time discussing how the good hash function should look like  refer slide time  01  34  what is the good hash function ? the function which can be computed quickly and as said in the previous class  it should distribute the keys uniformly over the hash table  refer slide time  01  53  all the keys should not get mapped to the same location because then the performance of hashing would become as worse as that of a linked list good hash functions are very rare and there is a famous paradox called birthday paradox there would be about 35 or more students sitting in the class there is a very high probability and you can actually compute that probability in which 2 of you would have the same birthday although you would think that there are 365 days in the year and if each one of you were to have one of these days as a birthday then there is very small probability that 2 would have the same day but that is not the case  even with just 35 people you would have fairly high probability that 2 people would have same birthdays  refer slide time  02  10  the same kind of thing is happening here your days of the year corresponding to your slots in the hash table and even if i were to take a key and put it randomly in one of those slots there is very high probability that 2 keys would end up in the same slot that is birthday paradox  refer slide time  02  50  collisions may take place in any kind of hash function you use then there is also a problem of how to deal with non-integer keys in fact we saw an example in the last class where the keys were telephone numbers and we had returned the telephone numbers with hyphen how did we treat telephone number as an integer ? we just dropped the hyphen in between and then we thought of it as an integer you are going to see some more techniques of converting non-integers keys in to integer ones the other example that i had taken in the last class was your entry number where again the key was a non-integer because it had c s y or some other thing  refer slide time  03  22  we have to convert in to integers and what we did in the last class was as i said  those keys are just going to take the last 2 digits as the hash function value we are going to see some more techniques of converting non-integer keys into integer ones hash function can actually be thought of as being in 2 parts there is a hash code map and there is a compression map and these 2 together make up a hash function a hash function is basically a mapping of keys to indices of a hash table your hash code map  maps the key to an integer if your key is already an integer then there is no need for this but when your keys are not integer keys then you will have to 1stconvert them in to integer keys key ? integer  this integer could be from an arbitrary range but we need to bring it to the size of our hash table  refer slide time  04  17  if n is my hash table then i need to bring this integer to the range of 0 through n-1  so that it can be mapped to an index of my table that part we will call as compression map we will see what kinds of functions are used for hash code map and compression map another important requirement of hash function is that if 1 key gets mapped to a certain index then the next time when i want to map a key it should get mapped to the same indexed location it is not like  the next time it should get mapped to some other indexed location  refer slide time  05  03  in the last class we took an example of key which was 2004sa10110 and we mapped to location 10 i can not have a hash function which sometimes maps to location 10 and sometimes maps to location 13 there could not be any kind of randomization happening there why is that because when i insert it  i may be mapped to location 10 when i try to retrieve or search for it then if it gets mapped to location 13  i would not know the location of the key it should map equal keys to the same indices and of course and we should try to minimize the probability of collisions let us look at the popular hash-code maps the hash-code map is the part which converts your key to an integer one thing is that we could just take anything as the bit pattern and interpret it as an integer if you have a numeric type of 32 bits or less  we can reinterpret the bits of the number as an integer your key which has more than 32 bits in it which is a long or a double real number which takes more than 4 bytes  then you can take it in chunks of 32 bits and add them up  refer slide time  06  14  take the first 4 bytes and add the next 4 bytes to it and so on to get eventually some 32 bit and that could be an integer you are working with such a kind of tree could also be used to compute the hash code map of a string suppose i was using the key as your name given a particular name  let us say ankur i want to convert it to an integer one possibility would be take the ascii code of a  n  k  u  r add them up and that i will interpret as an integer why is this a bad strategy ? why would the number of collisions be high ? why would the sum of 2 different names be the same ? only if the order is different and that happens for many different words it is not the case for the names  but many words in the english dictionary would be obtained from the same letters if you have 2 words such that the letters was same as g o d and d o g  then when you sum up the ascii values they will be going to the same location only we have to avoid such a kind of things even if the words were not the same but a was replaced by b and n was replaced by m even then we will end up with the same these are all the reasons for why it is not a great strategy especially when you are trying to convert character strings in to an integer one technique used in such settings is called as polynomial accumulation you have a certain string and is the ascii code for the 1st character of the string and is the ascii code for the 2nd character and so on you are going to think of it as a polynomial whose coefficients are  up to  the above given expression is your polynomial and you are going to evaluate this polynomial at a certain value of x the evaluated value is going to be the integer corresponding to this   string that integer might be from a large range then we will use the compression map to map it to the table but 1stwe are looking at the hash code map were in we are trying to convert a string or a non-integer data in to an integer we are looking at the setting where the string we have is this   and we are trying to convert it to an integer evaluate the below given polynomial at some integer value  refer slide time  09  24  the value of x has been the experimental stuff  people have looked at and found that if you work with  x = 33  37  39 or 41  these values and if you take an english dictionary with about 50  000 words in it and use this technique to convert your words in to integer then you will not get too many collisions at a particular time you will have at most 6 collisions there is no theory behind it  this has been observed experimentally this is an experimental study in favour of this kind of a hash code map  refer slide time  11  31  let us look at some compression map given an integer you have to map it to the small range of your table one natural thing would be that k is your integer and your table is of size let us say little m just do k mod m and k mod m will give you some integer in the range 0 through m-1 where k is the key and m is the size of the table suppose you were to choose your m and let us say your table is of size 1024  m is basically  when i am taking some integer mod then essentially that means i am taking the last 10 bits of that integer write the integer in its binary representation and then when i am taking mod 2 that means i am taking the last bit of the integer if it is 0 then i get 0 always  if it is 1 i get 1 if i am taking mod 4  i am getting the last 2 bits so if i am taking mod then i am getting the last 10 bits all the integers which have the same last 10 bits would get mapped to the same location this is bad because we are forgetting the other bits of the integer we are just taking some small set of bits that is the last 10 bits based on the hash function hence one should not do such a thing in this case if you are using the simple compression map then you should not pick up the size of your hash table to be some power of 2 in fact it helps  if you take the size of the hash table to be a prime number  refer slide time  13  24  let us look at an example suppose i had 2000 strings and i am trying to put it in hash table i will try to pick the size of my hash table let us say at 701 which is the prime number this will ensure that on an average i would see only 3 strings per location that is 701 x 3 is roughly 2000 in my chaining  i would have 3 as the length of the linked list one important thing is that one should not pick up the size of the hash table close to a power of 2  because the same kind of effect will start happening when you have the size of the hash table to be exactly the power of 2 if you are going to use that kind of a compression map which is just key mod m  then keep in mind that m should not be a power of 2 or even close to a power of 2 and preferably it should be a prime number things do not work when you see a lot of collisions happening lot of it depends upon the data and the keys you are trying to insert in to your hash table these are generic principles which if you follow will improve the performance there have been instances in which we did some experiment where it is better to take a number which is not necessarily a prime  refer slide time  15  35  what are the other kinds of compression maps ? there is other compression map you can use  essentially first i read out the 2nd part of the above slide suppose your keys are in the range of 0 through  recall now assuming that our keys are integers because we first used the hash code map to convert anything that was non-integral in to an integer the keys are in the range 0 through max  so first covert them from this range  0 ?  in to a range through times a essentially we multiply each key with a where a is some number between 0 and 1 first we converted to this range  0 ? a   now we take the fractional part of the each key that corresponds to k a mod 1 as a consequence we get a number between 0 and 1 because we took the fractional part we have to map it in to the range 0 through m-1 so i can just multiply that number i get between 0 and 1 by m this number  ka mod 1  was between 0 and 1 and when i multiply by m i get fractional number that is why i took the floor function which means round down thus i rounded that number down to the nearest integer i will repeat it again you first took a key and multiplied by a where a is some number between 0 and 1 then from that you took the fractional part of that number which is again something between 0 and 1 and then you rounded it down this is another popular compression map you could have done something different  for instance i could just take this  0 ? a  and map it to  0 ? m-1  directly although it is not clear about how would you do it perhaps divide by m or some other thing this is one of the popular ways of doing things  refer slide time  17  41  in the following case the choice of m is not critical even if m was the power of 2 now  the same kind of thing that happened before would not happen because we have done a lot of jugglery we have taken that number  first we multiplied it by a which was a small fraction then we took the smaller fraction part and then plotted it to the range 0 through m here it is not critical that m not be a power of 2  we could use m as  some evidence if we use a as something like then it turns out to be good if we use that value of a then it is called fibonacci hashing most of this is experimental without significant theory behind it so if you might want to read more about hash function there is a nice book by ronald knuth on sorting and searching which covers hash functions in detail  refer slide time  18  51  there is another technique for a compression map called the multiply  add  and divide which says the following  take your key multiply it by a and add b thus a and b are 2 fixed numbers then compute modulo n where n is the size of your hash table  sometimes i use m and sometimes n the first technique was just k mod n but now we are doing something different we are multiplying by a and adding b here a should not be a multiple of n if a were a multiple of n then a mod n will be 0  so ak mod n is also 0 for any key you will always get mapped to the same location b in fact a and n should be co-prime if possible to avoid any kind of patterns happening such a technique is used in your random number generator also you might have used the function random as a part of your programming if you specify the range it gives your random number in that range how does it come up with a random number ? many of the random number generators are based on the technique called linear congruential generators they start with a certain seed  refer slide time  20  51  seed is a starting value which could be user defined  you could provide what the seed is or it could be a random number generator which could just take the system time at that point or some other information and use that as a seed that seed becomes the initial k value and then you compute this quantity   and the value you get becomes your random number the above function will give random number in the range 0 through n-1 then for the next random number  you are going to use k which is the last value you return we will use the last random number generated as a value of k and once again compute  you will use the value you get for the next time and so on this is how you generate random number such numbers are actually called pseudo random number because they are not truly random once you know the seed you can actually figure out all the numbers that you get  refer slide time  21  39  there is another technique called universal hashing which i am not going to go in much detail  i will just briefly tell you the idea i pick up a hash function and tell you what the hash function is you can always come up with set of keys such that all those keys using my hash function will get mapped to a very few locations i think of you as an adversary who is trying to make life difficult for me let us say  by picking key which all get mapped to a very few locations in the hash table so that i have to spend a lot of time doing insertion  deletion and searching one solution i can imply is that i do not even tell you the hash function which i am going to use that means i am going to have a bunch of hash function let us say 15 different hash functions and before the process starts i am going to randomly pick 1 hash function out of these then with the keys that are given to me  i am going to use this hash function to put the keys in to the table i have to use this same hash function for inserting all my keys  for doing the search  deletion and so on for one run of the hash table implementation i have to use the same hash function i can not change the hash function in the midway but the next time when i invoke this program  i could perhaps use a different hash function because that i have picked up randomly from my set of hash function so even if you came up with the bad set of keys for one of my hash function  may be that is the hash function i did not pick up at all  when i was doing my implementation  refer slide time  23  43  there are some results which say that you can pick up a collection of hash function and such a collection of hash functions is called universal  such that for any 2 keys the probability that they get mapped to the same location is no more than  as i said  this is just a brief idea about the universal hashing and i am not going to see in detail when you do your next course on algorithms in the 3rd year you will see more of universal hashing so that is as far as the hash function is concerned when you use hashing you will get collision  there is no way around it and one technique we saw in the last class was to resolve collisions what we call chaining if many keys go to the same location you just chain them up and put a linked list there you can still do insert  search and delete by doing that operation in the linked list you are going to see 2 other techniques today which fall under the general class of open addressing one of these is called linear probing and the other is double hashing  refer slide time  24  31  open addressing differs from chaining in the following key fact recall in chaining none of these elements were actually stored in the table  refer slide time  25  06  they were all stored outside the table  in the table all we had was a reference to the starting element of the linked list the table was only storing the pointers or the references to the first element of the linked list but now we are going to put all the elements in to the table itself as i said hashing could map 2 elements to the same location in the table  we can not put both of the elements to the same location still we want to put all the elements in the table  we will have to find some other locations for the element clearly if all elements have to reside in that table  then the number of elements that we are trying to put n has to be less than the size of the table which is m  refer slide time  26  12  i am going to work where m is the size of my table and n is the number of elements that i am trying to put this was not a requirement for my chaining technique i could have the number of elements as larger than the size of the table  because there the elements were not residing in the table they were residing in the nodes which were a part of the linked list each entry of the table is now either going to contain an element or it is going to be null it is going to be null which means that does not have any element in it when we are searching or inserting or deleting  we have to probe the elements of the table in a suitable manner we are going to think as if we are modifying the hash function a little bit the u is the universe from which the keys are picked our hash function is mapping the keys  earlier this part  0  1  ? m-1  was not there we were mapping the keys  u  to 0 through m-1 and that would tell us where this key sets  for instance in the case of chaining we are going to have a second parameter and when i am trying to insert the key that will be my first probe  refer slide time  26  59  i will compute the value of the hash function for that key  k  0  let us say for 0th probe and i obtained h  k  0  as the value of my hash function i look at the 0th location in the table  if that location is occupied then i have to look again when i look up the next time i will have a value of 1 as the 2nd parameter the 1st parameter is still the key k i am going to compute the value of the hash function for  k  1  which gives some other location in the hash table and so on i am going to different location in the hash table till i find an empty location  if the operation was one of insertion depending upon the hash function we will have many different techniques the hash function h is really determining sequence of slots which are examined for a certain key the u was the range of the keys  u is the set which specifies the collections of keys that we have the number of elements we are trying to insert in to the hash table should be less than the size of the hash table if i try to insert all the 100 students of this class to a hash table that i create then clearly the size of the hash table has to be more than 100 because each of this student has to go to 1 location of the hash table  refer slide time  29  54  the first technique under open addressing is called linear probing i have the key k which i am trying to insert i have a hash function h  i compute h  k   this probe = h  k  is the first place of the hash table that i am going to look at if table  probe  is occupied then i just go to the next location so probe is incremented by one and then once again i check if it is occupied if it is occupied then i increment again till i find an empty location and at that point i will put the element k this is the guiding principles that if the current location is used  just go to the next location the mod m is used to do rap around  if you reach the end of the table then you start at the beginning your question is what happens when we retrieve the keys we will come to that in a short while when you are trying to insert  you compute the value of hash function and you go to a specific location as specified by the hash function for that key if that location is occupied that is there is an element already sitting there  you go to the next location and if that is also occupied go to next location till you find the empty location one advantage it has over chaining is that it uses less memory in chaining you have to keep track of references each of your nodes should have place for the element that it is storing but it should also have the reference to the next node so that space is wasted but this technique might end up slightly slower than chaining  refer slide time  32  19  let me show you an example my hash function is k mod 13  a very simple hash function my keys k are integers and i am trying to insert these keys in to the table 13 is the size of my table and the location is from 0 to 12 the 18 mod 13 is 5  so 18 goes to location 5 because at that point the table was empty  so it can come there 41 mod 13 is 2 so 41 goes to location 2  22 mod 13 is 9 so 22 goes to location 9 till this there is no problem in inserting  as the table is empty 44 mod 13 is 5  we want to put 44 in the 5th location but this location is already occupied by 18  so 44 will have to search for the next location as the 6th location is empty we put 44 there 59 mod 13 is 7  we place 7 there as that location is empty 32 mod 13 is 6  as 44 is sitting in 6 we go to the next location then 59 is sitting at that location  again we go to the next location and as that location is empty we put 32 there 31 mod 13 is 5  so we should put it in 5th location but this location is occupied with 18 and the continuous locations are occupied by 44  59  32  and 22 so we go to the next location which is empty and we put 31 in that location 73 mod 13 is 8  as 8th location is already occupied we check for the next locations and we put 73 in the 11th location all the elements are sitting in their respective position that is 41 at location 2  18 at location 5  44 at location 6 and so on this also shows you one problem with this technique the elements tend to aggregate  form clusters so you might have to go through many locations while searching for an element how would one search ? the hash table is given in the slide below which is after inserting those elements suppose we are searching for key k  we are going to compute k mod 13 because that was our hash function then this  k mod 13  is the first location we go to and after that if we do not find the element we do not say that the element was not in the table  rather we go to the next location  refer slide time  35  27  if at the next location there is some element present then we go to the location following it and so on till we either find the element or we reach a an empty location if we reach an empty location that means the element is not their in the table because if the element had been their in the table it would have been inserted at one of the locations that i have checked let us see suppose i am searching for 31 so we go to 31 mod 13 which is 5 i come to the 5th location in which 31 is not there  so i go to the next location and search the element till i find it i found the element in the 10th location when i did not find it  i can not say that the element is not their in the table it could be their  infact it is their suppose i am searching for 33 mod 13 which is 7  i would start searching it from the 7th location till 11th location the element is not present and the 12th location is empty this means 33 could not be their at all in this table because if 33 had been there in the table  then by this time it would have been definitely inserted in to the table till the 12th position because this is an empty location  refer slide time  36  32  that is an unsuccessful search  in an unsuccessful search the search terminates when you reach an empty location but a successful search will terminate when it finds the element how do you delete ? the following slide is my picture which is from the previous slide and i want to delete 32  refer slide time  38  15  first i have to search for 32  32 mod 26 is 6 i come to the 6th location  it is not there then i go to the next location  also it is not there then i find the element 32 in the 8th location suppose i removed it by setting this location to null i removed 32 from that location is this a good idea ? no why this is not a good idea ? suppose now you search for 31 the 31 mod 13 is 5  so we come to the 5th location but we did not find it there then we go to the next location for that element and we did not find it and at last we reached the empty location hence we will say that 31 is not their but still 31 is their why is a problem coming in ? because when 31 was inserted that was the full location that is why 31 was inserted later  but if you delete the element in the 8th location then you have a problem some how we have to do something different because we can not just set this location to null or we can not mark this location empty also look up will declare that 31 is not present  which is wrong how do we delete ? instead of setting this 8th location to null we will place a tombstone  actually an x  refer slide time  39  49  tombstone is just a marker so you could set up a bit at that location which specifies that this location was occupied by some one it is not always the case that this will be an empty location  at some point this was occupied by some one how it will help us ? when we are doing a look up and we encounter a tombstone  we do not declare that the search is ended and the element is not present but we continue as before if i was searching for 31  31 mod 13 is 5 so i would come to location 5 and go to the next location and at the 8th location i would see an x and not null which is a tombstone so i continue till i find either a null location or 31 i found 31 and declare 31 is their when a look up encounters a tombstone it ignores and continues when an insert encounters a tombstone what does it do ? it will put the element at that position we have to reclaim this space what happens if there are too many tombstones ? you do not have elements in the table  those are actually empty locations but in your search you still have to go beyond them the performance of your search degrades if you have a lot of tombstones you should just rehash just remove all the elements and put them back again the same kind of a technique you have to do when you grow the table now you are not growing the table  you have too many markers in the table so just do a rehash and that will create empty slots without the tombstones and your performance will increase again i will come to the other open addressing techniques we looked at linear probing  we compute the hash function we look at that location and next location and so on in double hashing we have 2 hash functions h1 and h2  refer slide time  42  31  the value of h1 gives me the first position were i am going to look for the key k then h2  k  will tell me the offset from the first position were i am going to look again for the key k let us look at the piece of code given in the above slide probe is set to h1  k   so that is the first position i look at and offset is set to h2  k   first i will look at the locations specified by probe and the table  if it is occupied then the next location i will look at is probe + offset probe is set to probe + offset which means this is a next location i look at if this is also occupied then the next location i will look is probe + offset + offset which mean offset is determining key with how much distance i am going to advance every time i do not see the element that i am searching for for linear probing your offset is always 1 you were always going to the next location so that corresponds to an offset of 1 instead of going to next location i jumped one location ahead that is i jumped 2 locations  then offset would have been 2 and so on offset in this case which is in the orange color in the slide below is determined by the hash function h2  k   this offset could be different for different keys  refer slide time  44  20  we will look at an example of how double hashing works if m is the prime then this technique will ensure that we look at all the locations of the table in linear probing because the offset was one we would look at all the locations in the table if there was an empty location you would always be able to insert the element we would not like the following to happen there are empty locations in the table but you start from a certain location  since the offset is 3 you go 3 units ahead and you keep finding everything is full and then you come back to the starting location because you will not be able to insert the element at all may be all of these elements that you looked at were full but the other locations in the table where empty  refer slide time  44  41  some how you do not cycle back when you will cycle back ? when your offset divides the size of the table if the size of your table was a prime number then your offset would never divide it and this kind of a thing would never happen in fact you would look at all the elements of the table this is the small fact you can go back and prove that if m is prime then i have given you the rough arguments for this case  but you can also prove it more formally this has some of the same advantages and disadvantages as linear probing one of it is it distributes keys more uniformly because you do not form clusters any more these clusters were getting formed because you were just going one step at a time if for some key you are going 7 steps ahead and for some other key you are going 13 steps ahead and for some other key you are going 2 steps ahead  then these clusters are not getting formed any more that makes the performance better we will look at an example i have 2 hash functions h1 and h2 the h1 is the same as before  k mod 13 the element is also as same as before  we have a table of size 13 the h2  k  is my 2nd hash function and is 8  k mod 8   it will always be a number between 1 and 8 it can not be zero  because k mod 8 lies between 0 and 7  so it is between 1 and 8  refer slide time  46  41  the zero does not make any sense  if it is zero then we are in trouble if h2  k  is zero for some k then that means you are continuously looking at the same place and if that place were occupied then you can not insert the element at all let us insert the first element 18  18 mod 13 is 5 so it will go to location 5 the 41 mod 13 is 2 so it goes to location 2 the 22 mod 13 is 9 so it goes to location 9 the 44 mod 13 is 5 so it tries to go to location 5 but the location 5 is already occupied we have to compute h2  44   what is h2  44  ? 8 ?  44 mod 8   44 mod 8 is 4 so 8-4 is 4  i have to go 4 steps ahead i will go to location 9 but that is also occupied  so i will go to location 0 that is empty so 44 will go to location 0 the 59 mod 13 is 7 so 59 will go to location 7 the 32 mod 13 is 6 so 32 will go to location 6 the 31 mod 13 is 5 so we go to location 5 but that is occupied i compute h2  31   31 mod 8 is 7 and 8-7 is 1 so 31 will check for the location 6 but 6 is also occupied we have to go to 7  it is also occupied so go to 8 and this is not occupied  thus 31 go to location 8  refer slide time  47  39  the 73 mod 13 is 8  so it will try to go to 8 that is occupied we compute h2  73   73 mod 8 is 1  h2  73  is 7 so we will go to 8 + 7 = 15 the 15 is 2 mod 13  we go to location 2 that is occupied so 2 + 7 is 9 where that is also occupied the 9 + 7 is 16  16 mod 13 is 3 so it goes to this location which is unoccupied this is how the elements would be distributed in the table we will do some analysis of double hashing recall that i am going to assume that the load factor is less than one what is the load factor ? the number of elements divided by the size of the hash table that is less than one i need it to be less than one otherwise more than 1 does not make any sense we are talking of a scheme where all the elements have to sit inside the hash table we are also going to assume  this is similar to the assumptions that we made in the last class that every time i probe  i actually look at a random element in the hash table which is uniformly random the first time i probe i will take a random location in the hash table and try to put the element their if it is occupied then once again i will pick a random location in the hash table and try to put it their if that is also occupied once again i pick a random location in the hash table and try to put the element their let us see how this performs  because we will only be able to analyze such a scheme because the other schemes are too dependent upon the hash function that we are using and we might not be able to analyze them if is the load factor then that means 1 fraction of the table is empty if is half that means the number of elements divided by the size of the table is half which means only half the table is occupied and half the table is empty  1 fraction of the table is empty  refer slide time  50  27  suppose my search was an unsuccessful search.what does an unsuccessful search mean ? that means the element is not in the table when does an unsuccessful search stop ? when i get an empty location how many probes will be required before i get to an empty location ? the 1 fraction of the table is empty let say of table is empty and 90 % of the table is full that is 10 % is empty the expected number of probes required before i hit fraction of the table which is empty would be roughly 10 because the first time with probability  i will get to an occupied location and so on so roughly after 10 trails i will hit an empty location because only of the table is empty  refer slide time  51  39  if 1 fraction of table is empty then roughly in an excepted sense probes are required before i hit an empty location and declare it to be an unsuccessful search this is the excepted numbers of probes required for an unsuccessful search let us look at a successful search i am going to talk about the average number of probes required for a successful search  not for one particular search but if i were to look at all the successful searches what are successful searches ? successful search are searches corresponding to the elements in the table i have some number of elements in the table  let us say i search for the first element then how many probes are required ? suppose i search for the second element how many probes are required and so on then i will take their average let us try and compute this quantity if you recall from the last class the average number of probes required for a successful search is the average number of probes required to insert those elements because when we are inserting those elements we are essentially doing the same thing it is the same as the average number of probes required to insert all these elements and this is the quantity i am going to compute  refer slide time  53  11  what is the average number of probes required to insert all the elements that i have in the table ? when i am inserting an element i need to find an empty location again suppose i begin with an empty table and i am looking at the number of probes required to insert the first elements size of the table is m  let us assume m is 100 i am talking of inserting the first 50 elements suppose i have already inserted 48  49 elements and when i am trying to insert element what is the excepted number of probes that are required ? the half of the table is empty  when i try once i may hit a full location may be when i try again  in expectation i just need 2 probes to be able to insert this element for the other first 49 elements i might on an average even required less  but all i can say for sure that the average number of probes required for inserting these elements is 2  refer slide time  53  51  how many elements am i inserting ? the elements  on an average the total number of probes required is m for these elements when i show you the rest  you will understand why i am doing this way suppose i have already inserted elements in to my table and i am trying to insert the next elements in to my table when i am trying to insert the next elements  just assume that i have already inserted -1 and i am trying to insert this last element how much of the table is already full when i try to insert this last element ? the of table is already full only a of the table is empty so on an average i am going to require about 4 probes before i get to one of the empty location i am searching for an empty location to put this element in i need roughly 4 probes  infact i am just praising this as an upper bound and i need at most 4 probes to insert all of these elements the total number of probes required to insert these elements is times 4 which is no more than m  refer slide time  53  14  similarly for these next elements  when i am trying to insert the last of these elements only of the table is empty on an average i require about 8 probes before i can get to one of those empty locations for these elements or for any one of them i would not have required more than 8 probes i would have required between 4 and 8 probes for these elements because when i was inserting the first of these elements only 3 quarters of the table was full one quarter of it was empty  but i am just upper bounding it i am just saying that no more than 8  refer slide time  57  19  what is the total number of probes required ? for recall from previous slide i said m  for this also i said m what is the total required for these elements ? it is m times i  m x i   how many locations are empty in the table ? what is the total number of elements in the table now ? after i inserted elements what fraction of the table was empty ? it is half after i inserted + how much of the table was empty ? it is  so it is really this last number after i inserted how much was empty ? it is  so after i inserted all of this that is how much is empty ? it is which is fraction that was empty after i have inserted all of these fractions i have only fraction of the table empty and the total number of probes required to insert these elements is m times i we have a load factor of  we already inserted enough elements so that the load factor is  when the load factor is  1 fraction of the table is empty if i have 1 fraction of table empty  then how many probes are required ? if i have fraction of the table empty then i require m x i probe what is i ? the i is basically minus log of this   quantity if i need to have 1 fraction empty  so i just need ? m log  1   these are the numbers of probes required  refer slide time  58  17  if i have fraction empty  is the number smaller than one so to get to this point i require m x i probes so to get to a point where 1 fraction was empty  i need ? m log  1  this many probes the above what we saw was the total number of probes required and the average was just divided by n that is   we will be able to capture it to a table for an unsuccessful and successful probes  when we had chaining it was 1 +  for probing  for an unsuccessful search it was   and for a successful search what i just showed you is     refer slide time  01  00  14  the last slide which shows how this performances of changes  refer slide time  01  00  38  data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 6 trees last class we discussed about hashing we saw few collision resolution techniques  chaining  double hashing linear programming and you also did a little bit of analysis of these collision resolution techniques today we are going to talk about trees we are also going to look at binary trees and some data structures for trees  refer slide time  1  31  what is a tree ? many of you might have come across a tree before  except this tree is going to be different from one that you have seen before the root will be at the top in most of the trees around  you do not see the root  refer slide time  1  37  the root is going to be at the top of the tree in the tree given in the slide above a is the root there is a notion of parent and children  the node b is the parent of node d and e by the same argument a is the parent of b and c  c is parent of f  g and h a is a parent of b which in turn parent of d and e  so a is ancestor of d and e a is also an ancestor of f  g and h a is also an ancestor of i a is a grandparent  sometimes we use the term grandparent a is a grandparent of d  e  f  g and h hope you understand the difference between ancestor and grandparent d and e are descendents of a  in fact b  c  d  e  f  g  h  i are all descendents of a c and b are siblings because they have the same parent b is a sibling of c and c is a sibling of b g and e are not siblings but f  g and h are siblings d and e are the children of node b a is a parent of b  b is a parent of d and e  d and e are children of b  b and c are children of a and all of these are descendents of a i have 3three ancestors h  c and a h is the parent  c is the grandparent and a is the great grand parent but we do not use that term we just call it as an ancestor the terms we defined till now were more in the nature of a family tree and then we will come to real trees d  e  f  g  i are called the leaves of the tree a is the root  if you just turn it upside down then the extremities should be the leaves what is the leaf ? the generic term for a  b ? i are also called nodes of a tree a leaf is a node which has no children if a node has no children then it is a leaf h is not a leaf since h has a child but i  f  g  e and d are nodes which do not have any children and so they are called the leaves  refer slide time  5  08  a  b  c and h are called internal nodes  a node which is not a leaf is called an internal node we associate a notion of level with each node  the root is at level 0 the children of the root are at level 1 the children of those nodes which are at level 1 are at level 2 d  e  f  g and h all are at level 2 it is not that h is at level 2  all of these nodes are at level 2 i is at level 3 sometimes we also use the term depth  in which depth and level are the same thing the level 0  level 1  level 2 are also called as depth 0  depth 1 and depth 2 the height of the tree is the maximum level of any node in the tree what is the maximum level of any node in the tree ? the height of this tree is 3 the degree of the node is the number of children it has b has a degree 2  c has a degree 3 and h has a degree 1 the leaves have degree 0 because they do not have any children basic terminologies are quite intuitive what are trees used for ? they can represent the hierarchy in an organization for instance there is a company let us call electronics r us which has some divisions rnd is 1 division  purchasing is another and manufacturing is division domestic and international are the sub-division for the sales you could represent the organizational structure through a tree you could also use a tree to represent the table of contents in a book let us say a book called student guide which has chapters on overview  grading  environment  programming and support code the chapter grading has some sections called exams  homework and programs they could also have some sub-sections and that would build up the tree  refer slide time  6  56  your file system in which if you use the unix environment or the windows environment is also organized as a tree the one in the level 0 is the root directory and in the 1stlevel are those 2 sub-directories then within the sub-directory i have some other sub-directories and within that i have homework  assignment and so on your file system is also organized like a tree  refer slide time  7  57  today in our class we are going to see about definitions and then we start using those definitions in our later classes  refer slide time  8  33  an ordered tree is one in which the children of the each node are ordered that means there is a notion in which we would like to put the left child in the 1stlevel to the right side suppose if you want to draw a family tree  you may want to draw the eldest child to the left and the younger child as you move from left to right there is a notion of order there and some time you want to reflect that order in your tree but there would be no notion of order in the following example the node which is in the level 0 is a directory and in the 1stlevel there are two sub-directories whether i place the left node to the right or the right node to the left  it does not really make any difference as far as the picture is concerned also it does not convey any additional information but sometimes you might have the notion of order between the children such a tree is called an ordered tree  refer slide time  9  37  a binary tree is an ordered tree in which there is a notion of left child and a right child actually it is an ordered tree in which every node has at most 2 children the diagram given in the slide below is an example of a binary tree the root node has 2 children and the child node on the left has only 1 child and the following child on the right has only 1 child the node which does not have child node are said to be leaves we have 5 leaves which have no children these nodes in the 1stlevel are ordered and there is a notion of left and right nodes if i were to change the tree that is if i were to draw the left nodes on the right and right nodes on the left then i get a different binary tree that would still be a binary tree but it would be different from this binary tree  refer slide time  11.06  all of this is dependent upon the application you have this is just a way of representing information sometimes the order has meaning to it  sometime it has no meaning to it when it has some meaning to it then you would rather use an ordered binary tree and when you change the order  then you are representing something different we will see more example of this and things would become clear i can also define a binary tree in a recursive form as follows a binary tree is just a single node or a leaf or it is an internal node which is the root to which i have attached 2 binary trees in the following slide the nodes which are marked on the left side are called left subtree and the nodes marked on the right are called right subtree i can construct any binary tree in this manner i take a node and attach a left subtree and a right subtree i get a left subtree and right subtree through recursive in which it is obtained by taking a node and attaching it to the left and right subtrees  refer slide time  12  12  i have said and/or which means this left subtree might be null that is i might not attached anything or i might not attached anything to the right or i might have attached both the subtrees remember we have introduced other terms  left subtree and right subtree the node to the left side of the root node is called the left subtree and the node on the right side is called right subtree what is the left subtree of the node which is in the 1stlevel ? in the 2ndlevel  the node at the extreme left is the left subtree of the node  refer slide time  12  49  one example of a binary tree is the arithmetic expressions i have an arithmetic expression which looks like the one given in the slide below  refer slide time  13  27  i can represent this as a binary tree let us look at a parenthezisation of this expression suppose i have parenthesized in the manner like  which is given in the last line of the slide we have  4 + 6   the numbers here will be the leaves of my binary tree and the internal node would correspond to the operations in fact this is also one way to evaluate this expression you would take 4 + 6 and you would sum that you would draw a tree which has 1 internal node and its two children are 4 and 6 the internal node would have plus operator in it whatever is the resulting value we are adding that to 1 i draw a tree whose root is a plus operator and one child is 1 and the other child is the subtree that is obtained from this operation and i could build this tree this is just another way of representing arithmetic expression decision tree is another example of binary tree the example given in the slide below is taken from the book star bucks  caf ? paragon and most of it would not make much sense  may be we would not come across them what is the decision tree ? each node in the decision tree corresponds to some decision that you want to make you come to root node and ask whether you want a fast meal the answer is yes then you come to the left node and whether you want coffee or not the answer is yes then you go to star bucks if the answer is no you may go to some other place and so on thus decision trees are another example of binary trees why because typically it is yes and no you would follow the decision tree to get into a particular node  refer slide time  14  51  this was just more of terminology and examples let us see more concrete stuff let us define a complete binary tree we are still at binary trees  as you can see every node in this tree has less than or equal to 2 children or at most 2 children but i will call such a tree as a complete binary tree we call a tree as a complete binary tree if at the level there are nodes in some sense it is full and when every node has 2 children it does not give you a complete binary tree  refer slide time  16  06  i will show you why it can not be a complete binary tree let us look at the slide below and check whether every internal node have 2 children in this tree every node has a 2 children then that tree should also have leaves it can not be the case in which every node has 2 children  in some case there are no children just with the requirement that every node has 2 children  every node other than the leaf that means every internal node has 2 children does not implies it as a complete binary tree this is a counter example to that in which every internal node has 2 children this is not a complete binary tree  refer slide time  17  00  the following is an example of a complete binary tree we want to say that at level i there are node the root node is at level 0 that is 1 node  at level 1 there are 2 nodes  at level 2 there are 4 and at level 3 there are 8 if h is the height of the tree  in the following example what is the height of the tree ? we call height as the maximum level number so we should not count this as 4 thus the height of the tree is 3 if h is the height of the tree that means all the leaves are at level h then by the definition of the binary tree we have said that the level i has nodes that means there are leaves the number of leaves in a complete binary tree of height h is just  what is the number of internal nodes ? at level 0 we have 1 node  at level 1 we have 2 nodes and so on thus the sum is given as 1 + 2 +  because at level h all the nodes are leaf nodes thus the sum is  this is the number of internal nodes and the number of leaves is  the number of internal nodes is the number of leaves-1 this is for a complete binary tree  refer slide time  17  34  what is the total number of nodes in this tree ? it is which is the number of leaves + which is the number of internal nodes  hence it becomes  let us call this number as n if i have a complete binary tree of n nodes  what is the height of this tree ? let us go one step at a time what is the number of leaves in this tree ? if the number of nodes is n and the number of leaves was which equals  just from this  = n  expression the number of leaves in a complete binary tree on n nodes is  if i have a complete binary tree on n nodes  half of the nodes are leaves and the remaining half are of internal nodes similarly i can say that if i have a tree on n nodes  then the height of the tree is  no of leaves   i can evaluate h from  = n   h will be log   and so it is the log  no of leaves   else we can go directly from  where the number of leaves is and so h is log  no of leaves    refer slide time  20  37  you are just doing some simple counting here if i give you a complete binary tree of height h then you should be able to say about the number of leaves and the number of internal nodes it has when i give you a complete binary tree on n nodes  you should be able to say the height and so on if you have a tree on n nodes then the height of the tree is log    the other thing your have to keep in mind is that in such a tree the number of leaves is very large it is roughly half the total number of nodes it is very leafy kind of a tree so far we have seen a complete binary tree but a binary tree is any tree in which every node has atmost 2 children to get any binary tree  you can start with a suitably large complete binary tree and just cut it off for instance if i were to cut off some pieces then i would get a binary tree as shown in the slide below i can always do it  no matter about the tree i need take the binary tree on the right side as height 3 then i would start with the complete binary tree of height 3 which is on the left just cut off some pieces on the left side of the tree to get the tree which is on the right side the picture given in the slide below is the proof  refer slide time  22  07  let us use this fact that you can obtain any binary tree by just pruning of a complete binary tree take a complete binary tree  cut off some branches then you will get a binary tree if i have a binary tree of height h then in a complete binary tree at level i there were atmost nodes in a binary tree at level i there will be atmost nodes  there can not be more than nodes because the binary tree is obtained from a complete binary tree by pruning  refer slide time  23  14  this is an important fact  atmost nodes at level i implies that the total number of nodes in your binary tree of height h is atmost 1 + 2 + nodes the last level is h  at level 0 there will be 1 node  at level 1 there is atmost 2 nodes  at level 2 there are atmost 4 nodes and so on this is the maximum number of nodes that binary tree can have  refer slide time  24  23  let us rewrite this suppose i told you that a tree has n nodes then n is less than or equal to this   quantity  n < = which means that the height of the tree is just rearranged and it is h > =  if i give you a binary tree with n nodes in it  its height is atleast and there is a particular binary tree which achieves this equality and that is a complete binary tree think of a complete binary tree as a tree which acquires the smallest height if i create a binary tree with the certain number of nodes  the one which has the shortest height will be a complete binary tree because there we are packing all the nodes as close to the root as possible by filling up all the levels to the maximum that is the minimum height of the binary tree i give you a binary tree on n nodes  its minimum possible height is  what is the maximum height that a binary tree on n nodes can have ? a binary tree on n nodes has height atmost n-1 this is obtained when every node has exactly 1 child and the picture is given in the slide below this would be a zigzag in any manner and the height is 8 since there are 9 nodes in it  refer slide time  25  35  in a binary tree on n nodes the minimum height is log  n  that is log    but we say it as log  n  and the maximum height is n-1 that is the mistake many people make they always assume that binary tree means height is log  n   but it is not the case  it could be anywhere between log n and n how many leaves does the binary tree have ?  refer slide time  26  44  what is the minimum and the maximum number of leaves it can have ? let us figure it out we will prove that the number of leaves in a tree is < = + no of internal nodes this is the useful inequality  in any binary tree the number of leaves is < + the number of internal nodes or atmost the number of leaves in a tree can be 1 more than the number of internal nodes how will you prove this ? we will prove it by induction on the number of internal nodes  refer slide time  27  19  in a base case consider a tree with 1 node if a tree has only 1 node how many internal nodes does it have ? it is 0  because that 1 node does not have any child so that is the leaf base case is when the number of internal nodes is 0  in which case the right hand side is 1 that is the number of leaves is 1 so the inequality is satisfied we will assume that the statement is true for all trees with less than or equal to k-1 internal nodes this should be read as  the statement is true for trees with atmost k-1 internal nodes not just k-1 but anything even for less this statement is true we will prove it for a tree with k internal nodes suppose i have a tree with k internal nodes  let us say on the left subtree i have internal node then how many internal nodes do i have on the right subtree ? it is exactly k -1 and not atmost because all the internal nodes are either in the left subtree or in the right subtree or it is the root node the minus one is because of the root node this is the number of internal nodes in the right subtree let us apply the induction hypothesis is less than or equal to k-1 and the quantity  k -1  is also less than or equal to k-1 we can use the induction hypothesis in the left subtree which has internal nodes  the number of leaves is less than or equal to + 1 in the right subtree the number of leaves is less than or equal to k -1 + 1 which is k  the total number of leaves is just the sum of these two   + 1  +  k    all the leaves are either in the left subtree or in the right subtree the total number of leaves is just the sum which is k + 1 that is we wanted to prove since we started a tree with a k internal node  you have to show that the number of leaves is less than 1 + k this is a simple proof which shows the number of leaves is atmost 1 + the number of internal nodes  refer slide time  27  44  there was a tree in which we saw the number of leaves is equal to the number of internal nodes + 1 it was in a complete binary tree what was the number of leaves in a complete binary tree ? the number of leaves was  if h was the height of the tree and the number of internal nodes was 1 + 2 + nodes there was exactly a difference of 1 between the number of leaves and the number of internal nodes the complete binary tree once again achieves the equality for any other tree the number of leaves will only be less than or equal to this sum how small it can be ?  refer slide time  30  53  let us look at that for a binary tree on n nodes  the number of leaves + the number of internal nodes is n because every node is either a leaf or an internal node also we just saw that the number of leaves is less than or equal to the number of internal nodes + 1 i will just rearrange  this implies that the number of leaves is  i have just rearranged  as the number of internal nodes is greater than or equal to the number of leaves -1 i replace that and get the number of leaves as for any binary tree the another thing to keep in mind is for any binary tree the number of leaves will never be more than half the number of nodes in the tree again this equality   was achieved for our complete binary tree  which is the most leafy tree all others trees are dry and the minimum number of leaves that tree might have is just 1 the example for that is the same example that i have showed you before the tree on 9 nodes has only 1leaf in it let us look at an abstract data type for trees you would have the generic methods which you seen for all the abstract data types till now the following are the generic container methods  size   which tell us about how many nodes are there in the tree  isempty   tells whether the tree is empty or not and the method elements   which list out all the elements of the tree  refer slide time  32  22  you can have position based container methods  it is as the kind we saw for the list or sequence data types the swapelements  p  q  in which i have specified 2 positions p and q think of the positions as references in to the tree except that using the position data type i am not able to access anything else but the elements sitting at that position the method positions   will specify all the positions in the tree it will give you all the positions in the tree as a sequence the positions method has no parameters  when you invoke it on a certain tree it will just give you a sequence of all the positions in the tree  references to all the nodes in the tree once you access a particular position then using the element method on that positions you can access the element in that node the swapelements  p  q  given 2 positions p and q  you are swapping the elements at these 2 positions replaceelement  p  e  which means that given a position p you are replacing the element at that position with e in query methods given a particular position isroot  p  is this the root of the tree given a particular position isinternal  p  is this is an internal node  given a particular position isexternal  p  is this external or leaf sometimes we use external or sometimes we use leaf  does this position correspond to leaf in accessor method when i call root it will return a position of the root  an object of type position isroot  p  is determined as given a position is it a root and root   returns the position of the root hope you understand the difference between the both the position of the root means it is not a reference to that particular node but it is a reference of type position so that you can not access anything except the element this was the same as the type casting which we did earlier the method parent  p   given a particular position returns the parent node the children  p   given a particular position returns the children of this node if it were children  there could be of many children for a certain node how it will return the various children ? it will return as a sequence  it will return a sequence of object type sequence which will contain the position of all the children position has an element method which will let you to access the data the update methods are typically application specific and this would be the generic method for a tree binary tree should really be treated as a sub-class  as a derived class from a tree all we need to do is to continue to have the same method as we described for the tree but we will have some additional methods there would be a notion of a left child given a position give me the left child  give me the right child or give me a sibling  refer slide time  36  37  we will come to the update methods when we see the example of it what is the node structure in a binary tree ? what are the kinds of data that you would be keeping in an object corresponding to a node of the binary tree ?  refer slide time  37  14  you would have the data  you would have a reference to the left child and a reference to the right child and you would have reference to the parent typically you would also have a reference to key or data associated with this node  any element that is sitting in this node you would have reference to it and these were all sitting together the reference to the node which is at the center will not be stored in the node and that does not make any sense for instance if i access to this node  suppose this was the root node and i use the root method to get a position to this node then using that position i can now access the left child by invoking the left child method and in this manner i can get the position of any node once i have the position of a node i can then invoke element method and any method to get the data associated with that a node in this case would definitely implement the position interface in the slide given below  this is what the binary tree would look like if you look at the links and so on  refer slide time  39  12  the parent link would be null for a root node because it has no parent then it would have left child in which the left child would be referring to the node on the left and the right child would be referring to the node which is on the right and so on in the above diagram the extreme right node does not have any right child  its right child member would be referring to null that was for a binary tree how do we take care of arbitrary trees ? let us say unbounded trees the root node has 3 children and its child which is on the left also has 3 children  refer slide time  38  39  are we going to have 3 different data members to refer to 3 children ? that is not clear about how to do it  because then if it has 4 children then how you would create space for another member the way to do it is that you have a reference to 1of the child only and then all the children are in a linked list each child will have a reference to the parent  so all of these children would be pointing to the parent node but the parent node would be pointing to only 1of them which would be the head of the linked list in the 2nd level ? from the node which is at the 1st level  if i want to refer to the children  i can just come here essentially return all the elements of this linked list how do i know that i have reached the last element of the linked list when the next is empty ? the 1stfield of the node is empty because it does not have children every node still has only 3 data members  parent or 3 references 1 for the parent  1 for left most child and 1 for the right sibling the left node on the level 1 would refer to left most child and not to all the children because that we do not know how many are there it will have 1 more to refer to the right sibling because for the left node at the level 2 should refer to the right sibling you can do with only 3 references the node in the level 2 has only 1 child and it is just pointing to that 1 child  there is no sense of left and right here this is not a binary tree  left and right makes sense only in a binary tree actually i should not have written left child  i should have written 1st child that is any 1 child then it just point to that 1 child and that let you to access its siblings through a linked list from the 1st child you will go to the next child and to the next child and so on you can step through all the various children throughout linked list with that we will end our discussion on binary trees today in the next class we are going to look at reversals of trees data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 7 tree walks / traversals in the last class we looked at definitions of trees  a binary tree and a complete binary tree and the height of these things today we are going to continue with our discussion on trees in particular we are going to talk about tree walk or tree traversals a tree walk is a way of visiting the nodes of a tree in a specified order there are 2 different tree walks that we will consider  one is called the preorder walk and the other is called postorder walk in a preorder walk you first visit or process each node and then you go and process its children i will show you an example to follow this and then you will be clear  refer slide time  01  23  in a post order you will first process all the children or visit all the children and after that only you would process the node let us see an example which will clarify this i am looking at the examples of preorder tree walks suppose recall that we said  we can construct a tree out of a book or a paper we can look at the organization of a book as a tree let us say a research paper you have the paper and it has a certain sections  the first section is the title  second section is the abstract which discusses about what is their in the paper and then you have section 1  section 2  section 3 and then at the end of it you have references that is what are the books and the other papers that this particular publication has referenced  refer slide time  02  37  the section 1 has 2 sub sections that is section 1.1 and 1.2 the section 2 has 3 sub sections  section 3 has 2 sub sections and so on when you read the paper  this is the order you would go in suppose you are reading the paper end to end  first you will go to the title  then read the abstract then you will look at section 1 and then its sub section 1.1  1.2 and so on if you were to think of a book and how the table of contents of the book are listed the way the tables of contents are listed is that first you have the chapter and then the sections within the chapter are listed then the next chapter and the sub sections within that chapter and so on  refer slide time  04  04  if i were to look at the above slide as the tree and these as the nodes of a tree the first node that we are referring or accessing is the node 1 then we go to the node 2 then 3  4  5  6 and after we are done with 6  in a table of contents you will have 7  8,9,10,11,12,13 and then 14 this is also called the preorder traversal of a tree the pseudo-code for preorder traversal would look something like the one which is given in the above slide if i have to do a preorder traversal of a node v in a tree  so to begin with i would call preorder traversal at the root of the tree then i would say first visit the node  visit here is a generic term and we will use it very often all it means is that i am doing some computations in that node in this particular case if i were listing out the book as table of contents then visit would correspond to print the title or print the heading of that particular node for instance each node corresponds to a section or some thing then this  ? visit ? node v  would correspond to print out the name of the section then once you done that then you go to each of the children nodes and repeat the process repeat this same process there on each of the child nodes because this tree could be arbitrarily d and the subsection 1.1 could be as 3 sub sections 1.1.1  1.1.2 and so on  refer slide time  04  52  if you were to do a preorder traversal then you would come to 1  then you would come to 1.1 then you would go to 1.1.1 and then 1.1.2  1.1.3 and only then you would go to 1.2 that is the need for this kind of a recursive traversal what you doing here ? you first visit the node then visit all its children so these are the 6 children of that node we are saying visit the first node what does visit correspond to ? it does not have any children so it just means visit the first node the second one corresponds to visit that node the third one corresponds to visit that node and then visit its children that is what we are doing  visit its children and then the next child and so on this is what would be called a preorder traversal i gave you the example this is like reading a document from beginning to end we could also have what is called a post order traversal in a post order traversal recall i said that we are going to visit the node at the end we will first visit its children and only then we would visit the node  refer slide time  06  43  let us say i have a directory structure like this this is my root directory courses this is an example from the book there are 2 courses here cs 016 and cs 252 and then in that there are 2 sub directories  there is a file called grades within this sub directory there are 3 files  within this sub directory there are 3 files and so on this is the directory structure suppose i want to compute the total space occupied by this file system or this entire directory what would i do ? i would compute the total space occupied by the subdirectory which is on the left and i would compute the total space occupied by the subdirectory which is on the right and then i would add these two up at the node which is at the center to obtain the total spaces required so in some sense i am actually visiting the node which is at the center or doing some computation on this node after having done the computation at the 2 children nodes after having computed the total spaces required by the sub directory on the left and after having computed the total spaces required by the subdirectory on the right  only then i am doing the node at the center when you are doing a post order traversal of a node v  for every child of the node first we are going to perform a post order on that in this example post order corresponds to finding the total space occupied by that sub directory so to compute the total space occupied by the directory which is at the center  we are first going to compute the total space occupied by the sub directory on the left then the total space occupied by the directory on the right and having computed that  you are then going to compute the total space required by the directory at the center in some sense the order in which computation is done is reverse from the pervious example in fact this is the order in which the disk usage command in unix  if you ever have used this particular command in unix what it does is  if you type in this command in a directory it tells you what is the total space occupied by the various subdirectory their the way you list it out is  if you were to type the disk usage command in this sub directory  it was first going to list out the total space occupied in this directory on the left then the total space occupied in this directory on the right and then eventually at the end it list out the total space required here because it would have computed it only after it had done the computation on the left and right how does this do the computation ? in a recursive manner that is to compute the total space required by this directory  refer slide time  09  41   first it is going to compute the total space required here then the total space required here and then add them up to get the total space required here so that would be a post order traversal  refer slide time  07  05  which child we would visit it first ? we are looking at ordered trees there is a notion of a first child  second child  the third child and fourth child so the first child is visited first and next is the second and so on if you have drawn the tree in such a manner such that the first child is at the leftmost then we would say that the leftmost child is visited first and after that the other one on the right and so on it depends upon how you have drawn your trees what i had just shown you was traversal in general trees if it is a preorder  first visit the node then visit the children nodes in postorder first visit the children node and then visit the nodes let us look at how this specializes to the case of binary tree in a preorder traversal what are we saying ? so v is a node  if v is null then there is nothing to be done if v is not null then in a preorder traversal we are first saying visit v the visit is some generic computation we do not know what it really is it depends upon what your particular application first say visit  then do a pre order traversal on the left child and then do a pre order traversal on the right child note that this is a recursive procedure we are calling preorder within the procedure itself how does this  preorder  v.leftchild     work ? this will work by making the call to itself  when we are doing a preorder traversal on the left child and on the right child and the difference between pre order and post order here is that visit now comes at the very end first you do a postorder traversal on the left child then you do a postorder traversal on the right child and then eventually you do visit v  refer slide time  10  54  let us see if you understood this let us look at an example this is my tree it is a binary tree i want you to tell me what is the pre order and post order traversal of this tree what we are doing when you visit a node is that we are just printing out the contents of the node so let us first look at pre order what do you think would be the first thing that would get printed if we are doing a pre order traversal of a tree ? the a is the root so we come here and we print a then we have to go and do a pre order traversal of a left sub tree when we do a pre order traversal of the left sub tree we are going to come to the root of the left sub tree and first visit the node  visit corresponds to printing the content we will just print it out as b then we will go to the left sub tree which is c we will come here  we will look at the root node  first visit the node visit the node here means printing the contents  we will print c then we try to go to its left sub tree but its left sub tree is null there is nothing there so then we go to its right sub tree which is also null nothing to be done now we are done with the preorder traversal of this c  refer slide time  11  57  where do we go now ? to the right sub tree because first we went to visit the node then we did a pre order traversal of the left sub tree now we have to do a pre order traversal of right sub tree which means first visit the node here which is d then we go left which is f then again we try to go to left which is null  then go right which is also null  nothing to be done then we go to g and now we are done with the pre order traversal of this sub tree we are done with a pre order traversal of the left sub tree we are done with a pre order traversal of the right sub tree which means we are done with the pre order traversal of the entire sub tree now we would go to the right sub tree  the right sub tree has only e in it so we would just print e this would be the pre order traversal of this tree let us do a post order traversal which do you think is the first node that would get printed ? it is c why c the right answer ? let us see we come here to do a post order traversal this a will be printed at the very end after i have done the post order traversal on the left side and post order traversal on the right so i will first try to do a post order traversal of the nodes on the left side when i try to do a post order traversal to b  i come here  first i will do a post order traversal of c then i will do a post order traversal of d  and then print the node b i have to come to do a post order traversal of this node c for doing that i will first do a post order traversal of its left child which is null  nothing to be done i do a post order traversal of its right child  null nothing to be done so i am ready to print the content of this node c the first thing that will get printed is c i am done with the post order traversal on the left subtree and now i come and do the post order traversal of the right sub tree to do a post order traversal of the right sub tree i once again come to the root which is d i first do the post order traversal of this left sub tree f then post order traversal of this right sub tree g and then print this content d so post order traversal of f is a single node so it will just be f the post order traversal of this right subtree would be g and then i would print the content of this which means d what we will print now ? so we have done the post order traversal of f and we have done the post order traversal of c so we can now print this node b so we will print b we have done with the post order traversal of the nodes on the left side so we go to the right sub tree e do the post order traversal here which means just print e and then we have done with the post order traversal here  refer slide time  15  45   we have done with the post order traversal here so we can now print the root which is a so this would be the post order traversal is this clear to everyone  how the procedure works  refer slide time  15  59  i am showing another example for evaluating arithmetic expression this is an arithmetic expression  we want to evaluate this expression so how does one evaluate the expressions ? this is minus  so in essence we have to compute the value of this quantity what is the value of this sub expression ? this corresponds to a sub expression so you have to compute the value of this sub expression which is on the left  refer slide time  16  36   we have to compute what the value of this sub expression on the right in the above slide whatever values we get we have to then take their difference that will be the value of the entire thing so as you can see it is like a post order traversal first we have to compute the value of this which is on the left then the value of this on the right and then take the difference which is the operator sitting in this node at the center how do i compute the value on the left side of the tree ? i have to compute the value of this left sub tree  i have to compute the value of this right sub tree and then do the division because that is the operator sitting here we can right a procedure something like this suppose i say evaluate the expression corresponding to v which is a node let say v is a root node here and i say evaluate this if v is a leaf then i just return the variable stored at v because that is the value the leaf corresponds to numbers in this expression else if v is not a leaf then that means we are at some internal node so to evaluate the expression corresponding to this node v  i have to first evaluate the left part let say evaluate  v.leftchild     the arrow after x in the slide should be in the other direction so that x gets the value of that the y gets the value of the right child when i evaluate on the right child and if o is the operator then i just compute x o y whatever that operator o is and return that value that will be the value of expression corresponding to node v this is pseudo code  i hope you understand what i am trying to say here this is like a post order traversal with a small modification we are not going to be addressing that problem  refer slide time  18  29   the problem of generating this tree  given an arithmetic expression you will have to incorporate the priority rules to generate such a tree we will not be worried about that for now we are just looking at traversals given such a tree how can you evaluate the expression corresponding to this tree ?  refer slide time  18  53  for a binary tree we have seen a preorder traversal and a post order traversal there is a third kind of traversal which is called an in order traversal so recall that in a pre order traversal we visited the node first  then we went to the left then we went to the right in a post order traversal we first went to the left then to the right then we visited the node so the third possibility is if we just visit the node  between the visits to the left and the right there should be an and between the visit to the left and right sub tree so pseudo code for in order traversal would be such thing like the following if v is null then we just get out  else we first do an in order on the left child then we visit the node and then we do an in order traversal on the right child these are the only 3 possibilities these are 3 binary trees  so you first go left where do you visit the node ? either you visit it before you visit both the left and the right or you visit it after you visit both the left and the right or you visit it in between the visits to the left and the right these are the 3 possibilities and these are the 3 traversals that are known let us just look at an example and see that we have understood inorder traversal which is the first node that will get printed ? is that a ? first to do an inorder traversal we come to the node a we first do an inorder traversal of this left sub tree then we come to the node a then we do an inorder traversal of the right sub tree e so to do an inorder traversal of the left sub tree  we will come to b first we will do an inorder traversal of the left then we will print the content then go right so to do an inorder traversal of the node c which is a single node  so it corresponds to printing c out that is the first thing we will print then we will be printing the content of this which will be b and then we will have to do an inorder traversal of this right sub tree for a right sub tree inorder traversal  once again we will first print out f then d and then g now we are done with the entire inorder traversal of left sub tree  so we will print out a and eventually we will print out e that would be the inorder traversal of this tree  refer slide time  20  07  there is an another way of traversing a tree that is called an euler tour suppose this is a tree corresponding to an arithmetic expression the tour is basically the one drawn in blue here we start from here  keep going down when we hit a leaf  we go up to his parent then go to the right sub tree and so on  refer slide time  21  54   it is a generic traversal of a binary tree and all the 3 traversals that we have seen that is pre  post and inorder traversal can be viewed at as a special case of this eulers tour traversal each node is basically getting visited thrice why because once we are coming like this  refer slide time  22  25  then other time we are going like this  touching this node the third time we are coming like this and touching this node so 3 times that we touch any node except the leaf nodes where you can count this as only once or thrice or what ever you want but every internal node will be touched thrice i should actually qualify  every internal node of degree which has 2 children  if the node has only one child then you will touch it only twice  refer slide time  21  31  suppose this is the tree corresponding to a certain arithmetic expression which is given in the slide below i want to print this arithmetic expression out with parenthesis i want to draw the parenthesis  i want to print it out in this manner which is given in the below slide so i can do an euler walk to print this thing suppose i am here in the middle  before i start on the left sub tree i will print a left bracket when i finish with the right sub tree i will print the right bracket this right subtree corresponds to taking this path up  refer slide time  23  54   going up like this and when i am coming like this and touching this node will just print out the content of the node did you understand what i am saying ? so recall that every node was visited thrice so once when i am visiting it from the left then essentially i am going to print a left bracket when i am touching it from the right essentially i am going to print the right bracket and when i am touching it from below i am going to print the content of this node if you do that then you will get exactly the one which is given in the bottom of the below slide first i will touch the node at the center from the left so first i will print left bracket then i will touch this node on the left i will print another left bracket  i touch this node on the left i print another left bracket and i touch this node on the left so i print another left bracket so i get 4 left brackets to begin with then i come to the node 3 for the leaf i will just print the content of the leaf and do nothing else so i just print 3 then i am going to touch this node from below  refer slide time  24  50   i am just going to print a star or a multiplication then i come and touch it from the left so i print a left bracket then i come here which is 1 and so on so you can think of this as essentially printing out this arithmetic expression as some kind of euler walk on this tree  refer slide time  23  12  we can actually write a generic method for tree traversal and then specialize it for whatever particular application you have whether you want to do a preorder  postorder or inorder traversal or any such thing so this is just a small example so you want to traverse a node specified at this position p if this is an external node then you will call this method which is called external you have not done anything here  we have just specified certain methods external is a method that you will invoke if the node that you are trying to traverse is an external node an external node is the same as a leaf node so if it is a leaf node then that is the method you invoke when you touch the node from the left then you will invoke this method called left here you continue with the left child when you touch the node from below  you will invoke this method then you continue with right child then when you touch the node from the right you will invoke this method now you can specify what these methods are so by specifying these methods you can create the traversal of choice  you can specialize this binary tree traversal  this generic tree traversal if you want to go into java details this is an abstract class which means that these methods in particular init result  isexternal of course is specified but init result  external  left  below  and right are left unspecified in a class you leave certain methods unspecified then it becomes an abstract class because you can not really create an object of that class anymore but then at some point you can specify those methods and in that manner create a sub class of this abstract class which specifies these methods and in that manner specializes this generic tree traversal procedure this is a generic tree traversal procedure so if i were to specify left  below and right in a certain manner then i could get a class for printing out arithmetic expressions  refer slide time  25  16  you want to know what the left result was when i come back from the left child  may be i compute a certain result in that example of disk usage we wanted to compute what is the total space occupied by that directory we computed the space required by the left child  the directory in the left child corresponding to the left child we computed the space required by the directory corresponding to right child when we computed that  those could be stored in r.left result and r.right result and then we would compute their sum that would be your final value  which would be the value we would return  refer slide time  28  48  let see how to specialize this for our printing arithmetic expression example so recall that if the node is a leaf node then all we said was that we are going to print the content of that node that is what we are saying  just print out the element in that node p is a position just print out the element in that node  what ever the element may be when we touch a node from the left  we said just print out a left bracket so that is what we are saying just print out the left when we touch a node from below  we just said that whatever is the operator present their just print that out that is exactly what we are doing when we touch it from the right  we just print out the right bracket the printexpression traversal is the class which is extending binarytree traversal when i invoke the traversal method it will now print out the arithmetic expression with the tree corresponding to arithmetic expression in parenthesized form so i could specialize the same class binarytree traversal to use it to compute the total space occupied by certain directories structure  by specializing these methods in a slightly different manner let us continue with our discussion on pre and in order suppose i give you the preorder and inorder traversal of a binary tree i have mentioned this in the following slide can you use this to figure out what the tree is ? yes or no suppose this was the preorder traversal and this was the inorder traversal of the binary tree i have given you these 2 can you use these  to print out to tell me what the tree is ? yes you can why we can do that ?  refer slide time  32  33  so given this preorder traversal  what can i say first ? i have marked a as the root what should i do ? the b is left child is this true that b is the left child ? no  not necessarily the root might not have a left child at all that can happen  so we can not say anything all we can say is  a is the root let us find a in the inorder traversal the a is the root  i know that let me just put down the node for the root and i know that i will search for a in the inorder traversal now what do i know ? i know that e is to the right that is e is the right sub tree i know that this  e  is the inorder traversal of the right sub tree and this blue colored is the inorder traversal of the left sub tree of a the green is the inorder traversal of the right sub tree and blue is the inorder traversal of the left sub tree i know that the left sub tree has 5 elements in it this is the information i know so in the preorder traversal the 5 elements following a  would correspond to the preorder traversal of the left sub tree the one element following that would be the preorder traversal of right sub tree so in essence what have i managed to do ? i have managed to identify what the left and right sub tree are and i know their preorder and inorder traversals i know the preorder traversal of the left sub tree and i know the inorder traversal of the left sub tree so my problem  i can use recursion now i know e is the right sub tree and now i can basically work on this problem  where i am given the preorder and in order traversal of a tree and i need to figure out what the tree is and whatever is the tree is  i will come and plug it as the left sub tree of a let us continue with the example and let see what we will do now so b is the root of this left sub tree whatever argument we used before so b is the root of the left sub tree  we are going to see where b is in the inorder traversal the b is here and b is the root so this  c  would be the left sub tree of b now and f  d  g is going to be the right sub tree of b so on the left i have only one element that would be c here so c would be the left sub tree and this  d  g  f  would be the preorder traversal of the right sub tree i figured out the c  since on the left there is only one so i can put that c down i do not know what the right subtree is i just know preorder traversal and inorder traversal i know that it has 3 nodes  the right sub tree has 3 nodes so the problem recursively reduces to this problem of given the preorder and inorder traversal of this 3 node tree  i need to figure out what the trees is so once again i know that the root is going to be d i look for d in the inorder traversal  it is there i know on the left i have f and on the right i have g i know the root is d and i know that the left sub tree would have f and the right would have g i get something like the one which is given in the below slide  refer slide time  30  36  you can translate this in to a piece of code it will require some thought because you have to write it in a recursive manner this is your second assignment which i have put it upon the web today this would be some input  you will take from the user  the pre order and the inorder traversal and you have to compute not the tree but you have to compute the post order traversal which is simple if you have computed the tree because you can do a post order traversal of this tree now and give the result it might be possible that given any arbitrary sequences  it is not necessary there is a binary tree corresponding to that you will also have to flag out an error  if the sequences that given to you are such that they could not possibly be the pre and inorder traversal of any binary tree this is pre and in order given post and in also you should be able to compute the tree suppose i give you the postorder  inorder can you use that to compute the tree ? recall what did we do ? we try to first figure out where the root was in the preorder the very first element is the root  in a postorder the last element is the root so first  once you know the root then you will search for the root in your inorder traversal and wherever you find that root  that neatly divides the thing into a left sub tree and right sub tree once you know the number of nodes in the left sub tree  you can figure out what the post order traversal of the left sub tree if there were 5 nodes in the left sub tree then the first 5 nodes of your post order traversal would be the post order traversal of the left sub tree so in this manner again you can recursively work you can recursively figure out what the left and right sub trees are and then plug them up to the tree given a post and in order traversal also you can do what is the third question ? given pre and post can you do it ? no  refer slide time  36  15  given the pre and post order traversal of a binary tree you can not uniquely determine the tree and the reason for that is there can be 2 trees which have the same pre and post order traversal preorder  a b c postorder  c b a suppose i gave you the above preorder traversal and postorder traversal that is a 3 node tree what do you think is the tree ? the tree given in the below slide is the tree with preorder traversal a b c the postorder traversal will be c b a this tree also has the same pre and post order traversal the a b c is the preorder traversal  the postorder traversal is c b a which of this tree is a right one ? both of them there is no unique tree  we could also have c as the right child so these are only 2 but they could be many trees that you could construct  refer slide time  37  44  that is the problem given a pre and post order traversal you can not uniquely determine the tree because there could be many different trees with the same pre and post order traversals but here note that some nodes in the trees had only one child suppose i gave you this information that every internal node of the tree has 2 children  not complete but every internal node of the tree has 2 children what is that called ? the below given slide is an example of a tree in which every internal node has 2 children this is not a full tree  this is just a tree with every internal node having 2 children there is no name to it  refer slide time  39  32  suppose i gave you this information did you say an indian tree ? if each internal node of the binary tree has exactly 2 children then actually you can use the pre order and post order to determine the tree uniquely again let see just as an exercise  why this is true ? i gave you the pre and post order traversal what is the first thing you can say ? the a is the root we can quickly draw the root what can you now ? the b has to be the left child  refer slide time  39  51   refer slide time  40  04  it has 2 children so we know that there is something on the left or actually i have done the example on the right what can i say is the right child of a ? the a has right child because every node has 2 children what is the right child of a ? it has to be e since my example  i have worked it out with that the e  i know is the right child from the picture given in the above slide i see e in the above picture and after e nothing is there what that it say ? that says e is a leaf because in a preorder traversal i would have first visited e and then gone to its children but there is nothing following it which means e has no descendants basically it means that the left sub tree has b c d f g so e is the right child and the left sub tree has b c d f g as the preorder traversal and c f g d b as its postorder traversal the same thing  since i have managed to divide  i am going to continue so i have b c d f g as the preorder traversal of the left subtree and c f g d b as the postorder traversal of the left subtree once again i know that the root is b  i have drawn the root what do i know about the right child of b ? i know the right child is d i see where d is in the case of preorder traversal so d is the right child  every thing that follows d has to be in the right sub tree everything that follows the d in the pre order traversal has to be in the right sub tree why because in the right sub tree when i did a pre order traversal i have first visited the d and only then visited the other elements so d f g forms the right sub tree and c forms the left sub tree the left sub tree has only one element  that is what i am going to do here in the case of postorder traversal this one element c would be my left sub tree and this f g d would be my right sub tree i have figured out the left sub tree which has only single element  i can just draw it and now i know that right sub tree has nodes d f g where preorder traversal is d f g and postorder is f g d i know root is d  actually i have already drawn that out i know the right child is g the g is here and there is nothing beyond that means g has no children further i can draw that out and then i know what remains the left sub tree has only one node  it is in the left you can do the same thing  i am just showing it to you at high level in fact this is the level i will be following for all the algorithms we do in this class you will have to translate it in to code what you have to do is recursion or whatever it is the idea of the assignment would be that many of these algorithms you should learn or you should figure out how to best program efficiently you can write down the code also for this given the pre order and post order traversal of a binary tree every internal node of which has exactly 2 children  you can even use that to figure out what the tree is why did we work with 2 traversals ? why can not we just take pre order ? so given just a pre order traversal can i use that to figure out what the tree is ? this has the pre order traversal the a  b  c  d  f  g  e was the pre order traversal of this tree this is one tree with this as a pre order traversal can you think of another tree which has this as the pre order traversal ? i could just have all of the nodes in one line to say  a b c and d below it  f after it g after at it  e at the very end  refer slide time  41  04  i could get huge number of different combinations all of which would give rise to the same preorder traversal so with just the knowledge of one traversal you can not really do much similarly for post order similarly for in order  even if i were to give you the in order traversal of this you can construct many different trees with the same in order traversal so just using one  you can not really do anything but 2 suffices for most purposes in the only case when 2 does not suffices when you are given the pre order and the post order traversal if some internal nodes of your binary tree could have only one child but if you were told that every internal node has 2 children then even that is sufficient can you count the number of binary trees given only lets say a preorder traversal ? what do you think ? at least 2 to the power n-1 we said a  b  c  d  e and f is my pre order traversal of a binary tree we said a  b  c  d  e and f this is one and all you are saying is i can make each one of them either a left or a right child of its parent so this could be one the other option could be at the side a  b  c  d  e  and f and so on so just since each of the nodes can be either the left or right child of its parent but there are many other possibilities this is absolute minimum you can have many other possibilities there could be lots and lots of things possible of course it will be finite because there are only finitely many different trees with 6 nodes on them it will be of some finite number  it will be just a function of n exactly but i do not know how to compute the close form expression for such things  refer slide time  49  38  so with that we will stop today ? s class what we looked at was tree traversals how to traverse ? so 3 different ways of traversing trees  in order  pre order and post order traversal for binary trees and for general trees there is no notion of an in order traversal as you perhaps understand why there is no notion of an in order traversal for general trees ? because if a node has 3 children then when do you visit the node itself ? after visiting the first child or after visiting the second child or when ? but in a binary tree there is a notion of left and a right first you visit the left then you visit the node  then you visit the right so there is also a notion of an in order traversal and we saw some applications of these and how given inorder  preorder and postorder traversal  two of these traversals you can figure out what the tree was which gave rise to those traversals data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 8 ordered dictionaries in today ? s class we will be talking about ordered dictionaries we will also be looking at binary search tree which is perhaps one of the simplest ways of implementing an ordered dictionary  refer slide time 01  16  so what is an ordered dictionary ? it is essentially that you have the dictionary functionality recall dictionary was that you have key element pairs and you use the to insert an element  to search for an element or to delete an element besides that  in an ordered dictionary  you have the notion of the element with the minimum key  the element with the maximum key and the notion of predecessor and a successor so when i say minimum key what then it means that there is some kind of a total order on the keys this is different from when we have talked about hashing and dictionary if we recall we said that the only operation that will ever need to do on the keys is to compare two keys for equality given two keys  we have to decide whether they are the same or not so here we are going to be excepting more out of our keys here we are going to assume that there is some kind of a ordering relation on the keys so that given two keys  i can either decide whether they are equal and if they are not equal then i can say one is less than the other one is larger than the other there is ordering relation on the keys  refer slide time 01  28  conversation between a student and professor  what are the parameters ? you ? re saying to the function predecessor and successor i have just shown ? s ? as the ordered dictionary as one of the parameters it need not be so in particular you could think of a predecessor as taking only one parameter which is a particular key so predecessor of k would give me the key which precedes k in the total order in the dictionary  refer slide time 02  50  there are certain keys in dictionary s give me the one which precedes the key k and which lies in this dictionary keys are the particular field or the part of data on which the things are ordered there is a total ordered on the keys similarly the successor function  refer slide time 03  34  so what is one way you can implement such an ordered dictionary ? there are two trivial ways of doing it where in both cases  we say using a list kind of data structure so an unordered list would just keep all the elements in here so all i have shown here are the keys since it is unordered  inserting takes only a constant amount of time searching will take ordered ? n ? time in the worst case because there is no order i might have to go through the entire list before i found out where the element is and how much time will deletion take ? it takes order ? n ? because first we have to search for what we are trying to delete  refer slide time 03  45  how much time would the successor take here ? order n not order one because suppose i say what is the successor of 12 in this dictionary ? successor of 12 is not 22 it is 14 which is the key following 12 in the order relation the order relation i am assuming is just the order on the integers so 12 is the smallest key  14 is the key larger than that 18  22  34 so 34 is the largest key in it given the key 12  i have to run through this entire thing to find out the one which was the smallest key larger than 12 both successor and predecessor and min and max will all take order n time so it ? s fairly an efficient implementation an ordered list on the other hand  let ? s say we ordered the thing according to the total order on the keys so now minimum takes only constant time maximum also we can organize so that it takes constant time let ? s say i have a pointer reference to the end node in this list  refer slide time 04  33  successor also takes constant time because given a particular node  i can just go to next one that will give me the successor let ? s say predecessor takes constant time it depends upon how you give the node when i ask for successor of a node if you have to search for the node then of course it will take order n time because you might have to go through this entire list to reach that node but if i tell you where the node is  let ? s say i give you a reference to this particular node in this list  then you can compute the successor and predecessor in constant time inserting also takes order ? n ? times because you have to find out where to insert you have to find out the correct position for insertion searching takes order ? n ? time because again we may have to run through the entire thing if we use an array  searching can improve and you have seen an example of how to do this  refer slide time 05  43   refer slide time 06  03  we use binary search to do that if you put the elements they are ordered i put them in an array then we can do a binary search to find the element in log time if we do binary search then now insertion and deletion still take order n time  refer slide time 06  33  while we can find out what is the place to insert an element  you will have to shift all the elements to the right so it takes lot of time to do the insertion similarly for deletion  we know where the element is which we are trying to delete then we have to shift everything to the left just to recap what binary search was  so you remember binary search to search for 22  you go to the middle element 22 is larger you will go to the right 25 which is smaller go to the left so on and on in that manner  you will eventually end up with the array location which has 22 or an array location which does not have 22 in that case able to say whether 22 is there or not and the number of comparisons you would take in this process is only logarithmic  refer slide time 07  15   refer slide time 07  43  every time you make a comparison the size of the array and which you are making the search ? halves ? and number of times you can half n to get down to one has only log of n and so you will take order log n time to do the searching recall insertion and deletion i said that will take order n time these are the trivial ways you adopt to implement an ordered dictionary  refer slide time 07  49  but we are not here to talk about trivialities so we are going to look at something more interesting and that ? s called a binary search tree what is a binary search tree ? a binary search tree is a binary tree which has a search property on it recall what is the binary tree binary tree is a tree in which every node has at most two children a node can have one child  two children or no children no children means it is a leaf node and now there is a search property that we are talking out so each node is going to contain a key and an element in most discussions that follow  we will not be talking about the element at all we are just interested in the keys  refer slide time 08  32  what is written on the nodes are the keys now what is a binary search property ? the binary search property says the following all the keys which are less than five will be in the left sub tree all keys which are larger than five will be in the right sub tree and this property holds at every node not just at the root node  hindi  not all keys which are larger than 3 of course there are keys larger than 3 which are here but basically if i look at the left sub tree  all the keys in the left sub tree will be less than this node all the keys in the right sub tree will be larger than this node  refer slide time  09  47   similarly for this tree all the keys in the right sub tree as you can see are larger than this key value if i look at this node  all keys in the left sub tree are less than 7 all keys in the right sub tree are larger than 7 this is called search property  refer slide time 09  05  a binary tree in which the nodes have keys which satisfy the search property so the search property satisfied is called a binary search tree so binary tree plus search property equals binary search tree i have these set of keys  2  3  5,5,7,8 this is the binary search tree with these keys in it this is also another binary search tree with the same set of keys you can have many different kinds of trees with the same set of keys both of them are binary search trees because they both are binary and satisfy the search property  refer slide time 10  26  conversation between professor and student  it is implementation keys stored at the node in the left sub tree of v are less than or equal to k  refer slide time  11  00  so there are couple of features here here i am assuming that you might have two keys which are the same so quite often this doesn ? t happen so quite often you would be using dictionaries only in settings were the keys are unique no two keys are the same  refer slide time 11  22  suppose you had the setting where two keys could be the same  suppose your key was the name of a student  you can define total order of names let ? s say lexico graphic order or alphabetic order and then two names could be the same so you could have settings in which the two keys are the same then we have to decide whether if a key is equal whether it should go to the left sub tree or it should go to the right sub tree and we can decide one way or other let ? s say we go to the left we could easily have said it goes to the right there is no problem with that here actually i am permitting it to go both ways either go to the left or it could go to the right  refer slide time 11  54  so for the rest of the discussion let me just assume the keys are unique otherwise it unnecessarily complicates matters so we will just assume keys are unique  do the entire discussion see if there is a need of duplicate key this is what should we do then if there are duplicate keys how do you handle that now ? suppose you want to search in a binary search tree  given a particular key so after all it ? s a dictionary we are implementing dictionary so given a particular key i want to find out where the element is so let me first show you an example  refer slide time 12  50  suppose this is my tree and i want to search for 11 i come to the root i compare 11 with 5 11 is larger than 5 so search property says that 11 has to be in the right sub tree that was the search property keys which are larger than here will be in the right keys which are smaller will be in the left so we go to the right sub tree  hindi  11 is larger than 10 so once again if it is there at all in the tree  it has to be in the right sub tree hence we go the right sub tree and we compare 11 with this and we find 11 so we are done we found 11  refer slide time 13  00  that ? s what was being said here to find an element with a key k in a tree t  you will compare key k with the key in the root if k is less than the key in the root then you will search for the key in the left sub tree otherwise you will search for k in the right sub tree  refer slide time 13  54  suppose we have same example but now searching for 6 we come here 6 is larger so we go right then we compare 6 with 10 6 is smaller so we go left then we compare 6 with 7 6 is smaller so we try to go left but the left child is null so it ? s not there because if it were there  it has to be here  refer slide time 14  22  it has to be in the right sub tree of this guy because 6 is larger than 5 it has to be in the left sub tree of this guy because it ? s less than 10 it has to be in the left sub tree of 7 since it is less than 7 so if 6 were there  it had to be here and since it is not here  it ? s not there  refer slide time 14  56  so we can write the search procedure for binary search tree either as a recursive procedure or as an iterative procedure so the recursive procedure is perhaps the simplest to understand so you are searching for a key k in a tree t so you look at the root of t let ? s say that its x if x equals nil which means there is no root or empty tree then you are essentially saying that nothing is there so just forget this for now if the key in this root node x is equal to the one you are searching for  then you just return the root node if it is less than the key in the root node  if k is less than the key in the root node  then you have to recursively search in the left sub tree so you are searching in the left sub tree of x and what you are searching for ? you are still searching for k  refer slide time 16  20  so what is the left of x doing ? this is all pseudo code let me come to what your question is x is a reference to a particular node so x to begin with refers to the root of the tree and then left of x is the reference to the root of the left sub tree so it ? s referring to that and we are searching for k in there so that ? s what we have to do and if key is larger than the key in the root  then we have to search for k in the right sub tree this is clear with everyone let ? s go to the iterative version in the iterative version  we are not going to make recursive calls to the search procedure what we are going to do is as we are doing in the search  we are just going keep matching down the same tree  refer slide time 18  14  so we start with x referring to the root of the tree well if x is nil which means that it ? s an empty tree and k is not the key in the root then we will do something what will we do if k is less than the key ? then we have to go left so x now becomes the left child x now gets the value of the left child of this current node so we started off with x  referring to this guy and then we said if k  so suppose there is key k1 here we are searching for the key k if k is less than k1 then we go left  if k is more than k1 we go right and since we go left here we are now continuing the search here so x is gets the new value which is either x dot left child either you want to call this way or actually in the code just showed you just now  i have written it as x gets left x pseudo code i can use any one of these so this is what it gets and we continue this search we are basically may be the next step we go right and so on and on till we reach here  this is where our node x so x will keep getting modified  first it will pointing to this node then its pointing to this node  pointing to this node and eventually pointing to this node it ? s keep getting modified in this manner  refer slide time 21  02  how much time does search take ? so let ? s look at the iterative version of the search what we did was that with each time we went through this while loop which is here  we came down one level in the tree we went from a node to one of its child nodes either the left child of that node or the child of that node   hindi  we can came down one level  refer slide time 21  15  we started at level zero which is the root then we came after one run of while loop  we came to one level after that we came to level 2  level 3 and so on how many times we will execute this while loop  the maximum number of levels in the tree and what is a maximum number of levels in a tree  it ? s the height of the tree so if the height of the tree is h then the running time of procedure is no more than h so order h is the running time of procedure  refer slide time 21  50  now h recall can be very large i might have a tree on n nodes whose height is order n and we will see at what kind of situations this happens but note that the height of the tree could be very large the search time is only order h the height of the tree  order the height of the tree but the height of the tree in particular can be has large as the number of nodes in the tree let ? s look at other procedure that of finding the minimum element in the tree  refer slide time 22  45  where do you think the minimum element in a binary search tree ? why left most tree ? left most node or left most leaf ? left most leaf let ? s see why that ? s wrong suppose i have a tree which looks like the following i need to put up in some keys so that this looks like a binary search tree so let ? s put in 7  5  6  12  13  11  10 this is the binary search tree ? now which is the smallest node here ? the leftmost leaf  i do not know the left most leafs but this must be the left most leafs but this is not the smallest one smallest node is 5  it ? s really the left most node expect left most node also doesn ? t too much sense last leaf  this is not a leaf at all  refer slide time 24  29  let ? s not try to say which node ? last internal node this is an internal node  you want me to take more internal node without left children no  i can create more internal node without left children so this is also an internal node without any left children so don ? t try to just give the half a sentence definition of which the smallest is  but let ? s give a procedural definition  refer slide time 25  02  so which is how do you find the smallest ? start at the top  keep going left till left becomes null that is clear to everyone so start from the top  keep going left till the left is null and that ? s the smallest node how about maximum ? keep going right till the right becomes null what ? s the proof ? why this is minimum ? so the proof is very simple  the minimum has to be to the left of its root  so it has to be in the sub tree then you have smaller  so the smallest has to be left and there is nothing to the left so this has to be smallest  everything to the right has to be larger than this so in one line that ? s the proof for this fact  refer slide time 26  06  so that ? s the entire code essentially  you want to find the minimum in a tree x so while the left of x is not null  just do x is left of x  keep going left of x when you stop ? when left of x is null at that point you will just return x or return the key x or return the element or whatever you want return so how much time do you take again in this ?  refer slide time 26  10  so why because of same argument  with every run of this while loop we are going down one step so we can go down at most the number of the height of the tree and so that ? s the maximum time taken the same procedure can be used in small modification to compute the maximum we just have to replace the left by right and then we will complete the maximum let ? s see how to compute the successor element of a tree ? successor  understand what successor means ? successor means given a particular key after find out the next one so given x  find the node with the smallest key greater than key of x  hindi   let ? s see so there are 2 cases  hindi  all of you saying key sub tree  hindi conversation   so there are two cases really so case one is in the right sub tree of x is non-empty  there is something in the right sub tree so the picture is  hindi  this is the node  hindi  successor  hindi  right sub tree is non-empty  there is a right sub tree it exist say  hindi  so then we know that the key which is larger than this  all the keys in here are larger than this we know that but why should the successor be lying here ? why can ? t the successor be some where else ?  refer slide time 27  58  it is greater than this so i know that the keys here are larger than 5 but there are other keys which are larger than 5  the parent is one key which is larger than 5 so lots of confusion so we need to look at it more carefully so what i am way trying to say  let me draw this picture that was there on the fresh sheet of paper so i have 5  i will put down 5 here in the center and we have 10 here  we have 7 here and we have 8 here  we have 1  3 now i have to find out the successor of this 5  refer slide time 30  17   i am trying to find out the successor of this node this has the sub tree  now all of you are tempted to say that successor of this guy has to lie in the right sub tree  you want to say that the successor lies here  why ? this is not the entire tree  please remember it could have a parent  the parent is going to be larger than this 5 when it is larger than 5 ? when it is in the left sub tree so there are two possibilities  the parent is larger than 5 which means 5 is in the left sub tree of the parent but than this guy will be larger than all of this guys because all of this guys then are in the left sub tree of the parent the a successor  hindi  this parent then can not be the successor  refer slide time 31  31  why ? that is the procedure which you have learnt but why is it that the successor only has to be in this right sub tree but nowhere else if the right sub tree is not null conversation between professor and student  refer slide time  31  58   but the next element which is larger than 5 could be let ? s say this is my entire tree  it could be some where here  hindi  why not ?  refer slide time 32  17  the easiest way to think of this is as follows suppose we were searching for some elements slightly larger than 5  we were searching for the successor of 5 the claim is that suppose we were searching for 5  the claim is that we must end up at this node that ? s a point  whatever decision we are making  we would end up at this node now if the key we were searching for is slightly larger than 5 then that means we are searching for the successor of 5 then that means we would second end up with this node and proceed because it is larger than 5 so which means that any successor of 5 really has to lie in this part of the tree so in this part of the tree the successor is essentially be minimum node because all the keys here are larger than 5 so the minimum key here is the one we are looking for  we have already seen a procedure for completing the minimum which is that keep going left we will go left  we will go left and we can ? t go left any further so this becomes the successor of 5  refer slide time 34  22  it remains me the remote that i have at home so that ? s what we have to do  if the right sub tree is non empty then we go right one step and keep going left  refer slide time 34  24  the other case is in the right sub tree suppose i was trying to look for the successor of 3  if i am trying to look for the successor of 3 the right sub tree is empty so where is the successor of 3 now ? look at the parent  refer slide time 34  57  the procedure is the following and we will see why it is a right procedure what you are going to do is start going from this node to its parent and then to its grand parent and so on till you reach the node such that this key x that the successor you are looking for is in the left sub tree of that node so you went up to here but note that this is in the right sub tree of this node then you went to its parent and here you found that 3 is in the left sub tree of 5 so we will stop here and this will comes the successor you understand the procedure but why is that procedure correct ? so recall the procedure is  i am searching for the successor of this node the right sub tree is null  there is nothing to the right then i go to its parent and i go to its parent and i keep going up to the parent till i reach an ancestor such that this node whose successor we are trying to find is in the left sub tree of the ancestor so this guy then going to be the successor of x  this node is going to be the successor of this  refer slide time  37  00   why this is true ? so this node has to be  is it larger than this ? no it is smaller because it is in the right sub tree so it is smaller  this is also smaller  this is also smaller  this is larger  refer slide time  37  23   in fact this this guy is in the largest node in the entire sub tree because how did i find the largest node i come here and keep going right which is exactly what i do  so this is the largest in the entire sub tree and the node following this is then this guy yes or no ? can the successor could have been some where else  could it have been to the right of this guy because all of this going to be larger than this  can it be an ancestor of this guy this ancestor is less than this but this ancestor if it is less than this it is also less than entire thing it ? s not a successor but if you are looking at this ancestor then this ancestor would be less than this and it would be less than entire thing so i was wrong  this ancestor is less than entire thing is not really a successor but this ancestor is greater than this entire thing but it is also greater than this so this is only the successor so better for confusion but you understand what the arguments are  refer slide time  38  57    refer slide time 39  01   refer slide time 39  08  so let ? s see what code i can write for computing the successor if this not null then i just return the minimum in the right sub tree otherwise i will come to this point i am looking at the parent  now so y is the parent and what i am doing here ? if y is not null and x equals right of y  so when do i have to keep marching till x becomes the left  refer slide time 39  56  so essentially recall i am going up the tree and the first time i essentially i am at the node such that the node is the left child of the parent then i stop the first time  so let me show you the previous slide the first time so i keep going up here the first time i come to a node such that the parent such that this node is the left child of the parent then i stop  refer slide time 40  22  so for instance if i were looking for a successor of 8  i would go up like this and this is the first time the node is a left child of its parent and so i stop it so that ? s what we are doing here  so initially y is the parent of x and all we are doing is moving the pointers x and y so y is the parent of x and then we are changing it so that x takes the value y and y takes the value of parent of y  so that it moves one step ahead  refer slide time 40  46  so in some sense these are a pair of pointers which are moving up the tree with y always ahead of x  x y  the x moves and then y moves and x moves and then y moves and so on when do we stop ? when x is the one which is trailing  y is the one which is head when x is the left child of y when x is the left child of y we will stop so essentially we are continuing in the loop till x is the right child of y  when x becomes the left child of y we will get out of the loop or y becomes null that means i have gone beyond the root then we stop and we return we return y which was the parent node in case y hits null then we will return y which means null if we return null which means it could not be found  so you can have a closer look at this code and convince yourself that it is correct so once again what is the running time of the successor code ? order edge  in each of the cases  in one case what we are doing ? we are going down the tree but we only go down as many levels as the height of the tree at most in other case we are going up the tree so the maximum number of levels we can go up the tree is at most the height of the tree  refer slide time 41  44  so now look at the insertion procedure in a binary search tree till now we looked at search  how much time did search take ? order edge  height of the tree we looked at minimum  we looked at maximum both of them take time proportional to the height of the tree  worst case time and we looked at successor and it took time proportional to the height of the tree can you also compute predecessor ?  refer slide time 42  50  similar idea  essentially interchange role of right and left  successor may  hindi conversation  and we will match up the tree and all of that is the same thing let ? s look at insertion so that ? s the other thing we will do today  we will take care of deletion in the next class so insertion i have a binary search tree and i want to insert an elements so what should i do ? alpha search for the elements  refer slide time 44  00  i first find out the place in the tree where the element should be we are assuming distinct keys  we are assuming that node to elements of the same key so we first find out where it should be and then we put it there so that it is actually there so let ? s look at an example  this is my binary search tree and i am trying to insert 8 so  hindi  you recall this 8 is not there in the tree so i fist search for 8 which means i go down i come here go right  i go left and then i want to go right but right is null which means 8 is not in the tree  so i put 8 here which means that 8 becomes the right child of 7 at which ever point the search fails because we hit a null pointer and null reference we put the node there that ? s all insertion is how much time does the insertion take them ? order h  which is same as searching essentially  hindi conversation   so now that brings me to that question i had asked at the beginning of the class which is in what order should i been inserting the keys in a binary search tree so that its height ? so we said the maximum height of a binary search tree is in or in minus one or one of those things this is the maximum height of the binary search tree suppose i have n keys  in what order should i insert those keys so that i can get a tree of height n ? 1 ? let ? s say our keys were 1  2  3 up to n so what order should i insert them  exactly this order or the descending order so  hindi conversation  we will insert 4 at this place and in this manner we will create the chain of this kind and we will get a tree of height n ? 1  refer slide time 46  03  similar would happen if i had inserted in the descending order so which order should i insert it so that it can get small height ? the first element i should insert is n by 2 which is the next element i should insert ? n by 2 ? 1 ? n by 4 and 3 n by 4 and then i would get something like this and now n by 8 and is it clear that n by 8 will come here ? why this because you will compare and put it here and which is the next one ? 3n by 8  suppose i insert 7 n by 8  if i insert 7 n by 8 what happens ? so can i insert 7 n by 8 at this point  can i insert 7 n by 8 ? no harm i can also insert it here 7 n by 8 will always come here  now i can insert my 3 n by 8 and now i have to insert 5n by 8 which will come here essentially i have to go level by level or i have to insert these nodes first and only then i have to insert later nodes otherwise so in this manner i will end up with what kind of a tree ? height balanced  a complete binary tree i have not told you what height balanced trees are  you don ? t know what the height balanced tree  you don ? t even know the full binary trees is  we have learnt only what a complete binary tree so this we will get is the complete binary tree  complete binary tree provided your n was some power of a 2 or 2 to the k ? 1  n has to be of the kind 2 to the k  1 then you will get a complete binary tree so in the next class we are going to ask the following question if i was able to take a random permutation of these elements  if i put the elements in an ascending order then i get a bad tree why i am calling this a bad tree and this a good tree ? because of the height  this has the huge height  this has a small height why is height such so relevant because so all our operations were depended upon the height of the tree the smaller the height of the tree  the faster the operation is so you would like to keep the tree height as small as possible  refer slide time 50  01  so we don ? t really want trees of this kind  of course you know with some effort you could figure out in what order should i insert these elements so that i get a small height tree and what is the bad order suppose i were to just take a random permutation of one through n  you understand the random permutation take one of the permutation there  where n factorial different permutation take one of them at random and insert elements in that order what will be the height of the tree then ? depends on what you or and me ? who does the insertion on the permutation ? it will depend up on the permutation so we have to talk of random variable so the height of the tree now will become a random variable you understand what a random variable means ? variable which takes many different minimum values so the height of the tree could take one of many different values  refer slide time 50  06  what are the many different values that the height of the tree can take ? log n to n  log n to n  1 or log n + 1 to n ? 1  i don ? t know exactly which but one of those log n to n so it will take one of these different values and it will take each of this value with a certain probability because after all i took a random permutation so what we have to find out ? so taking each of these values in the different probabilities so you have to find out what the expected value of these random variables we will address this kind of a question in the next class  refer slide time 51  47  so this can be the code for insertion  so i am given a tree t  hindi  i will just switch this can be the code for the insertion  i am trying to insert this node z into a tree t and once again i am going to have two pointers x and y and what is the need for this 2 pointers x and y because recall when i am inserting a node so when i am inserting this node z  i am searching for z the key corresponding to z in the tree  refer slide time 52  21  then i hit this null and so we said we will put z at that place but to put z at that place what we will have to modify ? the parent of z  hindi  right child  hindi  modify child a left child  hindi  modify  hindi  essentially parent pointer parent  hindi  pointer  hindi   we will have two pointers x and y such that now the game is that y will be preceding x  refer slide time 53  28  so these two pointers will keep moving down such that y will always be the parent of x so that ? s what we are doing initially y is null  x is the root then y takes the value x and x goes to either left or to the right child of x and we keep doing this till we hit null  till x becomes null when x becomes null y is pointing to the right node  hindi conversation  so y is going to be the parent of new node we are inserting  so parent pointer of z so recall that the node is also have a left child and right child and then parent so parent of z gets the value y and depending up on whether the key of z is less than the key of y or more than the key of y  if key of z is less than the key of y then z will be a left child of y then the left child of y becomes z and if key of z is more than the key of y then the right child of y becomes z  refer slide time 54  18  that ? s all you have to do but does everyone understand what the need for having these two references you need to keep track of the parent because that ? s the one you have to modify so you will go modify that and you will just set it appropriate to the left to the right so already i discussed this  so in what sequence the insertion should be done  we saw that which should be worst case sequence so with that we are going to stop our discussion  refer slide time 55  20  on binary search tree we will continue this in the next class with the deletion procedure for binary search trees and will also look at this questions that i asked you today but if to insert elements in the random order then what is the time taken to do the insertion and what kind of the tree do you get as the result of that data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 9 deletion today we are going to start with deletion in the last class we saw how to do insertion  search  computing successor  computing predecessor  computing minimum and maximum in a binary search tree today the only 1 operation that is left is the deletion and so we are going to see how to do deletion in a binary search tree then we are going to address the question that i had raised in the last class which was that if i were to insert some n elements into a binary search tree  suppose i were to randomly permute my elements and insert them then what can we say about the time that the insertion would take today we will see all of that in detail  refer slide time  2  21  we are given a node x in the tree and you have to delete the node we will distinguish 3 cases x has no children which will be the easiest case for deletion  x is the leaf in that case if x has only 1 child even then the case will be very easy and we will see all of that and when x has 2 children it is slightly trickier but still fairly straight forward when x has no children then deletion is trivial why is that because the point b is the node x  it does not have any children so it is a leaf i need to delete the node x i should just cut this length which means we will have to change either the left child or the right child of this parent in this case node b was the right child of the parent a  so we have to set the right child of a to null if b were the left child then we would have set the left child to null the 2nd diagram in the below slide is the tree that would be left after the deletion if the node that you are trying to delete is the leaf node then the problem is trivial  refer slide time  3  09  what happens if the node that you are trying to delete has only one child ? from the slide given below  you are trying to delete a  it has only 1 child which is b a does not have a left child the operation is like that you can think the part abd as a linked list it is just like a linked list and you are trying to delete a node from the linked list you take the previous node which will be d and you will make its left child point to b  refer slide time  4  54  effectively you are removing the 2 links which is coming from a and you are establishing the link directly from d to b are you convinced that this would maintain the search property why should b be on the left of d and not on the right of d ? because b is less than d  and b is in the left sub tree of d we would make b as the left child and everything that is below b that is all the descendants of b are also less than d because they are all in the left sub tree of d we will just continue with them as there is no change the only change that happens is that the 2 links from a go away and you set up 1 link from b to d so very little has to be done in this case in the above slide 2nd diagram will be the new setting or this is what will happen after the deletion you have d  b and f but a goes away the 3rd case is when the node to be deleted has 2 children x is the reference to the node which is to be deleted the node to be deleted is the one containing d and it has 2 children since it has 2 children let us do the following  it has a left sub tree and a right sub tree we find the predecessor of d we have seen how to do successor but we also said that you can equally find the predecessor how do you find the predecessor ? the predecessor of d would be the largest element in the left subtree we just have to come left and keep going right  since b does not have right child so b is essentially the predecessor of d in this example  refer slide time  07  40  how many children does b have ? b can have 1  it can have a left child nothing is preventing us from b having a left child i could have a situation in which let us say t  you could have something like t but b does not have a right child  there is nothing in the right side of b if b had a right child then it would not have been the predecessor of d  because we would have gone down further b has only 1 child or no child  the node t need not be there that is what is being said here b or y is the same thing the y is the reference and b is the content sometimes i am calling it b  sometimes y but this has atmost 1 child we are going to delete b and essentially we are going to move b to d that is we are not establishing such a link from b to d  but we are going to replace d with b and delete the node b why would the search property not get violated by moving the content of b to d ? since b was the successor of d  everything in this left subtree was less than d and b is the largest element in this left subtree everything in this left subtree is also less than b  if i move b to d there is no problem as far as the search property is concerned everything in the right subtree is more then d and so it is also more than b by moving b to d again the search property is not violated  refer slide time  08  38  i can move b to d and can i delete b easily because b has either no child or 1 child we have already seen how to delete a node which has no child or only 1 child if b had a left subtree and suppose i decide to move b to d and there is nothing left so we will delete the node b when we delete the node b  what happens we will make the right child of a point to that node the node b gets deleted and the link corresponding to that goes away and we create 1 link and it goes to the point where it is directed and b moves up that is the operation and now we have covered all the 3 cases the 1st case was when there were no children  2nd case was 1 child and 3rd case was 2 children we said in the 3rd case we will have to move the content of b to d and then delete the node b we worked with the predecessor but we could also have worked with the successor  since d has 2 children we can also find the successor of this node by going once right and then keep going left the same kind of a thing can be done even there  we could have replaced d with its successor instead of its predecessor but in this example i have shown the predecessor what do you think is the running time of the delete operation ? suppose you do not even have to search for the node i tell you this is the node and i give you the reference to the node that you want to delete how much time does it takes to delete ? in the 1st case when the node is a leaf  how much time it would take ? order one because it just needs to go the parent there is a pointer in the node  reference to the parent node i just go to the parent and i just update the link that is the right or the left child of the parent i am giving the reference of the particular node which has to be deleted in every node we also have a parent  left child and a right child we can always go back to the parent and update the content to show the deletion operation in the 2nd case if we are deleting the node a  then once again we need go to the parent and modify its left child  again a constant time operation in which case do we take more time ? in the case 3  because here we have to find a predecessor or a successor predecessor can take time as large as the height of the tree because we will have to go once left and then keep going right we can take in the worst case time proportional to the height of the tree case 3 takes more time and the time taken in the worst case is the order of the height of the tree  refer slide time  13  15  the pseudo-code for deletion is given in the below slide  so that you will understand roughly what is happening and we do not have to look in detail if the left or the right is nil then we know that either it is a leaf node or it is a node with only 1 child then in that case  z was the node which i am trying to delete so y ? z and we look at the treesuccessor  z   i am not completely sure that what i have is right  so let us just skip this you would have understood the delete operation i might have made some mistakes somewhere in the pseudocode predecessor or successor is the same thing  we can also work with the successor that is what i said for the successor we have to search in the right tree i do not think that it is very critical but let us skip this thing for now you understood the delete operation and the pseudo code you can all write yourself  refer slide time  13  51  suppose i give you a binary search tree and i do an in-order traversal of this binary search tree what does in-order do ? first the left then the 5th node then the right first we will be printing out all the keys on the left suppose all i do when i visit a node is print out the key that is what my traversal procedure is  first i will print out the keys which are on the left in some order then i will print the key which is in the center and then i will print out the keys on the right this means that i will print out the root key 5 after i have print out the left and before i print out the right all the keys on the left are less than or equal to 5 and all of the keys on the right are greater than or equal to 5  which means that 5 really comes at the right place in the ordering of these keys because everything which is less than 5 comes before 5 and everything that is more than 5 comes after 5 hence 5 come really at the right place and the same argument can be set for every key not just the root key when will you print 3 out ? after i have printed everything to the left which means everything that is smaller than 3 will come before 3 and then i will print out things on the right  refer slide time  16  54  in in-order traversal  if you were to just to look at this and see in what order you would print out first you will come to 3 and then go left  then come to 2 and print this one then you will print 3  5 then you will come right and then go left and so on this is the order in which you will print the keys the property of the in-order traversal of a binary search tree is that it prints out the keys in increasing order this can be a good method of sorting a bunch of keys i will call this the binary search tree base sorting procedure what is the method ? you have a bunch of keys which you want to sort you first insert all the keys into a binary search tree that is what you are doing in the slide given below you are taking all the keys and inserting them into a binary search tree and then just do in-order traversal of this tree you will get all the keys in an increasing order that is you have sorted a set of keys  refer slide time  19  31  how much time does this procedure take ? we have to insert all the keys and then we have to do an in-order tree work let us first look at how much time does the in-order tree work take how much time does it take to traverse the nodes of a tree in in-order ? it is order n why it is order n ? we have to print all the node but i might take much more time i need atleast order n time may be i need more time we will look at this question later how much time does it take to do an in-order tree work ? actually it just takes linear time that is it takes order n time we will not do it in todays class  we will see how to argue that it just takes order n times how much does the part which is given below takes  when i am inserting all the elements into a tree ? for i ? 1 to n treeinsert  t  a  i   it is n log n but why it is n log n ?  refer slide time  20  14  this is my bst sorting procedure i want to sort the keys given in the above slide  i insert them into a binary search tree one after the other first 5 then 10  7 then when i insert 1 it will go as the left child of 5 then when i insert 3 it will go as the right child of 1 when i insert the other 1 it will go as the left child of 3 it depends upon how you are doing it  it could also have come as the left child of the other 1 and it is the same thing and 8 would come as the right child of 7 and the final diagram in the above slide is the tree you would get if you have to do any in-order tree work on this tree you would get exactly the sorted sequence how much time does it takes to insert all the n elements ? it depends upon the sequence if i were to sort let us say given a set of numbers 1 through n and i just want to sort them the total time taken to insert this numbers is equal to the sum of the levels at which the nodes will come up because when i insert a particular number i come down the tree and i insert it at a particular place the number of levels i traverse or the number of comparisons i do before i insert it is exactly equal to its level either level or level + 1 or level -1 but you can think of it as the level for now if i had inserted the numbers in sorted order  first i inserted 1 then i inserted 2  3 and so on what is the kind of a tree i would get ? i would have 1 followed by 2 followed by 3 and so you remember that kind of a picture i would get a tree some thing like the one which is given in the slide in blue color from 1 to n what is the sum of levels ? it is from 0 + 1 + 2 + 3 ?  n-1  and o   is the series which sums to  that is not good  the time taken for insertion could be as bad as   refer slide time  22  15  is this clear to everyone and this bring backs the question that we had asked in the last class i take a random permutation of the elements there are n factorial different permutations i take one of them at random i insert the elements in this particular order i want to compute the time it takes to insert the time required for insertion is a random variable we saw an example where the time required for insertion could be as bad as  that is what i showed you in the previous slide in the best case it could be quite small and we will the best case it is really a random variable it depends upon the sequence and the permutation in which we are inserting the elements in fact we had discussed the best case in the previous class  we said the first element inserted should be then it should be and then and so on  refer slide time  24  52  all the way we had not computed the total time for insertion the total time for inserting these n elements is really a random variable and for random variables we compute what is the expectation of the random variable recall what is the expectation of a random variable ? if a random variable takes many different values then the expectation of the random variable is obtained by taking the average if the probability of each value is the same otherwise you essentially do many trials which means that you compute the value of the random variable then you do the experiments once again and so on look at the value of the random variable that you get and take the average over all the trials that is how you compute the expectation of the random variable in our case it is easier because each of the permutation is equally likely we are saying we will just pick one of the permutations uniformly at random each of the permutation is equally likely so we are going to see how much time it takes to insert the elements in the order given by a certain permutations how do we compute the average ? we will take a permutation  insert the elements in that order and compute the time it takes to do that insertion then take another permutation compute the time it takes to insert the elements in that order  take the 3rd permutation compute the time it takes to insert the elements in that order and so on  refer slide time  26  18  there are n ! different permutations  while compute the time it takes to insert the elements in the order specified by these n ! different permutations you will get the total time this huge quantity and will then divide by n ! to compute the average and that could be the expected time it takes just to summarize  for each of this n ! permutations we will compute the time taken to insert the keys in the order specified by that permutation and then we will compute the average the average is computed over the n ! permutations we will denote this quantity by t  n   whatever is this value will be t  n   let us see how to compute t  3    refer slide time  28  50  t  3  is the tree obtained or is the expected height of a tree on 3 nodes what are the various possible trees on 3 nodes that we get ? what are the various permutations of elements 1  2  3 ? we will have 6 different permutations as given in the slide when we have this particular permutation what is the tree we would get ? if we were to insert the elements in this order  1 2 3  and you will get a tree whose root is 1  2 would come to the right and 3 would come after that when the elements are inserted in this particular order  1 3 2   we would get a tree 1  3 to the right and 2 to the left of 3 if the elements are inserted in this order  2 1 3   we will get a tree which is 2  1 to the left and 3 to the right when elements are inserted in this order  2 3 1   we get a tree which is 2  3 to the right and 1to the left when elements are inserted in this order  3 1 2   we get a tree which is 3  1 to the left and 2 to the right of 1 but to the left of 3 and in this order  3 2 1   we get 3  2 to the left and 1 to the left what is the total time taken for insertion ? we recall what we said  it is just the sum of the levels of the nodes the levels of the nodes are 0  1  2 and so the sum is 3 in the next one the levels of the nodes are again 0  1  2 so the sum is 3 for the next one it is 0 and 1 in which both 1 and 2 are at level 1  so the sum 2 for the next one also the sum is 2 for the 5th and 6th one the sum is 0  1  2 that is 3 total of 16 and so the average is which is 2.66 which is t  3   hence we computed t  3  as 2.66 that is what being said here  for each of the n ! permutations we are going to compute the time taken to insert the keys which is what we did for t  3   then compute the average that gives us the value of t  3   but we can not do the computations in this manner  we have to do it cleverly because we have to compute what t  n  is now am going to fix a particular element i and i am going to look at all permutations in which the element i is the very first element in the permutation  refer slide time  29  10  there are  n-1  ! permutations in which i is the first element in these  n-1  ! permutations the tree that we obtain will have i as the root because it is the very first element and then the keys one through  i-1  will be in the left subtree of the root and the keys i + 1 through n would be in the right subtree of the root let us look at one of this  n-1  ! permutations and restrict our attention to the keys 1 through  i-1   they will be coming at many different places and at some places in this permutation let me look at another one of these  n  ! permutations these keys 1 through  i-1  would be coming at some other place if i look at all of these  n-1  ! permutations they will induce permutations of keys 1 through  i-1  elements also every permutation of 1 through  i-1  would be there  refer slide time  31  35  in particular each permutation of 1 through  i-1  would occur how many times there are  n-1  ! permutations in all and there are  i-1  ! permutations of the elements 1 through  i-1  and there is no reason why one of these permutation will occur more often than the other permutation each of them is occurring equally likely how many times is each one of them occurring ? it is times you can also think of it in a slightly different manner you have these  i-1  elements somewhere and the other  n-i  elements are getting inserted at different places how many different permutations are there of those  n-i  elements that are getting inserted ? you can compute that and it will be exactly this quantity this is a simpler argument  there are  n-1  ! permutations in all and there are  i-1  ! permutations of these elements 1 through  i-1  and there is no reason why one of these permutation should be more likely than the other one they will all occur the same number of times it is symmetric of law  each permutation therefore of these elements is occurring exactly times  refer slide time  33  12  suppose i had only  i-1  keys  1 through  i-1   then the average time taken to insert these keys is t  i-1   this is what we defined t  n   this average is the average taken over all the permutations of 1 through  i-1   the time taken to insert all these  i-1  ! permutations are just  i-1  ! t  i-1   the average time is t  i-1  and the average is taken by computing the total time to insert all the  i-1  ! permutations divided by  i-1  ! the total time to insert all the  i-1  ! permutations are  i-1  ! t  i-1   for instance in the example that we did earlier for t  3   the total time taken to insert all the permutations was 16 which we had computed  that was the average times 6 when we are inserting the keys 1 through  i-1  into the left sub tree  we go back to the previous setting recall we are considering only permutations in which the first element is i the keys 1 through  i-1  when we are inserting they will all be compared first against i and then we will go and put them in the left subtree each key has to be compared with the root which is i it is like as if i am creating a left subtree of  i-1  elements but i can not just count that as the average call i am also counting one more because for each of those elements in the left subtree their level is actually one more than  if it were just the left subtree  refer slide time  34  60  let me clarify what i am saying in the above slide the small round in blue color is the i and the keys 1 through  i-1  are coming inside the triangle if that triangle in blue color were my tree then i know that the average time to create this tree is t  i-1  but i am creating a tree of over n nodes the keys 1 through  i-1  are coming in the first triangle and the other keys are coming in the next triangle how much time i am spending in creating this part  darker triangle  ? it is the average for 1 through  i-1  plus one more for each one of these  because first i compare with i and then come down because the level of each of these is actually one more in tree i than it is in the tree  i-1  .then it has level 2 in the  i-1  tree and level 3 in the original tree what is the total time to insert all the  i-1  ! permutations ? recall t  i-1  is the average time to insert  i-1  keys in the tree that i am creating am taking one unit extra for every node that i am inserting  because first i am comparing it against the node  i-1  !  t  i-1  +  i-1   is the time i am taking to insert t  i-1  keys and that is the average time i am taking to insert the  i-1  keys in my tree what is the total time ? i have my  i-1  ! different permutations so the total time is this product  i-1  !  t  i-1  +  i-1    each of the permutations appears so many times that is times what is the total time i spend in inserting keys 1 through  i-1  ? the total time to insert all the  i-1  ! permutations is  i-1  !  t  i-1  +  i-1    but each of the permutations is appearing times so it is just times  i-1  !  t  i-1  +  i-1   which is  n-1  !  t  i-1  +  i-1    this  n-1  !  t  i-1  +  i-1   is the total time i take to insert the keys 1 through  i-1  into my tree where this sum is taken over all the  n-1  ! permutations and this is not actually the total time but this is the total time for permutations in which the first element is i  refer slide time  36  59  the time to insert keys 1 through  i-1  is  n-1  !  t  i-1  +  i-1    similarly the time to insert keys  i + 1  through n will be similar to the one before wherever there is  i-1  i will replace it by  n-i   because that is the number of keys i am inserting that would give me this expression  n-1  !  t  n-i  +  n-i   and this is to insert the keys in the right subtree the total time to insert all the n keys is just the sum of the above 2 quantities  n-1  !  t  i-1  + t  n-i  + n-1  is the total time over all the permutations in which the first key is i what is the total time to insert all the n keys in all the n ! different permutations ? it is just the sum of this quantity  n-1  !  t  i-1  + t  n-i  + n-1  as i goes from 1 through n because the first key can be 1 or 2 or 3  n-1  !  refer slide time  40  22  all i am doing is trying to figure out the total time taken to insert all the n elements not in one permutations but over all n ! permutations put together i am trying to do it in a way so that am able to analyze it there are  i-1  ! different permutations of  i-1  elements in the sequence of 1through n those  i-1  elements are present at different places all possible permutations of  i-1  ! different permutations of those  i-1  elements are there but each of those permutations itself is occurring  n-1  ! over  i-1  ! times we have to keep that in mind we are going to work with the expression which is given below  n-1  ! the total time to insert all the n keys is above thing  this is exactly the 16 which we had computed for t  3    refer slide time  40  22  what is the average time to insert n keys ? it is basically  this is  n-1  ! the total time  so this divided by n ! would be the average below given is the one which i would get just to make sure this divided by n ! will give me and this expression i have written where i go from 1 through n note that each of these terms t  i-1  and t  n-1  will appear twice if i look at t  3   it will appear once for i equals 4 and it will appear once for i equals  n-3   each of the term will appear twice  so that this part of the sum  is 2 times t  i  where i going from 0 through n-1 this part of  n-1  have moved out  so it is n-1 where i go from 0 to n divided by n  so it becomes just n-1 this n-1 is not multiplied by and this only multiplies the following part why do i go from 0 through n-1 ? because you will never generate t  n  neither from t  i-1  nor from t  n-i   you will generate t  0   when i equals 1 you will have t  0  and when i equals n you will again have t  0    refer slide time  42  16  what is t  0  ? t  0  is zero  in fact t  1  is also zero t  2  is not zero but t  1  is zero because it is just a single element we say it is at level 0 so we just do not count it any time for inserting it such a thing is called recurrence relation the function t is a function of n  we are expressing the value of this function at point n in terms of its values at previous points i can use the below given relation to compute t  0   t  1   t  2  and so on t  0  is zero what is t  1  ? when we substitute n = 1 in the above equation  we get t  1  as zero which we argued it before so t  0  and t  1  both are zero i can use that to compute t  2   what will i get the value of t  2  ? if i were to just use this expression i would get 1 which is explained in the slide given below thus t  2  turns out to be 1 if you are not convinced so far lets also compute t  3   t  3  will be times t  0  which is zero so let me ignore that t  1  which is also zero so let me ignore that and t  2  which is non-zero so let me leave that around plus n equals 3-1  refer slide time  43  43  t  2  was 1 so this becomes + 2 which is 2.66 that is exactly what we computed you can use this recurrence to compute any t  i   we have done something fairly sophisticated we have obtained some kind of a relation which tells us any t  n  provided we know the previous values but we will do a little bit more  we will try to figure out how to solve this recurrence relation also that is what we are going to do now  refer slide time  45  20  the t  n  is times the sum of the previous t plus n-1 i can write t  n-1  is times the sum of the previous t +  n-2   i just replace the n by n-1 and so i can just rearrange this quantity or times this sum equals  i have moved this n-2 on the other side so i get t  n-1  ? n + 2 and i have scaled it by because i am trying to compute instead of  =  t  n-1  -n + 2  if the above equation were times  this would just have been this part  t  n-1  -n + 2    if you cancel out the n the is exactly this part  t  n-1  -n + 2    i just want to compute this quantity  because now am going to substitute this in the previous expression that is  i have computed 0 through n-2 as this quantity  so am going to substitute that thus t  n  then becomes this sum + t  n-1  + n-1 then i just did some rearrangement  that is and that makes it  the cancels out and so i am just left with 2 times  so we will work with the below equation all i have done is some rearrangement to simplify things i have written t  n  in terms of t  n-1   t  n  was in terms of all the previous t this is the simplification i have achieved with this point  refer slide time  47  15  let us see it is a bit of a dense slide but we will run through this very quickly this is what we have  i will just replace that is is less than 2 because n-1 is less than n that is why the less than or equal to  actually it should be strictly less because is strictly less than 1.i just simplify this a bit and now i am going to do the following i am going to replace t  n-1  by using this recurrence relation that is by using this expression  the which is times t  n-2  + 2  where the other + 2 is coming from the before expression all i have done is replacing t  n-1  with   refer slide time  49  25  let me just simplify it the n and n cancels in that expression so i get and 2 is the same then  this is just the simplification and it is exactly equal once again i am going to do the same i am replacing t  n-2  with the value of that what is t  n-2  ? it would be t  n-2   that is what i am going to replace it for t  n-2   when i do that  n-1  gets cancelled and i get t  n-3   this multiplies with this 2 and gives  this part is the same as  when i replace it i get this and this quantity gets decreasing with every step and the sum inside keeps increasing with every step next time i will add  the next time i will add and so on eventually it goes down and when t  n-4  goes down to  n-n   i get a zero and in the denominator i would get  n-n-1  so it is 1 and i just get  n + 1   inside i will get all the terms going up to + 2 since t  0  is 0 that part goes away and i get exactly the equation which is given below so i get t  n  is less than or equal to the above sum this is the sum of a harmonic series and it is going up all the way up to   refer slide time  52  47  we are summing a harmonic series  we have to sum  one trick that we employ very often  you take this graph and this is a graph of a function  these are the points 1  2  3  4 and let me draw line at 2 what is the height of this rectangle ? it is  the width of this rectangle is 1 and its area is  i have drawn a line at 3  so its area is  i am getting the terms so next one is  and the last one at n  i will draw it in this manner  refer slide time  53  27  this sum is less than or equal to the area under the curve f  x  = and it is atmost the area under the curve in between the limits 1 through n recall t  n   it is that is harmonic sum + 2 i am going to just put that 2  n + 1  and that harmonic sum was the integral of from the limits 1 through n + 2 this integral part is just log  x   it will be just log of n and 2  n + 1  ln n + 2 is exactly the sum which is o  n log n   t  n  o  n log n  it is the expected time for inserting the n keys we have done a very sophisticated computation we looked at all the n ! different permutations possible and also we computed the total time taken to insert all the n ! different permutations and we took the average we got n log n recall we saw the worst case was and there is a particular permutation which puts the elements in increasing order for that the total time for insertion is  but the average time is n log n the best time is also n log n and the best time would happen when the tree was very shallow if you have a tree on n nodes and it has a height atleast log n  log n-1 or roughly  if you take a complete binary tree of height log n the last level has keys that is in the leaf there are leaves how much time you will take to insert each one of those leaves ? log n  because you will have to come down the entire tree so to insert each one of those keys you are taking time just to insert the leaves you take   time which is  n  time a function which is growing faster than n  it is some constant time but it is n   refer slide time  55  55  in the best case you are taking n log n time  in the worst case you are taking time but the average case is also n log n that is a very interesting part if i would ask you the average case  you would just take the average of the above 2 cases and report it why it is turning out to be o  n logn  ? what does it convey ? most of the trees are fairly shallow and do not have too much depth most of the trees have depth of only about log n or some constant times n log n so that the average is still only n log n you have a bunch of numbers  the numbers here are the total time for insertion under the various permutations the smallest of those numbers is n log n  the largest of those numbers is but the average is also n logn or some constant times n log n that means most of the numbers are closer to the minimum than to the maximum  refer slide time  56  20  that is all i was going to discuss in the class today what we discussed today was the deletion procedure and then we also discussed this particular analysis which says that if you were to take a random permutation of n elements and insert them  then the average time or the expected time for insertion is n log n in the worst case there could be a permutation for which the time taken is  we have seen examples of those  if the elements are in increasing order or in decreasing order then we take time the best possible permutations are also going to take at least n log n times or some constant times n log n but the average case is also n log n data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 10 quick sort today we are going to talk about quick sort this is the second sorting algorithm we are discussing in this series of lectures the first one was insertion sort for which we had argued a worst case running time of o  n square   today the quick sort algorithm which we are going to look at is also going to have a worst case running time of o  n square  but we will argue that on an average it takes only about n log n time it is a quick algorithm  in practice it is very fast with very small constants  refer slide time  01  35  another property of this algorithm is that it is in ? place ? sorting algorithm what is an in ? place ? sorting algorithm ? an algorithm is called in ? place ? if you do not require any additional memory to do the sorting we will assume that n numbers are given in an array  may be we need memory for 1 or more variables but we will not need any additional memory to do the sorting that is called the in place sorting and that is typically good thing to have because its space is at a premium  especially when you are trying to sort a large collection of numbers this algorithm falls into a paradigm which is called divide and conquer i am not going to say too much about this because we are going to see a lot of divide and conquer algorithms in this course at a very high level  the idea behind divide and conquer is the following that you are given a certain problem that you want to solve you divide the problem up into 2 or more pieces you solve the problem for those smaller pieces the divide step in the case of quick sort would be partition our array we will take the array which stores the n numbers and partitioned it ; break it up into two parts one is we will call it as the lower part and the other we will call the higher part the property of the lower and the higher part would be that every element in the lower part  every number in the lower part would be less than every number in the higher part how does this help us if we do such a partition ? if i sort the lower part now and i sort the higher part and i put all elements of the lower part first and follow it up with all elements of the higher part then the entire thing is sorted i have sorted the lower part and i have sorted the higher part  every elements here is less than the element in the higher part so the entire thing is sorted that is the combining part and in this case it is trivial because nothing needs to be done but quite often in divide and conquer algorithm you have to do something to do the combine and we will see examples of these later so we will go one step at a time we will first understand how this partition is done  refer slide time  4  10  so we will give an algorithm to do the partitioning which will be a linear time procedure so the partitioning is done around a pivot element i will take one of these elements as a pivot and everything which is smaller than the pivot will be my lower half that is lower part of the array and everything which is larger than the pivot will be the larger part this is the procedure to do the partitioning it takes the parameters  the array a and p  r are the limits of the array the p here refers to this location and r refers to this location and this could be part of a larger array  refer slide time  05  10   this just says that partition the sub array from p to r we will see what it will do at the end of the procedure i am going to take a  r  which would be the element 10 i will put it into x which means x is going to be my pivot element so x would contain 10 what is this doing ? the i is getting the value p-1 so i is assigned to something before p so this location is r and this location is p and i is getting p-1 and j is getting r + 1 and so which means i and j are just before and after that is the start and the end of the sub array that we are interested in and now we are just going to go through this lop the while true which means we just continue going through this loop  till you break out to the loop what is this doing ? this is saying repeat j is j-1 until a  j  is less than or equal to k so we are looking at this index and we are saying keep decrementing it till i reach a location which is less than or equal to 10 what was x ? the pivot 10 so keep decrementing it  so i decrement j till i reach a location which has content less than or equal to 10 so already i reached such a location so i stopped decrementing  refer slide time  08  40  now i go to the next loop where am incrementing i till i reach a locations which is greater than or equal to 10  so already i reached a location which is greater than or equal to 10 what am i going to do ? recall that i want everything in the left part to be less than 10 and everything in the right part to be more than 10 so these are in some sense culprits because this is more than 10 and it is in the left part and this is less than or equal to 10 and it is in the right part so we will like to swap them and that is what we will do here exchange a  i   a  j  means just swap these contents so i swapped these contents so i will denote blue as everything which is in the left part and orange would be everything which is in the right part so everything in the left part would be less than or equal to 10 which was my pivot element and everything in the right part which is the orange part will be greater than or equal to 10 recall  i is here at this point and j is here and once again i am going to keep decrementing j till i find an element which is smaller than 10 so i found one already and i keep incrementing i till i find an element which is larger than 10 so that actually i will find here and once again i will swap these things i swapped them and i continue with j  so j will keep moving till i find something which is smaller than 10 so actually i found immediately one which is smaller than 10 at this location and it will keep moving till i find an element which is larger than 10 so this is not larger so actually i will end up till this location 19 and i will once again swap 8 and 19 i swap 8 and 19 and i get this this is already smaller so this is also marked blue  refer slide time  07  38 08  30   now j would continue decrementing till i find something which is smaller than 10 the j is searching for something which is smaller than 10 so it will come to this position  this is the first element which is smaller than 10  refer slide time  08  45   so it comes here and i will continue incrementing till i find something which is larger than 10 so it comes here and now i and j have crossed each other  which means our job is done so if i is less than j then you do an exchange  if i is more than j which means they crossed each other then you exit which means return the procedure what we are returning ? we are returning the value of j which tells us about the boundary of the two halves so this is my left half that is my left half is from p to j and my right half is from j + 1 to r because am only returning j and not i so j + 1 to r is my right half how much time does this procedure takes ? it is order n is this clear that its taking order n time and no more because  hindi conversation  at every step we are decrementing j how many times can j be decremented ? it is at most 10 times the size of the array and how many times can i be incremented ? at most the size of the array  so this loop is done at most n times  this loop is done utmost n times and every time we increment or decrement we might have to do one exchange in the worst case so this is also never be done more than n times  refer slide time  10  16    refer slide time  12  30  it is a simple way why do we do it in this manner  you could also have done it in a slightly different manner after all we are taking the pivot and saying  compare every element with the pivot and put everything which is smaller in the first few locations and everything which is larger in the next few locations if you try to do it  some other way you will require more memory one way you could do is take one element at a time and put it in some other array and then copy that array back into this place that would be one way of doing it but that will take more memory  so we wanted to do it in in-place as to keep all the elements in this array and not to take up any additional memory space we can do this partitioning in in-place that is no additional memory and in linear time which is the best pursue i am saying let us look at this repeat until loop over all the while loops let me just look at this one statement  the total number of times this is executed not in one iteration of the while loop but all while loops put together how many times is this statement executed ? at most n times because i can decrement it only at most n times that is not possible  because for one particular run of the while loop i might decrement it say for 3 times then for the next one i might decrement it for another 5 times and so on but the sum over all will not be more than n because  student conversation  at most n  that is all i am interested in the total number of times this step is executed and this step is executed and this is executed is order n this is my complete quick sort algorithm  i did my partitioning so i have to do quick sort on lets say this array  array a between limits p and r when i do an initial call for quick sort i will do 1 to length of a  whatever is the length of a so in general this would be the thing  so p to r i need to do it only if p is less than r  if p = r then there is nothing to be done or if p is more than r then again it does not make any sense so if p is less than r then i do something what do i do ? i first find the partition of this part p to r then i invoke the previous procedure a  p  r what does it do ? it rearranges the part of the array between p and r such that everything which is less than the pivot is in the initial part of the sub array and everything which is more than the pivot is in the later part of the sub array  refer slide time  16  23  and what does it return ? it returns the demarcating lines  so the lower half is going from p to q and the larger half is going from q + 1 to r so i need to sort the lower half and the upper half separately so i recursively invoke quick sort on the lower half which is going from p to q and on the larger half which is going from q + 1 to r the while true means just keep doing the while loop forever where does this while loop stop ? it will stop when you return out of this  it ? s like an exit out of this while loop  like a break statement so when this condition is met that i is more than j then you will return j and go out of this entire partition procedure itself so which means that you also go out of the while loop so when you call quick sort recursively  note that i do not have to copy the array a  it is the same array that is used we might have to create more copies of the variables  actually we would only be creating additional copies of these parameters that we are passing but that is the space created on this stack we are ignoring this but we are not taking any additional memory for the elements that we have they are all sitting in a single array what element should be partitioned around ? what should be our pivot element ? did every one understand the quick sort ? you took a pivot element and you partitioned the array around the pivot element and you said let me sort this left half and let me sort this right half and then i am done then how do you solve the left and right half ? repeatedly by the same procedure since we have a notion of a left half and a right half therefore we need to write a quick sort procedure in this manner  because this will specify the limits of the sub array that you are sorting p  r let us try and analyze how much time does quick sort takes ? we have only seen that the partition procedure takes order n times that is linear time but we do not know how much time quick sort takes so the time taken by quick sort will depend upon how the split is happening what do i mean by that now ? i should not say left half but it is left part so how many elements end up in the left part and how many elements end up in the right part ? that is what we should find out and that will determine how much time quick sort is taking let ? s see why  refer slide time  17  00  so if at every point  suppose the following was happening at every point we were actually dividing the array up in to two equal halves which means that i started of with n elements  this here  hindi conversation  somehow or i was lucky or whatever it is  my pivot was such that it was the median lets say which means that half the elements were less and half were more so half the elements ended up in the left half and half elements ended up in the right part then when i did a quick sort on this again i was lucky  again i picked a pivot such that it divided up the thing in to two parts and when i did my quick sort on this again i was lucky it just divided up in to two equal parts and so on suppose i was lucky at every step  then how much time am i taking ? let ? s see how much time did i take to divide this array up into two parts that is n/2 and n/2 ? it is n times  the size of this array we saw the partition procedure took order n time how much time did i take to divide this array of size n/2 into two parts that is n/4 and n/4 ? the n/2 here and n/2 here so that it becomes n then to divide this up into two parts that is n/8 and n/8  i again took n/4 here n/4 here n/4 and n/4 and so that is also n so in each level of this tree that i have drawn am taking order n time to do the partition and how many levels are there in this tree of mine ? it is log n because eventually you will end up with one and there would be log n such levels so the total time taken is order n log n why have i written theta of n and not o of n ? can you also say that the partition will take at least omega n time or at least will take n time ? yes  because when did we say that we would stop ? when our i and j would inter change  so i has to go at least till some part and j has to go  so the total number of times i will increase i or decrease j is at least 10 total number of times i will increase i  i am not saying that number of times i will increase i is at least half  it is not n/2 may be i increased i only n/4 times but then it means i decreased j at least 3n/4 times so the sum is at least 10 i need at least n times which mean i need utmost m times and i need at least n times  so the exact time is really some constant time  theta of n so i can actually say equality  refer slide time  20  31  what happens in general  if you are not lucky ? what is the worst case ? n squared  when we partition  hindi conversation   once side gets one element and the other side gets n-1 elements we could have such a situation  t  1  + t  n-1   again i am writing the recurrence relation time to quick sort n elements equals the time to partition that was the very first step of our quick sort procedure plus the second step of our quick sort procedure was quick sort the left part lets say the left part has one element in it  so t  1  plus the time to quick sort the right part which has lets say n-1 elements  it is t  n-1   so this is our recurrence and let us solve this recurrence in exactly the same manner that we did earlier so i am assuming t  1  as zero so this is just t  n-1  + theta of n if you have one element there is nothing to be done  it is sorted so this is just t  n-1  plus theta of n what is t  n-1  ? it is t  n-2  plus theta of  n-1   so t  n-2  plus theta of n  n-1  and t  n-2  is t  n-3  plus theta of  n-2  and so on so it has essentially become theta of k where k going from one through n what all i am saying is  this is then equal to t  n-2  plus theta of  n-1  plus theta of n  which is t  n-3  plus theta of  n-2  plus this term which is equal to t  n-4  plus theta of  n-3  plus this entire thing and so on  refer slide time  23  54   so this is what you get which is basically theta of n squared it is n squared  k going from one through n  sum of k is just n squared that is why you get theta of n squared if this theta is bothering you  just replace it by c  some constant times n so this would be the worst case so the best case is when you do a half split and the worst case is when you know it is a skewed split so this is what the worst case look like pictorially  n divided into 1 and n-1  n-1 divided into 1 and n-2  n-2 divided into 1 and n-3 and so on and what will be the height of this tree now ? it is n in each step you are taking time n and again you are taking time n  n-1  n-2 and so on all the way down to 1 so that makes it n squared  refer slide time  23  46  when does the worst case appear ? suppose we were doing a following scheme  we were saying let me take the last element as the pivot always that is what we did to begin with  let me take the last element as the pivot so if my input is sorted already lets say in increasing order then i took the last element as the pivot how many elements will be in my lower part ? the n-1 elements in my lower part and only one element in my upper part because there is no element larger than the last element and then once again to sort the lower part i took the last element as the pivot so once again it will get divided in this manner  refer slide time  24  16  so the worst case would happen when the input is already sorted in ascending order or in descending order even in descending order you will take n squared time because when it is in descending order you took the last element as the pivot  it is the smallest element  hindi conversation  there will be one element  right half will have all the n-1 elements in it and you keep doing this and this is what will happen similar kind of a thing happened in insertion sort in insertion sort we said the worst case would happen when it is in descending order because if you recall in insertion sort we were taking an element and figuring out the best place to put that element and we would go from the end to find the best place so if it is sorted in decreasing order then the best place is always the front of the array so you will have to go all the way to the front of the array at every step it is again 1 + 2 + 3 + 4 and so on all the way up to n so you will get again the same n squared  refer slide time  26  35  but in insertion sort if the array was sorted in increasing order then how much time do you take ? then it is the best case because you do not have to move back anymore every element is in the right place  so it just takes constant amount of time that is the comparison with insertion sort but here both  whether it ? s sorted increasing or sorted decreasing you might end up with something like n squared time so worst case seems to occur more often let us continue with this analysis we saw  hindi conversation  if the split was half and half at every step  then we are lucky and we get n log n time suppose it was not half and half but it was one tenth  nine tenth that is 10 percent of the elements end up on one side and 90 % of the elements change out suppose this was happening at every stage you will not call this lucky because it ? s not half and half but it ? s still good which we will argue now at the first stage this is what happens  n/10 elements on one side and 9n/10 elements on the other side how much time did i take to do this partition ? n time  then this n/10 got divided into one tenth on one side and nine tenth on the other side one tenth means n/100 on one side and nine tenth of this is 9n/100 on the other side and this  9/10  n also gets divided into 9n/10 on one side and nine tenths of this guy which is 81/100n on this side how much time did it take to partition this into this and this  refer slide time  27  45  n/10 number of elements and so for this the total time is still n  refer slide time  29  56  so similarly the total time for every level will continue to be n but now how many levels do i have ? let ? s figure out that let ? s just look at the largest number we have  as we go down one level at a time we want all the numbers go down to one  so the largest number is the one which we have to say it goes down to a one so at this route we have n  the largest number at this step will be 9n/10 because the other number is smaller what will be the largest number at this step ? it will be in the nine tenths of this guy which will be the largest one  so that will be 81/100n the largest at the next step would be the nine tenths of this guy  hindi conversation  that will be the largest guy at this step which will be this and so on so the largest number at every level is decreasing by a factor of 9/10 how many times can i decrease before it gets down to one ? at most log of n to the base 10/9 because it is decrementing by a factor of 9  10 ? s at every step when it was decrementing by half at every step  we were saying log n base two so if we just work out the math it will be log n to the base 10/9 which is order log n it is just some constant  it is different constant times log n so once again the height is order log n  so the total time taken is order n log n because at each level we are taking a total time of n and number of levels is log n but even better  this is we are only providing an upper bound even if this split was in this strange manner one tenth and nine tenth or any constant fractions  there is nothing sacrosanct about one tenth and nine tenth i could have said 36/37  even that is ok  it is not a problem even then we will be able to argue log n there is nothing spectacular or special about 1/10 the important thing is we are saying a constant fraction of numbers go on one side we can not afford to say only one number go on one side that becomes bad for this when only one number go on one side or only two numbers go on one side then we will end up taking n squared time but if we say a constant fraction one tenth or one hundredth or one thousandth or one millionth the height would still be log n we will do a formal analysis starting from the next slide  but just to give you a little more motivation on this suppose we alternate the lucky and unlucky cases  even then you can prove a log n depth so what was our unlucky case ? 1 and n-1  then what was the lucky case ? n-1 divided into two  n-1/2 and n-1/2 how many operations did i take here to split n and how many operations did i take here to split n-1 ? so in total i took 2n-1 operation here and after 2n-1 operations or comparisons i managed to split it into n-1/2 and n-1/2 and 1 with 2n-1  refer slide time  32  51  so now i can again bring the same tree i will get a recurrence like this i can think of it as this with theta n or in particular 2n comparisons i managed to split it into n-1/2 on one side and lets say n-1/2 + 1 on the other side actually i managed a three way split because the 1 is coming here so once again we will have a depth of only log n and i took 2n in each step  so its 2n times log n we will not worry too much about this lets try and do this formally so it seems that for many scenarios we will get a log n we want to argue that this really is the case ?  refer slide time  35  14  so what is the best thing to do ? we said we will be lucky when we always partition half and half the best thing to do would be to find a median element pick the median element as the pivot and that will break up my array into two equal parts and that would be great how do i find a median element ? sort the numbers and then find the median element that would be one strategy except that sorting is what we are trying to do in that first place so finding median element is not straight forward  you will see a procedure for doing it in your next algorithms course  student conversation  not clear-some what close to the median by dividing the array into some odd number of small array then sorting these  as in like write it into small arrays of size five and sort them and then take the median of these now i repeat this till i get one number  that it is close to the median and we will take log n steps  you can actually compute a median element in linear time but it is fairly an involved procedure which you will learn later for now what you will do is  since you want to find the median element and you can not find the median element so you will just pick a random element and declare that what we are going to do is we are just going to pick a random element as our pivot we said we do not want to pick a specific element as the pivot why ? because if i always want to pick the last element as the pivot then if my sequence is in decreasing order or increasing order then i will struck with an n square running time so i will just pick a random element as the pivot so this is what we call a randomized algorithm what is a randomized algorithm ? an algorithm which is basically making some kind of random choices and we will analyze what this algorithm does we will analyze the running time of this algorithm so this is what a randomized quick sort is we will assume all elements are distinct we partition around a random element a pivot is a random element and we just pick any element at random with the same probability so what kind of splits we can get ? we can get all kinds of different splits  if i have n elements i can get a split of 1n n-1 ; i can get a split of 2n n-2 and so on what will be the probability of these splits ? they all will be equal they will all be with probability one over n did you understand why they would all be equal ? because it is a random element  each element can be picked with equal probability so if i pick the f five n elements and i pick the tenth smallest element then i will get a 9 versus n-10 split or a 10 versus n-10 split but what is the probability of picking the tenth smallest element ? it is 1/n  because i could have picked any element so i do not know what i am picking the tenth smallest element is as likely as the 11th smallest element which is as likely as the 12th smallest element the probability of each one of them is the same we will see more examples of randomization in this course and it is a useful tool for designing algorithms  refer slide time  36  44  so this is what our randomized quick sort is going to look like so we are only going to modify the partitioned procedure and call it randomized partition instead once again we are trying to partition the array a between p and r  the sub array between locations p and r what is random p  r ? random p  r generates a random number between p and r lets say that number is i  between p and r means including p and r lets say that number is i and we are just going to exchange i and the last element why am i doing this ? because this partition procedure  if you recall was taking the last element as the pivot now i want to put my pivot at the last location  so i just exchange the pivot element with the last location and then i call my partition procedure  the same partition procedure as before so this becomes my randomized partition procedure and what does randomized quick sort do now ? instead of calling partition it calls randomized partition  the rest is the same did you understand what it is ? since our choice of pivot is crucial and we do not know really how to choose the pivot we just pick a random element as the pivot no  it would not be a random choice so what is the difference between random choices here ? so he has a very good question  he says if i partition it around the last element  why is that not a random choice ? that is not a random choice because if i give you a specific input which is lets say increasing order then on that input you are going to take n square time if you partition around the last element now in randomized quick sort we are not partitioning around the last element we are picking a random element to partition when i pick a random element to partition then given the same sorted sequence as input  you are not going to take n squared time in fact how much time are you going to take ? we do not know how much time we are going to take that is the interesting thing why we do not know how much time we are going to take ? we do not know what the pivots are going to be  they are randomly selected  refer slide time  41  00  so it might happen that today you run the algorithm and it take some time and tomorrow you run the same algorithm and it takes a different time because it depends upon what random numbers are selected and those random numbers selected decide the pivot and the pivot as you see is crucial in deciding how much time we are taking because if that pivot was a nice one which was splitting the things evenly and if it is going to take less time and if the pivots were turning out to be bad ones fairly skewed  then i am going to take more time so we are going to see all of that so now if you do not know how much time the algorithm is going to take and it is going to take some time today and some time tomorrow  then what do we analyze ? what is that we can say ? the average time or expected  which is also called the expected time what is the average we are doing over ? so are we averaging over all possible inputs ? sequence of random numbers is generated in some sense so the way to think of it is  fix an input you are not going to change the input ; we will run the algorithm today and tomorrow and day after and so on till the end of this course and then you are going to compute the time and take the average and that will be the expected time for sorting that specific input sequence  refer slide time  41  35  let t  n  denote the expected number of comparisons required by quick sort t  n  is a function of n  the number of comparisons required to sort n numbers will depend upon how many numbers you have depend upon it let us recall what quick sort does quick sort first partitions  if it has to partition n numbers no matter what the pivot is it is always going to require the same number of comparisons it is always going to require no more than n-1 comparisons you can think of the partition process as every number is compared against the pivot and then all those that are less than the pivot are put on one side and all those that are more than pivot are put on the other side so we always require n-1 comparisons every number has to be compared against the pivot otherwise we will not be able to decide whether it goes on the left side or on the right side so this is the part of the partition depending upon what the pivot was  if the pivot was the ith smallest element then on one side how many elements am i going to get ? let ? s say i-1 on one side and n-i on the other side and the ith element lets say i leave it at the right place i have to quick sort those i-1 elements  i have to quick sort those n-i elements how much expected time am i taking to quick sort those i-1 elements ? t  i-1  is the expected time i take to quick sort these and this is the expected time i take to quick sort the n-i elements  refer slide time  42  53  so i will take this much amount of time in all but what is i here ? the i was the fact that the pivot was the ith smallest element that happens with the probability of one over n so i am going to take this much time with the probability of one over n i am going to take time t  7-1  + t  n-7  + n-1 with the probability of one over n i am going to take time t  13-1  + t  n-13  + n-1 again with the probability of one over n and so on so the expected time taken is basically this sum  refer slide time  43  45  this quantity summed over all choices of  so i have replaced i by the j here so this i is the same as this j here and each one of them is being picked with the probability of one over n this is how you compute expectation expectations  so for instance just to give you an examples those who are forgetting your expectations  i roll a dice what is the expected value i see ? how does one compute this ? each of the outcomes is equally likely  each occurs with the probability of one over six i see one over one with the probability of one over six  two with the probability of one over six  three with the probability of one over six and all of that so the expectation is one over six times one plus one over six times two plus one over six times three and so on whatever value we get that is the expected value you would see what should i repeat ?  refer slide time  48  12  throw a dice so what are the possible values we get ? it is 1  2  3  4  5  and 6 it is an unloaded dice  so each appears with the same probability what is the expected value ? what is the random variable ? random variable is the number that comes  so the random variable is the number on the dice this random variable lets call it x  this random variables takes six different values each value takes the probability of one over six probability x = i = 1/6  i between 1 and 6 what is the expectation ? think of the expectation as just the following you keep throwing this dice and keep recording the outcome keep doing this forever and then just take the average suppose you threw this dice one billion times how many times are you going to see a one ? one billion by six times this is what the probability means  the probability that it is 1/6 if you do the experiment sufficiently many times then this fraction of the times you are going to see this particular outcome  hindi conversation  times your outcome was one if i am looking at the sum of the outcomes this will be one sum how many times do you see a two ? how many times do you see a three and so on ? so let me just complete this which is exactly the same as saying one by six into one  this quantity here what is this quantity ?  refer slide time  47  32  this is just the probability of the event that x i equals one so this is 1/6 or i could even have written it as probability  the random variable takes the value one times this one which is the value of the random variable plus the probability 10 power 9/6 is the probability that it takes the random variable the 10 power 9/6 by 10 power 9 is just the probability that it takes the value two so probability x = 2 into 2 and so on and probability x = 6 into 6 so that is what expectation is one way of thinking of expectation is  if a certain random variable is taking a set of discrete values then you just compute the value of the probability with which it takes the value  times the value summed over all the possible choices is the expectation of the random variable so let ? s revert to our slides this is going to be taking this value with the probability of one over n and so we have done just the probability times the value summed over all the possible choices which is j varying from one through n and again as j varies from one through n  this quantity varies from t  0  to t  n-1  and this quantity also varies from t  n-1  to t  0  which means every term t  0  through t  n-1  appears twice so i can write this part of the sum as this and this n-1  we are summing it n times and then dividing it by n and so it ? s just plus n-1 separately and this is a recurrence which we saw in the last class it was the recurrence for the expected number of comparisons required to insert a randomly chosen permutation of n elements in a binary search tree  refer slide time  49  45  and what did we prove in the last class  we solved this recurrence and we showed the solution is n log n hence the expected number of comparisons required by randomized quick sort is n log n  the same recurrence we solved it before and we are just using that fact this is the analysis which we did and this is the expected number of comparisons required by quick sort so let ? s quickly summarize the time taken by quick sort worst case time we said was n squared  the best case time was n log n we did not prove it formally ? why it should be n log n and why it can not be less  but intuitively you can understand that the best thing happens when the two are roughly equal and then we argued that it will take n log n and the expected is once again n log n and this behavior is similar to what we also in the last class  refer slide time  50  41  when i am trying to insert n elements into a binary search tree  what is the worst case time ? it is n squared  it happens when my sequence is sorted what is the best case time ? it is n log n again and if the first element i was inserting was roughly the median and the second element i was inserting was n/4 and so on and the expected time was n log n the crucial difference between what we are doing today and what we did in the last class this is something that i have already said but let ? s just recap what we have done today is that the running time of quick sort depends upon the numbers that are getting generated if the same random numbers were generated then the running time would be the same for a given input  refer slide time  51  19  so the same thing i said  i fix an input the running time could be some value today  it could be some value tomorrow because the random numbers generated could be different what we have done is we have taken expectations over these different random numbers that have been generated  by saying that today we will compute what the value is  tomorrow we will compute what the value is so on and take the average we are doing this for one fixed input and we said if i fix an input and i compute this value it turns out to be n log n that is what we did and no way we used the fact that  what the input was really come to think of it  no matter what the input is  your expected time is turning out to be n log n so some how this is actually what some of the slides were also saying before when we said we would take a specific element as the pivot lets say the last element as the pivot we saw that the running time would depend upon what input was given to us if the input was sorted we would take n squared time  but if the input was such that the last element was the median element then once again we would get this half and half split and so on so if i had taken a specific element as the pivot always then my running time would depend upon what the input sequence was or what the input order was but i got around that somehow i said let me randomly pick my pivot element and now what has happened ? the running time does not really depend upon my input is  it depends upon what the random number choice is  which in expectation will give me a running time of only n log n  student conversation  so how does that make things if better we do not make any fix element ? ? ? ?  the algorithm time is independent upon the input how does  no so what we are trying to say here is that when we say it is independent upon the input  we are saying that no matter what input the adversary gives us you are trying to may be beat my algorithm  refer slide time  56  27  you want my algorithm to take as much time as possible so the point here is that you can not come up with any such sequence no matter what sequence you come up  what sequence of numbers you come up  my algorithm will take a time which in expectation is n log n  which quit often will turn out to be n log n  student conversation  i want to work somewhere so there nobody is going to ? we have to make an algorithm particular kind of input may be if you look at this quantity that you want to make it independent of the input  then this kind we are making a random for that kind of input  if we knew what kinds of inputs we were getting then perhaps it makes sense to design the algorithm for those kinds of inputs but this is not what we are doing here because we are not designing the algorithm for a specific input sequence or specific kinds of inputs we are saying we want to be able to consider all possible inputs and in doing that we want an algorithm which really does not depend upon what the input is  its behavior is independent of that what did we do in the last class for binary search tree ? and i want to make this difference very clear for the binary search tree we were doing an average over what ? we said take a particular input sequence and it is going to take a specific amount of time  whether you run it today or you run it tomorrow its going to take the same amount of time that was not a randomized algorithm it was a very specific algorithm were no random choices being made if you take the same amount of time no matter when you run it  but if i take a different input sequence it would take a different amount of time and if i take a third input sequence it would take a third different amount of time and so on  refer slide time  57  08  and there what we were doing was  lets take the average over all input sequences that is over all possible n factorial different permutations we took the average over all of them and then we got n log n did you understand the difference ? the recurrence is the same but there is a vast difference between these two things that we have done one was what you call an average case analysis ; we looked at all possible inputs that can be there of numbers one through n  there are n factorial different permutations so there are n factorial different inputs possible  we looked at all of them ; we computed the time taken by the algorithm for each one of those inputs and took the average today on the other hand ours was a randomized algorithm  our algorithm was taking different times depending upon what the random numbers were and today we were taking the average over the random numbers that were getting generated and not over the inputs  the input was fixed with that i am going to end today ? s lecture we saw quick sort and we did the expected time analysis for randomized quick sort data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 11 avl trees in this class we are going to talk about avl trees in the last class we have seen binary search tree data structure one problem with the binary search tree if you recall is that the operations of insertion  deletion and search take time proportional to the height of the tree height of the tree can be very bad we saw an example were the height of the tree could be as bad as order n or n-1 we want to some how create a tree which does not have too bad a height that is what we are going to do today we are going to look at this data structure called avl trees what is an avl tree ? avl trees are also called height balanced trees ignore the white spots that are showed on the slide below and they should not have shown here  refer slide time  01  58  this is the binary search tree and inside the nodes are the keys everything which is less than the root is to the left of the root and everything which is more than the root is to the right of it the thing that is written next to each node is the height of a node what we will call the height of a node ? we have not defined this term yet we will just say the height of a node is the height of the sub tree rooted at that node for instance if i look at this node  78   all the things which is below it is the sub tree rooted at this node what is the sub tree rooted at a node ? it is just the set of descendents i am looking at the tree which is on the right and in previous classes we have defined the height of such a tree as 2 and not 3 because we had said that 78 is at level zero and 50 is at level 1 and 48 is at level 2 and so we called the height of the tree as 2 we will just modify  we will say that if it is the singleton node just one node then it is of height one instead of height zero as we have been calling it so level numbers are beginning with 1 this sub tree 50 has height 2 and this sub tree 78 has height 3 and this entire tree has height 4 we are going to call this as height of the tree for the purpose of the avl tree with every node i have put down the height of that node what is the height of the node ? it is just the height of the sub tree rooted at that node all the leaves will have height 1  the parents of the leaves will have height 2 and so on such a tree is called avl tree if it is height balanced what is height balanced ? if i look at any node and its children then the difference in their height is at most one there might be no difference in their heights  as in the case with the 50th node its 2 children have the same height the node 78 has the difference  the left sub tree has more height than the right sub tree the left sub tree has height 2 and the right sub tree has height 1 the node 44 also has a difference of one the right sub tree has height 3 and the left sub tree has height 2 but the difference is no more than a one this is the avl tree this is what our definition of an avl tree would be it is true for every node of the tree the binary search tree has 2 properties it has to be a binary search tree and for every internal node of the tree  the heights of the children differ by at most one why have i said internal ? for a leaf node it has no children it does not make any difference to talk about the height of the tree so for this node 17 the right sub tree has height one the left sub tree is missing so we call it height zero now you understand why i had made this change if the tree is absent then i will denote the height as zero and the single node will become height one that is why i have to shift the definition a little bit  refer slide time  6  04  let us see what is not an avl tree ? so recall that one of our binary tree which was very bad  which had a huge height was a tree like this this is a binary search tree and i put some keys so that it looks like a binary search tree this has height equal to n-1  if there were n nodes is this an avl tree ? no is the last node height balanced ? yes  since it is a leaf node it is height balanced is the next node height balanced ? yes  it is also height balanced is the node following the 2nd node height balanced ? no because the right sub tree has height 2 and the left sub tree has height zero thus the height balanced property is violated here it is also violated in the following nodes thus we will never have such kind of trees as avl trees  refer slide time  07  22  since we said that we are not going to have such a kind of trees as avl trees  let us try and figure out how bad the height of an avl trees can be let say i have an avl tree of n nodes  if its height can still be as bad as n-1 i have not gained anything i would like to say that its height is no more than log n or something we will figure that out and that is what we are going to prove in the next few minutes the height of an avl tree t which has n nodes in it is only order log n let see why this is true i am not going to prove this claim directly  i am going to make a slightly different argument let us take an avl tree of height h amongst all possible avl trees of height h  let me see the one which has the smallest number of nodes i defined this quantity n  h  as the minimum number of nodes in an avl tree of height h let us figure out the quantity and then we will see how this implies the proposition given an avl tree of height h  we want to find out what is the smallest number of nodes it has can it have only h nodes ? then we will be in trouble we want to say it has many nodes  if you recall a binary search tree of height h can have only h + 1 nodes like the example that i showed you but a good tree which is like a complete binary tree of height h will have nodes what we would really like is that our avl tree which was of height h has large number of nodes  not just h but more like or something like that that is what we are going to prove  refer slide time  11  31  let us understand the quantity it is the minimum number of nodes in an avl tree of height h what is an avl tree of height 1 ? it is just a singleton node and nothing else it has only 1 node in it if i have an avl tree of height 2 then it has root and 1 node but it can also be root and 2 children why have i written n  2  = 2 and not 3 because i am counting the minimum that is why n  2  = 2  the minimum number of nodes will be just 2 in an avl tree of height 2 suppose if i have an avl tree of height 3 or more  it will contain 1 root node suppose if i have an avl tree of height h  it will contain 1 root node and an avl tree of height h-1 on one side and an avl tree of height h-2 on the other side why h-1 and h-2 ? it has height h so its children can have height only h-1 and not more than h-1 they can have a difference of at most one if one of them is h-1 the other one can only be h-2 or h-1 one of the sub tree has height h-1 and the other sub tree has height h-1 or h-2 but what will we pick ? we would like that the other sub tree should have height h-2 why ? because of minimum number of nodes a tree which has smaller height will also have smaller number of nodes  so we would like that the height of the other sub tree to be h-2 if n  h  was the number of nodes in the tree of height h  then what is the number of nodes n  h  equal to ? it is the number of nodes in a tree of height h-1 the smallest possible  because the left sub tree which is of height h-1 can have as small as little number of nodes as possible and in the right sub tree which is of height h-2 also has little number of nodes as possible the number of nodes in the left sub tree is n  h-1   the number of nodes in the right sub tree is n  h-2   there is one root node and the recurrence relationship would look like this  n  h  = 1 + n  h-1  + n  h-2    once again we are seeing the recurrence relation this is what we have to solve today what are the base conditions ? we know n  1  is 1 and n  2  is 2 with that you can figure out what n  3  would be ? n  3  would be 1 + 1 + 2 which is 4 and so on but we would like a close form expression to do this so we will solve this recurrence we are not going to be solving this recurrence exactly we are going to do it approximately first we use the fact that n  h-1  is only going to be larger than n  h-2   because as the height of the tree grows the number of nodes can not reduce  it will only be more so n  h-1  is at least as large as n  h-2   then this implies what we had written earlier that is n  h  = n  h-1  + n  h-2  + 1 this quantity is at least as large as 2n  h-2   strictly larger because i also dropped the one i have replaced this n  h-1  by n  h-2  and this  2n  h-2   is what i get n  h  = n  h-1  + n  h-2  + 1 > 2n  h-2  this becomes the simple thing to solve  n  h  is more than 2n  h-2   this is what i will solve so n  h  is more than 2n  h-2  and now n  h-2  is more than two times 2n  h-4   this implies the entire thing n  h  is more than 4n  h-4   which implies that the entire thing is more than 8n  h-6   you understand how this comes n  h-4  is more than 2n  h-6  and so on  which will eventually take us to something like after i steps n  h-2i   suppose i pick  i am going to assume that this quantity is an integer let us assume that h was even to begin with  so this is an integer and for this value i will get n  h  > in which i replaced  recall n  2  was 2  so it becomes  what does this say ? we just argued that if your avl tree has height h then it has at least nodes that is at least so many nodes what is the maximum number of nodes it can have ? something like  one of those because it can be a complete binary tree  refer slide time  16  34  suppose i were to take logarithms  what would i get ? i would get h < 2log n so n  h  is actually less than n because i have an avl tree whose height is h and it has n nodes suppose i had an avl tree of height h and n nodes then it will also satisfy this relation  h < 2log n  h    it will satisfy the relation because n is only going to be larger than n  h   what was n  h  ? n  h  was the minimum possible number of nodes any avl tree on n nodes has height at most 2log n from this argument the h < 2log n  h  is what we argued after taking algorithms let me take a tree of height h and n nodes so n is going to be larger than n  h  because n  h  is the minimum number of nodes that are possible in a tree of height h  n  h  is that quantity this n is just a function  do not confuse this n with the number of nodes you can replace this n with something else n  h  is the minimum number of nodes in a tree of height h what we argued was that h < 2log n  h   take an avl tree of height h and m nodes its height is h and it has m nodes in it what does this implies ? the m > n  h   this follows from our definition of n  h   we know that h < 2log n  h  which is then < 2log m this implies h = o  log m    refer slide time  18  47  the h is the height and m is the number of number of nodes the height of an avl tree on m nodes is less than two times log of the number of nodes that is what being said here we have shown that such a tree will have height no more than 2log n the best possible tree could have height only log n if it were like a complete binary tree  very dense and every thing but this has more height but not too much  just a factor of two more much better than having a height of an n let us try and solve this recurrence slightly better this is more of an exercise also to show you how recurrences are solved we did fairly crude analysis  we replaced n  h-1  with n  h-2  and then we did the steps and got the result let us try and get something better it is just an exercise  refer slide time  21  19  we will show how to get a sharper bound on the height of an avl tree the bound we obtained is 2log n let see if we can get something better than that we are going to use induction and we are going to do a tighter analysis of the same thing we are going to show that the minimum number of nodes in an avl tree of height h which was n  h  is at least c times h that is where c will be some constant more than one what did we show in the previous slide ? the n  h  was at least  what was the c ? it was  there we showed a c of  let see if i can get a higher c that is a larger c more than  what would be the way of doing such a thing ? we will assume that n  h  is at least as large as  we are going to prove this by induction we will figure out what c is later we are proving a certain statement without actually knowing exactly what the statement is because i am not telling what c is but you will see what the c has to be for the statement to be true what is the base case ? h = 1  say n  h  is 1 this statement n  h  > = is true at h = 1 we have said the number of nodes is going to be at least as large as i assume that i made a mistake  let us come back this base case again we will have to perhaps redefine the height of a tree i think we should have or some thing suppose the claim is true for all h < k and lets try and prove it for h = k we have to prove that n  k  > =  we will come back to this base case in a minute so recall this n  k  = n  k-1  + n  k-2  + 1 was our recurrence relation our induction hypothesis says that n  k-1  is at least  n  k-2  is at least and i have ignored this plus one actually i can say that this is strictly larger  refer slide time  25  16  i can show that n  k  is larger than if i can show this quantity   is larger than  this is what i have to show is lager than  what should be the value of c so that this  > =  is true i just cancel out the terms appropriately and i get  if c satisfy this   then this  > =  will also be true why because i just multiply both the side by and i would get exactly that if this  > =  is true then n  k  which is larger than this   would also be larger than  i just have to pick c which will satisfy this    you all know how to figure out c which will satisfy this we will just solve this quadratic equation and this has roots  this is negative  so anything in between would keep this less than zero but i want as large as c as possible  so i will take which is roughly 1.63 this quantity is also known as the golden ratio perhaps we will see this more often this n  k  = n  k-1  + n  k-2  + 1 is not a fibonacci relation if you add one to both sides  so n  k  would be with the fibonacci number minus one you can also do that we get a bound of roughly 1.63 that is c as 1.63 what is the mistake we have made ? one thing is base case have not worked out i guess this was the wrong thing to pick  refer slide time  26  28  it should not be but may be  so induction hypothesis should be  let us take  it will not make a difference we take the so precisely i am dividing out by c then the base would have also be satisfied if h = 1  you would have more than one which is the case and sorry about the base case  for the other two also it will be okay because for h = 2  n  2  is 2 and this would become which is c the c is less than 2 because we just argued it is 1.63 so please make that correction  we really require that the induction hypothesis is h-1 it will not make any difference on this  n  k  > =  how ever if this  n  h  > =  become h-1 then this  n  k  > =  will become k-1  refer slide time  27  05   refer slide time  28  05  this   would continue as it is this will become  we have to prove this   is greater than or equal to  every where there will be a minus one so that you will still get the same   quadratic in equality the value of the c would still turn out to be the same that is for n  h  please make that small correction thus the avl tree on n nodes has height atmost  we just do the same argument as before i take a tree of height h and n nodes we have just seen that  this is the tree with smallest possible number of nodes so n is going to be only larger than this that is   refer slide time  29  44  let us take log on both sides  we get = h-1 i am just using the definition of log i am taking  so i will get h-1 this implies h = + 1 we are able to prove this kind of a sharper bound this equation also works for n = 2  so that was our base case let us continue i have shown you the 2 ways of solving this same recurrence one was the much simpler way  actually both are very simple the 2nd technique is also used quite often you make a guess on what you think the right value should be then essentially you verify that we said that suppose the right value is some and then you figure out what your c should be you can get something better  earlier we had that is 1.414 and we could update to 1.63 by using this kind of a technique  refer slide time  31  20  let us look at the structure of an avl tree in detail once again i have an avl tree on n nodes let me take the leaf of this tree which is closest to the root  which means whose level number is the smallest among all the leaves suppose this leaf is at level k we can show that the height of the tree is at most 2k-1 this requires the proof and let us do that i have an avl tree which has n nodes in it  although the number of nodes in the tree is not going to be particularly important this is some tree  i took that leaf of the tree which is closest to the root suppose the red dot is the leaf which is closest to the root we said that it is at level k so the other leaves could be at this level or could be below in this class for avl tree we work with level starting with one it does not make a big difference  let us say we start with level one we are going to prove that the height of this tree is at most 2k-1 so the height of this tree is that is what we will prove let see why i will draw this picture again this is the leaf which i have colored red is at level k and it is the one which is the closest to the root from the node which is next to k  there will be some sub tree hanging out from the next node also there will be some sub tree hanging out and so on the first node is my root at level 1 let us look at this node which is at level k-1 what is the height of this node at level k-1 ? it has one child and this child has height one the heights are in blue this means this sub tree at level k-1 can have height at most 2 we want to get as larger height as possible for this tree whenever we say at most 2 will just take the largest value this can have height 2  if this has height 2 then what is the height of this node ? this sub tree will have height 3 if this sub tree has height 3  what is the largest height that the next sub tree can have ? it can have 4 what is the height of this node ? it is 5  refer slide time  35  45  what is the maximum height this sub tree can have ? it is 6 and this node would be 7  9 and so on what will be the height of the root ? in general given that this was k  just figure it out  it should be 2k-1 if it was just till the node 3 then it is basically k = 2 height = 3 if k = 2 then the height = 3  if k = 3 then the height was 5 if k was 4 then height was 7 and so on for arbitrary k this is 2k-1 it is a very simple argument which means that this entire tree can be no taller than 2k-1  if the closest leaf was at level k this is the property of avl tree and not a property of any arbitrary binary tree  refer slide time  37  03  in an arbitrary binary tree you might have leaves at any level but the height of the tree could be as bad as you wanted here is a leaf at level 1   hindi    refer slide time  36  30  but for an avl tree if there is a leaf at level k then the height of the tree can not be more than 2k so in any avl tree basically all our leaves will be in the shaded part of the above slide this band whose width is as large as this roughly and both of them was k so i am ignoring that i will just come back to this in a minute we just argued that if the closest leaf is at the level k then the height of the tree is no more than 2k-1  refer slide time  37  35  that is the largest possible height the tree can have let us make another claim if the closest leaf is at level k then all nodes at level 1 through k-2 have 2 children every node on these 1st k-2 levels should have 2 children why have i said k-2 and not k-1 ? let us prove this by contradiction what do we want to do contradict ? let us take some node at level k-2 which has only 1 child the picture is given in the below slide i have a node u at level k-2  it has only 1 child which is at level k-1 i have shown a node at level k-2 but the same argument would apply to any node at 1 through k-2 so v is at level k-1  it can not be a leaf because our closest leaf was at level k  refer slide time  39  13  so it has to have another child i have shown only 1 but it can also have 2 children but this u has only 1 child so sub tree rooted at v has height at least 2 because this should have 1 child  it can not be a leaf it has height at least 2 while the right sub tree here has height zero because there is nothing there so we have a height imbalance at this node u the height balance property is violated at u every node on these levels 1 through k-2 should have 2 children at level k-1 how ever there can be nodes with only 1 child this is level k  of course the tree extends the dot on the left side is the level at which the closest leaf is situated at level k-1  i can have a node with only 1 child and that child is the one which is in the middle and provided it would not have any more descendants it need not have descendants because it can be a leaf this is completely okay but if it had more descendants then we would again have a problem in height balance property this is okay which means that the node in the level in k-1 can have only 1 child but everything which is in the 1st place should have at least 2 children we said every node at level k-2 should have 2 children which means levels 1 through k-1 are full it means they have as many nodes as possible on that level in a binary tree this is after all a binary tree so they are full  refer slide time  40  58   refer slide time  42  24  what does that mean ? that means the tree has at least nodes we also argued recall that the height of the tree is at most 2k-1 if the height of the tree is 2k-1 then it has at most nodes this implies the number of nodes in the tree which was n is between and  since we have been using h for the height  let us substitute h for 2k-1 let us see how this equation would look like this   becomes and this   becomes  this is the same thing i am showing you again what is this saying ? if you have an avl tree of height h then it has at least which we had shown earlier now we are showing just roughly the same thing nodes  all though we have proved the sharper bound i am coming back to the older bound the point is it has an exponential number of nodes  it has number of nodes which is some constant an exponential because that gives the logarithmic height property this is actually a third way of proving that the height of the tree is only log n you can also use this as a proof this did not require solving a recurrence relation the other 2 methods we saw while solving the recurrence relation but the sharpest bound we have seen so far is that is   refer slide time  45  31  let us summarize what we have seen as the structure of an avl tree is concerned if the height of an avl tree is h then the closest leaf can be at level  i have just changed things around  when i said when the closest was at k then the height was 2k-1 if the height is h  suppose i give you an avl tree on n nodes of height h then the leaf which is closest to the root is actually pretty far from the root it is atleast half the height away  it is at least away it does not require a proof  i am just rewording what i have said earlier we also saw that on the first levels the avl tree is a complete binary tree this is what an avl tree looks like essentially for the first half levels it is complete  very dense and then it starts thinning out so it turn the tree around with the root at the bottom so initially it is dense and then it thins to the full height but the fact that it is very dense for the first edge by 2 levels means it has a lot of nodes it is a complete binary tree so it has nodes straight away that means that the height can not be too large  if i had n nodes the height can not be more than 2log n once again i have said that if number of nodes in the avl tree is at least just this fact  since it is a complete binary tree on levels it has at least and at most nodes because that is the height of the tree this is the useful structural fact to keep in mind about avl trees although we will not use it for any of our algorithms but it just gives you some intuition of what the tree is and why is that this tree has only a logarithmic depth we have looked at this height balance property  we said if this height balance property is there then it is nice the height of the tree is only algorithmic we want to say that all our operations are only logarithmic because we still want to say that you can do a search  insert and delete in log n times search is easy there is no problem with search because after all it is a binary search tree forget the height balance property  it is just a binary search tree so you just do search as you do in a binary search tree how much time will you take ? proportional to the height  order h height is log n so you will take only log n time that is the best you can do in some sense  refer slide time  49  16  suppose you were to try an insert when you are going to do an insert what can go wrong recall for the tree to be height balanced  if the difference in the heights of its children is at most a one when i insert a node it can change the height of some nodes and as a consequence the height balanced property might get violated the first step of insertion would be the same as we did in the case of a binary search tree how did we insert in a binary search tree ? first you find the position how do you find the position ? you will just search for that element that you are trying to insert  that will tell you where the position is and just put the node there and then you start marching up back to the route by following the parent pointers as you march up you keep updating the heights of the various nodes you encountered because these are the only nodes whose heights could have changed and no one else we will look at this again in more detail perhaps in the next class i am just giving you the flavor of what needs to be done when we are doing an insertion these are the nodes whose heights are going to change so we are going to the first place where the height change appears  where the height imbalance happens we are going to only start from the node where we inserted and move up the tree towards the root basically we keep going parent  parent till we hit the root on this path that we follow  we find the first node which has the height imbalance property suppose that node is called z and its grandchild is called x let me skip this part and y is the node in the middle so i think it is best if i show you the picture and that will give you an idea  refer slide time  51  13  suppose the 1st one was my tree  forget this empty node which is the last node for now this was my tree originally if this was my original tree  then is that an avl tree ? height balance is satisfied in the node 50 because 48 is one and this 62 is one the last node is not there  forget this type of node this 78 is also height balanced because this 50 is 2 and this 88 is 1 this is also height balanced because this is 1 and this is 0  refer slide time  49  46  this is height balanced because this is 2 and this is 3 initially  refer slide time  49  47 49  52  but now suppose i went and inserted a node 54 which came in here the 54 would come here  i go right  left and then right here and left here  refer slide time  49  56 50  03  now the height balance property is violated what i am going to do ? i am just going up the tree towards the root is the height balance property violated here ?  refer slide time  50  16  no it is not this is one this is zero is it violated here ?  refer slide time  50  21  no  1  2 this is height 2  this is height 1  refer slide time  50  27 50  30  it is not violated here is it violated here ? yes because this is now 3 and this is 1  so these numbers are the new heights  refer slide time  50  31 50  37  this is 3  refer slide time  50  40  so this 78 is the first node at which the height balance property is violated we call this node 78 as z  its child will be y and its grand child will be x we wonder which child of this node will be y the child on the path that we have taken  refer slide time  51  20  and now we need to do something to this tree to make it height balanced again this is not height balanced tree all the things we said about log n will go out of the window if you leave the tree like this what are we going to do ? we are going to do a kind of rotation operation and this 2nd picture in the above slide will become my new tree in some sense what i have done is  i have moved 62 up and moved this 78 down and this 50 was here it looks a bit mysterious that is what we are going to do in the next class understand how this rotation operation is done so as you can see now the height balance property is not violated at any node it is not clearly in the node 50  its not here in 62 and also in 78 both of them  50 and 78  have height 2 the 62 is at height 3 and this 17 is at height 2  so it is not violated this is still a binary search tree with the same keys as before  we will not change the keys there are other ways also but you want an automated way of doing it  you do not have to draw the picture and then figure out what rotation have to be done you will be able to do this program this is what we are going to do in the next class look at insertion and look at how to do these rotations so that the height balance property is retained even after insertion so we will look at both insertion and deletion in the next class so in todays class we looked at avl trees we saw how avl trees are defined and actually we proved a bound of as the height of an avl tree we spent a lot of time figuring out how to solve that recurrence relation we saw 2 ways solving that recurrence relation we also looked at some structural property of the tree which also proved a similar bound and the height of the tree with that we will end today ? s class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 12 avl trees  contd  today we are going to continue our discussion on avl trees in particular we are going to look at the insertion and deletion procedure in an avl trees so we will begin with insertion  refer slide time  01  24  we had started this discussion on insertion in the last class also suppose i am trying to insert a node v into an avl tree actually what i am trying to do is insert a key what is the process of insertion in a binary search tree ? first you find where the key is  you go to that place put the key there let say the node in which i put the key is v this is something we had started the discussion  if as a consequence of this insertion it does not remain an avl tree that is because the height balance property is violated what are the nodes whose heights could change as a result of this insertion ? which of the nodes whose heights could change ? recall we defined the height of the node as the height of the sub tree rooted at that node so this is large tree and some where below i insert a particular node which are the nodes whose heights could change ? it could only be the ancestors of this particular node not because it is written here but you should also understand why it is only ancestors because it is only in the ancestors of that node whose subtree has changed as result of this insertion process for any other node its sub tree has not changed it remains the same as before so the ancestors of this node  their heights might change and change means it will only increase because we have added a particular node so it is the ancestor of these nodes whose height might increase as a consequence of this insertion so if the insertion causes the tree to become imbalance or unbalanced  then some ancestor of this node v is the culprit and it is the place where one or more ancestors would have a height balance problem  refer slide time  03  47  height problem means it will become height imbalanced height imbalance means one left sub tree and right sub tree  the difference in heights is more than a one what are we going to do ? we are going to essentially travel up the tree from this node v travel up the tree which means just keep following the parent pointer till we identify the node z which is unbalanced so i have said  till we find the first node x whose grandparent is unbalanced  but you can also think of it as  i find the node z which is unbalanced and x is its grandchild which grandchild ? the grandchild that we traversed or went through the grandchild on the path because the node can have many grandchildren i will show you an example and this will be clear we will call y as the parent of x so y is the parent of x and then the child of z suppose this was the situation we had this was an avl tree which is given in the below slide and i insert let say 54 into this tree so 54 would come here why  because it is larger than 44  smaller than 78  larger than 50  smaller than 62 and so it would come here  refer slide time  04  54   now if there is a problem  actually this tree is not a height balanced any more this is not an avl tree any more if there is a problem we said that the problem would be on one of these nodes note that these are the only nodes whose heights are changed earlier the node 62 had a height of zero  now it is one the node 50 had a height of one  now it is 2 the node 78 had a height of 2  now it is 3 the node 44 had a height of 3  now it is 4 which is the first node on this path which is now imbalanced ? is the node 50 imbalanced ? no  the difference of height is 1.is the node 78 imbalanced ? yes  the difference of height is 2  the node 88 is 1 and the node 50 is of height 3 the height of no other node has changed the height of the node 17 is not changed  refer slide time  06  56  did you understand why the heights of these nodes on this path would change ? the node 78 will be z and x would be its grandchild on the path and the parent would be y lets call that x is a node  y is a node and z is a node so x is the node here in 62 so we travel up from 54  we find the first place where the imbalance happens let us call that z and x is the grandchild of z  grandchild means child ? s child so child is y and its child is x now we are going to rebalance this tree  so to rebalance this tree in particular we are going to rebalance this sub tree the sub tree rooted at z and we will do that by performing a rotation this is what will happen after the rebalance  this is what the tree would look like what we are going to do ? just understand how we came up with this picture as you can see i have only changed this sub tree  the one containing these 6 nodes 48  50  54  62  78  88 they are here the 6 nodes but organized in a manner so that this node 62 is not height imbalanced any more and neither this node 44 is height imbalanced we are going to understand this process today let us first understand what is a rotation in the previous slide i used this term rotation what does rotation mean ? so rotation is the way of locally reorganizing a binary search tree the picture shown in the below slide is a part of my binary search tree this could be a huge tree but i just consider a part of it so u is one node  v is its child and these are some sub trees the is the sub tree rooted at the right child of u and this is the sub tree rooted at the right child of v the is the sub tree rooted at the left child of u this could be a null tree  no node or could be a huge tree  i do not care what do i know ? because it is a binary search tree and i know all the keys in are less than the key in v all the keys in are more than the key in v keys in are less than the key in u and keys in are more than the key in u this follows from the property of binary search tree what is the rotation step going to be ? first what we are going to do is let us just forget these links and let just look at this  refer slide time  09  02   and now this is what a rotation does what has happened ? v has become the parent of u that is what a rotation is and will put the links back what happened was v became a parent of u the binary search tree property still holds by the way keys of are less than v  keys of are more than v so they come here and they are less than u so they come to the left of u it is still a binary search tree but we have done some local reorganization and this will be very useful and we will see why so remains to the left of v was to the right of u  if you remember was to the right of u  was to the left of v  was to the right of v so remains to the right of u  remains to the left of v but moves from being to the right of v to the left of u it is now the left child of u everyone follows what a rotation is  refer slide time  07  32  now let us see how we will use these rotations to do our insertion suppose the insertion happens this is the tree which is given in the below slide and i have not drawn the links but it should be clear what the links are who can tell me what the links are ? the y is the child of z  x is the child of y these two  are the children of x  is the right child of y and is the right sub tree of z so in the next few slides you will see pictures with out these links but that is just to avoid the clutter it should be completely clear about the relationships suppose i did an insertion in  and these are the x y z that we encountered in the procedure may be insertion happens some where in some leaf  we went up along the path towards the root the root may be some where here  refer slide time  11  48   and z was the first place at which we had an imbalance and y was the child of z and x was the child of y on this path that we took  refer slide time  16  29  i have taken one picture but it could also be different the y could have been the right child of z and x could have been the left or the right child of y how many different cases are possible there ? it is 4 the y could be the left of the right child of z and x could be the left of the right child of y two times two  4 different cases am looking at one particular case now that y is the left child of z and x is also a left child of y and the insertion happened in  i am using this ht   to denote the height of the particular thing the height of let us say originally it was h and now because of the insertion it became h + 1 it can not increase by more than a one because after all i am just adding one node so the increase in height can be at most a one and let say there was an increase in height so there is an increase in height of this node x also there is an increase in height of node y and there is also an increase in height of node z that is why z became an imbalanced if there was no increase in height of y then z would not become imbalanced  hindi conversation  everything is the same as before that means height of y is also increased and height of y has increased because height of x has increased height of x has increased because height of has increased and height of let say increased from h to h + 1 what can we say about the height of now ? what is the height of ? so x is balanced even after the insertion  because z was the first node which was imbalanced so x was balanced after insertion if x was balanced after insertion  hindi conversation   refer slide time  14  20-14  52   so height of is one of these 3 which one ? can it be h + 2 ? if it is h + 2 then originally x is imbalanced  because originally height of was h if this   is h and this   is h + 2 and then this  x  was imbalanced even to begin with  but that is not the case originally it was an avl tree so the height of can not be h + 2 can it be h + 1 ? if it is h + 1 then height of x does not increase because this   is h + 1 then that means what was the height x to begin with ? it is h + 2 if the height of this increased from h to h + 1  even then its height remains h + 2 the fact that the height of x has increased implies that this   can not be h + 1 if this   was h + 1 then the height of x did not increase it remained what it was before that is h + 2 this implies height of can not be h + 1 it has to be h so height of is h if height of is h and height of this   has increased from h to h + 1  then what about height of x ? what was the original height of x ? the original height was h + 1 and now it has become h + 2 the height of x has increased from h + 1 to h + 2  refer slide time  20  05  let us continue this argument so this is the picture so far which is given in the above slide we have argued that the height of has increased from h to h + 1 then height of is h then the height of x is increased from h + 1 to h + 2 what about the height of ? since y remains balanced  the new height of x is h + 2 and this y is height balanced the height of is h + 3 or h + 2 or h + 1 one of these 3  because the difference in heights can only be one so its one of these  if it is h + 3  we are repeating the argument roughly if it is h + 3 then that means y was originally imbalanced because original height of x was h + 1 so y is originally imbalanced height of can not be h + 3 if it is h + 2 then that means that the height of y has not increased because if this   was h + 2 then the height of y that means originally was h + 3  hindi conversation   so height of can not be h + 2 height of has to be h + 1 so height of is h + 1 if the height of is h + 1  what is the height of y ? originally it was h + 2 because both of these guys were h + 1  refer slide time  18  21   so this  y  was h + 2 originally and now it has become h + 3 so it increased from h + 2 to h + 3 what about height of ? note that z is imbalanced the new height of y is h + 3 so what should the height of be ? or it is h + 5  initially it was balanced since z was balanced  height of is h + 1 or h + 2 or h + 3 since this was originally h + 2  this   could only be h + 1  h + 2 or h + 3 and since it is now unbalanced it can not be h + 2 or h + 3  it has to be h + 1 the height of is h + 1 what is the height of z initially ? this was originally h + 2  this   was h + 1  so this  y  was h + 3 originally  refer slide time  20  02   and now of course its heights become h + 4  but now we will do some rotation and stuff like that so that will reduce its size  so its original height was h + 3  refer slide time  20  05  so we will keep this picture this is the final thing we argued these are the heights of the various things so when i said from here to here that is from h + 1 to h + 2  the first thing is  what it was originally and what it is now we just need to look at the new values we are going to do a rotation around this pair  y  z   what does rotation do ? rotation is going to rotate this  so that y is now going to become the parent of z what do we want to do ? we want to move this y up so that it will come here and y will become the parent of z this is what the rotation is let me just draw it here so y will now become the parent of z which is shown in the below slide where will i put these two ? the x is one sub tree  this remains as it is this will not be changed so will remain at the right and will come to the left and this big piece under x will remain as it is that is what the rotation was this is what will happen  refer slide time  22  07  the y has become the parent of z  these two and are the children of z and this entire thing under x was to the left again i have not shown the links but you should be clear what the links are i have written down the heights the height of was h + 1  was h  was h + 1 and was h + 1 after a rotation we already saw that the binary search tree properties are maintained so this is still a binary search tree  but now we want to argue that the height balance property is also restored  hindi conversation   refer slide time  22  31  where was the imbalance happening ? at z  as you can see this has height h + 3  has height h + 1 so this is height imbalanced  refer slide time  23  20   what is the height of node x ? it is h + 2 because this   is h + 1 and this   is h what is the height of node z ? it is h + 2 what is the height of node y ? it is h + 3 is everything balanced now ? this x is balanced because there is only a difference in height of one this z is balanced because there is no difference this y is balanced because there is no difference we have done a rotation this is called a single rotation you will soon see why it is called a single rotation how much time does this operation take for just one rotation ? we just have to do a constant number of operations may be z will have to become a child of y so there will be 3 or 4 different reference changes that you have to do may be 5  may be 6 or some constant number  independent of the number of nodes in the tree now one interesting thing is happened the original height of z was h + 3 that is why we had written this h + 3 here after this rotation the height of this sub tree is also h + 3 whatever was the original height of this  z  is the new height of this sub tree  y  also  refer slide time  25  01  so the height of the sub tree remains the same after the rotation the h + 3 was the height before insertion  after we inserted and did the rotation the new height also becomes h + 3 why is this important ? because now i do not have to go up further because now any ancestor of this  its height would not change any more because whatever was the original height of this h + 3 of this node is the new height of this sub tree also so any of the ancestors of z  their heights would become the same as before and so there will be no imbalance on them after i did my insertion  i started moving up i find the first place where there was an imbalance i did the rotation and i am done  i do not have to go up any further we have actually considered only one case one out of 4 different cases why one case ? because we said y is the left child of z and x is the left child of y now there is one symmetric case  which is the symmetric ? both are right  right that i am not going to handle because i trust all of you can believe me that it is the symmetric case completely the other case is this one where x is let say the right child of y which is the left child of z this has the symmetric case that is  y is the right child of z and x is the left child of y again that is completely symmetric and will not handle that so let us repeat the argument that we had  refer slide time  31  18  so once again i am assuming that the insertion happens in  it could happen in any one of these that is and but again it is symmetric let us assume it happens in  so this height went from h to h + 1 what about the height of ? since x is balanced  the height of is either h + 2 or h + 1 or h if it is h + 2 then that means x was originally imbalanced if it is h + 1 then that means the height of x is not changed so it has to be h i am repeating the argument  it is the same as before if is h and the new height is h + 1 what is the new height of x ? it is h + 2 what was the original height ? it is h + 1 so its height moved from h + 1 to h + 2 now let us look at the height of  since y is still balanced then that means the height of is either h + 3 or h + 2 or h + 1 if it is h + 3 then that means y was originally not balanced if it was h + 2 then the height of y has not increased it has to be h + 1  which means the height of y has increased from h + 2 to h + 3 which means that now since z is imbalanced  the height of has to be h + 1 which implies that the original height of z was h + 3 exactly the same as before  we do not make any difference but now the rotations will have to be a bit different in x  y and z  which of these 3 keys is the middle key ? x  y or z which of these is middle it is x z is the largest  y is the smallest if you recall in the previous rotation  we had x  y and z again in the previous rotation which was the middle key ? y  because they were all in a line z was the top  y was its left child so it means y is less than z and x was its left child so x is less than y is less than z so after the rotation we ended up making y as the root the middle key we ended up making the root here also we wanted to do something similar but except that the middle key is now x so we are going to do a 2 step rotation that is why it is called a double rotation first i will rotate x y let see what will happen after i rotate x y this is what it will look like x has moved up y has moved down  remains the left child of y  remains the right sub tree of x and switches loyalties from x to y so earlier it was the left sub tree of x  now it is the right of sub tree of y and remains as it is and i have just copied the same height so has height h + 1  has height h + 1  has height h and has height h + 1 no difference is this balanced ? is this height balanced ? height of y is h + 2 because both of these and have height h + 1 height of x will be h + 3  actually now there is an imbalance at x itself because y has h + 2 and has h there is an imbalanced in x and height of z would be h + 4 because height of x is h + 3 that is one more than that so this rotation has not done the job for us yet we need to do one more rotation what are the other rotation i need to do ? rotation  x  z   what will happen now ? x will go up and z will come down x will become the parent of z was the right sub tree of z  so it will remain the right subtree y had and as its left  so they will remain as they are and which was the right sub tree of x now becomes the left sub tree of z  the same thing now let us compute heights height of y  h + 2 height of z  h + 2 height of x  h + 3 height balance happens  this is balanced in y  its balanced in x and its balanced in z further the height of this sub tree is the same as the original sub tree  h + 3 so the final tree has the same height as the original tree hence we need not go further up the tree did you understand the need for the double rotation ? we ended up doing the same thing  as i said the middle key ended up being at the top because we want to be able to split the thing uniformly why was the height imbalance happening ? because x was the middle key  it was coming way down when i kind of split uniformly the heights reduced and there is a height balanced it is roughly what is happening here how much time does the double rotation take ? constant time so just as a quick recap  we have 4 different ways to rotate nodes in an avl tree the single rotation was something like this given in the below slide there were all in a line x y and z or they were like this x y and z  refer slide time  33  33   and after rotation this is the picture you get and here after rotation this is the picture you get  refer slide time  33  30  this is just a recap  you understand why we are doing this thing and why this picture is a height balanced picture and we also saw double rotations so either like this  in which case after rotation you got something like this or it could be like this left and right and in which case again after rotation you got something like that this is just to show you the picture  you do not have to understand much here you are hopefully understood why the single and double rotations are done in the way they are done  refer slide time  33  56  let us come to deletion because exactly the same principles are going to be used for deletion also it is a binary tree the difference between the height  does it become zero ? we saw that did we see that ?  refer slide time  37  50  let us see here here the difference is zero but in this node z the difference is a one  refer slide time  34  50   some nodes there would be a difference of a one  some other nodes there would be a difference of zero let us look at deletion in a binary search tree when i delete a node  we will have 3 cases if you remember when i am deleting the node which is a leaf or i am deleting a node which is only one child or i am deleting a node which has 2 children when i delete a node which has 2 children  what did i do ? i went to the successor of that node i copied the content of their successor in to that node and i deleted the successor the actual node i deleted was the successor node and the successor node has only one child or no children why does the successor has only one child ? because it does not have the left child  because if it had the left child then it would not be the successor it has only one child or it has no children so the actual node that you end up deleting is either a leaf node or a node with only one child this is the actual node that you ended up deleting what is a node which has only one child ? in an avl tree if i tell you  here is a node which has only one child what can you say about that node ? this is a node with only one child can it have another child ? can this node have the child ? no  if it had a child like this  then what would be the problem there would be a height imbalanced so it can not have this child or it can not have the other child  which means this node is a leaf exactly if in an avl tree  a node has only one child  then that child is a leaf what are we saying ? when i am deleting in an avl tree i am either deleting a leaf or i am deleting the parent of a leaf if i am deleting a node with only one child  then it is a parent of a leaf which means that i am essentially deleting a leaf if i am deleting the parent of a leaf them essentially what am i doing ? i can just think of it as if i was deleting the leaf and copying the content of the leaf in to the parent so i can always think of it as if i am deleting a leaf so either deleting a leaf or parent  let us just keep that in mind  refer slide time  39  46  let us say w is the node that we are deleting we are going to define our x y and z slightly in a different way so z is once again the first unbalanced node that we encountered as we go up from w towards the root when i deleted w  once again what is going to happen ? the ancestors of w  their height could reduce so one of these ancestors will be unbalanced  if any are unbalanced then one of this will be unbalanced let us say z is the first unbalanced node encountered while we are traveling up the tree from w now y is not the child of z on the path but we are defining y as child of z with larger height and x is the child of y with larger height z has 2 children  one of them has a larger height than the other one so we take that one once again we will perform rotations to restore the height balance of the sub tree rooted at z in the case of insertion what was happening is that once you did this rotation  we did not have to worry any more on the ancestor nodes everything was taken care of  we could stop after doing the rotation in delete what we are going to see is that we might have to continue up and we will see what the reason for that so you might have to continue up the tree  go to the ancestor of z and once again find the first node which is unbalanced and repeat the rotation there and after that go even further up find the first node which is unbalanced  repeat the rotation there and so on till you reach the root let us understand what is happening ? the x is the child of y with larger height if both of them have the same height  then we will say which of them should be x we will say that in a minute it could happen so this is a valid question both the children of y might have the same height then which is x ? we will see which is x the two children of z can not have the same height because that is the imbalanced node ignore these h-1 or h-2 for a minute they should have come at the end this is the picture which is given below  i have z which is the first unbalanced node y is the child of z which has larger height and x is the child of y which has larger height i did a deletion in  i started going up the tree i found a z can y be this node here  refer slide time  42  18  ?  refer slide time  45  49  if y was here then its height would have actually decreased what is a problem ? let see why did i draw y to be this ? so w is some where here  the node i deleted is some where here i started walking up and i came to z and this was a first node i identified which had an imbalance and then what did i say ? this node z has 2 children  this is one child of z and the other child of z is y let us take the child of z which has larger height why could it not have been this node which has larger height ? this is very simple actually  refer slide time  46  32  there is an imbalance that happened here earlier there was no imbalance imbalance happen because the height of this guy decreased  refer slide time  43  55   if there are 2 things which was balanced and one of them decreased then what can we say about the relationship between these two things initially ? could this have been smaller than this ? no  if this was smaller than this then actually it will become more balanced  refer slide time  44  20   so this y must have been larger than this for imbalance to have happened so this is y therefore the height of has reduced from h to h-1 what can i say about the height of y ? it is h + 1 it means that y must be h + 1 or h + 2 it can not be h + 2 because then originally also it was unbalanced it can not be h-3  because then initially it was unbalanced it has to be h + 1 so height of y is h + 1 of those 2  x is the one which has the larger height the height of x is h what can i say about of height of ? it can be h since this y is balanced this can be h or h-1 because y is balanced so this is what we have argued so far this goes from h to h-1  z is h + 2  y is h + 1  x is h  is h or h-1 so the height of x is h and this is also balanced so the heights of these two    are h-1 or h-2 one has to have a height of h-1  both can not have a height of h-2 that is the only thing we can say both can have a height of h-1 you can not say that only one can have a height of h-1 that is a wrong statement  at least one has a height of h-1 let us do a rotation now to see what needs to be done so these are the various heights that have seen which is given in the slide below this is what we argued in the last 2 slides what kind of a rotation should i do ? i will do a rotation  y  z  once again similar to what i did in my insertion so as a consequence you will have this kind of a picture now  refer slide time  47  12   y went up  z went down  and became the 2 children of z  and are the children of x i have written down the heights h-1 or h-2  h-1 or h-2  h or h-1 and h-1 because went from h to h-1  so this is h-1 what is the height of x ? this is h-1 or h-2  this is h-1 or h-2 but one of them is at least h-1  so x is h  refer slide time  48  59  what is height of z ? h or h + 1 what is the height of y ? h + 1 or h + 2 what was the original height of this tree ? h + 2 so if this is h + 2 then we are okay  we do not have to continue but if this is h + 1 then we may have to continue because this now becomes the bigger tree  refer slide time  48  21   hindi conversation   we will have to continue the argument as we go up the way we said  hindi conversation  height has reduced from h to h -1  now we might have to say that this bigger thing height has reduced from h + 2 to h + 1 and we will have to repeat the argument at the next higher level and so on  refer slide time  51  26  after rotation the height of sub tree might be one less than the original height in that case we have to continue up the tree it is might be  you understand ? because it could not have reduced  in which case we can just stop so this is single rotation  in the case when this was the picture which is given above y was the left child of z and x was the left child of y but we could have this kind of a picture which is given above  that x is the right child of y so the first part of the argument is the same this has gone from h to h-1  so we argued that the height of y is h + 1 so height of y is h + 1 and height of x is h because x is the one which has larger height and height of z is h + 2 because height of y is h + 1 this is of height h or h-1 how about the height of ? so y is balanced so height of is either h or h-1 now if height of was h then what i would do is  i would pick the root of as x so in that case i will be able to do that single rotation of mine  the previous case if the height of is h and the height of x is also h  the same question which he had asked earlier which do we pick ? which one will i pick ? i will pick the one which will give me the single rotation case i can not say that i will pick the left child or the right child i will pick the left child  if y is the left child of z if y were a right child of z then i will pick the right child since such was not the case  if it was h then i would have picked x as the root of  so height of is h-1 since the height of x was h and these  are the same as before h-1 or h-2 for both of them  with one of them at least being h-1 this is our new picture  refer slide time  51  35   let me just copy it here these are the heights of the various nodes and trees let us do the double rotation step so first i am going to rotate as before  x  y   the same process as an insertion essentially  refer slide time  52  03  so with the rotation of  x  y  y will come down and x will move up i would get such a picture which is given in the right side of the above slide is the right child of x  and are the two children of y that is the left and right sub trees of y the is h-1  is h-1 or h-2  is h-1 or h-2 and is h-1 what are the heights of these nodes ? height of y is h what about the height of x ? h + 1 and there could be an imbalance at x if this where h-2 and height of z is h + 2 because x is h + 1 and there is an imbalance at this node z  so there could be here at x and there is here at z there is none here at y but we are not done so we will now do a rotation around  x  z    refer slide time  52  55  what would happen ? x moves up  z moves down  and becomes the two children of the z has height of h-1 or h-2  has height of h-1 and has the height of h-1 or h-2 and has a height of h-1 what about the height of y ? it is h is it balanced ? yes  is h-1 and is h-1 or h-2 what is the height of z ? it is h is it balanced ? yes  h-1 and h-1 or h-2 what is the height of x ? it is h + 1  it is also balanced but this height is now strictly one less than this  z    hindi conversation  there is no might this time why did i make that argument  hindi conversation  height h-1  hindi conversation  h we could have done single rotation  hindi conversation  and all that thing  hindi conversation  you understand y i had to make this kind of an argument ?  hindi conversation   refer slide time  54  00   so hopefully you all understand this  refer slide time  55  12  what has happened is  final tree has height less than original tree  we need to continue up the tree you understand the need for continuing up the tree because height has reduced by one  as the consequence they could still be imbalanced at the ancestors ancestors of this node  that is what ever is this node this will require a proof even if it is correct  so think about it it is a good question he is asking me whether we can just be satisfied by checking the parent of this node so think about this and we will answer it  may be in the next class or may be after the class  refer slide time  56  38  let us quickly look at the running time of insert and delete so for insertion we spent log n time in finding way to insert why log n ? height of the tree  we actually spent time proportional to the height of the tree which is the height we argued in the last class that is log n so we spent log n time coming down then we spent log n time may be moving up at most log n because that is the height and then we spent constant time in doing a rotation and one rotation and we are done the entire thing is only log n deletion  recall that in insertion you will first find the node in the binary search tree whether the insertion has to be done you will insert the node then you will start moving up the tree to find the place where the imbalance occurs the first place and then in that place we said we will just do a rotation and with one rotation you will be able to satisfy the height balance property once again insertion basically requires order log n time to insert the node and you might have to spend order log n time to move up and a constant time to do the rotation so in all it just takes a log n order time deletion on the other hand also requires only order log n time but we need to do a little bit more work the reason for that is to delete a node  recall that you have to identify which of those 3 cases the node is does in whether the node you are deleting is a leaf node or if it has only one child or if it has 2 children then we need to find the successor of the node we need to go right and keep going left  find the successor  swap contents and then delete the successor node once you have deleted  now you have to move up the tree to find the first place where the imbalance occurs having found that you do a rotation  that rotation may or may not solve your problem if it does not solve the problem of height balanced  it does not restore height balance then you might have to continue up from that from that node and may be once again perform a rotation  if that is also the problem then you stop otherwise you will have to continue up so in all the number of rotations you might require is as large as the height of the tree because with every rotation you are moving one level up you might require as many as order log n rotations  but each of those rotations only taking a constant time the total time required for all these rotations put together is only order log n and we took order log n time to delete the node all the rotations also took order log n time the total time required for the entire delete operation is still order log n so with that we will end today ? s class we saw how to do an insertion and deletion in avl trees we argued eventually that the total time taken for both insertion and deletion is only order log n in the last class we had seen that the time taken for search is also only order log n in the case of an avl tree so all the 3 operations of insert  search and delete can be done in log n time in an avl tree data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 13  2  4  trees in today ? s class we are going to be talking about 2-4 trees this is another way of representing a dictionary so we are going to see the operation of insert  search and delete on this data structure and we are going to have the same kind of performance guarantees as the case in avl trees but in later classes we are going to see how this data structure is useful so today i will just begin with this  refer slide time  02  10  what are 2-4 trees ? they are search trees  they are a kind of search trees but they are not binary search trees so recall in a binary search tree what was happening ? the tree was a binary tree with each node at most 2 children so this not going to be a binary tree that is a first point nodes can have more than 2 children now so these 2-4 trees are also called 2-3-4 trees i will tell you what this really means so 2-3-4 actually refers to the number of children and node can have so a node can have either 2  3 or 4 children such trees in which a node can have many children but satisfy a certain kind of search properties are called multi-way search trees  refer slide time  04  43  so each internal node of a multi-way search tree has at least two children it will have at least two which means it could have more than two children any number of children more than two each node of a tree also stores a collection of items of the form  key  element   in the binary search tree  each node was storing one key and the element there was let ? s say a reference to the element or the element itself could be stored there if the key was a student entry number  then the student record associated with the key could also be stored in the node itself so in the similar way  we have that in the multi-way search tree you will have each node containing a pairs of this kind that is  key  element   and how many pairs there could be ? it is more than one in the binary search tree there is only one such pair in each node and in a multi-way search tree there could be more than one in particular there could be d-1 such pairs or items  where d is the number of children that particular node has so we are just generalizing the binary search trees in the binary search trees each node has two children each node could have two children and then there is only one key that is kept in the node because that key helps us to determine whether we should go left or right similarly here we have d children  if d is the number of children then you really need to know in the search process whether you should go to the first child  second child  third child  fourth child and so on so you will have d-1 different keys sitting in the node to help you determine that i will soon show you an example and that will be clear so this is an example of multi-way search tree  refer slide time  04  50   as you can see this node has two children this has 3 children  this node has 2 children and this actually has 6 children how many keys are there in a node ? the number of keys in a node is one less than the number of children that node has and why is that ? so for instance this node  refer slide time  05  20  has three children and you need two keys in the node the keys in the node determine what set of keys the various sub trees are going to have  refer slide time  04  43  so what i am trying to say here is  this is key 22 so this is also in the left sub tree so everything in this left sub tree here is less than 22 and everything here is more than 22 everything here is more than 22 and everything here is less than 22  refer slide time  06  00   if you look at this key everything to the left of this is less than 5  so in the right sub tree we now have 3 children so in this first sub tree everything would be less than 5 in the last sub tree everything will be more than 10 and those in between 5 and 10 would lie in this middle sub tree so that is a concept now you understand why you need d-1 keys if you have d children so everything less than the first key would be in the first sub tree for that you have to follow the first child everything between the first key and the second key you will have to follow in the second child and so on with that let me go back to the previous slide  refer slide time  04  43   so the children of each internal node are between the items this is what i mean by between in code so you have a certain node it has various keys or items if you look at two consecutive keys then all the elements or all the items which have key value between the consecutive pairs would be in one sub tree for that you will have to follow one child so let ? s get back to this this is an example of a multi-way search tree and how do you search in such a tree searching is similar to the binary search procedure as you did in the binary search tree so suppose we are searching for 8 you come down here  compare 8 with 22 so 8 is less so you go here  now you will have to find  so 8 is not less than 5 and 8 is not more than 10 but 8 lies between 5 and 10 so you will follow this and then you will find that 8 is sitting here so it ? s a successful search so when you are searching for a key s you will compare it with k1 k1 is lets say the very first key in that node and k lets say kd-1 is the last key in that node so you compare it with the very first key if it is less then  that means you have go to the left most sub tree if it is more then kd-1 then you have to go to the right most sub tree  refer slide time  09  25  so when you are searching for the node  for instance when we are searching here for 8  we came down  we went left because 8 is less than 22 then 8 lies between 5 and 10 so we came down here and then we found 8 here so when we are searching for 22  we came down the sequence of steps and we found that 12 was not there in the tree so in particular when you are at a node  you have to determine that the key that you are searching for lies between which 2 keys and once you determine that you will follow the appropriate child at the two extremities you will check whether it is less than the first key or it is larger than the last key in which case you would follow either the left most child or right most child so it is as simple as that so what would an in order traversal in the tree would look like ? that was the question we were at so first what is the in order traversal in a tree ? we recall in order traversal says left  then you print the data of the node and then you go right but now there is no left and right  because a node can have many children so what does an in order traversal here mean ? so first go the left most then print the key  then go to the next child then print the key  then go to the third child then print the key  then go to the next child and so on that would correspond to an in order traversal so for instance here if were to do an in order traversal  what would i do ? i would come down here  first go left so first i will do an in order traversal on this part of the tree which means that i first come in here  i first go left i will do an in order traversal here  which means i come in here i first go left but there is nothing here so then i print the key  that is 3 then i go to the middle child  nothing there so then i print the next key 4 then i go to the right child  nothing there so that finishes the in order traversal on this node  refer slide time  11  45  having finished the in order traversal on this node  i go back to the parent and then i will print this key  because first i went left then i print the key which means i print 5 then having printed this key i will now do an in order traversal of this sub tree  refer slide time  11  15   so when i am doing in order traversal of this i will get 6 and 8  having finished that i go back and print this key now which gives me 10 and then i will do an in order traversal of this right sub tree and that would give me 11 first  13  14 and then all of these so 17  18  19  20  21 now i finish the in order traversal of this entire thing so i print the key 22 and then i go right so as we can see  you will get the keys in sorted order that is also easy to prove why ? because in an in order traversal i will first print out all these keys and only then will i print out this key so which means that in the order of printing all the keys which are less than this key will appear before and all the keys which have more than this key will appear after and this is true for every key so which means what you get is a sorted order yes  8 could have more than other children also for instance  i could have something here let ? s say 5.5 the 5.5 would be a valid node here ? instead of this i could have just one node with 5.5 here that we could have organized in a different manner but 5.5 is a valid node  there could be more nodes here so now let us understand what 2-4 trees are so 2-4 tree is something like this what are the properties ? each node has at most 4 children so first it is a multi way search tree multi way search tree which means every node has at least 2 children now we are saying each node has either 2  3 or 4 children that is why it is called a 2-4 tree or 2-3-4 tree each node has at most 2  3 or 4 children the second important property is that all the leaf nodes are at the same level so the leaf node here are this  just forget this square boxes for now so these are the leaf nodes and they are at the same level  refer slide time  16  28  they are all at level  suppose we are numbering level 0  1  2 again  so they are at level 2 these are the only 2 properties of a 2-4 tree of course it is multi-way search tree  so a 2-4 tree is a multi way search tree with these 2 additional properties search tree will have a property that  everything which is less than this key is going to be in the left and everything that is more is going to be in the right this is an example of a 2-4 tree  as you can see this node has 3 children and this has 2 there is no node with 4 children but you could also have a node with 4 children in it what is the height of a 2-4 tree ? why should the height of the tree be at least log4n and at most log2n ? what is the worst case ? when would the height of the tree be maximum ? it is when everyone has 2 children in that case everyone has 2 children and all the leafs are at the last level then it is exactly a complete binary tree and in complete binary tree we argued that the height is log2n  there was plus one  minus one some where forget where it was  but it is some thing like that that is a setting when the tree height is maximum the tree height is minimum when every node has 4 children in it because then the nodes are closer to the root  you will have 4 and then 16 at the next level and then 16 times 4 that is 64 at the next level and so on once again if we do the same analysis you will find that the height of this tree is log4n so height of the 2-4 tree on n nodes always lies between these two quantities it is either log2n  it lies between log2n and log4n log4n is essentially half of log2n basically the height of the 2-4 tree lies between half of log n and log n how much time does it take to search in a 2-4 tree then ? why log n ? how do we search in a 2-4 tree ? it is a multi way search tree so if i am searching for a particular key lets say suppose what do i want to search ? i want to search for 11 lets say i came here with 11  where would i go ? compare 11 with 12  i come here  refer slide time  17  10   i am comparing 11 with 10  so i go right and then i find 11 here so i found 11 so how much time does it take for me to search in a 2-4 tree ? height of the tree  is it something more that i need to do ? it is correct  it is order height of the tree i have to compare with in each node because when i am searching for 11  i have to essentially compare against  how many keys there could be in a node ? a node we said has how many children ? 4 if it has 4 children how many keys would it have ? 3 the maximum number of keys therefore is 3 if it has 2 children how many keys do i require ? 1 so a node has either 1  2 or 3 keys so when i search for the key and i come with key  then i have to compare it with this key  this key and this key  refer slide time  18  16   so i might require 3 comparisons in all to determine which particular branch to take out so i might require 3 comparisons so the time is 3 comparisons with in a node  times log n because that is log n is a number of node i would be visiting order log n so order log n is correct but you have to be careful about this within each node you require more than one comparison in a binary search tree you required only one comparison but now you could require up to 3 comparisons why 3 log n ? he is asking me why did i say 3 log n when i am searching  i start from here  refer slide time  19  06  start at the root and then whatever key i have i compare it with the keys in a node here this node has only one key but it could have 3 keys in it then i have to compare against each of those 3 keys to determine which particular branch to take out of that node if it has 3 keys then there are 4 different branches  which should i take ? to determine that i need to make 3 comparisons let us look at insertion in a 2-4 tree i have this largest example that i am going to be using to show you the process is this a 2-4 tree ? this has 4 children  this has 4  this has 2 children  this has 2 children and this last one also has 2 children  refer slide time  19  56   i have shown the node with 3 locations in it so each node will have space for 3 keys and 4 pointers  refer slide time  19  43  so it has only one key but i have shown each node having space for 3 so the first element i am going to insert is 21 how do we insert ? we insert just as in the case of the binary search tree first we will search and wherever our search terminates  if we found that element then it would say that it already exist you will not insert then but wherever the search terminates we would insert the element there i am trying to insert 21 so 21  i come and compare here 21 lies between 13 and 22 which means i am going to take this branch out so take this branch out  i compare it against 18 it is larger than 18 so i am going to take this branch out  refer slide time  21  00   so take this and it goes and sits in that particular node why does it go and sit in this node ? why did not i compare with 20 and say that let me go down further this is a leaf node i could also have said it  i compare it with 20 then i try to go right but right node is empty the right pointer is a null pointer because it is not going down any further so i know that this is the place where i have to insert and this is empty and there is space here so i just put it in we would not put it next to 18 we would continue till we can not go any further this is what happens in the binary search tree  hindi conversation  you keep comparing till you hit a null pointer and then you put it there so till we hit a null pointer we compared 21 with 20  let ? s say we were trying to go right but this is a null pointer and so we put the node here now you are wondering how i am going to use this space we will see how we are going to use this space if this was already filled  refer slide time  22  22   hindi conversation  you will have to wait till the next slide so if there is empty space no problem you can do the insertion let ? s say now we try to insert 23 so 23 lies between 22 and 32 we are going to take this link out we took this link out  23 is less than 25 so we come down here in a node we will try to keep the keys in a sorted order because only then so 23 should come at this place what should i do ? move 24 to the right and 23 will come at its place insertion actually happens at the very last node that is at the leaf nodes the other way i could think of it is 24 was here  i compare 23 with it  i tried to go left that is null pointer so that means i have to insert at that node itself we are trying to insert 40 there should be no problem with 40 the 40 is more than 32 so i go right  i come here 40 is more than 35 so again go right and there is space here so i compare 40 with 39 it is a null pointer which means i have to put it right here there is space so i put it there  refer slide time  23  48   refer slide time  23  58  if i am trying to insert a key and there is no space available in the node in which the key should go then what do i do and that is an example when i am inserting 29 that is the kind of thing would happen so 29 between 22 and 32 so i follow this 29 more than 25 so it wants to come and sit here between 28 and 30 except there is no space here  refer slide time  24  20  so this is what we are going to do we are going to split the node which node are we going to split ? the one containing 26  28  29 and 30 we are going to split it in to 2 let ? s say these are 4 keys  the two smaller one will go to the left and two larger one will go to the right and we will remove this node we need to link up this node  this should be the children of this guy here  refer slide time  24  53  because these are all originally children of this node so this should also be a child of this node but now its going to have 3 children but how many keys are there ? one  so we need one more key if it has 3 children  it should have 2 keys so which key i should put here ? i am going to promote  hindi conversation   so it is best to just promote up 28 that is what i will promote 28 here  refer slide time  25  54  i could also have promoted up 29 you understand why 28 and why not 26 if i had promoted up 26 what would be the problem ? then the search property would not be valid so i have to promote either the largest key from this node  up here or smallest from here this will become the new structure we have promoted one key to the parent and inserted that key we could insert the key in to the parent because there was a space in the parent but it might happen that when i am trying to insert the key in to the parent  the parent does not have any space  hindi conversation  7 less than 13 so we have go to left the 7 between 3 and 8 so we should follow the second pointer it should come here and we want to put it here except that there is no space  so we will split this node two nodes created 4  5 go to the left node 6  7 to the right node we get rid off this these are the 5 children of this node  hindi conversation    refer slide time  27  20  so if the parent node does not have sufficient space then it is split so we split the parent node in to two 3 and 5 will go to the smaller one  8 and 10 will go to the larger one that is to the other node i have 1  2  3  4  5 children and they have to be made children of these guys and one of the smaller  hindi conversation  that has to be promoted up because when a split happens then we take the largest key of the smaller node and promote it up the first two children would be made the children of this node the right three would be made the children of this node why two of this and three of this ? because 5 is going to be promoted up so that means there is only one key left here which means that this can have only 2 children the first two children will go here  5 is going to be promoted up so this will have two keys which means 3 children so these 3 would be its children and we promote 5 up so we split this node  hindi conversation  that we split first then we went and split the parent and now we will see the split happening here also because this does not have any space so we will split it in to 2 the 5 and 13 would go in to one node 22 and 32 will go to the other node this will disappear  refer slide time  29  41  and now 1  2  3  4  5 these are five children  refer slide time  27  35  so 13 will get promoted up now so the first two will become children of this and the next three would become children of this and 13 get promoted but where does it get promoted ? there is nothing above so we will create a new root  eventually we may have to create a new root that is what going to happen now we create a new root  13 goes up there and these two become the children of this  refer slide time  29  40   refer slide time  30  05  so if we create the new root the height of the tree increases by one you understand the procedure so you first come down the tree till you hit a leaf you will try to put the key there  if there is space nothing to be done it is very simple if there is no space then you split that node and then we decided that the two lower keys will go to one node and two higher keys will go to the other node the largest key in the lower part would be promoted up so when we split there are four keys in a node there were four keys  hindi conversation  to which means the second key of those four is the one which will get promoted up promoted up means we are trying to insert the key in to the parent node if we are successful if there is a space no problem  otherwise repeat the split process of the parent node so split it and this split might cascade all the way up to the root if it cascades up to the root and the root also gets split then we have to create the new root that is it  refer slide time  32  33  how much time does insertion take ? so search was very clear for search we said it will take order log n time how many splits can be there in the process of insertion ? its at each level we might be doing the split how much time does one split take ? how much time does it take for me to split a node ? i will create some two nodes  hindi conversation  constant time independent of the number of node so each node split takes constant time so the total time is order log n  hindi conversation    refer slide time  33  45  so now let ? s look at deletion so suppose i wanted to delete 21 first as in the case of the binary search tree  first you have to search for 21 find out where the key is in the case of a binary search tree  recall deletion require 3 different cases if the key was at the leaf then we just knock out the leaf  nothing to be done if it was at the internal node then you had to distinguish between one child and two child the one child case is not really happening here so it is only two child case that we have to be worried about if it is such an internal node with two children then what did we do ? we found the successor or predecessor of that key lets say we found the predecessor and we move the predecessor to that and delete the predecessor that is what we would mean we are going to do something similar here let us see suppose i wanted to delete 21 so 21 there is no problem because 21 is in a node we will search for 21 we come down here  go right  go left  go right and i find 21 here why is there no problem in deleting 21 ? it is in a leaf node  i can just remove it and i can remove it without violating the property of the 2-4 tree in a 2-4 tree we require each node has at least one key and at most three keys so after deleting  this will still continue to have one key  so no problem that is what is going to happen i have not shown the process but this 21 will get deleted  we just knock it out from here  nothing to be done if the key to be deleted is an internal node  is at an internal node for instance i was trying to delete 25 i search for 25  i find 25 right here what do i do ? i am going to swap it with its predecessor what is the predecessor of 25 ? how do i find the predecessor of 25 in the case of a 2-4 tree ? i will go left and then keep going right  hindi conversation  then i find the largest key in this node  refer slide time  37  35  i find the largest key its 24  so predecessor of 25 has to be 24 i am going to swap this two then i am going to remove the 25 from here this is a same thing  i can remove the 25 from here why  because its a leaf already there are two keys in the leaf  so if i remove one there is no problem note that the predecessor will always be in the leaf in this case not in the case of a binary search tree let us check this point out in the case of the binary search tree  the predecessor of a node need not be a leaf node suppose this was my binary search tree  this was a node 10 i am finding the predecessor so i go left and then i go right this could have been my binary search tree what would be the predecessor of 10 ? it would be this guy  refer slide time  36  15   this is not a leaf node but here the predecessor will always be a leaf node why ? how do i find the predecessor ? i go left and then keep going right  keep taking the right most child so when will i stop ? when there is no right child what does it mean when there is no right child ? when my right child is null then that means all the children are null because i can not have a situation in which there is a node which has a key  it has no right child but it has left child this is not permitted at all if there is a key then we will have two children  if there were two keys then we will have three children and so on so my predecessor would always been a leaf  so i would just remove that leaf node and i would be done so that is what i do recall i was deleting 25  so i swapped 24 and 25 and now i have to just get rid off 25 so i will get rid off 25 by that so 25 disappeared from here it is a very simple case as you can imagine  problem were arising when i am in a leaf  i am trying to delete a key from a leaf which has only that one key in it then that leaf becomes empty so what do i do now ? so let us look at that if after deleting a key  a node becomes empty then we borrow a key from its sibling let us see what that means suppose i am trying to delete 20 so i search for 20  i come down in this manner i reach here  now if i delete 20 so 20 is removed  problem is this is an empty node not permitted what will i do ? borrow from sibling what does borrow from sibling mean ? this guy has only one sibling so can i borrow 15 from here to here ? no  it is disaster because search property is not going to be valid so we are going to do something like a rotation like we did in an avl tree what does it mean ? 15 goes up and 18 comes down  refer slide time  38  23  then the next thing you are wondering is  if i can not borrow from my sibling when can i not borrow from my sibling ? when the sibling has only one key in it for instance now if i were trying to delete 18 then that would be a problem let see if sibling has only one key then we merge with the sibling that is we combine with the sibling suppose i was trying to delete 23 so 23 is here if i delete it this is an empty node so i try to borrow from a sibling  refer slide time  39  44  there is a small catch here  hindi conversation  one and two  but i can not borrow from this one you see why it is because if i have to promote something then 28 is going to come down but this going to jumble this so when i say borrow from a sibling i really mean and adjacent sibling  refer slide time  40  35  i can borrow from here  so when i am here i can borrow from here  if i am here i can borrow from here if i am here i can borrow from here or from here but here i can only borrow from this guy did everyone understand why this is required ? i try to borrow from here but if i borrow from here that is 26 goes up and 24 come down this is going to become empty so that is not going to solve our problem what we are going to do is merge these two are going to merge  combine but if these two combine then the number of children here of this guy will become two which means  hindi conversation   so the key in the parent node which separates these two siblings is this key  which is separating these two siblings is going to move down in to the merge node let us see  i create a new node which is the merge of these two nodes this 24 moves down and this 26 also these are the only keys in the new node because there was one here  there was none here and there was none here two keys in all so they come and sit here these two will now disappear and this becomes the child of this node  hindi conversation   now what can happen ? essentially what we have done is we said we are going to one of the keys from the parent node is going to come down but what if there was only one key in the parent node the same as before  hindi conversation  and so on so moving the key down from the parent node corresponds to deleting the key from the parent node  refer slide time  43  02  this procedure will be the same as that we have done so far in this leaf node but it can lead to the cascading cascading as in  hindi conversation  we will see that happening in this example  hindi conversation   this is the only child left of its parent  hindi conversation  sibling is also only one key so we are going to merge with the sibling we are going to create a new node which is going to get the sibling key and the key from the parent which is 22 this is the situation now and we will delete this and this  hindi conversation   because of these deletions  height can reduce by one after all we said height  hindi conversation  log4 n is less than what it was  then that means height has to shrink and that would happen there are just very few concepts that we really handled and insertion  hindi conversation  or deletion  hindi conversation    hindi conversation  no point is doing that so first you try to borrow if not successful then you merge so let us conclude today ? s discussion height of a 2-4 tree we have seen is log n  refer slide time  48  15  this would actually be a theta of log n because it is at least log4n and at most log2n so as far as deletion was concerned we have not looked at running time for deletion yet but you can see that is also log n why ? it was first we come down the tree to search for the key that is log n and then we keep moving back up at every step we might go all the way back up to the root so another log n step each step where either borrowing one from the sibling or we are merging with the sibling but all of them are constant time operations borrowing would correspond to  hindi conversation  constant time  hindi conversation   so what you have seen is that search  insertion and deletion all take order log n time in a 2-4 tree so why did we come up with this very complicated data structure ? why are we doing all of this ? there is another reason  we are going to see another data structure called red black trees and that is also very fast data structure for implementing dictionaries what we are going to see is that what we learnt about 2-4 trees today is going to be very helpful in understanding how the red black trees functions so we are going to look at this in next class so with we will end today ? s discussion on 2-4 trees data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 14 red black trees in today ? s class we are going to talking about red black trees we are going to spend some time discussing about red black trees  what is the relation to 2-4 trees and what will discuss next and then we will see the process of deletion in red black trees it is going to be slightly more involved process so we will be spending fair bit of class on deletion  in the next we are going to handle insertion in red black trees  refer slide time  01  17  so what is a red black tree ? so red black tree first it ? s a binary search tree so we take the node of the binary search tree and we color them red and black and then it becomes the red black tree subject to certain properties so first the root has to be colored black that is important a red node can have only black children that is another property that a red black tree has to have if there is in a red node then its children have to be black now one thing we are going to do is in our binary search tree if a node does not have left or a right child  so we will create the left or a right child by creating what we will call an external node and i will show you what i mean by that we will create an additional left or right child  if it ? s a leaf node of the binary search tree then it does not have either a left child or a right child so in which case we will put in a two external nodes below that leaf node and make it the left and the right child  refer slide time  01  40  so external nodes we are not going to color them so it ? s only the non-external node  original nodes of the binary search tree that we are going to color red or black we define the black depth of an external node as the number of black  its number of black ancestor ? s so what that means is we are going to take an external node and we are going to walk up the external node towards the root and the number of black nodes we encounter is the black depth of this external node and the one key property of the red black tree is going to be that every external node has the same black depth and that we will also refer to as the black height of this tree so lots of definition but we will see what this means  a couple of examples  refer slide time  06  42  so this is two examples of red black trees so let us look at the one here so what do we have ? this is the binary search tree on 5 nodes i have colored the nodes black and red the root is black  a red node has only black children  black node can have black or red children but a red node can have only black children as you can see this node does not have any left or right child this does not have any left right child ; this does not have any left or right child so i am going to add them  refer slide time  04  20   these i will call external nodes  they are not colored so all the external nodes in this class today will be shown with the square boxes now what is the black depth of this external node ? 1  2 it is the 2 ancestors which are black  similarly the black depth of this are external node is 2  of this is 2  of this is 2  of this is 2 and of this is also 2 so this is a red black tree so we will add this external node also to node which has only one child so let us look at this example and that will be clearer so once again the root is black  a red node has only black children that is the key  the red node can have only black children black node can have red children or black children now we are going to add the external node so as you can this node has only one child so we will need to add an external node here also similarly it will need to add 2 external nodes here  one external node here and of course these will take 2 external nodes and so on so these are the external nodes we will end of handing  refer slide time  05  43   student conversation   a black can have black children but red can not have red children  it ? s not symmetric  student conversation  you going to take first case  staff  ya  student  it has black and both the children left and right to be red right child is if we place the external node and we count the black height so it will be one staff  red so then it will not be a red black tree that ? s what you say  so if i had colored this red then this would not be a red black tree the black height of this guy is 2 what is the black height of this guy  of this tree ? 2  i will take any external node and look at how many ancestors are black and we will see that its 2 ancestors which are black and this is true for every external node ; if i look at this it also has two black ancestors  this also two black ancestor and so on so this also has a black height of tree so what are the key things we have to ensure ? first that no red node has a red child  second root is black  third black height of the every external node is the same black height or depth i sometimes use the term depth to say how far it is from the top so black depth of the every external node is the same  the black depth that ? s what we will call the black height of the tree  depth of the node and height of the tree and these are the two examples of trees which are not red black  refer slide time  07  24   why this is not red black ? this red child  this red node has a red child so this is not  so even i have put in the external node like this  this will not be a red black tree why is this not a red black tree ? so the problem here is what we call a double red problem we will use the term quiet often  double red as in two reds occurring consecutively one after the other  refer slide time  07  55  here i add the external nodes  the black height of this node is  the black depth of this node is 2  of this node 2  of all of these is 2 this is also 2  this is one  this is culprit  for this reason this is not a red black tree so black height is not uniform  black depth is not uniform so let ? s look at what is the height of the red black tree is going to be ? so let ? s say h is the black height of a red black tree on n nodes what does it mean ?  refer slide time  08  23  if i take any external node and i will look at  count its number of ancestor that it has exactly h black ancestor when will the number of nodes in this tree  suppose i just tell you that this is the tree of black height h  when will the number of nodes in the tree be small ? when the smallest ? when everything is black  you don ? t want any red you want as few nodes as possible so why include your red nodes and increase the number of nodes so let ? s have everything black  if you have everything black then this becomes a complete binary tree of height h or my red black tree why because all the external nodes have to be at the same level now if they have to be at the same level all the external nodes then it will become a complete binary tree of height h if i have a complete binary tree of height h then the number of nodes in the tree is 2 to the h-1 so the smallest number of nodes possible in a red black tree of black height h is 2 to the h-1 when is the number of nodes the largest ? when every black node has 2 red children  but red node can not have any red children so then it will have to have black children which will have to have red children and so on we will have these alternate layers of black and red so we start with the black then we have red layer then we have black layer then red layer and so on if the number of black layer is h then the number of red layer is also h so the total height of the tree becomes 2h and so number of nodes in the tree becomes 2 to the 2 h-1 which is about 4 to the h-1 so this implies that h lies between log of n to the base 4 and log of n to the base 2  just + 1and -1you can figure out so if i give you a red black tree on n nodes  so i just turn thing around then if i give you red black tree on n nodes then its height is at least log n to the base 4 and at most log n to the base 2 we have seen exactly of the same property for 2-4 trees we said its minimum height is log n to the base 4 and maximum height is log n to the base 2 the same kind of the thing is happening here so now you can immediately see that if i give you red black tree then to search in the tree  will take how much time now ? log n  why because first remember it is a binary search tree so it has the search property  so i can do the search in this regular way that is start from the root  compare key with the root  go left or right and so on so i can do my search and the time taken for that search is just the height of the tree and the height is no more than log n base 2 so that ? s the time i take now let ? s look at the correspondence between red black trees and 2-4 trees so in particular i am going to say that given any red black tree  i can convert it into a 2-4 tree so what are we going to do ? we are going to take a black node  that black node  how many red children will it have ? it ? s a binary tree so it might have both its children could be black  one child could be red  the other could be black or both could be red  both could be black  both could be red one could be red  one could be black or you could have external node also  one could be external node but in any case the number of red nodes can not exceed 2 it will be 0  1 or 2 so we are going to take this black node and its red children and combine them in to one node how many keys there will become in this one node ? at most 3  when this node had 2 red children let ? s see so what i am saying ? i am saying  we have a black node and we look at its red children suppose it had 2 red children so i am going to combine it in to one node  all these 3 i am going to combine in to one node so this one node will have 3 children suppose it had only one red child and then it would be 2 keys in here and if it had no red child then there will be only one key here  refer slide time  12  00  so each node so formed has at least one and at most 3 keys furthermore black height of all the external node is the same  so in the resulting 2-4 tree all leaves will be the same  will be at the same level and this might has not too make sense what are we saying ? black height of all external nodes is the same so if i start from the external node and go up the tree  the number of black nodes i encounter would be the same no matter which leaf i started from ? so each of those black nodes is now part of a unique 2-4 node because i took a black node and i took its red children and i combine in to one so each of a black node is a part of a unique node of a 2-4 tree so as consequence when i start from a leaf and i go up to the root i encounter the same number of nodes in a 2-4 tree which means that all the leafs are in the same level of the 2-4 tree  refer slide time  17  23  we will show an example with which this will become clear so this is my  refer slide time  15  36  red black tree i am going to convert it in to a 2-4 tree so i start with the root node  i will look at its red children it has two red children all of these will combine in to single node of my 2-4 trees now i am going to look at another black node which is this  look at its red children it has again 2 red children so all of this combine in to one and they combine in to one like this  refer slide time  16  16   so as you can see when these combine in to one  these 4 links that i am going out of this combination will be the 4 links going out of this node when i took this entire thing let me go up  there are four  1  2  3  4 children of this  refer slide time  16  47  combined structure they would be the 4 children of this node so this is the first one  then i look at this how many red children does it have ? only one  so they would combine in to one  so i get another node which is 5  7 this becomes a second child  as you can see this is more than 4 so this will be more than 4 here and what will be my third child ? it would be just this black node  it has no red children so i create a node with only 11 in it and the fourth one 19 and 17  so i create another node with just 17 and 19 in it so this is the 2-4 tree i get now you can see the black height was 2  it was the same for every external that was the black tree and i get 2-4 tree of height 2 so i am giving a proof by example but this should be clear why i will get the 2-4 tree ? so the property of a 2-4 tree  one critical property of the 2-4 tree is that all leaves are at the same level just saying that every node has 2  3 or 4 children doesn ? t make it a 2-4 tree all leaves have to be at the same level and that is in ensured because of the fact that the black depth of every external node is the same so this is how we can obtain a 2-4 tree from a red black tree  refer slide time  18  29  we can also go the other way round  that is given a 2-4 tree you can make a red black tree so what are we going to do ? we are going to take a node of the 2-4 tree  replace it with 1 black node and then appropriate number of red nodes what do you mean by appropriate number ? if they were 2 keys in this 2-4 tree node then i will have 1 red node if there were 3 keys then i will have 2 red nodes if there was only one key then i will have no red nodes and these red nodes will be the children of the black node so first i put down the black node then i put the appropriate number of red nodes now this ensures that i will not have the double red problem why ? i will not create one red node as a child of another red node  because what am i doing i am first taking a node of my 2-4 tree  first putting down a black node and then putting 0  1 or 2 red children and then when i take the next node of a 2-4 tree which is the child of the previous one then once again i will first put down the black node so i will not have 2 reds consecutively happening that we will see in the example shortly furthermore what ? s going to happen is that for every node of the 2-4 tree i am putting in one black node so since all the leaves of the 2-4 tree are in the same level the black height of the resulting red black tree would be uniform ; the black depths of all the leaves would be the same so let ? s take an example ignore this for now  this should have come later this is my 2-4 tree  refer slide time  20  21    refer slide time  21  52  as you can see each node has 1  2 or 3 keys which mean 2  3 or 4 children and the height of the tree is 3 let ? s see so there is only one key here  i will just create a black node and nothing else no red nodes let me take this one  so i will create 1 black node and it will have 2 children  2 red children what should be the key in the black node be ? 8  3 and 10 means 2 children then i take this one  18 just one black node with 18  no red children let me take 1  2 so this would have 1 black node and 1 red node i have an option ; i might put 1 as the black and 2 as the red or the other way round so i am going to put 2 as the black and 1 as the red for 4  5  6 ; 5 will be the black and 4  6 will be the red  black 9 nothing else here 12 black let ? s say and 11 red  14  15 black  14 red and 20 so now are you convinced that you will not have double red problem ? just by the way we are doing things when i take a node and i create some thing in the red black tree i first put down the black node and only then i put down the red node so at the next level i will first put down the black node so it will never have two consecutive reds furthermore the black height of this red black trees so if i have to draw the external nodes and count their ancestors so if suppose there is an external node here  it has three black ancestors which is as same as the height of the red black tree because of that all of them would have same black depth if i were to look at this external node which is here then it has black depths of 3 everyone would have the same because if it is going from here to here then it corresponds to going from here to here because each of those black nodes is one level here so the black height is same as the height of the 2-4 tree so you understand what red black trees are and you understand how they are related to 2-4 tree basically there is 1 to 1 correspondence given any 2-4 tree i can create a red black tree  given any red black i can create a 2-4 tree so in fact the operation of insertion and deletion in a red black tree are exactly the same as you do in a 2-4 tree so we are just going to mimic those operations in this setting and that was one of the major reasons for doing the 2-4 tree so we are going to mimic the operation but of course it will require to do it carefully so i am going to look at the operation of deletion because this is slightly more tricky operation  refer slide time  28  22  so how do we delete in a binary search tree ? the first step of the deletion is the same as the binary search tree which is let we first search for the node  you are in to five other node if the node is a leaf then you just deleted if the node is an internal node then you find it successor or predecessor  you swap and then you delete the successor or predecessor so now the successor or predecessors suppose we are talking about successor so successor is a node which does not have a right child if it does not have a right child then that means we would have its right child which is an external node  we put an external node there so that means the node that i am deleting is always the parent of some external node if it ? s a leaf even then its parent of an external node otherwise it doesn ? t have a right child if you were talking of a successor if it doesn ? t have a right child we put in an external node so it ? s always parent of an external node so these are the three settings we could have of the node that we are deleting  these two corresponding it to being a leaf so either if the node is a leaf either it is a red leaf or black leaf and the third setting is when the node that we are deleting does not have a right child so it does not have a right child which means right child is an external node  if it does not have a right child but has a left child then this left child has to be red why ? if it were to be black then black could not be remain consistence yes why ? because if i look at these external node verses this external node   hindi  you follow what i am saying if this were black then if this node has 10 black ancestors then this one would have 11 black ancestors why ? because all its black ancestors are also ancestor of this guy and this has one more ancestor  this has to be red therefore if this is red then it can not have any red children but it can not have any black children either because if it had black children then once again we could have a same problem of black height not being the same so this is the entire structure that we would have if this is the node that i am trying to delete and it did not have a right child and it was not a leaf either then that means it ? s right child is an external node  we said that already its left child will be a red node which would be a leaf so then in this case the node that we are deleting is really parent of a leaf node in this case the node we are deleting  in each case we are deleting the node here in these two cases the node we are deleting or leaf node themselves and this case it ? s a parent of a leaf node if 19 is a red node can 19 be a red node and 17 be a black node  black height would not be the same he is saying suppose this is red and this is black  this is red and this is red  it can not be it ? s a red double red problem this is red and this is black  hindi   so now this is an easy case to handle if i am trying to delete this node what should i do ? it ? s a leaf ; just delete it  nothing to be done it can not create a double red problem  if i delete this that ? s what i have done  just delete and just replace this entire thing with this external node it can not create a double red problem and it can not also change the black height of any node because it ? s a red node after all similarly this case is also easy what will i do ? i am trying to delete this 19 so what should i do ? 17 can move there and this entire thing can be removed so i have not created a double red problem  hindi  as it was before and this earlier had 10 black ancestors  it still has 10 black ancestors and this node also has same number of black ancestor so the only tricky case is this one by the way what do these two cases corresponds to in the case of 2-4 tree ? this and this  refer slide time  30  30   what are we deleting ? the key that we are removing is from a leaf always in a 2-4 tree and this corresponds to the case when the key that we are removing is part of node which has at least two keys the key that we are removing is in a node which has atleast two keys and that was the very simple case there if this was my 2-4 tree node and this had keys let ? s say 3 and 5 and i was trying to remove 5 or 3 its very simple operation nothing needs to be done and this case as well as this case both of them correspond to this  refer slide time  30  54    refer slide time  31  25  why does this corresponds to this ? this is the node  even here this has to have a black parent and so this is the node then corresponding node in the 2-4 tree and this is a corresponding node  it might be even larger actually it might have 3 keys ,this might also be red  hindi   this however is a tricky case  this corresponds to a single key in a 2-4 tree node so in the 2-4 tree node  if i remove this key then the node becomes empty that ? s a problem and here this would correspond to change in the black height hence we can assume that the door deleted is a black leaf that is this is the only case which is really interesting for us and we removing this reduces the black depth of an external node by one and so in general we are going to assume the following we are going to look at the following step there is some sub tree whose black height is reduced by one and we want to re organize the tree to take care of that why i am saying sub tree  refer slide time  31  25  where this is a sub tree what is going to happen is that as we do reorganizing this tree could become larger and larger this is a black height  hindi  and we will see that so it ? s going to have a bunch of cases as procedure  refer slide time  34  44  so let me assume that this is a tree  hindi  black height because of the deletion once  hindi   so what i am going to do  i am going to look at the parent so this is the tree  hindi  root has sub tree i am going to look at its parent the parent is let ? s say  hindi   so first i will check whether a is a black or a is red depending upon this i will have two different cases happening if a is red so this is a picture what about the other child of a ? it has to be black lets says its b let ? s look at the two children of b let ? s call them c you do not know whether they are black or red a is just name for this node nothing else this is the tree whose black height is reduced by one  the sub tree i am just looking at the root of the sub tree and its parent  refer slide time  33  44   so a is the parent let me just clarify this point so what you are saying is we are interested in when we are deleting this black node which has two external nodes and this has some parents somewhere when i delete this entire thing i replace it will one external node here so essentially this sub tree  this node and its two external node children  hindi   it is getting replaced by this  black height zero  hindi   the problem why we have to formulate this way is that this is going to in some cases what is going to happen is this tree is going to expand so just take this for now and we will see  hindi  if you are confused then just think of this has the single node with two children like this picture you can think of this blue triangle as that  its black height is reduced by one so this is one possibility if this is red and this child is black and we do not know what its two children colored are the other is that if this is black  a is black then b could be red or black so depending upon what the color of b is we will have different cases here  depending upon what the color of c is we will have different cases so these are two cases either both of these are black that could be one case  refer slide time  37  30  so i have not shown them black  i am just showing you what the various cases are then we are going to handle these cases separately one after the other so one case when both of these are black  the other case is when one of these is red this is let ? s say red and these is one case for us this is just a part of the tree there would be a left sub tree here  there would be some sub tree is hanging here and so on and of course this will have something  this will have a parent and more happening here  refer slide time  36  28   this is the case when both are black so i have not shown them here but this will be another case let ? s come here now depending upon what b is we will have two case red or black so b is red then this is the red node then it will have a right child which is black  it ? s right child can not be a red and this will be black and now i am going to look at two children and depending upon what the two children are i am going to have two more cases the other option is when b is black in which case we will have two children and depending upon what these two children are once again we will have two cases so here there is one case when one of this two is red so that is the case like this and the other is when both of them are black which means i will just look at the scan structure similarly here  there would be one case when both of them are black when one of them is red then i will have this and when both are black i will have this so in this manner  this is just a kind of a starting picture to show you that there will be six cases that we will be looking at and we will see what the tree organization  re organization has to be done so i am going to refer this as case 1.1  1.2 this will be 2.1.1 so this is the first case we are going to look at so this is what the picture would be so a b c and basically a b c and this is the tree sub tree whose height is gone from h to h  1 let see the black height is gone from h to h ? 1  refer slide time  39  53  now what will be the black height ? so all these heights are now black heights what is the black height of this sub tree ? i have written h ? 1 why is it h ? 1 ? earlier this had a black height of h  what should be the black height of this ? h  1 because there is one black node here already so this will have the black height of h ? 1 similarly this will have black height of h -1  this will have the black height of h -1 and if a node is red then both its children have to be black red node can not have a red child ; it ? s a double red problem the other possibilities c is the left child of b so it ? s a symmetric thing now how are we going to reorganize this tree ? we are going to reorganize this tree in this manner so it ? s basically a rotation  b goes to the top  c goes here  a comes there and these have not labeled these things but you can understand 1  2  3  4 ; 1  2  3  4 in this order will set there we will see in this kind of reorganization when you are taking of avl trees now what does this correspond in the case of a 2-4 tree ? let ? s look at it so what this corresponds to ? this picture is basically that this node was empty that ? s why the height went down in the parent node i have an a and it is red which means the parent node in the 2-4 tree has at least two keys  hindi  this will be always black  hindi  why is this rotation ? student  c is greater than b you are right perhaps  so you are saying a is here  hindi   so it will become a c and b so ignore this one  it ? s for this one  this picture  refer slide time  41  10   now let ? s see what this corresponds to in the case of 2-4 tree because that ? s where all of this motivation is coming from so this is a red node which means its parent is a black so when i had created the 2-4 tree node i would have at least two keys in the 2-4 need tree node corresponding to this guy  at least two  may be three but at least two so that is this one  so it could be either two or three i put the a here now in the 2-4 tree node corresponding to this guy  actually i took this one  so i would have b and i would have c  refer slide time  41  47   so i would have b and c may be there is another key if this guy was red so this is what the picture is and then what do we do in the case of a 2-4 tree ? i have a problem because i don ? t have any key in this node  what do i do ? i borrow from my sibling my sibling can lend me because it has at least two keys so it is going to lend me one so one of the key is going to go up from here to here and one is going to come down from here to here so that ? s exactly what is happening so  hindi  one goes up  let ? s say the b goes up  c remains here when i am looking at b c  so this corresponds to this so let me correct this in a second  refer slide time  43  00   so what we are saying ? suppose we were to keep this one in picture so lets remove this one now and then this should be c and this should be b now it ? s okay so let ? s keep this in mind now what ? s going to happen  we have c and we have b here so which is the one which is going to go up ? c and a is going to come down so in the new node that i get here  i would have only one key a in node that i have here c is not going to be there and in this node a will get replaced by the c in this node a is the only key which means a is black in this node b is one of the key and if there were one other key here either b is only key in this node or if there was one other key here then it is already sitting here  we don ? t have to worry about that so b becomes the black node and this c why should c be a red node because there are more keys here so c can continue to be a red node so this is just for motivation but if you have look at this this is good enough we have taken care of the height problem  this is my new re coloring  this was red  this is also red so they can not be a double red problem why ? because there is a double red problem if the parent is red but the parent is not red if the parent is red then there is a double red but if the parent is red then the parent of this was also red which means there was already a double red problem so there is no double red problem let check the height business so black height is h -1 and now what is the new black height of this sub tree ? so for all these external node it will be h  for all of these also it will be h  for all these will be h  for this it will be h  the black height is h  refer slide time  45  15   what was the black height of this guy ? h  1 + 1  h  1 + 1  h ? 1 + 1 and this was h to begin with  hindi   so the problem is taken care of you have not introduced double red and the black height has been restored what case was that ? so that was very first case let me just show you so it was this one  refer slide time  45  58   so we have to go through this one  refer slide time  46  02   so we quickly now start going through them  refer slide time  39  53   this is when parent is a red node  so this is what is written so parent by parent i mean this is a sub tree whose height is decreased  i am looking at the parent of this root it ? s a red node it has a child which is black then black child has the red child this is what we do so the other thing is when it does not have any red child  b does not have any red child that would be in a second case so let ? s look at that  refer slide time  47  55  so b has no red child in this case the picture is a b and both of this sub tree have as the root black children now this went from the h to h  1 so this has to have a black height of h  1 and this is also have a black height of h -1 why because originally black height of entire tree was h so this must be h  1  this must be h  1 now what are we going to do ? just the re coloring will solve the problem because i make this red and make this black what is the black height of the resulting tree now ? h  which is what the original height was why this was not introduced the double red ? i made this red  no this could be a red that ? s why we have taken care of the other case first if any one of these where red  hindi  and what does this corresponds to for our 2-4 tree picture ? this is the node  hindi   this is the only key in this node sitting all alone and then what do we do ? if this goes up then this guy becomes empty so what do we do then ? merge  these two combine in to one single node and one key comes down from the above so what will the key ? s in the new node be ? b from here  a from here which comes down from the above so this new node is going to have b a in it which is what is being done here  this new node has b a in it this will be one node  i take a black and look at all its red children this will be one node with be a in it so this is one to one corresponding between what we did in the case of 2-4 tree and what we are doing here and that helps to clear things so we are looked at both the cases when this guy  when the parent was the red if then the parent was the red then we know this is a black if this had any red children we have taken care of it in previous case  if this has no red children then we taken care of it now so now we go to the red next set of cases when this parent is a black so parent is a black node  refer slide time  52  54  if parent is a black node then this could be a red or could be a black ? so first considering the case that it has the red child b if this is red then this has to be black and if this is black then this may be red may not be red now again some two condition i am making or some two assumption making of ; this is red first and this is red in the next case i am going to consider this was not red  this was black and this was black this node had no red children and you see why this is required  you already seen one reason why to consider whether node has red child or not so this is a picture this height went down from h to h -1 so what is the black height of this tree ? this entire black height that means was originally h + 1  hindi  first let ? s make sure that this is correct and then we will see why we came up with this and why we came with this is justified by our 2-4 tree so let ? s just check it is correct so first you can see here that b is less than a  b is on the left c c is more than b less than a so c lies between b and a and d is more than b but less than c  so d is more then b and less than c so search property is okay and 1  2  3  4  5 ; 1  2  3  4  5  i just organize as before they just go in a same manner now this one is a this one  it has now black height of h -1 this guy is this  its black height of h  1 and this one is a very first one  its black height of h so now if you look at the black depth of the external node so these guys will have black depth of h + 1 this will have h minus one plus one plus one  h + 1 h -1 + 1 + 1 h -1 + 1 + 1  refer slide time  52  15   so the black depth of all the external nodes are the same so that thing is taken care of and far as a double red problem is concerned the only thing could be that this is red  hindi   it was only a red black tree and it had only made changes in this sub tree so this is a valid thing and in takes care of the problem now where is this coming from ? what is the motivation ? again this was an empty node  this corresponds to an empty node  this is a parent node  this has a and this has red child so it means that two keys a and b and this has one child here which has two keys c and d so that ? s what happening here this corresponds to this node and a b corresponds to parent node and what happens now ? i can  because my sibling has enough keys it will lend me one so one of the key will go up and a would come down which is the key which would go up  the largest one c would go up and a would come down  this is the picture would have b c d a and what is this corresponds to ? this corresponds to exactly this b c here corresponding to this node  a this one and d this one so everything is coming from the 2-4 tree what would you have done in this case ? this is direct one to one correspondence  you just use this thing to decide what to do here so what is the case we considered here that this is black we also considered the case when this parent was the red and then we made the assumption that it has the red child then this has to have the black child and we made the assumption that this is red so now we will get rid of the last assumption that this is red that means this guy has no red child  c has no red child which means both of these are black  refer slide time  54  20   so we come to that key  refer slide time  56  03  c has no red child and so this is the picture so this are two sub tree both of whose two root are black and so this has to have black height of a h -1 because the entire black height was h + 1 to begin with same as before  hindi  and we will see the motivation once again coming from the 2-4 tree though once again c is between b and a so b here  a is larger than b  c is more then b but less then a so binary search tree property is okay and the same t1 t2 t3 t4  hindi  t1 t2 t3 t4  hindi  black height check  hindi  black depth  hindi   double red problem  hindi   these are both black  hindi   where is this coming from once again ? this is the node which is getting empty the parent has a and b in it and then this has one child which has only c in it because both of its children ? s are black so now once again we can not borrow  we have to merge and merge may c  hindi  which corresponds to this  hindi   so c has no red child now what is the case left ? we started assumption that the b is red so now we need to work with assumption that b is black that was assumption b is red so we come to b is black  hindi   this is the node we are talking of  this is black  refer slide time  58  07  so now again the next case that it has a red child and one possibility and the other is it does not have a red child so if it have a red child lets say this is a red  hindi  d is between c and a so d is between c and a  where is it coming from ? this is empty  a does not have any red child which means its only key in its node and this has a red child so that means there are two here so once again it is going to borrow one from here so d is going to go up  a is going to come down and we will have this picture  so d is the only key in its parent  this may or may not be the only key in its node because this could also be a red but we are not bother about this  hindi  but this only be the one key in its node because this node was earlier empty  hindi  c does not have the red child at all a c c no red child  hindi    refer slide time  1  00  00  so now what do we have to do ?  hindi  h -1 + 1h  hindi   i worked with the assumption that this is the sub tree  hindi  black  hindi   what case does this correspond to ? this has only one single key  this neighbor also has only one single key so you kind of combine both of them  they come here and the parents becomes empty so the parents becomes empty so you have to then repeat the process for 2-4 tree deletion in the parent which means it either has to borrow from one of its siblings or it has to merge with one of its sibling and all of that so there was the same kind of thing happening in the case of 2-4 trees there that the process continued up  the deletion process the parent became empty now so you have to do something there and may be then again the parent became empty so you have to do something there and so on and all the way up to the root in which case you reduce the height of the tree at the end of the thing the same thing could be happening here except that here all we are doing is re coloring a node  hindi   essentially one bit of information  hindi   in one of the six cases we have to go up but when we have to go up we don ? t have to do too much work we just have to do one recolor so that ? s the summary so in all cases except the last case 2.2.2  refer slide time  1  01  45  so deletion can be completed by either some reorganizing  by some rotation or by some re coloring  hindi   in this particular case the height of the sub tree reduces and so we need to proceed up the tree but in this case we are only re coloring the node  hindi   so what is happening is why is this is a fast procedure because you have to do essentially one rotation only  hindi   it ? s a very short  so which is what makes the process really fast except for the last case in all case the height preserving  student   hindi   you have to check that  hindi   you have to check this last thing if you have to convince but this is the entire process of deletion next class we are going to look at the process of insertion  it ? s much simpler than this so this was the harder one but keep in mind you don ? t have to remember it  if you remember the 2-4 tree which was much simpler to understand conceptually if you remember that you will also be able to remember this process data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 15 insertion in red black trees in the last class we saw a red black tree  the correspondence of red black trees and 2-4 trees then we saw the deletion process in red black trees this was the extensive process with 6 cases and so on today we are going to see how to insert the key in the red black tree also going to introduce the notion of an a-b tree first we will define the a-b tree and then we are going to see the process of insertion and deletion in a-b tree  refer slide time  01  40  we get to insertion suppose we are trying to insert a key k in to red black tree after all a red black tree is a binary search tree since it is a binary search tree  first the insertion process would be like the binary search tree which means that we would try to find whether the key already exist in the tree if it exists then we would not insert it if it does not then we should be able to identify the place for the key to be inserted we create a node with that key  we put it at that location and we have to color this node because a red black tree differs from a binary search tree in the fact that each node is colored and this coloring obeys certain properties  refer slide time  01  50  now we color this node and we are going to begin by coloring this node red let us say that in the slide given below the red colored node in the left side is the node that i inserted and it has a key k in it which means in my binary search tree i must have come up to the black colored node and gone right  because k was larger then this key and found that this was an external node earlier in the binary search tree this was an external node i decided to put my node to the right side of my black colored node and i color it red i will create 2 external nodes which will be the children of this node if the parent of this node is black then we have no problem because this node is colored red  the black height of the tree has not changed  refer slide time  02  31  the black height of the external nodes of the children is the same as the black height of the external node which was sitting earlier at the location of the key and which was the same as the black height of the other external node in this tree which means that the black height of the 2 external nodes of the children is the same as the black height of the all the other external nodes that property of the red black tree continues to hold  that is primarily because we have introduced a red node and not a black node the property that the black height of all the external nodes should be the same and it continues to hold the problem could how ever be the double red colored node and that happens if the parent of the red colored node in the left side is red as it is shown in the right side of the above slide the red colored node with key k inside it at the right side of the slide is the node i created if its parent is red then we have the double red problem and we have to handle this problem remember that in the case of deletion the problem was arising because the black height was changing and all along we were trying to take care of that problem we never encountered a double red problem in the case of deletion in the case of insertion how ever we will never have the problem of black heights not being uniform the black heights of all the external nodes will be the same no problem on that front but the problem will be one of a double red we have a double red problem let us see how to take care of this problem just concentrate on the left picture in the slide below the k is the node that i am inserting and in the previous picture i had shown the 2 children who are external nodes and now i am just replace that by sub trees you will see the reason for this in a short while  refer slide time  04  54  we would have a double red problem if the parent of the node that we inserted is red this parent which is node a is colored red clearly the parent of the node a must be a black if the parent of this node was red then there was already a double red problem in my tree so the node b must be a black and the first case that i am considering is when its other child is black which means that the sibling the k is the node that i am inserting  the sibling of its parent node a is black that is the case i am considering we just do a simple rotation note that a is larger then b and a is smaller then k so i can put a in the middle  b on the left and k on the right i get a kind of a tree which is on the right side in the slide above the a will be colored black  b and k would be colored red what is the black height of the tree on the left ? the black height of the tree on the left is same as the black height of the tree on the right if you take any external node then its black height was the black height of the external node plus one and for the external nodes on the right  its height is still the same as the black height of those external nodes plus one  refer slide time  07  48  would the black height of all of the nodes be the same ? the black height of all the external nodes is indicated in the slide above you can see that the black depth of all the external nodes anything below the node k will be  h + 1  + 1  on the node a  which will be h + 2 and below the node c will be h + 1  on the node c  + 1  on the node b  which is h + 2 so the black height problem not there at all  it is uniform only thing we have to worry about this transformation is whether we have introduced a new double red problem  and we have not we would have introduced a new double red problem if the root of any one of these 3 sub tree under node a and k was red but if the root any one of these 3 sub tree was red then that means we had 2 double red problems and not 1 double red problem if the external node under the node a was red and also the node a was red  then it is a double red problem if the external node under k was red and also the node k was red  then it is a double red problem we have more then one double red problem but we have introduced only one double red problem by inserting that node  so this can not happen in this case we are inserting k and for now we assume that the nodes under the node k are external nodes in the next slide i will come to why i have drawn this 2 sub trees if i were to think of this as a 2-4 tree then that means that i have a node which has these 3 keys  a  b and k  in it earlier it had keys b and a in it  c was another node and k can be accommodated with b and a without any problem  refer slide time  09  56  this is what we said but we are getting a double red problem why is that ? it is because this  b  a  k  is not formed in a right manner if i had 3 keys in a 2-4 node then the middle key is the one which is to be set black  while it is not getting done in the left side tree on the above slide just that simple rotation takes care of this so it is not that we are changing the 2-4 trees in the any manner this  a  b  k in the left side  is the node corresponding to the 2-4 tree and these 3 goes together in to one 2-4 tree these 3 nodes  b  a  k in the right side  still go together in the node of the 2-4 tree as before it is just that we are reorganizing it  so that it is now in the form of our red black tree so that was one case when the parent of the inserted node  has the sibling which is black so the other cases when c is red and we will look at that now so this is the second case  the parent of the inserted node  a  is red and the other child of b is also red we have this double red problem and we need to take care of this what should i do now ? can i do which i did on the previous slide ? why not ? because then i would get a double red problem on the other side if i look at what is happening in the 2-4 tree that means in the 2-4 tree this  c  b  a  is the corresponding node of the 2-4 tree recall how i get the node of 2-4 trees  i take a black and look at all of its red children so the nodes which are marked in the below slide is the corresponding node it already has c  b and a in it and i am trying to bring in k in to this where clearly there is no space  refer slide time  11  48  so we split it into 2 that is what we are going to see in the following slide  refer slide time  12  26  this is what the transformation we are going to do no transformation but we just recolor the nodes and this corresponds to split and let us see why it happens the left side tree in the above slide is the transformation that i have done i have colored the node a and c to black in the above picture  c  b  a  was sitting in one node and k is trying to come in how do we split ? we split with c on one side ; a  k on the other side and then b goes up since c on one side that corresponds to a single black node  a and k on the other side corresponds to a and k on the right side of the tree and b goes up  so this is now trying to go up to the parent does this take care of all problems ? there are 2 issues first have we created a black height problem ? no  so let us say what should be the initial black height of all these sub trees ?  refer slide time  14  37  if the node below k is h  then all the black height of these entire sub trees which is on the left side would be h + 1 this means the external nodes on the right side are all h and now the black height of these entire sub trees is h + 1 so no problem  it was as before but i have a red node b and its parent could have been a red thus i have a double red problem and this is the same thing we have managed to move the double red problem one level up and now you see why i had these sub trees hanging out of here when this moves one level up  the rounded part in the above slide will be one sub tree hanging from the node b and the one which is marked on the right side would be the other sub tree hanging from here this is the continuation  the parent of b could also be red and that case the double red problem moves up one level  refer slide time  14  53  we will repeat this process at the next level  we will consider the 2 cases if we can by rotation take care of it we would have done it  if not then the double red problem will move even one level up and so on eventually we will end up coloring the root which was originally black as it was in a red black tree we will end up coloring it red but if the root is colored red everything else is okay that is the root is colored red how do i take care of it ? just color it black again and that will increase the black depth of all the external nodes by one but it remains the same we are not saying that the black depth of the all the external nodes should remain the same  we just say it should remain uniform the black depth of the one external node and the other external should be the same if i color the root black  it will just affect all the external nodes by one so there will be no problem this essentially corresponds to moving all the way up and splitting the root when we split the root in the case of a 2-4 tree  even then the height of 2-4 tree went up by one and so we are seeing that the height of the red black tree is correspondingly increasing by one when we do such thing so again what we have seen in this insertion process is that either we have to do one rotation to take care of the problem and if we could not take care of the problem by one rotation then we have to move the problem up to the next level  refer slide time  16  31  but when we move the problem up to the next level we just did a recoloring of the nodes lets see  when we move the problem up to the next level in this case all i did was  change the reds to black and change the black to red and now it is moved up to the next high level and may be if it has to moved up to further higher level it will just corresponds to recoloring of nodes  refer slide time  18  59  suppose in the above slide  the parent of the red colored node b was red  then the other child of this has to be black  it can not be red clearly other wise there was already a double red problem but it is not that the one we are worried about its basically the node on the extreme right which we are worried about  whether it is red or black if we look at the previous case  we looked at the parent nodes sibling whether it is red or black so it is the extreme right node whose color we are worried about and still this node can be red or black so in insertion we just have to do one rotation if we move up the tree  we just have to do recoloring the same was happening in the case of deletion also and i had mentioned this very clearly that if we move up  we just had to do some recoloring the moment you do one rotation the process ends  other wise it just does recoloring this is what it makes the process very fast because recoloring is just one bit of information really in each node the 1 or 0 will just tell you whether it is red or black you just need to quickly change those bits if you are moving up the tree rotation is slightly more expensive because it requires some pointer changes  6 or 7 pointers have to be changed and this is why the insertion and deletion in red black tree is faster than in the case of avl trees in avl trees recall that we have to do more then one rotation we did a rotation then we moved up  perhaps you have to do another rotation and so on although for both of the data structures  the worst case time for insertion and deletion is log n because even there you were doing only log n rotations  but the constant behind that log n are much larger in the case of avl tree than in the case of the red black tree so even with in the log n  this would be a faster process for both insertion and deletion than in the case of an avl tree  refer slide time  16  31  that is all we wanted to discuss about the red black trees we looked at search  insert and delete all of them take log n time  you can also think of other operation like if i say find the minimum element in a red black tree how much time do you think its going to take ? minimum means just keep going left so time is height  height is log n then its just log n you can do all such kind of operations in log n time most of those operations are not changing the tree it is much easier  the 2 operations where we changed the tree are insert and delete but we seen that you can still take care of them in log n time  refer slide time  23  49  we will come to this notion of a-b trees and this is a generalized idea of 2-4 trees what is an a-b tree ? i have drawn an a-b tree and actually this is the same picture that i used for the 2-4 trees if you remember an a-b tree is a multi-way search tree each node has at least a and at most b children when a is 2 and b is 4 then you get 2-4 tree if it has at least a children and at most b children then how many keys are there inside ? a-1 to b-1 what do you mean by b-a + 1 ? if it has a children then it has a-1 keys  if it has b children then it has b-1 keys so the number of keys is between a-1 and b-1 the one node which does not satisfy this property is the root node the root node can have only 2 children if a is 3 or 7 or some other thing then its not that the root also should have at least 3 or 7 children root is out of this definition  so root can have only 2 children root has at least 2 and at most b children for the root the requirement is from 2 to b and we will see what is the need for this requirement again all leaf nodes are at the same level what is the height of an a-b tree ? we have seen this before  is the minimum height and is the maximum height you can context this to the little bit because the root has the only 2 children when the root has 2 children every one else has a children  so there would be a plus one in that  refer slide time  24  15   but this    would be the roughly the bounds as you can see in the above slide  every node has at least 2 and at most 3 children  so this is an example of 2-3 tree we can talk of 2-3 tree  2-4 tree  2-5 trees and so on  for any choice of a and b i will correct the statement as this discussion proceeds it is not any choice of a and b  we will see what are our requirements on the relation between a and b this will not work on any choice of a and b  but for now we will just assume it as any choice of a and b  refer slide time  25  04  in insertion so as you can imagine this is going to be essentially a repetition of what we did for 2-4 trees and it is with small modifications i am trying to insert the key 21 as it is a multi way search tree  i will find a position where this has to go the 21 does not go between 13 and 22 so come down it is more then 18 so go right and it can fit in to that position next to 20 no problem if the node has an empty space similarly for 23  as it is less than 25 it comes to this space and in a node we are just keeping in order so 24 will make way and 23 will come at the place if there is no space in the node that we are trying to put the key in  then the node gets split let us see 29  29 compared with 22 and it is more than 22 so it goes right  more than 25 and again goes right i am looking at the 2-3 tree in this picture we are talking of a-b but i did not want to make a and b very large because it would not fit on the slide so i am just looking at a = 2 and b = 3 and the concepts are the same for an a-b tree all the leaves have to be at the same height as in the case of 2-4 tree this is essentially 2-3 tree basically 2-3 tree means each node has between 2 and 3 children which means that each node can have 1 key or 2 keys only which is why each of those has been made with space for 2 keys each could have 1key or 2 keys this can have only 2 keys but now i am coming with another one that is the third one if there is insufficient space then split the node i am going to split this node and the median key is promoted to the parent thus 28 is the median of these 3  so 28 will get promoted to the parent  refer slide time  27  54  so i split 26 goes down 29 goes down and 28 goes up and the lines disappear and these become the children of this the split can cascade and we will see the example of that when i am trying to insert 7 i will compare 7 with the first key the 7 is less than 13 so i will go left  7 lies between 3 and 8 so i take the middle path  come down and 7 tries to come to this node except this node does not have enough space  refer slide time  27  54  this node gets split in to 2 the 4 will go down  7 will go to the adjacent node and median is 5 so it will go up as nothing is left here because we just remove this node and we will remove it shortly  refer slide time  28  51  this 5 is trying to go in to this  3  8  node  except there is no space here either and once again this gets split in to 2 the 3 goes to the upper node and 8 to the adjacent node and the median 5 get promoted to the parent it is same as in the red black tree  we have not done anything which is different from the red black tree but what i am pointing out through this is that we need not have a 2-4 tree  we could also have 2-3 tree in the red black tree every node had space for 3 keys  even if every node had space for 2 keys we can still make it work that is what happens  3 and 8 get splitted and 5 goes to the top once again 5 is trying to enter here  but there is no space for 5 first let us just reorganize this these 4 children have to be children of these 2 nodes  3 and 8   the 2 left will go to the left of 3 and 2 right would go to its right let us take care of this node  5   the 5 try to go between 13 and 22  but not able to go so this gets split in to 2 and 1 key gets promoted to the parent except there is no parent this is the root so we create a new root and we would go like that  refer slide time  30  00  these are the 4 children  3  8  18  25 28  they would have to become children of this two nodes  5 and 22   so 2 left most go to this  5  and 2 right most will go to this  22  and the new root  13  will have to this 2 children  5 and 22    refer slide time  35  47  exactly the same thing would happen for any a-b tree i am trying to insert  if there is space put it there  if there is no space split and move the median up the median might not be unique like in the case of the 2-4 tree  there were 4 keys there the median could be the second element or third element we can not insert in to an empty node what is this statement ? there would be no empty node at least a children  at most b children mean every node has at least a-1keys and at most b-1keys so this is the property we can also rephrase it in this way every node has at least a-1keys and at most b-1keys if your tree had less than a-1keys in it  then all of them would basically sit in the root this property is not true for the root  root can have as small as 1 key only because it can have as small as 2 children so root can have only 1key we are saying every node has at least a children and at most b children which mean that every node has at least a-1keys and at most b-1keys this property of at least a children and at most b children does not apply to the root node the root node has at least 2 and at most b the root node has at least 1key and at most b-1keys why we said that this property does not apply to the root  because when we went in this manner and inserted and we ended up splitting the root node in to 2 and we created the new root node then this new root has only 2 children we have to permit the root to have only 2 children this is why this requirement  the root can have as small as 2 children if we insist the root have to have at least a children then we might not be able to do this at all we are going back from 2-3 trees to a-b trees so in a-b trees we said  we are trying to insert in a node if it has space  we put it there how much space does an a-b tree node have ? space for b-1keys  if it has space we will put it if it does not have space  what is that mean ? they were already b-1keys there and i am trying to insert one more key  key then we will split in to 2  one of the keys will go up and from the remaining b-1keys  half will go on one side and half will go on other side that is exactly what is being said here a node is split when it has exactly b keys why exactly b ? because earlier it had b-1  i was trying to put in one more there  then it means it has exactly b one of these is promoted to the parent and the remaining are split in to 2 what is the remaining ? b-1  the b-1is getting split in to 2 one part gets and the other part gets  the  if it is an integer then both of these are the same if it is not an integer  like in the case of a 2-4 tree the b is 4 in the case of a 2-4 tree you had which is 1.5  which means one side was getting 2 keys and the other side was getting 1 key thus 1.5 rounded up is 2 and 1.5 rounded down is 1 one was getting 2 and the other 1 so one node gets this many keys and the other gets this many keys but after the split  these 2 nodes are valid nodes of the key so one node is getting so many keys which means that a-1this quantity should be less then or equal to   refer slide time  36  16  i have corrected in the above slide which is given below a-1 < = why this is coming  because i am creating a node with keys which means i have a requirement that every node has at least a-1keys in it this quantity should be greater than or equal to a-1 otherwise if this was less than a-1  then there would be a problem because this node that i am creating is not a valid node let us look at the deletion deletion again is the same as the case of a 2-4tree the simple case is when i am deleting a certain node and there are more than one node in that for instance if i were deleting 12 and there is nothing to be done  just delete 12 and still there is one key left suppose if i was deleting 20  then the problem would be that when i am removing 20  this node becomes empty and node has to have at least 1key and at most 2 keys so it has to have at least one if the node becomes empty then i first try to borrow a key from its sibling the sibling of 20 is 14 and 15 i will try to borrow one from that and recall the way we borrowed was one key went up and the other one came down that is exactly 20 disappears and 15 goes up and 18 comes down this is valid 2-3 tree what happens if the sibling has only one key ? for instance if i was trying to delete 23  23 goes away i try to borrow one key from its sibling  26 is the only sibling i can borrow from i can not borrow from the next one and you remember the reason for this i am trying to borrow it from 26 but this has only 1key if i borrow from 26  this becomes empty in this case of a 2-4 tree we merge first try to borrow if not possible then merge  refer slide time  38  33  we will merge this and we will create a new node and this will get the key 26 and one key will come down from the parent the 24 will come down and 26 will come from here and this will become the merge node thus only one key left there  so it goes to the left and these become the 2 children of this node we also saw that this process could go up and up because what we had effectively done is that we have removed one key from this 28th node but if this node had only one key then it would have become empty if this 28 was not there then this would have become empty then we would have tried to borrow one from 18  but we can not borrow because there is only one key this 18 would have merged which means this 22 would have come down and we would have created one node with 18 and 22 which means i would have deleted something from 22 but if i am deleting something from here this becomes empty so again it will merge and in this manner eventually the root has to be removed and the height of the tree reduces by one we have seen this example from the case of the 2-4 tree  exactly the same thing is happening let us continue in an a-b tree we will merge a node with its sibling now we are coming back to the a-b tree when do i merge a node with its sibling ?  refer slide time  45  36  the minimum number of keys in a node is a-1  which means it had a-2 keys i am trying to borrow one from its sibling but i am merging with the sibling which means that even the sibling does not have anything to lend me which means how much does the sibling have ? the minimum number a-1 if i am merging the node with the sibling then that means the sibling has a-1keys and the node itself has a-2keys after merging the new node that gets created  how many key will it have ? the sum of these two  a-2 and a-1  plus one why plus one ? it will have 2a-1keys now 2  a = 1  better be less than b-1 this is the same as saying that a-1 is better be less than  why have i set flow ? the a-1has to be an integer as and since a-1 is an integer it has to be less than or equal to the floor of  floor means rounded down this symbol means  if this is not an integer round it down to the nearest integer this   is the property that your a and b should satisfied let us just quickly see what this just means given the particular value of a  what are the different values b can take ? you just have to look at this  2  a-1  < = b-1  again so b can take a value 2a-1 or more the b should be greater than or equal to 2a-1 when a was 2  what are the values b can take ? 3  4 and so on that is the thing that we need to keep in mind if we have a as 5  then b have to be at least 9 so you can not have a  5  7  tree  this will not work where  5  9  tree is okay  refer slide time  45  36  we will see a quick summary for insertion and deletion  we saw insertion and deletion in a-b trees the height of an a-b tree we saw is log n and so insertion and deletion both take order log n time the reason for that is the same as in the case of a 2-4 tree the reason why the insertion and deletion was taking log n time in 2-4 tree was the height was log n and we might have done some number of operations but we were doing the operation proportional to the height we might move up all the way  so first we move down in the case of insertion and deletion so that height is order log n then sometimes you are borrowing in the case of insertion  sometimes splitting  but the number of times you have to split is at most the height in the case of deletion we would either borrow the key or we would merge or again the number of times we would have to do this is proportional to the height because every time we did one of these operation  we moved one level up or we just stop the entire process so both of these operation take order log n time the other thing we saw was  what should be the relation between a and b for this to work that is as far as this a-b tree was concern the other thing we did today was red black tree and for that we saw the process of insertion we saw that it takes only some number of re coloring and one rotation to complete an insertion that is the key thing about the red black tree  they only require one rotation some number of re coloring or might have to re color many nodes but only one rotation is required and this is what gives the power this is what makes them very fast in practice and they are faster then avl trees for this reason so the next class we are going to see the particular kind of the a-b tree which is called b-tree and what role does it plays specially in searching very large databases that is what we are going to do in the next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 16 disk based data structures so today we are going to be talking about disk based data structures in last class we looked at ab trees  refer slide time  01  17  so these were the extension of the 2-4 trees that we had seen today we are going to look at disk based data structure and in particular we are going to look at b trees and we will see that they are very similar  they are in fact ab trees for specific value of b so now we are looking at is when we have a large amount of data over which to search till now all our search trees were limited to main memory  in the sense you build a binary search tree or build a 2-4 tree or a red black tree so we had this nodes which where objects in memory and you know the references corresponds to pointer addresses or memory addresses now we are looking at the setting where we have the huge amount data let ? s say some kind of transaction data which could be bank share markets  you know setting we are large amount of data get generate and such huge amount of data is not stored in the main memory of computer this is typically stored on disk and now you want to be able to search through this data or insert something in to this data or modify this data how do you do that ? so you just imagine the setting where you have let ? s say particular bank which has records of each of its customers so they could be a million customers each of those records would be huge the data should set in the each account should be huge because it would have all the transaction data associated with what has been history of transaction and so on you can ? t expect all of that data to decide in the main memory of the computer so it would be kept on disk and now suppose type in particular account number you should be able to retrieve that particular account and the data associated with that account so question is how are going to do this ? so we want to make a search tree which is some sense secondary storage in avl tree which will help you even when the data most of the data is stored on disk will still be able to search through it now the problem here is that the data is stored on disk that ? s fine but even the index that we are building so what do you mean by index ? the search tree  search that we have so huge that we can not expect the entire search tree to fit in to the main memory we will come to this in to the short while so what ? s the problem in you have think on the disk verses when thinks are the main memory of the computer  refer slide time 04  01  one big problem is that disk access is very slow how is disk accessed ? you have let ? s say this is the disk  so you typically have bunch of disk in stack one and top of each other each one of them has its own read write head  head which will traverse which can move along this disk and get to a particular track so these are the track on the disk the disk rotates in one particular direction and these read write head can decide that it wants to go on this track or this track or this track and so on when you have to read a particular location so a track is further divided in to sectors so when you have to read a particular sector  the disk rotates and this read write head gets to the appropriate tag and then starts reading the data from there so significant fraction of the time is spent in this read write head moving determining which track it has go to and moving and the rotation so one of this is called seek latency  so this that time that is required for the head to get to the appropriate tag its called seek latency and the other one is called rotation latency the time required for the disk to rotate so that the head is positioned at the right place  the right sector and once you have write at the right place then the entire sector is typically read so one sector or let ? s say one let ? s call it as page so the data then is read in units in larger units you don ? t read one byte of data from the disk why don ? t you read one byte of data from the disk ? because you already spend so much in getting to that one byte then might it is well read whole lot of bytes so you typically read or write in units called pages which are you know it could depend upon the particular computer system but it could be in this range 2 to 16 kilo bytes so you read this much amount so this could be one page setting here and you read this much amount of data and it will be moved in to the main memory this is reading  when you writing similarly you would write back and entire page what are the problems associated with this ? we have to organize our search tree in such a manner that first it can sit suitably on this disk as i said or search structure itself is going to be so large that it can not fit in to the main memory and that ? s what we are going to do in next slides so when you have the disk based algorithm like this  the running time is going to be measured in terms of the time taken by the cpu and the number of disk access  refer slide time 07  11  now this time  the time taken by the cpu is insignificant compared to the number of disk access in the time spend in each disk access so what you would do in most of these algorithm is to organize the data in such a manner that there is a number of times you have to access the disk is very small and what i have said is you know till now we had seen the algorithm which are called main memory algorithm where the entire data sets in the main memory so they can not be easily ported to this module when part of the data sit on the disk  it can not be ported in the straight forward way what are the problems that are going to happen now that we have data setting on the disk ? so one is as for as this pointer business is concern pointer is to same as references to objects so till now we had reference to an object  we knew that correspondence to the address in the main memory so you would go and access that location in the main memory now if part of your data structure is sitting on the disk  so just imagine that your red black tree or whatever it was  part of it was in the main memory and part it was sitting on the disk one of those pointer  one of those references is referring to a location on the disk now so if it is referring to something in the main memory then you can go and get it at that particular memory location but if it is referring to something on the disk then you will have to do something lets use the operation disk read to read the particular data from the disk and disk write to write bind of the disk we have to use such kind of operation to be able to access the data  i will come to what key means in a short while  refer slide time 09  15  so one big problem is that you know the pointer now have to be translated suitably if the pointer is just pointing to a memory location then it is easy  you just get to the memory location and do your job but if its not pointing to a memory location  if it is referring to something that sits in to the disk then we have to first fetch that block of data  that page of data from the disk in to the main memory and then you can access that particular object so typical pattern would look like something  refer slide time 10  01  so x is the pointer to some object so you would read this object from the disk you will do some operation on this object and then you will eventually write it back and you might omit this step if you did not modify the object at all so we are going work with two operation today  disk read and disk write  reading a block from disk and writing block back to disk so now let ? s come to what a  b tree is  refer slide time 10  32  b tree is a same as your ab tree here i have drawn an example where in this ab tree each node has 1000 keys so you value of a here is at least thousand lets say is a 1000 so recall in an ab tree  each node has at least a children and at most b children so here i have taken my value of a as 1001 so each node has at least 1001 children so here i have just tried to illustrate why is this data structure now useful for disk based access so you have this first node which has 1001 children right and since it has 1001 children how many keys would it have inside it ? 1000 keys and just i have organize it very uniformly so that then this each of this each node has also 1000 children and then further more these leaves so its just two level trees these leaves also have 1000 keys in them so how many keys are there in all in this ? so that ? s a 1000 plus million plus a billion so there will be so many keys in this entire two levels structure so let ? s say i had a data base with so many records  so many different accounts so i could put those of this each of this accounts  records you know lets say the key just the account number so i could put all of those keys in to this kind of a structure now each node had contain 1000 keys now this entire structure can not fit in to main memory  you can see this is already 10 to the 9 keys write which each of this keys there is associated with the pointer each of the key itself could be let ? s say 4 bytes of memory  so 4 bytes of memory let ? s say 4 bytes of pointers is about 8 bytes per key so that ? s 8 bytes times a billion that ? s 8 giga bytes so you need that kind of space just to keep this data structure in to a main memory and here we have not said anything about the data associated with this records each of those data themselves could be 100 mega bytes because my account has listed with all transaction that have been done on the that account lets say the last three years or four years or some such thing that ? s huge amount of data that ? s lets says stored on the disk we are not even bringing that in to the main memory but what i am pointing out first is even if the actual data was stored on the disk just to be able to access the data  just using keys and pointers is so huge that you can not have all of it in to the main memory now why is this kind of structure useful ? we are talking about this base  so what we are going to have now is that we are going to have this structure this called b tree this structure itself would be kept on the disk  so each of these nodes would now be one page on that disk and it is just this very top node  the root node which will be kept in the main memory yes  now what happens if you have to search  what would you do ? you will determine which of this 1000 keys between which two keys your particular key lies in suppose it lies so and then go to the appropriate child node suppose this is a child we have to go to  now what will you do ? you will access this node from the disk and bring it in to memory from here you will determine key which should be your next node suppose it is this node so you will access this node from disk and bring it in to main memory and from here you will be able to find your account number and then you will have to follow the account data  let ? s see so how many disk access would you need ? one to get this  one to get this and one to may be get the actual data associated the information associated with that particular record that you are trying to access so how much disk access  how many disk access do you need ? height of the tree so to reduce the height of the tree what do you want ? so you want as little height as possible for the tree  yes so how can you reduce the height of the tree ? increase the value of a  increase your whatever the number of children each of this nodes have  refer slide time 15  50  but what is limiting you from number of children each of this nodes and page size ? instead of 1000 why didn ? t i put in 10000 key here or 100000 keys in here ? that would have been even better  that would reduce the height even further if i had  that would reduce the height even further but i can even put too many because each of those keys is taking certain amount of space and i can only put as many keys as can fit in to one page and what is the page ? page is a unit of transfer between the disk and the main memory so that is define for the particular computer system  hindi conversation   so depending upon if each of your keys comma pointer per taking let ? s say 8 bytes  your page size is 16 kilo bytes each of key comma pointer pair is taking 8 bytes that you can put at most 2000 keys in to one page and so that determine  hindi conversation   so this is just read writing what the node ? so x is now referring to an particular node so what does the node x have ? n  x  is the number of keys in that node and then once again the first key is going to be less then the second key is going to be less than the  so key one of the node is less than the key two of the node and so and on  refer slide time 17  08  so there are n of x keys and they will have lets say methods or particular bit in a node which specify whether the node is a leaf node or not whether it is has any further children  so leaf if this is true then that means leaf node other wise not and if its not a leaf node it ? s a internal node then we will have  if there are n of x keys then will have n of x + 1 children of that node and this we all know we have seen this before if k sub i is in z key in the sub tree c sub i in the case of i is less than the ith key in the node and so on so it ? s the same  refer slide time 18  05  so b tree is the essentially same structure as you ab tree now only difference is so for as ab tree we say we provided a lower bound on the value of b  we said b is should be at least 2a-1 what are we saying today we want that b should be ? so if a node has degree t so t is the same as that we had talked off all nodes except the root had between t and 2 t so this so we want that b  so today we want basically this is out bound for b so we were working with b equals two times a exactly so b tree is essentially special kind of ab tree with ab with bb exactly two times a so each node has between t and 2 t children and so it has at least  it may be between t -1 and 2 t minus one keys so the other way in which b tree differs from a  ab tree is while ab tree is meant to be a data structure meant for an internal memory  b tree is a data structure meant for secondary storage so you really have to choose large value of b so that height of the tree is smallest possible and the entire node  all the key is in the node can fit in to one page and the same as before the root node has between 0 and 2 t children actually i have said zero but you know  it need not be zero it could be 2 between 2 and 2t children  let ? s make it 2 and 2 t  refer slide time 20  08  so the root node in this example has exactly two children and then this is t -1 keys and let ? s say t children so this is the setting in which the height of the tree is as large as possible because each of the node has only t children so if this is all just making sure that you remember things from the previous classes there are one node here  two nodes here  2 t nodes here and so on so this is goes up to height h  you can compute you know this would be the total number of nodes that would had and since n is equal to this that will give you the height of the tree as this quantity so i will just show you some pseudo code also for searching so that you know that these things are completely clear in your head  refer slide time 20  53  suppose i am searching for key k in a node x so this will be a recursive search procedure what am i going to do ? i am going to first find out the key what should i do ? i first have to find out the key  the first key which is larger than k  the keys are arranging let ? s say increasing order in a node so you have to find a first key which is larger the k so that ? s what i do here  i keep moving till i find a key which is larger than k then i come out so if i found a key which is larger than k let ? s say that will give me the ith key so if i found exactly the key i was searching for then i return if the node that i am in was leaf node that i can ? t procedure any further then i return else either then the key is not there else i fetch the next node i fetch the next node and i continue my search in the next node what you have to do here ? you were searching  this is let ? s say ci  x   we have to know excess the particular node so ci  x  is just the reference to the child node  the appropriate child node  you just have to access that i am going to skip this  refer slide time 22  54  so splitting nodes the same idea is before when you split nodes ? when they are full so how many keys can sit in a node ? we said 2t  2t-1 it can have 2t children so it can have 2t -1 keys so if it has 2 t  1 keys and new key if we are trying to insert a new key then we split the node and what was the process of splitting  if this is the node that i am splitting let say t q value is 4 so this already has seven keys if i am trying to put one more here then i need to split it so s goes up and this gets split in to these so i have put down the code here  you can have a look at this slides separately to understand this code i am not going to spend too much time during it here  refer slide time 23  38  it ? s very straight forward what you have to do  this is a procedure for splitting a node y whose parent is x and this is lets say the ith child of this parent so i refers to that and what you do  you create a new node z and then first you copy the appropriate number of keys t  1 keys from y to z that ? s what being done here and then you also  if this is not a leaf node then you will copy the children also from y to z that ? s being done here and then coping that here you are moving so this has to be promoted up here which means that these keys in here have to be moved one step right in the array that ? s what is being done here and then this key that is to be moved up copied in to the appropriate place there and then we have these three describe operation because we have modified this node and this node and the new node we created so they all have to be return back to disk  so that is being done here so the same thing is before the only catch today is that we are doing this disk operation also  you can look at this slides and understand the code so how much time does it take for ? so now today we are going to be measuring running time in terms of the number of disk access that we have to do so in doing the split the number of disk access we have to do was three because we did three input outputs at the end  refer slide time 25  37  the cpu time which will now be proportional to the number of keys in that node because we have to moves certain keys and so on is going to be fairly small compared to this so we will actually be counting time in terms of the number of disk access so today one variant of binary of b trees also works with  so if you recall inserting when you did inserting in two four trees or in ab trees  we went down the tree  found out the place where we have to insert the element then try to put the element there and if that resulted in the node getting split  we split that node and that may have to insert the key in the parent node and that could lead to another split and so on and on there is another way of doing this thing which is that we start from the top so that is called the two parse operation where in first you come down and then you go up the tree one possibility is to do the entire thing is only one pass  what is that mean ? that is as you are starting from the top you check to see if the node that you are looking at already has its full quota of keys what is the full quota ? 2 t -1  if it ? s already has 2 t  1 keys then you are going to split that node right there and then and only then proceed down the tree  does everyone follow so we are going to start from the root and we are going to recursively travel all the way up to the leaf but before we descend to a lower level we make sure that the node contains strictly less than 2 t  1 keys if it has 2 t  1 keys then we split the node right there let ? s understand this  refer slide time 27  33  so i will come back to the slide later  let ? s say this was my root node i am not yet inserted the key  this was the very first root node that i already counted this is already fill up i am working with t = 4 so this has 2t-1  7 keys in it this is already full  so before descending down i see this is already full  i write at this step split this node in to a d f l n p and h moves up and now i will continue down the tree whatever key i am trying to insert i will now continue so let me see  lets show you an example i will skip this slide and come back to this later so let ? s take an example and then i will look at the code again so suppose this is the tree  i am trying to t is the value of three i am trying to insert b so first i come here this node is not full  t is three so it node is full when it has five keys in it  refer slide time 28  33  this is not yet full  so i can come down and b is inserted at this place suppose i am trying to insert q so once again i come to this node this is not yet full  so i go down so actually this should b here i come here this is not yet full i come down here and then i put q here but this is full already so which means it will call this is split so q r s would go on one side u v on the other and t gets promoted here note the very interesting thing why did this node not get split ? what we had seen in the two four trees or ab trees what was happening was that when i inserted an element in to the parent  the parent could also gets split and that ? s not going to happen here anymore why ? because i came down from the parent only when the parent had room in it  if the parent had room then when i came down and i split this node and i put the one key in to the parent  the parent is now not going to get split let ? s with this happening again  so now when i am trying to insert the next key lets say l so now when i come to the root node  i will straight away split this because this already full  doesn ? t matter where l is going l is you know l m n o m l m n  it will come here this node is not full so but i am then i am trying to insert l i will right away split in to g m t x p and then come and insert l so now let ? s say when i try to insert f  i come here this is not full so i can continue this is not full so i can continue then i come here insert it here  split it and one guy gets promoted here so the fact that this is not full lets me accommodate this addition key here without crossing ripple effect in the splitting process  refer slide time 31  11  so in some this is like a one pass  you know in just one way down we have kind of access all the nodes in just single pass we have access to all the nodes of the tree and whatever splitting then it will be done so how many disk i was required ? basically it just move down the tree once  we have to access every node and then every time you split the node  you have to right down that down back to the disk its parent node back to the disk and one new node that you create back to the disk so for every time you split you might have to write down three nodes back to the disk so you will have to read as many nodes as the height of the tree and how many nodes will you have to write back ? you will have to write back at most three times the number of splits that many nodes you will have to write back to the disk  student conversation-refer slide time  32  28   so towards the end i will discuss what are potential disadvantages of doing in this way if you keep splitting because you will have to now see what i am going to do when i have to delete a key there i will try and let ? s see what i try and do that and then it will be clear so when i am doing deletion  some going to actually skip the code i showed you  so you can look at those slides and understand them on your own  refer slide time 32  50  as far as deleting key is concern once again we recall the earlier procedure  we went down the tree we deleted the key  when we deleted the key that node could have less number of keys than it was supposed to have in which case we first try to borrow  if not successful merge if we merge we have to remove one key from the parent that could cause the ripple effect  the cascading effect so that we ended up doing all the way up to the top now we are again trying to do the single pass delete procedure which means that we just going to down from the top and do the deletes so now what we are going to do is if we encounter a node which has already the minimum number of keys what is the minimum of keys in a node ? t -1  if it just t -1 keys then we are going to make a effort to let it have more than t -1 keys strictly more  at least t so what are we going to try the same thing as before ? first we try to borrow from a sibling  if we are successful with that great if not then that means the sibling also has t  1 then we merge and when we merge we bring one from above and why can we now successfully bring one from above because the upper has strictly more than t ? 1 so you can do the entire thing in a single pass in exactly this manner so that ? s what we being said here before descending to lower level in the tree make sure that the node contains at least t keys in the case of insertion we require it contains strictly less than 2 t  1 keys now we say it contain strictly more than t keys suppose this is the situation so we are once again working with the t equals three  t equals three means each node has to have at least two keys so this node it ? s okay  there is no problem with this node why because it has three keys so i can continue down i can continue down i come to this node and f is deleted from here and there is no problem but if i was trying to delete something from here then when i encounter this node which has only two key the minimum number then i will try to do something write then and there before proceeding down so you know i have actually put down all the cases here where you know the key that we are trying to delete not in the leaf then you have to do all of the snaps so you seen all of these before so lets skip see some of this and this was the case when we have to merge so sorry just once again let me make sure what right  refer slide time 36  12  so if this is the setting if the particular node has only 2  1 keys then we have take action to ensure that it has at least t keys before we continue down and first thing is that we can borrow from the sibling and if not then we merge so this is the picture  refer slide time 36  43  let ? s look at this one  we trying to delete b we come here there is no problem here and when i am trying to delete here i have borrowed one from the sibling  you may have seen many example of this by now so how do you borrow  one goes up and one comes down so this is the situation happening here and if we can not borrow then you merge same as before you are deleting d so you come here c l when you are deleting d this is already has problem because it has minimum number of nodes so you going trying borrow one from the sibling but you are not going to be successful in borrowing one because that also has minimum so you merge and you get c l p t x bringing one down and then you go head and you delete d from here so this is the situation that ? s going to happen then this also illustrates why this is the bads key  who can tell me why so this is answering the question that he had raised ? why did we do the same thing for the red black tree is and the ab trees ? student  so we could have delete either we will have ? staff  okay but  student conversation   okay i am looking for one other answer which is perhaps who can  student conversation  good  split again see what ? s going to happen i just deleted and this is the picture i got  suppose i insert now what ? s going to happen i am going to go back this one  suppose i delete i am going to come back to this suppose i insert  this kind of going to go back and forth between this and i am spending lot of works in doing this because splitting the node lots of pointer moments and all of that so this key does not work in very well then this we have this kind of things happening so insert and deletes are very highly interspersed  if you have a block of insert and block of delete happening then it ? s okay then you can still work with the scheme fine because if you had just deletes happening  hindi conversation  so they would be no problem this has large number of keys now so it can handle whole lots of delete without significant trouble so if you had large sequence of delete then this is a fine strategy or if you had long sequence of insert but if you had these things alternating vary often then would be in some trouble so once again what are the disk  i was going to look like ?  refer slide time 39  52  so we are going to read as many nodes as the height of the tree and each point when i am borrowing one from the sibling or merging one from the sibling and basically modify only my sibling node so if i am doing any of those operation i might have to right back my sibling  my one node and the parent node  by the parent node because even when i borrow from the sibling one key goes up and one key comes down from the parent so its parent nodes also gets modified or even then merging again the parent gets modified  so every time i do some borrow or merge with the sibling i will have to right back three node and so that gives the number of disk right that we have to do a thing so again this two pass operation we have actually seen before  refer slide time 40  35  so this was single pass we have doing things  the two pass we have already seen so you first go down and then you go up as much as necessary so to say but in the case of disk access you have to think carefully or you have to organize the things more carefully because if you first make one pass down and then you make a pass all the way back up then you spending twice as much time as you should have by just having made a single pass so one thing you can do is that when you making first pass down you keeps all those blocks read in memory how many blocks is that ? how many pages is that just the height of the tree which is not too much you keep them in memory why do we keep them in memory  because you might require them on the way back in second pass so those are in optimization that you can do to try and reduce the type because as i said most of the time here spend in the disk access  you have to reduce the number of disk access as much as possible so with that we are going to end this class today so this was mainly meant as a recap of a data structure that we saw today was just small extension of the ab tree but it is specifically for disk based accesses and this useful in that setting data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 17 case study  searching for patterns so today we are going to be talking about pattern searching or pattern matching the setting is that we are given a piece of text let ? s say ? t ? is our text which is of length ? n ?  so it is ? n ? characters over some alphabets so for today let ? s assume that it ? s the english alphabet we have to search for a pattern ? p ? in this text you have all come across this problem you are using a certain editor you want to find out all occurrences of a certain work most editors will provide you the facility  refer slide time 01  17  the browser provides you the facility many things provide this kind of facility that you can search for a particular pattern not one occurrence but all occurrences of the pattern so question is  how are we going to do it ? this is also the exact matching problem there are versions where you can not do an exact matching as in you can search for the pattern in an approximate manner that means occurrences of the pattern in that text where it matches most of the texts if there is difference in one character  it is okay difference in two characters  it is okay but at most other places it matches so how would one solve this problem ? what are the applications ? this comes up in text editing as you can imagine  it comes in information retrieval one big application is bio informatics where your text would be a large database with sequence of nucleotides in it and you are searching for a particular gene or a particular sequence of nucleotides and you want to find out where all they occur so this is an example where the alphabet that you have is small if it ? s a dna then the alphabet has 4 bases in it but if it is a protein sequence  then it has 20 bases or it is an alphabet of size 20 so what is the na ? ve method of doing this ? suppose this is the text and i have a certain pattern let ? s say the pattern is ag ag this is the text  refer slide time  03  29  so what do you mean by the naive method ? i will put the pattern at the first place and i will start matching the pattern against the text in the third place  i find the mismatch so what do i do ? i start again from the second element is it clear to everyone why i should start from the second position and not from the fifth position ? what we are going to do is move the pattern by one step we will see examples of why this one step was critical and not more clearly by moving it by one step  we are not losing anything we will be able to find all the occurrences of the particular pattern so we do this again there is mismatch right at the very first step so we will move forward by one step and now here you see this is the mismatch of the fourth position so how much should i move it ? we will keep moving by one even here there is a mismatch at this place and so you will say that this is one occurrence so this is the question why are we moving by 1 and not by 4 ? if we were moving by 4  we could have skipped this thing so suppose i moved at 4 at this position  then where would i end up in ? it is a g a g here and then if i moved at 4 again  then i would end up a g a g and so i would have missed the occurrence of the pattern because the pattern is not occurring at multiples of 4 or such things it could occur anywhere in the text so moving by 4 is a wrong thing to do  refer slide time  06  40  how much time does it take ? n m so for every position that i put the pattern  i might have to match up to n places it might be that only at the very last place  we find out the mismatch in which case i am matching it at all the places of the pattern how long was the pattern ? so for each location of the pattern we might have to do ? m ? matches and how many different positions of the patterns are there ? n different positions so i might be spending as much as m n time the time complexity then is order m n space complexity is also going to be an issue how much space we require ? is this clear that we require only m we just need to store the text we need to store the pattern we don ? t need to any other additional space we don ? t need another array to move the pattern in it this moving the pattern is only to show it to you here that you can always increment your index appropriately so this unfortunately is not too good why is it not good ? it ? s too high so if you have a huge document  m is very large and your pattern is also reasonably sized let ? s say 20 or 30 characters  then you are going to spend a lot of time so this is not the way it is done we are going to look at another solution today we are going to look at a third solution in the next class so this will be the sequence of improvements we will improve the time complexity today from m n to something else i will see what that is so how can we do better ?  refer slide time  07  48  so when a mismatch is detected at a certain position  let ? s say at position ? k ? in the pattern string  what do we know ? we know that we have matched k-1 characters before that and i will try and take advantage of this fact that we have already matched k-1 characters let ? s see what i mean by this so here the mismatch is detected at position 3 of the pattern so what do i know ? i know that the first two characters of the pattern are the same as the last two characters of the text so i can use this information to try and move the pattern not by one step but by more steps why ? let ? s look at the second so this is c there is a mismatch here so what do i know ? even if i did not know what was here  i know since this is the mismatch i know that here  at this position in text it is a ? g ? and this position text it is an ? a ?  now if i shift the pattern by one unit what happens ? i know that in this position in the text it is a ? g ?  you understand why i know that ? i don ? t have to look at the text now that although the text is here in front of you  you can erase these two things and yet you know that this is ? g ? and this is ? a ? and since this is a ? g ?  there is no pointer in shifting in one step because then this would never match with this we will have to shift by one step if this were also ? a if this were in ? a ?  then we would have shifted it at by one step so that ? s the idea and we will see how to implement this idea now again what do we see ? we see that the mismatch at the very first step the mismatch is at the fourth position of the pattern now should i shift it by one position ? should i shift it by two positions or three positions ?  refer slide time  11  41  now what do i know ? so what i claim is you don ? t have to look at the pattern here you know that the last three characters of the pattern are the same as these three characters here because after all you know the mismatch was happening at this position so this has to be an ? a ?  this has to be a ? g ? and this has to be an ? a ?  now if i were to shift it by one position  then that means that i have to move by one position so there would be a mismatch if i were to shift it by two positions  then i know this is an ? a ? this is an ? a ? and what else do i know ? i know this will become a g but the g was already mismatching with this actually i don ? t really know that the shift will depend upon the pattern of course and we have to determine what the shift will be so here it ? s completely clear that we would not want to shift it by one unit but whether we wanted to shift it by two units or not  we don ? t know i am shifting it by two units we will see that exact procedure very shortly that ? s what the purpose of this lecture is once again we see that there is a match here and then there is a mismatch here so mismatch is at the second position should i shift it by one position ? i will shift it by one position again now i see a complete match there is nothing to be done here but i have to continue i can ? t stop how much should i shift it forward by ? 2 or 4 ? what do you mean by split pattern ? what do you mean by mix pattern ? if there was another ag here  this are two occurrences there this would be one occurrence and this would be another occurrence if this were a and g  it ? s all occurrence of this pattern i am not saying all disjoint occurrence of the pattern i should be shifting by two units so this is what is known as the knuth-morris-pratt algorithm it ? s very famous algorithm so key idea is when mismatch occurs we need not restart the computation all the way from the back we can use some information about the pattern some information obtained from the pattern to determine how many steps we should shift forward what we are going to do is we are going to construct an array ? h ?  that ? s going to determine how many characters to shift the pattern to the right in case there is a mismatch so we are going to store this information of how many characters we have to shift right in an array which we will call ? h ? and we will see what the array ? h ? would be  refer slide time 13  50  what is the key idea now ? so i guess i need to explain it more clearly so recall we have our text we have a pattern we have seen mismatch at a certain position that means this is not the same as this suppose if we have successfully matched the prefix p1 through p  i  -1 of the pattern with the substring t  j i + 1 ? ? j -1   so let ? s label these things so this would be location j t ? his would be i so i successfully match p1 through i-1 so this would be location i-1 i successfully match p1 through p  i   1 of the pattern with what part of the text ? it ? s j-1 this would be j-1 and basically we are counting i-1 locations here so that would be location j-i + 1 to j-1 so this is the part of the text which is the same as this pattern that i know because this is the first place where the mismatch happens and pi pattern this is not equal to tj  then we did not reprocess any of the suffix so what we are saying now is that we need to determine how much we need to shift so we should shift in such a manner so that this part matches with this so now this is the shifted pattern i need to shift in such a manner so that these two parts are the same this part matches up completely why would this part match completely ? this is because then this would also match up with this here because i know this is the same as this i will repeat it with the next slide so with each position of the pattern  we are going to define so recall we said that there is an array ? h ? which determines how much we are going to shift the pattern right  refer slide time 16  53  what is the information ? hi ? ? hi is the extent to which i will shift the pattern  if there is a mismatch at position i + 1  that ? s going to be the semantic so we will understand this how much i am going to shift the pattern right we will of course try to make the smallest possible shift we will come to all of that so we are going to make a certain amount of shift we will see what the right shift is smallest or largest because it ? s both smallest and largest smallest so that you don ? t miss out any pattern largest so that you don ? t waste any comparisons so it ? s both smallest and largest so you can pick suppose this is what is happening  this is my pattern  i am now not showing you the text at all but i tell you just the following information that the mismatch happened at position 11 so you don ? t know what the text is but the mismatch happened at position 11 how much should you shift the pattern by ? let ? s draw a picture and let ? s see how much should you shift the pattern by let ? s say i shifted the pattern by one unit then what will happen ? i will have a b a a this is useless i am now comparing the pattern against the pattern itself why because you know that text is the same here that was i said i don ? t know what the text is but i know now what the text is it has to be this this is one key observation so now if i shifted the pattern by one unit  then clearly it could not match against the text so one is useless let ? s shift it by two units if i shift it by 2  i get a b it ? s of no use again let me draw the shift by one also a b a a useless again  refer slide time  20  54  shift by two ? useless because this is not matching this shift by 3 a b a a useless shift by 4 ? a useless shift by 5 ? so i can keep playing this game a b a a a we have shift by 5  hindi  so we are trying to shift by 6 but that is also useless 7 and 8 are also useless actually i want to make i + 1 = l2 so 12 is the first place at which the mismatch occurs 5th is okay it was a b a a b a  hindi  which is not the same as this so this is acceptable because  hindi   so we will say that 5 is the reasonable value to shift by so we will come to what h11 or the 11th location of this array would be so i have defined hi to be the length of the longest proper suffix of p  1  through p  i  that matches the prefix of p let ? s understand what this is what is the suffix of p  1  through p  i  ? now recall we said this would always be an ? a ? and there is a mismatch here  refer slide time  25  22    refer slide time 27  45  so p  1  through p  i  is this part of the pattern  refer slide time  25  29   what is the suffix of the p  1  through p  i  ? prefix is contiguous parts before so ? a ? is a prefix ? ab b ? is a prefix ? ab a ? is a prefix ? ab a ? is a prefix and so on what is a suffix ? ? a ? is a suffix ? ab b ? is a suffix ? ab a ? is a suffix ? a b a a b a ? is a suffix so i am finding the longest proper suffix proper suffix means suffix which does not include the entire text like proper subset means strictly smaller so that ? s what proper suffix of p  1  through p  i  means that matches the prefix of p so i have to find out length of the longest suffix of p  1  through p  i  that matches the prefix of p which is exactly this this is the one we showed here why should the suffix match the prefix of p ? because when we shifted  it is the prefix of p which comes towards the suffix i have to find out the longest match because that determines how many we have to shift without missing out on a possible match somewhere so i have to find out the longest possible match and then there is the additional congestion here that the i + 1th character  so ? i ? is the length i am finding out hi  the length of the longest suffix which matches the prefix of p and then i want that  i + 1  th character of this should not be the same as the  hi + 1  th character of the pattern because hi this  refer slide time  27  31   so hi then is 1  2  3  4  5  6 so i don ? t want that the 7th the same as p12 and why did we require this ? because we know that there is a mismatch happening here so we want that better be different so this is the definition for our hi so it ? s a bit of a tricky definition but you understand what the argument is so it ? s not really how much you are shifting by if the pattern has matched the first 11 positions  then h11 says that ? okay  if there is a mismatch in the next position  then what is the shift ? ? so after the shift how many characters still continue to match ? 6 characters and what is the extent of the shift ? 11 ? 6 = 5 the logic is very simple you are trying to determine what is the extent to which you can shift the pattern you are trying to determine what is the smallest extent by which you can shift the pattern you will say smallest is one but smallest is not one because one is quite meaningless you know that clearly there will be mismatch happening by shifting the pattern by one so what is the smallest extent by which you can shift the pattern without you doing a necessary work ? you know that there are certain mismatches happening so you want to figure out the right extent to shift but you don ? t want to shift by huge amount either why did i make shift by 11 units all together because then i would have missed out on certain possible matches let ? s continue so this  refer slide time 30  14  part of the pattern what we already discussed in the same as this one and 7th position is not the same as the 12th position which means that with the value of hi  h 11 as 6  then this condition is true this would be 7 the 7th position is not same as the 12th position i is 11 and hi is 6 if there is no proper suffix of p  1  through i with this above property then what should the value of h  i  be ? what is h  i  capturing ?  hindi   so let ? s take some examples and then this will be clear so this is my text  refer slide time 31  35  and this is my pattern where is the mismatch happening ? in ? c ? or ? a ?   refer slide time 31  35  this is position 12 of the text so till 11 positions  matches happen so the value of i is 11 again h 11 is 6 by how many are we shifting ? 5 so that ? s what is happening  hindi   so last six characters and first six characters are the same you can actually move the pattern all the way up to here and further this is different from this so there is a potential this guy matches with this it does not that there is a different thing there is a potential that this guy matches with this so we will shift it by so much amount so this is the shifted pattern h11 is 6 so you were shifting p to the right so that p  1  through hi  1 through 6 aligns with this as the suffix of text so k is the position of mismatch k -1 is before this and k  hi is this part so it aligns with this perfectly  refer slide time 32  14  these parts should match why ? because this is the same as this which is the same as this so they match so in other words we are shifting  p i ? hi  places to the right suppose the pattern was only up to here  a b will not be the part of the pattern so that means that till the 11th position everything is fine how much should i shift forward by ? again the same i  hi because by doing that  we would not be missing out on any other patterns then so everyone understands why we are looking at longest such matching part ? so that minimum shift occurs or maximum shift occurs ? so that minimum shift occurs that way the minimum amount of shift is happening but why did we want a minimum amount ? we want the largest possible shift so the right answer should not be so that minimum shift occurs it is so that we don ? t miss out any patterns that ? s why we are looking at the longest prefix if i were to take shorter prefix  i might end up missing out on some guys why does this work ? why is it that we are not missing out on any pattern by doing this ? we have to argue correctness of the algorithm  refer slide time 35  19  so this is my piece of text the mismatch was at position k of that text and position i + 1 of the pattern this is position i + 1 of the pattern this is the position k of the text  refer slide time  35  43   in this case k and i + 1 are turning out to be the same but there could be in some part of the text even before this case even before this i + 1 and k would not be the same this is before the shift and these 6 character are same as this character which is why we could move it this way so this is the situation after the shift so if this part is beta  this substring is also the same as beta suppose this was not the case that is  the kmp algorithm missed out on certain patterns  they were certain patterns in the text which we could not find the procedure at all  we will argue that certain things can not happen suppose there is this missed occurrence of the pattern   hindi   these are the same as this but we missed out on this one this guy mismatched only at this this better be the same as this so this is also alpha so these alpha characters  this prefix of the string of length alpha matches the suffix of p 1 through pi of length alpha and alpha is more than beta so this violates our definition alpha is more than beta which is hi these are longer these matches this these is a longer prefix yes agreed but this character is also the same as this  hindi   so p l = tk because they matched but tk is not equal to pi plus one because there was a mismatch so pl is not equal to pi + 1 so it could not be that this and this are the same for which reason we did not take this longer suffix or prefix so it is also the case this and this are the different there was one requirement that we are looking for the longest prefix which matches the suffix of p 1 through p i and p i + 1 is not equal to p of hi + 1 both conditions need to be satisfied  hindi   here hi value was not correct and this establishes the correctness of the algorithm so if you have the correct value of hi  these things would work fine so let ? s take an example this would now be clear after this i have a certain  refer slide time 40  16  pattern which is 13 character long this is the input string  refer slide time  40  25  we will expand it out this is the array h suppose i have calculated it in some manner  array h can be calculated for every i with some amount of effort you can figure out what h of i should be we will see how to do that also suppose i have figured this out  for instance this is the same pattern  at 11 you have 6 let ? s see how we are going to use this information let ? s do a complete example so this is my pattern this is the text the first mismatch occurs at position 12 which means till position 11 there was a match so i go to position 11 in the array i see the 6 written there there was a 6 written in position 11 so what does it mean ? i have to shift by 11  6 = 5 units this 6 is telling me how much of the pattern is going to remain matched after the shift so 6 characters of the pattern will remain matched  hindi   h11 is 6 so i  hi is 11 6 which is 5 so i have to shift by 5 units as you can see  the pattern has been shifted by 5 units the pattern is the one on top and the text is below now again i will continue to look at this position note that i don ? t have to try and match the first 6 positions because they are now already matched by the definition of the function h they are matched but this 12th position  hindi   but what position in the pattern is it ? this is position 7 in the pattern the value of i is 6 now i go to 6 and i see so h6 is 3 so now i am going to shift by i  h6 6  h6 = 3 units i shift by additional 3 units and this is the situation i have now  hindi  which we have to shift by 2 units  refer slide time 43  15  so we shift 2 units to the right and so we will get a b after the shift we will get a b and something but b and c still mismatch which means we will now shift by 1 unit a and c mismatch so we will shift by another 1 unit  hindi   when you shifted beyond the c  then there was the match from when you found the match so if you had the h function  you can use that to determine how much you should shift by at every step so that the match can be found and this shift function is designed in such a manner that you will never miss out on any potential match every one followed this 210 business ? we come to calculation of h how much time does our algorithm take ?  refer slide time 45  23  suppose h is given we will see how to do the h  hindi   we will count the number of comparisons  hindi  this was the first step at which we had the mismatch  hindi  because it did not result in the match  hindi  every time we were comparing with c so how many times would we be comparing with a certain character ? many times up to the length of the pattern but that doesn ? t sound very good because that would mean that the number of comparisons is huge for each character  the maximum number of comparisons could be large but let ? s look at the total number of comparisons put together so let ? s call this unsuccessful comparisons what is an unsuccessful comparison ? comparisons that result in a mismatch now how many unsuccessful comparisons are there  over all put together ?  hindi  every time i do an unsuccessful comparison  i shift the pattern  hindi  at most  the number of the size of the text types so the number of unsuccessful comparisons is at most the size of the text which is ? n ?  so unsuccessful comparison are not too many how many successful comparisons are there ?  hindi  these were all the successful comparisons after i shift  these characters are a part of successful comparisons we will never compare against these characters again  hindi  we will never compare this part of the pattern ; the part before this red line with the text so each character of the text which is ever part of the successful comparison is compared only once there ? s no back track happening the number of successful comparison is at most the size of the text the total number of comparisons is the number of shifts plus the number of unsuccessful comparisons so we broke up our comparisons into two sets  successful and unsuccessful once a character is part of the successful comparison it ? s never compare again if a character is part of the unsuccessful comparison  it might be compared again but it results in a shift so every unsuccessful comparison results in a shift so total number of shifts since it can be no more than the size of the text no two successful comparisons can be more than the size of the text so total number of comparisons therefore it at most two times the size the text so total number of comparison that are required is the size of the text  refer slide time 50  48  but what about computing the array h ? how do we compute the various hi ? s and how much time does it take ? so we are going to call that preprocessing time so recall that the size of the pattern was n what one can argue is that the time required to compute the array h is only order m  the size of the pattern and the time required to do the searching is order n  the size of the text so the total time therefore is order  m + n   i have not told you this as yet  ? y ? is computing the array h ? y ? can we done in order m time let ? s see why so we have to compute array h  refer slide time 55  09  what was our definition of an array h ? suppose i have to compute h  i   i look at my pattern i was certain pattern this is the ith position what is h of i  who can remain me what h of i is ? the longest proper prefix of the pattern which is also a suffix of 1 through i and that next character should be different  hindi   so hi is the value  it ? s the longest suffix  longest prefix or longest suffix whatever longest prefix of the pattern so what are the potential value of hi  what are the different value hi can take ? zero to m  zero to i -1 because we also said proper what is the proper subset ? when is the subset proper  when it ? s not equal to the set so that ? s what the proper suffixes  when it ? s not in the entire string so essentially it can take i different values  give or take a one and then i can try out all those various values what is that mean ? suppose i am trying out the value h  i  = 3 what should i do to try this out ? i should look out the last three character here and the first three character and see if the other same if this is the same as this  if this as the same as this and if this as the same as this then h  i  can be 3  hi is more than or equal to 3  refer slide time  53  43   so i will try out 3  4  5  6  7 all the way up to i-1 and whichever are the possible value i just take the largest among them so how much time does this take ? so how much time do i take to compute hi  i will try out all the i different values i will do all the so many comparison  so in particular if i choose a value of h  i  equals j then how time do i need to do check whether j is the candidate value ? j time i will take j  j going from 1 through i-1  zero through i-1  so this is i square roughly so for h  i  i will take i square time  so for entire array h  i will take summation i square i going from 1 through m which is m cube time  huge amount of time this should be o of m cube ; divide by what ?  refer slide time  55  11  we just taking computing the total time  refer slide time  55  26  huge amount of time right so we want to do something better we can use the previous value of h  i  which have been calculated how can we use that ? so that ? s a nice idea in fact that ? s the right idea so to compute h  i  so we are going to assume the following that when you are trying to compute h  i  you already have the previous values h 1 through h  i  -1 these are already there  refer slide time 1  00  00  note that in doing this computation of array h we don ? t require the text at all it ? s being done just on the pattern you can take your pattern  compute your h and then you can match it again which ever text you want so the text can be whatever you want  once you computed this then you can just go head and work with the text suppose i am trying to compute h  i  again and i know all the values of h 1 through h  i  -1 how can i use these to compute h  i  ? who can tell me ? span of the stock using the stack now what can we do ? i don ? t think that is the same idea but can someone tell me what should i do here ? so for h  i  -1 we know so if h  i  -1 was let ? s say 5  so we know that the first five match with these 5 so these 5 match with these so these are the first 5 of the pattern  these is the pattern p these also the pattern p so the first 5 of the pattern match with i-1  i-2  i-3 basically i-5 to i-1 of the text of this pattern itself now how do i know what h  i  is ? these doesn ? t solve the h  i  problem now if this 6 character of the pattern matches this then can i say that h  i  is equal to 6 can i say that ? why not ? so i claim the following  if p  i  = p  6   the 6 character of the pattern  student  it is atleast h  i-1  so we will try of z assuming that it is at least five  so that ? s what we have to do we have to do something like  refer slide time  59  56   there was zeros also so it need not be an increase  no but it need not be equal to h  i-1   it could be zero also we are saying but it could potentially if this and this match now  i am sorry i am confusing my array h with my  refer slide time  1  00  23   student  h  i + 1  is not equal to h  i + 1   staff  so they would not match so it has to be less than 5  so they would be not match student  so it has to be less than five greater than six or staff  okay so that ? s a good question we will take this off in the next class so today we looked at pattern matching in a text so we looked at very simple algorithm for doing that which had an order mn time then we looked at the knuth-morris-pratt algorithm which we argued has the running time of order m + n so that was the improvement  we went from a mn to m + n this is the modulo fact that you can compute the array h in order m time so we shown you how to compute the array h and order m cube time and we are going to see how to do that in order m time in the next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 18 tries today we are going to be talking about another data structure called ? tries ? and we are going to see it ? s used in pattern matching so i am going to be starting off with what are called ? standard tries ? which is the plain version of tries and we are going to move on to ? compressed tries ?  this is a space sufficient way of keeping tries and the last topic we are going to look at today is what are called ? suffix trees ?  so first 2 terms have tries in them and the 3rd has trees in them recall in the last class we were looking at pattern matching given a piece of text  we were interested in matching patterns finding out at what all places certain pattern appears in the text and what we had done there if you recall was that we had preprocessed the pattern that is  we took the pattern we computed this failure function h on the pattern and then we used that information to search for the pattern in the text and the time we took was proportional to the size of the text  refer slide time  02  45  so this preprocessing the pattern speeded up the time it took to match the pattern if we did not compute the failure function h  then we just had this brute force method of matching the pattern which took order m n time ? m ? size of text and ? n ? size of the pattern so after processing the pattern in time proportional to the length of the pattern  the knuth-morris-pratt algorithm searches an arbitrary text in time proportional to the length of the text now if the text is very large  this is not a very good situation to have  refer slide time 02  54  so i have a very large piece of text which doesn ? t change and i am searching for patterns in the text every time i search for a small pattern  if i am going to spend time proportional to the size of the text  that ? s a lot of time so you have let ? s say  collected works of shakespeare in which you want to search for ? veronica ? and you are going to spend time proportional to the size of the text which is very huge now what we want to do today is to process the text so that i can search for the pattern in time proportional to the length of the pattern see this becomes great because now patterns are typically very small ; 7 characters  15 characters  something like that while your text could be a million characters large you don ? t want to spend that much time every time you are searching for a text but here today we are going to require that we will preprocess that text we will work on the text initially and we will have created some data structure on that so that when a pattern comes  we can search for that pattern all occurrences of that pattern we can spot in a very little time proportional to the length of the pattern  no matter what pattern comes in the previous kmp algorithm  it was the other way around you processed the pattern you did a preprocessing on the pattern so that no matter what text came  you could search on that text but there you were taking time proportional to the length of the text which is quite expensive we will come to the notion of tries today what is a trie ? i will perhaps show you a picture and i will explain it through this picture so trie is a data structure to maintain a set of strings let ? s say i have a set ? s ? of strings s =  bear  bell  bid  bull  buy  sell  stock  stop   now i am going to create a tree here now this is not a binary tree in fact the number of number of children that particular node can have it can be as large as the size of the alphabet we are working with the english alphabet let ? s all our strings are lower case characters so the size of the alphabet is 26 each node can have up to 26 children now the children of the node are ordered alphabetically what does it mean ? each node is going to have a particular character in it and if i look at all the children of this particular node  then those are going to be ordered alphabetically so b will proceed c if c were there and c would come after b and so on i have just 2 b and s so b comes to the left of s this had 3 e  i and u so they come one after the other in this order so it ? s an ordered tree  refer slide time 06  44  this is read left to now how is this organized ? suppose i have to start from here and i have to follow a path in this tree suppose i came this way ? b e a r ?   refer slide time  07  05   bear is one of the words here suppose i were to take some other path ? s e l l ?  sell is another one ? s t o c k ? ? stock this is another word here so now you can build this thing if i give you set of words can you build this trie it ? s straight forward what am i doing ? at the very first level i am looking at the first characters of all my words and see what are the various occurrences if you look at the first character i have just b ? s and s ? s so there will be one node corresponding to b and one corresponding to s and within this b then this b has only 5 words associated with it what are the second character of these words e i u so that ? s why e i u is the children of b and so on the square here just reflects it ? s a leaf node corresponds to a word suppose i had built such a trie  how much time does it take to search for a word here ? suppose i give you a word how much time does it take ? suppose i said ? bed ?  how much time does it take to search for bed here ? first i come here so this has two children how is this organized ? how do you think what kind of data structure would i have to organize this ? it ? s a multi way search tree it is in some sense but each node can have up to 26 children as a set so one way of organizing it is each of the nodes has an array of size 26 sitting inside it the first location of the array points to the node corresponding to a second to the node corresponding to b third to the node corresponding to c and so on if you organize it in an array  you waste space each of the nodes has 2 to 3 children here in that case  instead of an array you could keep a linked list ordered according in the alphabetical order in which case you know you will have two nodes here the first nodes will be pointing to b and the second node will be pointing to s you will say that this is b and this is s now given this  how much time does it take to search ? suppose i had a link list at each nodes  why would this change the search time ? it is 26 times the length of the word i am searching for so i have a link list sitting here  refer slide time  10  38  and in each of the nodes of the link list  there is a particular character which says that if you are searching for this word and if this is its first character  then follow this pointer if you are looking for a word beginning with ? s ?  you will have to run through the link list first to get to s and then follow the pointer if s is not there you can stop away but if s is there in which case you will have to follow the pointer and repeat these things so how much time does it take in the worst case ? you might have to traverse 26 nodes of the linked list into the length of the word  refers slide time 12  32  let ? s look at the operation of find how much time does find take ? i am using let ? s say linked list of presentation on each other so 26 is the alphabet size i am using d to denote it may be the alphabet was not 26 large you may have a smaller alphabet or a larger alphabet and m is the size of the string of the word that i am searching for so that ? s the time for find can you see that this is also the time for insert and for delete ? when you know you are searching  you keep coming down and then you don ? t find it any more if you don ? t find it any more  what you do is insert you will create that letter  put it in the linked list  make a pointer down and may be you will have to create new nodes you want me to show how you do this ? suppose we were trying to insert let me quickly do it what do what do ? i want to insert bed what will i do ? i will search for bed i will come down here ? d ? found here i would have a node i would have seen a ? b ?  so i come down here then i would search for a ? e ?  i come down here here i am searching for a ? d ? in the linked list here there is no ? d ?  so i create a node now it will be a square node because it ? s the end of the word and this would have ? d ? written in it but if i had ? b e d s ?  then i would create one circular node and then a square node below i might have to create such a longer change here in any case total time taken would be proportional to the length of the word we will see later when one of the words is the prefix of the other that ? s what you worried about  refer slide time 12  32  so find  insert and delete all take the same time order dm but one thing is bad with this data structure and that ? s the space requirement of the data structure how much space does it take ? 26 times the number of nodes how many nodes are in this tree that we have created ? total number of characters in the entire text which is the size of the text that ? s the worst case and it can be close to the worst case i have let ? s say 10 words let ? s say i have 10 words  each beginning with a different character the first word begins with the ? a ? second with the b third with the c the fourth with the d and so and on and you can make a long chain below this depending upon what the size of the word is there can be as many as many as total not total number of words which is exactly total size of the strings in it by size i mean put all the characters together and their total size let ? s call that double so that ? s the space required which is too large so we got to do something about this one before that  let ? s see applications so this actually does our task what we started off with  refer slide time 17  07  so suppose i give you a peace of text and we take all the words in the text and throw them into a trie i make a trie out of all the words in the text now if i have to search for a particular word  i can search for the word in time proportional to the length of the word this is what we started off today so i can do word matching find the first occurrence of word ? x ? in the text why have i said first occurrence ? it will be inserted only once so one occurrence i can detect by doing that we can also do all occurrences we come to all of this in a second let me show you an example and you will see that we can actually even do all occurrences so each of these operations of matching is done by tracing the path corresponding to that word in this trie so let ? s look at an example this is a piece of the text  refer slide time 18  27  so you have a bunch of words ? see ? for instance appears twice so i am looking at all the distinct words that are there in this piece of text which is ? see ?  ? bear ?  ? sell stock ?  ? buy stock ?  ? bull ?  ? bid ? and ? bell ?  so these are all the words i threw them into a trie this is the trie i get and as you can see  this leaf corresponds to ? b e a r ?  refer slide time  19  15  and bear occurs at position six that text that is so with this leaf i store 6 let ? s look at the bid bid is occurring at two places perhaps starting at 47 and starting at 58 so i will store both 47 and 58 here  refer slide time  19  42   this is what we call preprocessing the text i took my initial text and did something  built this trie on it  stored this information in each of these leaves  so that now if you come with queries like where does this particular word appear  i can quickly tell you how much time do i need ? it ? s very little it ? s just proportional to the length of the word and i will be able to tell you all the places where this word is  by looking at this number down here this doesn ? t really solve the problem that we were talking of in the last class which was that i give you piece of text and i give you pattern and find where all the pattern appears in the text because my text need not be a collection of words as i said you know my text could be let ? s say  sequence of basis in a gene database so i have just a long sequence of ? a c t g ? that kind of thing and i am searching for a particular sequence in there so here we have a separate notion of words and if we are searching for words  that ? s okay suppose i was searching for ? a r blank s e ?  then i can not search for patterns here so if i have a pattern like that so if i don ? t know if i think of these blanks also as some special character of my alphabet  then i can not really search for anything so the reason i can search here is because there are well defined boundaries my pattern has to begin with the boundary and end with the boundary that ? s why i can search so now first we will address the issue of the large size that this trie has let ? s try and reduce the size of the trie first we will do the following  refer slide time 24  19  we are going to look at all nodes of the trie which have degree only one and remove those nodes by degree one i mean who have only one child and i am going to compress those nodes so if this is my standard trie  see that there are whole lot of nodes here which have only one child  refer slide time  23  30 to 23  40  this node for instance this node this node this node in fact this node as well as this node this node also has only one child this has only one child so i am going to compress that by compress i mean i am going to take the child and collapse it in to the parent and if the resulting node also has only one child  i am again going to take the child and collapse it in to the parent and keep doing this in my previous example  i had said i have trie in which there were a bunch of words  each of which begins with a different character so i had created a long chain like this now if i compress them in to a single thing  then this entire thing becomes just one node so i will just show that to you in a second this is what my compressed trie would look like  refer slide time  24  39    refer slide time 24  36  b and s are the same ? i d ? collapse in to one now a node doesn ? t have one single character but a string as its labeled this e a r collapses here l collapses there and so on as you can see  the compressed trie is smaller than the standard trie why would this take less space now ? what is the number of nodes in this thing now ?  refer slide time 25  29  so this is a fact which will prove for yourself it ? s very simple suppose i have a tree which has ? l ? leafs in it and every node of the tree has at least two children every internal node of the tree has at least two children then the number of internal nodes can not be more then l -1 a tree in which every node has at least two children  by that i mean except leaf node clearly leaf nodes don ? t have any children every node has at least two children it has at most l -1 internal nodes where ? l ? is the number of leaves if every node has at least two children  then the number of internal nodes is not too much this is a very simple thing you can prove it by induction how are we going to use this ? how many leaves are there in my trie ? it ? s the number of words this says that the number of internal nodes is going to be  number of words ? 1  at most so the number of nodes in a compressed trie is order of s where s is the number of words s was the set of string so s is the number of words this is the number of nodes in a compressed trie this doesn ? t solve our problem completely why because each node now has a longer label inside it we will also have to store that label we need space to store that label from where do we get that space now ? we are going to store labels not as labels but as numbers let ? s see what i mean by that let ? s look at this label ? i d ?  this was the last two characters of the word ? b i d ?   refer slide time 27  27  so ? bid ? is the 6th word in my collection i have kept all the words in some array in some arrays and id is the last two characters so in the 6th word  ? i d ? begins at position one and ends at position 2 so each of these labels no matter how long they are  can be stored as three numbers this is because each of these labels will be a substring of one of these words do you follow what i mean by sub-string of one of the words ? not necessarily a suffix or the prefix although in this example it looks like a suffix while it is not necessarily for instance ? to ? is not a suffix i am not saying prefix or the suffix i am saying it ? s a sub string it is a contiguous part of the string now what is the space used by the trie ? you will have to store these words somewhere this is your input this is stored somewhere so we are just trying to figure out how much additional space we are taking for the data structure there then how much additional space are we taking ? now this space i am taking by this data structure is number of nodes number of nodes is two times number of words at most into three for three integers each because then there are some pointers how does searching happen ? let ? s look at that now how does insertion and deletion happen in a compressed type ?  refer slide time 32  52  suppose this is the trie i have so the labels that i have put at a node  we can also think of that they are the labels on the parent edge of that node it ? s one and the same thing you understand what i mean ? there is also a subtle reason why i am doing it this way and we will see why i am searching for this string ? b b a a b b ?  i start searching so conceptually it is the same as saying i see a ? b ? here and come down then the first here is the a this is a b so i should go this way and i come down here  refer slide time  32  04 to 32  29   now the third character i have is an ? a ?  so i am looking for an ? a ?  so the first character here is an ? a ?  the first character here is a ? b ?  so i should come down to ? b ? and then i start matching this with this the label here we are not doing anything sophisticated we should now get familiar with this we are searching for this pattern we are moving down the tree  hindi  degree is the number of children so we are inserting b b a a bb which means we first search for it we search for it we reach the middle of this edge till the middle of this edge  we have matched b b a a  hindi  next character is b  hindi   red node is the node i ? ve inserted  hindi   this is how you will insert now how will you delete ? we proceed  we find the node and we delete now something else has to be done suppose i have to delete b b a a b b i will come here and i will delete this guy now i look at the parent if the parent has only one child left now  collapse the child with the parent and you might have to do this multiple times so it ? s a very simple data structure i am leaving out the implementation details you will have to figure a few things out tries are very useful they are used in web search because you can imagine why  refer slide time 36  59  imagine you are going to google you type a word and it retrieves to you all the web pages that have that word that part which helps you retrieve all the things is called the index of the search engine so it is stored as the compressed trie typically i am not saying that google doesn ? t this way this is what generic search engine do and each leaf of the trie is associated with the word  hindi   that ? s called the ? occurrence list ?  the trie is kept in an internal memory the list can be very long if you type a word like ? computer ?  you imagine the number of urls pages that could contain that word so this occurrence list will be huge so that ? s why it ? s not kept in the main memory it ? s kept on disk now suppose you wrote ? computer and music ?  so now it will search for computer and it will search for music it will get two occurrence lists now it has to take their intersection so boolean queries corresponds to set operation of this occurrence list if it is ? and ? it is union and if it is ? or ?  it is the intersection of course there are lots and lots of techniques that go into speed up the thing you eliminate stop words and many other things we will not go into that they are also used in internet routers  refer slide time 39  02  now you are all perhaps familiar that each computer on internet has an internet or an ip address which is a 32-bit number so type google.com you can use nslookup to find out the ip address so a particular organization just uses the subset which are all related in a certain manner for instance  all iit delhi address will look something like 10 now how is routing done ? in a router when packet comes in  it has an ip address written to it it doesn ? t say if this is the ip address  send it here router is a bunch of links coming in links and going out so packets comes on one of the links and the router has to figure out which links to send it out to there are 232 ip addresses it says take the ip address of the packet and find out the longest match your table would have the following anything that begins with a 10  send it here anything that begins with the 10.27  send it here  anything that begins with the 10.27.36  send it here so now what is the router going to do ? it ? s going to find out the best possible match of these three it will try to find out the longest match so if the packet had 10.27.36  then it will go on the 36 route but if it was 10.27.34  it will take the 10.27 route if it was 10.28  it will take the 10 route this is the way routing tables are organized so they are also tries i used to do this tries could be one way of doing it so we will come back to pattern matching now  refer slide time 40  01  we saw compressed tries are doing the job reasonably well provided there was the notion of words or delimiter and our pattern started and ended at the delimiter but suppose you are as i gave you an example if you are searching in a biological data base there is no notion for the delimiter there what do you do then ? so this is something we said before instead of preprocessing the pattern  we are going to be preprocessing the text now what we are going to do is the notion of what ? s called the suffix tree we will take all suffixes of the text and organize them in to a tree and you will see what i am trying to say in a second let ? s see piece of text x a b x a c  refer slide time  41  09    refer slide time  41  09  how many suffixes does it have ? there are 6 suffixes i am not saying proper suffix i am going to take them as my words x a b x a c is a one word a b x c is another b x c is another x a c is the 4th a c is the 5th and c is the 6th there are 6 words and i am going to create a trie of these words  in particular a compressed trie and this is what the structure is so let ? s see why it ? s a trie here if it were a ? b ?  i would go this way if it were a ? c ?  i would go this way if it were an ? a ?  i would go this way if it were an ? x ?  i would go this way  refer slide time  42  06    hindi  numbers are the starting position of that suffix so this corresponds to x a b x a c what is the starting position ? it ? s one this corresponds to x a c its starting position is 4 this corresponds to a b x a c the starting position is 2 the starting position for a c is 5 and so on and so 4th so put all our suffixes in a trie so it ? s essentially a compressed trie for all the suffixes of the text  refer slide time 44  09  so it seems it would be huge but why should it be huge ? how many suffixes are there ? there are as many as length of text so we will have that many words recall that the size of the trie is just the number of words order number of words so its order length of the text  hindi  so this size of the trie is not too much so suffix tree for us text x of size n from an alphabet of size d stores all the n suffixes of x in order n d is typically small so it doesn ? t require too much space  hindi  we will come to why we are doing suffixes can someone think of why suffixes ? so i was searching for a b what will happen if i am searching for a b ? suppose i start searching for a b i will come at ? a ? here and then i will come at ? b ? here and i will stop in the middle but can i say something now ? i did not find that ? s what you will be tempted to say if the pattern appears in the text then there is some suffix whose prefix is that pattern that means that there is some word in the collection of words that i have thrown in whose prefix is that pattern which means that when i am searching for the pattern  that initial part of the word will match up and i will be able to do something with that many of you can see what i will be able to do i will just look at the leaves of that sub tree and identify we will come to all of that that ? s the remaining of this lecture so let ? s say i had this word ? minimized ?   refer slide time 46  49  i don ? t make the suffix tree for each word in the text i make a suffix tree for the entire text so if this is my entire text i make a suffix tree for it there would be 8 suffixes this would be the corresponding suffix tree i would get once again i have collapsed my nodes you can all make this suffix tree and now we want to do a compact representation once again  refer slide time 47  58  how much space do i require ? so instead of storing labels  there are big labels here we don ? t want to store labels so once again we can store by numbers once again each one of them is a sub string so i just need to know what the start and the end position of the sub string is i don ? t even need three integers now i just need two because they are all part of one single text so this is for instance what would happen m i n i m i z e  m i n i m i z e starts at position 2 and ends at position 7 so i can store it very efficiently now this is the key thing which we are using in pattern matching  refer slide time 48  22  so if i have two suffixes ? x a b ? ? x a c ? and they have the same prefix ? x a ?  their corresponding paths are the same at the beginning and it ? s just the concatenation of the edge labels of the mutual parts so x a b x a c x a b x a c  its common part is ? x a ? and it comes here  48  53   this is going to be crucial in a short while because now if i was searching for x a  i would end up here  refer slide time  49  12   so i have to actually report all occurrences and this will help me do that so what do i have to do report all occurrences basically i have to look at its children look at the leaves in the sub tree and that will give me the position we will come to all of that this was the problem that some one had pointed out very briefly in the beginning if one word in my trie is contained in another word  what happens ? suppose my text is x a b x a  now what is going to happen ? i have one suffix which is x a and another suffix which is x a b x a this suffix x a is a prefix of the other suffix so in my trie  what is going to happen ? you know one of the words is going to end up at some internal node you don ? t see a big problem with this ? let me quickly show you what i am trying to say  refer slide time 50  54  let ? s call it ? x a ? and ? b x a ?  there are 2 suffixes ? x a ? and ? x a b x a ?  we are ignoring the other suffixes  hindi  what is special about dollar ? there is nothing special about dollar it just is a character which is not part of an original alphabet  hindi  so now how does one build a suffix tree ?  refer slide time 53  10  we start with one initial  one suffix let ? s say this is the entire text so that basically is one edge and then we keep breaking this edge so we will search for the next suffix  hindi   starting at the root  find the longest path from the root whose label matches a prefix of si through n at some point if no matches are possible and if this point is at the node  then we denote this by a ? w ?  if it is in the middle of an edge  we insert a new node and then call this node ? w ? and we create an edge running from the root to the suffix that we create so we can take an example quickly one suffix is ? x a b x a c ?   hindi   refer slide time 55  16  so this will take time proportional to the length of the text if the length of my text was n then it takes time order summation n2 it is a bit more but we will see what we can do about this one  refer slide time 55  29  this is the key idea that we are exploiting in pattern matching so given a pattern ? p ? and has text t  our aim is to find all occurrences of pattern p in the text so the idea of algorithm is that every occurrences of p in t is a prefix of a suffix of t  hindi  thus an occurrence of p can be obtained as concatenation of the labels of edges of the path beginning at the root so how do we do pattern matching ? we build a suffix tree for the text  match the characters of the pattern along the path beginning at the root until the pattern is exhausted  refer slide time 56  25  if the pattern is exhausted completely  that means that we have found a match if no more matches are possible  then that means that pattern does not exist so 2 in this case  p does not appear anywhere in the text in case 1  p is the prefix of a suffix of a certain suffix which is obtained by extending the path and till we reach a leaf each extension gives a suffix all the leaves we can reach from there will tell us the occurrences of the pattern each extension provides af occurrence of the p in t what are the extensions ? they are basically all the leaves below that  hindi  let ? s quickly see an example  refer slide time 57  44  this corresponds to this suffix this corresponds to this suffix this corresponds to this suffix  refer slide time  58  08   the number that you write here is the starting position of this pattern of this suffix so we write a 7 here we saw only an order n2 algorithm for constructing the suffix tree  refer slide time 58  41  it can actually be done in order n time but that ? s a fairly complicated algorithm we will not be doing it in this class so that gives us the total complexity of pattern matching  refer slide time 58  56  so preprocessing which means building the suffix tree we said it can be done in order n times proportional to the size of the text although we saw only an n2 algorithm today and for searching i ? ve said size of the pattern plus ? k ?  number of occurrences of the pattern in this this is completely essential if a pattern is only 3 characters long but occurs one thousand times in the text and you have to say all the times it appear then clearly you are going to take time proportional to 1000 so this is clearly a requirement and why is this coming up ? this is because we have to report all the leaves of this node  refer slide time 59  41  if there are k leaves we have to go and report all the k leaves have many internal nodes are there in this sub-tree ? there are  k ? 1  nodes what is the size of the entire sub-tree ? it ? s of order k  refer slide time 1  00  42  that gives us the total complexity of pattern matching let me go the last side the total space we require is the proportional to the size of pattern to store the pattern so with this i end today ? s lectures so we looked at a faster  faster in the sense now we decide to preprocess the text and to search for the pattern we just need time proportional to the length of the pattern data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 19 data compression today we are going to be talking about data compression  refer slide time 01  17  we will begin with what the idea behind file compression is and then we are going to be talking about huffman tries which is the way of doing data compression we are going to see how ? abracadabra ? translate into these sequence of 0 ? s and 1 ? s so what is file compression ? as you know  if you have a piece of text  it ? s stored as bits in your computer and what is typically done is that  for each character  you have what ? s called an ? ascii code ?  so if you were to go into a unique shell and type < man ascii >  then that will give you the ascii code for all the various characters  refer slide time 03  31  the ascii code is an 8 bit code which means that every character is stored as 8 bits so this is what is called ? fixed-length encoding ?  why fixed length because for each character  i have the same number of bits but our idea today is to try and reduce the amount of space required to encode a piece of text if each character i am going to use 8 bits then the total number of bits required will be 8 times the number of characters in the piece of text but suppose i don ? t have to do fixed-length coding you know some character might have two bits associated with them some character will be encoded using three bits  some using four and so on  can we exploit this and the fact that some characters occur more frequently than others to design a coding screen which will represent the same piece of text using lesser number of bits using lesser number of bits you understand the need for doing this kind of compression ? clearly the lesser memory you require  you know if you are transmitting the file  you have to send less number of bits if you are storing  you will have to store less number of bits and so on so it ? s very useful to be able to compress the information that you have that will bring us to what we call variable-length coding so the number of bits used to represent each character would be different in particular  character which occur more frequently  we are going to represent them using less number of bits and use that characters which appear very infrequently  let ? s say x or z in the english alphabet  we can have longer sequences may be more than 8 bits let ? s see how this is done so let ? s say my piece of text is just 4 characters java and i decide to encode ? a ?  how many characters are there ?  refer slide time 07  00  suppose my alphabets were just a  j and v the only things that ever encoded were strings on this alphabet a  j and b so java is1 example of such a string and suppose i were doing fixed length encoding  how many bits should i associate with each of these ? i will need at least two i can ? t do with just1 because there are three different characters and there are only two possible values if i choose1 bit so i need at least 2 bits and if i take 2 bits then how many bits do i need to represents java ? 2 times 4 is 8 as straight forward as that but suppose i decide to use 0  just single bit for ? a ? and11 for j and 10 for v and i will tell you why i am doing this then java can be encoded as110100 that would be the encoding and it will take only 6 bits it will take the lesser number of bits then you can ask me  ? well  why did i do j as11 and v as10 ? ? so the problem with variable length decoding  variable length encoding is that of decoding how do you decode ? given a sequence of bits you want to decode it uniquely so suppose i gave you a sequence of bits  then you should be able to retrieve java from this of course i ? ve told what the codes were you should be able to get back to java suppose for instance  i had used this as my encoding  for ? a ? i use 0  ? j ? is 0 1 and ? v ? is00 so still it should take 6 bits only and the encoding would be 01000 and 0 from here can i get back to java given this code ? well 01 could be either ? a ? or it could be a ? j ?  it has to be a ? j ? because we are using this ? 1 ?  so what would you do with these 4 0 ? s ? it could be ? java ?  it could be ? j v v ? or it could be ? ja ?  it ? s ambiguous you see the problem ? if you have to use variable length encoding  then you could have this problem of ambiguity while decoding so you have to be careful when you are using variable length codes this problem would not arise when you have fixed length codes you understand why because you will take those many bits and then you now determine what exactly the character was so to prevent ambiguities in decoding  we will ensure that our encoding satisfies what ? s called ? the prefix rule ? which is very simple it says that no code is a prefix of another code by code  i mean the bits i use for a particular character when this was our code  you can see 0 was not a prefix of either j or v j and v were also not prefixes of each other the encoding arising out of this would be unambiguous and we will see an example to show that to illustrate that but the encoding arising out of this  refer slide time  08  15  will be ambiguous because ? a ? is the prefix of these  refer slide time  08  21  and i will show you an example you must understand what the prefix rule is so if your codes satisfy the prefix rule  then decoding will be unambiguous but if it does not  then you will have ambiguity in decoding so i will come back to the prefix rule in the next slide code is the collection of code words  refer slide time 08  48  what i have written out here is a code each one of these is called a code word for each character the sequence of bits what ? s called the code word and the entire thing is called a code so code which satisfies the prefix rule can be represented as a tree in particular as a trie so recall the ? trie ? that we have discussed in the last class  the branching was a 26 way branching but here branching will only be a 2 way branching each node will have only a 2 children here my alphabets are a b c d r five characters only the characters will be stored at the leaves or the external nodes and every for every node the left edge will label with 0 and the right edge will be labeled with 1 now a = 010 because you know if you look at this  from root two a  you will encounter 010 when you are coming to r  the code for r will be 011 can you see that if i drew such a picture for you  then the code word for any character will not be a prefix of the codeword for some other character otherwise it could have ended midway but it ? s not because everything is a leaf each character corresponds to a leaf that ? s the very first statement here so the code word for one character would not be a prefix of code word for another character we will represent our codes using such a we trace a from the root to the particular leaf to determine the code word for each character i need not have shown this picture at all i could have just drawn this trie and from this you can figure out what is the code word corresponding to this now how do we do the decoding ? suppose this is my trie and these are the code words  refer slide time  11  33    refer slide time 11  28  now i give you a sequence of bits that ? s this is my encoded text and i have to decode this text  refer slide time  12  01   as you can see  the code satisfies the prefix rule so how do i do the decoding ? so i start from the beginning you always start from the beginning you start from the beginning 010 so you will trace out 010 you will get a leaf you stop and these 3 characters go away and i get an ? a ?  so i have struck off these 3 and i have written down an ? a ?  now i will take 1 and the next 1 is also1 so i get a ? b ? and i will strike these two off i have taken care of these two now i get a 011 its 01.1 so 0 remains as you can imagine it will come to the same ? abracadabra ?  so that ? s what this will turn out to be and we can decode it and see  refer slide time 13  01  suppose i give you this trie and i give you this encoded text  how much time does it take to decode ? clearly i am just looking at a bit and i am going to spend 1 unit of time with every bit i just look at that bit and go down one level in that trie.so it ? s basically length which you have to spend clearly so this is another trie  refer slide time 13  55  and you know this is a long piece of encoded text and you can figure out what this is  refer slide time 13  55  you can take this is an exercise so what is our aim in doing this ?  refer slide time 15  52  recall we wanted to build up a code in such a manner such that the total length of the encoding is as small as possible suppose this trie was specifying my code and once again i was encoding abracadabra  this has 29 bits how will you compute such a thing ? well let ? s quickly do that to make sure that you understand what is the frequency of each character ? a ? 5,b  2  c ? 1,d ? 1 and r ? 2 im using 3 bits for a  2 for b  2 for c  2 for d and 3 for r i am just counting the number of bits so this becomes 15  4,2 and 6.29 totally now suppose i had another trie say this one  refer slide time 16  06   you think this will have less or more ?  refer slide time 16  34  this will have less ? a ? was occurring 5 times here i ? m using 3 bits and i am using 2 bits here i ? m saving 5 bits for ? a ?  of course  i will have to compensate elsewhere c and d  there are 2 here and 3 there but c and d occur very infrequently so it ? s good this will have less than 29 we are also saving on r this you can check it will require 24 bits we have to design this in such a manner so that the number of bits required it as little as possible so let ? s try and understand what is it that we are given ? we are given the frequency of that character suppose i give you a piece of text you will count the frequency of characters and we are trying to compute the trie so that the length of the encoding we get is as small as possible  refer slide time 17  36  recall that each character is a leaf in our tree number of bits used to encode the character is its level number where i ? m assuming that the root is number 0 so if the ith character has frequency of f i and has level number of l i  then what is it that we are trying to minimize ? it is summation fi li so we have to choose a tree so that this quantity is minimized our tree will determine the li ? s fi is given to us we can not change the fi ? s we can pick a tree so that we can get appropriate li ? s so summation fi li is called the ? total external weighted path length ? of a tree it should be very easy to see why  refer slide time  19  51  external because we are talking about external nodes which are our leaves what is its path length ? the length of the path from the root to the leaf which is basically the number of levels ? weighted ? because we are multiplying it by the frequency and ? total ? because we are summing it up so we are viewing each leaf as having a weight which is equal to the frequency of the corresponding character the weights in the weighted are referring to this frequency from now on  i might call the same thing is weight or frequency this means the same thing here for instance given these weights or frequencies  f1 through fn  we wish to find the tree whose total weighted external path length is minimum that ? s what we want to do we are given the weight on the leaf we want to build a tree whose leaves will be these and who ? s weighted external path length will be minimum and will denote this minimum weighted external path length by this quantity so given ? n ? leaves with weights f1  f 2  f 3  ? fn ; your problem is to build a binary tree whose leaves will be these ? n ? leaves and which will have a minimum total weighted external path length so we have managed to translate our question of finding the minimum length in encoding such that the length of the encoded message minimum to that of designing an appropriate tree one thing i am going to assume is that when i write it in this way  f1 is smaller than f2 and these are in increasing order now let me show you what the algorithm is once again  my text is the same ? abracadabra ?  there are 5 characters and i have put down the frequency of these 5 characters  refer slide time 20  58   refer slide time 22  13  i have put red boxes around them these will have to be the leaves of my tree now what i am going to do at the very step is i am going to take the 2 with the smallest value which are the ones in the ends these are the two smallest ones i am going to combine them how am doing that ? i am going to create another node i am building up a tree now these are my leaves i make another node as the parent of these two and this node gets the value of weight of sum of these two now these two will disappear from the picture and i will just be left with 4 nodes and i will repeat the process so what is the process ? take the two smallest and combine them together into one take the two smallest and combine them together into a node and when you combine  you basically sum up their weights so at the next  we have an option .we can either combine b and r or we can combine r with this one  refer slide time  22  13  that we have created let ? s see which one i take i decide b and r to be combined into one when you have an option we can pick whichever you feel like so they have combined into one and what we are left is only three node now many times i will have to do this process ? if i started off with ? n ? leaves  how many times will i have to do this process ? every time you are reducing a node by 1 so it is  n -1  times not n by2 now which will we combine ? two and four clearly because they are the two smallest ones so you combine them into one and we get a six finally we have only two nodes left ? 5 & 6 they will get combined this is the picture we will combine them into one and these are 11.now how do i label ? i can just label whichever way i like to it really does not make a difference the length of the encoding was determined by the depth of these things this becomes encoding now and the claim is this is the best this will give you the same minimum whatever was the minimum for abracadabra will be achieved by this as you can see ? a ? which was occurring five times is getting only1 bit looks like it is the right thing to do so this is our final trie  refer slide time 24  07  this is my text this is the corresponding code as you can see for ? a ? you have 0 for b you have 100  the next three characters for r you have 101  the next 3 for c you have 3 and so on and on there should be a gap between this 101 and 0 because ? a ? corresponds to the last one and these are only 23 bits these is even better than the previous code which was 24 and this is the best possible which is what we will argue in this class can you do better than this ? let me take the same example and then build another trie how can i build another trie ? we recall that there was an option at each point let me take the other side of the option let me see what trie i get now here there are 2 minimums here there are 3 2 ? s  refer slide time  25  44   first i combined these two let me do that i decide to combine r with this one  refer slide time  25  49   i get a four  refer slide time 25  50  now which do i have to combine ? this four with this two  refer slide time  25  55   i combine the four and the two and then i get six finally i am going to combine this and this so this is the final trie i get it ? s the same piece of text once again ? a ? gets only 1 bit b gets 2 r gets 3 ? a ? gets 1 ? c ? gets 4 now and d also gets 4 you think it will be different from 23 ? it should not be otherwise the theorem i am claiming is false it should be the same you can count it will be 23 because this algorithm is computing the tree with the minimum weighted external path length since it ? s the minimum  it can not be smaller or larger than the other one because they are both the minimum so we now need to argue correctness why is this computing the minimum ?  refer slide time 27  40  why does this algorithm compute a tree with the minimum weighted external path length ? so there ? s no reason to believe its too simple to do anything useful let us see what the argument for this one is we will be proving it by using induction on the number of leaves which is same as the number of characters suppose i gave you only two leaves  then what is the algorithm going to do ? it will just combine them into one and so it will basically give you a tree with the three nodes  one root this will be 0 and this will be 1  refer slide time  27  54  and this will be something and this will be something and clearly it ? s using 1 bit for each of the character  you can not do better you can not take 0 bits for a character so it ? s true when you have only two leaves so we are going to assume the claim is true when you have  n -1  characters or leaves and we are going to show that it ? s going to be true when you have ? n ? characters or leaves so when we have ? n ? characters  what are we doing at the very first step ? we are taking the two characters with the smallest frequencies and combining them into one  refer slide time 29  22  we are taking the two characters frequencies f1 and f 2 and we are replacing it with one node of weight f1 + f 2 it ? s as if you have one character now of frequency  f1 + f2   so once it does that  beyond this point the behavior is as if it was given  n-1  characters with frequencies as f1 + f 2  f3  f 4  f5 upto fn beyond that the point it ? s the same behavior so beyond the point the algorithm behaves as if it had only  n-1  characters with frequencies f1 + f2  f3 all the way up to fn using our induction hypothesis it would have computed the best possible tree because these are only  n-1  characters now and it would have computed a tree on these  n-1  characters with total weighted external path length as this quantity this was the minimum quantity this was the notation we used for the minimum the tree computed by this algorithm has weighted external path length f1 + f2 + this quantity  refer slide time  32  02   this is what our algorithm has computed this is the weighted external path length computed by this huffmen ? s algorithm now we have to argue that this is the minimum possible it will not go lesser than this what we will argue is that the best solutions for f1 through f n equals f1 + f 2 + exactly the quantity that the algorithm had computed we will argue this now  refer slide time 32  56  this quantity that algorithm has computed is actually the best it is the minimum weighted external path length when your weights are from f1 through fn how do we argue this ? this will follow from the fact that in the optimum tree  by optimum tree i mean that tree whose weighted external path length is minimum so let ? s prove this fact suppose this factor is true  how does this implies this ? why does this imply ? let ? s do one step at a time suppose had proved this factor that in the best possible tree suppose we had prove that in the best possible tree that two lowest weights are siblings we will do that in a slightly more formal way let ? s assume that the two minimum are always siblings let ? s argue that if this is true  then it will imply this  refer slide time  34  18   we have our best possible tree and the minimum are siblings why does it imply that we found the best > that ? s because it implies the best over f1 through f n equals this this is the best tree we are going from here to here  refer slide time  35  28  which means that we have assumed this statement and we are proving that the best tree over f1 through f n has weighted external path length equal to f1 + f 2 + the weighted external path length of the best tree over f1 + f2 through fn so now we are kind of trying to mimic what we have already done let me now look at this tree now i am just looking at the remaining tree this is a tree  refer slide time  36  08  and let me give this node weight equal to f1 + f 2 now this is the tree over leaves f1 + f2  f 3 up to fn what will its minimum weighted external path length become ? if this is the best tree for the entire thing  for these values or leaves  this should be the best tree we are looking at the best tree for f1 through fn i am saying the following let ? s cut off the two leaves and just keep that let ? s give this a name of f1 + f 2 then this tree is the best tree for these choice of weights also suppose there was something smaller possible  then this  refer slide time  37  21  blue would not have been and best tree for these guys the best would be a green tree so suppose the black tree was the best  better than this red one  hindi  this tree is the best possible tree when you have leaves with weights f1 + f 2  f3  f4  f5  f6 this is the best possible tree so this red weighted external path length is this quantity then and so blue total external path length is red external path length + f1 + f 2  refer slide time 40  51  so which means blue weighted external path length which is this leaf is equal to this leaf which is equal to the best possible  refer slide time  41  28   what did we get in our previous algorithm ? we got the right hand side exactly so the algorithm is completing the best possible if this black is better than the red  then what have i done ? i have only increased the black by a quantity equal f1 + f 2 while this blue also differs from the red by this quantity f1 + f 2 if this black is better than this red  then this bigger black is also better than the bigger blue which violates our optimal case but why is this statement true ? why should it be the case that in the optimum tree  the leaves with those two lowest frequencies are siblings ? let ? s take the leaf with the lowest weight it will have the maximum level number suppose this leaf with the lowest weight comes in between and there is another leaf with a higher weight  this is not optimum so we have to swap these two so the total external weighted path length becomes minimum so the leaf with the smallest weight has to be at the last level let ? s look at its parent and let ? s look at its siblings which is this  refer slide time  43  53  leaf by the same argument this leaf is the second smallest weight because if it for anything else then once again you can swap and reduce so the leaves with the two smallest weights are actually at the very last level in all our examples you must have seen that happening they are all at the last level and they are siblings you just use this fact  make them siblings and then the problem reduces by 1 because now you have only  n -1  nodes how do we take care of  n -1  nodes ? it is the same way we took care of them once again you take the two smallest ones  make them siblings and continue so just this one property being exploited in this algorithm we got the very simple algorithm to compute the best possible trap so with that i am going to stop today ? s class after we have done priority queues  we are we are going to analyze these particular algorithm to compute its running time so i ? m leaving the bit about computing its running time today and i will take it up after we have developed the notion of paradigms data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 20 priority queues today we are going to look at the priority queue abstract data type i am going to motivate it with the scheduling example then we are going to look at what the data type is  we are going to see how to implement the priority queue with the sequence then the key thing today we are going to do is to introduce the concept of binary heap we are going to see how to do procedures for insertion in a heap and procedure called heapify which will be using in subsequent classes to see how to find to delete the minimum element in the binary heap and for other operations on heap  refer slide time  01  48  so we have a multi user computer system  that ? s the system in which there was multiple users who can submit jobs at different points in time  refer slide time  03  16  we assume that when a job arrives  we know in advance how much time the job is going to take on the particular system that we have further we are going to assume that the jobs can get preempted that is that job is running  it can be stopped some other jobs can be schedule on the processors and then later this job which was stopped can be resumed one policy which minimizes the average waiting time of job is what is called the srpt the srpt rule  its stands for shortest remaining processing time what this policy says is that the processor schedules the job which is the smallest at any point in time which has smallest remaining processing time at any point in time so to begin with this processor has the bunch of job  it will take the smallest job amongst that bunch and schedule it may be the job finishes then it picks up the next smallest jobs in this collection it has and schedules that one but suppose you have a job which is running and then in mid way some other job comes in which has the processing time which is smaller than the remaining processing time of this job  the one that is currently running if such is a case then we are going to interrupt the currently running job and schedule this new job that ? s given this is the setting in which interruption happens in which preemption happens this is just a motivation we are not going to be looking at this srpt rule any more carefully than this but if you were to implement this kind of a policy  what kind of a data structure would you need that ? s what we are going to look at  refer slide time  04  02  first we some how need to maintain the remaining processing time of the unfinished job  jobs that have not been completely finished they are still with us  they still need to be scheduled for some period of time we need to maintain that collection amongst these set of jobs  we need to find out the one which has the shortest remaining processing time because we need that so that according we can schedule the job according to the rule that we are following when a finishes we would like to remove it from this collection and when a new job arrives we would like to add it to this collection these are the kind of operations that we need to do on our data structures to be able to implement the srpt policies one data type which will let us do all of this  what ? s called the priority queues it is data type to maintain a set of elements each of which has an associated priority the priority queue data type supports the following operations the first operation is one of inserting an element the x is an element  we are going to insert it to our collection s  so that new collection is now going to be s union x of course this element has certain priority when we are inserting the element  we will also have to take care of the priority of that element the minimum operation returns the element of s with this smallest priority priority perhaps is not the best word here because when you say each element has a priority  you would like to say that you would like to get the element of the largest priority it ? s a bit of misnomer here but that ? s what we will work with  so in the scheduling example it made sense to remove the one with the minimum processing time remaining we will continue with the minimum  the priority really is the misnomer here and then we have the delete min operation the delete main operation returns the element with the minimum priority and also removes it from the collection the way minimum and delete min differs is that while minimum only returns the minimum element it doesn ? t delete it from the collection  delete min also deletes it from collection these are the three basic operations that the priority queue is supposed to support of course there could be many other operations  like for all other container classes that we have seen so far we have seen methods like is empty  is size and so on or size  is empty and so on one thing that we require on the priorities is a total order  let me come to that  refer slide time  08  11  recall the priority queue ranks its element by priority every element has a priority  priority need not necessarily be unique but they are totally ordered that is given two priorities i can compare them  i can decide whether one is smaller than the other or larger than the other or they are both equal there is the total order which will lets say denote by less than or equal to on the priorities these priorities need not be integer  they could be anything at all but there is definitely some kind of a total order on these priorities in particular this relation less than or equal to is reflexive that is priority k is less than or equal to k it is antisymmetric which means that if k1 is less than k2 and k2 is less than k1 then k1 is also less than or equal to k2 the k1 is equal to k2  this is the error here and k1 k2 should be the same and its transitive if k1 is less than k2 and k2 is less than k three then k1 less than k3 these are the properties of total order relation and we will assume that the priorities that we have satisfies the total order deletion the most general and reusable form of priority queue uses comparator objects what do i means by this ? recall that we said that in a priority queue  each element has priority associated with it and the priorities there is a total order on the priorities if i want to put any kind of an object in to my priority queue  i should have a mechanism of comparing the priorities of the objects in the queue  refer slide time  10  05  we can have such a comparator object which will help us to do this comparison so that comparator object all it does is it specifies the methods which will help us compare to priorities in this manner we can ensure that our priority queue that we would have one implementation of priority queue and we can use same implementation to store any kind of object because we would also specify this comparator object which would help us compare the priorities of any two object that we decide to put in the collection the comparator abstract data type would include methods like is less than  is less than or equal to  is equal to  is greater than  is greater than or equal to and whether it is comparable or not let ? s first look at an implementation of priority queue using an unsorted sequence recall the items that we are trying to insert in to our sequence or pairs of priority and our element we can implement the insert by using just say insert last  refer slide time  11  03  the insert operation of the priority queue  to do this we will just insert the element that is the item at the very end of our sequence in this case six was the element that was to be inserted let ? s say we went and put it at the very end this takes only the constant amount of time but if i do such a thing  if we always insert at the end irrespective of the value of the priority then our sequence is not ordered any more since it is not ordered according to the priorities  we are going to have problems when we are trying to find a minimum or when we are trying to delete the minimum element  the element with the minimum priority from this collection in that case we will have to look at all the elements of these sequences for instance if i have to find the minimum then i would have to start right from here and traverse the sequence till i reach the element with the minimum priority which is let ? s say one here that ? s to find the minimum similarly for delete min because i will have to get to here  i will have to remove the element and then i would have to find out the new minimum element so worst case time complexity of minimum and delete min therefore becomes ordering that ? s not very good  here all the insertion takes constant time we are saying that both for minimum and for delete min we are going to take order n time how about using the sorted sequence to try and implement a priority queue  refer slide time  13  20  now we are going to have a sequence in which the elements are sorted with increasing priorities that is the elements with the smallest priority is straight sitting right at the front of our sequence in which case minimum and delete min i am just going to take a constant amount of time the minimum element as i said is the element at the front of our sequence so you just be able to retrieve the minimum element in constant time similarly to delete it  you just have to delete the minimum element and then delete the minimum element from the front of the sequence this is what your sequence would look like now  note that the element with the minimum priority is sitting right at the front here but now the problem is if you have to do the insert operation if you have to insert lets say an element with priority 7  i will have to traverse the sequence till i come to the right position and put the element there in the worst case insert could now take order end time in this example i am inserting 8 which can be inserted either before this 8 or after this 8 in this case i am taking time proportional to the length of the sequence priority queues find many applications  refer slide time  13  34  i gave you an example of scheduling they are also used in discreet event simulation and they are used as a building block for many other algorithms we are going to be seeing more algorithm in this course lets says dijkstra ? s algorithm which require the priority queue data structure to be able to efficiently implement the algorithm today what we are going to see is how to use a data structure called a heap  to implement a priority queue we saw the two methods to implement the priority queue and unsorted sequence and sorted sequence and both of them had their problems in case of unsorted sequence the delete min operation and minimum operation would take order n time and in the case of a sorted sequence  the insert operation would take order in time while the other operations are constant time operation we would like to have a data structure which would do all these three operations insert  delete min and minimum very efficiently  refer slide time  14  39  what is a heap ? when we say heap we typically mean what ? s called a binary heap binary heap is a binary tree that stores the priorities or the priority element pairs at the nodes in the rest of the class i am just going to show the nodes as containing the priority of the element and the element is sitting somewhere here also they could be storing only priorities of the priority element pairs now heap has to two properties one is the structure properties in this binary tree all levels are full this is level zero  it can have only one node  it has one node level 1 can have 2 nodes  it has 2 nodes level 2 can have 4 nodes  it has 4 nodes level 3 can have 8 nodes it has only 5 nodes so all levels except the last levels are full and the last level is what we will call left fill which means that all the nodes on the last level are as left as possible they could be 8 elements there there only 5 but these 5 nodes would be the ones which are the first five if i were to move left to right that ? s the structural property of a binary the other properties what i call a heap property the heap property simply says the following the priority of the node is at least as largest that of its parent for any node its priority has to be larger than the priorities of its parent this picture here that satisfy both of the properties  structure as well as heap consider any node  its priorities is at least as larger then the priorities of its parent you can take any node i can restate this  i can also say it in the following manner the priority of any node is less than or equal to the priorities of its children sometimes we will also think of it in this manner  priority of any node is less than or equal to the priorities of its children there might be two children  there might be only one child as is the case here in this case priority of this node has to be less than the priority of its lone child let ? s look at example which are not heap  refer slide time  17  01  this is not a heap because if you look at this node  we require that it have a priority which is larger than the priority of its parent  at least as large as the priority of its parent but its priority is 18  its priority is 19 this violates the heap property this does not violate the heap property but as you can see this node is empty  so this last level is not left filled we would like that if there were only 4 nodes at the last level then they should appear as the first 4 nodes of this binary tree  refer slide time  17  24  this appears as the first four nodes of the last level of this binary tree  refer slide time  17  51   how does one find the minimum element in a heap ? suppose i give you a heap what ? s a heap ? recall as this two properties  one is the structural property the other is the heap property suppose i give you a heap  how does one found the minimum element ? the claim is the minimum element  the element with the smallest priority always sits at the top of the heap the top of the heap i mean the node here at the root and as you can see such as the case in the picture the element with this minimum priority is the element by 11 and its sitting in top of the tree why is this the case ? why can ? t the minimum not be some where else ? if it is not at the root of the heap or at the top of the heap  it could be somewhere in the middle  somewhere inside the heap but then it has a parent and the heap property says that the priority of the parent is at least as large as the priority of the particular node then the parent would have a larger priority the heap property says that the priority of the parent is no larger than the priority of the node now if such is the case then the parent would have even smaller priority and so the element that i was talking of was not the one with the smallest priority just recap what i said  if the element with the smallest priority was sitting else where in the heap then it would have a parent with smaller priority and this would violate the heap property this larger should really leads smaller  it would have parent with the smaller priority and that would violate the heap property the minimum can be done in constant time because we just need to go to the root element to find the element with the smallest priority what is the height of the heap ? suppose i give you a heap on n nodes  what is its height going to be ?  refer slide time  20  08  recall our discussion on binary tree  if you have a complete binary tree of height h then it has exactly two to the h plus one minus one nodes if we have a heap of n nodes with height h  note that since the height of the heap is h  it has more nodes than a complete binary tree of height h minus one a complete binary tree of height h -1 has so many nodes in it the number of nodes in the heap is larger than the number of nodes in the complete binary tree of height h -1 a complete binary tree of height h has 2 to the h plus one minus one nodes and the number of nodes in the heap is less than or equal to this quantity this inequality holds  n is strictly larger than the two to the h minus one and less than or equal to two to the h plus one minus one i can replace this as n equals the floor of the log of h this notation here really means that log of h which need not be an integer  we are just rounding it down to the nearest integer hope this is clear to everyone this is the mistake  this should read h equals log of n the height of a heap is the log of the number of nodes just interchange this h and n  this is error on this slide if n lies between two to the h and two to the h plus one minus one then h is log of n how does one implement the heap ?  refer slide time  22  04  recall that till now we were saying that heap is this kind of a binary tree we can of course implement the heap using the binary tree but it ? s much simpler to implement the heap using an array let ? s see what i mean here this is level zero of my heap  this is level one  level two and level three of the binary tree corresponding to this heap i am going to put these nodes of binary tree in to an array with the root node sitting at the first location in the array my array is going to be indexed starting from location one so 11 comes here 17 and 13  the next level would follow and we would go left to right 17 would be the next element  13 would be one after that then 18  21  19  17  43  23  26 this is level zero of the binary tree  this is level one of the binary tree  this is level two  this is level and this is level three of the binary tree what ? s the advantage of putting the nodes of a heap in to an array like this ? suppose i look at a node at location five lets say  node 21 and i want to find out the parent of this node in the heap then all i have to do is take 5 divided by 2 take the floors of 5 by 2 floor is 2 the parent of 21 in this heap is going to be 17 which is the case here we can do it for any other node let ? s take node 26 the 26 is at location 10  10 by 2 is 5 whose floor is also 5 the parent of 26 that location 5 and is 21 you can quickly determine the parent of any node  if you know the location of the node parent is just at location i by two if the node is at location i conversely if the node is at location i and i want to figure out its two children then the two children  the left child would be at location two i then the right child would be location two i + 1 we can work out this math it will be very easy  i will just show it with an example here if i look at node thirteen it ? s at location three  its two children then should be location 6 and 7 two children are 19 and 17 and they are at location 6 and 7 given the location of any particular node  i can just quickly figure out what is the location of the parent  what are the locations of the two children of that node those are the only thing that are really need to do in heap and the heap property is really saying that if i is the location  parent of i is the location of its parent and a of parent of i  a is the array which is holding these priorities so its priority of the parent of i the priority of the parent is less than or equal to the priority of the node itself that ? s what the property is we implicitly are maintaining the tree links the parent child relationships are getting implicitly maintained the children of a node i are at location two i and two i plus one and this is very useful in binary  in multiplying by two just corresponds to a left shift and multiplying by two and adding one is equally simple  refer slide time  25  53  one can quickly figure out the children of a node or also the parent of the node by just doing one left or right shift and an increment operation this makes the operation really fast  when you trying to access the parent or the children of a particular node let ? s now see how one would insert an element in to the heap  refer slide time  26  54  till now the only operation we have seen is to find the minimum element in the heap and that we said can be done in constant time and because minimum element in a heap always sits at the root of the heap suppose i wanted to insert twelve in to this heap what would i do ? right now this heap as 3  7 and 12 nodes in it if i insert 12 this heap is going to have 13 elements in it if it has 13 elements in it then structurally i should have another node here that ? s the first thing i would do i would first create a node here and let me now put 12 in to it  refer slide time  27  28  of course structurally this does satisfy the structural property of heap but it is not heap because it violates the heap property this node should have lesser priority than its two children it does not  it has higher priority than this child we need to take care of that since this is lesser priority than this we need to swap this thing  refer slide time  27  55   refer slide time  28  08  we do that in this manner we swap this two element now the heap property is satisfied here  no problem this has lower priority than its two children but it ? s violated here this does not have lower priority than its two children we should then swap this and this  we do that heap property also now satisfied here since we change the content of this node  could it be that the heap property is violated at this node let ? s look this has priority eleven  this has 17  this has 12 this has lesser priority than both its children  the heap property is satisfied here no problem at all we are done with the insertion of 12 all we did was create a new node  put twelve here and then move twelve up  so as to maintain the heap property we saw that 12 had a lower priority than its parent so we swap 12 and its parent then once again we saw that 12 had reached here 12 had a lower priority than its parent so once again we swapped 12 and its parent 12 now reached here  but now 12 does not have lower priority than its parent  so we stop let ? s see if we were to insert another element let me insert 8 in to this heap  refer slide time  29  24  once again 8 would come at this location  so i have put in 8 here 8 has a lower priority than its parent this violates the heap property  so we would swap 8 and 17  refer slide time  29  34  once again 8 has the lower priority than its parent  so we would swap 8 and 12 once again this has lower priority than its parent so we swap 8 and 11 and now we were done this is now a heap with 8  the element that we inserted last now coming at the root of the heap and in fact it should come there because this is the minimum priority element in the entire thing let ? s look at insertion again from the slightly different point of view  refer slide time  31  48  we again have the same heap as before  we are trying to insert 12 first we enlarge the heap which means that we create the new node where we create the new node because we know that the new heap now has 13 elements in it and so this is what it structure should be like now we consider the path from the root to inserted node which is this slight colored path so this was the inserted node and we just march up  we just follow  go from this node to its parent  to its parent and to its parent this is path from the root to the inserted node and on this path  we find the top most element with the priority higher than the priority of the inserted element what are the nodes on this path ? these are these three nodes  they have priorities 19  13 and 11 the top most element on this path with higher priority  the element we are inserting is priority 12 this is the top most element but it has priority lesser than 12 this is the next highest element and this has priority more than 12 this is the top most element of the path with higher priority than that of the inserted element this is the element  so what are we going to do now we are going to insert 12 at the location but where would 13 go ? 13 would get pushed down and where would 19 go ? 19 would get pushed down like this  refer slide time  32  03  this is exactly the same procedure as before if you look at the slide that we got earlier  the elements where at the same location except there we started 12 here and we bubbled it up now i say that i am going to directly figure out where 12 is going to come and i am going to move elements down let ? s argue correctness let ? s argue that the procedure of the insertion is really correct and for this we look at this other view of insertion that we saw in the previous slide  refer slide time  33  37  the first claim is that the only nodes whose contents changes on the ones on this path this is the path that we considered which is the path from the newly inserted node to the root and we are changing only the contents of this we are in fact only changing the contents of this part of the path if the heap property is getting violated  the heap property can be violated only at the children of these nodes it could that for this node  since we are modifying this content it might be that the new priority of the parent is larger than the priority of this guy or new priority of the parent of this node is larger than the priority of this node that would be violation of the heap property so it is only for these two pink color nodes that the heap properties might be violated  refer slide time  33  45  what is happening ? what are the new contents of the parent of 31 and 17 ? 31 is 19  what is the new contents of this going to be ? if you recall 19 moved down  13 was coming here and 12 was reaching there the new content of this node is 13 which is only going to be less than this the new content of any node are only going to be either the newly inserted element or the parent of that node the new content of this is going to be the content of its parent and the content of the parent is already smaller and has the lower priority that is the priority of this guy the priority of each node is only going to be reduce  so the priority of these guy is going to reduce because 13 is going to move here the priority of this guy is going to reduce because newly inserted element 12 is going to come here and recall from our choice of path that this was picked as a node with higher priority than the priority of the element that was getting inserted this is higher than this the priority of this is also going to reduce as the consequence of insertion procedure the priority of all of these nodes only going to reduce the consequence of insertion procedure and ones the heap property would not get violated  refer slide time  35  56  these are going to be the new priorities of these nodes we said that heap property could be violated for this guy or for this guy this should also have been pink  it could be violated for this or this but earlier its parent had a priority 19 now it has a priority 13 earlier the parent of this guy had a priority of 13 now it has a priority of 12  the priority is only reducing if there were only reducing then earlier if this had a priority which was smaller than the priority of this guy  it continues to have priority which is smaller than the priority of this guy if earlier this had a priority which is smaller than that of this guy  it continues to have a priority which is smaller than the priority of this guy heap property is not violated at all and so what we get after insertion is still a heap i am now going to look at another procedure called heapify which we are going to use as i mentioned at the beginning of the class  we are going to use for the other methods that we have to do on a heap  refer slide time  36  04  i am now assuming that my heap is kept in an array a and i is an index in to this array so heapify take the parameter as an index in to the array a then the binary tree is rooted at the two children of i  left i and right i are the two children of i the binary trees rooted at these two locations are already heaps but it might be the case that the heap property is violated at this node i that is a  i  might be larger than its children a  i  might be larger than its children and this violates the heap property now heapify is the method which tries to maintain the heap property  makes the binary tree rooted at i a heap by suitable modification and will see what this is in a second let ? s look at this structure this is not a heap because this node right here at the very top has priority which is larger than the priorities of its two children  refer slide time  38  47  but this binary tree  if i were to just restrict myself to this part which is a heap why it does satisfy the heap property ? every node has a priority which is smaller than the priority of its two children this has smaller priority than its two children  this has smaller priority than its two children  this has smaller priority than its two children similarly this here is a heap  structurally as well as it does satisfy the heap property each node has priority smaller than its two children these two are already heaps but this entire thing is not a heap because the heap property is getting violated at this node  refer slide time  38  23   this does not have priority smaller than the priority of its two children and some how we want to make this entire thing a heap we can invoke the heapify procedure heap property is violated at node with index one which is this node but the sub tree is rooted at two  two is this and three is this so sub tree is rooted at two which is this and this are heaps we would invoke the heapify procedure with one because we want to make this entire thing a heap for heapify remember we require that whichever node heapify is invoked on  the sub tree is rooted at the two children of that node are already heaps that ? s a very crucial part for heapify only then we would heapify it if heapify is invoked at one  it can be invoked at one only because the sub trees rooted at two children of node one  this and this the sub tree is rooted here are already heaps let ? s see how heapify works heapify is going to look at the two children of this node where the heap property is correctly violated you have to look at the two children which are these 10 and 11 and it would take this smaller of these two children and swap it with 17 the smaller is 10  it would swap 10 with 17 now the heap property heap property is valid at this node this has priority less than the priority of its two children but the heap property is violated at this node because this does not have priority smaller than the priority of these two children once again we are going to do the same thing we are going to look at the two children  take the smaller one amongst them which is 16 and swap it with this the heap property is now valid at this node but is the heap property valid at this node ?  refer slide time  40  39  because we also changed the content of this node it is  because now when i look at the two children of this  they are 23 and 43 both of which have priority higher than 17 and so the heap property is violated here now this entire thing is heap  this is the heap because the heap property is now valid at every node in this tree recall  we have changed only the contents of these nodes that ? s the heapify procedure once again to recap  the heapify procedure can be invoked at the node i  only if the two children of this node or the sub tree rooted at the two children of this node are already heaps once again we will present the second view of heapify which will help us prove the correctness of heapify very easily  refer slide time  43  55  heapify essentially is tracing a path down the tree in our previous example  this path was this blue colored nodes these were the node whose context we modified if i look at the last node on the path suppose i call it node j then the left and the right child of j have priority which was larger than the priority of node i i is this node  refer slide time  42  22   i is in our example is one so 43 and 23 are both larger than 17 all elements on this path have lower priority than their siblings what are the siblings ? sibling of 16 is 21  sibling of 10 is 11  17 does not really have a sibling 10 is less than 11  16 is less than 21 and why is this true and why is that the case that the priorities for all nodes on this path have priorities less than the priority of the sibling that ? s because of our choice of the path we came left because we compared 10 and 11 and we picked 10  so that we could then swap it with here and then when we came here  we compared 16 and 21 and we picked 16 just from the way we constructed our path this statement really follows what are they really doing in heapify ? in heapify what we are really doing is that we are moving these elements up  let me show you how i am just showing it in one step now but what we saw earlier was a sequence of step this was the net result  10 moved up  16 moved up and this 17 really came at location j it came at this location this was the net result of our heapify step  refer slide time  44  00  now once again the same thing is happening 16 was here  it was less than its sibling and it moved up here now 16 is less than 21  similarly 10 10 was less than 11  10 was less than its sibling  10 moved up here now it has priority less than its child and 17 which was here because of this property that the last node on the path in which both of its children have probability which was larger than the a  i   the 17 is going to have lower priority than both of these while the contents of these three nodes have changed  the heap property is satisfied at all of these three nodes this is going to have lesser priority than its two children because of this property that we mention here this is going to have lesser priority than its two children because of this priority  this 16 which was here which was earlier a sibling of 21  had a lesser priority than 21 now it has become a parent and similarly for 10 10 will have a lesser priority than this guy because this was the smaller priority node amongst the two siblings  10 and 11  refer slide time  45  36  this essentially establishes the correctness of the heapify procedure what you get as a result of heapify is still a heap heapify is a really a mechanism to rebuild a heap if due to our operations  the heap property is violated at a particular node then we can heapify at that particular node assuming of course that the two sub trees  the two child sub trees which are rooted at that node have the heap property then we can do heapify on that node and get a larger heap let ? s do a quick runtime analysis of the various procedures that we have seen today  refer slide time  47  11  recall that a heap of n nodes has height order log n when we are inserting an element  the insertion procedure was that we would create a new node and then we would move the element up the heap in the worst case  the element might move all the way up to the top if its moves all the way up to the top then we require time proportional to the height of the heap but an n node heap has the height at most log n we require at most order log n steps to do an insertion the other procedure we looked at today was the heapify procedure in the heapify procedure on the other hand  the element moved down the heap we took the element so if we are invoking heapify at node i  we looked at node i we looked at two children of node i  we took the smaller of the two children and swapped it with node i and continued the process till the element came down and the heap property was eventually satisfied in the worst case the element might moved down as many steps as the height of the heap the height of the heap is only order log n in the worst case  the time taken for the heapify is also order log n the two operation that we looked today insert and heapify  both require only order log n time we also looked at the operation of minimum which was just to find the minimum element in the heap without removing it just to find the minimum element  we could do it in constant time because all we have do was to go to the root element of the heap and return the value of that  return the element stored at the root minimum takes constant time and insertion takes order log n time heapify also takes order log n time and in the next class we are going to use heapify to remove the minimum element from the heap and we will be able to do that in order log n time too with that we end to today ? s discussion in the next class we are going to see how to use heapify to remove the minimum element  the delete min operation we also going to see how to create a heap quickly in order n time and we are going to see how heaps can be used to do sorting efficiently.thank you data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 21 binary heaps we will continue our discussion of binary heaps in this class recall that in the last class we saw what a binary heap was  we also looked at the operations of insertion and heapify on a binary heap to recall a binary heap has two properties two critical properties  one is the structural property where we require that the structure of the heap be similar to that of a complete binary tree so all the levels except the last level of full and even the last level is what we called left full that is all the nodes in the last level are as left as possible the other property was the heap property which was that for any node  the priority of that node should be less than or equal to the priority of its two children  refer slide time  02  05  so today we are going to look at the operations of deleting the minimum element from a binary heap and building a heap it is very easy to build a heap using repeated insertions but today we are going to do a build operation  it just takes linear time then we are also going to see how to use binary heaps to do sorting and that procedure is called heap sort so recall that the minimum element is the one at the top of the heap  refer slide time  02  35  so one way of doing a delete min is to just remove this element and then we have an empty space at the root so we have to fill up this empty space and to fill up the empty space it would be natural to promote one of the two children of this root element to fill this empty space so if you were to do that then this empty space would move down into the tree  move down the tree and it might end up at any particular location in the last level so that the resulting tree might not be left filled so just to illustrate what i am saying here let us look at this picture  refer slide time  03  14  we are trying to delete a minimum element from the heap which is eight so suppose i were to do that so this creates an empty location here  now i am going to take the smaller of the two children element and push it up here  move it up here so 10 is the smaller one i move 10 up there  so i have an empty location now here  refer slide time  3  36  so it is natural to take the smaller of these two and move it up there and this moves the empty location here and now it is natural to take the smaller of these two  23 and 43 and move it up there at that empty location so that now we have an empty location here  refer slide time  03  59  now while this does satisfy the heap property this is not a heap because it doesn ? t satisfy the structural property of a heap the elements at the level are not left filled there is an empty slot here so we can really do delete min in this manner but this is close to what we will be doing in our delete min and let ? s see what is the right procedure for doing a delete min so we need to get rid of 8  refer slide time  04  35  now when we get rid of 8  the number of elements in this heap is going to reduce so structurally this heap should not be having this node any more here so it makes sense to move this last element here  so we knock off eight and then we move this last element at this place and remove this node now structurally this is a heap but it doesn ? t satisfy the heap property now so to make sure if it satisfy the heap property we have to adjust the contents of the various nodes but now note the following interesting thing this sub tree is a heap and so is this sub tree is a heap the heap property is violated only at this node  this does not have a priority less than the priority of two children so but we know for procedure for taking care of this problem if this is a heap and this is a heap  all we have to do is to run a heapify procedure on this particular node so we just have to do heapify one and recall what does heapify one do heapify one we saw also saw this in the last class heapify one would take the minimum of these two which is 10  swap 10 and 17 the heap property is valid at this node but it ? s now violated at this node so once again we are going to take the smaller of its two children 16 and swap it with 17 now the heap property is valid at this node but while it ? s also valid at this node because if i look at the two children  they are both larger than 17 so this entire thing is now a heap and we have deleted the minimum element so this is the delete min procedure to recap in the delete min procedure we are going to remove the minimum element  take the last element of the heap which means go to the last level and take the right most element in the array implementation this just corresponds to the last element in the array take that element and put it at the root and then just do a heapify of the root  heapify one so this would make this entire thing a heap once again  refer slide time  07  00  so this was the delete min procedure fairly simple all it required was the heapify procedure we are now going to see another application of heapify procedure and that is to create a heap one way of building a heap is to just repeatedly insert the elements in the heap so we could insert the first element  second element and the third element and so on and on and how much time does this procedure take ? so recall that to insert an element we take log of the number of elements that are already in the heap so to insert the first element we will take order log one time  for the second element we would take order log two time  for the third we will take order log 3 time and so on and on all the way up to n  if you were to insert n elements the last element would take order log n time to insert so if you some up this series it ? s exactly log of n factorial which is the same as n log n this simple minded method of creating a heap by repeated insertion takes order n log n time so we are going to look at this other method of creating a heap which is going to take only linear time and the key to this is to create the heap bottom up so note that this point  this is not the heap these are the elements that were given to me  i just put them at arbitrary locations in this heap so in the array so it just means that since we implementing heaps using array  so we just put all the elements that we have to make into a heap  we just put them into the array now we are going to create the heap bottom up  so note that these are already heaps look at this sub tree rooted here which is just this node itself  this is a heap because it doesn ? t have a child  any children so it does satisfy the heap property so these individual leaves are heaps so no problem here now what we are going to do when we say we are going to create the heaps bottom up is we are going to make a heap out of this so we would want that the sub tree rooted at this node also becomes a heap what is the sub tree rooted at this node ? it ? s this sub tree how will we make this into a heap ? this is already a heap  we have to make this entire thing into a heap so we will just run a heapify procedure on this and that is what happening here this element would be at location n by 2  floor of n by 2 we are going to run a heapify procedure on this file what would heapify do ? heapify would just compare this with its two children whichever is the smaller child  so it has only one child  so it will just take this smaller child and swap it here now this entire thing is a heap now we are going to look at this element  so we are going to make a heap out of all of these four sub trees now so we are basically go to this element  we are going to look at the sub tree rooted at this element and make it a heap so what is a sub tree rooted at this element ? it has these 3 nodes in it 13  11 and 19 how do i make a heap ? i run heapify on this to run heapify the first thing that heapify does is it takes this  looks at the two children  takes the smaller of t children and swaps it with this so i am going to make a heap out of this the smaller of the two children is 11 so i am going to swap 11 and 13 so this also now becomes a heap similarly i now need to make this  the sub tree rooted here a heap the smaller of the two children is 8  i swap 8 and 21 now i need to make the sub tree rooted at this node a heap  these are the two children i want to make this a heap but note this is already a heap this is a heap  this is a heap and this entire thing is a heap because the heap property is also satisfied here  refer slide time  11  15   so now i have these 4 heaps  these are all heaps now i am in a position to run a heapify operation here why run a heapify operation here ? this is a heap  this is a heap so i can now run a heapify operation on this one and make this entire thing a heap to see the advantage of heapify  this is already a heap  this is already a heap so i can make a heap out of this so to make a heap out of this when i run heapify what does it do ? so i am going to make the sub tree rooted at this node a heap now to do that i have to take the smaller of these two and swap it there so that is 11 and 26 swapped and now recall we are doing heapify so heapify would bubble up the element all the way to the bottom if need be so as a consequence of this swap  the heap property is violated at this one this node now has a larger priority than its two children so once again we are going to take smaller of these two and swap it with this and now this entire thing is a heap sort this was just a heapify operation on this node the heapify operation on this node just doesn ? t stop with one swap it will swap and if need be bubble the element down and that ? s what happened here now i need to run a heapify operation on this node to make this entire thing a heap this is already a heap  this is already a heap  i need to make this entire thing a heap so once again it will take the smaller of these two which is 8 in this case and swap it with 43 and now this is not a heap because the heap property is violated here so i need to run a heapify essentially on this one or actually we are just part of the larger heapify  so we are doing the heapify we took the smaller of the two children swapped  now we come to this node if the heap property is validated here which it is  i will take the smaller of the two children  swap with it 43  so 21 and 43 get swapped so now this is a heap  this entire thing is a heap and all that remains is to make this entire thing a heap the heap property is violated here so i run a heapify operation on this the heapify operation will take the smaller of these two nodes and swap it with 23 so it ? s going to happen now  8 and 23 get exchanged now the heapify continues it just doesn ? t stop with this because now this is not a heap we have changed the content of this node so we are going to take the smaller of these two and swap it with 23 and then now this is not a heap so we go and take the smaller of these two and swap it with 23 so we get that since this does not have any other children we are done so this entire thing now becomes a heap so that was the build heap procedure the build heap procedure all it is saying is essentially just go down  so recall this was 1  2  3  4  5  6  this is how the elements are laid out in the array if this is element n then recall that its parent is going to be at location n by 2 so this element on which we first have to run the heapify procedure is at location n by 2 so we first run the heapify on this then we run heapify on this  then we run the heapify here  then we run the heapify here and after we have done all of these we know that these are already heaps so we can now go and run the heapify here and then the heapify here and then the heapify here the right order of running heapify is really to first run the heapify on all of these nodes then on all of these nodes and then on all of these nodes and that is exactly what is being done here through this single for loop we first run the heapify on all of these then on all of these then all of these of course this here is saying that you first run the heapify here then here  then here  then here  refer slide time  15  10  this is not necessarily required you could also run the heapify in this order but remember that the heapify has to be run first on this level only then can you proceed to run the heapify here why is that ? that is required because to run the heapify on this node these two should already be heaps and this can be a heap only after you have run a heapify here so this is the entire build heap procedure we are using the heapify sub routine crucially which takes as parameter the location at which you want to run heapify  refer slide time  15  53  so let ? s analyze the build heap procedure so to prove correctness and i am not going to discuss it in detail here you can do an induction on i and the induction claim would be that all trees rooted at locations m which are more than i are already heaps so given this induction statement  with this induction hypothesis you can do the induction step and prove the correctness of the build heap procedure a simple minded approach to do the running time computation would just be as follows there are n calls that we make to the heapify procedure or n by 2 calls that we make to the heapify procedure each one of them we saw in the last class takes in the worst case order log n time so the total time taken by the build heap procedure is n log n but we said the build heap takes order n time and we can actually prove a better bound of order n the intuition for this is most often we are doing the heapify procedure on heaps which are very small and let us see what this really means so let ? s define the height of a node as the length of the longest path from the node to a particular leaf  refer slide time  17  22  so the height of this node is one  the height of this node is 2 and the height of this node is 3 we will call the leaves at height zero  we will say that the height of the leaves is zero so 1  2 and 3 and the height of the tree is just the maximum height of any node which is therefore 3 so the height of the tree is the same as the height of the root and its 3 in that example now the time for heapify  if i do a heapify on i on location i  the time for heapify is just the height of the sub tree rooted at that node i because in heapify as you recall  we might have to move the element all the way down but if the height of the sub tree is some quantity h then we can only move it h levels down and so the time is proportional to just the height of the sub tree this we will have to remember that the time for heapify on i is just the height of the sub tree rooted at i we are also going to assume that the number of nodes in the heap is of the form 2 to the k  1 so that it is a complete binary tree this will only help us simply the analysis  it is not really required to we can also do without this  refer slide time  18  48  if the number of nodes was of the kind 2 to the k-1 then we know that there are roughly n by 2 nodes of height one and for each of these nodes  we require only one swap these are height one nodes  the sub tree rooted at these nodes is height one so we require only n by two swaps for the n by 4 nodes at height 2  the number of nodes is half the number of the nodes at height 1  height 3 the number of nodes is half the number of nodes at height 2 and so on and on so at height i there are n by 2 to the i nodes and for each of these nodes you require at most i swaps so the total number of swaps that are required by swaps i mean the time  so you can count the time required by heapify in terms of the number of times you have to swap the location of two elements the time required by the heapify procedure is just proportional to this to the number of swaps so we are just counting the number of swaps what is the total number of swaps required then ? it is n by 2 times 1 + n by 4 times 2 + n by 2 to the i times i so this is what the sum would look like  it is basically n + 1 or n times summation i over 2 to the i  as i goes from 1 through log n why log n  because that ? s the height of the heap it is this sum that we are really interested in and now this summation here  summation i going from 1 through log n i over 2 to the i is just 2 and i will show you why in a second so if this is just a constant then this entire thing just becomes order n so this is what we said earlier  heapify all though we are making n calls to the heapify procedure  most of the calls are being done on heaps which are very small n by 2 calls have been done on heaps of size of height 1  n by 4 calls have been done on heaps of height 2 and since the time taken for heapify is proportional to the height of the tree on which the heapify procedure is being called much less time is spent here then just saying n by 4 log n which is a crude upper bound  refer slide time  21  37  i have to argue that the summation i over to 2 to the i is 2 and this is a simple argument for that so recall that summation x to the i  i going from zero through infinity is 1 over 1  x  if x is less than one now if i just differentiate this i get i times x to the i -1  i going from one through infinity i have dropped the i equal zero term because that would now contribute to zero the differential of the right hand side is 1 over 1 x square now i multiply both sides by x to get i times x to the i equals x over 1 x square and now i plug in x equals half so i get i over 2 to the i  i going from one through infinity equals 1 over 2 divide 1 over 4 which is equal to 2 and if you recall what we required was that this sum go from one through log n so that then is only going to be less than or equal to 2 or strictly less than 2 so the sum from 1 through infinity is 2 so that completes analysis to show that one can build a heap in just order n time the key thing here was that we build heap procedure went bottom up  it first created smaller heaps and then combine them into larger heaps by just using the heapify procedure repeatedly  refer slide time  23  09  today we have seen how to delete the minimum element from a heap we have also seen how to build a heap in linear time  in order n time now we are going to see how to sort using heaps so give you a bunch of elements and i want to put those elements in increasing order so what would be one way of doing it using a heap ? i could just do the following  i could take those elements  build a heap using them then i could repeatedly remove the smaller element from the heap so that is exactly what i have said here i first create a heap  this can be done in order n time as we just saw then i repeatedly remove the minimum element from the heap till the heap becomes empty so how many elements would i have to remove in all ? there are n elements in the heap  i am going to be removing n elements in all and each of the delete min procedure  each of the delete min steps requires order log n time so i do n steps here  so the total required would be order n log n and this requires order n times  so the total time required is order n log n now suppose you have to do an in place sort by in place sort i mean that you are given an array of n elements and you are given no other space this is all the space you have and you just want to swap the elements in this array so that finally you have a sorted sequence recall that our heaps are implemented using arrays so we first create a heap  for that we did not require any additional space starting with the initial array  just create a heap in that array now the contents of the array are basically 8  10  11  12 so on and on  in this order sitting in the array now when i delete the minimum element  where does it go ? where would i put this element  because i don ? t have any additional space so now what we are going to do is when we delete this element we are going to put it at the end of the heap so recall that for deleting the element  i am going to move this element here to the top  so which means that this location in the array is now available to me it is free so i am going to use this location to move 8 to put 8 in essentially i am swapping 8 and 31 and now this location is really not part of the heap the heap is this now and actually this is not a heap because it doesn ? t satisfy the heap property so to do a heapify  to make this into a heap so which means that the same as before i take the smaller of the two children ? s  swap the element with that now again heap property validated here  smaller of these two and swap and now this is again a heap so all i have done is  so this was essentially the delete min procedure i have done a delete min  i have removed 8 but i have kept the 8 in my array at the very end so this is in place sorting we are not using any additional space  we delete the element but then we keep it in the array in an empty location and now once again we do a delete min so we delete 10 and 19 is going to come here so this location is going to become empty so ten and nineteen essentially are getting swapped this location now goes away from the heap  so this is not marked which essentially means that this is the part of my heap of course i once again need to ensure that the heap property is satisfied  so i am going to do the swaps  11 and 19 get swapped  13 and 19 get swapped and 10 and 19 are not going to get swapped because this is not part of the heap any more  the heap is just this so the heap property is satisfied here because this is only one child and it has priority less than the priority of its child  its lone child so this is now a heap so once again i do the delete min  so 11 is going to be deleted  26 is going to come here  11 is going to come here because this location is now going to be empty and so this is what is going to happen this location is going to go out of the heap now because the heap is only this part and once again we are going to do the swaps we are going to do a heapify at the root so as to convert this into a heap and that is what we are doing now and now this is a heap as you can see the last element is the minimum element the second last element is the second minimum and so on and on eventually this is what is going to happen  we are going to have a sorted sequence but in decreasing order and that can easily be reversed in linear time to get a sorted sequence in increasing order so i will just continue the procedure  we swap the last element with the root and then this element goes away from the heap now we are just going to do the swapping so 13 and 29 get swapped  here the smaller of these two  17 and 19 ; 17 is going to get swapped with 29 and now this is again a heap furnace now the minimum element is sitting here  13 is going to swapped with the last element  this element is going to go out of the heap now it fades away out of the heap and now we are going to ensure the heap property by doing the necessary swaps so smaller is 16  it got swapped  smaller is 21 it got swapped and now this is a heap because these two are not part of the heap so heap is only this thing  this is the smart so once again you swap the last element in the heap with that root element so 16 comes here and 26 comes there  this goes away it is not part of the heap any more and then we are going to ensure the heap property by doing the necessary swaps so 17 and 26 get swapped and now the heap property is violated here because this has higher priority than one of its children so 19 and 26 are going to get swapped and now this is a heap this again is now going to swap with the last element  17 and 31 get swapped  17 is going to drop off from the heap  17 drops off and now we are going to ensure that this entire thing is a heap by taking the smaller of its children  swapping heap property validated  take the smaller of these two and swap the heap property is now valid this is a heap so this is a minimum element  swap it with the last element  19 and 29 get swapped this element goes away from the array  gets dropped and now we have to ensure that this is a heap the heap property is violated here  take the smaller of these two  21 and 29 are swapped the heap property is still violated ; take the smaller of these two  23 swap it with 29 this entire thing is now a heap so we are going to remove the minimum element which is 21 we remove it  31 goes in this place and since this location is now empty  21 comes at this location now we need to ensure that this is a heap  21 dropped away now take the smaller of these two children twenty three  thirty one swap 23 and 21 and then take the smaller of the two children and swap it with 31 so now this is a heap  so the minimum element is 23 we are now going to remove the minimum element which essentially means swap it with the last this is not part of the heap anymore and once again ensure the heap property by swapping and this is now a heap the smallest element is 26  exchange 26 and 31 remove it from the heap and now ensure the heap by doing the necessary swaps so the smaller of these two children ? s is 29  so 29 and 31 are going to be swapped this is a heap now  smallest element is 29 so i am going to remove this and 43 is going to come at this location  so 43 comes here 29comes here  this is not part of the heap anymore so i drop this off and now i need to ensure that this is a heap so this now has only one child  this is the remaining part of the heap  this has only one child and which is smaller  so i need to swap them so this is a heap now so the minimum element is 31  i remove this minimum element and the last element is 43  it will come at this place so 43 comes here  31 is removed and it is put at the location of the last place because this location now gets empty so essentially that corresponds to 31 and 43 getting swapped again and this element going away from the heap now this is the only element left in the heap and so it is a heap i do a delete min which means i remove this element and it ? s not part of the heap anymore so this is what we get  as you can see this is a sorted sequence in decreasing order now if you read it like this and this is how we do heap sort  refer slide time  33  40  so let ? s quickly summarize the running times of the various heap operations that we have seen so far the last thing we saw was the heap sort which takes a total time of order n log n why did it take a time of n log n ? this was because it was a two step process  first we created a heap this took only order n time and then we did delete min repeatedly till the heap becomes empty so the first time we did the delete min operation we spent log n time  the second time we did a delete min operation we spent order log n  1 time let ? s say because the size of the heap reduces and so once again we have a series of this kind log n plus log n -1 plus log n-2 plus log n -3 going all the way down to a one but the sum of this series is log n factorial which is the same as n log n the total time taken by this system is order n log n so while this is only order n  the total time taken by this step is order n log n and that implies that heap sort takes a total time of order n log n building a heap  we saw a bottom up procedure for building a heap so there are two ways of building a heap  one is repeated insertion repeated insertion we insert one element at a time and we argued that takes total time of n log n and you can actually come up with the examples were it takes that kind of time so repeated insertions would take n log n time but if we did this bottom up process of building the heap where in the leaf elements are already heap  the sub trees of height one you made them a heap then you made the sub trees of height two a heap then you made the sub trees of height 3 a heap and so on and you repeatedly use the heapify procedure to be able to do that so if you were to do it this way this bottom up construction of a heap this takes order n time the delete min operation which we also sorted is takes only order log n time this was because the delete min operation is a two-step thing first we remove the minimum element which is sitting at the root  take the last element in the heap so in the array implementation this corresponds to the very last element in the array and put it at the root location  put it at the location of the first element which we have removed which was the minimum element so once you did that  now this is not a heap because the heap property could be violated at the root but the two sub trees the two children of the root  the left child and the right child and the two sub trees rooted at this two children are heaps so we can invoke the heapify procedure on the root heapify we have already discussed and we are going to recap today  a recap just now takes only order log n time so the total time taken for delete min then is log n for the heapify and constant time to do this swap of moving the last element to the very first location so total time taken is order log n so this was delete min where you are removing the minimum element if you just wanted to find what the element was  the element with the least priority that we said is the element sitting at the root node now that we can just directly access and so finding the minimum element just take constant time in the last class we saw the heapify operation we also saw it repeatedly in the delete min and the build heap procedure today and also in heap sort actually heapify is really crucial operations and we saw that it takes only log n time this is because heapify we are bubbling the element down the tree and the worst case we might have to bubble it all the way down but since the height of the tree is no more than log n  it will take no more than log n steps to do that in the insertion process on the other hand we are moving the element up the tree  so first we decide what the new structure of the tree is  so we add an additional node  we put the element there and then we keep moving it up till the property at all the node is not satisfied so we keep moving it up so it bubbles up the tree since once again the height of the tree is only log n in the worst case we might be bubbling up the tree at most log n levels and so the total time taken by the insert procedure is at most order log n so as you can see  if i use a heap to implement the priority queue data structure then the worst case time complexity of any of the operations  so forget heap sort because the typical operations that we are doing are insert  find min and delete min these were the three operations we started of with and while find min is done very quickly  it ? s just constant time insert and delete min also don ? t take too much time they take only order log n time compare this with the implementation we had done using a sorted sequence in an unsorted sequence in the case of an unsorted sequence we said insert would take constant time but find min and delete min will both take order n time in the case of a sorted sequence we said that insert would take order n time while both find min and delete min could be done in constant time so it ? s not the case  in some settings you might be interested in implementing a heap  implementing a priority queue using a sorted sequence and which would those settings be if you were implementing it using a sorted sequence then as i said both find min and delete min just take constant amount of time but insert takes a lot of time it takes order n time if you had a setting where you were doing a lot of find min operations  very few insert operations then it might make sense to use a sorted sequence so depending upon the application one has  depending upon the settings one is in  one might have to choose between i mean the different ways of implementing a priority queue so we have looked at three ways heap  sorted sequences and unsorted sequences and depending upon which operation of occurring more often  one might have to choose an appropriate implementation with this i am going to end today ? s class today we looked at the other operations on heap in particular we looked at the delete min operation and the operation for building a heap in a linear time we also saw how to use a heap to do sorting in order n log n time only this sorting that we saw was an in place sorting algorithm thank you data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture # 22 why sorting ? today we are going to be looking at sorting sorting is actually one operation that computers love to spend their time on you know it is estimated that 90 % of the time spent by all computers is on sorting numbers  refer slide time  01.26  so it is really a problem which requires attention  requires consideration and so we need to develop good algorithms for it so in the last class before you have looked at heap sort so today we are going to look at another sorting algorithm so where does sorting occur ? most oftenly in databases when you are searching in the databases you want to keep data sorted in a certain manner so that the search becomes efficient recall the search is more efficient when you have the data sorted there are lot of settings in computation geometry  computer graphics where sorting is essential so i am not going to more of these applications but we are going to look at certain sorting algorithms  refer slide time  02.14  sorting algorithms also give us an idea of different algorithm design techniques so actually this is a point we have not spent any time on yet what is an algorithm ? it is a way of solving a problem and there are certain techniques that people adopt to design an algorithm given a particular problem  how do you design an algorithm for it ? so there are certain standard of techniques in sorting it shows you some of those techniques so today we are going to look at one such algorithm design technique through a sorting algorithm there is also what a lower bound on sorting is it means there is no sorting algorithm which requires comparisons no sorting algorithm can sort n numbers in less than n log n comparisons there can not exist any sorting algorithm so we are also not going to be spending time on this but this fact is useful to prove lower bounds for other problems as well this was as far as motivation for why are we spending so much time on sorting is concerned  refer slide time  3.32  so far we have seen insertion sort and selection sort these are two sorting algorithm with the worst case running time of n2 there are two algorithms i should also have written quick sort actually heap sort has a worst case running time of n log n and one algorithm that is missing from the list is quick sort which has the worst case running time of n2 but an average case running time of n log n so today we are going to see another algorithm and the algorithm design paradigm that is used here  what is called divide and conquer so some of you might have seen divide and conquer in your earlier cs course basically what the idea is that  given a certain problem  to solve the problem you first divide the problem up into two or more parts then you recursively solve those sub problems so that ? s what is called the conquer step so recursively solve the problems on those parts when i say recursively solve  how do you solve the problems on those parts ? by once again dividing them into smaller parts and solving the problems on those smaller parts and so on and on so use the same algorithm to solve the problem on the smaller pieces and once you have the solutions for the smaller pieces  you need to some how combine the result to get the solution for the original problem so that is what is called combine step we will see through an algorithm for the sorting problem  refer slide time  05.02  we are going to look at what is called the merge sort algorithm some of you again must have seen this before if you have seen it  it is ok because we will see at least a different way of analyzing the algorithm so what is sorting ? basically you are given n numbers which you need to put in increasing order  lets say lets say s is the set of n numbers what we do is we would split ? n ? into two sets ; s 1 and s 2 so this is the divide step the split would be such that s 1 and s 2 would contain roughly half of the elements of s now recall this should look very similar to another algorithm ; the quick sort algorithm there also we did a division at the very first step but how was the division done there ? it was not equal so in the divide step there  we were dividing the problem into two sub problems but those two sub problems were not equal in size one could be smaller than the other but here we would make sure that we divide it into two equal sub problems equal i mean  the numbers of elements in the two sub problems are equal so if s 1contains the first one  lets say n/2 elements  then s 2 contains n/2 floor elements what do you mean by first n/2 elements ? not the first n/2 in a sorted order because i don ? t know what the sorted order is s is just some arbitrary collection i just take the first n /2  call that s1 the next n/2  call that s 2 now conquer step is that i would sort these two sequences i would sort s1 i would sort s 2 so recursively i am solving the same problem and then once s 1 and s2 are already sorted  i have to combine i wanted a sorted sequence for s i have s 1 as one sorted sequence  s 2 as another sorted sequence .but what is s ? it is not just s 1 followed by s 2 no guarantee that is sorted so i need to what is called ? merge ? s 1 and s 2 into one sorted sequence that is called the merge step or the combine step here now who can tell me  in the case of quick sort  the divide step was  i take an element and i compare that ? s the pivot element and i compare every element against this element we had this procedure called partition which was helping us do that that was a more involved procedure because we were trying to do it in place so we were kind of just swapping elements till we got two sequences one containing all elements less than the pivot and another containing all elements greater than or equal to the pivot that was the division step how much time did we spend in division there ? order n because we have to compare every element against the pivot how much time do we spent in the division step here ? constant time because we are just saying if it is an array we just say this is s 1 & this is s2 we are not copying anything from anywhere to anywhere that is one difference we will come back to the conquer thing in the case of quick sort  we were doing the same thing we partitioned then we said we will quick sort one part  quick sort the other part and then we will combine did we have to do combine there ? no because we could just take the first sorted sequence  put the pivot element and then take the second sorted sequence and that would be the sorted sequence for the entire thing so how much time was combining there taking ? constant time here combining will not take constant time here we have two sequences and we have to combine them we will see that it will take order n time this is also called the merge step and the name merge sort is deriving from this step so every one understands what the algorithm is  refer slide 09.24  so for instance  this is the pseudo code for the algorithm i give you an array a  p and r identify the part of the array  the lower and the upper bound which needs to be merge sorted if p is less than r  only then we need to do something p is the lower and r is the upper index so q is the mid point p plus r by two so this is the division step these two are the recursively solving the conquer steps i am saying from p to q sort the first part of the array  from q plus one to r sort the second part of the array .sort using same merger sort procedure and once you have this part and this part sorted you have to combine for that i have another procedure called merge to which is specifying p q and r so this procedure the definition is this following this is what it is doing but what is the definition of merge ? it is going to take the two sequences one sequence is from p to q the other is from q plus one to r and merge them and make one sorted sequence which will sit in p through r that is merge and how does merge proceed ? that ? s essentially what the merge algorithm is doing we are going to see examples of it so don ? t worry but next is read through this and you will understand a little bit of what merge is going to do it is going to take the smallest of the two top most elements of these two sequences what do i mean by the smallest of two top most elements ? what is the top most element of this sequence ? the first element the top most of the first element which is p or the element at the location p  a  p  and the top most element of this sequence is a of q + 1 i am going to take the smaller of these two and put it into the resulting sequence whichever is the smaller when i have to merge so if i have to merge these two sequences which will be the smallest element of these two sequences it will be the smallest of this and these two the smallest of these two numbers i don ? t have to worry about any other numbers because this is already sorted and this is already sorted in increasing order take the smaller of these two and that gives me the first element of my resulting sequence in this manner i can continue building up the resulting sequence and we will see how that ? s done  refer slide time  12.07  that ? s merge now let ? s look at an example for merge sort this is my sequence as you can see  it ? s not sorted it ? s an 8 element sequence so the first step is a divide step you will divide this into two parts so one is this and the other part is this this is the division i have shown it lower down because i am kind of doing a recursive call of merge sort so this corresponds to one level of recursive call so first do a merge sort here this is another merge sort call then i will do another merge sort call here and so on this is a recursive call on this part of the sequence on these 4 elements  refer slide time  12  55  and how is this done ? this is done by once again dividing this into two parts  58  24 is one part and the other is the other part and i do a recursive call on this part now first first i do the division and then i do a recursive call on the first half then i do a recursive call on the second half  hindi  we just seem to be doing divisions and doing recursive calls as you can see how do i sort this part ? once again i divide it into two parts  85 and 24 and i do a recursive call on 85 just a single element sequence and what is the solution for this when there is only single element ? that itself is a sorted sequence so 85 goes back up so to say we go back to the parent calling procedure so that is 85 so this is the sorted first half and this goes down this is also sorted so this is the sorted list and now we have to do the merge at this call so we have to merge this sorted sequence which is just 85 sitting in this blue oval are two sort sequences we have to merge them so right now we will just do the merge so the result as you can imagine is 24  85 and this is one sorted sequence so now we have finished the merge sort for this call that we had done ? 85  24 so now this can go back up we have finished that merge sort now we are getting ready to do the merge sort on this second half let me show you the procedure once again first we divide then we merge sort the left half and then we merge sort the right half and when i merge sort the left half  what happens ? i once again divide and then i merge sort the left half and then i merge sort the right half then i merge sort the left half what do i do ? i once again divide and so on and on so in some in some sense  first do a merge sort on this and nothing is to be done here so far and then how do i do this ? once again i divide and then i do a merge sort on these two but first i do it here only when i have finished this merge sort  will i come back to this one and how am i doing the merge sort here ? once again i am dividing this is the trivial case so this is easy to do this is the trivial case i get this sorted sequence so i have finished the merge sort for this part now so this goes back now i have to do the merge sort for this part once again i am doing a recursive call on this i do a call  divide trivial merge ; 45  63 and now this is my sorted sequence so i am now ready to go up and this is now the two sorted sequences that i get now i can merge this so i will show you the merge step again more clearly but you can see which should be the first element it should be 24 so this is the sorted sequence or the merge sequence now i am done with this part this merge sort call has finished the merge sort call that i have made on these four elements that has finished so it goes back now i do a merge sort call on this so i do one more merge sort call here i am not showing you the entire thing i am just showing you that this entire thing would happen in exactly the same way 17  30  1  96  30 would sort and you get 17  30  1  50  96 this goes back and then we will merge these two and this is the resulting sequence so these are two sorted sequences we can merge them i will show you how to merge them very quickly and that will give us the resulting sequence so who can tell me how many merge sort calls have i made in all ? how can you count the number of merge sort calls you have made ? in this example how many merge sort calls have i made ? order n why because each of these blocks correspond to one merge sort call  hindi  so the number of merge sort calls is just the number of nodes in this tree and how many nodes are there in this tree ? well you can see that this is the tree ? how many leaves are there in this tree ? n leaves there are n leaves at this level there will be n/2 elements at the next level there will be n/4  n/8 and so on and on some of this sequence n by two n by four n by eight n by sixteen so on is n minus one you can check that there are many other ways of thinking of it you can think of it has a complete binary tree on n leaves and you can apply those formulas that you learnt  hindi  so this will do exactly  n-1  recursive calls to merge sort  refer slide time  18.49  so let ? s see the part that we missed out on how do we merge two sequences i should really say two sorted sequences so let ? s say these are two sorted sequenences i have s 1 s 2 24  45  63  85  73  150  96 these are i believe coming from 24  45  64  85 are they the same ? no they are not the same so these are the two sorted sequences we have to merge them so what should be clear is that the first element of the resulting sorted sequence is the smaller of these two so it is clear that the resulting sorted sequence which is s has its first element 17 then i can strike away 17 from here because i have kind of removed it and i have put it here i have to merge these two sequences and append them to this sequence that i am constructing so how do i merge these two sequences now ? once again the same idea which is the smallest element which is the next element will be the smallest element in these two sequences put together and that will be one of these two the next element should be 24 and so i remove 24 out of there and i get two smaller sequences like this once again i have to find out the smaller of these 6 elements that has to be the smaller of these two so i will just compare these two and i will write that down here so i compared i found 31 is smaller i write that down here and i remove 31 from this and then in this manner i can proceed so 31  45 would be the next one to go these are things left then next one would be 50 it would be left with 63  85  96  refer slide time  20.40  then the next one would be 63 we would be left with 85 & 96 eventually it would be taking that and we would have nothing left this is what you would get as a result  refer slide time  20.56  so how much time do we take in doing ? order n why ? because what are we doing ? we have these two sorted sequences we are comparing two elements ; the two right & the two front elements we are comparing them and taking the smaller of those two and writing them out into the resulting sorted sequence with every comparison  we are writing out one element how many elements do we write out in all ? as many elements as there are so if there are n elements  then i am going to be writing out n elements in all which means how many comparisons am i making ? n comparisons this was assuming whether two sequences were of length n/2 and n/2 suppose one sequence was of length ? l ? and the other sequence was of length ? m ?  one sorted sequence of length ? l ? elements and the other sorted sequence with ? m ? elements in it s 1 & s 2 what is the total time taken by merge ?  l + m   these are the four choices let ? s see minimum of  l  m  max of  l  m   hindi    l + m   hindi  none of above  hindi  none of the above  noise   which do you think is the right ? let ? s look at worst case how can you tell me what the worst case is ? let ? s look at worst case in the worst case what do we have to do ? we have to in the worst case we will have to compare the worst case should be  l + m   we might have to do every possible comparison what is the best case in your opinion ? best case it ? s not really clear what i am trying to say by best case because what might happen is that if one of the sequences finishes then i can just copy the next one so even the copying requires time so if you include the time for the copy  then its always going to be l + m you can not do anything more about it but if you don ? t want to include the time for the copying  if you are just counting the number of comparisons that you do then if you are just counting the number of comparisons  then you can do less than it will be so you all understand this in the worst case  why do you require l + m comparisons ? so you might require as many as l + m comparisons so in fact that was happening in this example so you know if you count the number of comparisons that we did in this example for every element that we had to write out  we have to do a comparison except for the last one so you really require l + m -1 comparisons that is the worst case the number of comparisons if you are counting the number of comparisons you really require that many and you can create sequences of arbitrary values of l and m so that you require l + m  1 comparisons  refer slide time  26.19  so we have understood merge we have understood the merge set we understood what merge sort is so let ? s try and analyze it how much time ? how many comparisons does merge sort take in all ? this is a quick recap of what we said so far we have this sequence we spit it into two then we spit this into two  this into two and so on and on when we had these single ones  then we merge this and we got 15 in the previous example i had shown you them going up i have just kind of created a mirror image so i have merged them here merge these 2 got 2 4merge this to get 3 6 merge these 6 get 2 6 then i decided to merge these and i get1  2  4  5 here i merge these two get 2  3  6  6 and then i merge this to get 1  2  2  3  4  5  6  6 so you could also think of pictorially we could also think of this as what is happening that you did your divisions of algorithmically it ? s the same thing you are doing your recursive call this is just a way of representing it why am i doing it this way because it will now be easy to compute what the running time is can you by looking at this picture say what the running time should be ? no time spent in all of this part no time spent in this split part but when we are doing the merges we spend time how much time do we spend in doing this ? merge two units essentially how much in this two ? why am i counting two length of the two sequences ? i am merging i am always going to count that one l + m so  hindi  each of these merges require two unit of time and how many such merges would i have to do at this level n by two such merges ? if these were n elements  then i would do n by two merges of two elements so total time would be n /2 into 2 n so that ? s what is going to happen we are going to see another way of doing this in a short while but you should understand what ? s happening so each of these merges is taking two units and there are n /2 such merges and after that we get sequences of length two after this step we get basically sequences of length two as you can see now we are merging these so each of these merges is now going to take 4 units of time and there would be n /4 search merges this should correspond to this and the next one would take 8 units of time and that corresponds to n /8 and there are n/8 such merges n here is 8 so there is only one such merge but in general there would be n /8 and so you would get such a sequence this is what we have to sum this is the total time spent by your algorithm we will see this in a slightly different way in a short while  refer slide time  29.45  so we are going to analyze it once again using recurrence relations so we had used recurrence relation before i am going to say it once again so that it is refreshed in you mind so typically for all recursive of algorithms of procedure which are recursive in nature  you can analyze their running time using recurrence relations and is basically an equation or inequality that describes a certain function in terms of its values at pervious points at smaller inputs so for instance  for a divide and conquer kind of a problem  the time taken to solve t if t of n is denotes the time taken to solve a problem of size n  then it is equal to the time taken look at this part suppose i divide it into some number of pieces  how many problems did we divide it into two and each of the sub-problems was half of the original thing so the sub problem by sub problem size factor  i mean by what factor have i reduced the size of the problem ? so that is the time required to solve each of the sub problems this part for each sub problem  there is a time required that times the number of sub problems is the total time required to solve the various sub problems plus the time required to do the division plus the time required to do the combining that would in general denote the recurrence that you would get of course this is when n is more ; if n = 1  then it is basically a trivial problem and whatever the time required to solve the trivial problem would be the value it would be kind of the base case for this recurrence the initial condition for instance for the merge sort problem  we divided the problem into two pieces and each of the pieces were of size n by two so the time required to solve the problem of size n /2 to sort to merge sort n /2 elements will be t n /2 if t n denotes the time required to merge sort n elements  we are using t of n to denote the time required or the number of comparisons required to merge sort n elements then this is the kind of a recurrence we get i have written theta n here but you can just write n here because that ? s the upper bound on the number of comparisons that we would do let ? s say that ? s the number of comparisons we are doing so this is the kind of a recurrence relation this is clear to every one we have a problem of size one if n = 1 this is just a constant because we don ? t have to do anything here  refer slide time  32.48  there are bunches of ways of solving recurrences we have only looked at what is called repeated substation method what does that say ? that basically says we expand the recurrence by substituting repeatedly and noticing any patters that you get there is another method which is called the substitution method where you guess a solution to the recurrence and then you verify that your recurrence really satisfies that guess in the course of this course  we will perhaps see examples of this way of solving recurrence relations there is a third method called the master method which basically says that you know if a recurrence is of this kind  then this is the solution for this recurrence and you just plug in the values of a and b and you get your solution i personally don ? t like you to remember those formulas it should always be possible to solve those recurrences by just looking at them but these are three ways then there is a fourth method which is a recursion tree that you draw out a tree of the calls that have been made as we drew and you count at each node  how much time is being spent  so we are going to look at lets say  the repeated substation method once again suppose i am trying to merge sort n elements and n is some power of two  lets say two to the b  this will help us ease the analysis a little bit so recall the recurrences t on n = 1 and t on n equals t of n = 1 if n = 1 and t on n = 2 times t of n by 2 + n if n is more than one  so we are just going to adopt repeated substitution i just keep writing over and over again and it ? s same what i get so i get t of n = 2 times t of n /2 + n so i substituted once and now i am replacing this t of n by 2 so this is the substitution step i am replacing this t of n /2 with 2 times t of n /4 + n /2 why n /2 because this is t n/2 so this part ? ? ? is coming in here and this part whatever is n written here  it comes again here as plus n and now i just expand this which means i just write it as 22 t n/4 + 2n once again i substitute for t n/4 and i expand 2  get this and now i have to observe a pattern basically what is that ? s happening ? i get 22 times t 4 times t n /4 + 2 n  then 8 times t n /8 + 3 n and so on so in general at any step  i am going to get something like after i have done this thing  i times i get 2 to the i times t of n/2 to the i + i times n that ? s what the 3  the 2 and 1 here and now if i choose i to be log n  what do i get ? i get 2 to the log n times t of n by n + n times log n now t of n by n is 1  2 to the log n is n t of 1 is 1 so this becomes n in all and this becomes n log n so i get a total of n plus n log n which is order n log n so that ? s the total time taken by this procedure everyone understands this so the very simple recurrence you can just solve this using repeated substitution now if you are understanding this  let me ask you a question does this give us the average case time ? it is in all cases it will be the same time because we have written that the time to combine the time to combine is n this is the combining time at the time to combine is always n so to say because we need to look at our merge step more carefully  when we look at our merge step more carefully and i actually show you the code  we will see that you really need that much time you can ? t do in less than that time as many elements as you trying to merge total number of elements you are trying to merge you really need that time so what you have actually argued is that of n the time for merge the number of time for merge is theta of n log n it is not omega it ? s actually theta it is always you take this kind of time its bounded by some constant time n log n upper bounded and lower bounded also by some times now suppose i had instead of this one here  i had a c  what do you think will be a solution for this ? why am i doing this ?  hindi  n into n plus c log n so this is by just looking at the solution you can see that this is what you would get  hindi  provided c was not that big the one way of also thinking this entire thing is what we said a recursion tree let ? s draw out a recursion tree for this let me write down the total time taken in the division and the combining at this node  hindi  so i should write down n here i should write down n/2 and so on and on  hindi  now what ? s the total time taken ? it ? s basically the num sum of numbers written in these nodes which is n here this level  hindi  and so on  hindi  i have not said that these c ? s are necessary constants there could also be something will depend upon n n which case this is how this is another way to view this thing you can draw out this tree and you can write the total time being done at that node in the combine at the divide step so this is what we do in the repeated substation method substitute  expand substitute  expand and keep doing that observe a pattern so do it sufficient number of times you observe a pattern and that on how you would get an expression after the ith substitution and find out a value of i which gives you the value the initial condition so to say this is what the method is  refer slide time  42.44  so i can now show you a kind of a java implementation of merge sort so these things are clear it is a very simple algorithm that ? s why i am showing it to you here we are also taking a comparator object what is a comparator object ? we are not just merge sorting integers we could use this to sort anything so we are looking at a java implementation of a merge sort so this would require the sort object so you define an interface called sort object which is implementing a method called sort and this method requires a sequence and a comparator why comparator because we said we are not interested in sorting integers we could be sorting anything so if i give you tow objects  this comparator is going to tell me whether one is less than the other  greater than the other and so on depending upon what you want to do  the sorting on you will design a comparator so the comparator typically has three functions ? is less than ?  ? is equal to ?  ? is greater than ? and you could also have ? is less than ? or ? equal to also ? or you could just these two do the implementation and all of these three functions are essentially boolean they will say true or false  refer slide time  44.31  so this is basically the merge sort you have this sort so you have the sequence comparator let ? s say ? n ? is the size of the sequence if n is less than two which means they are just zero or one elements nothing to be done it is already sorted otherwise you create a new sequence s 1 is a new sequence and you are going to insert the first half of s into s 1 so let ? s say we have an operation called insert last which will insert an element into the sequence s 1 this is an operation this is the method on the class sequence or a data type similarly we create a new sequence called s 2 and we put the second half of s into s 2 these are how you implemented your methods you could have done it this way you could have done it in some other way but let ? s say we have such methods then you can break it up in this manner and now you just need to call sort sort on s 1 and s 2 this merge sort on s 1 and s 2 and then eventually you need to do this merge so s1 and s 2 were two sorted sequence c is your comparator and s is lets say the resulting sequence you want so you will have to do this step and what does this merge step contain ? this is basically a two sorted sequence you have a comparator this is the resulting sequence what you ? re saying is that while both the sequences are non-empty you will keep doing something what is that something ? you will compare the first element of s 1 and the first element of s 2 if the first element of s 1 is less than or equal to the first element of s 2  then what is that you should add to s ? you should add the smaller which is s1 you should add the first element of s 1 to s so you are going to remove the first element of s1 from s1 and add it to s that ? s the only thing you are doing here in this statement get the first element of s1  remove it and then insert it into s and you are essentially repeating this if this is not true  then you will insert  remove the first element of s 2  insert into this and you keep repeating it still either of s 1 or s 2 becomes empty when one of them becomes empty then depending upon which one it is  if s 1 is empty then that means that you have to just copy s 2 to s so which means that you will once again keep removing one element at a time from s 2 and inserting it at the end of s that ? s what you are doing removing the first element of s2 and inserting at the end of s you keep repeating this if s1 is empty  if s2 is empty  then that means that s1 is left with some elements we will keep removing one element at a time from s 1 and insert it into s with that we will end today ? s discussion on sorting we learnt what merge sort is on which we also saw the divide and conquer paradigm for sorting is data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 23 more sorting today we are going to continue our discussion on sorting we will begin with radix sort then we are going to look at bucket sort in place sorting is something that we have seen before which are the examples that we know of in place sorting heap sort  quick sort  insertion sort  selection sort  bubble sort bubble sort we have not done we are going to see which is in place and which is not in place  not all of these are in place what you just said we are going to see and then we are going to finally look at how fast we can sort can we do better than what we have been discussing so far what is a radix sort ?  refer slide time  1.21  see in radix sort we are going to look at the keys that we are going to sort so recall that in all other sorting algorithm  we are only comparing the keys we are not looking at what the actual structure of the keys is it doesn ? t really matter if the keys or people provided you have a way of comparing two persons if you have a comparator function which is given two persons who can say one is less than the other then you can also sort people but today or in radix sort  we are going to look at the key itself that we are trying to sort  the collection of keys we are going to assume that the keys are represented in some base m number system and m is called the radix if m equals 2 then the keys are essentially in binary  base two  refer slide time  02.58  this could be an example 9 is 1 0 0 1 in binary  in base two we are going to use this representation of 9 to do the sorting first i can represent 9 in base form or some other base also  base three let us say then m would become three and i can still use that to do the sorting and we will see how and in radix sorting  the sorting is done by comparing bits in the same position if instead of comparing numbers  instead of comparing 9 with 11  we are not going to compare 9 we are just going to compare the bits in 9 and 11 which bits ? let us say look at the bit at position three and we are going to compare them we will see all of that in a second and this idea can be extended when the keys are let us say alphanumeric strings also not just binary numbers  not just numbers like this but alphanumeric strings so name of people or some such thing you can also use a same idea to do sorting on that and we will see how i am going to talk of two variants on radix sort one is called the radix exchange sort so what we are going to do in radix exchange sort is we are going to examine the bit i am going to assume now that the keys we are trying to sort are some numbers represented in binary first and am going to examine the bits from left to right let us assume also that each of the numbers that are given to us have a fixed representation they are expressed in the same number of bits that can always be done if the largest number in your collection is let us say some n then you need basically log n bits to represent that largest number so with log n bits  you can express all the other numbers in log n bits and that would be the number of bits that you would use to represent all the numbers in the collection you have we are going to sort the array with respect to the leftmost bit first suppose the numbers are sitting in this array and the left most bit of this numbers so it really doesn ? t matter what these other bits are i am just looking at the left most bit of each of these numbers this is the first number  this row the second number is in this row so there are 5 numbers  5 rows i am going to look at the left most bits and i am going to sort the numbers according to this bit which means these are two zeros  so they come first so this number goes at this position  this number goes at this position and the ones come later this goes here  this would go next and this would be the last  refer slide time  05  54   this is what i would do sort according to the left most bits and since the bit can have only two different values  it is easy the zeros comes before the ones clear to everyone ? now we partition this array  so this is not yet sorted  this set of numbers is not sorted i will now divide it into two parts this is the top sub array and bottom sub array i am going to sort this top sub array independently of the bottom sub array what do i mean by sort the top sub array ? just look at these numbers  forget this bit because this bit is same for all of these numbers it will not make any difference in the value of the number  i will just forget this bit  refer slide time  07  54  similarly when i am sorting this  i will forget this bit what does it mean to forget this bit  when i am sorting these numbers ? i am saying  i would take the number or remove and subtract some number from that what is that number ? if these where k bits number  i am subtracting 2 to the k from that number if i subtract 2 to the k from each of the numbers and then sort them  then it is same as the sorting the original collection of numbers  it doesn ? t makes a difference i can sort this bottom sub array independently of the top sub array and then i just put them together and i would get a sorted sequence it is a divide and conquer algorithm once again there is a divide step in which zeros come before the ones there is a conquer step and the combined step is triviled here so the conquer step  this is the recursion we will recursively sort the top sub array ignoring the leftmost bit we will recursively sort the bottom sub array  ignoring the left most bit once again how are we going to sort these ? using the same idea  we are going to partition this using the second left most bit  this left most bit and so on how much time does it take to sort these n-bit numbers ? i claim it takes order b n time  if i have n numbers and b bits why is it ? why can you do it in so much time ? pardon no of bits is log n is the number of bits log n ? log of the largest number the largest number need not be n it could be much larger than n  it could be much smaller than n  student  the number of keys can be at most the largest  n is only the number  n is the number of numbers and not the largest number  student  exactly sir the number of keys n is at most the largest number  number of keys is at most largest number  this statement is not true you could have duplicates and also the largest number can be much larger than the number of keys  student  1 to 20,000  okay great we will continue this discussion later so i claim to sort n b-bit numbers you will require order b n time and why is this ? let us try and understand this can i write a recurrence for this ? can someone write a recurrence for this ? let ? s write a recurrence let me stretch and write a recurrence so t  n  b   why comma b ? number of bits so t  n  b  is the time to sort n b-bit numbers let ? s say this is t  n  b   what is this equal to ? we are going to partition this n numbers into two pieces this was the top sub array  let ? s say this has i numbers in it and the remaining would be n minus i now how much time does it take to sort these i numbers ? because we are going to do it recursively so it should be t  i  b-1  that ? s important the b minus 1 why is it important ? because we are going to ignore the left most bit because the left most bit is going to be the same for all of these numbers the time required to sort the other n minus i numbers is n minus i  b minus 1 plus something more how much time ? because i had time to partition this numbers  the numbers in which the left most was 0  come before the numbers in which the leftmost bit was a 1 they had to be rearranged for each and that can be done in order n time this is the kind of recurrence we would get now what is the solution for this recurrence ? anyone ? what is the solution to this recurrence ? b n no  it ? s perfectly right if you are saying b n let ? s substitute  so this is the third method we had talked about solving recurrences by guessing a solution and substituting that solution on actually verifying weather its true or not let ? s see what it should be ? let ? s not worry too much about it let ? s see  suppose t  n  b  was equal to b of n may be i am wrong let ? s see whether i am right what is my right hand side then ? the right hand side equals i because n is i times  b minus 1  plus  n minus i  times  b minus 1  plus n which is  this part is  b minus 1  times  i plus n minus i  plus n  b minus 1  times n plus n which is b n which is also our left hand side so this is correct this is a solution to this reference no harm  so this is the time taken and we will say other ways of arguing the same thing  refer slide time  13.22  no  we don ? t have to do that this would be the same for all choices of i  we don ? t have to any averaging here  student  but when we did quick sorting   that was because we were doing a randomized quick sort we were computing the expected time  i can be anything   i can vary but the whole point is no matter what i is it will always be the same their depending upon what i were  the time would be different and so we were computing the average if we try to compute the average here  you would get still the same the point is it is always the same no matter what i is no  even then you don ? t have to go if you do repeated substitution  once again you will see of course it will be more complicated which is why i did not do that method here you can also solve it by repeated substitution and you will get the same answer it is just that you will have to keep track of what i ? s you use in the various points in the recursion and that will make it a bit more cumbersome that you will get a same solution these are all b bit numbers that is what we assume the maximum number of bits is b exactly  n has to be less than or equal to two to the power b no  this is not true i never said these are distinct numbers  i could have repetitions  student  can ? t we just say that we have  so that would be one way of arguing it i just wanted you to show  how to solve recurrence relations also there could be many ways of arguing the same thing  that ? s one argument everyone understands what the algorithm is yes  how do you combine in this divide and conquer step we don ? t need to combine once we have sorted this top sub array and we have sorted this bottom sub array all the numbers are b bit exactly here that is why this is all uniform that is why i said  you will take the largest number  see how many bits you need to represent in that and you will use that many bits to represent every number otherwise it does not work you just target with zero ? s to the left if 8 is 1 0 0 0  4 bits then 2 would be 0 0 1 0  4 bits great so let ? s continue  student  what about negative  we will not worry about negative numbers right now if you had negative numbers and positive numbers what will you do ? first split the numbers into negatives and positives  sort them separately and put them together why make life more complicated in that ? you can always sort them separately no  that will not happen we will see more examples and it will be clear in the previous slide i said that you will have your zero ? s before your one ? s that was the first step we did let me go back  hindi  we took these numbers  we changed this so that you had the numbers in which the leftmost bit was a 0 appearing before the numbers in which the leftmost bit was a 1 we did this kind of partition  refer slide time  17  28  how do you do this quickly ? if you recall in my recurrence  i wrote order n for this and you did not arrays occur on that the point is we can use the partitioning algorithm that we employed in quick sort to do this what does that mean ? we will scan from top to down  finding the first key with the one in the left most bit and from bottom to up finding the first key with a zero in the left most bit and swap the same kind of technique we use for quick sort and we will exchange these keys and we will keep doing that until you know the scan indices exchanged so that we know that there are zero ? s above and ones below how much time did it take ? at most the size of the array in this manner we can do the partition and then we can just call it recursively we will get a time of order n b so that is what we are doing here we are scanning from the top to bottom so this is the first place we find a 1  this is the first place we find a 0 we swap them  0 comes here  1 comes here then the next index would be this one and the next here would be this zero we will also scan them and we would get this and now we are done  refer slide time  18.41  what is happening ? how is this different or related to a quick sort ? i will come to that in a minute but before that see what we are doing at each step suppose these are the numbers before we sort them what does this mean ? these are the numbers  the first number in my array is this let ? s say this is the value the y coordinate is the value of the number  this is the number  the second number is this  this is the third  this is the fourth  this is the fifth  this is the sixth what i am doing at the first step is that i am partitioning the numbers according to numbers which are more than 2 to the b minus 1 and numbers which are less than 2 to the b minus 1 the numbers which are less than 2 to the b minus 1 why 2 to the b minus 1 ? because the first bit  the most significant bit we are saying should be a 1 they will come together and the ones for which it is a 0  they will come together i am partitioning the numbers according to 2 to the b minus 1 those numbers whose value is more than 2 to the b minus 1  i am moving it to the right part of my array this is what is happening these are the numbers with values more than 2 to the b minus 1  so they are in the right part of my array and the numbers which are less than 2 to the b minus 1  they are in the left part of my array i repeat this on this one once again i am going to divide this up and now i am going to consider the numbers here which are larger than 2 to the b minus 1 plus 2 to the b minus 2 essentially within this part of course more than 2 to the b minus 2 after i ignore the leftmost bit but otherwise  so we keep doing this eventually we will get something like this which corresponds to a sorted sequence this is pictorially what is happening but you understand the algorithm now how does this compared to quick sort ? both the algorithms partition the array  both recursively sort the sub arrays so structure is very similar  the difference is in the way we partition in the case of radix exchange sort  we are partitioning with respect to not a pivot element but with respect to a fixed quantity we are saying anything more than 2 to the power b minus 1 goes there in the bottom half of the array  anything less than 2 to the b minus 1 goes in the upper part of the array it is the method of partitioning which makes the difference in the radix exchange  divide the array based on whether the number is larger than 2 to the b minus 1 or less than while in quick sort we are partitioning based on a pivot element the difference is also in the time complexity for radix exchange we argued just now that the time complexity is order bn  refer slide time  21.52  for quick sort we argued that the average case is n log n sometimes this might be a better scheme depending upon what the value of b is for you that was a radix exchange sort where we were exchanging the elements in the array i am going to look at another one version of radix sort  the principle is the same this is also another way of implementing radix sort quick sort can be better when b is larger than log n b can be larger than log n you can have one number  you can have numbers which are 2  3  7  11 and one number which is one million and three now you need a huge numbers of bits because there is one very large number so that b would be much larger than log n because the number of numbers is very small but the largest number is very large so that the number of bits you require to do your sorting is large we will continue this is another version as i said of radix sort  straight radix sort we are going to examine once again the bits from right to left now not from left to right but from right to left the k equal to 0 corresponds to the right most bit now the least significant bit also called the least significant bit so k equal to 0 is a least significant bit and b minus 1 is the most significant bit we are going to sort the array based on this bit  the k th bit in a stable way sort the array in table way looking at only k th bit let ? s see what this means ? do you understand what ? s table way means ? no  great we will come to that in next slide but let me show you what this is this is the collection of numbers you have  what the algorithm is you are first going to look at the rightmost bit and you are going to sort these numbers based on the right most bit as you can see after you sorted them  you first have the numbers which have the rightmost bit as 0 then you have the numbers which have the rightmost bit as a 1 then you sort these numbers based on the second right most bit this corresponds to k equals 1  so you are sorting them based on this and then finally you are sorting these numbers based on this what will happen ? at the end of that you will have a sorted sequence  refer slide time  24.29  as you can see this is originally non-sorted and what you have here is a sorted sequence why is this magic happening ? you understand the algorithm take the rightmost bit  sort the numbers based on that which means that just restrict your attention to the rightmost bit anything that is a 0 comes before everything that is a 1 now you have done some rearranging of the numbers now look at the second rightmost bit they do the sorting with respect to the second right most bit everything which is a 0 comes before everything which is a 1 and so on and on how much time does this take ? b n once again  because for each bit you are spending time proportional to n  student  partitioning  partitioning will not be used we will see how to do it it is not completely clear why b n but will come to that argument also in a minute first we need to understand what is sorting in a stable way what does this mean ? a table sort is one in which two numbers are the same then after sorting  so if two keys are the same  equal keys then after sorting their relative order remains unchanged suppose i have two numbers so i have a collection of numbers i have 1 3 11 3 5  these are my numbers i have two threes in there  equal keys now if after sorting  of course after sorting this array would become 3 3 5 11 but the two 3 ? s i have now  suppose with those threes i had one which was colored red and the other was colored blue the first was colored red and the second was colored blue and after sorting  the red should appear before the blue although they are still threes  they should appear in the same relative order as was the case before we did the sorting that is called table sort and we will see why it is relevant here and why it is important here let ? s look at this now this is what we were sorting and let us say we are sorting with respect to the right most bit  refer slide time  27.05  i have 4 keys with 0  they will all come before the 4 keys which are at a one which have the rightmost bit at a one but i would like that this appears before this  so the first number should better be 0 1 0 the next should be all three zero ? s the next should be 1 0 0  the next should be 1 1 0 which is the case here i am not permitted to rearrange them when i am saying i just sort with respect to the last bit  you could also create this array post sorted in which this was the first number but that would be wrong that would not be a stable sorting and similarly for the one ? s the first should be a 1 0 1  the next should be 0 0 1  the next should be 1 1 1 and the next should be 0 1 1  this is crucial for the correctness of the sorting algorithm if you don ? t do it this way  this will not give you the sorted sequence at the end so everyone understands what table sorting is now let ? s understand the correctness of the algorithm we are now going to show that any two keys are in the correct relative order at the end that means if i take two keys  one is smaller than the other then in the end  the key which is smaller appears before the key which is larger  very simple proof so suppose these are the two keys that were given to me let me look at the leftmost position at which they differ  refer slide time  28.43  leftmost  so this they don ? t differ at this place they don ? t differ at this place even but they differ at this place let me call this position k  refer slide time  28  50   now when i am sorting this bunch of numbers what is going to happen ? when i am sorting remember i am sorting by considering first the right most then the second right most then the third right most and so on let ? s us understand this the claim is that the step k  the two keys are put in the corrective relative order at the first step they may be rearranged i don ? t care  they are put in some order at the second step also they are put in some order  i don ? t know but at the k th step  this key would put before this key because this is a 0 and this is a 1 at the k th step the two keys are put in the correct relative order but all is not done now we want to argue that at the latest step  at the k plus 1 th step and the k plus 2 th step and so on  the relative order is not interchanged  hindi  because of stability now when i am looking at the k plus one th step  at the k plus one th step these are the same these are the same  because it is a table sort this key which is appearing before this would continue to appear before this and similarly at this next step and so on and on beyond the k th step  the relative order would not change anymore at the k th step you would get the right order between these two keys  the smaller key will appear before the larger key and add sub sequent steps  this relative order would be preserved the smaller key would be continued to appear before the larger key  hindi    refer slide time  31.13  let ? s take an example this is the two keys once again that i am considering initially they could be in some arbitrary order i have in fact that the larger keys appearing before the smaller key this is the array in which the numbers are ?  hindi   this is location zero of the array and so on you would like that the keys be in increasing order but right now bigger number is appearing before the smaller number when i am looking at the k th step  at this step when i am sorting with respect to this bit  the k th bit i would have put 0 1 0 1 1 before 0 1 1 0 1 clearly because at the k th position  this is a 0 and this is a 1 now when i am looking at the next more significant bit  i would continue this relative order because at the next more significant bit they are the same if they are the same then stable sorting ensures that i have to maintain the relative order that was there till that point in which this was appearing before this so this will continue to appear before this step and in subsequent steps also so because the sort is stable  the order of the two keys will not be changed when bits more than k are greater than or bits at position larger than k are compared you can also see now  why i had to start from the right end if i start from the left end then this technique is not going to work take this is an exercise  think of an example if i were to start from the left end  this would not give me a sorted sequence at the end there is nothing sacrosanct about binary numbers  i can also apply the same technique to decimal numbers  refer slide time  33.15  what do i do ? first i sort with respect to the right most digit which means that the ones would come before the two ? s would come before the three ? s and so on and on again the sorting is stable after the first step as you can see  the first number would be  so there is a 1 1  there are two 2 ? s here and so on and on there is a unique one 0 3 1  so 3 1 becomes the first number then there are these two 2 ? s  0 3 2 and 2 5 2 which should be the second number 0 3 2 because it ? s stable so 0 3 2 is the next  2 5 2 is the third and so on and on so i sort with respect to this next i sort with respect to this  so there is a 1 here  0 1 5  there is another 1 so i will first put this and then i will put this and so on as you can see at the end i get a sorted sequence now we need to figure out the time complexity  how much time have you taken ? so how man passes  such passes are we are making ? we are making as many passes as the number of digits or the number of bits or whatever it is but we need to now see what we are going to do in one pass how are we getting a one ? s before the two ? s before the three ? s and so on in a stable manner how much time does that take ? what kind of a scheme should be employed for that ? exactly  for exchange radix sort we basically wanted to partition the array into two parts only but here because these are digits  not just 0 1 it is not a two way partition anymore for decimal numbers  we will have to represent it in a binary form to be able to do this what is like an insertion ? i don ? t quite follow what you are saying we will discuss this later let ? s figure out what the time complexity is for k equal to 0 to b minus 1  we are sorting the array in a stable way looking only at k th bit suppose this could be performed in order n time then the total time complexity would be order bn that ? s completely clear provided we can do this sorting in order n time which sorting we are talking about we are looking at a particular digit  one pass we are looking at a particular digit or a bit and we want to ensure that all the numbers  if i am looking at decimal numbers all the numbers are sorted based on that digit the one ? s before the two ? s before the three ? s and that the sorting is stable we want to be able to do this in order n time and the method of choice is what is called the bucket sort algorithm  refer slide time  36.34  that brings us to the second sorting scheme that we talked about so what is bucket sort ? lots of buckets we have n numbers  each number is in a certain range let ? s say one through m  so bucket sort is a stable sorting algorithm and it will take time order n plus m you understand what we are talking of this is very useful when you have a large number of numbers with lots of duplicates perhaps and the numbers are coming from the small range then you don ? t need something like n log n time or some such thing you can then do it in time order n plus the range of the numbers essentially let ? s see how this works suppose this is my collection of numbers 2 1 3 1 2 so m is 3 because you can see the numbers are in the range 1 2 3 the m is 3  there are two two ? s and two one ? s so first what we are going to do is you are going to create an m buckets you can understand what you will do in each bucket just take a number and throw it in an appropriate bucket  so we have these 3 buckets  refer slide time  38.04  one corresponding to each possible value in this range and each m element of array is put in one of the m buckets so these are my buckets  take the first number it goes into bucket two  i put it here  refer slide time  38.17  then i take the next number it goes into bucket one  so i put into here the third number goes into bucket three  i put it here the fourth number goes into bucket one  so i append it at the end of this list end is important to maintain stability and then i take this two and append it at the end now i will just read the numbers  i will take the numbers in the first bucket  basically append all of these lists so 1 1  2 2  3 and so on i will put the elements from the buckets into an array and just read it off in this manner  refer slide time  39.05  this gives us a stable sorting you understand why it is stable ? because if two keys are the same then they would be in the bucket but we would also have put them in the right order that ? s why we are appending if we were attaching at the front then we would have to read it the other way around which is the same as that so with that you should be able to argue that our straight radix sort takes order bn time now we said for each pass we want to do it in order n time and you can do it order n time using such a scheme  using bucket sort so you do that in order n time  there are b passes in all so it becomes order bn yes  you are going to get one question from this in the exam yeah  okay in-place sorting yes  you want to know what the question is a sorting algorithm is said to be in-place if it uses no auxiliary data structures it could use a constant amount of additional space over here and it updates the input sequence only by means of the operations replaceelement and swap basically it ? s just you have a bunch of numbers  it replaces one of them by some other or it just swaps two numbers that ? s when we call the algorithm to be in-place so let ? s see which algorithms we have seen can be made to work in in-place  refer slide time  40  59  bubble sort actually you have not seen right or you know what bubble sort is ? you don ? t know what bubble sort is ? i will not go into bubble sort then let ? s see who can tell me heap sort is heap sort in-place ?  student  yes sir  we can have one array and basically implement a heap in that array and we are just changing the elements in that array merge sort is merge sort in-place ?  student  no  why not ? to merge two list  you need additional space you can not merge in the same list  so merge sort is not in-place quick sort  student  yes sir  quick sort is in-place because we partition in the same array and then we just did recursively left and right to do the merge  to merge two lists you need additional space because what were we doing in merge ? we are taking the first element of the two list  comparing them and putting it out into some other space you can ? t just copy it back there  it would not work  student  in an algorithm uses what are one space would increase  yeah  order one space is okay it is in-place but not space proportional to the number of elements  it should be independent of the number of elements you can look at the other algorithms and think off whether they are going to be in-place or not radix sort is radix sort in-place ? but number of buckets is independent of the number of numbers  student  but we are inserting  then nodes that we are creating yes  that is additional space so can you modify the scheme to make it in-place ?  student  to keep every bucket just count the number of those elements that are in the array  yeah  you will have to think about it  think about this can you make it in-place ? can you make radix sort in-place ? it is a good thing to think about let me get to the last topic that we are going to cover as far as sorting is concerned and that is a lower bound for comparison base sorting what does comparison based sorting mean ? it basically means that we are only looking at sorting algorithms in which all you have permitted to do is to compare two numbers suppose you have a bunch of elements  i am not even saying numbers now and you want to sort those elements i give you those elements  i have a comparison function which you have to use to do the sorting so like your comparator  so you give me the two numbers  i will tell which of them is smaller than the other because may be these are not numbers but some objects and i am the only one  who knows how to compare these objects that is a comparison operation  you give me these two numbers  i decide whether one is less than the other or not  whether the first is less than the second or the second is less than the first and i give you the answer now the question is how many times will you have to ask me for a comparison ? you understand  you wanted to sort this n numbers  how many times will you have to ask me ? may be i charge you 1 rupee every time you give me certain comparison to do the comparison is let us say an expensive operation every time you say compare these two numbers for me  i am going to charge you 1 rupee how much money are you going to spend ? n log n  you have seen algorithms which would take no more than n log n time what we are going to argue now is that there can be no algorithm which takes less than n log n time  n log n comparisons no one can come up with an algorithm so that algorithm will always take less than n log n comparisons for all inputs for certain inputs it could take less than n log n comparisons but for all inputs  it would take n log n comparisons that is not possible at all we are going to understand this in the following way  refer slide time  45  50  let ? s look at the particular algorithm you have a certain algorithm and let ? s say your objects are sitting in some array and you algorithm works on that array the first step it ? s going to ask me to compare two elements of that array let say that two elements are at position s1 and s2  hindi   so my very top node here is this node whether s1 is greater than s2 or not it is going to ask me this and i am free to say whether one is less or whether one is more based on what my comparative functions says these are so to say  the questions that the algorithm is asking me first it asks me to compare s1 and s2 if i said a yes then it would have asked me for a comparison of s1 and s3 let ? s say i have such a thing if i had said no  maybe it ask me for a comparison of something else  this need not be s1 s3 it could be something else  depends upon what the algorithm is but at each point it is coming back to me with certain comparisons  with certain numbers to compare first time it says something then depending upon whether i say yes or no  then the next comparison it ask me something else now depending upon whether i said yes or no  the next comparison it could ask me would be something else and so on and on the execution of the algorithm is really a path down this stream yes now at some point the algorithm is going to stop it doesn ? t ask for anymore comparison  it says well i am done  this is your sorted sequence  so which means that this path ends in this external node here  this leaf node here which corresponds to a particular permutation of those numbers this sequence of moves would have been made  if i had certain ordering on the numbers for a certain permutation of the numbers let ? s understand this  student  there would be some finite criteria of the let me go for a s noise it is not necessary say s1 is less than s2 we can compare any  we can compare anything  yeah  student  so those numbers which we are comparing that is randomized over the entire set  any two numbers we pick up randomly  no  so don ? t look at it that way we are saying your algorithm  you have a certain algorithm which has the numbers written in an array  let ? s say one through n at the very first step it is going to come and make certain comparison let ? s assume it is deterministic algorithm  no randomization for now so same argument applies for randomization also but for now let ? s assume it ? s deterministic it will say compare lets say  first time it comes to me it will say look at the number in location 3  look at the number in 7 and tell me which is smaller whether the number in location 3 is less than the number in location 7 or whether the number in location 7 is less than the number in location 3 i put a node here saying let ? s say this array was s  so whether s3 is less than s7 is the first comparison it asked me for if i had said a yes  i do not know if i said a yes  it would go and ask me to compare some other two numbers it ? s your algorithm  i don ? t know what it is going to ask me but whatever it is going to ask me  i am going to put down here suppose it came and said s2 verses s5  whether s2 is less than s5 and if had said a no  may be it came back and asked me something else it came and asked me s6 is less than s13  it may be it is your algorithm  hindi  so depending upon what option do i have i have an option of basically saying my yes and no that ? s all i say i say a yes then i say a no and so on and on  depending upon what i rate as the relative order of these elements in these array think of these objects are some complicated objects you don ? t know what the relative order is so that ? s why you are asking me about that i have some way of figuring out what the relative order is may be today i feel like that the relative order should be based on gpa then tomorrow i feel like relative order should be based on height or whatever it is like  i can decide for that i would make a certain choices of yes and no  which would eventually end up in leaf  in an external node of this when you reach this say  you well i have sorted it you will sort because this is all the comparisons you did the question is how many comparisons did you have to do ? the number of comparisons is basically the length of the path that you took  the height of this tree yes so how many comparisons would you have to do ? how height does this tree have to be ?  student  n log n  why n log n ?  student  n factorial permutations of the array so they have to be n factorial leaves  yes  so that ? s right there have to be n factorial leaves in this tree now this is not a straight forward thing to understand  hindi   depending upon what these objects are  i should be able to get all kinds of permutations every permutation is a possible solution at the end  every permutation of these n numbers what is sorting ? a sorting you are given the elements like this and eventually what do you generate ? you generate a permutation of these elements yes or no ?  hindi  what is this ? this is just a permutation of this set of elements  hindi  this is just a permutation of this now all possible permutation should exist as leaves that depends upon what the relative order is  what i have picked as the relative order so given a certain permutation  if that is what i picked as the relative order then your algorithm should end up in that if i took some other permutation and picked that as the relative order then your algorithm should end up in that and so on and on every leaf of this tree corresponds to a permutation and further more every permutation should be representable as a leaf so which means that this tree has n factorial leaves it is not a complete binary tree  may be it is i don ? t care ; i know it is binary tree it ? s a binary tree with n factorial leaves so what is its height going to be ? at least log of n factorial so height therefore is at least log of n factorial  at least  hindi  yeah  student  sir our order to comparator  does it satisfy the symmetric or the transitive property  yes  it satisfies all of them even then it can i take a particular permutation of these elements and i say i am going to answer with respect to this permutation all queries that are asked for me  i will answer with respect to this particular permutation that i have in my head  student  is it possible  if suppose i have s1 there are 3 s1 s2 and s3  yeah  student  and at some point at that we have some decisions of s1 s2 and s2 s3  yeah  student  and then other point in the tree the other point in the tree decision based on s1 and s3  yeah  student  that can not take both the paths yes and no because  yeah i understand that  but that is not the point the point all we are trying to say here is that  student  it is not necessary every node  that i could have a certain permutation in my head and i could use that to answer all your questions and it could consistent so there have to be n factorial leaves and if in a binary tree  there are n factorial leaves then basically if there are some n leaves in a binary tree then it has to have a height of at least log n so which means that the tree has to have a height of at least log of n factorial height of the tree is at least log of n factorial this is roughly n log n which means that there is a certain permutation what is the height ? the height is the distance of the longest of the farthest leaf from the root if this is the furthest leaf from the root  then if this were the permutation then your algorithm is going to take a time of at least n log n  on number of comparisons at least n log n it ? s going to take  hindi   this is the argument  we can go over the slides once again and understand it more carefully this is the argument for why any comparison based sorting algorithm has to have at least n log n time so recall you are only permitted to compare two keys radix sort is not an example of a comparison based sorting algorithm because you are not comparing keys you are going into the keys  looking at the bits or the digits and so that ? s why radix sort doesn ? t have the complexity n log n it could be less than n log n  if b the number of bits or digits is less than log n yeah  so radix sort is the only such all other algorithms have to have because they are all comparisons based sorting algorithm  they have to have complexity of at least n log n and there are many which achieve that bound so with that i am going to end today ? s class we looked at radix sort  we looked at bucket sort  we understood what stable sorting is and finally we saw this lower bound on comparison based sorting data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 24 graphs today we are going to start talking about graphs we are going to spend quite a lot of time understanding the basic definition in terminologies associated with graphs  see some examples and then if time permits we are going to do the graph abstract data type or i think we will able to do the graph data type today  refer slide time  01  30  so question is what is a graph ? so pictorially this is what a graph is and what are terms we are going to have so graph is always represented by a two tuple v and e typically  v ? s what we will call the set of vertices and e will call the set of edges so set of vertices and a set of edges together specify a graph in this picture these red circles are the vertices i have given each of these vertices a name a b c d e to distinguish them and the blue lines are the edges  so edge really is a pair of vertices an edge is a pair of vertices or an edge is specified by giving a pair of vertices so this edge is said to connect what is u and v or will not use the term connect but this edge is an edge between u and v ; when i say e = u v is an edge then that means it ? s an edge between vertices u and vertex v  vertices u and v  refer slide time  2  08  so for instance in this example this graph could be specified either by giving this drawing or giving these this detail as in v the set of vertices is 5 vertices a b c d e and what are the edges i have ? each edge as you can see is a pair of vertices  an unordered pair of vertices here  a comma b is the same as b comma a all that specifies is it is an edge between vertices a and b so a comma b  a comma c is this edge ; a comma d is this edge  b comma e is this  c comma d is that  c comma e is this and d comma e is this so there are 1  2  3  4  5  6  7 edges and there are the 7 pairs mentioned here so set of vertices and a set of edges what are they used for ? they are for lots and lot of applications  you can model circuits as graphs  each of component of the circuit could be a vertex  refer slide time  04  18  so this could be a vertex  this could be a vertex  this could be a vertex  this could be a vertex  this is a vertex which is your cs201  you are trying to find out the path of these resistance to get cs201  they can be used to model networks so i can take the map of the city and every intersection could be modeled as a vertex and the roads which are connecting to intersections could be modeled as an edge and then that could be a graph and then start asking various questions on whether how can i go from this place to this place by asking the corresponding question on a graph so transportation networks  lots of this communication networks all of them are modeled as graphs  refer slide time  04  53  one more example so this is typically student day so you wake up  you mediate first 201 then you eat  may be you work then more cs201  play cs201 programming sleep and you dream of cs201 cycles  student  so idealistic  there is no room for any other course this is the day before mine so this is slightly different from the graph that i had shown in the previous example why  student  directed  directed so this is what we call directed graph because we can ? t do any meditation before you wake up so there is clearly an edge going from wake up to meditation so every edge has a direction associated with it  we will call such graphs directed graphs so we also consider directed graphs but in the rest of the lecture i am going to spend most of time with undirected graphs whatever things i define will carry over in a straight forward way to directed graphs as well so i will tell you what the difference is so to begin with let me go back to the previous slide in this example or in this definition where would the difference be when i am talking of a directed graph ? so e comma u v is not just a pair  it is an ordered pair let ? s say so the ordering is important  the first vertex typically specify what the start of the edges is or the origin of the edge and the other would specify the destination of the edge where the edge is going from  so what is the start and what is the end so as i said today is a fairly simple lecture  we are going to look at lots of terminologies so now you have understood what a graph is so there are two kinds of graphs a directed graph and an undirected graph so graph which is not directed is called undirected graph and you understand what a vertex is  what vertices are  what edges are adjacent vertices  so two vertices so this is all terminologies associated with an undirected graph so two vertices which are connected by an edge are called adjacent is this vertex and this vertex  these two vertices are they adjacent ? no  they are not connected by an edge while this and this are adjacent and this and this are not adjacent either so what is it which are connected by an edge are called vertices  the degree of a vertex the degree of the vertex is the number of adjacent vertices it has so what is the degree of this vertex ? 3 so in fact i have written down the degrees of the various vertices on these so this vertex is degree is 2  this vertex is degree 3  this is degree 3  this is degree 3  everyone understands the degree of the vertex it is the number of adjacent vertices sometimes we say that this edge is incident to these two vertices should i write down the word ? so this edge  let ? s say this vertex is vertex a and vertex b and this edge is e  so e equals a b is incident to vertices a and b so this edge is incident to these two vertices similarly this edge is incident into this vertex as well as this vertex so degree of a vertex can also be defined as the number of edges which are incident to that vertex there are three edges which are incident to this vertex  so the degree of this vertex is 3 these are equivalent ways of saying the same thing so question is what is the sum of the degrees of all the vertices   hindi conversation  twice the number of edges because when i am counting  so let ? s think of it in the following manner so the answer is right  twice the number of edges and the argument is actually half a line of an argument so pictorially i would say the following ; when i am counting three for this  i am counting three because i am counting this one edge  this edge and this edge so let me put 3 stones  one on each of these three edges then when i am counting 3 here i am counting this edge  this edge let me put down 3 stones then here i am putting down 2 stones  here i am putting down 3 stones  here i am putting down 3 stones  refer slide time  10  50  so i have to put as many stones or pebbles  if you want as many peppules as the sum of the degrees of the vertices now if i look at any edge  how many pebbles are there on that edge ? exactly 2  so the sum of the degrees of the vertices equals two times the number of edges so that ? s degree and you understand what degree is  you understand what adjacent vertices are now let ? s define the notion of a path  refer slide time  10  57  so a path in a graph is a sequence of vertices let ? s say v1  v2  vk such that consecutive vertices have an edge between them so if i take vertex vi and vi + 1 then these two vertices are adjacent there is an edge between this vertices so there are two examples here so this is my graph  the same graph as before recall that there is an edge between c and e also so this is the path a b e d c e why is this a path ? because there is an edge between a and b  there is an edge between b and e  there is an edge between e and d  between d and c and c and e  so this is a path similarly this is the path b e d c because there is an edge between b and e  between d and e  between d and c it is easy to construct examples which are not paths suppose i had written down a b c  a b c is not a path in this graph why because while there is an edge from a to b there is no edge from b to c  so everyone understands what a path is a simple path is a path in which no vertex is repeated so this is an example of a simple path b e c these three vertices are all distinct so it is a simple path a cycle is a simple path in which the first and the last vertices are the same so a c d a is a cycle  d a c d is the same cycle  c d a c is also a same cycle so you can read the cycle anywhere  this is a cycle this is a simple path in the previous slide we had an example of a path which is not simple this is not a simple path why  this is not a simple path because vertex e is repeated here  refer slide time  13  05  so this is a simple path except that the first and the last vertices are the same that ? s what a cycle is a graph is said to be connected if there is a path between every pair of vertices in the graph   hindi conversation  that the graph is connected  refer slide time  13  48  is this graph connected ?  student  yes  the path  path  hindi conversation   so this graph is connected  this is not connected there is no path from here to here  so this is connected this second one is not connected and this is the common mistake connected  hindi conversation  there should be a path between every pair of vertices  refer slide time  15.37  if there is a path then it is connected  if there is no path it ? s not connected so these two vertices so again this is the common mistake when you are writing a minus especially you are going to say these two vertices are not connected because you don ? t see an edge between them that ? s wrong terminology these two vertices do not have an edge between them but they are connected because there is a path between these two vertices so we say two vertices are connected if there is a path between them and a graph is connected if there is a path between every pair of vertices is this clear to everyone ? let ? s understand the notion of a sub graph  so this is a graph on the left hand side suppose i take a subset of the vertices and of the edges such that the resulting thing is also a graph  refer slide time  16.23  so i took some vertices from here  this vertex you can see it ? s corresponding i took 1  2  3  4  5  6  7  8  9  10  11 vertices from here there are 13 vertices in here i took 11 of them and i took some of the edges between these vertices i am not taken all the edges  as you can see this edges is not here  this would be called a sub graph of this graph i can not takes this edge because the other point of this edge is not there  i have not included here at all for an edge  the two vertices between which the edge is running are also called the end points of that edge each edge has two end points and those are the two end points so this is called the sub graph of this graph  refer slide time  17  39  now let ? s understand what a connected component is a connected component is a maximal connected graph suppose this is one graph  it is not 3 graphs i have drawn just one graph in this is not a connected graph is this connected ?  hindi conversation   student  this is not connected  this is not a connected graph why  because there is no path from here to here  hindi conversation   this is not connected because there is no path from here to here  there is no path from here to here  so it is not a connected graph if i look at this sub graph it is connected just this sub graph these three vertices and these three edges it ? s connected these 4 vertices and these 3 edges are also connected  these 5 vertices and the 7 edges on them are also connected these 3 are the connected components of this graph now what ? s the definition of connect ? it ? s a maximal connected sub graph what does a maximal connected sub graph mean ? this needs to be understood more carefully suppose i were to take this vertex and this vertex and i were to take this edge and this edge this is a sub graph  yes or no ? this is a sub graph of the original graph but this is not a connected component  i am not going to call this a connected component why ? because it is not maximal so what does maximal mean ? so when we say maximal in this class  we mean a set is called maximal if we can not increase the size of the set while retaining the property so a set is said to be maximal with respect to a certain property if we can not add more elements to the set and retain the property that ? s not true here i can add more elements to this set  i can add more edges or i can add more vertices and both so i can add this edge and it is still connected i can this vertex and this edge and it is still connected  i can add this vertex and this edge and it is still connected  i can add this edge now it is still connected  i can add this edge now it is still connected now if i add any other vertex or any other edge  suppose i decided to add this vertex  i add this but it is not connected anymore so this is a maximal connected sub graph and so we will call this a connected componenent so this entire thing is the connected component this is also a connected component and this is also a connected component  hindi conversation  i can not add any other vertices and still have the property of it being connected so essentially intuitively how do you think of connected component ? you just see which are the pieces which are connected among each other  each of them is a connected component as simple as that so this graph is 3 connected components more terminologies ; what is a forest ? forest is a jungle  jungle is a collection of trees and animals but we will leave out the animals so we are thinking of forest as a collection of trees so these are trees in the forest now what is a tree here  refer slide time  23  38  a tree here is a connected graph which does not have any cycles in it it ? s the same as the tree that we till now except the  hindi conversation   refer slide time  23  00   so this is an example of the tree it is a connected sub graph as we can see and it does not have any cycle in it this is also a tree  this is also a tree  this is also a tree when you have collection of trees it is a forest so forest is a collection of trees so everyone understands this what a trees ? tree is a connected sub graph which does not have any cycle in it so i am typically going to use n to denote the number of vertices and m to denote the number of edges in any graph so what is the complete graph ? a complete graph is one in which there is an edge between every pair of vertices  between every pair of vertices there is an edge this is an example of a complete graph  refer slide time  24.41  this is a graph on 5 vertices between every pair of vertices there is an edge so how many edges does a complete graph have ? nc2  because there are n22 pairs of vertices and there is an edge between every pair and so you will have so many edges how many edges does a complete directed graph have ?  student  three by two two  two times nc2 a directed and a complete so basically there will have to be and edge in both directions right so it will become twice if a graph is not complete then the number of edges going to be strictly less than n chose two so in an undirected graph this is the maximum number of edges that a graph can have  n chose two  hindi conversation   suppose i give you a graph on n vertices  zero  it might not have any edge at all so the minimum number of edges in a graph on n vertices is zero and the maximum number of edges is n chose two so once again we have n number of vertices  m number of edges  student  minimum elements connected in graph   that ? s the slide  suppose in a tree so what is a tree ? recall a tree is the connected graph which does not have any cycle in it how many edges are there in a tree ? i have said number of edges in the tree is n ? 1  why ?  student  every pair of   student  start from a node and we end and we can not have a like a cycle so starting  so  student  we can have about one two one two two three after and the number of edges these vertices two  each vertex is degree two in a tree every vertex is degree two  no  hindi conversation   student  nodes we write a so that will be n minus one you can ? t have repetition sir we get we can count the edges by  we will take the direction so the edge coming to a node is one    refer slide time  25.54  what do you mean coming to a node ? so is this edge coming into this node or this edge coming into this node ?  student  sir we take this as even starting from if you start from any particular node you don ? t have whether number of node have to have a  let ? s prove this  hindi conversation  it is a true statement  hindi  so let ? s prove that so what will be the proof ? we have to prove that a tree on n vertices has n  1 edges  induction  hindi  as simple as that so proof by induction  so what should be the base case ? let ? s say n equals two so suppose i have a connected graph on two vertices  hindi  statement is true so number of edges equals n  1 equals one so induction hypothesis  hindi  statement true for all n less than or equal to k let ? s say so now the induction step so given a graph on k + 1 vertices why should this have k edges ?  hindi  one leaf good so he is saying something useful  he is saying there is no cycle in the graph we have to use somewhere the fact there is no cycle in the graph  hindi   he says that there has to be one leaf  hindi   student  degree one  good so let ? s define a leaf  now as a vertex  a leaf is a vertex of degree one so his claim is that given a tree on k + 1 vertices we are given a tree  we are proving this the tree or every tree has a leaf  hindi  so maybe we come back to one of the vertices we have already visited  hindi  so it is not a tree  hindi  because that was a leaf  hindi    student  there should be part of the path relating these vertices  exactly this edge can not be part of any simple path between any two vertices because  hindi  this edge can not be part of any simple path and so even after i remove this edge and this vertex this there is a path between every pair of vertices so this is still connected  this is connected and by removing an edge and a vertex i can not create a cycle  hindi   i can apply my induction hypothesis on it so  hindi  we have removed only one vertex so this is a tree on k vertices and has k  1 edges  this is by induction hypothesis  hindi  and so we prove that  hindi    refer slide time  35.40  you have to use the fact  both the facts are critical that it is a connected graph and it does not have a cycle in it otherwise you will not be able to argue that it has k  1 edges  hindi   that ? s the proof for this  everyone follows this most text books would have this proof also  you can also go back and and look at one of the text so if the number of edges is less than n  1 in a graph then the graph can not be connected at all why ? this statement  if the number of edges is less than n  1 then the graph is not connected proof by contradiction suppose if it is connected then so let ? s follow this argument so suppose it is connected  if it is connected then why is it not a tree ? it is not a tree because it has a cycle so let ? s take lets remove an edge from the cycle  hindi  i should have switched but okay so what what are we trying to argue ? if number of edges is less than n  1 then g is not connected so this is another useful thing to remember that suppose i have a cycle  g is a graph suppose i have a graph in which there is a cycle  hindi  if you have a cycle and if you remove any edge from the cycle you can not make the graph disconnected by doing that so what is the argument that to prove this claim ? if suppose i have a graph on less than n  1 on less than n  1 which is connected why it is not a tree ? it is not a tree because there is a cycle in let me remove an edge from the cycle i only reduce the number of edges and it ? s still connected if there is another cycle let me still remove another edge so i will only get less than n  1 edges and the graph will remain connected eventually i will get a tree after removing all of this so i am contradicting the earlier claim which says that any tree has to have exactly n  1 edges in it it can not have less than n  1 edges so any graph which has less than n -1 edges can not be connected  hindi   is there something that is not clear ? so couple of examples n = 5  m = 4 this is a tree on 5 vertices  refer slide time  40.46  it has to have four edges  this is a graph on 5 vertices and 3 edges and it can not be a tree  it can not be a connected graph at all let me ask you a question suppose i have graph on n vertices and it has n  k edges n  k edges how many connected components do you think it has ? i have a graph on n vertices and n  k edges  how many connected components it has ? k or more  k when there would be no cycle and if there were cycles then it could have more number of connected components  try to prove this this is a very simple exercise so a given a graph on n vertices and n  k edges how many connected components does it have ? so more terms ; a spanning tree is a sub graph which means you are given a graph so it is a sub graph of a graph and this sub graph has to be a tree and it should include all the vertices of the graph  refer slide time  42.13  so spanning tree  hindi  tree which means the sub graph has to be a tree and  hindi  it should include everything ; include everything here means include all the vertices so as you can see this sub graph includes all the 4 3 7 and 3 10 13 vertices that are there and it is a tree there is no cycle here so this is the spanning tree of this graph  this is the graph and this is the spanning tree of this graph g has to be connected if g is not connected then there is no notion of the spanning tree if g is not connected then no sub graph of the graph of g can not be a spanning tree  hindi   so this is a useful thing to have  quite often your network could be a just spanning tree suppose these are points i want to connect so these are cities  these are possible roads that i can build but i just want to put the minimum amount of effort  i want to build has few roads as possible so that all these cities are still connected so i could built a spanning tree but this does not provide you any fault tolerance what does that mean  hindi  you can not reach from some city to some other city now as you can see if i cut of this link then these 4 vertices would be disconnected from the other 8 vertices  hindi  these 6 vertices would be disconnected from the other 7 spanning tree is a useful but they provide don ? t provide much fault tolerance  refer slide time  44.43  let ? s talk about bridges koenigsberg  this is a city in germany or austria i don ? t remember where so pragal river okay i don ? t remember where this is this city has this nice thing  there is a river flowing through the city and there is an island in the river and there are bridges in this manner so a is this island and there is a bridge from here to here  here so there are 7 bridges in all this black bar are the edges so question is can you start from here let ? s say or any point so can one across each bridge exactly once and return to the starting point why no  so suppose i start from here i can take this bridge go here  student  it will land up  and you can go on land up  hindi  so on and see let ? s see whether we can solve this problem or not ? suppose this would have been useful if you were a postmen who had to visit the various brides and you did not want to retrace the steps so this is also known as koenigsberg problem and euler proved that this is not a problem and we will give a simple proof for that one so we can model this thing as a graph  there is this island a so these are the going to be the vertices of my graph this island a this is one piece of land and there is this part b because i can go from anywhere to here this is one vertex  there is a vertex d and there is a vertex c which is this part so i will have a graph with 4 vertices in it a b c d and then depending upon so since there is a bridge from b to a in fact there are two bridges from b to a so i will put two edges between b and a similarly there are two bridges between a and c so i will put two edges between a and c there is one bridge from a to d so i will put one edge between a and d  there is an bridge between d and b so i will put one edge between b and d and an edge between c and b so i will get this is not a graph why is this not a graph ? because we did not define a notion of two edges between pair of vertices  we just talked about pair of vertices the edges don ? t form a set  they form a multi set so this is called multi graph  refer slide time  48.43  what is a multi-graph ? in which they put the many edges between a pair of vertices is called a multi graph but this captures that problem in certain sets so eulerian tour is a path that traverse every edge exactly once and returns to the first vertex and that ? s exactly what we want to do because these are the bridges so we want to traverse each bridge exactly once and return to the starting vertex can you do that on this graph ? so same problem can now be thought of here  can is start from a and come back to a and and visit each or traverse each exactly once so the same question a same  can you draw this picture without lifting your pencil or redrawing an edge  you know coming back over a line twice so  hindi  euler theorem says that you can do this if and only if every vertex has even degree  hindi   when you come to a vertex  you come by one edge and then you have to go by another edge and if you come again then you will need another edge to or fresh edge to go off by so every vertex has to have an even degree for this to work but here there are all vertices of odd degrees so clearly this can not be done now let ? s quickly do the uninteresting part  the abstract data type the graph can be thought of as a container of positions so you have the regular methods for any positional container like queues and stacks we always had this methods called size and is empty and elements ; elements would return all the vertices and the edges that ? s in and you can have some methods like swap which can swap two positions replaceelement those kind of thing  these are methods associated with the regular positional container swap is the generic method for any positional container when you are saying that provide two positions and swap the contents at those two positions that ? s the swap method so here i am not saying it specifically to the graph abstract data type  you will have to think of what it would mean so you could decide what it means here for this particular data type but i am saying it is a generic methods these are all generic methods for positional container and i am just saying in that context so here i have methods which are specific to graphs so numvertices would be a method which returns number of vertices numedges number of edges vertices would know be an enumeration of all the vertices  refer slide time  51.05  so it would be a method returns an iterator which will let you iterate through the various vertices of the graph  edges could be a method which returns all the edges directededges would be a method if you had a directed graph  it would return all the enumerated all the directed edges in the graph what does enumerator do and an iterator ? it basically returns an object which has two methods associated with it  one method is next and the other method is whether there is anything left  has next whether there is a next method next element at all or not so as you every time you call next it gives you a next object in the enumeration so when you are enumerating edges i call next once it will give me one edge  when i call next again it will give me another edge what order this edge is come in that you typically do not know it depends upon how you implemented the iterator undirectededges could similarly enumerate all the undirected edges incident edges  if i specify a vertex it would enumerate all the edges incident at that vertex this is for an undirected graph incident edges ; for a directed graph right there are two kinds of edges either there would be edges which start from this vertex or there would be vertex which end at this vertex so it could have a notion of any incident edges which are edges entering a vertexv which are ending at vertex v and you could have an out incident edges which are edges which are starting from vertex v going out of vertex  opposite so i specify an edge e  all of these are objects an edge is also an object and i specify one end point on the edge so this method gives me the other end point of that edge  refer slide time  53.24  degree gives me the degree of the vertex  indegree so degree would be for an undirected graph  for a directed graph there would be the notion of in degree and an outdegree indegree would be n number of edges coming into the vertex outdegree would be the number of edges leaving the vertex similarly i could have adjacent vertices  adjacent vertices would be a method which will turns an iterator over all the vertices which are adjacent to this particular vertex this would be for the undirected graph  for a directed graph you could similarly have a notion of inadjacent and an outadjacentvertices then you could have a method areadjacent whether vertices two vertices v and w are adjacent or not so this would be return a boolean value ; endvertices given an edge it will return the two end points of that edge  refer slide time  53.31  origin  for a directed edge e it would return where the edge is starting from  destination for a directed edge e it would return where the edge is ending given an edge e it will tell whether it is directed or not this method would be useful when you have  what are called mixed graphs  mixed graphs some edges are directed and some are undirected can you give me a setting where it would be useful to have a mixed graph  what kind of a problem setting can you imagine there ? it would be natural to have a  student  roads  roads  traffic network once again where you have some roads are one ways so you are bi directed edges  roads which are two way could be undirected edges and roads which are only one way could be directed edges there such a methods could be useful because given an edge you can then determine whether it is a directed edge or an undirected edge i will just take  i guess this is last slide yes it is make undirected e  so you are given edge and you set it to be an undirected edge you can have a method which reverses the direction so you can have tonnes and tonnes of update method also you can have methods to create the graph  change remove an edge  remove a vertex do whatever you want so set direction from  so you can set the direction of an edge suitably we just look through this these slides that i have given so this is just a subset of method depending upon what application you have  you could design your own set of methods  refer slide time  55.50  so graph can be thought of as data type  is an abstract datatype on which you can have a bunch of methods which you can use to update and modify the data type so with that we will end our discussion on graphs we will continue in next class however to see how to actually represent a graph what kind of data structures can you use to represent graphs data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 25 data structures for graphs today ? s class we are going to be talking about data structures for graphs if you recall in the last class we discussed various things about graphs various terms actually  what undirected graphs are  what directed graphs are  what is a path in a graph  what is a cycle  what are connected components so on and on we are going to start using the terminology now i am going to be discussing three different data structures for representing graphs  refer slide time  01  36  one would be the edge list data structure  second adjacency list data structure and third would be adjacency matrix data structure we will see what these are and how they can be augmented  how they can be combined to give better performances  faster running times  refer slide time  02  43  the simplest data structure is what we call an edge list data structure suppose this is my graph  it is a directed graph this is just a graph of a various flights these are airports the blue vertices and the red arcs are flight numbers from a airport to some other airport and suppose we want to represent this one way is to have two lists  one of the vertices and one of the edges we call each edge is a pair of vertices in this case it will be an ordered pair of vertices so we could have two such lists let ? s see what that corresponds to that is we called the edge list data structure the edge list data structure simply stores the vertices and the edges in two unsorted sequences it ? s very easy to implement and this is what it looks like  refer slide time  02  59  these are lists of vertices that you had and these were the various edges each edge recall corresponds to a certain flight between two airports this is a flight let ? s say nw 35 it goes from airport boston to jfk and so this particular node has references pointers to these corresponding vertices here for each edge i will keep two pointers  two references to the vertices between which that edge goes this is called the edge list data structures it is very easy to implement so there are many operations which can be done very quickly for instance suppose there was one operation which was given an edge  find its two end points so that can be done very quickly you are given the certain edge and you want to find the two end points of that edge that can be done or there was an operation called opposite  given an edge and a vertex  you wanted to find out what was the other end point and so on and on but there is one operation which is very inefficient and that is finding the adjacent vertices of a given vertex suppose i give you a certain vertex i give you vertex dfw and i say which are the vertices which are adjacent to this how will i do thus ? i will have to go through the list of edges and i have to find out all such edges suppose i wanted to find out vertices which are adjacent to dfw  i will have to look at this edge this edge is not an end point of this  so i go to the next one this is not an end point of this  i go to the next one this is an end point of this so i will look at what the other end point is  that is lax so lax becomes adjacent to dfw and so on and on this is what i will have to do to find out the adjacent vertices of a given vertex  refer slide time  04  54  if i look at the various operations  i can see what times they take so let ? s see size  isempty  replaceelement  swap these are all container operations these are when i am giving you the position  so size for instance is constant time  i can keep track of the number of edges and vertices in the tool list isempty is again constant time  if the size is zero than its empty replaceelement  if i give you a particular position corresponding to an edge and i say put some other edge at that location  that just takes constant time similarly swap all of these take constant time number of vertices  number of edges takes constant time what does the method vertices do ? it enumerates  it is an iterator over all the vertices since i would have to run through all the vertices  that would take time proportional to the number of vertices similarly these are iterator ? s over the edges  so they will take time proportional to the number of edges let ? s look at some more interesting thing suppose i say insertvertex  i want to insert a vertex then how much time should that take ? it should take constant or order n it should take constant time because these are unsorted lists similarly insertedge  insertdirectededge all of these can be done in constant time let ? s look at remove vertex this last operation you will not able to see it very clearly perhaps because it is getting overlapped here but it is removevertex so suppose i wanted to remove a vertex how much time would it take ? if i remove a vertex  i also remove the edges which are incident to that vertex clearly because otherwise where would the end points of the edges be referring to i have to essentially get to that vertex and i also have to traverse to the list of edges the list of edges is  number of edges is order m i have to traverse through the entire list to find out whether which are the vertices which are adjacent  which are the edges which are incident to this vertex and also remove those edges which is why this operation is going to take order m time  student   here when i say removevertex  i am assuming that you are given the particular vertex you want to remove let ? s say you are given the position in the list  hindi   in this manner you can look at this slide more carefully and understand the times  refer slide time  07  10  this is not the only way of representing a graph there could be other ways we are now going to look at what ? s called the adjacency list data structure this is your graph  here i am taking an example of an undirected graph but all these data structures  all the three data structures that i am going talking of today can be used to represent both directed and undirected graphs if so in this undirected graph how do i represent it ? i have an array of vertices  an array corresponding to vertices let ? s say this location corresponds to vertex a  this corresponds to the vertex b  this location corresponds to c d and e that ? s how it should be now what are the vertices which are adjacent to a ? they are b c and d  so i will have a link list starting from this location which will have elements b c and d in it this corresponded to location vertex b so which are the vertexes adjacent to b ? a and e so this links contain only a and e in it this was corresponding to d  vertices adjacent to d are a c e so that ? s why we have a c e in this these lists are also unsorted lists so adjacency list of a vertex  so what we are keeping track of is the adjacency list of each vertex how much space does this data structure require ? i will have an array of size n and what will be the length of the link list at each location the degree of that vertex the total space required in this part is sum of the degrees which we argued is two times m the total space required is n plus m  so it should be of the order of theta of n plus m  student  so having implementing this as a link list  hindi  we could keep them in an array  that ? s the next data structure we will see what are the pros and cons for that  student  array implementation of the linked list  pardon  student  array implementation of the linked list  no  what he is saying is  we will come to what he is saying in the next slide  when i show you the adjacency matrix implementation what ? s the advantage of this ? how is this better than the previous data structure ?  student  moving a vertex  adjacent vertices  to find out what are the adjacent vertices of a given vertex that can be done much more quickly here how much time does it take now ?  student  order  order degree  student  order degree  if i want to list out all the adjacent vertices if i give you two vertices and i ask you are these two vertices adjacent ? how much time would you take ?  student  order degree  order degree still degree of one of the vertices let ? s say  the smaller one  student  the smaller one   student  the larger one  this is an array this one is an array this is an array of just references of pointers  nothing else there is nothing else stored in this array you can store more information if you want  any information associated with the vertex you can store at this storage location in the array  student   it ? s just an array  you can  student   it ? s an array typically indexed by ? suppose so you typically number your vertices 1 2 3 4 and so on and then that would correspond to this location  refer slide time  10  59  we can combine this with the edge list data structure and we will get something more complicated like this what is this ?  hindi  is just your edge list just i showed you and now with each of these vertices  i have the adjacency list associated with each of these vertices i have both the in adjacency list and the out adjacency list from each of these elements  there are two pointers one is pointing to a list of incoming edges and the other is pointing to a list of outgoing edges we have combined this and that the adjacency list and the edge list data structure  somehow we have combined them let ? s see in what regard is this better than this ?  student   here for instance the operation  suppose i said  given a particular edge here we actually have no mechanism of storing edges really we are not really storing edge information we are storing information only with regard to vertices  given a vertex what are the adjacent vertices  student  so edge information regarding the edges easily obtained what information regarding the edges do we want that we what   suppose i had the same picture as before i have this graph i ask you flight ua 120 which airport from  what is the starting airport  what is the ending ? yes  so we have information associated with edges and that is somehow not getting represented in this  student  we can store name of  pardon  student  we can store  you can store there is no harm you can store  so with this whichever was that airport you could do that  but now if you have to retrieve that information suppose you have to answer that question  given a particular flight number  what are the starting and the ending airports you will have to go through this entire data structure to be able to figure that out while here you could get that information very quickly  student  there is also an   that ? s not connected to the top  student  as good as having a double arrow for an edge list so this thing is as good as having a double arrow for the edge list  double arrow  what do you mean by double arrow ?  student  doubly length like in the above portion of this slide an arrow points from an edge to its vertex  vertices and from here it ? s pointing from the vertex to the edges exactly let ? s look at what are the time requirements for this particular data structure let ? s see suppose i want to find out the incident edges edges incident to a certain vertex so i can get to that vertex  so given a particular vertex i can find both the in edges and the out edges in time proportional to the degree  the in degree and the out degree respectively so that ? s the incident edges given two vertices  are those two vertices adjacent ? how much time do i need for this ? so given one vertex i just need to run through the ? it ? s given a particular vertex dfw and let ? s say mia are this two adjacent ? is there a flight from dfw to mia  what will i do ? i will go in the out list of this and see no  i will have to do more  i will come to this i will come to the out list and then i have to go from here to this list here this is just numbers or whatever  this would be referenced to this information it depends upon how you organize it this could be organized as out list of edges or it could be organized as out adjacent vertices if it were organized as out adjacent vertices it would have been easy but if like here  i am organizing it as edge list  so you will have to now go to the corresponding edge and see what the other end point of that edge is all of that is constant time there are many ways of organizing a graph i am just giving you a very high level idea and then for your particular application  depending upon what operation you are doing more often  you will have to choose the appropriate organization  student  organize the data it will be in minimum of degree of u and common degree of worst case will be maximum  worst case would be maximum but suppose i also kept degree information associated with each vertices that ? s not very hard to do just one integer variable which will keep track of them  then i can make this it depends upon where you want to optimize if you are doing this kind of operation very often then it makes sense keep degree and try and reduce running time if you are not doing this operation then there is no reason why you should keep track of the degrees of the vertices third representation is what ? s called the adjacency matrix representation and this is very simple representation here you just have an n cross n matrix and there would be basically just binary entries bits 1 0  there is a one which is a true  if there is an edge between those two vertices there is a one here because there is an edge between a and b what can you say about this matrix ? what property does it have ?  student  symmetric  it ? s symmetric if it is an undirected graph it would be symmetric if its directed graph it need not be symmetric if in a directed graph you can have it that this would be one  if there is an edge from b to a or you can have it the other way round depending upon what  you can keep any way you like m  i  j  is true that means there is an edge i  j in the graph m  i  j  false means there is no edge in the graph and the space requirement is n square it ? s again a very simple implementation  it ? s also quite efficient in a certain sense or let ? s see  refer slide time  17  37   student  adding a vertex means  adding a vertex would mean creating a new row and a new column it is order n time  order n so that will be order n time i could have for instance ? again there is a possibility of  instead of having 1 ? s and 0 ? s  you could keep track of the edge information here you could keep ? the adjacency matrix structure augments the edge list structure with a matrix  so you could also have the edge list together with the adjacency matrix both of them together in the edge list recall that for each edge you would have information about what are the two end points  refer slide time  18  21  there could be referring to the corresponding locations here  instead of pointers they could just be integers not they are telling which row they corresponds to and here instead of 1 ? s and 0 ? s  for the ones you could also have the corresponding edge augmenting an array  again so this is an operation which is not done very often quite often the graphs that you work with are static graphs that is you don ? t add new vertices in the graph  you don ? t add  remove new vertices from the graph if you want to have a data structure which implements that then perhaps this is not the right data structure  student  array implementation  you could do that  of course all of those thing could be done i am not saying it can not be done here at all but then this would perhaps not be the best data structure to use if this was a frequent operation you were doing  adding vertices  student  even that will take order n time only because just when 2n minus 1 basically n square  let ? s look at what are the times required for the various operations here ? given two vertices to determine if they are adjacent or not  it is just a constant time operation but now given a particular vertex to find out all the vertices which are adjacent to it  how much time does it take ?  student   row or column which is order n it is not order degree now  it is order n this is the difference  refer slide time  20  21  why because now you will have to take that particular row or column and look at all the entries and see which are ones and which are zeros that will give you order n so incident edges  inincidentedges  outincidentedges all of them will take order n insertvertex  remove a vertex i have put down order n squared here because i am assuming that you have to copy them into a new array it ? s not very easy to take a two dimensional array and extend it by one row and one column you understand why ? because the problem is that two-dimensional arrays are stored as one dimensional arrays you know after all in a particular row major or column major form  if you want to extend it now how does that happen ? because you have to then move all the information that ? s why extending a two dimensional array is not an easy task you essentially have to copy all the information into a new array that ? s all i will have to say about data structures for representing graphs there are three different things you have seen adjacency list  adjacency matrix and the simple edge list you can depending upon what operations are critical  which are the ones that you are doing more often combine them in a suitable manner if space is not such an issue then you can keep the adjacency matrix data structure because it ? s quite simple but it requires a lot of space it requires n squared space the standard implementation which is preferred very often is the adjacency list if you can ? t think of anything then just use the adjacency list data structure to implement a graph now i am going to go onto graph searching algorithms this is something that you have done in a certain sense which is why i am going to be taking it up right in this class  refer slide time  22  27  what is the graph search algorithm ? it is basically a mechanism of visiting all the vertices of the graph in some systematic manner by systematic i mean  you know in some organized manner so that you don ? t miss out on any vertex a graph could be either a directed or an undirected graphs and we are going to be assuming adjacency list algorithm implementation of the graph for the algorithm that we would be discussing graph searching algorithms are the most common algorithm that you typically perform on graphs and it appears on a whole lot of settings  refer slide time  23  03  the algorithm that i am going to be discussing now is what is called the breadth first search algorithm or bfs for short what does bfs do ? it will visit all the vertices of a connected component in a graph and it will define for us what we will call a breadth first search tree which will be a spanning tree on this particular connected component we are going to be discussing breadth first search on undirected graph only today breadth first search makes more sense in undirected graphs and the idea is roughly the following you start from a vertex and this starting vertex let ? s call it as s  it is assigned a initial distance of zero we are going to proceed in rounds in the first round you are going to  so think of yourself as in a maze  in some kind of a maze you have a string with you  you are going to use this to help you search the maze you have tide one end of the string at one location in the maze now you unroll the string by let ? s say just one unit and you see where all can you reach by unrolling this string by just one unit those in some sense will be  what we will call the vertices at a distance of one from the starting vertex after you visited all such vertices then you will unroll the string by one more unit and see which all vertices  new vertices you can visit as a consequence of that and so on you will understand all of this when we start discussing the algorithm in more detail we will do this  so we will unroll the string by one more unit find out all that we can visit now  refer slide time  24  59  unroll the string by one more unit  find all the vertices that can be visited now and so on and on each vertex we are going to give it a label which will be that when it was first visited what was the length of my string then ? if it was visited in the first round then i am going to give it a label of one if it was visited in the second round i am going to give it a label of two and so on and on what this label will signify eventually would be the distance of the vertex from the root  from the starting vertex or the root as i call  refer slide time  25  34  all of these will be clear with some example suppose this was my graph  very simple graph and s was my starting vertex i give it a label of 0 i am going to have a q  so this is the only data structure i need to implement in this algorithm a q recall this is very similar to your minor question you have a q and on which you have s at any point what you are going to do is look at the front element in the q and look at all the neighbours of that front element the neighbours of this front element are w and r  so you are going to put them into the q now i am going to remove an element from the queue  remove the front element from the queue  find its neighbours and put them into the queue  insert them into the queue when i insert a vertex into the queue i color it gray  after i remove a vertex from the queue i color it black initially this is the only vertex in the queue so it ? s grey all the vertices which are in the queue will always have a color of grey in some sense the grey vertices are vertices which have been discovered till now but i have not gone beyond that  grey signifies that black means that i have also gone beyond those vertices and white means undiscovered  i have not reached those vertices at all this is the order in which the thing is this is the first picture  the second  the third and the fourth let ? s understand this  i had s in the q  i removed s  colored the vertex black  took its two neighbors and put them into the queue i assigned them a label of one node then the label of s  so the label of s was 0 so i gave them both of them a label of a 1 now let ? s see what the procedure here would be i remove the front element of the queue which is w i will color it black  i will look at its neighbors how many neighbors does w have ? 3 neighbors s  t and x amongst these s already is black so i don ? t touch it at all t and x are white so i will put them into the queue and color them grey from white i color grey  grey color gets colored to black when an element gets inserted in the queue  its gets colored grey when it gets knocked off from the queue  it gets colored black  as simple as that t and x get to put into the queue what label do they get ? they get a label of one more than the label of w why one more than the label of w ? it was because of w  the t and x came into the queue when i had knocked off w and then looked at its adjacent vertices  i have found t and x so they get label of one more than that so they get a label of two this is the q at this point now i look at vertex r which is the front of the queue what will i do ? first color it black  look at its adjacent vertices which are white and put them into the queue color it black look at its adjacent vertices which are white  this is the only vertex which is white  put that into the queue with the label equal to one more than the label of r that ? s what this is and this get a grey color once again you see all the vertices which are grey are sitting in the queue at any point this is the invariant you have if a vertex is grey  it is in the queue if a vertex has not yet been visited it is white  if a vertex has been visited and removed from the queue its black everyone understands this next vertex we are going to touch is t we are going to remove t from here  going to look at its adjacent vertices how many adjacent vertices it has ? 3 but the only vertex which is white is u it is only u which will get entered into the queue and nothing else and u will get colored grey what will be its label ?  student  three  3 u will get colored grey  its label is 3 and its get added to the queue now i knock x out of the queue  it gets colored black i look at its neighbours which are white this is the only one which is white  this gets a label of a three  it gets colored grey and it ? s added to the queue so y is colored grey  gets a label three and is added to the queue this is what the queue looks now like now i remove the front element that ? s two  look at its right neighbours  it has no white neighbour nothing needs to be done it gets colored black and we remove it from the queue  so the queue is now u and y only so i remove u from the queue  i color it black  look at its white neighbours  it does not have any white neighbour so nothing to be done then i look finally at y  y is at the front of the queue i look at its white neighbours  no white neighbour nothing needs to be done this gets removed from the queue and the queue becomes empty the procedure stops when the queue become empty  these are the labels on the vertices  refer slide time  31  29  now what do these labels signify ? one signifies that it was discussed in the first round  two that it was discussed in the second and three that it was discovered in the third round this one is also the length of the shortest path from s  hindi  if i look at this vertex u  there are many paths from s to u i am interested in the path which has the least number of edges on it  the smallest number of edges on it and the path with the smallest number of edges is this path with three edges on it and so this is label three we will see why this is getting done in this manner shortly  refer slide time  33  41  so one more way of thinking of this so that you understand this completely  i started from this in the first round i am visiting the adjacent vertices of this these are the vertices which are getting a label of one these are also called level one vertices  these are the vertices which are getting a label of a one in the next step  all though i am going one vertex at a time but now the vertices which are going to get a label of two will be vertices which are adjacent to these which are these vertices ? these are i and c  so these are the two vertices which will get a label of a two now the vertices which get a label of a three are the ones which are adjacent to the vertices which are at two and they are basically m  j  g and d this is getting a label of a three  refer slide time  34  02  the vertices which are getting the label of a four would be the one which are adjacent to the vertices which are at a label three  which are these vertices so these get a label four and these would finally get a label of a five you can think of a breadth first search as dividing your vertices or partitioning your set of vertices into levels or sets there is one vertex at level zero  some vertices at level one  some vertices at level two  some vertices at level three and so on what will be the number of levels going to be ? the number of levels would be the maximum distance of any vertex from s  refer slide time  34  56  now this is what the algorithm is  so let ? s run through the algorithm and then we will look at the other aspects of the algorithm initially every vertex is given a color of a white so du is the label on that vertex  on a vertex u du is the label so it ? s initially infinite which means i have not put any labels on it and pi u  i will come to what pi u is pi u signifies the predecessor vertex the vertex because of which you got its label what i mean by this is so for instance let ? s look at this vertex c here this got a label of 2 which was the vertex because of which it got the label 2 b  so pi of c would be b what is the pi of k ? you can tell me  this vertex got its label from either this or this i do not know which  it could be any we will just pick one of them arbitrarily this is the initializing all vertices and then how do we begin ? we color the vertex s which is our starting vertex grey  we give it a label of a 0 its pi of u is null because it doesn ? t get its label from anyone else but from itself and we add it to our q we insert it into our queue and this is the entire process this green should have extended all the way here what we are doing is while the q is not empty  we keep repeating something let ? s say we remove the element from the head of the queue  so u is the element from the head we are not removing it yet  so u is the element at the head of the queue we are looking at all the adjacent vertices of u for all v which are adjacent to u  if the color of v is white only then we do process it if it is already grey or black  we don ? t do anything with it if the color of v is white then what do we do ? we add it to the queue  we color it grey and we give it a suitable label what is the label we give it ? d of u plus 1 whatever was the label of u  we add one to that and we give back to this since this vertex v is getting its label from u  pi of v becomes u we add the vertex v  such vertex into the queue and once you have done it for all the vertices  we do this dequeue operation which is we remove u from the queue this could have been done here also  it could have been done at the end  it could also have been done here that ? s okay and u is colored black to signify that it has been removed from the queue we keep doing this till the queue has an element in it does everyone understand what i am saying ?  student  so for initializing also we have to do some operations like breadth first search  what do you mean for initializing ?  student  making the color of every node to be white  making the color of every node to be a white  what can we do ? what is color ? color is something like an array for every vertex so this is an array of size ?  student  values into it is less than the value we would assign to it  but we can also assign it  you know it is we are just creating an array  so let ? s say white is zero so just assign  put zero to all the entries in the array we just giving a color to ? each of these color d and pi will have to be separate arrays indexed by the vertices  we are just assigning that  refer slide time  39  09  how much time does the breadth first search procedure take ? what are we doing ? basically all the time is being spent in this loop yes  because this is just  how much time do i spend here ? one for each order n for each vertex  i am spending constant amount of time how much time do i spent in this part ? constant time and here  all the time is getting spent in this loop how many time is this loop executed ? order n times how many times is this part of the loop executed ? this is two loops  one within the other for each vertex v adjacent to u  i am doing so we are doing as much as the degree times if i look at these statements they are being  what is the total time i am spending on these statements ? order degree for each vertex and summed over all the degrees of the vertices which is order m  twice the number of edges let ? s look at each statement and see what is the total time  what is the maximum time that could be spent on each statement how many times the statement is executed  how many times the statement 10 executed ?  student  order n  order n how many times is statement 12 executed ?  student  order m  order m because 12 is executed degree many times for each of the vertices so order m  so 12 is executed order m times in the worst case similarly if 12 is executed order m times so 13  14  15 and 16 could also be executed no more than order m times actually you can say something about 16  how many times is 16 executed ?  student  order  order n and not order m because you enqueue a vertex only once once you enqueue it  it becomes grey  once it get removed from the queue it becomes black you don ? t ever touch it again once it becomes black you don ? t ever put it back into the queue you only put a white vertex into the queue in fact this statement 16 here is executed order n times and so this is also executed order n times and this is also executed order n times it is only this if statement which is really executed order m times yes  you understand why if this is executed order n times  this is also executed ? because they are one after the other with no condition in between them in any case the total time spent on the entire thing is order m plus n  refer slide time  42  18  let ? s look at the couple of properties of bfs bfs what it is doing is it starts from a certain vertex  a source vertex s and it is visiting all the vertices which can be reached from s it will visit all such vertices which can be reached from s what do i mean by that ? all such vertices to which there is a path from s  all those vertices will get visited which means that all those vertices which are in the connected component of s  connected component containing s will get visited if the graph was in more than one connected component  if the graph had more than one connected component then if s is in a certain component  i will only visit those vertices the vertices in the other connected component i will never be able to reach them at all the first thing to keep in mind is that it will discover all the vertices which are reachable from a source vertex if a vertex v is at level i then there is a path between s and v with i edges on it i have not told you what a bfs tree is ? so let ? s first understand what a bfs tree is so my slide order is a bit wrong here what is a bfs tree that we have generated as a consequence ? so recall that for each vertex  i have kept track of one edge which gave that vertex its label  refer slide time  44  16  so let me consider the following graph of the graph g what is the sub graph ? the set of vertices or all the vertices which are reachable from s  all those vertices which have a pi of v which is not null and s was given a pi of v which was null so pi is also known as the predecessor each of the vertices which have a predecessor is the set of vertices vpi every vertex is given a predecessor  every vertex which was visited given a predecessor it is basically the set of all vertices which are visited what are the edges in the sub graph ? the edges in the sub graph are the edges from the predecessor vertex to this particular vertex for every vertex let me illustrate this let ? s look at this picture here this picture if i ignore the dotted edges  if i just keep the dark edges with me  the solid edges they are my ? this is the sub graph that i am talking about note that each of these vertices has a predecessor except for this starting vertex  this has no predecessor  refer slide time  45  41  what is predecessor of this ? it was this  the predecessor of this was this and the predecessor of this was this so these are 3 edges that i am including in my sub graph the predecessor of this is this  the predecessor of this is this one  this was level 2 at level 3 when i had vertices  this has the predecessor as this  this had a predecessor let ? s say this this has its predecessor this  n has i as its predecessor  m has i as its predecessor  refer slide time  46  00  is this clear to everyone ? because this vertex was discovered because of i when i took i out from my queue and looked at its adjacent vertices which were not yet visited which are colored white then i found m n and j  so m n and j have as their predecessor vertex i and d and g have as their predecessor vertex c  k could have g or j as its predecessor let ? s say we decided g as its predecessor and h as d as its predecessor and l has g as its predecessor these are the predecessors and then finally p has l and o has k as its predecessor  student  g and j are at the same level  g and j are at the same level  yes why is not ?  student  not necessary  it is they both  why are they at the same level ? because they both get the same label  same level number  student  g is not necessary  they would  it is necessary because they are both adjacent to vertices which have label two  g is adjacent to a vertex which is ?  student  is but i am saying for deciding for an element k which has two predecessors  yeah  student  you will see which which predecessor has the shortest label  no  both will have the same label then  student  then you will not assign  both will have the same label if there was such a  you can not have a vertex which has two predecessors at different levels  student  but this we only call ordered at which order can be different that we can  this is the predecessor information and these solid lines now form a spanning tree why do they form a spanning tree ? how many solid lines are here ? how many solid lines do i have ?  student  n  1  n  1  yes why n  1 and not n ? there is no edge entering a because a did not have any predecessor every other vertex has a predecessor  for every other edge there is one solid line  exactly one so exactly n minus 1 edges using these solid lines i can go from a to any other vertex yes  if there is a solid line entering here that means that i can come to this vertex from that vertex and there is a solid line entering here  so i can come to this vertex  from there is a predecessor of that and there is a solid line entering here  so i can come to this vertex from some other and so on so eventually i hit the root basically starting from s  i can get to every other vertex this is a tree  it is a connected graph these solid lines form a connected graph with exactly n minus 1 edges it has to be a spanning tree recall that we said that if a connected graph has no cycles in it then it has n minus 1 edges if a connected graph has n minus 1 edges then it has no cycles in it and it is a tree this is what we have this is called the breadth first search tree  the bfs tree this spanning tree that we have which is the solid lines is the breadth first search tree i think in both of the previous examples i had this this is the breadth first search tree here  the blue lines they form the breadth first search tree once again for each vertex  i have just darkened the line i have not drawn the arrows here but i have just darkened the line because of which was corresponded to the predecessor  because of which this vertex got its label this vertex got its label 2 because of this vertex this got its label 2 because of this vertex and so i have darkened these lines and this forms your spanning tree so this is the breadth first search tree let ? s quickly go on this is the breadth first search tree i will switch over to this screen to show you something i did not so what has really happened is that we started from this vertex s  these were my vertices at level 1  these were my vertices at level 2 and so on let ? s say the largest level was 7 now this will answer some of your questions also when i was at s  all these vertices which are here at level 1 are adjacent to vertices in s that ? s why they are at level 1 the vertices in level 2 are all adjacent to vertices of level 1 that ? s why they got the level 2  number label 2 they got a label 2 because they were adjacent to some vertex  may be more than one but they were adjacent to some vertex in level 1 could these vertices have been adjacent to s ? they would have been in level 1 because when i looked at all the adjacent vertices of s  i would have discovered this vertex and put it level 1 instead so such an edge can not appear this is the nice thing about structure that you get i am not showing the tree edges here  i am just showing all the edges of the graph now all the edges of the graph just go between adjacent levels they can not skip a level i can not have an edge which skips a level  it can not go like this this can not happen why ? because when i was this vertex  would then have been in this level instead i made a small mistake i said all the edges go between adjacent levels they could also go within the same level  yes why could they ? i could easily have this this vertex was adjacent  these two vertices were adjacent to s but they were also adjacent to each other  no harm even later this is what the graph looks like now and this is the important property of breadth first search that you have to keep in mind certain edges we would call them tree edges  so this is my bfs tree  this edge so my bfs tree would look like this now let ? s say these edges and then from each one of them  i have let ? s say something like this i am basically covering all these edges for each of these vertices is getting its level number because of certain vertex at the previous level and it ? s this edge having through did in my bfs tree this is what my bfs tree  student  from the edges that through from elements of the each other if we have two elements of the same level in the   student  we we wont count those  no  if i have an edge between two vertices of the same level  such an edge  this edge was not part of bfs tree why ? what are the edges which are in the bfs tree ?  student  solid  the predecessor this vertex did not get its level number because of this vertex it got its level number because of this vertex it is this edge which would be part of the bfs tree and not this  refer slide time  54  24  let me  student  multiple edges leading to a node we take only one  we take only one we have that  so just to show you all those things i just said to you  i had organized it like levels but it is the same thing happening here these are the levels zeroth level  level 1  level 2  level 3  level 4  level 5 as you can see all edges are going either between adjacent levels or within the same level this vertex could have got its level number from either this vertex or it ? s this vertex  so i picked one arbitrarily and this i included in my bfs tree the bfs tree is not necessarily unique but the level number of each vertex will be unique why would it be unique ? the level number of a vertex would be the length of the shortest path from s to that vertex why shortest path ? we have not proved yet if there is a path from a to a certain vertex of length 6 then this certain vertex lets say whatever z  will get a label of at most 6 if the shortest path was of length 4 then this vertex can not get a label of more than a 4 because on that path if there is a path of length 4  what does that mean ? there is s  there is a first vertex  the second vertex  the third vertex and then this vertex z then the first vertex would get a label level which means that the first vertex is adjacent from s it will get a level number of 1  the next vertex will get a level number of 2  the third vertex will get a level number of 3 and this vertex will get a level number of 4 that is why each vertex gets a level number equal to the length of its shortest path from s and that is unique we said in choosing the predecessor edges  you could choose any one but the level numbers would be unique for each vertex because it corresponds to the length of the shortest path from the route with that we are going to end today ? s discussion on breadth first search we are going to be using breadth first search for finding the connected components in a graph and we will see that in the next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 26 two application of breadth first search -connected components -bipartite graphs today we are going to be looking at two applications of breadth first search in particular i am going to look at applying breadth first search to finding out the connected components in a graph and a second application will be to checking if a graph is bipartite  refer slide time  01  20  i define what bipartite means and then we will see how to apply breadth first search recall that a graph can be in many pieces  so i could have a graph which looks like that how many connected components does this graph have ?  student  five  five  hindi  connected components what we want to do is have a procedure which will label these vertices it will label every vertex here 1  say that this is in the first connected component i have just arbitrarily called this as the first connected component it will label every vertex here 2  it will label every vertex here 3  it will label this vertex 4 and it will label this vertex 5 i want a procedure which returns this labeling of the vertices i will have an array called label let ? s say and for each vertex  so this is the index corresponding to vertex v at this location i should have 1  2  3  4  5  6  7 whatever is a number of connected components that number should appear here so that by looking at this array  given any two vertices i can just in constant time determine if they are in the same connected component only if they have the same label then that means that they are in the same connected component  if they have different labels they are in different connected components question is how will i do such a thing this is very useful procedure first it is also counting the number of connected components your graph has how will i do this  is the question that we are going to ?  student  do the  for each vertex and if the vertex are maintained one which counts vertexes which already have been traversed   the standard things in any case in the first slide they said it is an application of breadth first search the first thing you are going to do is to do some breadth first search somewhere  hindi   there is a notion of a starting vertex that we take one starting vertex and then we start doing our breadth first search from there suppose i take this as my starting vertex and starting doing the breadth first search  so what ? s going to happen ? i am going to give each vertex a ? so there also i was giving each vertex a label  a distance let ? s call that a distance label and let ? s call this component number there what i am going to do is all the vertices that i visit  if i do a breadth first search starting from this vertex  which all vertices am i going to visit ? only the vertices in this connected component is it clear to everyone ? in the very first step  in the first round what i am going to do is i am going to look at all these three adjacent vertices and put them into the queue these will get visited then when i take this out of the queue then i will put this into the queue and so on i will end up putting all of these vertices into the queue  removing them and so all of these vertices will get visited but i would not visit any of these vertices i would visit only these vertices as i am visiting these vertices  i can keep giving  assigning them a component number equal to one i keep assigning whatever these vertices are let ? s say these vertices are some a  b  c  d  e and f and a appears here  b appears here and c appears here and d appears here and e appears here and f is here i give each of these a connected component number of a one now what should i do ?  student  implement the  initially what are the values that i give to each of these connected component number ? let ? s say initially everything is zero now after i finish this one bfs  some vertices have a connected component number of one and some others have connected component number of zero which are the ones which have zero ? all of these and which have a one ? these now what should i do next ?  student  pick any of the  pick any vertex with zero  easier set then done how do i pick any vertex with zero ? i just start from here and find the first place  first vertex which is a zero then what do i do ? then i  let ? s say this was the first vertex which was at a zero  very first this is let ? s say this vertex here  so i start a bfs from here  hindi  there might be a two here  this would get label two  there might be a two here  this might also be two  this might also be two something like that now find the next zero how do i find the next zero ? start from  so this is where the small thought is required i should not start again from the end  start from where i found the last root vertex and continue from there  continue from the next location then once again when i find a zero  i start a breadth first search from there once again that will end up labeling certain vertices  hindi  once again i find the next zero and so on and on this will at the end do what we wanted it do to question is how much time does it take ? how much time did this breadth first search take ? number of edges plus the number of vertices of course number of edges is more than the number of vertices why ? it ? s at least n minus 1 if a graph is connected then there is a spanning tree in the graph if there is a spanning tree  the spanning tree itself has n minus 1 edges in it  hindi  is the total turning time equal to order number of edges ?  student  order number is total vertices  is this the right number ?  student yes  yes  hindi  number of edges can be much smaller than the number of vertices in this entire graph the graph could have zero edges  student  suppose  so we have not counted the time required for traversing this array to find the next vertex from which to start our breadth first search how much time does it take to traverse this array ? order n exactly  order n critically because we are not going back from the starting when searching  hindi  if we start always from the beginning then it will be order n times the number of components  student  only once   hindi  we have just made one scan of this array that ? s critical the time required for that is order n  refer slide time  07  30  the right time bound should be order m plus n you understand why am saying m plus n here and not just m ? it is not the case that m is more than n  it is not either the case that n is more than m i can ? t say that because this is not a connected graph over which i am doing the breadth first search so this would be the right thing to say or if want to say maximum of m  n that is also okay but just saying order m or order n is not correct  student  when you know a you started breadth first search then how do you label a without label b  no  i started my breadth first search from here when i started my breadth first search from here let ? s say you are saying i want to start a breadth first search from here suppose i started my breadth first search from here then i looked at its adjacent vertices these b  e and f were its adjacent vertices these vertices i am going to put them into the queue  at the time i put them into the queue i am also going to go to the location corresponding to the these vertices in this array and mark them one  student  sir but without like you are saying we go through the array work  we go through the array only once for selecting the root vertex but for each one of these vertices  when i am visiting each of these vertices in my breadth first search  at that point i am going to go that particular location in this array and label that vertex  student  you are not counting the time  how much is that time ? constant for each of these vertices so again number of vertices is n so again i would take order n time for that for each one of these vertices  in any case i am spending a constant amount of time because i am putting this vertex into the queue  i am removing them from the queue i am actually going to give them a distance label also  all though that distance label is not really required but i am going to access this vertex i am going to spend a constant amount of time so that in some sense  in that constant amount of time also accessing this array and updating that information here  student  sir is the location where the next element like k where you start way b is it know directly  when i start from a  how do i know what b  e and f are ? so think of b  e and f as numbers when i look at the adjacency list representation of a  i have the adjacency list of a i know what the 3 vertices adjacent to a are  they are let ? s say vertices numbered b is 2  5 and 6 these are vertices number 2  5 and 6 i will go to locations two  five and six in this array and make them one you can just have a direct correspondence as numbers  if that ? s how you like to think of it clear to everyone ? we can determine connected components in so much time  order m plus n  linear time this is also called linear time  refer slide time  13  47  we have used this term before i can remind you such an algorithm is called linear time algorithm the next application we are going to look at is for what is called bipartite graphs first let me define for you what is a bipartite graph is we are given a graph g  so recall a graph is given by a set of vertices and set of edges we are talking of undirected graphs here g is a bipartite graph if there exist a partition of v into u  w partition  hindi  what is partition mean ? v equals u union w  u intersection w equals null i can divide the set of vertices into two pieces  u and w such that every edge has one end point in u and the other in w let me draw an example  hindi  this is an example of a bipartite graph every edge has one end in the set u and the other end in the set w  the other end point that means there is no edge like this or like this these edges are not there there are no edges both of whose end points are in u or both of whose end points are in w  hindi   refer slide time  16  27  such graphs actually model a lot of things one standard setting is these are boys  these are girls and these reflect their  whether they like each other or not no  we are not saying they are getting married this way we just trying to find out if they can get married or these could be jobs and these could be applicants to jobs  yes and a certain applicant is suitable for certain subset of jobs and you want to know whether for each job there is an applicant or for every applicant there is a job some such thing such graphs find a lot of applications in these kinds of settings question  given a graph can you determine if it is a bipartite ? everyone understands what the question is given g is g bipartite  so suppose you said the answer is yes yes  g is bipartite how will you convince me it is bipartite ?  student  no edge between the same lines levels with  he has a suggestion what he says is do a breadth first search  after all that ? s the topic of this class do a breadth first search from which vertex ? any vertex let ? s do a breadth first search i said starting from an arbitrary vertex  just to make sure so that you understand that there is nothing sacrosanct about the starting vertex  hindi   if you recall  breadth first search will divide the graph up into layers into levels these will be the vertices at level 1  level 2  level 3  let ? s say level 4 and there were 5 levels there was one other interesting thing that we have talked about as regards breadth first search all the edges of the graph  we are not talking of the breadth first search tree we are talking of the original graph in the original graph there will be edges which go between adjacent levels or within a level there will be edges of this kind which go between the adjacent levels and there might be some edges which go within a level there would be no edges which jump levels  there can not be an edge which goes like that  hindi  you should not confuse it with anything else everyone follows this these brown edges are not there we have only the green and the red edges when is this graph bipartite ? suppose these red edges were not there is this graph bipartite ? suppose there were no red edges which are the red edges ? these are the red edges here what do i mean by no red edges ? there are no edges  suppose all edges go between adjacent levels  hindi  i.e no edge has both end points in the same level suppose such was the case  what can you say ? this implies the graph is bipartite does everyone see why ?  student  componental graph   hindi   i am assuming that let ? s assume that it is a connected graph to simplify matters given g is g bipartite so let ? s assume g is connected  hindi   refer slide time  21  50   we will have to check it for each connected component if each connected component is bipartite then the graph is bipartite if some one connected components is non-bipartite then the graph is not bipartite i will come to all of this in a second for now let ? s assume we have given a connected graph and we have to determine if it is bipartite or not  hindi   refer slide time  22  14   edges which go within the level the claim is that the graph is bipartite now why ? because now you are going to take alternate levels on the u side  hindi   this is the bipartition after all to show you that to convince you that the graph is bipartite what do i have to do ? i have to show you a partition of a vertices such that every edge is going between one side  has its end point on the two sides of the partition now if i do my partition in this manner  hindi  then every edge is going from a vertex on the u side to a vertex on the w side yes  if these red edges were not there but if these red edges were there then we can ? t say because then such an edge is going between a vertex on the w side and another vertex on the w side if this were the case  all edges go between adjacent levels that is no edges has both end points within the same level then g is bipartite but we have not solved the problem here suppose there is an edge which has both its end points in the same level what then ?  refer slide time  24  09  suppose such an edge exits  does that mean that the graph is bipartite ? you will not solve the problem  hindi  if in the bfs  we find an edge both of whose end points are in the same level  then what ? what can we say then ? life can not be too hard then what ? basically we have to say  the graph is not bipartite then g is not bipartite but why ?  student  you have partition between u and v then the vertex you started this bfs must be in some partition let ? s say u then this would definitely contradict because the next level must be in v  the next level must be in u ultimately it will contradict that  proof is correct i will give you a different proof though because it will bring out another aspect  another property of the bipartite graphs suppose we had such an edge we had an edge  hindi  both of whose end points are in the same level  hindi   now recall we had a notion of a breadth first search tree  hindi   what was the notion of a breadth first search tree ? we said there is a tree and basically for each of these vertices  there is a predecessor for each vertex there is a predecessor except for the starting vertex  the root vertex  hindi   is this  hindi  if such is the case then g has an odd cycle  hindi   let ? s prove that fact now if g has an odd cycle then g can not be bipartite i have not proved this fact  i will prove it but if i prove it then we are done  hindi    refer slide time  28  29  so proof by contradiction suppose the graph is bipartite what will happen ? suppose this vertex either it ? s on the u side or it ? s on the w side ? suppose it ? s on the u side then this vertex has to be on the w side then this has to be on u side  this has to be w  u  w  u  w u  w  u  w  u  u  hindi  i started with the u but this could easily have been a w and you would have to adjacent vertices which are both labeled w  refer slide time  29  45  everyone follows this proof let me show the previous slide once again if the graph has an odd cycle then it can not be bipartite and if we found an edge  both of those end points are in the same level then we have shown it has an odd cycle this is the odd cycle in the graph  hindi   this is the general proof  this is not a proof by example because  hindi  everyone follows this  refer slide time  30  20   in this manner you can use breadth first search to check if the graph is bipartite or not which is equivalent to checking  if the graph has an odd cycle or not if the graph has an odd cycle then it can not be bipartite if the graph has no odd cycle then does it mean  it is bipartite ? if all the cycles in the graph are even in length then does that mean that the graph is bipartite ?  hindi  my next question is if all cycles in a graph g are even is g bipartite ? yes or no ?  student  yes  once again take your graph  do a breadth first search on the graph  hindi  which is between the same level then there is an odd cycle  hindi  by taking alternate levels on one side  you have shown it to be bipartite yes ? how much time did our procedure take ? the procedure to check if the graph is bipartite how much time did it take  hindi  and then what did we do ? we did also something else we checked if there was an edge both of whose end points were in the same level  hindi   let me write  hindi   we will look at all the adjacent vertices then when i come to this vertex  what are the various things we were doing ? we looked at all of these and we put them into the queue and we gave them a certain color what was the color we gave them ? grey  so each of these vertices were colored grey then i removed one of the vertices from the queue let ? s say i removed this vertex from the queue and i looked at its neighbor ? s if any of the neighbor ? s is grey then we can stop the procedure  hindi   refer slide time  34  18   if the neighbor is white  grey or black  hindi   i will repeat all you need to do is to check if the other end point of the vertex is grey or not just grey  if it is grey stop  exit  reboot the graph is not bipartite and that ? s the only thing we need to check why is that ? the reason for that is if the other point is black then that does not mean that the graph is not bipartite because you could have such an edge when i am looking at  so let me draw this picture again because this is getting cluttered when i am looking at this vertex  then it has its neighbor ? s one of which is this  which is already colored black i can not use black  the other end point being black has a test for non bipartiteness because this could be the entire graph for all i care this is clearly bipartite but to say that this vertex  when i am looking at this vertex it has a neighbor which is black  use that to say it is non-bipartite  would be wrong now what we are saying is that suppose there is an edge like this when there is an edge like this  then when i am considering one of its end points for the first time  then the other end point ; since it has not been considered yet  would be colored grey yes since it would be colored grey  we would be able to identify that edge as an edge which is running within the same level  hindi  they will also get into queue  student   refer slide time  36  55   here is a valid point i made a mistake does everyone understand his question ? no let ? s look at this picture for now  hindi   refer slide time  36  39  what is the point ? depends upon me where the point is this is the thing that has been so this should be black clearly this should be black because it has been expanded out and then since it has been expanded out all of these guys are in the queue they are all grey what are the color of these guys ? because i have not touched them yet  they are in the queue they are grey now who can tell me  what i am trying to do ? if now suppose i look at this vertex next and this has an edge going here the other end point of this edge is grey  so i might say it is not bipartite so that is not right  refer slide time  39  24  simply level  hindi   we are keeping level numbers so that quantity is important that level number business is important we are keeping the level numbers of the vertices if the level number is the same  say the graph is non-bipartite if the number level is different  continue clear ? one thing i wanted to do today which i think  i did not do very well in the last class was to argue that the level number of the vertex that your breadth first search procedure is giving you the shortest path some of you perhaps understood it but i think i did not do it very well let ? s do it once since we have some time today let me write down the formal statement what i want to argue is that in a breadth first search  starting from vertex v  the level number of vertex u is the length of the shortest path from v to u what are we saying ? we are saying that i started a breadth first search from vertex v  i got a bunch of levels let ? s say vertex u is sitting in this level 4 ; level 1  2  3  4 then the shortest path ? what do you mean by shortest path ? let ? s define what shortest path means you all understand what a path is so between v and u  there could be many paths in the graph it could be very complicated each of these paths has a certain length what is the length of the path ? it ? s just the number of edges on the path  let ? s say for now we will just keep that as a definition later we will modify this definition so for instance if i were to look at this path  this has 1  2  3  4  5  6 ; 6 edges on it so it has a length of 6 if i had gone like this  it was even longer  it had length 7 if i had gone like this 1  2  3  4  5 ; this had length 5 but there is also a path of length 4  this is 1  2  3  4 it is not an important here exactly which it is but you understand that there could be many different paths in a graph between two vertices the shortest path is just the path which has the least number of edges on it it is relevant clearly because if these are certain roads or some such thing  you would like to travel the minimum possible although i have not kept any distances here but let ? s say these just reflect the number of hops that you are taking say suppose this is some computer network  you want to talk between v and u let ? s say most of the time is spent in a  when you have to go through one node this is the link between this computer and this computer  this is link between this and this is the link between this and this so information travels very fast on link but at a node  at a computer it has to be processed and forwarded and stuff like that there is a lot of time wastage here clearly you would like to minimize this is called the number of hops then this path has 6 hops on it so you would like to pick a path which has the smallest number of hops because then you are information travels very quick you would like to find the shortest path the claim is that if this vertex u is at level four then the shortest path from v to u is of length 4 first let ? s show that there is a path of length 4 how do i show there is a path of length 4 ? very simple i start from u  i take its predecessor its predecessor would be some vertex there then i take its predecessor its predecessor would be some vertex at the previous level you understand what predecessor means ? let me recall predecessor is the vertex which gave due to which this guy got its label clearly that is the vertex sitting here the predecessor of this and i would get to the predecessor of this and clearly the predecessor of all of these vertices at the first level is the root vertex itself what is the length of this path ? it ? s just the number of levels and its four there is a path of length 4 can there be a path of length 3 ?  student   if there is a path of length 3  then we will have to jump a level which violates the fact that this is a breadth first search this is a partition it gives by breadth first search  hindi  you understand ? if there is a path of length three  then that path can not visit all these it has to come here  it has to start from here but then it can not visit all these 3 levels it has to jump over one of these but if it jumps a level then it ? s a path  then it violates our breadth first search property that shows that this process gives you also the shortest path and the shortest path is just the distance  the level number of each vertices if i wanted to find the shortest path from a certain vertex  all i have to do is do a breadth first search and the level number would give me the length of the shortest path  refer slide time  45  33  now one last thing i want to do with you is again applications of breadth first search it ? s a very simple application using this fact that we just understood i give you a graph and i define the diameter of a graph what do you think the diameter of a graph should be ? maximum distance between two vertices along the shortest path between those two vertices maximum distance between 2 vertices in g  let ? s just say that what does distance between 2 vertices means ? distance between two vertices equals length of shortest path we are not saying that the diameter is the length of the longest path between two vertices that is a very hard quantity to compute that ? s impossible to compute  more or less we are not talking of that diameter is very specifically defined maximum distance between two vertices and the distance between two vertices is the length of the shortest path how am i going to find the diameter of the graph ?  hindi  what is the answer ? bfs  just do a bfs and let ? s say the largest level number is 3 the diameter of the graph is 3  that ? s not true we will have to do a bfs on every node and then find the maximum level you understand why this is wrong ? does everyone understand why this is wrong ? because i could have a graph which looks exactly like this suppose this is my graph  so it ? s exactly this if i did a bfs from here  i would get exactly level 3 but the diameter of this graph is not 3 the diameter of this graph is 6 the diameter is 6 because it is the maximum that we are interrupting so to get the diameter  i would be able to get to the diameter if i started my bfs either from this vertex or from this vertex or from this vertex or from this you started from one of these  then the maximum level number would have given me the right information but i did not know which these vertices are  so i will have to try it out for every vertex how much time would determining the diameter take ? mn time we are assuming that the graph is connected  refer slide time  49  22  so it will take  why because each of these breadth first search will take m time and we are doing n for a disconnected graph it is not defined  let ? s say it is infinity for each connected component you can define the notion but if i do a depth first search from one vertex and i look at the largest level number  it doesn ? t tell me what the diameter is exactly but it does tell me approximately what the diameter is it can be at most half the diameter  the maximum level number is at least half the diameter yes the diameter can not be more than two times the maximum level number for any bfs you understand ? diameter of the graph is going to be less than or equal to two times the maximum level number in any breadth first search you understand why ?  hindi  the claim is diameter can not be more than 10 no 2 vertices are more than 10 units of apart why ? take any 2 vertices  hindi  since this is true for every pair of vertices  the diameter can not be less than 10  can not be more than 10 diameter is less than 2 times the maximum level number and diameter is greater than ? what is the diameter greater than ? maximum level diameter we know is at least 5 why ? because there is this vertex here and one vertex here  hindi   so by doing one bfs  you can get an approximation to the diameter  hindi  you know the diameter is at least 6 and at most 12  hindi    refer slide time  52  46  it ? s clear to everyone ? so with that we will end today ? s discussion on breadth first search in the next class we are going to look at depth first search data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 27 depth first search  dfs  today we are going to be talking about depth first search this is another way of searching a graph in the previous class we looked at breadth first search there are certain applications where depth first search is more meaningful than breadth first search and we are going to look at these application also one application is the following you are a mouse  you all know who you are so you are a mouse and there has to be whatever something  carrot no  i thought you said carrot  it was cat there is a piece of cheese at the end of the maze and you have to find your way to this cheese  refer slide time  02.06  this can be thought of as a graph in the following sense at each of these squares i put down a vertex we come to that in a minute what will a mouse do ? the mouse is not going to do a breadth first search unlikely that is going to do it is not even going to do a depth first search but what it ends up doing is something like a depth first search what this mouse is going to do as all other mice would is that it is going to go off in one direction try to explore that path  that direction fully and if it ? s not able to get to the cheese  it is going to try and backtrack we will understand what all of that means let ? s assume that our mouse has photogenic memory when it comes back to the certain place  it knows that it has been at this place and it knows what path it took when it was in that place last time we of course have data structures to keep track of this information but let ? s say mouse can also keep track of this let ? s say it started from here and it went down one step and it did not find its cheese so it came down another step not yet  so let ? s say it decided to go right why ? i don ? t know  it just decided to go right it is said to go right and then it moved another step and at this point  it can only go down it went down and again it came down here and lets say whenever it has option it can always goes right it goes right again let ? s say that the mouse tries to take this direction first  east and then it tries to take this direction south and west and north now there is no doubt about left and right it will try to go again east and did not find the cheese  so now it can not go east  so it goes south and south and now it is stuck it can not go anywhere else because all the three sides are blocked but it can move  when it gets stuck like this it backtracks backtracks means goes back to the place where it came from it goes back and at this point  it knows that it has been here before it went south  so it now tries to go west but it can not go west so it has no other possibility but has to go back to where it came from and it came from here  so it goes back similarly here it goes back and it goes back at this point when it reaches  it sees that it has another option which it has not explored which is going south so it goes south now and then it comes here  it comes here now it will have no other option but to go west  west  north  north  north and now it comes to this point it comes to this point but it sees that this is the point which it has been to before it is already been to this place it is not going to go to this point any more if it has been at a particular cell before at a particular location before  it will not go there again because otherwise it will just keep going in a loop it will not make any progress since it has been to this point before it will not go here at this point it has no other option left  it can not go east  it can not go west if it goes north  it goes to a place where it has been before so it backtracks at all of these points it will have to backtrack because there is nothing to be done and it comes back at this point at this point it had explored the two options it had the third option is not an option  it can not go west so it will backtrack  backtrack  backtrack come here now here if it tries to go south  it sees well this is a place i have been to before why should i go there ? it is after all just trying to find where the cheese is if it has been to a place before there is no point going there again because it will then repeat the same sequence of steps so it doesn ? t go here that ? s one important thing that the mouse does and so it backtracks and backtrack and comes back to the starting position what have we learnt ? it is not so easy to find cheese now it will take the other option comes here  comes here  comes here  comes here  comes here  comes here he said it will first try to go south  south  struck  backtrack  backtrack at this point it has another option goes there  goes there  goes there  goes there and now it is a homerun time to clap  no it has found the cheese this is what we will call depth first search and we will formalize this shortly but this is fairly natural way of exploring it is not artificial  you don ? t have to be a mouse to be doing this you take a particular direction and you try to follow it till wherever it will reach till whatever you can  using that direction so direction here now corresponds to in our graph sittings  it will correspond to taking one edge  going out along that edge to the next vertex and continuing and seeing where all you can reach then if you can not reach any other vertex then you start backtracking while there was a notion of goal here which was the cheese and you would stop here in our depth first search there is no goal really so our depth first search would just be a mechanism of exploring all the vertices of the graph we will keep continuing our depth first search till we do not come back to the starting vertex and there are no other options left from the starting vertex so to say  refer slide time  7  58  our search is basically a method of visiting all the vertices with the graph now let me do a depth first search on a graph and show you what you get i will start including some terminology now this is the graph  we are working with an undirected graph for now the notion of a depth first search is applicable also for directed graphs so small simple graph and six vertices and i am starting from this vertex so as in the case of breadth first search there is always a notion of a starting vertex i am starting from this vertex what am i going to do ? i am going to take one edge out of this vertex in the case of the mouse we choose a particular ordering we said first we will take the option going east then south  then west  then north here we can choose whichever we want and typically we are going to take ? so recall we are working with the adjacency list implementation for every node  so recall an adjacency list implementation  you have an array and for each vertex you have a linked list and this linked list is a list of adjacent vertices the first edge i will consider is the edge going to the first vertex and when i have worked with this edge and i am explored everything  all the places i can reach with this end i come back to this vertex then the next vertex i will consider is this one and so on and on suppose here this was the first edge i considered i went along this edge to this vertex i am now going to just so that you follow the procedure i am going to do a time stamping what does it mean ? nothing much i start at time zero when i reach a new vertex  i increment my time i will say i reach this vertex at time 1  so 1  2  3 will tell you what is the sequence in which i visited the vertices i reach this vertex at time one now i start from this vertex  i am going to look at the label options i have i have three different options let me say i first took this option and come to this vertex i came to this vertex at time two at this vertex do i have any other option ? there is this edge going out but when i go along this edge  i see i come to a vertex which i have already been to  vertex zero here there is nothing to be done at this vertex what do i do now ? i backtrack  i leave this vertex i am done with this vertex when i am done with the vertex i am again going to increment my time i came to this vertex at time two and i am going to say i am done with this vertex at time three i will just increment our time counter this is not particularly useful this time counter but there will be one application where we will use it this is just right now to show you how things are progressing i am done this with this vertex and then where do i go back ? backtrack which means go back to the vertex where we came from so i come back to this vertex now can i backtrack out of this vertex ? no  because there are no other adjacent vertices which i have not explored let ? s say this is the next one i go to or let ? s say this is the next one i go to why not ? i take this one and i reach this vertex at time 4 no  our numbering is when we reach a vertex  we increment the counter and we backtrack from a vertex then we increment the counter that ? s the only way we number i am not saying that i leave from here at time three  i get to here at time four then i could do that also but why keep incrementing unnecessarily i am going to increment only when i reach a new vertex  so i reached a new vertex i give it a time stamp of a 4 now at this vertex what are the other options i have ? i can go along this edge or i can go along this edge let ? s say i decided to go along this edge i decided to go along this edge  i came to this vertex at time 5 say at this point i could go along this edge to this vertex but again this vertex is already visited i am not going to do that since there is no other option left  i will backtrack out of here i have finished my visit at this vertex at time six always backtrack to where we came from we came from 4 so we go back to that now i come back to 4 but there is one other option at four which i have not explored which is going like this i am going to follow that now and reach this vertex at time 7 yes ? when i reach this vertex at time 7  now i look at the other options i have this is one option but this leads to me to a vertex which is already visited this is another option i have but this also leads me to a vertex which is already visited so no other options  i backtrack out of seven at time 8 i backtrack out of seven and i come back to this vertex at this vertex i have explored all options i went along this edge  i went along this edge and had come along this edge  so this is the only edge left in some sense i go back along this i have explored this  i have explored this so i am ready to backtrack out of this vertex i backtrack out of this vertex at time nine backtrack out of this vertex at time nine and where do i end up ? at this vertex  refer slide time  15  48  so now reached this vertex at this vertex i have explored this possibility  i have explored this possibility i have not yet explored this possibility but this is meaningless because this vertex is already visited i have explored all possibilities out of this vertex  so i now backtrack out of this i backtrack out of this at time 10 and i come back to this vertex at this vertex i have only explored this edge yet now i go explore this edge but this is going to a vertex which is already visited  so i can not do anything this is going to a vertex which is already visited so i can not do anything this is going to a vertex which is already visited  i can not do anything i am done with this vertex also at time 11 i finish at this vertex each vertex is been given two numbers the time at which we came there  the time at which we left  6 vertices so there should be 12 numbers in all  refer slide time  16.49  that ? s what we have 0 through 11 this procedure is called a depth first search any questions so far ? once again we will have a notion of black  grey and white vertices just as we had in the case of breadth first search what should our initial color on the vertices be ? white  unvisited same as breadth first search when should i color a vertex grey ? when i reach that node then i color it grey when should i color it black ? when i leave that node eventually then i should color it black is it clear to everyone ? same as in the breadth first search when i had removed the node from the queue  when i inserted the node into the queue in breadth first search i color it grey when i removed it from the queue i put its neighbors back into the queue if any of the neighbors is white i put into the queue and i color this node black so corresponding thing here would be when i backtrack from a node i have explored all possibilities going out of that node then i color that node black so if i am at a node  i will look at its neighbors and which neighbor will i go to ? suppose this is the first neighbor i consider  in what circumstances  what should be the color of this neighbor so that i would go to this neighbor  white yet to be explored only if this node is white  will i go to this node if it is black or grey then i will not go to this node at all i am at this node  this is what i am saying if this node is white only then do i explore it so to say let ? s understand this example a bit more let ? s mark out the edges along which we traveled in the course of our breadth first search with red i travel along this edge because i came from here to here along this edge  how did i reach two from this one ? i traveled along this edge  so once i went along this edge then i backtracked along this edge then i went along this edge then i went along this edge  then i backtracked along this edge then i went along this edge  backtracked along this  backtracked along this  backtracked along this each one of these red edges  i have went along them twice once i went along the edge  the other time i backtrack along the edge how many such edges are there ? how many red edges are there ?  student  n minus 1  the number of these red edges would be n minus 1 why ?  student  forward tree  why it is a tree ? who said it is a tree ? we are going to use a different argument for it ? s a tree first why should this have n minus 1 edges ? for every vertex there is one edge along which i came to that vertex and the same edge along which i backtrack from that vertex so for every vertex there is a unique edge except for the first vertex since for every vertex there is a unique edge except for one  there should be n minus 1 edges so number of red edges equals n minus 1 if i just look at the red edges  they form a connected sub graph why do they form a connected sub graph ? because by walking along the red edges  i could visit all the vertices yes  all i did was walk along the red edges that ? s all i did so by just by using the red edges  i could visit all the vertices starting from the root  from this start vertex these red edges form a connected sub graph  refer slide time  23  00  so connected sub graphs with n minus 1 edges is a tree yes  we have done this before if i have connected sub graph with only n minus 1 edges in it  it can not have a cycle we have proved this so it ? s a tree the red edges form a tree and this tree is also called the dfs tree  the depth first search tree is this clear ? just as we had a breadth first search tree  a breadth first search tree was defined in terms of predecessors here also we can have a notion of a predecessor what is the predecessor of this vertex ? the vertex which was visited at time one because why should that be the predecessor ? i came to here from there so that is an actual notion of predecessor and these edges then ? the same thing  same idea is getting repeated just as we had a breadth first search tree there  we have a depth first search tree here but the breadth first search and the depth first search tree are completely different what i am going to do now is to redraw this tree i am going to keep it like this can you all see the picture ? i am going to redraw it so that it looks like a rooted tree now this is this vertex and let me draw it in brown this is that and the next vertex would be there and from here i have this  so this is this vertex that i have drawn  from here i have an edge to there and i have another edge these are all the 6 vertices if you want  i will put down the numbers so that you can also see the correspondences this is 0 slash 11  this is the 1 slash 10  this is 2 slash 3  this is 4 slash 9  5 slash 6  7 slash 8 let me also draw the other edges of the graph right now i have only drawn the tree edges  the dfs tree edges these are the edges along which we traveled let me also draw the other edges how many other edges do we have ? we have 4 other edges there is one edge from here to here  there is one edge from 1/ 10 to 7/8 this is another edge  this is this edge there is one edge from 7 8 to 0 11 this edge  there is this edge 0 11 to 5 6 let me draw it like that this is an undirected graph so these directions that i have shown are meaningless it is just to signify that this is how we moved and now i can get rid of this picture this is our graph i have just redrawn it so that now it looks like a rooted tree and the predecessor of the node now is just the parent of that node if i define this as the root then there is a natural parent child relationship between the nodes the parent of this node is this and it is also the predecessor so quite often we will talk in terms of parent child siblings and all for a dfs tree when we say that basically means we are thinking of the starting vertex is the root of the tree and we are basically hanging the tree from there and then whatever is the parent child relationship that gets defined that ? s what we are working with let ? s look at more properties of depth first search these green edges  so the brown edges are called tree edges  that ? s the brown edges the green edges are called back edges and we will see why they are called back edges and why not front edges what ? s back about them ? now let me think of depth first search has been done on this graph this is the entire graph all the edges and the vertices are here i started from this vertex  i came down to this  i came down to this and then i looked at  this was one option available to me but this edge was going back to a vertex which i had already visited yes  and so this is called a back edge  going back to a vertex which is already visited  hindi  then it is going back to a vertex which was already visited so i don ? t go there there is no other option left here so i backtrack this is the option here i come here  i come here again this is an edge going back to a vertex which is already visited i don ? t go along this edge i backtrack from here  i come here this is an edge going back to a vertex already visited i don ? t go along this  i backtrack  i backtrack i could now look at this edge again and say well this is going ahead to a vertex already visited i could potentially have also called it a front edge but since we first considered it as a back edge  we are going to stick to the term back edge this is an edge we going to a vertex already visited  so we don ? t consider this and since all option i exhausted here  back track  i come here these are all edges which we have so to say have been classified as back edges we don ? t or they are going to vertices which are already visited we don ? t do anything and we are done who can formally define for me what a back edge is ? what is a property of a back edge ? now i think i am getting ahead of myself now i have the following question  could there be an edge from this vertex to this vertex could this dotted red edge be ? so i have drawn a dotted but most likely it should not be there but why ? when i came to two  when i came to this vertex at time two then i backtracked out of this vertex only because there was no other option available to me but if this edge was there then this was an option available to me why because this vertex was not yet visited this vertex was visited only at time 4 at time 2 this vertex was not visited and so it is still a white vertex and so i would have gone along this edge and if i had gone along this edge then this would not be the picture at all clearly this edge is not there in the graph  student  sir we have the level difference  no  we will understand what these edges are in a second there is nothing to do with level here unfortunately this is again two we are saying edges which jump a level in breadth first search  they can not be because if they were then that would not have been our breadth first search  that would have not been this collection of levels if this edge was there then this should have not been the picture at all  it would have been something completely different so this edge is not there this edge is not there  similarly this edge from here to here is not there or from here to here is not there what are these edges which are not there ? what can i say about edges which are there and edges which are not there ? sibling but this and this are not sibling  student  there is no ancestor which   what are the edges which can go from here which can emanate from here ? they are only edges which can go up to root or to ancestors ?  student  ancestors  so let ? s understand this  this is an imp very important point i have reached the certain vertex and this is let ? s say the sequence of vertices along which i reached here i am sitting at this vertex at this point and i am ready to backtrack  ready to backtrack means there is no other option available to me what are the other edges which could have started from here ? these are only two vertices which have already been visited these are clearly vertices which have already been visited there could be edges from here to here but why can ? t there be an edge from here to some other vertex which has already been visited  student  there will be no need instead of vertex  no  so why did you say only ancestors ? suppose this was my vertex here  why are we saying that only two ancestor why can ? t we have an edge from here to here ?  student  because then it would be a ancestor of this and have been visited earlier it would be  if there was an edge from here to here ?  student  it has to be child of ancestor when do we backtrack before backtracking we would cover that vertex that path would have already been covered   what is a formal way of saying this ? why should we have only edges from a vertex ? let ? s just put down what we have concluded so far from a vertex we can have edges only to ancestors and such edges are called back edges what is a back edge ? so now we are ready to define what a back edge is anyone  what is a back edge ? an edge  student  from a node to another  from a node to an ancestor what is an ancestor ? an ancestor with respect to the depth first search with respect to the dfs tree the notion of an ancestor is coming in only because we have defined dfs tree an edge from a node to an ancestor is called a back edge but not to ?  student  but not to parent  an edge from a node to a parent is a tree edge so we will distinguish between tree and back edges an ancestor is not a parent let ? s say those are the back edges and these edges  the once in the red dotted here are not back edges because they are not going from a node to its ancestor neither is this node an ancestor of this nor is this an ancestor of this so such edges can not be there at all in our graph depth first search basically means  so after you do a depth first search you end up dividing now the set of edges into two classes tree edges and back edges and there is no other edge  student  we can just say that any edge  every edge gets classified either as a tree edge or as a back edge let me write this down so dfs classifies every edge as a tree or a back edge this is similar to breadth first search means breadth first search classifies every edge as an edge going between adjacent levels or going within the same level  let ? s see  refer slide time  36.49  so here depth first search also does this thing for us clear to everyone ? we are still talking about depth first search in undirected graphs when we come to directed graphs things will change a bit  keep that in mind how do we implement depth first search ? looks like a fairly complicated thing stacks or recursion let ? s see what are the things we needed ? we said we have to keep track of whether a vertex is visited or it ? s not visited whether what the color of a vertex is so actually we don ? t even need to distinguish between grey and black we just need to distinguish between white and non-white  whether a vertex is visited or it was not visited that was the only thing we really needed we are going to keep an array called visited so what will this have ? basically it will have an entry for every vertex for a vertex v it will have an entry let ? s say 0 or 1  0 if it is not visited and 1 if it is visited this is a zero one entry  zero means not visited initially all the entries of this array would be a zero  hindi  suppose i wanted to do a depth first search starting from a vertex v in my graph so now my graph is going to become more abstract this is my graph  this is a vertex v  i want to do a depth first search from this vertex so what am i going to do ? what does depth first search involve  what is the first thing i should do ? first i should mark this vertex as visited clearly let ? s say this is the very first thing i do  visited v equals one now i have to look at all the vertices one after the other  adjacent vertices so let ? s say this had 3 adjacent vertices x  y  z let ? s put down a loop for all w adjacent to v  do something for all vertices w  so w is just a running variable so to say which will take the value x  y or z depending upon which this is what should i do ?  student  doffs dfs dfs w  i just do visited dfs w right away no  student   if it is not visited if visited w  student  equal to one  equal to zero  if not of visited w then  student  dfs  just say dfs  w    hindi  else  student  no else how can you define  no else then what ?  student  the else w will backtrack  backtrack  student  else backtrack if for all w  for all w  hindi   student  not of visited of w then we backtrack visited w equal to one  visited w equal to one  hindi   refer slide time  41  15   if it has now then  student  sir predecessor  backtrack  student   hindi   if all w is not visited then we backtrack to the predecessor sir after we have done   basically  hindi  but this takes care of everything for us  all our backtracking everything it is not trivial to understand this part why it is taking care of all the things for us ?  hindi  for all  student  adjacent vertices   hindi  all adjacent vertices  hindi  but to convenience yourself this is doing all of that you know recursion is not magic right it ? s after all just a piece of code  hindi  it is particularly well suited for depth first search you can write three line program  four line program for something we spent 30 minutes telling what the procedure is  refer slide time  43.19  what is that is happening ? why is this working out for us ? so let ? s try and understand that and i will just ? i think i will just explain it on this picture i started a depth first search from v this is what my depth first search v was let ? s say the vertices were considered in this order  exactly this order x  y  z visited v is one  visited x y z are all zero  as are visited of all the other vertices i just started my depth first search here then i came to this vertex since visited of x is zero  i launched a depth first search here that ? s what we would have done here i launched depth first search on this what is this depth first search going to do ? let ? s say our depth first search visits a certain bunch of vertices which are not already visited and marks them visited one as a consequence this guy is going to visit a bunch of vertices and set visited one for each one of them  visited at one and then it is going to terminate  every program has to terminate it also terminates but what is it that terminates ? dfs on x when dfs on x terminates  this recursive call terminates where do we end up ? when this terminates we end up in the dfs of v because this is the dfs which called dfs  x   the picture is something like the following you had dfs  v   making a call to dfs  x   this did a lot of recursive calls but at some point it terminated after it terminated we made a call to dfs  y   when you made a call to dfs  y   why did we make a call to dfs  y  ? because we are looking at all the adjacent vertices and i am assuming for now that y was not visited in this dfs suppose it was not visited so it was still at zero i made a call to dfs y now as a consequence  it visited another bunch of vertices it would not have visited any vertex which was already visited by x we are ensuring that not going to a vertex whose visited is already set to a one so it visited another bunch of vertices and then it terminated now i am going to go to vertex z and try to launch a dfs there but i see that z is already visited because z was set to visited  when i did my dfs  y   when that happens  z is already visited so i don ? t launch a dfs here i have taken care of all adjacent vertices and so this terminates now this terminates means the dfs on v terminates  this whole process terminates the claim is i would have visited all the vertices that were to be visited from this vertex which are the vertices i can reach if i reach a certain vertex  either i can reach it through x or through y or through z because after all these are the only three edges incident at this vertex if i can reach it from x then that means it should have been visited in dfs  x   if i can reach it from y  it should have been reachable from dfs  y   if i can reach it from z  it should also have been reachable from dfs  y   why ? because z is reachable from y if z is reachable from y then after i had reached z  i would have continued and visited all vertices which can be reached from z so anything that is reachable from v therefore is visited and so our dfs from v should terminate and that is exactly what is being done here we are not done with this yet as you can imagine i want to add my timestamps how should i modify this procedure ?  student  starts  suppose with each vertex i want not juts visited but i have two other arrays arrival let ? s call it a and departure let ? s call it d so a of v so this is also an array and this is also an array it is not a zero one array sorry  so this zero one was for the previous thing if i have a vertex u  so a of u will be an integer which will tell me what time i reached vertex u and d of u would be another integer which will tell me at what time i left vertex u what modification should i make to this piece of code ?  student  when d of u   student  a of u comes when you start dfs v after visited   so a of u equals  student  plus plus b plus whatever  time plus plus  student  and after dfs not after dfs w after   hindi   student  after the for loop   hindi   it ? s just saying stamp and increment so that the next guy doesn ? t get the same stamp it could be plus plus time or time plus plus  doesn ? t make too much of difference it will just change the starting yes  no ? so and time could initially be zero  hindi   you can also modify this procedure to identify which edge is a tree edge and which edge is a back edge can you do that ?  student  if visited w   student  for dfs w we can mark its edge   suppose i also wanted this information every edge which is a tree edge  i want to mark the tree edge  student  with is equal to one then  when i am ready to launch dfs w then that means ?  what does that mean  what can i conclude at this point ?  student  noise  which edge ? v w  student  v   the edge v w is a tree edge that i can conclude  hindi  i can write that statement  hindi    refer slide time  52.48  v w is a tree edge if you have identified what the tree edges are then its equivalent to identifying what the back edges are  anything which is not a tree edge is a back edge i am going to stop here today in the next class we are going to see to analyze the running time of this procedure and we are going to spend a couple of classes in applications of depth first search data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 28 applications of dfs today we are going to be talking about applications of depth first search in the last class we looked at the depth first search procedure we will also be discussing the running time of depth first search today and then looking at an application of depth first search to check if a given graph is two edge connected recall what we did in the last class we wrote a small piece of code depth first search v can someone tell me what this was ? the first thing we do is we said visited v equals one lets say and then i will not worry about the counters for now because that1 ? s for all w adjacent to v he was saying children of v  there is no notion of children of a node in a graph for all w adjacent to v  if not of visited w then dfs w  that ? s it that ? s what we said our dfs procedure is it first marks the node as visited then it will start the dfs on each of the adjacent nodes provided they have not already been visited that ? s what dfs v corresponds to how much time does this procedure take ? it is a recursive procedure  so you have to do something careful some careful analysis of the running time how much time does it take ? why ? pardon  student  every  compared  what do you mean by compare ?  student  like we have to check the end is visited or not   for every edge we will have to look at the edge twice the answer is right  you are basically doing a total time of order m actually i can just say order m because i am assuming that the graph is connected in a connected graph m is at least as large as n minus 1 so you can always say order m so let ? s just say order m and we have assumed graph is connected now let ? s try and see what ? s happening here for this i am going to use my adjacency list representation because that will also give you a better picture of what this is recall that in the adjacency list representation of the graph  there will be one entry corresponding to node v this would be the adjacency list of v  the nodes which are adjacent to v if a node x is adjacent to v then v is also adjacent to x because it is an undirected graph so x  hindi   refer slide time  04  57   when i do this step for all w adjacent to v  what does this say ? how will i actually translate it into code ? this is pseudo code  you don ? t really have a statement like for all w adjacent to v what will you do ? you will basically have to traverse this list  for that you will have one pointer which points to the first node and then when you have looked at this node then you will update the pointer to point to the next and so and on till the pointer becomes null or reference becomes null then you would have reached the end of the list that ? s how you will be actually implementing it basically every time i go through this loop i advance that reference  i advance that pointer by one now if this was the very first node u and it was not visited then what would i do ? i would start a dfs on u as a consequence i will do some other computation and when that computation finishes  i come back to this dfs procedure the dfs that i was doing on v and i retrieve that pointer  refer slide time  06  01  essentially i would have that the pointer is still pointing here that because that was a local variable so to say you follow what i am saying ? i would not start so  suppose let me say i advance through this pointer this was the longer list and i reached this pointer reached at this point let ? s say this node is a and a was not visited  so i went and did dfs of a when i came back from dfs of a then what is the next node i will see in this for loop i will go beyond this a  i would not continue i will not start all the way from beginning and how i am retrieving the fact that i was here last  this pointer was pointing to this information this is coming from the recursion the fact that in a recursion when i make a recursive call i store the local variables  hindi  if i were not to write for all w adjacent to v  i would have written something like the following i would have let ? s call this array a i would have p equals a of v what is p ? p is this pointer of v  so p initially is pointing to here and i would be replacing this by  while p not equal to null  good something like this  this might not be completely correct but it will be something like this while p not equal to null what would i do ? i will do something like this and i will do p equals p dot next you understand what this is basically each one of them has a next and this w will p dot data or p dot node or some such thing what is w ? because we don ? t have notion of w  so it will be p dot data let ? s say basically i am saying each one of these nodes has two members  one is data and one is next and p is referring to this  refer slide time  8.45  why am i going into all of this ? if i have to replace this line  i would have to do something like this this is how you will actually code it up and this while loop  this braces ends here the while loop will now have these two statements in it why am i doing this ? now note that visited is not local variable  visited is some global array the only local variable that i have here now is my p when i make this recursive call  this p is stored on the stack so that when i return from this recursive call  when i finished dfs of a i was so let ? s now say p was pointing to here  i am doing dfs of a when i return from here  i will retrieve this p back and i will increment p or advance p like this  p would now point to the next one i would come back to this p  i would not come back to this p right at the beginning or some such thing why am i saying this ? this is crucial for the running time of the procedure you can understand why  because if every time i was going to start from the beginning then i can ? t say order m i am now using a same fact  i will be traversing this list only once for each node  hindi  once i start traversing the adjacency list of a node  i don ? t repeat any entry in it i kind of just keep moving forward in that adjacency list what does that mean ? for each node i am effectively spending time proportional to the degree of that node some of that degrees of that node is the number of edges  two times the number of edges in the graph and so the total time required is order m yes  she said each edge is visited twice that ? s also true  v x  x v the edge v x is being looked at here when i look at this node because x is now treated as a adjacent node of v and the same edge v x is looked at here  when i look at this node x because v is being treated as an adjacent node of v actually every edge is looked twice  exactly twice this gives you the running time is this clear ? we are heavily using the fact that this is a recursive program and when this recursive call finishes  we retrieve this particular local variable this local variable gets back the same value it had before this recursive call was made now if i told you that implement dfs without using recursion  you will have to use a stack you will essentially simulate the recursion by using the stack but now it should be clear what variables will you store on the stack what information would you store on your stack ?  student  current pointer  basically p  the value of p in the case of recursion two things are stored actually  not just p someone else has to tell me what else is stored  student  v also  v local variable  hindi  they are stored and the parameters to that procedure are also stored the parameters to this procedure is v  that will also have to be stored in the stack of course the stack also stores return address and stuff like that but those things you don ? t need here because you know exactly where it is returning to this will be your sixth assignment you will have to implement it i will give out the details later but you will have to implement dfs without using recursion so that you understand this way  refer slide time  13  16  we looked at dfs  we have classified  the edges has tree edges and back edges and we have looked at what the running time of dfs is one other thing that perhaps we should do before we proceed further is look at this distinction between tree edges and back edges once more so tree edges and back edges suppose i have an edge u v which is a tree edge and if u v were a back edge let ? s see what can we say about the relation between the arrivals time and the departure times for the nodes u and v let ? s see  let me ask you these questions suppose i tell you that the arrival time of u was less than the arrival time of v that is i reached node u before i reached node v  student  back edge  pardon  student  u v form a back edge  u v form a back edge suppose i told you  i gave you this information i reached u before i reached v now what is the relation between the departure times of u and v ?  student  departure of v is less than is less than the departure of  departure of v is greater than or less than  student  less than less than  departure of u is less than or departure of v is less than  student  departure of um v is less than   hindi  you reached u first  u v is a back edge you reached u first and then you reached v what does that mean ? v is a descendant of u in the tree u v is a back edge  so there has to be an ancestor descendant relationship between the nodes of u v one has to be an ancestor of the other which is an ancestor of which ? clearly you will reach an ancestor before you reach the descendant because you are coming down from the top of the tree so u is a ancestor of v in fact i have shown that in the picture essentially so u is an ancestor of v if u is an ancestor of v in this tree then first i would have finished v and only then i would have backtracked all the way and come back to u and finished u  student  same  no  this is for the back edge this is not a tree path  sorry there is some tree path between u and v also of course and lets say this is the edge u v there are other nodes on this tree path  so you would have finished a descendant before you move up because that ? s how you backtrack you finished a node and only then you move back up and then you finish that and you move back and back and so on the departure time of u is more than the departure time of v you would have left v  we would have finished v before we finished u what if u v is a tree edge ? would that make the difference ? suppose once again that arrival of u is before arrival of v if arrival of u is before arrival of v then u is a parent of v so u v have a parent child relationship not just an ancestor dissonant but an parent child u is a parent of v  student  why  because it is a tree edge u v is a tree edge so when i depart from v after that only will i depart from u so departure time of v is less than the departure time of u note i can not say that the departure time of u is one more than the departure time of v  student  because  because it might have more children similarly i can not say that the arrival time of v is one more than the arrival time of u because there could be other children also  refer slide time  18  05  the relationship is the same but these are the same relationship but they coming from different reasons  roughly the same reason agreed  granted now let ? s look at an application of depth first search to determine if a graph is two edge connected let me write down connected so that ? s the term that i am going to be using graph g is two edge connected if and only if g minus e is connected for all e  hindi  i am saying take any edge  capital e is the set of edges when i write graph as v  e ; v is the set of vertices and capital e is the set of edges  little e is an edge  g minus e means remove the edge from the graph if it is still connected and this is true for every edge for the graph then we say that the graph is two edge connected in words a graph is two edge connected if it remains connected even after the removal of any edge yes  only one edge a graph is two edge connected if and only if it remains connected after the removal of any one-edge let ? s see is this graph two edge connected ? if i remove this edge then it becomes disconnected such an edge whose removal disconnects the graph is also called a bridge this edge we would call it a bridge this graph is not two edge connected is this graph two edge connected ?  student  yes  yes  so graph which is two edge connected will not have any bridge edge a graph which is not two edge connected will have a bridge edge why do you think this notion of two edge connectivity would be useful ? if this were a computer network and some link fails then you are interested in whether the network is still connected or not if your network was two edge connected to begin with then no matter which link fails your network can still keep functioning because it will still remain connected but if the network were not two edge connected to begin with then the failure of a link can call the network to break down into disconnected components so that messages can not go from one connected component to the other anymore  refer slide time  21  55  this is basically measuring liability of the network now the question is a following i give you a graph and i ask you is it two edge connected how will you check if it is two edge connected ? anyone ?  student  if we can suppose we have from one end point to the other point of an edge sir each vertex  for each vertex if we can find a cycle how you will check whether a given graph is two edge connected ? we have to do it fast pardon  student  we will look at the departure time  if you look at departure times  student  sir between any two node there should be a tree edge also and back edge also  between any two nodes  there should be a tree edge and a back edge ?  hindi   student  so on removal of either of one its still remain connected   hindi  each node should be visited twice ?  student  between any two node  let ? s don ? t worry too much about dfs because that is not straight forward but you will see how to do it let ? s see can you check this property of two edge connectivity by some other mechanism ?  student  sir by bfs  bfs yes  what will you do with bfs ? you have to check if the graph remains connected even after removal of an edge so take an edge  remove it check if it is connected then take another edge remove it  check if it is connected take another edge remove it  check if it is connected  hindi  so that ? s more expensive we can do it in order m square by removing every edge and checking if resulting graph is connected yes  but that ? s expensive for us so we want to do something in order m time  linear time  student  say that v vertex has a back edge  if every vertex has a back edge only then is the graph two edge connected  hindi  is a cycle two edge connected graph ? it is two edge connected  hindi  what will be the tree edges ?  hindi  this will be my dfs tree  the one in red and the only back edge will be this last edge  refer slide time  27  05  my dfs tree  if i were to draw it differently would look like this it would be a path  my dfs tree with one back edge only  hindi   student  when you are back tracking from that vertex if you get a back edge that means there is a cycle connected that particular path of traversal so you can then compute something  good  we are getting somewhere so let ? s develop this  one step at a time i did a depth first search  so clearly we have to do a depth first search suppose this is the depth first search tree i obtain i have just drawn the tree edges  there are other back edges i have not drawn them yet now when i am backtracking out of this node  backtracking means i am going back up because i have explored this entire thing what do i require ? i have explored this entire thing  i have not yet gone here so i have come from here  i came like this  i came like this  i explored this entire thing now i am back tacking i want to ensure that this edge along which i am backtracking is not a bridge i want to ensure that it is not a bridge  hindi  what will ensure that this edge  i am only interested in this one edge not being a bridge ? what we ensure that this one edge is not bridge ?  student  it is connected  it is also back edge  there is a back edge from where ?  student  from this vertex  from this vertex ?  student  yes yes  from this vertex  hindi  any of these vertices say  hindi   refer slide time  29  25   if you remove this edge  let ? s look at the blue tree  the dfs tree in a tree when i remove one edge  i will get two pieces not more this will be one piece and the other remaining piece i can not create more than two pieces by removing an edge i create exactly two in a tree now these two pieces are connected among themselves by the tree edges  by the blue edges i can go from any node to any other node how will i go from a node in this piece to the other piece ? by going from that node to the end point of this green edge  taking this green edge  going there and then going from here to whichever node i wanted to go to so which means every pair of node is connected which means that the entire thing is connected  even after i have removed this red edge this red edge is not a bridge if such an edge is present then this edge is not a bridge  hindi  but it has to go to this node or beyond  hindi  i will get two pieces which are disconnected from each other because there will be no edge going from here to anyone here because we said there is no edge of this kind  hindi  this is the condition we have to check everyone understands ? what is the condition we have to check ? when i backtrack from a node  i have to check that there is some edge from here which is going to an ancestor of this node  hindi  how will i check this ? linear time  hindi   there should be some edge from its descendent to one of its ancestors  that ? s all let me write it down in words when backtracking from a node v  we need to ensure that there is a back edge from some descendent of v to some ancestor of v  hindi  i have said descendent without saying proper descendent so descendent includes the node itself but this ancestor is a proper ancestor which means parent or above  hindi  now we have to somehow ensure this how will we check this property and we have to do it all fast  refer slide time  35  47   hindi  we are only permitted order m time  student  do we keep track of the back edges then we back track on particular node we believe from our record that particular back edge that node  keep track of all back edges do we need to keep track of all back edges ?  student  which   hindi  i am interested in a back edge but do i need to keep track of all the back edges starting from ? which is the back edge which is of interest  hindi  if we keep track of every back edge then we are going to be spending a lot of time  student  sir we will delete the  but there is one back edge which is of interest to us which is the one back edge which is of interest to us ?  hindi  clearly if i know  hindi   you understand what i mean by  hindi  is going to the node which is closest to the root how can i figure out which is the deepest back edge ? by looking at the arrival time of the other end point  hindi   so just by looking at arrival time of this end point  i can figure out what the  hindi   now question is how am i going to build this information recursively i have to find out the deepest back edge from this sub tree so i am just keeping track of the deepest back edge now i have to find out the deepest back edge from this sub tree how will i find out the deepest back edge from this sub tree ? suppose recursively i have done this information i have figured this information from the sub tree i know the deepest back edge because after all we are doing recursively when i run the dfs from here  i actually end up running dfs ? s from let ? s say these three suppose i figured out the deepest back edge from this sub tree  i figured out the deepest back edge from this sub tree and i figured out the deepest back edge from this sub tree how can i compute the deepest back edge from this sub tree ?  student  compute that compare  compare all three and take the minimum  student  and from u also  the one with the minimum arrival time  student  corresponding with the minimum arrival time   so this will give me an edge whose other end point has a smallest possible arrival time this will give me an edge whose other point has a smallest possible arrival time  this will give me an edge whose other end point has the smallest arrival time now if i take the minimum of these three  it will give me the edge which has the smallest possible arrival time which emanates from this sub tree is this true ?  hindi   now let ? s write our dfs procedure so this is our  lets give it some other name to distinguish it from dfs let ? s call it two ec  two edge connectivity so we are writing a two edge connectivity procedure once again it will take as input a particular node we are going to write it as the dfs thing and i will tell you how we have to call the dfs  this two edge connectivity procedure eventually recall i need the arrival times of the nodes so i should maintain my arrival counter suitably so what should i do from my arrival counter ?  student  time is equal to zero   hindi  for all w adjacent to v  same thing for all w adjacent to v do what should i do ?  hindi  arrival value of this node itself would be a natural thing to do let ? s set that at that now deepest back edge  hindi  as i do my dfs calls  i have to kind of keep updating this variable what should i do for all w adjacent to v do if not visited w then then what should i do ?  student  then if then arrival v or smaller than dbe  arrival v then dbe equal minimum of dbe  2 ec of w  hindi    student  sir even it is even it is visited  if the node is visited then what does that mean  what edge is it ?  student  back edge  it is a back edge  hindi   so else what should i write on here ?  student  if you are maintaining that d ec w and some particular array then you can write that minimum of i will say i have to write the same thing again minimum   we will just write the same thing  dbe equals minimum of dbe comma  student  2 ec w arrival of  not 2 ec  we are not running a arrival of w  hindi  now what do i have to check ?  student  if it is less than or  if dbe is less than arrival v  student  never be possible   hindi  if dbe is less than arrival v then continue  student  there we can then we can continue  then we can continue if dbe equals arrival v then  hindi  then abort basically then you stop your procedure saying you found a bridge you can do whatever you want  i will just write abort here you should not write abort  you should end gracefully but you understand what i am saying basically why have we said equal to and not greater than or equal to greater  hindi    student  sir can you explain else part if w is  he wants me to explain the else part why do we need the else part  you are wondering  student  we need the else part  you need the else part  great  student  but why arr w what is the significance of w  what arrival w ? the else corresponds to a back edge starting from v it is going to a node w w is a node which is adjacent to v  so it is going to a node w how am i keeping track of deepest ? i am keeping track of deepest by arrival numbers of the nodes so that ? s why i am comparing it the arrival of that node with this  hindi  so i need that and if the deepest is less than this v then its okay  i can continue if it is here only  deepest is this then this means that this edge is a bridge  hindi  no  we can not say anything about the arrival time of this verses the arrival time of this i have said this before we can not say that this is one less than that basically we have to modify this so that i am not considering this edge  this tree edge this has to be modified so that the tree edge is not considered  this parent edge is not considered  hindi   refer slide time  49  55   when we do the dfs from that vertex  we visit all the vertices all the back edges  if any coming from below can not go to some smaller number clearly they are only going up to this vertex because this vertex has the arrival number zero there is now vertex with arrival number less than zero  student  dbe should not be zero   hindi  basically there are many ways of doing it you could perhaps have marked this edge as a tree edge you will have to think of ways of doing this i will leave that as an exercise these are two minor things but they are important your procedure would not run at all  if you were to ignore them what is a running time ?  hindi  so essentially as same as before for every edge we are spending a constant amount of time the total running time is still order m this is clear ? so actually very sophisticated procedures can be built on top of dfs  refer slide time  52  46  there are many other graph problems which can be solved in liner time they might seem very complicated problem but you can essentially solve them in linear time using depth first search i will mention one other problem because i have a couple of minutes we will not of course discuss it the other problem is  is g a planar graph ? do you know what a planar graph is ? you are not done a discrete math ? s courses no  you are doing it next semester  hindi  that is not sufficient what is a planar graph ? a planar graph is a graph which can be drawn in the plane such that its edges do not intersect  hindi  this is a planar graph i can draw it whichever way i want but the edges should not intersect now suppose what is this graph ? this graph is the complete graph or almost the complete graph on five vertices i told you what the definition of a complete graph is complete graph or a cleak  refer slide time  54.55  is this the complete graph  compete graph on five vertices no  why not ? the edge 2 5 is missing   hindi  2 5 is the edge which is missing  hindi  there is no way i can draw 2 5 here without crossing and that has nothing to do with the way i drew the initial thing  hindi   there is no way i can draw 2 5 actually this complete graph on 5 vertices is not a planar graph  hindi   if i were to draw it this way  it would cross with this if i were to draw it like this  it would still crosses with this edge if i were to draw it like this  it would cross with this edge and so on and on there is no over drawing this so that ? s the question  is a given graph a planar graph this problem can be solved using depth first search so that you can get an algorithm which runs in linear time  order m time  very sophisticated algorithm to check if the graph is planar or not  refer slide time  56  07  this is an example of a non planar graph that i had shown you learn more about this in your discrete math ? s course what are non-planar graphs  what can you say about non planar graphs ?  hindi  this is another example of depth first search but we are not going to be taking up this in this course there is one third example which i will do in two minutes so just as i defined two edge connectivity  i can define two vertex connectivity just replace the edge by a vertex a graph is two vertex connected  if removing any vertex still keeps the graph connected this corresponds to computer failures now instead of link failures earlier  hindi  then you would call it a two vertex connected so no matter which computer breaks down if the network is still functioning  it is still connected then you would call it a two vertex connected graph for instance this would be an example of a graph is this two vertex connected ? no  why because if i remove this vertex  it becomes disconnected when i remove a vertex  i also remove the edges incident to that vertex clearly it becomes disconnected but this is a two edge connected graph this graph is two edge connected once again the same question given a graph  is it two vertex connected that can be checked by depth first search in linear time such a vertex is called a cut vertex  bridge  hindi  corresponding notion is cut vertex here  refer slide time  58  31  in today ? s class we have done example of depth first search which is checking if a given graph is two edge connected there are many other application that depth first search can be put to i have shown you  i mentioned briefly two examples  checking if a given graph is a planar graph and checking if a given graph is two vertex connected so next class we are going to look at depth first search in directed graphs and see how it is going to be different from undirected graphs data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 29 dfs in directed graphs today we are going to be talking about depth first search in directed graphs in the last two classes we have looked at depth first search in undirected graphs and seen applications for the same how does depth first search in directed graphs differ from depth first search in undirected graphs ? let ? s take an example of a directed graph let me make sure this has something interesting happening let ? s put this edge back here suppose this is the directed graph that i started and this is my start vertex the process is going to be exactly the same as in the depth first search  so the code for depth first search would remain the same let me write it down once again for your benefit so depth first search from a vertex v  what did we do we set visited v to 1 and then for all w adjacent to v what do you do ? if not visited w then dfs  w  and this was the quote for depth first search in undirected graphs now this is the same quote for depth first search in directed graphs i just need to redefine what the adjacent means now what do you thing adjacent means ? so a vertex w will be called adjacent to vertex v  if i can go from v to w i am at vertex v  i want to look at all the vertices to which i can reach from v so these three vertices would be adjacent to v so sometimes the term out adjacent is used because you might also want to call this vertex adjacent so x will be called in adjacent but here we talk of adjacent we mean out adjacent  vertices to which you can go from vertex v and the rest are the same let ? s see what will happen now let ? s say i start from this vertex s and i took  this has the first edge to go out i came to this vertex  now i took this as the first edge to go out so i came to this vertex now i will consider the edges going out of this vertex how many edges are going out of this vertex ? only one which is going to a vertex which is already visited yes so there is nothing more to be done at this vertex  i will backtrack from this vertex  go back to where i came from i come back to there now from here i am going to look at the other edges which are going out of this vertex  there is one more edge so that will bring me to this vertex from here i am going to look at the edges going out of this vertex there is only one edge which is going out of this vertex that 's going to bring me to this vertex from here i am going to look at the edges going out of this vertex there is only one edge going out of this vertex which is going to a vertex which is already visited so i am done here  i backtrack come back here yes  backtrack why do i backtrack from here ? because there is no other edge going out of this vertex so i backtrack  i come back here there is no other edge going out of this vertex  so i backtrack  i come here from here now what will i do ? i will look at the other edge going out this is going to this vertex  so i come to this vertex along this edge and from this vertex  i look at the other edge going out  any edges going out  so this edge is going out but it is going to a vertex which is already visited  yes so i backtrack from this vertex and i come back to here there is no other edge going out of this vertex so i backtrack from s which effectively means i have finished the procedure  hindi  this is what dfs here would look like let me give the arrival and departure numbers to these vertices so that it ? s completely clear what we are doing so this zero  can some quickly tell me what these numbers would be ? 1 here  2  3  4  5  6  7 that is very easy we are just saying 1  2  3  4  you are not putting it down on the paper  it is harder for me ; 7  8  9 here  10 also here  11 here  hindi  it ? s clear ? this is how our depth first search happens now suppose let me modify this graph a bit let me change the direction of this edge let me make it this way what will happen now ?  student  vertex will not  this vertex will not get visited what will be the departure time of this vertex now ? i will come back to this vertex  so i departed from here at time 8  i came back here come to here and now there is no other edge going out so i will finish at time 9 now what happens ? what about this vertex  when will this get visited ?  student  this will be only be visit start from  now we are going to ? so depth first search when it starts from a vertex  it might not visit all the vertices this is true even in the case of an undirected graphs it will not visit all vertices if the graph is not connected for instance as was the case of breadth first search you started the breadth first search from a vertex  it would visit only the vertices and that connected components similarly depth first search in an undirected graph would visit only the vertices in that connected component in a directed graph  the depth first search would visit only such vertices which can be reached from this vertex such that there is a path from this vertex to that vertex  hindi  there is no path from this vertex to this vertex why  because this vertex is no edge coming into it now there are only two edges going out of this vertex and no other edge coming in there is no way of going from here to here in fact there is no way from any vertex to this vertex this vertex does not get visited when we do our first depth first search but just as in the case of breadth first search what we did was  if some vertices were not visited we took a vertex which is not visited and started out breadth first search from that vertex similarly we are going to do that here if some vertex is not visited after we finish our depth first search from this vertex then we are going to pick that vertex which is not visited and continue our depth first search from there so which means that i am going to now pick this vertex  give it an arrival time of 10 now  look at the edges which are going out of this vertex they are all going to vertices which are already visited so there is nothing to be done so which means that i also finish this depth first search in this manner every vertex is going to get both an arrival and a departure time i will keep this picture and i will again redraw the tree  the depth first search tree  refer slide time  09  31  we did a similar thing in the last time  student  sir we are all vertices  we have to visit all the vertices  so both depth first breadth and depth first search require that you go visit every vertex so while i did not elaborate on this when we were discussing depth first search in undirected graphs but there i was assuming that the graph was connected if the graph is not connected  you did a depth first search from a vertex  you visited a bunch of vertices if you have not visited all vertices then you will take another vertex which is not visited and start a depth first search from here  student  sir to see that whether this vertex is not been visited  we also have to go to once again to all the vertices   we had looked at a procedure for doing this in the clever manner  when we were looking at connected components all we have to do is traverse the visited array to find the first vertex which is still at a zero and we will never have to retrace  we will just have to make one scan of that array we can adopt the same procedure here let me now draw these are the tree edges that you have drawn now i am going to draw the back edges now we will understand what kinds of edges can there be  just one second i have drawn all the edges as you can see  so the tree edges are in blue  student  we ca n't  you ca n't see the colors wow  i did n't realize that that ? s tragic  let me try to make them darker can you see the color now ?  student  yes  it looks a deeper black  student  it is easy bold and fine  fine  student  find in dash dash dotted  so good that you pointed out is that today that you ca n't ?  student  no noise every day you pen moves on that we assume that it is the same color  is it better ?  student  slightly  slightly  student  but because if you use a pen now we realizing its blue  so this blue edge  no it ? s not blue does it look blue now ?  student  its red light red  its red  student  sir sketch pen sir we have to make that out by using the sketch that you are using   hindi   hopefully the others were watching this program  we will be as smart as you are ;  1  8    2  3    4  7    5  6  and  10  11   now we do n't have the nice picture we had in the case of undirected graphs that all edges are in two categories either tree edges or a back edges as you can see there are three different color already and i have not yet used a forth color there is also a possibility of a forth color and let me show  you could also have an edge which goes from here to here this is green clearly this edge could have been there  why ? suppose this edge was there  i am continuing to follow this path when i come back here to this vertex  i look at the other edges going out  this is another edge going out but its other end point is visited now we have to classify these edges  we have to give them names our green edge  this edge is a forward edge why forward ? because it is going forward in the tree  down we will call that forward the brown edge is a back edge  it is going back up in the tree we do n't use the term backward edge  we just use back edge it is nothing backward about the edge the red edge is called a cross edge  student  which has which one which one   this is a red edge and this is also a red edge and this is also a red edge  these three are red edges the brown also looks like black is it ? the brown edge is that edge  it is a back edge so it should be clear tree edge is completely clear  an edge along which we traverse is called a tree edge now something that is going forward in the tree is called the forward edge  something that is going back in the tree is called a back edge something that is not going either forward or back is called a cross edge what is a property of a cross edge ?  student  not going to ancestor  not going to ancestors or to a descendant  student  descendant   the two end points of the edge do n't have an ancestor descendant relationship  not parent child  ancestor descendant relationship the two end points of this edge or none of them is a ancestor of the other similarly for this edge  none of them is an ancestor of the other this is one tree  this is another tree so to say  just a single ten vertex this is not an ancestor of any of these vertices these three are cross edges could i have a cross edge which goes in this direction ? it would have become a tree edge so cross edge would go in one direction only what is that direction ? we will translate all of these into numbers very soon but essentially if you draw picture in which you are first visiting the left side of your tree and then going right then they are going from right to left the cross edge only go from right to left so to say not higher to lower but more like right to left this cross edge is also going from right to left  this is also going from right to left we know this is bit subjective but i will tell you what the actual thing is what ? s the property of a forward edge  who can tell me ? so what is it that makes an edge of forward edge ? so a forward edge how can i relate its arrival and departure times if i have an edge u v which is a forward edge  what can i say about the arrival of u verses the arrival of v  student  arrival of u arrival of v  pardon  arrival of u  student  is less than other  it ? s an forward edge such an edge this is u  this is v i would have first reached u and then i would have reached v what can i say about the departure of u verses the departure of v ?  student  departure of v  clearly i will leave this before i leave that so departure of v is less than the departure of u that 's for a forward edge i can play the same game let me now say it for a back edge once again i have a u v back edge so arrival of u verses of arrival of v which is smaller ? this is a back edge  this is u  this is v v will be smaller because when i am saying the edge is u v  in a directed edge i always specify the tail first this is u  that 's v this is v then i reached this before i reached this the arrival of v is less than arrival of u what about departure ? departure of u verses departure of v departure of u is a u v edge  i will leave u before i leave v now let ? s come finally to our cross edges and since this is more important and you have not seen this before once again u v is a cross edge if this is a cross edge  this is u  this is v what about arrival of u verses departure of u ?  student  arrival of u  arrival of u verses arrival of v  this is u  this is v  student  every  arrival of u is greater this is u  this is v i will reach here  after i have reached here arrival of u is greater than the arrival of v i will first arrive at u actually then i will depart form u yes  so i should actually write it in a more sophisticated way as departure of u sorry arrival of u is not greater  i would first less i first arrive at u then i depart from u then i arrive oops what am i saying  sorry  refer slide time  21  25  i have managed to create a mess there let me do it again so we are considering a cross edge  can you all see this picture ? let me consider a cross edge again i am looking at an edge u v  so in my picture this is u  this is v now it should be clear so which vertex will i reach first ?  student  v  v  so first i reach v then i leave v that 's important then i reach u  then i depart from u yes  refer slide time  22  49  the arrival and departures are arranged in this way for a cross edge great so in a depth first search the edges get classified into four categories and based on the arrival and departures  you can figure out what those categories are or based on the fact that whether they are a tree edge or not so first you will create the tree edges  first you will identify what the tree edges are using the tree edges you can identify the parent child relationships also  ancestors descendant relationships and using that you can figure out whether it is a forward edge or a back edge or a cross edge if the two end points have an ancestor descendant relationship then it ? s either a forward edge or a cross edge or a tree edge if they don ? t have then it has to be a cross edge sorry in the first case it ? s either a forward or a back or a tree and in the second case it is a cross edge when you have to distinguish whether it is a forward or a tree or a cross  then again you know it ? s based on whether the tail is an ancestor of the head or whether the tail is an descendant of the head you can use that to figure out these things so as an application we are going to look at how to check if a given graph has a cycle or not so that 's the application we are going to look at i am giving you a graph g  so given a directed graph g check if g has a cycle what is a cycle in a directed graph ? it ? s basically a path which closes on itself  the starting and the ending of the path are the same how will you check if a given directed graph has a cycle ? how will you check if a given undirected graph has a cycle ?  student  starting node if we have any back edge if we access the starting node   hindi  so then there is a cycle if there is a back edge there is a cycle if there is no back edge  is there no cycle in the graph ?  student  yes  because then the remaining edges are just tree edges  they form a tree a tree does not have a cycle in it and a back edge  why does it form a cycle ? because the two end points of the back edge are connected in the tree there is a path between those two end points so for an undirected graphs  it is very simple for a directed graph it is not so simple when does a directed graph have a cycle ? once again you want to do a depth first search in a depth first search in what ? s  student  the back edges are definitely  if there is a back edge then the graph has a cycle if we encounter a back edge then g has a cycle great  why ? well  let ? s just look at an example this was the tree  this was the back edge  what is a cycle ? well  the cycle is exactly this  refer slide time  26  32  since it is a tree  this node is an ancestor this is a back edge so this is an ancestor of this if this is an ancestor of this  there is a path in the tree from here to here i will go down to one of its child and so and on and reach here and this together with this forms the cycle for us if there is a back edge  there is a cycle if there is a cross edge  does that mean that there is a cycle ? so question is if there is no back edge  does that mean g is acyclic ? i am using a term here  what does acyclic mean ? no cycle  student  there is a cycle consider a graph it is only a cycle when definitely you will not have a back edge  he is saying consider a graph which is only a cycle we will not have a back edge it will have a back edge is it clear ? so he is saying consider a graph which is only a cycle  hindi   when we do a depth first search of this graph  what do we get ? no matter of what vertex i start from i will let ? s say go down here then i go down here then i go down here  here  here and at this point this is will become a back edge because i will just retrace my path here and reach here so this will become a back edge so back edge  if you find a back edge there is a cycle if there is a cycle  it seems that you will get a back edge can you prove this ? if there is no back edge does that mean that there is no cycle in the graph no  student  all forward  if there is no back edge  does that mean g is acyclic ?  student  due to a cross edge also because it can happen that in a particular cycle the child is traversed by some other path like the origin of cross edges   hindi   so let me do a very interesting proof of this statement or what is a statement ? this is not a statement  this is a question so statement is no back means no cycle no back edge  no cycle  student  for a cycle does it mean a arrow is going in one direction  of course  this is a directed graph a cycle means a path i was very clearly specified in a directed graph  a path means you can go from one vertex to the next think of them as one way streets a cycle would mean only if you can traverse in such a manner such that you can reach the starting point great so no back edge means no cycle and how am i going to prove this ? let me do the following i will do a depth first search and now i will order the vertices according to their departure times so do dfs  order vertices by their departure times what does that mean ? let ? s say i will first put down the vertex which has the largest departure times say  hindi   this has the largest and this has the smallest and the departure times are decreasing like this this is the largest side  hindi   so this is the vertex which has the largest departure time  no two vertices at the same departure time yes because every time we depart from the vertex  we change the time so this is the vertex with the next smallest  the next smallest  the next smallest and so on and on  refer slide time  31.40  now let ? s go back to all that we have done so far let ? s look at this picture for a forward edge  if u v is a forward edge then the departure time of u is more than the departure time of v   hindi  yes so the departure time if u v is a forward edge then the departure time of the u  u is the tail  v is the head of the edge the edge is going from u to v the departure time of u will be more than the departure time of v so if i have a forward edge then will it go from left to right or will it go from right to left ? if i have a forward edge its tail would have a higher departure time  so it could go from left to right a forward edge would like this let ? s look at a cross edge now a cross edge  u v cross edge the departure time of u is again more than the departure time of v so the edge will also go  a cross edge would also go from left to right  hindi  there is a cycle in the graph so what edge remains ?  student  tree edge  tree edge what is the property of the departure time if u v is a tree edge then departure of u v  hindi   so first i will leave from v and then i will leave from u so departure of u would be more than the departure of v great so a tree edge also goes like this all edges are going from left to right how can they be a cycle ? can you create a cycle by just going from left to right ? no if you have to come back to the starting vertex  hindi  and you have to come back to this vertex   hindi  you can go forward but at some point you have to come back but there is no edge which is coming from right to left so there is no cycle in this graph  hindi  yeah  everyone follows this proof now you know why we were worrying about departure times so you have to do this with departure times you can ? t do this with arrival times  unfortunately so try that as an exercise if i were to order them by arrival time this is not going to work  hindi  so this is actually a very simple proof theorem if there is no back edge in the graph then there is no cycle if there is a back edge then there is a cycle so all you have to do is do a dfs  if at any point you encounter a back edge  you declare that the graph has a cycle if you are able to finish your depth first search without encountering a single back edge then you declare the graph is acyclic  hindi  what is an acyclic graph ? a acyclic graph is a graph which does not have a cycle  refer slide time  35  45  this ordering so ? what we have ? another thing we have shown and that is the very nice thing is that given an acyclic graph  let ? s say g is an acyclic graph we can order the vertices of g so that every edge  so that every edge goes from left to right  yes that ? s what we did here we said we started with an acyclic graph we started with a graph  we did a depth first search in a graph we did not encounter any back edge so we said the graph does not have a cycle it is an acyclic graph and then we said lets order the vertices of the graph according to decreasing departure times then what we see ? if we order the vertices in the manner then every edge goes from left to right this ordering is also called a topological sort  hindi   so in a acyclic graph you can order the vertices  linearly order the vertices so that the edges are going only from left to right this ordering is called the topological sort so how much time do you take to find a topological sort ? you just have to do a dfs and then  then sorting  student  this is  check what ?  student  is there exists some   hindi  but you have to produce an ordering of the vertices right  student  hindi  right  so we don ? t need to sort because we know what the departure times are what is a maximum departure time we can have ?  student  2 n  2 n  yes 2 n actually 2 n minus 1 because each vertex is getting two numbers  right so the total set of numbers that we are going to be assigning arrival and departure times will be in the range 0 through 2 n minus 1 so the departure times is at most 2 n minus 1 that is at least to 1 so i can just have an array with 2 n entries in it and as i depart from a vertex  as i assign it with departure time at the position in the array i put down the vertices i just need to make one scan of this array to get the vertices in the right order  hindi  so you don ? t need to sort the n departure time because if you had to sort  you would take n log n time we have not seen a sorting algorithm which performs better than n log n so this ordering is called the topological sort and it can be computed in order n time  order n plus m time so i have used  so i should also tell you about another term that is used for acyclic graph so we are talking of directed graphs here a directed acyclic graph  directed graph which is acyclic is also called a dag  d a g  hindi    refer slide time  40  29  these graphs arise quite a bit in circuits  in combinational circuits where you know your pulses are essentially traveling from one side to the other there is no notion of a cycle  there is no loops and so these graphs model that and we can do a lot of things on such kind of graphs which we can not do on a regular directed graph the graph which has cycles in it and we will see some of that in this course questions so far ?  hindi  so let me introduce  i will like to take one more application of dfs in directed graphs and since that is a longer application  we will not be able to finish it in this class but i will develop the terminology for it so let ? s go back to our notion of ? so for undirected graphs  so if i gave you an undirected graphs there was a notion of whether the graph is connected yeah  when is an undirected graph connected ? when it all vertices  student  there is a path between every two vertices  there is a path between very two vertices then we say that the graph is connected so connected means there is a path between every pair of vertices in a directed graph the corresponding term is what is called strongly connected a directed graph is called strongly connected  if there is a path between every ordered pair of vertices why am i using this term ordered pair of vertices ? between which  so i said pair of vertices but you know it is a directed graph may be there is a path from u to v but there is no path from v to u let ? s take an example is this graph strongly connected ? let me label there is a path between a and b but there is no path from b to a there is a path from b to c but there is no path from c to b there is a path from d to c but there is no path from c to d  hindi  it is still not strongly connected there is a path from a to b  student  but not from  but from b to a there is no path still pardon yeah  sorry  student  what do you mean by the  no  no when i say there is a path from a to b it basically means that i can go from a to b like this or like this right but i can not go b to a there is no path from b to a is there a pair pair of vertices such that there is a path between these two vertices in both directions  student  no  no can not happen right because not in this graph  refer slide time  44  55  let ? s see more examples which will perhaps be better so a b c d  is this strongly connected ? no  yeah between any two vertices so from d to b there is a path  from b to d also there is a path because everything is on a cycle  student  cycle  yes  so this graph is strongly connected is this graph strongly connected ?  student  yes sir   hindi  is there a path sorry  is there a path from a to f ?  student  yes yes  yes  student  a to b  yes a and f there is also path from f to a going like this so this graph is also strongly connected no that is not sufficient right  i can ? t just take two pairs and check them and say it is strongly connected we have to look at every pair right but you can check  hindi  all of these form one strongly connected component for all these 4 vertices any pair i choose is connected similarly for these four vertices any pair i choose is connected yeah and that should somehow tell you how to do things  student  both of them must be part of cycle  right something like that if there is a notion of strongly connected there should be a notion of weakly connected  not daily weakly connected  sorry it ? s weakly connected what do you think is a weakly connected graph ?  student  between u and v all v to u  yes  student  as undirected graph  no no  not as undirected they are connected the following is  student  there is a path from u to v or  there is a path from  student  u to v or v to u  or v to u and or v to u the following graph is weakly connected  student  yes  yes  hindi  is there a path from b to d ? no is there a path from d to b ? no is it weakly connected ?  student  no  no  this is not a weakly connected graph so why am i showing you this example  it ? s not sufficient to say  hindi  so this is a graph such that if i were to ignore the directions  it is a connected graph but it is not a weakly connected graph so what is the right definition of weakly connected ? a graph is weakly connected if for every pair of vertices u  v there is a path from u to v or a path from v to u or both if both the paths are there its okay and this should be true for very pair of vertices right  hindi  right  good so i have told you what is strongly connected graph is and what a weakly connected graph is  refer slide time  49  36  so natural question is given a graph  is it strongly connected ?  hindi  given a graph g  is g strongly connected ? so what are you saying ? we are doing a dfs starting from here so we have to check  so strongly connected means we have to check that from between every pair of vertices  every ordered pair of vertices there is a path so from u to v there should be a path and from v to u there should be a path so one solution that is being suggested is that you take one vertex  do a dfs from here it should visit all vertices and then take another vertex and do a dfs from there it should also visit all vertices take a third vertex and do a dfs from there  it should also visit all vertices so do this dfs how many times ? n times from every vertex if each of those dfs ? s visit all the vertices then the graph is strongly connected yes  is that clear is this argument clear ? if all of these dfs visit each and every vertex then the graph is strongly connected perfectly okay  except how much time does it take ? order m n time that ? s too much for us we want do it in linear time so we want to do it in order m plus n time  refer slide time  51  45  so question is how did you do that ?  hindi  so try to think about this and think in terms of the procedure we used for two edge connectivity we will borrow ideas from there in two edge connectivity what did we require ? we required that for every sub tree there should be an edge  back edge going out of the sub tree so to say  going to a ancestor of the root here also we require something similar that ? s the hint so you will have to see what that is and we will discuss it in more detail in the next class data structures and algorithms dr naveen garg department of computer science and engineering iit delhi lecture ? 30 applications of dfs in directed graphs today we are going to look at more applications of depth first search in directed graphs recall that in the last class i had mentioned that we will talk about strong connectivity we will see how to figure out  if a given directed graph is strongly connected or not and i have defined what is strong connectivity means it essentially means that between every ordered pair of vertices there is a path in the graph so which means i take two vertices lets say u and v  there should be path from u to v and also a path from v to u then we would call the graph strongly connected so in the last class there was a very simple algorithm that was suggested which was that take a vertex  do a dfs from there take another vertex  do a dfs from there and so and on which means do a dfs from every vertex in the graph if in each one of these dfs ? s  we include all the vertices of the graph only then is the graph strongly connected that should be easy to see let ? s see if we can reduce the number of dfs calls that we make  instead of making n dfs ? s  can we reduce the number of dfs from n to lets say some small number let ? s say i take one vertex v and i do a dfs from here and when i do a dfs from here  i visit all the vertices in the graph this is let ? s say the dfs tree i obtain and if these were the only vertices in the graph then i have visited all the vertices in the graph so what do i know ? i know that there is a path from v to every vertex in the graph if dfs v visits all vertices in graph g then there exists a path from v to every vertex in g suppose we could somehow figure out  we could also do the following we could somehow figure out that there exists or i claim there exists a path from every vertex in g to v let ? s assume this is the case  suppose this is true that is  hindi conversation  then does that imply that the graph is strongly connected basically we are saying 1 + 2 implies g is strongly connected so if we have to find a path between some two vertices like say x and y  so what will i do ? go from x to v  by the statement two there is such a path from every vertex to v and then i go from v to y by statement one so all i need to somehow ensure is that there exist a path from every vertex in the graph to v  refer slide time  05  25  how will i ensure this ? this says that there is a path from v to every vertex in the graph if i can ensure that there is a path from every vertex in the graph to v  then i am done how will i ensure that from every vertex in the graph there is a path to v ?  student  from the lower most vertex  we are ending first starting from the path deepest back edge have as a back edge   so the question is how do i ensure that there is a path from every vertex to v ?  student  sir we can back edges  think of something new  student  also we need the cross edges to if there are some cross edges so we can go along from them to   suppose i were to do the following  refer slide time  08  14  i took my graph g and i reversed  hindi conversation   reverse edges to get a graph g sup r  hindi conversation   student  do dfs from that vertex again now it look at a path  so do dfs  student  that gives now  do dfs v on this graph g of sup r  hindi conversation    student  if you get all the vertices   hindi conversation  if all vertices are visited then this implies  in g there is a path from every vertex to v yes or no ?  hindi conversation   student  yes sir  if every vertex gets visited in this dfs then i can say that the graph is strongly connected  hindi conversation   in this graph there is no path from v to this vertex which means that in the original graph there is no path from this vertex to this vertex which means that the original graph is not strongly connected  refer slide time  09  01   hindi conversation    student  in adjacency list we can fetch change the function go along  we can also change the function dfs instead of looking at out adjacency edges  we can look at inadjacency edges and we don ? t even have to reverse the graph then  hindi conversation   so essentially by using two dfs ? s  you can figure out if the graph is strongly connected or not so everyone understands the procedure let me write down what the procedure is pick an arbitrary vertex v  do dfs v  reverse g  do dfs v on g reverse  if all vertices are visited in both dfs ? s then g is strongly connected else g is not strongly connected  hindi conversation    refer slide time  11  19  we will now try to do it with one dfs it ? s an academic exercise for this problem but at least you will learn the properties of dfs and because this is perfectly fine algorithm and it just requires two dfs ? s to do it so let ? s look at another way of checking if a graph is strongly connected or not now we will use our whole gammon of definitions and terminologies so what are we going to do now ? we are going to do a dfs  we start from a vertex and we do a dfs so let ? s say these are the red edges which form the dfs tree  hindi conversation  suppose this is what i get my dfs tree as now i remarked in the last class that we are going to use ideas similar to what we developed for two edge connectivity so two edge connectivity  hindi conversation   we were saying that when we are back tracking  lets say backtracking from this vertex i am going back to the parent because i have finished everything i ensure that there is some edge which goes from this sub tree to it can only go to an ancestor or above because we said there are only back edges in the case of undirected dfs so if an edge goes out of here  it can not go to one of these nodes it can go only to an ancestor so we said we would like to have one such edge now we need similar such thing in the case of strong connectivity from here we would like that there is some edge going out  hindi conversation   what kind of edges will be going out of this sub tree ? only back edges but if this were the sub tree i was considering then there could also be either there is back edge out of this sub tree or there is a cross edge out of this sub tree so i could also have an edge going like this it can happen so this edge is also an edge going out of this sub tree  if there is an edge going out of the sub tree i am happy this is the only thing we will require clearly this is necessary  if from this sub tree there is no edge going out then this graph is not strongly connected why ? because then you can only enter the sub tree  we can only come to these set of vertices  we can go out of this set of vertices what i mean by that is if there were no edge going out of this sub tree then i can not go from this vertex to the root for instance to vertex v because there is no edge going out of this 4 edges this is like an island in itself  you can only come into here but you can not go out of here  student  but if an edge is going out what do you do ?  so all i am saying is that we require that it is necessary that an edge go out whether that is sufficient  we have to figure out it is clearly necessary that an edge goes out of every sub tree you understand the difference between necessary and sufficiency so it is necessary that an edge go out of every sub tree you understand what i mean by out of every sub tree  so you are looking at the sub tree what is a sub tree here ? it is the descendance of any one vertex  take any one vertex  look at all its descendant that ? s a sub tree we are interested in and there has to be at least one edge going out of that this is clearly necessary  hindi conversation  no edges is going out of that sub tree then we can stop the process at that point  stop our dfs and say that this graph is not strongly connected now we will see how we can check this thing we will look at the procedure  we will look at what modification to make to the dfs so that we can check that there is an edge going out of every sub tree the check would be very similar to what we did for the case of two edge connectivity but now let ? s see that this condition is also sufficient if from every sub tree there is an edge going out then the graph is strongly connected  hindi conversation   why ?  student   why  student  arrival time is the difficulty  of what  student  all the sub trees if there is an edge from here to some other sub tree    student  the vertex that is feature will have a lower arrival time  will have a lower arrival time than whom  student  then the vertex in all the vertices of the sub tree  close  almost there so what am i going to do ?  hindi conversation  from the root i can reach every vertex now all i have to show you is that from every vertex i can reach the root if i can reach the root from every vertex i am done yes  because then how do i find a path between x and y ? i go from x to the root and from the root i go to y so all i have to show you is a path from every vertex to the root so we want to find a path from every vertex to the root  hindi conversation   we take some vertex  let ? s say this is the vertex x i want to go from x to the root v how will i go ? i am going to look at the sub tree rooted at x  hindi conversation   x is some vertex somewhere in my dfs  hindi conversation   will it be smaller than x or larger than x ? it is smaller than x and  hindi conversation  smaller because this is a cross edge you would have first come here in fact  hindi conversation   so let ? s give this name  suppose this node is w so i can reach a node w  so what have we said ? we have said that from x  can i go from x to w ? yes  why ? because this is a sub tree  these are all descendant this node is also a descendant of x which means that i can come to this node and then i can take this edge and get to w so what ? s the big deal about to getting to w ? from x i can get to a node which has a strictly smaller arrival time than x now from w i can repeat the same process from w  i can get to a node which has a strictly smaller arrival time than w which means that may be  hindi conversation   now what do you know ? you know that the arrival time of x is strictly larger than the arrival time of w which is strictly larger than the arrival time of a which is strictly larger than the arrival time of c  hindi conversation   i can get to a node with the smaller arrival time  hindi conversation   student  when you reach  when i reach the root so that will give me a path from this node to the root  hindi conversation   just this requirement that an edge go out of every sub tree is both necessary and sufficient just this requirement and this is an easy requirement to check and we are going to do that next  refer slide time  21  44  so how am i going to check this requirement ? how should we modify dfs so that we can check if there is an edge going out of every sub tree ? i am using the sub word sub tree a bit loosely  here by sub tree i mean the part of that tree which is composed of the descendants of any vertex so take any vertex  look at all its descendants  that part of the tree is what i am calling a sub tree the generic definition of a sub tree is slightly different how will you modify dfs to be able to this ? in the case of two edge connectivity we had modified dfs so that it returns to us the deepest back edge the arrival time of the node to which there is a back edge from the sub tree and the smallest such arrival time  hindi conversation   in the case of two edge connectivity what we have done was that we would return from every sub tree  would return the deepest back edge by that we mean the arrival time of this node now we will do the same thing here this dfs would return to us  not the deepest back edge anymore  the node with the smallest arrival time to which there is an edge from this sub tree so let me write that down  dfs returns the smallest arrival time to which there is an edge from this sub tree rooted at let ? s say v so dfs v returns this  refer slide time  25  29   what i am trying to say now is the following when i do a dfs from v  there could be many edges going out of this sub tree let ? s say there are four edges going out of this sub tree and edge which is going out of the sub tree will either be a back edge or a cross edge forward edge can not be going out of the sub tree  it can only be coming in to the sub tree or if it starts from here in the sub tree it will go within the sub tree only so now essentially i am going to look at these four arrival times and take the smallest amongst them and that is the quantity the dfs we will return to v if this arrival time was a  this was b  this was c  this was d  dfs v returns min of a b c d clearly b is smaller than a and d is also smaller than c  refer slide time  26.45  this is what we have to return now we have to figure out how we will return this thing note that dfs is a recursive procedure  when i do a dfs from vertex v  i end up doing a dfs from its neighboring vertices so suppose its three neighboring vertices were x  y and z so i will do a dfs from here i will get this tree  let ? s say i do a dfs from here i get this tree  i do a dfs from there i get that tree  refer slide time  27  21   now this dfs x will return something to me so it will look at all the edges which are going out of this sub tree and look at the node with the smallest arrival time to which there is an edge from here similarly dfs y would return something to me and dfs z would return something to me so what is the value of dfs v going to be ? dfs v would have a value  we have to find out the edge going out of this sub tree so an edge which goes out of this sub tree would be an edge going out of here or out of here or out of here but an edge going out of here could end up here itself so it is not really going out of this sub tree  student  we have to check it with arrival time of the then it will not  and we will also look at v of course so from v we will look at the back edges out of v and cross edges out of v so we will basically look at all the edges going out of here  all the edges going out of here all the edges going out of here and all the edges going out of v and take the minimum of their arrival times when will the edge be going out of this sub tree ? when that arrival time is less than the arrival time of v  hindi conversation  there is an edge going out but  hindi conversation  there is no edge going out  hindi conversation   so you have to check that  hindi conversation  that is less than the arrival time of v if it is less than the arrival time of v then that means that the edges going out of the sub tree and we are okay if it is not less than arrival time of v then we can stop the procedure and say that the graph is not strongly connected  refer slide time  29.36  so now i just have to write the code for this so what should i do ? let ? s call this a strongly connected so what is strongly connected going to do ? so first it is going to be setting up the arrival time of the vertex v now what should i do next ? i need to keep track of this minimum so i need a variable for that so let me declare some variable what should we call it ? min  no min is for the function so what shall i call it ? you can ? t think of a name of a variable ? xyz that ? s how you name a variable let ? s call it xyz  so what should be my initial value of xyz be ? arrival of v  no harm in setting it to this value and now what am i doing  what should i write next ? for all w adjacent to v  out adjacent is the same as adjacent we are saying adjacent means out adjacent here ; adjacent to v do  if not visited somewhere i have to set visited v equals one as soon as i started dfs i set the visited variable to one if not visited v then what do i do ? then i do a dfs from there or i run this procedure from that vertex w and it will return something to me and i have to update what it returns so xyz equals minimum of xyz  sc  w   else if visited w is true ; if the vertex is w is already visited so then that means that is either a cross edge or a back edge starting from v else xyz equal min of xyz  arrival of w what are we doing here ? we are looking at the cross edges and the back edges starting from the vertex v and also including that into the min computation now what are mins ? this is the end of this for loop if xyz equals arrival v then stop and we will stop with saying that graph is not strongly connected else we just return  refer slide time  33.46  this will again have a small problem for the root vertex because for the root vertex this quantity will turn out to be zero  can not be less than a zero so that has to be checked we can ? t abort always  we have to just ensure that it is not the root vertex  hindi conversation   so almost exactly like we did for two edge connectivity so how much time does this take ? almost the same time as depth first search we have one additional variable which we are modifying and that ? s all the time  the additional time that we require so as far as applications of dfs are concerned  you will see quite a few applications can someone tell me what all you have seen ? application of dfs in directed graphs  what are the applications we have seen so far ? two edge connected is not for directed graphs checking if a graph is strongly connected  checking if a graph is acyclic and of course also topological sort all though it is the same as that there are a lot of other applications  i am not going to be taking them up in this class any questions so far ? so as a recap since we are now going to be switching topics  let me also look at what we have done for undirected graphs we actually have looked at only one application that was for two edge connectivity i did mention that you can use similar procedures  you can use dfs to also check if a graph is vertex connected and if it is plain but we did not do those two applications in detail in this class what application did we see for breadth first search ? finding the connected components of the graph and checking if a graph is bipartite  refer slide time  37.42  also the shortest distance that ? s just breadth first search  the label that it returns are the shortest distance of the vertices from the root  the starting vertex and all of these are linear time procedures data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 31 today we are going to be talking about minimum spanning trees we are going to define what a minimum spanning tree is we are also going to look at algorithms of minimum spanning trees so you all know what a spanning tree is does everyone know what a spanning tree in a graph is ? did we define it ? yes we did so i gave you an undirected graph  so what is a spanning tree in g ? so spanning tree  the term is composed of two things tree and panning  tree means it should be a tree what is a tree ? tree is a connected sub graph without any cycles connected sub graph without cycles that is a tree and what does spanning mean ? spanning means that it should include all vertices this basically means that it should include all vertices that would be a spanning tree in the graph so for an example if i drew a graph something like that  say this were my graph then i could draw a spanning tree in this graph by let say  i am going to use a very  let us say  i pick this edge in the tree  pick this  pick that  pick that then i pick this and i pick this how many edges do i need to pick ? is this a spanning tree ? no this vertex is not included here i could pick one of the edges incident at this to include this this is a spanning tree we know that our spanning tree  if the graph has n vertices  so spanning tree has how many edges ? number of vertices minus 1 edge yes  great  refer slide time  03  43  what is a minimum spanning tree ? minimum spanning tree is a spanning tree of minimum weight sometimes i will use the term weight  sometimes i will use the terms length  one at the same thing  hindi  you are not just given the graph but we are also given a length function on the edges of the graph let me assume the lengths are non-negative reals so  every edge has a length now so  think of that in the following way these are certain cities and i can either draw or i can either connect these 2 cities by a wire or i can connect these 2 cities by a wire or i can connect these 2 by a wire  i can connect these  these or these these are the possible options i have of connecting them with wires some options are not there why ?  hindi  could be some reason  hindi   so  this is a graph now  to connect 2 particular cities  i am also told  how much length of the wire i need  that is my length function suppose i told you that you need 3 here and you need 5 here and you need 2 here  what are the units ? it could be anything  1000 kilo meters  meters  i do not care this could be 1  this could be 7  this could be 4  6  9 i just put in some numbers in between so  we need to connect these cities which means we need to create a spanning tree and i am not interested in any spanning tree i am interested in spanning tree for which the length of wire is spent as small as possible so  that is what i mean by a minimum spanning tree  a spanning tree of a minimum length what is the length of the spanning tree now ? so  sum of the lengths of the edges in the tree so  let us formally define that the length of the spanning tree equals sum of the lengths of the edges in the tree so  i might now decide to pick some edges suppose i pick  i did not give this length  i give this the length 4 suppose  i pick this edge and i pick this edge and i pick this edge and i pick this edge and i pick this edge  hindi  so  i can not pick this edge  it is not a tree at all  i can not pick so  let me pick something else so  let me pick this 6  hindi  what is the length of this tree ? 6 plus 4 plus 4 plus 3 plus 5  22 right ? there might be other trees in this  other spanning trees which are smaller than 22 i am interested in the finding the one which is the smallest  refer slide time  07  46  there is no notion of the root in the case of spanning tree  when we defined  spanning tree is trees in graph  there was no notion of the root over we call that also  we use the term free tree for that there is no notion since  the vertex  since all the vertices are going to be included  hindi  3  4  1  2  5  9  7  4  6 and the edges we included were  this edge   hindi  one way you can convince yourself that this is not the smallest possible tree is  by seeing that for instance if i include this edge of the length 1 then what is going to happen ? will it be a tree or ? we will be have a cycle so  that is one property of a spanning tree always  hindi   it is a connected sub graph which means  hindi   so  i can go from  let say  this is vertex u and this is vertex v  i can go from u to v by following the edges of the tree and then i can take this edge that is added just now  back to go to u which means it form a cycle if it is a cycle  it is not a tree any more now  in this cycle  suppose the edges have a certain length  hindi   now  what can i do ? i can include this edge and drop the edge of length 4 will that remain ? will that continue to be a tree ? if i were to drop this edge  will it remain a tree ? why ? why would it remain connected ? no notion of a descendant there is no notion of a descendant why ? that is the question we have discussed this before the point is that  if there is a path which gets it straight then that path must be using this edge  hindi  i can now create alternate path between those 2 vertices by instead now  going like this between this 2 edges so  that means they are still  is the path between those 2 vertices  hindi   all paths are still there or not paths are still there  all face of vertices are still connected may be  by different path but they are still connected so  that is an operation we can do always i can try and add an edge  try to add an edge in to this tree and see if as a result of that operation  so  as a result of that operation  i will clearly form a cycle if from that cycle  i can drop and edge of longer length than the edge i added  then i would have reduced the cost of this tree  the cost of the length or weight  i will use these terms  hindi  so  i form of this cycle i can drop any edge of this cycle and it will still remain a tree which is the edge i would like to drop ? 4  i will drop this edge  4 and now  my new tree has length what ?  hindi   22 minus  hindi  so  this new tree length 22 minus 3  hindi  see  i can repeat the process  i can see  there is something else that can be done can you say something else that can be done ? 2  so suppose  i include 2 so  now i form the cycle which has edges of length 3 and 5 in it so  it make sense to drop 5 and the reduction now is 3 units again now  let me draw the tree  we have the  hindi  so  the tree that i have at this point is  this is the tree i have now this is the edge  length 1  this is 3  this is 2  this is 4  this is 6 would it make sense to include some other edge and try and repeat the process ? no  because  if i include this edge which is of length 4  then this edge is the longest edge on the cycle that gets ?  hindi  and the edge i am including is the longest edge on the cycle it does not make sense to include it  therefore if i include this edge  it is of length 5 the cycle found may  this is again the longest edge of the cycle does not make sense to include  if i include this edge 7  this is the cycle that get formed and 7 is again the longest edge of the cycle if i include this edge 9 then there is the longer cycle that gets formed but once again 9 is the longest edge of the cycle so  it does not make sense to include 9 so  it does not make sense to include any other edge and so  actually  i should not say  and so  the reason is that  is not the reason why  i can not claim from this that this is the minimum spanning tree but  it is the minimum spanning tree we will use different arguments proving that so  this is a minimum spanning tree in this graph so  mst has length  what is the length of this ? 16  refer slide time  16  36  this could be treated as an algorithm  so computing the minimum spanning tree how did it work ? you start with some tree then try to include an edge  look at the cycle that gets formed  see  if you can drop an edge of longer length from that cycle or if there is a longer edge on that cycle if there is  then you can drop that edge and therefore reduce the cost of the tree so  you keep doing procedure till you reduce the cost of the tree and you stop when you can not reduce it anymore but  we will not look at this algorithm or we will not analyse this algorithm because it will be fairly expensive  in terms of running time we are going to look at the different algorithm for computing the minimum spanning tree and algorithm we are going to look at  is called kruskal ? s algorithm so  we are looking at kruskal ? s algorithm in minimum spanning tree it is actually very simply algorithm let me illustrate it on the same graph that we had before i am going to draw this graph out  refer slide time  18  38  the algorithm is the following  it says  take the minimum edge in the graph  hindi  this is an example of what is called the greedy algorithm also you will be greedy  you are all greed  but  we will now be greedy to compute the minimum spanning tree so  what you think greedy means ? try to get the larger go for less ? that is not greedy make the best possible choice at each time without thinking about the future that is the key thing make the best choice available  i will not write without thinking of the future but that is reason why it is called greedy we just make the best available choice at each time here  of course  our objective is to minimize the length of a tree what is the best thing to do at the first step ? take the edge with the smallest length so  let us do that we pick the edge with the smallest length  that is 1 and this gets included into a minimum spanning tree so  i am now building the minimum spanning tree  edge by edge i included the edge 1  edge of length 1 which is the next smallest edge ? which is the next best choice to make it ? 2 ? 2 or 3 ? when you are saying  we need to connect it your thinking of the future do not do that think of the  be greedy  as greedy as you can just take the best choice so  the next best is  just go for the length 2 and now what is greedy ? say next  which is the next i should take ? 3  4  hindi  so  it will form a cycle since it forms the cycle  we are not getting what we wanted it is not a tree any more  hindi  so  you understand the only modification that i am making ? if by including an edge  i form a cycle  i do not include that edge so  i am not going to include edge 4  sorry  this  this particular edge which is the next edge that i would like to include ? 5  i try to include 5 but 5 also forms the cycle so  i do not include 5 which is the next edge i would like to include ? 6  this edge  6 actually  i can stop at this point because now i have a spanning tree any other edge that i try to include will always form a cycle because this is a spanning tree and so i can stop this as you can see  this we have already argued in  we have not argue  this is the best possible actually  till now  we have not seen an argument for why this is a best possible but  this is the same solution  we obtained earlier soon  we are going to argue that this is the very best possible does every one understand ? yes ? can we write down what the algorithm is ?  refer slide time  22  42  let us quickly write down what the algorithm is  because it is very easy to write down so  kruskal ? s algorithm  hindi   so  let us say the very first step is sort edges in increasing order of length let us say  this is order is e1 e2 e3 em what is this mean ? this means e1 is the edge with the smallest length so  to be more specific  l of ei  length of edge ei is less than the length of the edge ei plus 1  less than or equal to now  what should be the next step ? for i going from 1 to m do  what should i do ? take the first element ? take ei to that spanning tree so  we need to define some spanning tree let say  my spanning tree is t which is initially  null t is the set of edges so  what should i do now ? if ei union t has a cycle  or is a tree then t is t union ei  hindi  return t  i plus plus for loop   hindi  you could do that  may be  hindi  how do we check ? we can later array and we can given it a on every edges in type greater we can increases when it is greater than two that we can wrong  hindi  how do you check  if that edge that you are trying to include  form the cycle or not ?  hindi  what is visited means ? before including a vertex in the tree ? no  we do not include the vertex in the tree we are only including edges into the tree  refer slide time  26  51  as we included edges in the tree  what is visited array of that edges means ?  hindi  what does visited array of vertices mean ?  hindi    refer slide time  28  05  sir  we can do that we can take that both vertices the n point of that edge and we can go for dfso and pfso dfso  bsfo in what ? we will have to develop this later  hindi  we will see how to do it and important thing is also to do it efficiently  hindi  because that will dictate the running time  because expect for this step  there is nothing else this algorithm  hindi  how much time will that take ? m log m  hindi  so  this will  if this step takes less then m log m time  over all iteration put together then this will be an order  m log m algorithm  hindi  so  we have to somehow achieve that  but we will come to that point later before that  we have to argue  why this is a minimum spanning tree ?  hindi  that means all you are saying  you know  you can not greedily impure the tree may be  but there is some other sequence of   hindi  no  we are not taking always the minimum we are not taking always the minimum  because  we are at sometime  when the minimum forms a cycle  we through that minimum away  conversation  so  we need to formalize this equation all i will say is  this is not a proof this is an intrusion for the proof let us see what a proof looks like  hindi  so now  what we are going to do ? look at this carefully because this is how you will have to write your proofs in the exams i am going to look at the edges of kruskal ? s algorithm  the edges picked by kruskal ? s algorithm so  kruskal ? s algorithm picks up certain set of edges let us call those edges  let us give those edges name let us call them g1  g1 is like say  the first edge in kruskal ? s algorithm so  clearly it is the edges of the  so let us g1 g2 g3 how many edges of does kruskal ? s algorithm take ? n minus 1,less than or equal to  hindi  all edge lengths are distinct  hindi  the same proof can be extended to a non distinct case also that will be a question in the majors so  but for now  you will  we will just assume that  the other set of edges is the set of edges that  what should be the other ? so  this is the edges that kruskal ? s pick suppose  you have figured out  what is the best possible tree is ?  hindi  f1 f2 f3  hindi  and again this ordering is such that f1 is less than f2 which is less than f3 and so on  hindi  this is the optimum tree by optimum i mean  the best tree  the minimum spanning tree now  these 2 sets of edges need not be the same  refer slide time  33  37  what we will argue  is that they are indeed the same if they are the same then what we have found from kruskal ? s algorithm is the best tree so  if these 2 set of edges are not the same  so  the proof is by contradiction suppose  these set differ and the first place they differ is i what you mean by that ?  hindi  .because  that will mean that gi and fi are also the same so  let us say  this is the first place where they differ  first point of difference  hindi  case 1  gi  let say less than fi  hindi  every  all edge lengths are distinct  hindi  g i can not be 1 of these because it is of length  strictly less than   hindi  i actually mean  length of gi less then length of fi  just to be more particular i am not going to write it again but that is what i  it really means so  gi less than fi  then that means  the g i can not be 1 of these and it can not be 1of these can it one of these ? no  because these are the same as these and they are all distinct so  these can not be the same  so that  hindi  so  g i less than fi  add gi to opt tree  hindi  gi is the longest edge in the cycle  can gi be the longest edge on the cycle ? add gi to optimum tree let c be the cycle formed this cycle  i am calling it c  refer slide time  39  54  you are saying  hindi  all of these edges had length less than gi  what are these edges ? these edges are some edges are from this side  hindi  they are all from this set  f1 to fi  n minus 1 now  if every edge has length less than gi  then these edges have to be f1 through fi minus 1  yes these edges have to be from the set f1 to fi minus 1  hindi  then these edges have to be from the set  f1 to fi minus 1 but  f1 through fi minus 1 is identical to g1 to gi minus 1  hindi  contradiction  should i repeat ? no ?  refer slide time  43  30  quick repetition  gi is less than fi  i add gi to the optimum tree  to this tree  hindi  but  this set is identical to this set great  that is why this can not happen let us look at the other cases do you want me to repeat ? does everyone following the line of argument ? there are 2 or 3  2 or 3 fine point there but  let us look at the other case let me 1 second  write down this  because it is useful to have this we are not talking of case 2 and this case is when fi is less than gi recall that these are identical and now f i is less than gi  that is what we are going to do now  hindi  fi is distinct from g1to gi minus 1  hindi  why did kruskal not pick fi ? ask him  why ask us ? why did kruskal not pick fi ? because they form the cycle  that was the only reason why he did not pick fi  noise   if it forms the cycle  so because  fi union g1 through gi minus 1 contains a cycle  these set of edges  hindi  but these set of edges is identical to fi union f1 to fi minus 1  hindi  that implies optimum tree also has a cycle but that is not possible because it is a tree  so that is the contradiction  hindi  there is no place where these 2 sets differ because  you said  if these 2 sets differ  let us look at the first place where they differ if they differ  then let us look at the first place where they differ and apply this  hindi  that means they do not differ at all  if they do not differ  these to case are the same so  kruskal ? s algorithm finds the best tree  hindi   refer slide time  47  47  now  note that there is no notion of the term the best tree should i use the term the best tree or a best tree  hindi  so  is the minimum spanning tree unique ?  hindi  yes  listen to me carefully  hindi  edge lengths are distinct is the mst unique ? yes  if edge lengths are distinct no  otherwise why no  otherwise ?  hindi  very simple so  if edge lengths are not distinct  then you could have many different minimum spanning trees but  if the edge lengths are unique or distinct  then you have a unique minimum spanning tree  hindi  that follows from the proof that we have seen  they will be a unique minimum spanning tree  hindi  great   hindi  we have proved the correctness of kruskal ? s algorithm  hindi   refer slide time  50  12  now  we have to figure out  hindi  when i include an edge  how do i ensure that no cycle in formed basically  that is the question  how do we check if a cycle is formed when an edge e  let say  an edge e  u comma v is included and we have to do this quickly  hindi  when will be a  when will a cycle be formed ? i am trying to include this edge  u  v  hindi  when u and v are already connected  hindi  cycle is formed if and only if u and v are already connected yes  already connected   hindi  u and v are in the same connected component connected component or component ?  hindi  so we are  what we are going to do is  we are going to maintain the collection of components so note that  so  what is happening ? in kruskal ? s algorithm  suppose  these were my vertices  hindi  does not matter this is or no matter  what 3 edges i pick  it will always have n minus 3 connected component  hindi  3 edges which form of a forest  then the number of trees in the forest see  if i have a forest containing some k edges  then how many trees are there in my forest ? n minus k  this you can prove very easily basically   hindi  i combine  2 connected components into 1 connected component that is the way you have to think of  i combine 2 connected components into 1 connected component  hindi  so  the number of connected components reduces by 1 every time you take an edge  hindi  so   hindi  at each step  hindi  with every edge we include so  what we are going to do is  to maintain the connected component we have at this stage  how many connected component have at this stage ? 4 i am going to maintain them as 4 sets of vertices what do i mean by that ? let me give these vertices names  a  b  c  d  e  f  g  h so  i am going to have 4 set  abc is 1 set  fgh is another  d is the third and e is the fourth these are the 4 sets that i have at this point i am just interested in the sets of vertices the sets of vertices in 1 connected component they form 1 set  as you can see  these sets are all disjoint and there union is the universe  they form a partition of the vertices sets now  what is it that happens at each step ? when i try to include an edge  hindi  what do i have to check ?  hindi  so  this is the data structure we have to maintain  refer slide time  57  39  we are going to discuss it in more detail in next class you just keep this in mind and we will see how do to this data structure and what time does it give us for kruskal ? s algorithm so  with that we are going to end today ? s discussion we are going to continue the discussion on this data structure in next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 32 first class we looked at the kruskal ? s algorithm for computing minimum spanning trees we were  we saw what the algorithm was and what we were doing was  to complete algorithm  we have to figure out  how to detect if there is a cycle that gets formed when we add an edge into the current set of edges that we have already went by so  if you recall what we have said was that we would try and maintain the collection of connected components so  i am going to revise part of that but we are going to today  look at the data structure  for being to do that  that is called the union fine data structure so  let see  where we were as far as kruskal ? s algorithm was considered we said  i have already picked a set of edges  refer slide time  3  27  recall that the set of edges would always form a forest  it would be a collection of trees there could be no cycle that is already existing so  these are the set of edges that have already been picked in krukal ? s algorithm now  when i am trying to add a new edge  i have to check if it forms a cycle or not suppose  this is the new edge being added  this forms a cycle and 1 way of detecting whether a certain edge would form of a cycle or not  is to check  if its 2 end points lie in the same tree of this forest the tree is the same as the connected component and so  it suffices to check whether the 2 end points of an edge  line the same connected component this is where we were  at the last class so  we have to somehow maintain our collection of connected components so  as the algorithm proceeds  we have discussed this in the last class  in number of connected component reduces by 1 with every step initially  we started off with n connected components initially  we had n connected component and eventually  finally  we have only  how many connected component will we have ? 1 this is how the algorithm proceeds so  i am going to abstract this problem out and capture it as a problem on maintaining a collection of disjoint sets so  what is the setting now ? i have a universe of elements let say  i have e1 e2 en let us say  these are n elements in my universe initially  each of these elements is a set in itself now  the following operation  so  this is a collection of disjoint sets that i have initially  i have the collection of disjoint sets  at each stage i am going to have a collection of disjoints so  what we are trying to do is to maintain a collection of disjoint sets under the operations of  let us see  what are the operations  we are doing  going to be doing on the disjoint sets so  what do these elements correspond to  in the case of kruskal ? s algorithm ? but  what are they initially ? initially  these e1 e2  what are e1 e2 ? these would be the vertices  the initial vertices now  what are the operations that we have to do on this collection of disjoint sets ? 1 operation is union  the operation of union has to be down when i have 1 connected component  i have another connected component and the edge that i add  runs between these 2 connected components then  the resulting thing would be  this entire thing could be  1 connected component and it should get reflected here  by taking the union of the corresponding sets so  i have to do an operation of union that is 1 operation under which i have to maintain this collection of disjoint sets so  what do i mean by that ? suppose  this collection have e1 e3 e7 in it and this  sorry  this set has e1 e3 e7 in it  this set has e2 e5 and e9  then after the union  i should not have these 2 sets in my collection but these 2 sets of the collection should get replaced by 1 set which is e1 e2 e3 e5 e7 and e9 the other operation that i have to do is  so  given an edge  i have to look at the 2 end points of the edge and determine if they belong to the same connected component or not so  the end points of the edge would be the 2 elements and i have to check given to 2 elements  whether the line same set or not so  we will call that an operation of find so  what does find do ? let say  find takes as parameters 2 elements  x and y and returns true  if x comma y are in the same set what should it return ? well  this is not a completed description of find if x and y are not in the same set  what should find return ? it should return the 2 sets in which those 2 elements lie why ? why should it return the 2 sets ? because  then we need to do the union on those 2 sets  exactly so  union should take as parameters  2 sets  let say s1 and s2 and should take the union this is what we require of our data structure  refer slide time  7  39  so  this is not an accurate description of find  i will have to modify it but you understand the need for returning the sets in which the 2 elements lie so  instead of find x comma y  let me have just an operation  called find x  returns the set in which x lies there is a unique set in which x lies  because our collection of sets is always a partition of universe so  there will be a unique set and you want to return that set then how will we implement this operation ? we will do find x  we will do find y  if the 2 sets are the same then we will conclude that they are forming a cycle  if those 2 sets are different  then you would take the union of those 2 sets yes  everyone following ? so  if i were to write down kruskal ? s algorithm now  it would look like this so  with this  assuming that these 2 operations exist  it would look something like this  refer slide time  8  22  so  what were the steps of kruskal ? s algorithm  first step ? sort the edges sort the edges in increasing order of length let say  this ordering is e1 e2 please do not confuse between this e and the element e that i had in the previous slide this e corresponds to edges and the previous e is element so  keep these separate now  what should i do ? for i equal to 1 to m do i pick an edge  what is the edge ? ei  i am considering an edge ei so  let ei equal to u comma v which means u and v are 2 end points of the edge ei what is it that i have to do ? if find u equals find v  then it forms a cycle then  we do not have to do so  i should really do  not equal if find u is not equal to find v  then  t is t union ei so  i should have some t and initialised to null and what else should i do ? union  find u  find v of course  i need to initialize this collection of disjoint sets so  i would have  when i create this collection of disjoint sets  it will get initialized to  what will it get initialized to ? singleton  so  each element in the collection would be singleton vertex so  this would be what the procedure will look like now we need to understand  what kind of data structure to keep for  to find and what kind of a data structure to keep for maintaining the collection of disjoint sets  so that these operations can be done very quickly how many times do we do the union operation ? how many times do we do the find operation ? number of unions  because  every time i do an union  i include an edge into my tree how many edges can be there in my tree ? exactly  n minus 1 so  i will have exactly  n minus 1 how many finds will i have ? for every edge i consider  i have to do 2 finds in the worst case  how many edges will i consider ? all the m edges  no more so  number of finds is less than or equal to m let us make it not equal to 2 m  refer slide time  12  17  i have said  for i equals 1 to m but  you know  you can always break out of this procedure  the moment you form a tree so  if you form a tree before  you can break out of this procedure  of this for loop so  you will keep it less than or equal to 2 m so  what will be the total running time of this procedure then ? if this operation ; let say takes u times and this takes f time  then what is the total running time ? anyone ? this step will take m log  m time  plus u times n  plus  m times f so now  we have to find out a good data structure by good view  mean  which would do the u and which will have the small u and small f is everyone comfortable with this ?  refer slide time  13  17  are there any questions to this point ? can someone suggest a data structure to me ? how will we maintain this collection of disjoint sets ? linked list  let say  liked list you are at the end of the course  but  you can not think beyond liked list so  how will we have ? we will have as many linked list as the number of sets  is the qutei so  1 linked list for each set no  let us complete this first how much time union take and how much time did find take ? union can be done in constant time  hindi  so  let say  we keep track of the front and the end of each liked list if we do that  then i can combine 2 linked lists in constant time union will not take too much time but  how much time did find take ? order size of the liked list  which in the worst case could be end now  is that good ? we were to do this  we will take m  n time which is too large we are looking for the time complexity or something like  n log m if we looking for something like  n log m  this quantity should be no more than log m and this quantity should also be no more than log m we can permit it to be as large as log m so  this is not too good at data structure someone had another idea what was your idea ? a tree ? what will you do with the tree ? how will you use a tree ? heap ? what will you do with a heap ? how much time does it take to merge 2 heaps ? order n ? height of the heap  why ? why does it take  if i have 2 heaps  why does it take order h time to merge them ? order smaller  no number of elements in the smaller heap  but that could be as large as n by 2 what else ? so  we will have a new data structure ? and what will a new data structure be ? the sets  i will just show this thing to you and then you will understand what is happening  refer slide time  16  32  so suppose  my universe was a  b  c  d  e  f  6 elements  simple so initially  recall that my  what are the sets in my collection ? the singletons  a  b  c  d  e  f so  i have a  i have b  i have 1 node for each of these 6 sets now  suppose you say  union  the set containing a  so  you will say something like  union find a comma  find b the set containing a and the set containing b so  what i am going to do is to make 1 of them  so  each of these nodes has only 1 point ? or a reference so  it has a data field and 1 reference field so  i will make 1 of these guys point to the other so  at the next step i will have  when after i do this  this is what my collection looks like these of course  remain like as they are  hindi  suppose  you were to say the same thing  union  find a comma find c when i say find a  i will start from a and keep going up  till i head the root so  this is now the root how do i know it is the root ? because  its pointer points to itself or it is null or whatever yes  when we do the union  you will understand this  you know as  as we proceed so  this is what the trees look like so  each one of them is a tree right now  this tree has only 1 node in it but  this tree has 2 nodes in it and now the pointers are going up you just have parent pointer ? when i say find a  i will start from a and keep going up the tree till i reach a node  let say   hindi  parent point is null or it is pointing back to itself i think at that point  i know it is a root and so  this says that find a  that the element a  is in the set whose root or in which b is when i come to b  this is the element  this is the set in which  what we are doing is that for each set  how do we represent a set ? so  each set is represented by 1 of the elements in a set which is in this representation  it will be the root of the set so in some sense  all the element of the set  elect a leader and this is the leader of that set so  a and b are the only 2 elements of the set and the leader is b so  when i say find a  it return to me  reference to this node which says that this is the root of the set to which  in which element a lies when i say find b  what will it return ? the same thing and then i can compare those 2 and can determine that they are in the same set or not so  what find a  find b returns are the roots of the corresponding trees you will understand this as you proceed  refer slide time  21  06  what union does is  it takes the root of these 2 trees and links them up and makes 1 point to be other for instance  here  i might decide to make b point to c in which case  my new representations would look like this now  if i were to do a find a  what will be returned when i do the find a ? a reference to c  a reference to this node and when i do the find b  what is returned ? a reference to the same node so  i can compare these two  i can return c or i can return a reference actually  it is best to return a reference because then that can be used by the union operation what do you mean ? c was not alone ? if c was not alone  i understand what you mean  if c was not alone we will come to when c was not alone so  all you are doing is  taking the roots and merging them so suppose  at this point i did another operation which was union  find d find e so  what will i do ? i will link up the roots for d and e  refer slide time  21  42  so  let say  i decide to make d point to e now as you can see  d and e are not alone if i decide to do an operation like  let me keep this picture there and if i do  let say  union or let me write it down here union  find a comma find d then  what does find a return ? it returns a pointer to c  d returns a pointer to e i need to link up these 2 nodes so  i can make c point to e or make e point to c  whichever i please let say  i decide to make c point to e this is what i would get there and of course  f would be sitting on its own is everyone understands  what the procedure is ? you understand what the find operation is ? what does find operation do ? it starts from the element and keeps tracing the pointers up  till it hits the roots exactly  so  you have a list of vertices when i have an edge  i have its 2 end points  i have the vertices and from that vertex list  i must have the reference to this node recall  you have a data structure for your graph in which you have an array suppose  i had an adjacency list of presentation  so this array would contain my list of vertices i could have another reference from here to this node here  for every  so  this was node vertex b  try to have another reference from here to here  so that i can access the state this is just referring to this particular node and so this will always remain the same so  what is the problem with this implementation ? how much time does union take ? so  union takes now as input  references of root nodes and so  all it as to do is to modify 1 pointer  1 reference to point to the other  to refer to the other so  union takes order 1 time but  how much time does find takes ? find could take a lot of time because it might go through a very long ways to reach the root  in the worst case can you construct a sequence of unions in which this would happen ? write at the side first to merge a b  then a c  then a d  then a e  and a f and if you were to doing the union in this order then  things would go back  refer slide time  25  38  we have to do the unions in a more clever manner find ? no  we will do the union in a clever manner so recall that when we were linking elements  we had that option  either link make 1 point to the other or point  make the other point to the first so now  we will exploit that so  i am going to use a rule called union by rank in which if i have 2 trees and suppose  this has n1 nodes in it and this has n2 nodes in it then  i will make the lighter tree point to the heavier one so this  without loss of generality  let say  n1 less than n2 then  i will make this point to that we will make the lighter point to the heavier now  you will not have a this kind of a scenario in which you know  if you have this  let say  6 elements ; first you made this point to this and then  when you are trying to combine this and this  you will not make this point to this anymore what will happen now ? you will make this guy point to this and now  this tree has 3 nodes in it so  if this combines this  you will make this point to this and this point to this and this point to this so that now  what is the height of this tree that i get ? 1 only  and so  find will take very little time  hindi  so  we have to see that if we use this root  what can be the height of the tree in the worst case how high the tree become ? how high can the tree become if we use this root ?  refer slide time  28  24  anyone ? login  why ? you are trying to construct the worst case but that need not be the way we do things that might not to be worst case how will you argue that this rule of union by rank will lead to trees which have height ? so  what is the claim we want to make ? no  not the height is minimum a tree with n1 or n  n1 nodes let say  has height less than or equal to log of n1 suppose  i have to make  prove this claim  at tree with n1 nodes  set any point if i have a tree with n1 nodes in it  it has height at most log of n1  hindi  by induction good so  let us use induction i am not going to write down the proof formally  but i will tell you what the procedure is so  i am combining 2 trees  one  n1 nodes  the other  n2 nodes without loss of generality  let us say  n1 is less than or equal to n2 let us assume that the induction hypothesis is true till this stage of my procedure that means  hindi  height is less than or equal to log of n1 and  hindi  is less than or equal to log of n2  hindi  everyone with me ? now  we have to show  as a consequence of this i will get a new tree with how many nodes in it ? n1 plus n2 could be the number of nodes in the new tree so  i have to argue that its height is no more than log of n1 plus n2 let see whether that is true so  what are the 2 cases ? n1 strictly less than n2 what will be the height ? no  what will be the height ? the height could be  so  height of resulting tree is either the height of this tree  so we have done this it is either the height of this tree or it is the height of this tree plus 1 so  height of resulting tree  hindi  height of resulting tree is less than or equal to max of h2 comma h1 plus 1 it can take a value of h1 plus 1 also  hindi  the height of resulting tree fine  equals max of h2 fine  hindi  now let see  this is the height of the resulting tree if this value equals h2  there are 2 possibilities  either this value equal to h2  but h2 less than log of n2 which is less than log of n1 plus n2 the other possibility  as this quantity equals h1 plus 1 which is less than or equal to log of n1 plus 1 which is equal to log of 2 times n1 which is less than or equal to log of n1 plus n2  because n2 is greater than or equal to n1 actually  we have not used the fact that n1 is strictly less than n2 have we used that fact ? so  it will become equal  but that is okay so  i do not really need this what i was said ? one of the trees is  has lesser or equal to number of nodes than the other  if they are equal  actually you can connect it in any way so  i made 1 point to the other this  by induction hypothesis this height is at most log of n1  this is height at most log of n2 what is the height of the resulting tree ? it is either the height of this tree or it is height of this tree plus the 1 if it is the height of this tree then  it is log of n2 which is less than or equal to log of n1 plus n2 if it is this tree plus 1  height of this tree plus 1  then it is log of n1 plus 1 which is log of  the same as log of 2 times n1 which is less than or equal to log of n1 plus n2  because n2 is larger than n1 this is the base case 2 when n equals 1  the height becomes 0 let us define the tree of 0 with the only 1 node  as having a height zero  hindi  if n equals 2  this becomes 1 which is okay when we have 2 nodes in the tree  it has height 1 then  by definition  hindi  so now  what are we saying ? if this is  if the tree has only 1 node in it  this is height 0 if this is the case  that is height 1 so  i am counting the number of edges on the longest path from the  from one of the leaves to the root  counting the number of edges and not the number of nodes everyone with me  so  what does this show ? is this the complete proof ? what am i doing in induction on ? number of nodes in the tree  so  i am assuming that the statement is true for all nodes of a certain number  less than a certain number  i can say  it is true for this when i link this and i get a tree with larger number of nodes  it will continue to be true  refer slide time  36  14  great  this is called union by rank rank meaning  the rank is the number of nodes in the tree you can also do a union by height as in  you can keep the  make the shallow tree point to the tree with larger height that could also work let see why ? what am i doing now ? this is a tree of height h1  this is tree of height h2 h1 less than or equal to h2 i do this  i make root of h1 point to the root of h2 i am just showing you 2 alternative ways to do the same thing now  what should my induction statement will be ? how will i proof  what is the claim i should try to make ? what holds true ? so  a tree of height h ; what should i try and proof ? a tree of height h has at least  2 to the h nodes this is converse of that claim there we were talking of a tree with so many nodes of height at least log of h here  if the height is h  then it has at least 2 to the h at most  it has height at most log of n1  here we would write that the tree of height h has a large number of nodes in it  at least  2 to 3 h so  that means that you can never have a tree of height more than log of n  because if the height of the tree was more than log of n  then it will have more than n nodes in it it is not possible because  there is only n node in the graph to be ? in a collection to be ? so  that will place a log in bound on the height of any tree how will we prove this ? once again by induction  suppose  claim is true for all trees of height up to a cretin number and then when i do this linking  the resulting tree has height h2 max of h2 comma h1 plus 1 once again h1 plus 1 will occur only if h1 equals h2 now  this is the height of the new tree let say  h is the height of the new tree  this is this why is this h  why is the number of nodes  now  what is the number of nodes in the new tree ? equals n1 plus n2 ; number of nodes in this tree plus the number of nodes in this tree now  we know that n1 is at least 2 to the h1  n2 is 2 to the h2 so  this quantity is greater than or equal to the 2 to the h2 that is one way of thinking of it and since  h2 is more than h1  this is also greater than or equal to 2 to the h1 plus 2 to the h1 which is equal to 2 to the h1 plus 1 so  the number of nodes is grater than or equal to max of 2 to the h2 comma 2 to the h1 plus 1 i can also write it as  max of this is 2 to the max of h2 comma h1 plus 1 which is 2 to the h  hindi  proofs are very similar  if you look at it carefully you are just turning them around  both of these schemes can be used to do the union what do they both ensure ? why does this ensure that the height is more than  no more than log n ? because  if a tree has a height more than log n  hindi  2 to the  a tree of height log n will have 2 to the log n which has n node in it already if it has height more than login n  if it will have more than n nodes  which is not possible  refer slide time  41  47  so  from this argument  no tree will have height more than log n and this argument  we have already said directly that no tree has height more than log n  log of the number of nodes in the tree since the maximum number of nodes in any tree is at most n  no tree has height node the log n so now  given this  how much time does union takes ? constant time ? yes  so something has to be done more and what is it that has to be done ? in the root node  we have to keep the track of  either the height or the number of nodes  whichever it is and  this is an information which is not difficult to maintain because  when i do an union  this value is updated to either the height  if you maintain the height it becomes the max or if you are maintaining the number of nodes  you just add this quantity that so  how much time does union take now ? constant time because  you just have to update this variable and do this reference update how much time does find take now ? i start from a node and keep moving up the tree since the height of the tree is never more than log n  find takes no more than log n time total time taken by kruskal ? s algorithm then becomes  time for sorting  m log n plus  how many unions did we say we need ? at most n unions  every time i include an edge  i need 1 union since  each one of them is taking constant time  this is just order replay how many finds do i need ? for every edge  i may need 2 finds so  m times log n what is this ? m log n  hindi  what is log m ?  hindi  n square ?  hindi  value is 2 log n and minimum value  hindi  in the connected graph ? log of n so  log m and log n are the same things log m is theta log n they are in the constant so  whether you write log n here or log m here  it is immaterial they are the same quantities  refer slide time  45  26  so  i will  the next thing i want to do is to show you 1 way of improving the union find data structure we saw the method  one way so  this data structure we said if you do union by rank then the time required for find improves it becomes order log n you can further improve the time required for find by using the technique called path compression whose analysis  we are not going to do in this class but  you will do learn in your algorithms course what is the technique ? so  it is just the following you have your tree in which you are doing a find  hindi  so  you went up the tree like this to do this find now the question is  why do not we do something at this point  so as to improve the performance of future finds ? you might have to find this node again ? yes  we will modify these things we will make this parent pointer  point straight to the root and not just this guy  everyone on this path why are we doing this ? anyone ? because now  this guys become closer to the roots what is  i am not drawing rest of the tree but now  you can see that this node is this  this  let me put a dot here this guy  connected to just 1 link to the root let me put a cross here and this last 1  without anything is this of course  there are sub trees hanging down here they will continue to hang down here  because there could be other nodes pointing towards this so they will continue to but when i later  so  what are we doing as a consequence of this ? we are bringing the nodes closer to the root  thereby  reducing the height of the tree and that reduces the number of  the time required to a find no  the root is not changed to this tree the root of this tree remains as before union by height  you are worried about if the union procedure requires height the root of this tree will point to the root of other tree no  these will not change then  these will not change then  we are not going to change these now if i take the union of this with someone else that is okay i did that  i am not going to change this pointer so  if you are opting this procedure  then union for the union operation  you should not work with height but  with number of nodes  you understand why ? because we are changing the height of the tree by doing this we might be changing it in a manner which might be hard to recompute after i do this compression  may be this was a node  there was leaf here which was the farthest from the root when i change this  the height of the changes  but how do i now compute the new height of the tree in constant time ? very difficult  so we use the union by number of nodes that is the procedure we are going to use so  the metric will be which tree has lesser number of nodes the tree with lesser number of nodes will be made to point to the tree with larger number of nodes or the root of the tree with less than number of nodes will be made to point to the tree  the root of the tree with larger number of nodes everyone follows this ? questions ? what we doing in ? what are we doing in path compression ? what we are doing in path compression is that  we say  when i am searching for this node  when i doing a find operation on this node  in any case i am going to travel all the way up i am going to traverse this link and i am going to traverse this link and this link and this link why do not i do something now  which will make future easier for me ? future finds easier  lesser time  so  what i do is  that once i do this  i will may be make another pass of this and now change the pointers to directly point to there we do not know the root  we do not know when to make the  no  but when i am doing the find  i need to know where the root is that is why i am doing a find in the first place how do i know  the root point there only when i reach the root  i could know where the  what the root reference is so  i need to make a second path to update every time we do a find  we will update the pointer then there is no need so  for here instance i did not change this this is no point  what does it mean to change the pointed this this we will change because  that gives us  the next time the picture is this  we will look at this picture and decide what to change and what not to so  again when i go throw here  what is the point in changing it  because it is already pointing the ? this becomes the picture  i do not have this picture any more in the  the next type how do we directly go to the nodes in this tree ? we keep a reference for every node  when i am keeping the node in this union find data structure  the node corresponds to a vertex of my graph i do not just create the union find data structure as the standalone entity i have to link it up with my graph somehow for every vertex  i have 1 node here  i keep a kind of cross reference from the vertex in my linked list data structure or the adjutancy list data structure for the  in which i have the vertices  i would have the reference to the corresponding node in the union find data structure so that when i have to reach a particular vertex  i can follow that reference and find out which connected component that vertex belongs to  hindi  so  with that we are going to end today ? s class on the union find data structure and we are going to discuss another algorithm for computing minimum spanning trees in the next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 33 in the last class we looked at the union find data structure that was a data structure to maintain a collection of disjoint sets  under the operations of union that was the operations we were doing in the sets  that was the operation which were modifying the sets or modifying the collection and the find operation was just to identify  given an element  which set it belongs to we used this  we needed this data structure to implement the kruskal ? s algorithm kruskal ? s algorithm was the first algorithm we looked at for computing a minimum spanning tree in a graph it was an example of the greedy algorithm today  we are going to look at another algorithm for computing the minimum spanning tree in a graph this one is due to prim and that is what we are going to discuss today so  let me define the notion of a cut in a graph first  for you so  recall that we are talking of undirected graph a spanning tree  the notion of a spanning tree is defined only for an undirected graph for a directed graph  there are different notions we do not say spanning tree in a directed graph it is only an undirected graph we are talking about here so  give you an undirected graph  a cut  let say  this is graph g and a cut in graph g is a partition of the vertex set into 2 parts what does it mean ? let me partition  break vertex into 2 pieces so let say  1 piece is this and the other is remaining because  it is the partition this way of splitting would define a cut so  if for an instance  i had vertices  a  b  c  d  e so  then the first cut i am considering is a  b one side and c  d  e on the other side there could be many other cuts possible  i could have a  c and d on one side and b and e on the other side or i could have only 1 vertex let say  c an one side and the other 4 on the  the remaining 4 on the other side these are all examples of cuts in the graph how many cuts can there be in the graph ? 2 to the power n ? 2 to the n or something ? 2 to the power n minus 1 because  this partition is the same as saying  c d e and a b how did you come out with the number 2 to the n ? every element  for every element  there are 2 choices  either left or right so  there are 2 to the n possibilities but then  but then  we are repeating each possibility is repeated twice once we will say  a b go on the left side  c d e go on the right side and the other time we will say  c d e go on the left side  a b goes the right side but the partition is the same so  that is why number of different cuts  2 to the n minus 1  minus 1 also okay  then null ? you are talking of the null  hindi  sometimes  what we do is when we say a cut  so cut is really a partition of vertex a but i sometimes would also say  these edges which are going from 1 side to the other side are called the edges in the cut so  these edges could be called the edges in the cut  edges in the cut or edges of the cut  whatever you understand which edges i am talking about ? edges which have 1 end point in 1 side of the partition and the other end point in the other side of the partition so  you understand what a cut is you need this notion and how to we use this notion ?  refer slide time  5  53  suppose  i take a cut of my graph  some cut in the graph  s and i will denote other point  other side by s complement or v minus s where v is the vertex set so  i have a graph g s v  the vertex set and e is the set of edges so  s is the set on one side and the remaining is the set on other side now  let me look at all the edges which are in the cut recall  we are trying to compute the minimum spanning tree so  i am now going to be taking of a particular property of the minimum spanning tree so let me take this cut and let me look at the edges in the cut and let us look at their lengths of these edges so  may be  this edge is length 2  this edge is 4  this is length 3  this is length 7 i am going to be assuming that all the edge lengths are distinct this is just to ease all my arguments  to simplify my arguments all the algorithms  everything works even when edge lengths are not necessarily distinct so  just to simplify my presentation here that i am going to assume edge lengths are distinct now  the claim is that  so recall  when the edge lengths are distinct  there is a unique minimum spanning tree we have discussed this before  there is 1 and only 1 minimum spanning tree now  the claim is that this edge which has length 2 will be a part of that minimum spanning tree let me write down the claim more formally  for any cut  any cut s  s complement ; the minimum edge in the cut belongs to the mst  hindi  2 to the n minus 1 different cuts  refer slide time  8  20   hindi  1 ? for instance  hindi  let us make a tree such that there will be both of these edges will be part of the minimum spanning tree or part of the minimum spanning tree  hindi  both the edges are part of the minimum spanning tree i could have my edge length so that this was my minimum spanning tree i could choose my edge length so that this is the minimum spanning tree so  it is not necessary that only  for any cut  there is only 1 edge which is the part of minimum spanning tree  there could be more than 1 edge which could be a part of minimum spanning tree  refer slide time  9  26  but  all we are claiming is that the minimum edge in the cut will belong to the minimum spanning tree  hindi  why ? what is the proof ? so  proof is by contradiction  hindi  you are saying that this is the minimum spanning tree but  that tree does not contain this edge so  let t be a mst mst is short for minimum spanning tree t is an mst which does not contain edge  hindi  does not contain edge  hindi  which does not contain edge e so  what now ? what will i do ? i will add e to the tree  add e to t what will happen ? cycle will be formed why will a cycle be formed ? because  these 2 vertices are already connected  these 2 vertices are already connected in the tree so  there is some path going from this vertex to this vertex any path that goes from this vertex to this vertex  from u to v which connects u and v has to use 1 of the edges of the cut think of this as  this is the river in between  this is 1 end  this is the other end if you have to go from this end to other end  you have to use 1 of these bridges  no other alternative so  it has to use 1 of these edges which means that the cycle that gets formed has to use 1 of these edges at least but  all these edges has length more than 2 so  what will i do ? same thing  i will remove this edge from the cycle and at that  this will reduce the length of the tree so  let me write that down so  we add e to t  let me continue  refer slide time  11  59  so  after you add e to t  so let me addition of e to t forms a cycle say  capital c c contains at least 1 edge of the cut yes or no ? at least  1 edge of the cut  this implies c contains at least 2 ? it will contain an odd number of edges added c  at least 1 edge  let me write down other than e  good  hindi  e will have to be part of the cycle it is because of the addition of e that cycle got formed there was no cycle earlier  e has to be part of the cycle so  c contains at least 1 edge of the cut other than edge e so  this implies c contains on edge of length more than the length of e c contains an edge of length more than the length of e they can be greater than ? i just have to show that there is some edge in the cycle which has length more than e no  we created the cycle  we brought in e  now how do we want to reduce the cost of the tree ? by removing some other edge whose length is larger than e by removing this edge from t union e  we get a smaller tree that is a contradiction  because we assumed that t was a minimum spanning tree  hindi  this we have discussed before that  from a cycle i can remove the any edge and it will remain a spanning tree we can also remove that  i just have to show you that there is some edge in the cycle which can be removed to just  i have to just eye with a contradiction i am just arriving at a contradiction here  this is a mind game we are not actually removing any thing  i am just proving a structural property i am saying  in any cut the minimum edge has to be a part of minimum spanning tree i do not ever sit down and remove any thing there is no algorithm does that this is just a proof  proving this statement  hindi  how do know that 1 of the edges of the cycle has length more than e ? because  we can only argue for the edges of the cut  for then we know for sure that they are all more than e that is all  nothing more now  how are we going to use this claim ?  refer slide time  16  57  so  prim ? s algorithm exploits this simple fact  that  if you take any cut  the minimum edge in the cut will be part of the minimum spanning tree  always prim ? s algorithm is an algorithm which essentially is built around this simple fact  hindi  so  let us understand what prim ? s algorithm is let say this were my  this were my  what ? graph and let us give every edge length so  i will just rapidly put down edge lengths  1  2  3  4  5  6  7  8  9  10  11  12  say  i missed out one  13 now  how does prim ? s algorithm work ? first  we start from some vertex and we call this the root vertex now  the first partition that i am considering  the first cut i am considering is the root verses everyone else root of 1 side and everyone else on the other side so  which edge has to be part of the cut ? the edge of length 1  so  i will include this into my cut  into my which edge has to be part of the minimum spanning tree  edge of length of length1 and i will include it into my 3 now  what is the cut i am going to consider ? this and this  so i am going to  this is going to 1 side of the cut  this is going to be one side of the cut and the other side of the cut is going to be all the other vertices so  which are the edges which are part of the cut ? 9  8  2  3  11  so which is the smallest ? 2  so we know for a fact that this has to be there in the minimum spanning tree  this included  hindi  what is the cut i am going to consider ? these 3 vertices on 1 side and all the other on other side  so side let me extend it like that  can everyone see this ? this is 1 side of the cut and all the other vertices are on the other side of the cut so now  which are the edges in the cut ? 9  8  7  5  13  11  3 is not in the cut  because both end points of 3 are on the same side so  the smallest of these is 5 so  this gets included now  i am going to  you can now understand how i am going to extend it this becomes my  1 side of the cut and the remaining becomes the other side of the cut  4 is in edge  3 is some kind of a gone  so 9  8  6  4  no  not 10 ? 13 and 11  hindi  4  hindi   refer slide time  21  20  which are the edges in the cut ? 11  13  10  6  7  8  9 ; so  six is the smallest  8 gets included and now  my set becomes this it is time  we finish  because it is getting very messy so  which are the edges in the cut now ? is 8 in the cut ? no  it looks like it is in the cut  but it is not because  both its end points are in the same side so  it is 9  10  11  13 also 12  of course so  9  10  11  12  13 so  9 ; 12 is not in the cut any more so  it is only 10  11  and 13 are the options  10 is the smallest and we that we are done because  all the vertices are now included everyone understands the procedure  it is very simple we have done the proof effectively not effectively  we have done the proof because  what did we say ? we proved this claim that the minimum edge across the cut has to be part of the minimum spanning tree and that is the edge we are picking at every point so  this is the minimum spanning tree  refer slide time  22  33  you will get the same tree  since this is unique  i assumed edge lengths are distinct  you will get the same tree when if you were to run the kruskal ? s algorithm everyone follows this ? so  i am not going to write down the pseudo code for this  but you understand how the algorithm works very simple  so the key idea is that we have  so let us try and see how you would implement this algorithm ? so  what is it that you have to maintain ? of course  you have a data structure for the graph now  what it  what is the operation you have to do at each step ? add a vertex to a set ? so at some  at any point you have the following ; this is 1 side of the cut  your root is here let me call this set as s so  the set is  this is going to be the set on 1 side of the cut  as in the vertices we have already reached  so to say  from the root so  the root is always the part of the set s and the remaining vertices  s complement of v minus s i have to maintain this collection of vertices which are on 1 side this can be done very easily by keeping 1 bit with every vertex if the bit is 1 then that means  let say it is on the s side  if it is 0  it is on the s complement side that is very simple now  what is it that i have to do at each step ? i have to find out  i have to look at all of these edges and to find the minimum how and ? i am going to do this ?  hindi  you look at all of this vertices  you look at their adjacent edges  for each edge you see whether the other end point is in s or not if it is not in s then you look at its length and you look at all these edges and find the minimum so  how much does the time take ? how much time does it take ? order  you are going to each vertex  looking at all its adjacent edges ; looking at all its adjacent edges  going to each vertex in s  looking at all its adjacent edges what is the maximum time it could take ? order m at each step and you have n such steps so  order m in time  hindi  i am not even writing it down because it is a very ?   refer slide time  24  56  so let us do  look at something clever what could be a clever way ? maintain a minimum ? let see  this is some idea  so  you are saying i have this set s  i have s complement and there is this vertex v  let us call it v i have a single this vertex out because this is the vertex which is now going to go from right to left  hndi  you have figure out minimum of all of these edges  you know the minimum of these edges in the cut now  what is going to happen ? v  let me draw it this way now  refer slide time  27  53  some edges are going to go from v to s  some edges go from v to s complement  there are of course  some edges which go from s to s complement now  right now  i know the minimum of these edges because v is the same this picture is the same as knowing the minimum of the edges when i move v from here to here  i want to find out the minimum of these edges what will i do ? compare the ? so i just  suppose i have kept track of the minimum of these  noting else let say that the minimum was 1  the minimum has to be an edge incident to this one  that you understand ? so  that is why we pick this one this is 1  this is 2  this is 5  this is 6 and this is 7 and then these are 8  9  3 let say now  the new minimum  earlier the minimum was 1 and now the new minimum is 2 if i just know the minimum  it is not going to useful so  you want me to keep the track of the second minimum also ? which does not go to ? but  what do i know about v as in  v something that i find out so  we know the minimum that is coming to this vertex so suppose  we keep the track of the minimum to each of the vertices in s complement insert v ? so  what he is saying is  but how to  what data structure should i use to keep these edges ? a heap ? min heap ? so  that could be 1 possibility i have a heap  does everyone know what a heap is ? so  heap is the data structure which will and which i can put some elements  each one of them has certain priority or certain key and it will give me  i can use an operation called delete min which will remove the minimum element  i can find out what the minimum element is in the heap in constant time  i can insert element into the heap  i can also remove element from the heap i can do all of these operations and except for find min  all operation take in log n time find min takes constant time everyone remembers at least this much so suppose  i were to keep a heap here  a heap which contains these edges  2  1  6  5  7 then  using find min i can find out what is the minimum edge that will  once i know the edge  i know the other end point of vertex  i know both the end points of the edge  i know which vertex i have to bring in when i have to bring in this vertex  i look at all the edges incident at this vertex the edges which are going in s  i have to remove them from this heap and the edges which are going from this vertex to vertices not in s  i have to add them into the heap but  let us keep it clean like  when we say that our heap is going to contain the edges of the cut  let it contain only the edges of the cut  because you are going to spend the same amount of time in any case we do not search in a heap  please remember  heap is a very bad data structure for searching so  how do you find out where the edge is in the heap ? once again the same thing  when you put some information related to the edge into the heap  you do not just put it and forget it  you keep a track of where the information is  where the particular node is we do not need to delete  but there is no harm in deleting also no  you can also delete from a heap why can not you delete from a heap ? so  there is some confusion here let me back up a little bit we need to  i think i need to show this delete operation to you again when we do or the other class we will do delete operation once again but take it from me  you can also delete from the heap in the same log n time of course  to delete you need to know where the element is  you are not searching for the element  you know where the element is and then you can delete from the heap in log n time so  that is what we are going to do when this element comes in  i am going to insert 3  9  and 8 and i am going to delete 1  6 and 5 and i know exactly where 1  6 and 5 are and this is how i will do the implementation so at any point  what does the heap contain ? exactly the edges of the cut  exactly those edges and noting else it is best to keep it clean so that you know what is happening now  how many operation are required on the heap ? what kind how many ?  refer slide time  32  29  so  let us look at the heap operations let me draw the picture again for you this is vertex v  it is coming in on this side so  these edges have to be removed these edges have to be added each remove and add takes log n time how much time am i spending ? degree times log n for ever vertex that i process so  degree of v times log n and then this has to be summed over all the vertices  because i will processes each vertex exactly once log n  number of elements in the heap  which could be m so  i should write log m number of elements in the heap which is the number of edges in the cut  could be as much as the number of edges all that it will ever may be that but it could be as large as then in the worst case we are decreasing  but you know those are so small  that it will not going ? even if you do a careful analysis  you will still get the some order this is what the total running time will be these are not the only operations ; i also what have to do 1 find min how many times do i have to do find min ? number of vertices time ; n times so   hindi  n into order 1  constant time  that is a small order time in this one what else we have to do ? what are the other operations you might have to do in the heap ? just insert and delete  and this operation  find mine so  everyone understands what the procedure could be now ? you start with your initial vertex  root and all the edges incident to the root will be your initial heap  will be the elements of initial heap then  you will do a find min that will tell you what vertex to include on that side then you are going to look at all the vertices adjacent to this vertex  all the edges that are adjacent to this vertex  beside  if you are to remove an edge or to add an edge  hindi  let say  i have an array s s in an array  s of v equals 1 if v belongs to s  0 otherwise  refer slide time  37  42  what is this s ? this s is the s side of the cut not visited  but reached ; all those vertices that have been reached so  this is 1 data structure we are going to have then  we are going to have a heap and let see what  so initially  i pick a vertex as the root and s of the that vertex root equals 1 and for all v  s of v equals 0 initially  everything this is my initialization only the root is on  so  initially everything is 0 and s of r is set 1 this is my root vertex now  what should i do ? i should insert the edges incident at the root into the heap so  what should i do ? for all e incident to r  do h that is my heap  dot insert e some such thing  i have to insert the edge into the heap so  everyone follows ?  hindi  so  hindi  while not  i would say not h dot empty  hindi  do now  what should i do ? i should find the minimum edge h dot find min equals let say  this is equal to  what will this return ? this will return in edge   hindi  and now what should do i with f now ?  hindi  i have to find the end point of f which is not in s let v be the end point of f such that s of v equals 0  hindi  for all e  e adjacent to v do what do i do ? for all e equals v comma w  hindi  if s w equals 0  hindi  then edge dot insert e  not w ;  hindi  else h dot  hindi  this is the spanning tree  minimum spanning tree  hindi  this entire thing is the part of the this loop clear to everyone ?  hindi  as you can see  all the effort is being spent in this step or not too much actually in this step how many times is this loop going to be executed ? n times ? how many times is this loop  the while loop is going to be executed ? n minus 1 or n times ? n minus 1 times why  because every time i execute this loop 1 vertex comes into the set as n vertices  hindi  so  this is getting executed n minus 1 time so  this statement is executed n minus 1 time but  this is again just a constant time operation so  this is not too much time  hindi  it is this way the most of the work is getting done for every if you are looking at all the vertices adjacent to the vertex v  degree and for each one of those vertices or edges  you are spending  doing either an insert or a delete log n  degree times log n  you have seen that before  summed over all vertices will be m log n there is a modification to this scheme that can also be done  refer slide time  45  58  in this modification  what you do is you have your set s  you have your set s complement each vertex in s complement has a number on it what is this number going to be ? let us look at all the edges going from this vertex to s suppose  these were the 3 edges going from vertex v to s  suppose these edge lengths are 3  4  and 7 then this vertex is going to have a number of 3 return ?  hindi  what are we going to do with these numbers ? we are going to create a heap now  my heap is a heap of vertices and not of edges so  this heap has 1 element for each vertex in s complement  hindi  what will be the minimum element in the heap ? it will be the vertex which has the minimum edge incident at it among all the edges in the cut so  it will be the vertex which has to go across  hindi  if i find the vertex the vertex which is sitting here at the top  the vertex with the minimum value  minimum label  let us call this labels  the vertex with the minimum label let say  it is this vertex  hindi  so  that means that the minimum edge going across this cut is 1 we are not keeping track of edges which are here  within here this vertex will only contain a label which is equal to the minimum of the edges which are going across the cut if there is a vertex which has no edge going across the cut  incident at it  hindi  so the minimum will tell me which is the minimum edge going across and that is the vertex that i have to move across and when i have to move across the vertex  what do i do ? how do i update information ? very simple  this is vertex v  hindi  all those in s bar which are adjacent to this vertex  hindi  the minimum edge that is coming to this vertex  so far is 4 but now  this edge is also coming to this vertex  because this vertex going on that side  hindi  so  that is the only things we have to do now so  what is the operation we have to do on the heap now ? update what ? update or decrease ? we will only decrease the label  decrease priority decrease priority is the operation we have to do decrease priority  hindi  no insert  no delete find min  of course and decrease priority  hindi  since  i have 4 or 5 minutes  let me write down the code for even this 1  hindi   refer slide time  52  23  so  once again i will  as in the previous case i will have my array s  i will do the same initialization ; for all vertex v  s v is initially 0 and s of r is 1 now remember  the heap is going to contain vertices in s complement h is going to contain vertices in s complement what should i put initially in my heap ? everything ? except r ? so for all v  s v is equal to 0 and let say  i do h dot insert v comma  hindi  distance from r  what does that mean ? what does that mean ? length of the edge from r ? infinity  hindi  h dot insert  hindi  no  no  everything is infinite only r is 0  hindi  while h is not empty  we will do something what will we do ? we will take the minimum let say  that is the vertex v i will take the vertex  hindi  for all w adjacent to v do if w is adjacent to v what should i do ? if s w equals 0  what does it mean ? w is on the s complement side then what should i do ? then i have to update its priority then if what should be the new  what is the option here ? if  we will need a label array somewhere if label of w  hindi  which is keeping track of all the labels  so if label w  hindi  is greater than length of v comma w then that means that this edge now  so what is it  what are they saying ?  hindi  then label w equals 6  sorry  equals length v w and h dot decease priority w comma label w  hindi  so  this is an alternative way of doing so  the same running time complexity you will check that yourself why is that ? because  once again we are looking at degree  for spending degree time at each vertex and degree times log n  because decrease priority also takes log n time  refer slide time  10  04  some over all vertices will come m log n and that is basically where most of the work is getting down  hindi  so with that i am going to end today ? s lecture so  we looked at prim ? s algorithm for computing minimum spanning trees and we saw 2 ways of implementing it data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 34 today we are going to be talking about the single source shortest path in the last class  we looked at the minimum spanning trees  prim ? s algorithm for computing minimum spanning trees this is a different problem and i will soon tell you what the problem is ? what we will  how you will find is that the algorithm is strikingly similar to prim ? s algorithm so  let see what is the problem is and what the algorithm in this problem does so  once again you are given a graph and today we can assume that the graph is directed so  this algorithm or this problem is well defined even for directed graph i am going to assume that the graph is directed let us take a graph  each edge has a length l  is a function from the edges to positive ? non negative  we can have the edges of length 0 also and let us give ? let say  this edge has length 2  this is length 3  this is length 3.1  this is length 7  this is length 0.5  this is length 1.1  this is length 5 these this could be a network of let say  the roads in a city so  each length so the length corresponds to the distance from this end point to this end point and let see these are 1 way roads i will  at the end of this class i will tell you other applications of this problem  the ton and tons of that what is the problem ? the problem is to find the shortest path let say  i want to go from this place s  s is also the  also called the source ; i want to go from s to t  t stands for termination  no destination why should t stand for destination ? you will figure out yourself  refer slide time  4  03  i want to go from s to t and clearly i would be interested in taking the shortest path how many different paths are there in this graph between s and t ? 4 only ? so  there is 1 path i go like this  then i go like this  then i come back here  that is 1 path the other path is i go like this  i come down  then i go like this and then i come down  this is a second option the third option is that i go like this  come down  i go straight  this is third option fourth option is that i go 2 and then 7 and then 1 other option is this  this and this is there 1 more ? 0.53 ? 3  i can not come back  i can not come back on this this is not a path because that this edge is directed in that manner it would have been a path if this was an undirected graph but not in this graph so actually  this graph has only 5 different paths so  it is a simple problem to compute the length of each path and take the minimum so  what is the length of this path ? 8.6 length of this ? 7.7 what is the length of this ? 2,3 8.1 this is 9  this is 8.6 if these were your gpa ? s  you would have preferred this but clearly  we are interested in the shortest path so  we would like to take this path  7.7 because it is the shortest path  shortest way to get to a destination  refer slide time  5  49  so  can we always do this thing  as in list out all the paths in the graph and just take whichever is the shortest  compute the length of each part and then compute the shortest ? not feasible ? why is not feasible ? not practical  why is not practical ? what is impractical about it ? high time complexity  why high time complexity ? why should there be  may be a graph on n vertices never has more than n paths then it is simple matter just list out all your n paths and just compute the length of ? if it has a cycle ? will you ever go along a cycle ? you are looking for a shortest path why would you want to cycle ? so  you can ignore ? not when you are listing out your paths you will try ignore cycles so  it is not feasible but that is because  the number of paths can be very large what do you mean by very large ? let us look at an example very large means exponentially varying this is my graph  edges are all directed left to right you get the idea  this is s and this is t sorry  there are more such diamonds  this is t if there are n vertices  how many such diamonds are there ? how many such diamonds are there if there are n vertices ? or let us do it the other way round if there are k such diamonds  then there are  how many vertices are there ? k diamonds would count as 3 k plus 1 just do your count correctly with each diamond i associate this vertex  this vertex and let say  the left end i can not associate both because ? so  it will be something like  3 k plus 1 vertex how many path are there between s and t ? 2 to the k  why ? because for each diamond  i can either take the top part or the less bottom part so  there are 2 options in each diamond so  i can have 1 path which just takes the top part always  1 path that takes  hindi  2 to the k different paths between s and t everyone follows ?  hindi  so  k is roughly n by 3 so  this is 2 to the n by 3 paths roughly how large is this number  hindi  2 to the 30 is the number of particles in this universe  hindi  that is the number of particles  roughly of course  no one has counted it  this is an estimate and 30 would be achieved for a graph of size 90  n equals 90 which is not a  which is a very small number  actually these graphs are typically huge when you are trying to compute shortest path system so  it does not make any sense to do this caliber  to follow such an approach to compute shortest path what should we do ? how can we solve this particular example ? can you think of a way of solving this example ? of course  there are lengths on all of these edges which i have not written down but you can imagine ; 0.5  1  1.1  0.2  0.3  0.4  0.8  0.5  i have just taken some arbitrary numbers what is it that you can do in this example to figure out shortest path between s and t ? compare  so what you are saying is here  i am going to see  1.5  if i take this term  thing and 1.3  if i take this one  so i will go bottom and so i would have reached this point now and then from here  i have an option of going 0.7 up or 1.3 down so  i will take this one  now i would have reached this point so  what you were essential saying is that to reach this destination  i will first have to get to this  then i will have to get to this  then i will have get to this and so on and on so  first i will have to go from here to here so  i can choose the  there are 2 options and let i can choose the better option of going from here to here and then  i have to go from here to here  there is no other possibility in this graph so  i can choose to better option and so on and on  refer slide time  12  12  now  this works in this example  not to always i have to get to this vertex and i am staring from here so  but i do not know which is the first vertex i should get to from here there is no such clear demarcation as in saying that if i have to go from here to here  i have to clearly go from this vertex to this vertex we can not say such a thing in ? so  if i have to go from here to here  i can not say  which is the first vertex have to get through may be  i have to go through this vertex  may be not  can not say everyone with me ? so  that is the part of the problem so any ideas  how will we do this ?  a to be must contain all shortest path but never part of the part if x is the part of the part from a to b then a to x is the part of the part form the to b then a to x also be a shortest path we can you some shortest heap improving the path  that is an important property of a shortest path so  this is 1 property we are going to be using so  what he saying is  suppose this is the shortest path from s to t  this is some path in the graph there are some intermediate vertices  i have not drawn let say  x is one of these vertices then the part of this path from s to x  that means this part of the path what i am referring to is  this part of the path  is the shortest path from s to x this is also the shortest path from s to x  refer slide time  16  22  why ? this is  we are saying  this is the shortest path from s to t why should it be also the shortest path from s to x ? x is any arbitrary vertex we are trying to arrive at the contradiction  you are saying suppose  there were a better path between s and x   hindi  so  then the claim is that the shortest path between s and t is this blue path from s to x followed by this green path from s to t and there was nothing particular about x any vertex any vertex on this path  the shortest path from s to that vertex is this path  hindi  by the way  the blue path  hindi  so  this is also a shortest path from s to x so  that is all you are saying  this is also  hindi  this part of the path is also a shortest path from s to x  hindi   refer slide time  17  44  so  what does this suggest ? this you know  this is giving you the following idea  hindi  we will end up having to compute the shortest path from s to many other vertices  all the vertices on the path so  what the algorithm we are going to discuss today is actually going to compute the shortest path from s to every vertex in the graph not just t  in fact  what we are going to do is  forget t first step of the algorithm  forget t and just compute the shortest path from s to every vertex of the graph once you computed the shortest path from s to every vertex the graph  you also got the shortest path s to t  hindi  so  we will compute the shortest path from s to every vertex in g  hindi  so  this problem is also called as single source shortest path problem why ? because  we are starting from 1 particular source and from that source we are computing the shortest path to every other vertex in the graph sometimes this would be abbreviated as triple s p  sssp  single source shortest path  refer slide time  19  43  now  given that we are not just interested in the shortest path from s to t but  the shortest path from s to every vertex in the graph let see  what we can say about this example we are interested in the shortest path from s to every vertex in the graph  hindi  and without using your head too much  which vertex  you know which vertex or the shortest path from s to which vertex is immediate ? adjacent ones ? minimum of the adjacent ones we know by looking at this  we know that the shortest path from s to this vertex is 0.5 but this  the shortest path from s to this vertex is not 2 so  we can not say that i know the shortest path from s to every adjacent vertex but we know  for a fact that the shortest path from s  so if these are adjacent edges or the 3 adjacent vertices and suppose these lengths were l1 l2 l3 let us assume l1 less than l2 less than l3  then i know for a fact that shortest path from s to v1 is l1 why ? why do i know this for a fact ? any other path  since it has to start from s  it has to take some edge out of s  either it takes this edge or this edge or this edge if it takes this edge then the length of the path will be at least l2 why ? because edge lengths are all positive why negative  hindi  has to be at least l2 because this part of the length  path is only non negative it can not be negative similarly   hindi  so the length of the path has to be at least l3 so  what does that mean ? the shortest path from s to v1 is l1  hindi  so just by looking at this i can say that  so i am going to use d to denote distance so  distance of vertex v1 i know is l1 what can i say about the distance of vertex v2 ? d of v2  what can i say about that ? greater than ? greater than l1 ? greater than l1 and less than or equal to l2 let us that put down and similarly distance of v3 is less than or equal to l3  hindi  we do not know the correct distance but  we have an upper bound on the actual distance this is an upper bound that this actual distance is only less than this value  refer slide time  23  44  so  what are you going to do now ? we know that actual distance of v1 now  how can we extend it ? how can we find out the  we know i have to find out the distance from s to every vertex  hindi   initially the directed length we have each vertex have vertices the shortest path have length of the shortest path found nay point if you at vertex found with visited vertex then compare to the are in the length already stored in the vertex to the some of the path   hindi  i am just taking an example and soon we will concretize this algorithm so  do not worry too much about it let say  v1 v2 v3  hindi  l1 l2 l3 edge lengths  hindi  let me now replace them by numbers because ? otherwise  we will keep having lots of ls so  let me put down numbers  0.7 and say this is 1.1 and this is 2.3 so  l1 is the smallest  let us put down more numbers  hindi  let us try and understand what i have done here ? just to separate this out so  we know this  let me circle it we know the correct distance of vertex v and the correct distance of vertex v1 is 0.7 now  looking at the picture can i say  so this is the only  you know there might be other edges and so on between theses vertices  i have not shown those edges i have just looked at the edges going out of v1 now and there are 5 edges  4 edges going out of v1 now  looking at these edges can i say for certain  what the shortest path to some other vertex ? i am not saying to this specific vertex what is the shortest path  i just want to know the correct shortest path to some 1 vertex no  you are going into details let us understand what the idea is let us look at vertex v2 or let us start by looking at vertex v3  hindi  we had seen that  hindi  we had seen only this edge and we had said that the distance of v3 from s is less than 2.3 that is what we had so far  it less than 2.3 now  can i say something better ? because  now i see this edge from v1 to v3  i know the shortest path from s to v1  what is it ? 0.7 i see that the length of this edge is 0.3 so  0.7 plus 0.3 means 1 so  i have found another path from s to v3 of length 1 i can say that the distance of v3 from s is less than or equal to 1 now  let us look at vertex v2 1  we will come to why it is exactly  1 step at a time all i will say is v3 has a  the distance of v3 from s is less than or equal to 1 that is all i can say at this point  till i bring in some additional argument so  the distance of v3 from s is less than equal to 1 that is all i can say what can i say about the distance of v2 from s ? well  i have found another path to v2 that is the path which goes from s to v1 and then follows the edge v1  v2 but this path  any such path is going to have a length of at least 1.3 in particular there is only 1 path at this point but this has a length of 1.2 and since earlier i had a length of 1.1  well  i have not found a better path to v2 what can i say about v4 now ? well  v4  hindi  there was no path from s to v4 now  i am seeing a path from s to v4 whose length is ; well  this is an edge from v1 to v4  so first i get to v1 i know the shortest path is from s to v1 that is of length 0.7 so  this is 1.1 and distance to v5 is 1.3  0.7 plus 0.6 so  these are my new upper bounds in the distance i call them tentative distances this of course is fixed  final this will not change this was the shortest distance  this can never reduce but the other distance is might reduce as the algorithm proceeds for instance  this distance  this tentative distance which was earlier 2.3 has now reduced to 1.1  1 sorry this did not reduce this earlier was not reachable at all let say  it was infinite earlier now  it has 1.1 and this also became  came down from infinite to 1.1 now  what i am claiming is that let me look at the smallest of these which is 1 and this is the correct distance of v3 from s  hindi  at least 3 edges ? no  we can not say such a thing  refer slide time  32  48  conversation  hindi  this is what  so let us first say what the algorithm is and we will have to prove its correctness and we will have to look at its implementation and we have 3 lectures do it so do not  let us not rush ourselves this is not a straight forward algorithm but let us understand what the algorithm is first so  once the algorithm in grained then we will see what the  why it is correct so  what is my algorithm now ? so  my algorithm is going to have a set s of vertices  hindi  what does this set denote ? this set is the set of vertices to which i have found the shortest path from little s  hindi  so this  what is going to happen in this algorithm is with every step of algorithm  i would have found the shortest path to 1 more vertex when i say i found the shortest path ; i mean these shortest path  not an upper bound or any such things i have found the correct value of the shortest path from s to that vertex  hindi  i would include 1 vertex into the set at every step i will include 1 vertex into the step so at any point  this is the set of vertices which i have found the shortest path to and this is the set of vertices for which i have not yet found the shortest path i just have an upper bound on the value of the shortest path i know that the shortest path less than this number but  i do not really know  what is the correct value of shortest path ? so  each of these vertices has an upper bound this is the vertex v  let d of v  so  let me write down ; for all v in s complement  d of v is an upper bound on the length of the shortest path from s to v you understand what i mean by upper bound ? it is a quantity which is only larger than the length of the shortest path it can never be smaller than the the shortest path and for all v in s  d of v is the length of the shortest path  hindi  i am just telling you  what are the various invariance the algorithm is going to ?  hindi  these quantities would be upper bound and this could be the actual values now  i will tell you how do i figure out  how do i move 1 vertex from here to there ? which is the vertex i move from here to there and what happens when i move that vertex ? so first  which is the vertex i will move from here to here ?  refer slide time  37  27  so  i find the vertex in s complement for which d is minimum is moved to s  hindi  i have my s complement  i have my s  i have these tentative distance on all of these vertices  hindi  i will move that vertex here  hindi  this is the vertex which will move from s complement to s  hindi  so understand  what moves from s complements now  what happens when this move ? when this move is down ? how do these numbers change ? so  how do we update ? that is what we have to determine now  hindi  let say  i am looking at this edge   hindi  from what we have said  the right distance from little s to this vertex w will now become 1.1  will be 1.1 so  i know that from s  i can reach w using the path of length 1.1 which means that i can reach this vertex by using the path of length 1.1 ? 3  4.1 so  i can change this 9 to 4.1 now and this is my new upper bound or the length of the shortest path from s to this vertex so  this is how i am going to update these labels these ds are also called distance labels  hindi  i have not told you  you have a slide ? of why we are doing ? what we are doing ? but  we have not discussed why it is not correct we will do the correctness for this so  do not lose heart i first want to make sure that you understand what the algorithm is  hindi   refer slide time  41  34  understanding will be complete after we write down the pseudo code so  let us do that so this is going to be almost exactly like prim ? s algorithm with a very small modification so  you can now start telling me what i should do ? what should i do ? what should my initial values of distance labels be ? infinite  distance label recall  we said is an upper bound on the length of the shortest path from s to that vertex since  initially i have no clue what those things are  i put every vertex  i give every vertex distance labels of d of v equals infinite and d of s is 0  distance of s is 0 because it is ? now  what should i do ? i should take vertex with the  at any step what do i do ? i take the vertex to the smallest distance labels so  all of these guys should be put into a heap so  for all v belonging to v  dv equals infinity and h dot insert v comma dv i have inserted the node v with priority  dv this guy also i am going to insert h dot insert s comma 0 so  the minimum  hindi  we have already inserted  you are saying there let say decrease  let us call it decrease priority  hindi  in my heap the minimum  the top element will be s i should now remove this element what should i do ? i should remove the minimum did i also remove the minimum in the case of prim ? s algorithm yesterday ? or we just did the find min ? that was a mistake correct that in your notes we do not just have to do a find min  we also have to remove it from there because recall  the only vertices that we are keeping in the heap all the vertices on the s complement side so  let us look at this and you can then go back and look at your prim ? s notes again so  what should i do first ? i should remove the minimum element so  h dot delete min and let say  this is vertex v so  i get the minimum element  the vertex with the minimum priority and that say let say that vertex v what should i do now ? this i got as the minimum vertex  i should look at the edges  i should look at the edges going out of this vertex or the same as saying  let me look at the adjacent vertices so  for all w  let me just say  out adjacent so it is complete clear what i am saying  out adjacent to v do so  i am looking at this vertex w which is out adjacent to v now  i have to update its label when should i update the label of w ? w already has a label what is that label ? that label is an upper bound on the shortest path basically  that label is saying  hindi  now we are seeing a shorter path but  what she is saying is that will we  we should update w only if it is in s path  hindi  even if i were to not to worry about that  the point is i have that i have already found the shortest path to w if w were in s that means i have already found the shortest path to w then there is no way it is getting updated now because  if it is getting updated ; there is something seriously wrong with what i am saying think about this we do not really need to maintain this information in this particular case so  when should i update w or distance label of w ? if i find a better path to w and what would be the better path ? through v  so d of w equals minimum  d of w comma  d of v plus l of v w this is the other path i am saying  to w and if this is shorter then let us put this as the new level everyone understands  hindi  because s complement  hindi  the only vertices in the heap are the vertices in s complement  hindi  h dot decrease priority  w comma  this is together  hindi  this statement would not be executed  hindi  you can do it more carefully this implementation  only if d w decreases  should you call this  but waste of time you will have to follow a few pointers to get to be heap  make a comparison all of ?  hindi  so  we have done at the end  where are the shortest path ? sorry  what have we found out ? we have only found out the length of the shortest path and they are all setting in d  refer slide time  49  54  we will come to that  we will come to that  hindi   it is not very different from prim ? s  hindi  we do not have to maintain s and basically  hindi  this is similar to the version of the prim ? s  the second version of prim ? s that i talked about  hindi  you recall the second version of prim ? s what was that ? we had maintained s  s complement and for every vertex in s complement  i had 1 label what was that label saying ? look at all the edges going from this vertex to s  the minimum of these edges would be the label here now the label is saying  completely something completely different ; in the case of dijkstra ? s algorithm this was prim ? s algorithm this label  label v equals minimum of  hindi  l1  l2  l3  minimum of these 3 area now again  we have a similar thing we have  each of these vertices has a label we are calling that label d now but d is not the minimum of these 3 it is not that  d is not the minimum of l1  l2  l3  hindi  d has some other semantic which we will see later  hindi  can someone hazard a guess here ? what did you think is d ? minimum of  min of s  the value of d v is min of d w1 plus l1 comma d w2 plus l2 comma d w3 plus l3  hindi  all these vertices are part of a heap priority is this label here and the priority is this d value here  hindi  we will see why this is true this is we will see when we are doing the correctness of the procedure  refer slide time  54  22  who can tell me what the running time is ? v square log v ? why v square ? i understand  but why n square log n ? second summation degree log n  hindi  we are spending time proportional to the degree of this vertex or the number of times we are calling this loop time will be log n times that because of the decrease priority operation because  each decrease priority operation takes time at most order log n and  hindi  because up this operation corresponds to removing the vertex from s complement  hindi  each time it takes log n time  so it will be n minus 1 time log n this is the now realize  this is the mistake i made in the prim ? s algorithm  hindi  because the semantic is the same the vertices in s complement are the ones in the heap and so when i am moving a vertex from s complement to s  i have to remove it from the heap so  you have to do a delete min operation we just said  find min if you do not do  it will be an infinite because the same thing will coming as min  min  min  min  hindi  so  this total running time  let me put it down no  not n  but m not n  but m why because  we have the total time  the total number of times this operation is being executed is order to m  hindi  with that we will end today ? s discussion on shortest path  but we will continue this because  we have to prove the correctness of this algorithm we also have to see  how to find the shortest path because  here we have only computed length of the shortest path from s to the root data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 35 correctness of dijkstra ? s algorithm in the last class we looked at dijkstra ? s algorithm for computing the single source shortest path the algorithm i do not recall if i did tell you the name of the algorithm it is called dijkstra ? s algorithm what remains to be done ? we have seen what the algorithm is hopefully you all understood  i am going to be revising it any case today we had also argued how to implement the algorithm and what its running times would be the implementation was very similar to prim ? s algorithm computing minimum spanning tree with some small modifications but we have not argued why the algorithm is correct ? why the dijkstra ? s algorithm is correct ? as a quick recap of what is being done in dijkstra ? s algorithm we are given a source vertex  we are given a graph you are given a length function on the edges and the edges are non negative you can have zero edge lengths but you can not have a negative edge length that is important and we will see why what is happening at each point ? with each vertex we have a distance label associated with that vertex d  v   today we have to first understand the semantics what do these numbers represent ? initially d  v  recall is infinite for every vertex d  v  is an upper bound on the distance of v from s and this quantity with every step only decreases and it never increases at a particular step what does the algorithm do ? at any point we have two sets  the capital s and s complement the vertices which are in s  for them we have computed there actual shortest path distances from s we have already computed that and the vertices which are in s complement  for them we do not know the correct distance we only have an upper bound on the correct distance at a particular iteration what do we do ? we take the vertex for which the d  v  is minimum suppose this is the vertex u  so d  u  is less than or equal to d  v  for all v in s complement  hindi conversation  signifying the fact  hindi conversation   and then we are going to move u across you will go from s complement to s we will also have to make this claim to argue correctness that is at this point  hindi conversation  that is the correct shortest path distance of u from s when we move across how do we update the other labels ? if there are 3 edges going out of u to other vertices in s complement  hindi conversation  what is the new distance label of w ? min d  w   d  u  + length of the edge  u  w    refer slide time  06  38  this is how we update the distances  hindi conversation   as you can see this operation shows that d  w  value will only decrease  it can not increase because it is the minimum of two quantities one of which is d  w   d  w  value will only decrease so if these distance label were sitting in a heap then all you have to do is to do a decrease priority operation on the heap when you are removing the minimum that correspond to the delete min operation this is just a recap of what we have done in the last class we have seen all of this before  hindi conversation  that is the algorithm we keep doing this  till every things moves from here to here and then we are done what is the initial composition of s and s complement ? initially the only vertex in capital s is little s and every thing else is in s complement let us first understand given a vertex u  what does d  u  means given a vertex u in s complement  this is s and little s is here  refer slide time  06  50   what is the meaning of d  u  ? what connotation or what semantic can i associate with d  u  ? shortest length of a path including vertices only from ? yes so claim is d  u  is the shortest path from s let us look at all path from s to u which use only vertices of s and at one point that take one edge across and reach u  hindi conversation  there can be many such paths this is one path may be there is a second path which goes like this there may be a third path which goes like that and so on there could be again a whole lot of such paths let us compute the length of all those paths and let us take smallest amongst those that is d  u   so formally i could try d  u  = length of shortest path from s to u that includes only vertices from the set s  hindi conversation  except for u which is the last vertex  the other intermediate vertices will only be vertices from s that is the meaning of d  u   that i clime is the meaning of d  u  and let see whether this is really true how will we prove that this is true ? the best way to do this is to prove it by induction make sense to try and prove it by induction we will assume that at this point this is true the numbers or that d on these vertices do reflect this quantity and then we will say when i move one vertex across then the new d ? s on the vertices continue to reflect the same thing and then we will show that the base case is also true and that will establish this claim if it is true now i move a certain vertex across let say vertex w which is here  moves across as a consequence i might end up updating the distance label of u  refer slide time  10  14  so this edge is not there  this is just signifying that this vertex moves across let say u1  u2  u3 are the 3 neighbors of w that is out neighbors so we are going to update u1 to d  u1  = min  d  u1   d  w  + l  w,u1    this is how we are going to update why is this correct ? why is it that after this the new value of d  u1  ? may it is the new value  may be it is the old value  still satisfies this thing if d  u1  remains unchanged then that means the earlier value was the smaller one so what is that happening ? the w moved across  let me draw the picture s complement minus w and s + w  w is here  and u1 is here not another path  but i should say let me look at all the paths from s to u1 now those paths  what could they be doing ? so i have to look at all path form s to u1 which only includes vertices from this side  hindi conversation  either the paths do not include vertex w at all and they go directly like this but then the length of such a path is already captured in the earlier value of d  u1   the d  u1  is smaller than the length of all such paths or such a path includes w one possibility is that it includes w  that it visits w and then goes to u1 third possibility  it goes to w goes to some other vertex and then goes to u1 let us look at these 3 things we are saying that either it does not visit w at all which is the first case then what remains is  it visits w it touches w what touches w ? we are looking at the shortest path from s to u1 which includes only these vertices  refer slide time  13  51  so the other case is that it touches w and the moment it hits w after that it goes directly into u1 this is the second case third is it comes to w then it goes of some where else that it goes to u1 you are claiming that the third case can not happen what do you mean by can not happen ? the claim is that this path has length at least as large as d  u1   we have to look at these three cases one after the other the case one is covered case two is also covered why because this path comes up to here  refer slide time  15  06  and then i take this edge if this is the shortest path from s to u1 and it goes via w like this then this part has to be the shortest path from s to w  refer slide time  15  26   that is equal to of length d  w  by induction hypothesis and then this plus this length would be the length of this path from s to u1 that is getting captured here we are accounting for the length of such a path what remains is this case three why can not we have this ? let say this vertex is x you are wrongly concentrating on w  it has to be x we have to look at x the x was already there we already knew the shortest path from s to x and that was equal to d  x   the label on x it does not involve w  we already have that information if this is the shortest path from s to u1 then s to x is also the shortest path from s to u1 what is the blue line that i have drawn ? this is this the shortest path from s to x the x was already a path of s which means we already had the shortest path from s to x and the shortest path from s to x is using only vertices of capital s  not using w at all and that path sits here if this path which goes from s to w then from w to x and then from x to u1 is the shortest path from s to u1 using vertices only of s + w then this path from s to x followed by x to u1 is also the shortest path if it is also the shortest path then we have already accounted for it in d  u1   d  u1  is only less than this quantity  because what is d  u1  ? d  u1  till now is the length of the shortest path from s to u1 using vertices only of capital s so this path that is now i have created does not use vertex w at all so it becomes something like case one  except that you have to make this argument  refer slide time  18  52  so may be all of this is not very clear so let us try and do it more completely we are looking at s  u1 w is the vertex which has just come in and we are looking at third case  when shortest path from s to u1 goes via w to a vertex x and then it jumps across to u1 now the length of this path  which is s to w plus w to x plus x to u1 the claim is that the length of this path is at least as large as the length of this path from s to x  followed by x to u1 let me write it down  length of path s to w to x to u1 is no less than that of the path s to x to u1 what is the path from s to x  i am taking ? the shortest path from s to x  that does not include w shortest path from s to x does not include w why  because w just came in and x was already there by our induction hypothesis we had already found out the shortest path from s to x that is the path which is lying completely in s let me write that part also the shortest path from s to x does not include w and only includes vertices of capital s this is capital s + w now  this is capital s complement minus w capital s was the part before we moved this thing this path which is going like this  refer slide time  21  28   has length at least as large as the length of this but what do i know about this ? about this i know that d  u1  is less than or equal to this u1  length of path s to x to u1 already i know that  because d  u1  was the smallest possible path which used only vertices of s this is only less than that and since this is less than this  d  u1  is less than or equal to this longer path so i can effectively ignore this thing  i do not have to consider it  because it is already included in my d  u1   d  u1  is already a smaller quantity than that so all such paths are captured in d  u1   d  u1  is the quantity only smaller than such paths the one path which is not captured is such a path which goes to w and then takes an edge out that is case 2 for that we have included here and this smaller of these 2  will give me the smallest path from s to u1 which only includes vertices of s + w  hindi conversation    refer slide time  23  24  that is a semantic and once you have the semantic in mind then it is easy to prove  most of the other things what is the meaning of those distance label ? once you have that in mind every thing else are very simple to follow are every one convinced that d distance label reflect this kind of length why are we justified in moving the smallest label vertex from here ? that is what we are doing at each step at each step i am taking this vertex which has the smallest label and moving it across and claming that it has the right number on it why am i justified in doing this ? what we are claming is d  w  is the length of the shortest path what is w ? w is the vertex which has the smallest label the w is the vertex with the smallest d value in s complement the claim is d  w  is the length of the shortest path from s to w why is this claim true ? proof by contradiction  suppose this is not true if this is not true what does that mean ? that there is a shorter path form s to w shorter than what ? shorter than d  w   what will that path do ? that path will visit some vertices here  refer slide time  25  47  and at some point it has to jump across and then it has to come to w  may be it jumps back and then comes again it can do a whole lot of crazy things  but it has to at least jump across once if it jumps across once  let say it jumps across and reaches vertex x what is the length of this portion of the path ?  refer slide time  26  16  greater than or equal to d  x   that is our semantic that we have associated with d  x   so this part of the path is at least d  x    hindi conversation  why because we said  the shortest path from s to x which uses only vertices of s  has length d  x   this is the path which uses vertices only of s so it has length at least d  x  or more that is why i put greater than or equal to this part of the path whose length is at least d  x  which means the entire path has length at least d  x   here i am using the fact that edge lengths are non negative so this entire path that we have drawn has length at least d  x   so path drawn has length greater than or equal to d  x   which is greater than d  w   it is greater than or equal to  may be they were at the same distance  refer slide time  26  43  so this path has length at least as large as d  w   refer slide time  27  50   which means it is not a shorter path we started of by saying that there is a shorter path than d  w   there is a path whose length is strictly less than d  w   so that is not the case if there was such a path it should have a length  greater than or equal to d  x  it can not be strictly less than do u you said this is the best path all i am saying is this part of the path has to have length at least d  x   if it were the shortest path then it would have exactly d  x   but may be  you did some thing i do not know  it is at least d  x    hindi conversation  there is no path which is smaller than length d  w   there is no possible path at all there is no path from s to w of length strictly less than d  w   which means d  w  is the length of the shortest path from s to w  refer slide time  30  37  and so we are justified in moving this vertex across because we have found the length of the shortest path form s to w what is that path ? that path would include some vertices from here and then jumps across we are justified in moving this vertex let us recap the argument this clam is okay  hindi conversation  we were proving this  refer slide time  30  07  length of shortest path from s to u that includes only vertices from s equals d  u   this we were proving using induction and when proving this induction statement we required that  hindi conversation  we have found a shortest path from s to x already and that we have proved now which is shown in the slide that is  refer slide time  26  43   hindi conversation  induction is being applied on the number of elements of s so what is the induction statement ? what should be the induction statement ? i have told you everything  now you need to just turn it in your head and figure out what is right induction statement ? this is s and this is s complement  refer slide time  31  21   so the induction statement should be for all x in s what should i write after this ? d  x  is the length of the shortest path from s to x for all x in s complement  d  x  is the length of the shortest path from s to x which includes only vertices of capital s  hindi conversation  induction hypothesis how will this work ? we will do the base case later we say there is a vertex w  which we move from here to here since it has moved from here to here  we have to argue for vertex w that d  w  is the length of the shortest path from s to w that we did here  refer slide time  33  26   d  w  is the length of the shortest path from s to w for the other vertices s complement we have to argue this statement that  hindi conversation  and that we have done in the slide which is given above that is d  u  is the length of the shortest path from s to u that includes only vertices from s basically this was vertex u1  we looked at these three cases  hindi conversation  from s to u1 which only include these vertices from s that either includes the vertex w  if it does not include the vertex w then we know that the length of such a path can not be no more than d  u1   if it includes the vertex w then if it were such a path then its length is no more than d  u1  but if it were such a path case two then its length is exactly this  refer slide time  34  36   so the minimum of these 2 quantities is the length of shortest path from s to u1 which only includes vertices of s + w  hindi conversation  for the other vertices basically sub vertices  hindi conversation  statement continues it will continue to remain true because we have not changed the distance labels at all what have we changed as the result of this ?  refer slide time  35  02-35  26  we have moved one vertex from here to here and changed the distance label of these vertices since we have changed the distance label of these vertices  we need to argue this statement of those vertices and since we move this vertex from here to here we need to argue this statement for these vertices and we have done that  hindi conversation  which only includes vertices of s no  you do not want to say  hindi conversation  if you just say that for all x  d  x  is the length of the shortest path which includes only vertices of s when w comes in here  you will have to look at all the vertices their and also argue that why w coming in  the length of their shortest path is not reduced  refer slide time  36  13  because w only comes in now  hindi conversation  complicated this is what exactly the thing is so vertices  hindi conversation  number  right number and they will not change that is the length of the shortest path from s to those vertices  period and those vertices s complement  hindi conversation  that is qualified in a certain way that is the length of the shortest path from s to that vertex  provided the path uses only the vertices of capital s that is the qualification to the path  hindi conversation   this is the property that you have to keep in mind about these things no  for the vertices which are already here  it is the same we have not changed the distance labels for those vertices at all if earlier it was true that for a vertex which was here  the d was the length of the shortest path from s to that vertex then it remains  it is the shortest path unqualified this is not qualified  hindi conversation  it is the shortest path from s to that vertex let us do the base case what is the base case ? but base case is very simple the s has only little s in it and s complement is every thing but little s in it  hindi conversation  basically length of this edge only we start of by putting these as infinite but then the moment we move this across  refer slide time  39  00   this will get the length equal to this so if this was 7  this was 12 and this was 3  then these would get distance labels 3  12 and 7 is this correct ? is this the length of the shortest path from s to this vertex which uses vertices of capital s only ? yes  there is no other vertex in capital s  refer slide time  41  30  so there is only this one edge and it is the length of the shortest path it is similarly for 7 and 12  so it is correct the base case is correct and at each step we are maintaining these 2 properties this is what you have to keep in mind you just have to say this is length l1  this is length l2 and this is length l3 and this will have l3 written on it  this have l2 written on it and this will have length l1 on it and this need not be 3 edges and there can be any number of edges this is a proof for any graph  hindi conversation  that argues the correctness of this algorithm this algorithm is due to dijkstra where j is pronounced as y  so it becomes dijkstra what did we argue is the running time of this algorithm ? this algorithm would not work if the graph had edges of negative length in fact if a graph has edges of negative length then actually there is no notion of a shortest path some times do you understand what i am trying to say ? suppose this was my graph  one comes repeatedly so for instance the shortest path from s to t has length minus infinity why  because i start from here  go down  i come back and keep going  refer slide time  42  33   every time i go around this cycle  i get minus one and i just keep doing this so the problem is because you have a negative cycle this is called a negative cycle if the graph has a negative cycle then the shortest path is not defined there is no notion of a shortest path any more  because the length of the shortest path could be minus infinity but this graph need not have a negative cycle for instance if this edge had a length of minus one  now what is the shortest path from s to t ? it is length one  i would go like this  come down and then go like this what will be the length of this path ? it is one when do you think negative length make sense ? is this very artificial  negative lengths  can you think of a setting ?  refer slide time  47  25  what other settings can you think where you can have negative edge lengths ? so one other setting that i saw somewhere was  this is a graph which represents currency tradings you can think of it in a different setting also so each node is a currency  you are a global currency trader and then an edge reflects that if i change from  if this is let say rupees  this is indonesian path then this is the profit i incur in doing that and negative would then correspond to a loss because of what ever i exchanged at that point of time and then finally you want to change your rupees into  let say back into rupees what you are seeing if there is a positive cycle in this graph then you will just keep going around the cycle and keep making when see  hindi conversation  i do not understand your example but there are many such setting where negative would make sense how can i solve this or how can i find out the shortest path in graph which has negative edge lengths ? does dijkstra ? s algorithm work here ? keep the minimum as zero and shift increase everything by plus one that is by the minimum  hindi conversation   add sufficiently a larger number so that there is no negative length brilliant idea except that it does not work  hindi conversation   you add a delta x so that everything becomes positive why does this not work ? number of edges on one path could be different from number of edges on another path suppose i have a very simple graph  hindi conversation   what am i trying to show you ? what will i do ? let me finish this example first so this path is the shorter path but its length increases because there are a lot of edges on it let say all edges had length one on it and one edge had a length of minus one so what is the length of this path ? the length of this path is 3 + 4 = 7-1 = 6 let us make this path of length longer than 6  so let make it 3  3  3 this becomes 9 if i increase everything or let me make it 3  2  2 just to be on the safe side so it is 7  longer than this so this is the shortest path but if i now increase every edge by one  then what is the length of this path ?  hindi conversation   so  hindi conversation  what do you mean reconvert back ? keep track of number of edges how will you keep track of number of edges on the path ?  hindi conversation  there is no notion of a shortest path if there is a negative cycle but the graph need not have a negative cycle  let say this graph there is no negative cycle in the graph negative cycle  hindi conversation  is well defined  refer slide time  49  55  so first tell me what goes wrong in the dijkstra ? s algorithm ? where does it break down ? did this argument break down ? here we argued the d  u  is the length of the shortest path from s to u that includes only vertices from s does this break down ?  hindi conversation  this part of argument is fine i think  refer slide time  51  10   but this part of the argument  when we said the d  w  is the length of the shortest path from s to w  is not correct any more because i could have a path which goes like this but this is shorter than d  w  because there are plenty of negative edges on this part  refer slide time  51  43  so this inequality is not true  hindi conversation  now i can not say anymore that d  w  is the length of the shortest path from s to w  this thing breaks down so dijkstra ? s algorithm does not work  you can not use dijkstra ? s algorithm to compute shortest path if you have negative edge length  hindi conversation  how are you going to make your millions ? how will you do that tell me ? so this is a valid question here we will basically not discuss it today  because we do not have the time do it so that is one thing remains to be done  hindi conversation  every vertex has linked list of edges what does it do with the linked list of edges ? what way does it maintain a pointer to ?  hindi conversation  the shortest path from s to w and then the edge w u1  hindi conversation  and so on  hindi conversation   we are going to look at it in more detail in the next class how exactly you are going to do it  what is the modification to the code that will be required do such a thing that is the one thing i would like to cover the other thing i would like to cover is also to show you an algorithm to compute shortest paths  when you have negative edge lengths but it is going to be very different from this algorithm these are the two things that remain  we will take this up in the next class data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 36 single source shortest paths we will continue our discussion on single source shortest path today we are going to see how to actually compute the path in the last class we have seen how to compute the distance of any given vertex from the source  when all edges had non negative lengths today we are going to see how the path can be found and in second part we are going to see how to compute single source shortest path when edges might have negative lengths i am going to start from the picture you have s  and there was a vertex w so the should be  the vertex w is going to move from right to left and when this vertex is moving it causes the distance label of the adjacent vertices to be updated if this were the vertex u  we said that d  u  is going to be min  d  u   d  w  + l  w  u    i have repeated this many times essentially what this means is that if d  u  is getting this  d  w  + l  w  u   value then that means the best path that i am finding from s to u which includes only vertices of s and w and it is going through w or w is the vertex preceding u on the best path from s to u  refer slide time  04  50  let me write it down  if d  u  = d  w  + l  w  u  then the best path or the shortest path from s to u  using vertices of s + w  has w preceding u basically we are saying that the best path from s to u and then the vertex preceding u on that path is w this is the best path from s to u  if this is how the updation is happening that is if d  u  was getting this  d  w  + l  w  u   value and this is not the best shortest path from s to u because this is under this qualification  using vertices only of s and w because w is going to left hand side and using only these vertices the best path from s to u will have w preceding u this is the information we will maintain with vertex u what is the vertex preceding it on the best path that i have found so far ? the best path means the shortest path with each vertex we maintain predecessor information what do i mean by that ? if w = pred  u  then w is the vertex preceding u on the best path from s to u how am i going to use this information to compute the shortest path ? suppose i have this predecessor information for each vertex  this is vertex u and i know that the vertex which precedes u and the best path from s to u is pred  u  and i have maintained this information let say this is a vertex  i am going to look at predecessor of because this part of the path from s to has to be the shortest path from s to  if this is the shortest path from s to u then this has to be the shortest path from s to  the predecessor of would be the vertex preceding it  on the shortest path form s to  so this vertex would be predecessor of  this part of the path has to be the best path from s to  i have the predecessor information for that tells me what is the vertex preceding on the best path from s to  this i have information that is pred   and so on i can keep doing this till i reach the source vertex  refer slide time  07  28  once i have this information i can just keep tracing it back till i reach the source vertex and that will give me the path how to we maintain this information ? when ever we update the distance label  we have to keep track of this we update the predecessor when do we update or how do we update ? when we transfer a vertex from the side to the side s  that is w is the vertex which is getting transferred then this is the vertex u and i am updating its information how should i write it now ? if d  u  is greater than d  w  + l  u  w  then d  u  is d  w  + l  u  w   what is this saying ? the d  w  + l  u  w  is the length of a better path if the path you found now is better then what you already had then you update the information and pred  u  = w that is the only modification we are doing then basically we are storing with each vertex  2 pieces of information d and this predecessor information and now using this predecessor information you can find the path and keep moving back up how ? suppose i wanted to find the shortest path from s to a vertex x while ! pred  x  equals null i will set the predecessor of my source to null because the source vertex has no predecessor initially let us say x = v  v is the vertex for which i am finding find the shortest path from s to v ? initially x = v  now i will go through this loop  while pred  x  ! = null print it directly that is print  x    hindi conversation  initially v   hindi conversation   so in this manner you can also print out the path  i have printed out the vertices of the path once you have the vertices in the path you can also figure out the edges of the path if you want to print out the edges one suggestion is instead of having this condition i can also right x ! = null  hindi conversation  all of you can figure this out  refer slide time  12  36  what we have done using this procedure ? we have computed the shortest path from s to every vertex in the graph not just one vertex but every vertex in the graph let us draw all the shortest path and let see what is the sub graph that we get  hindi conversation  let say this is the shortest path from s to vertex   hindi conversation  except for root vertex that is the source vertex  hindi conversation  n-1 do you understand what edges i am taking about ? i can also call them as the predecessor edges  hindi conversation  this is the predecessor vertex if i am looking at the vertex u and v is the predecessor vertex  we have kept track of the predecessor vertex information bur we could also have thought of this  u v  path as the predecessor edge the edge connecting the predecessor vertex to this vertex is the predecessor edge  hindi conversation  how many predecessor edges we have ? the n-1 predecessor edges  hindi conversation  i can reach every vertex because if i take any vertex i can take its predecessor edge go to the previous vertex  go to the predecessor vertex and i said i will eventually reach s is it clear that i will reach s in this process because the whole point is that this guy got its length from here  which means we must have been able to reach this vertex in the first place and this guy got its length from here and so on  refer slide time  16  20-16  30  we will eventually hit the root so what can we say about this sub graph ? if i ignore or forget the directions of the edges then it is a connected sub graph with n-1 edges it will be a tree that is a spanning tree but if i bring back the direction  note that in a directed graph there is really no notion of the spanning tree  refer slide time  18  57  there is another name give to it it is called a branching  the same thing it is basically a sub graph with n-1 edges such that i can reach from a specific root vertex to every vertex such a thing is called a branching it is not very important  you do not need to remember this step  but you understand what the idea is with these edges i can go from the source vertex to every other vertex in the context of shortest path this is called the shortest path tree because if i just look at this tree  these set of edges then it is very nice if i want to find out the shortest path from s to this vertex which is next to  what do i have to do ? i just follow the unique path that is there in this tree from s to this vertex  or conversely i go to the predecessors and then to the root that is the path  which is the shortest path from s to this vertex which is next to  similarly the shortest path from s to this vertex is this path and so on all the shortest paths are getting captured here by just these n-1 edges these n-1 edges capture for us in a second manner  all the shortest path from the source to all the various vertices  hindi conversation  this is called the shortest path and we can compute this tree in the same time as required by dijkstras algorithm we have not spent any additional time you also know how to find out the shortest path what remains is what we had mentioned in the last class if edges have negative lengths how can you then find out the shortest path ? once again we are talking of single source shortest path when edges have negative lengths what i mean by this is  not all edges have negative lengths  some have negative some have positive but we are permitting edges to have all kind of negatives and positives once again we have a source and we are trying to find out the shortest path from this source to all the vertices of the graph i am going to assume that there is no negative cycle because recall if there is a negative cycle then this thing is meaningless there is no negative cycle in the graph what can you say about the shortest path from s to v ? can it be a non simple path ? what is a simple path ? it does not repeat any vertex  no cycle on the path can this be a path like this ? why not ? this cycle can not have negative length which means if i were to go in the straight line above the circle  it would be shorter because this cycle has positive length it will only be shorter to go directly like this the cycle could have the also zero length in which case it will not be shorter but this will be a path of same length  refer slide time  25  02  there always exists a shortest path which is the simple path this could also be the shortest path if this cycle had zero length but the point is there will always be a simple path also we can just restrict our attention in finding a simple path we will only be interested in finding simple path the algorithm is very simple actually  it is a gossiping kind of algorithm what is that mean ? think of each of this vertex as a person and this person talks to 3 people  hindi conversation  whatever information this guys gets  he promptly communicates it to his 3 mates what they do is  they intern communicate this information to their mates and so on  hindi conversation  what is the information that is being gossiped about ? length of the shortest path from the source what this guy is going to tell these people is that the shortest path that i have seen so for from the source has length 10 so he will communicate this to all this 3 and what will this guy do ?  hindi conversation  now i have found a path of length 8  hindi conversation  what is the shortest path it had found so for from the source ? may be that information was 9  so now it will quickly change its thing to 8 because it had found a path of length 8 now and may be  hindi conversation  that will call one round  hindi conversation  from its in neighbor  hindi conversation   refer slide time  29  39  i have found a path of length 9 and this is 4th and here you have a path of length 13  hindi conversation  i have found a path of length 12 and this is 1 and you have the path of length 13  hindi conversation  i have found a path of length 13 this is minus one so you have a path of length 12 what is this guy going to do ? it is going to take the minimum of these 3 and if it had some original  earlier information it is going to take the minimum all of them and put that down as the new path length let say original information was more than 12 then that will become path length and this is the information that it would communicate in the next round  hindi conversation  one round is inner round  hindi conversation  ever one talks to their neighbors and sends the information and then each node also gathers the information from its neighbors and updates its value that is the end of the round after it has updated its value in inner round  each guy talks to its neighbors  hindi conversation  first transfer then updation let us say the round starts with the transfer then when you have got information from all your neighbors  you update all the nodes do the same thing simultaneously a node will get information only from its inmates  hindi conversation  you have these vertices  you have to implement this thing what is the information we are maintaining with each node  once again we call it a distance label with the node v  i am maintaining this distance label how will you implement one round ? i take a vertex  there is no notion of actual transmitting any more this was just to show you the idea what does this vertex do ? it look at its in adjacent vertices  hindi conversation  propositional to its degree the total time  hindi conversation  number of edges this is how you will implement one round  hindi conversation  zero on the source and infinity for all others  hindi conversation  if in a round nothing changes then we can stop  refer slide time  35  44   hindi conversation  from the source we will have to prove that  hindi conversation  let see  hindi conversation  there is a difference between length and number of edges on the shortest path this is the shortest path using edges length  hindi conversation  n-1 shortest path  hindi conversation  a shortest path from s to v then what is the shortest path from s to this vertex which is between  that property continues to hold true  hindi conversation  that was independent of whether the edge lengths were positive or not shortest path from s to this vertex will be this they can not be a shorter path because if there were the shorter path then this could not have been the shorter path from s to v similarly shortest path from s to this would have been and so on so the claim we are going to make is  if the shortest path from s to vertex x has l edges on it then d  x  gets the right value which means the value of the shortest path after l rounds  hindi conversation  after 5 rounds this vertex v will have the correct length of the shortest path why ? this claim is true we will prove the claim by induction on l l equals one  hindi conversation  is this true ?  hindi conversation  when we find a better path because if there is no better path  we will never be changing the value later  hindi conversation  value  hindi conversation  after five steps then it will not change beyond that  hindi conversation  you take the value of the in adjacent vertices which has not been updated in that round there is a vertex whose value has been updated right now and it has vertex you reach the vertex after that you will consider new value or old value for confusion a new value or old value let us forget about new values or the old values let me write down the code  hindi conversation  for all v do  hindi conversation  for all w in adjacent to v do the d  v  = min  d  v   d  w  + l  v  w    hindi conversation  for i = 1 to  hindi conversation  n-1 do  hindi conversation  you will try to reduce the running time a bit the worst case will remain the same  hindi conversation  d  s  equals zero  for all v in v-s  d  v  equals infinity  hindi conversation  for i = 1 to n-1 do is just to count the number of time we have to repeat the process  hindi conversation  in adjacent vertices  hindi conversation  why did you put down only n-1 and no more because i argued in this claim that  hindi conversation  what is the maximum number of edges that there can be on any shortest path we have argued that on any shortest path there can be no more than n-1 edges because there will always be a shortest path which is simple does not repeat  so at most n-1 edges on it and so i need to repeat it only n-1 edges and no more  hindi conversation  should we do the correctness for this ? yes let us do the correctness  why is it correct ? why have we computed the shortest path ? have you computed the shortest path ? is it clear that after round 5 this vertex v is going to get a distance label of  it is going to get a distance label of this or smaller  hindi conversation  i am assuming this is the shortest path after one round this guy has to get a label of that is completely clear  after 2nd round this guy is going to get a label of or less this guy is going to get a label of after 3 rounds or something even lesser  refer slide time  41  49  after 4 rounds this is going to get a label of or some things lesser this guy is going to get a label of after 5 rounds or something lesser so for correctness we need to argue that this guy is not going to anything lesser than  if you have argued those then we have that it gets exactly the distance label  refer slide time  42  00-43  17  we have to argue that a vertex can not get a distance label which is lesser than the length of the path from the source to that vertex i give a vertex of a certain distance label  it is because i have found a path of that length from the source to that vertex that i have to convince you and that follow from the way we are doing things that will be a proof by induction what should we induct on ? what is the claim we are trying to make ? let us write that down if a vertex v gets a certain distance label d in round r  then we have found a path of length d from s to v this is what we are trying to argue basically what i am saying is that if a vertex is getting some distance label it is not that  hindi conversation  why is this claim useful ?  hindi conversation  l  hindi conversation  this is not a shortest path contradiction why is it true ?  hindi conversation  distance label d need not be an integer it is just the length of the path  hindi conversation  suppose this statement is true till round r-1 then in round r  if this vertex v is getting as a certain distance label d because either that was the distance label on it or because one of its neighbors  so this vertex getting a distance label d  hindi conversation  it could have been updated in the same round and you are worried about that aspect then we will have do a double induction kind of a thing let us not worry about that  i will modified the code so that every thing gets updated simultaneously  hindi conversation  but let us just assume this vertex u  this d  u  was the label in round r-1 so now we can apply induction hypothesis which means that we found a path of length d  u  from s to u that was the induction hypothesis saying  hindi conversation  and this plus this means that i have found a path from s to v of length exactly d  u  + l  u  v  which is all d  hindi conversation  that is complete  hindi conversation  there is a valid doubt  you guys are worried a little bit  hindi conversation  look at the algorithm but let us modify the thing so that we do not do that at all  hindi conversation  for all v do  hindi conversation  x  v  equals d  v   x  v  equal to min  x  v   d  w  + l  v,w    hindi conversation  in fact that will be faster than this one because you are kind of doing a little bit more work in each round for this perhaps the correctness is more apparent so it is okay if you do it this way but even that it is correct  refer slide time  52  12  the last thing i want to say very briefly is apsp  this is all pair shortest path  hindi conversation  all pair  every pair of vertices  hindi conversation  n  mlog n  time  hindi conversation  n  m  n   hindi conversation  these are not the best possible  there are algorithm which can do better than this you will learn about these algorithms in the algorithms scores but let me just tell you what are the better bound nodes  refer slide time  56  29  so for single source shortest paths with positive edges length  hindi conversation  m logn  the best bound known is m + n log n  hindi conversation  m could be as larger in which case this will be + nlog n could be and this will be log n so factor log n more this is single source shortest path when edge lengths are positive when edge lengths can be negative  when i write negative it does not mean that every thing is negative please remember this  it just means that in fact every thing is negative  hindi conversation  best possible be mn you can not  hindi conversation  all pair shortest path  hindi conversation  mn logn best possible  hindi conversation  n  m + n logn   hindi conversation  best possible is mn + log n  basically same as this one best known  no these are not the lower bounds these are only the best known  hindi conversation  so with that we will end today lecture on shortest path in fact that also brings us to the end of this course we are not going to take up any other topic  this is all we have to discuss data structures and algorithms dr naveen garg department of computer science and engineering indian institute of technology  delhi lecture ? 1 introduction to data structures and algorithms welcome to data structures and algorithms we are going to learn about some basic terminologies regarding data structures and the notations that you would be following in the rest of this course we will begin with some simple definitions an algorithm is an outline of the steps that a program or any computational procedure has to take a program on the other hand is an implementation of an algorithm and it could be in any programming language data structure is the way we need to organize the data  so that it can be used effectively by the program  refer slide time  1  27  hope you are all familiar with certain data structures  an array or a list in this course you will be seeing a lot of data structures and you will see how to use them in various algorithms we will take a particular problem  try to solve it and in the process develop data structures the best way of organizing the data  associated with that problem what is an algorithmic problem ? an algorithmic problem is essentially  that you have a certain specifications of an input and specify what the output should be like here is one specification a sorted  non decreasing sequence of natural numbers of non-zero  finite length for example  ? 1,20,908,909,100000,1000000000 ? 3 this is a completely specified input above are the two examples of input  which meets the specification and i have not given any output specification what is an instance ? a sorted  non-decreasing sequence of natural numbers of non-zero  finite length forms an instance those two examples are the instances of the input you can have any possible number of instances that may take sequence of sorted  non-decreasing numbers as input  refer slide time  2  29  an algorithm is essentially  describing the actions that one should take on the input instance to get the specified output also there can be infinitely many input instances and algorithms for solving certain problem each one of you could do it in a different way  refer slide time  3  33  that brings the notion of good algorithm there are so many different algorithms for solving a certain problem what is a good algorithm ? good algorithm is an efficient algorithm what is efficient ? efficient is something  which has small running time and takes less memory these will be the two measures of efficiency we will be working with there could also be other measures of efficiency  refer slide time  3  53  but these are the only two things we will be considering in this course we would be spending more time on analyzing the running time of an algorithm and we will also spend some time on analyzing the space we would be interested in the efficiency of algorithms  as a function of input size clearly you can imagine that  if i have a small input and my algorithm or a program running on that input will take less amount of time if the input becomes 10 times larger  then the time taken by the program may also increase it may become 10  20 or 100 times it is this behavior of increase in the running time  with the increase in the size of input would be of our interest let us see the slide  refer slide time  5  20  how does one measure the running time of an algorithm ? let us look at the experimental study you have a certain algorithm and you have to implement the algorithm  which means you have to write a program in a certain programming language you run the program with varying data sets in which some are smaller  some are of larger data sets  some would be of some kinds and some would be of different kinds of varying composition then you clock the time the program takes and clock does not mean that you should sit down near stopwatch perhaps you can use the system utility like system current time millis    to clock the time that program takes and then from that you try to figure out  how good your algorithms is that is what one would call as the experimental study of the algorithm this has certain limitations  let us see them in detail first you have to implement the algorithm in which we will be able to determine how good your algorithm is implementing it is a huge overhead  where you have to spend considerable amount of time experiments can be done only on a limited set of inputs you can run your experiment on a small set of instances and that might not really indicate the time that your algorithm is taking for other inputs  which you have not considered in your experiment  refer slide time  6  23  if you have two algorithms and you have to decide  which one is better you have to use exactly the same platforms to do the comparison platform means both the hardware and software environment because as you can imagine  different machines would make a difference  in fact even the users who are working on that system at that particular point would make a difference on the running time of an algorithm it becomes very messy  if you have to do it this way hence same hardware and software environments should be used what we are going to do in the part of this course ? in this very first lecture  we have to develop the general methodology  which will help us to analyze running time of algorithms we are going to do it as follows  first we are going to develop a high level description of an algorithm the way of describing an algorithm and we are going to use this description to figure out the running time and not to implement it to any system a methodology would help us to take into account of all possible input instances and also it will allow us to evaluate the efficiency of the algorithm in a way that it is independent of the platform we are using  refer slide time  7  38  pseudo-code is the high level description of an algorithm and this is how we would be specifying all our algorithms for the purpose of this course  refer slide time  8  23  here is an example of pseudo code and you might have seen this in earlier courses also what is this algorithm doing ? this algorithm takes an array a  which stores an integer in it and it is trying to find the maximum element in this array algorithm array max  a  n  the above mentioned example is not a program  because the syntax is wrong but it is a pseudo code which is a mixture of natural language and some high-level programming concepts i am going to use a for loop  do loop  if-then-else statement and a while loop but i will not bother about whether there should be a semicolon or a colon  because they are required for the compiler but for our understanding  what the program is doing is clear in the beginning it keeps track of the maximum variable in a variable called current max which is initialized to the first element of the array current max ? a  0  then it is going to run through the remaining element of the array  compare them with the current maximum element if the current maximum element is less than the current element  then it would update the current max a  i  becomes the new max and then when the loop terminates we would just return current max if current max < a  i  then current max ? a  i  return current max it is a very simple algorithm but just with this pseudo-code  you are able to understand what it is doing this will not run on any computer since it is the pseudo-code  but it conveys the idea or the concepts  refer slide time  8  48  thus pseudo-code is more structured than usual prose  but it is less formal than a programming language how pseudo-code will look like ? we will use standard numeric and boolean expressions in it  refer slide time  10  33  instead of the assignment operator which is ? = ? in java  i will use ? and instead of the equality operator  an equality relationship in java which is ? = = ? the same in c  i will just use ? = ?  i will declare methods with the algorithmic name and the parameter it takes algorithm name  param 1  param2  i will use all kinds of programming construct like if ? then statement  if ? then ?  else  statement  while ? do  repeat ? until  for ? do and to index array i will say a  i   a  i  j   it should be clear in what it is doing i will use return when the procedure terminates and return value will tell about the value returned by the particular procedure or a function returns  return value when i have to call a method  i will specify that with the name of the method and the argument and the object used calls  object method  args   refer slide time  11  22  object specifies the type of the value returned by the particular method you will see more of this  when we come across more pseudo-code how do we analyze algorithms ? first we identify what are the primitive operations in our pseudo-code what is a primitive operation ? it is a low level operation example is a data movement in which i do an assignment from one to another  i do a control statement which is a branch  if ? then ? else  subroutine call or return i do arithmetic operations or logical operations and these are called as a primitive operation ? data movement  assign  ? control  branch  subroutine call  return  ? arithmetic an logical operations  e.g addition  comparison  in my pseudo code  i just inspect the pseudo code and count the number of primitive operations that are executed by an algorithm let us see an example of sorting the input is some sequence of numbers and output is a permutation of the sequence which is in non decreasing order what are the requirements for the output ? it should be in non-decreasing order and it should be the permutation of the input  refer slide time  12  37  any set of numbers which are in non-decreasing order does not make an output algorithm should sort the numbers that were given to it and not just produce the sequence of numbers as an increasing order clearly the running time depends upon  number of elements  n  and often it depends upon how sorted these numbers are if they are already in sorted order then the algorithm will not take a long time it also depends upon the particular algorithm we use the running time would depend upon all these things the first sorting technique we use is the one that you have used very often let us say when you are playing game of cards  refer slide time  13  11  what is the strategy you follow  when you are picking up a set of cards that have been dealt out to you ? you like to keep them in a sorted order in your hand you start with the empty hand and you pick up the first card  then you take the next card and insert it at the appropriate place  refer slide time  14  45  suppose if i have some five cards in your hand already  let us say 2  7  9  jack and queen then i am getting 8  so i am going to put it between 7 and 9 that is the right place it has to be placed in i am inserting it at the appropriate place and that is why this technique is called insertion sort i keep on doing this  till i have picked up all the cards and inserted in the appropriate place let us see the pseudo-code for insertion sort i will give an array of integers as input and output is a permutation of the original numbers  such that it is sorted the output is also going to be in the same array a  1  a  2  _ a  n  this is the input  output specification i am going to have 2 variables or indices i and j the array is going to be sorted from a  1  through a  j-1   the element should be inserted at the location  which is the right place to insert clearly j has to vary from 2-n for j ? 2 to n do  refer slide time  15  43  i am going to look at element and i put that in key key ? a  j  i have to insert a  j  or the key in to the sorted sequence which is a  1  through a  j-1   i.e a  1_j-1  i am going to use the index i to do this what is index i going to do ? index i is going to run down from j-1 down to 1 we have to decrease index i  which we are doing in the while ? do loop it starts with the value j-1 i have to insert 7 and i am going to move 9 to location  because 9 is greater than 7 then i compare 7 with 8 and 8 is still greater than 7  so i will move it right then i compare 7 with 6 as 6 is smaller than 7  i would put 7 in the appropriate place i run through this loop  till i find an element which is less than a key key is the element which i am trying to insert this loop will continue while the element  which i consider is more than key and this loop will terminate  when i see an element which is less than key or the loop will terminate when i reach i = 0 while i > 0 and a  i  > key do a  i + 1  ? a  i  that means i have moved everything to the right and i should insert the element at the very first place and i am just shifting the element one step to the right do a  i + 1  ? a  i  note that i have to insert 7 at the right place  so i shift 9 right to 1 step location becomes empty  then i shift 8 to 1 step  so this location becomes empty and now i put 7 there i + 1 is the index  which would be the empty location eventually and i put the key there a  i + 1  ? key all of you can implement it may be you would have implemented it in a slightly different way  that would give you a different program  but the algorithm is essentially the same you are going to find the right place for the element and insert it let us analyze this algorithm  refer slide time  19  34  i have put down the algorithm on the left there is a small mistake in the last line of the slide  where there should be a left arrow please make a correction on that a  i + 1  ? a key let us count key ? a  j  i ? j-1 these are all my primitive operations i am comparing i with 0 and i am comparing a  i  with key  also i take and  so there are three primitive operations while i > 0 and a  i  > key each of the operation takes a certain amount of time  depending upon the computer system you have      just represent the amount of time taken for these operations and they can be in any units i am counting the number of times  each of these operations is executed in this entire program why this operation is done n times ? i start by assigning j = 2 then assign 3  4,5,6,7 and go up to n then when i increment it once and check that there is one more  so i have counted it as n times there might be small errors in n and n + 1  but that is not very important roughly n times we need to do this operation  refer slide time  19  34  how about this operation ? key ? a  j  i am going to do exactly n-1 times once for 2  once for3  once for 4 up to n that is why this operation is being done up to n-1 times just leave the comment statement again the operation will be done exactly n-1 times we have to look at how many times i come to this statement while i > 0 and a  i  > key  counts the number of times i have to shift an element to the right  when i am inserting the card in to my hand in the previous example when i am inserting 7  i had to shift 2 elements 8 and 9 is going to count that quantity and that is the number of times i am going to reach a  i  part of my while loop while i > 0 and a  i  > key i will be checking this condition for many times for one iteration or for the iteration of this for loop  i am going to reach this condition for times the total number of times i am saying that condition is the sum of as j goes from 2 to n while i > 0 and a  i  > key do a  i + 1  ? a  i  every time i see  a  i  > key  condition i also come to a  i   because the last time i see the statement i would exit out of this condition that is why this is -1 where j going from 2 to n a  i + 1  ? a key this statement here is not a part of the while loop rather it is a part of the for loop as it is done exactly n-1 times as the other statement if you knew about the constants then the total time taken by the procedure can be computed you do not know what is is quantity which depends upon your instance and not problem problem is in the sorting the instance is a set or a sequence of numbers that have given to you thus depends upon the instance let us see the difference that makes if the input was already sorted  then is always 1  = 1   i just have to compare the element with the last element and if it is larger than the last element  i would not have to do anything is always a 1 if the input is already in increasing order what happens when the input is in decreasing order ? if the input is in decreasing order  then the number that i am trying to insert is going to be smaller than all the numbers that i have sorted in my array what am i going to do ? i am going to compare with the element  element  element  element and all the way up to the element when i am trying to insert the element  i am going to end up in comparing with all the other j elements in the array in that case when is equal to j  note that the quantity becomes its summation of j  where j goes from 2 to n it is of the kind and the running time of this algorithm would be some constant time plus some other constant times n minus some other constant thus the behavior of this running time is more like  we will come to this point later  when we talk about asymptotic analysis but this is what i meant by  on the other hand in the best case when = 1  the sum is just n or n-1 and in that case the total time is n times some constant plus n-1 times some constant minus some constant which is roughly n times some constant hence this is called as linear time algorithm  refer slide time  24  36  on an average what would you expect ? in the best case you have to compare only against one element and in the worst case you have to compare about j elements in the average case it would compare against half of those elements thus it will compare with  even when the summation of where j goes from 2 to n  this will be roughly by and it behaves like  this is what i mean by the best  worst and average case i take the size of input  suppose if i am interested in sorting n numbers and i look at all possible instances of these n numbers  refer slide time  26  47   refer slide time  27  08  it may be infinitely many  again it is not clear about how to do that what is worst case ? the worst case is defined as the maximum possible time that your algorithm would take for any instance of that size in the slide 27  08  all the instances are of the same size the best case would be the smallest time that your algorithm takes and the average would be the average of all infinite bars that was for the input for 1size of size n  that would give the values  from that we can compute worst case  best case and the average case if i would consider inputs of all sizes then i can create a plot for each inputs size and i could figure out the worst case  best case and an average case then i would get such a monotonically increasing plots it is clear that as the size of the input increases  the time taken by your algorithm will increase thus when the input size becomes larger  it will not take lesser time  refer slide time  28  18  which of this is the easiest to work with ? worst case is the one we will use the most for the purpose of this course this is the only measure we will be working with why is the worst case used often ? first it provides an upper bound and it tells you how long your algorithm is going to take in the worst case  refer slide time  28  50  for some algorithms worst case occurs fairly often for many instances the time taken by the algorithm is close to the worst case average case essentially becomes as bad as the worst case in the previous example that we saw  the average case and the worst case were  there were differences in the constant but it was roughly the same the average case might be very difficult to compute  because you should look at all possible instances and then take some kind of an average or you have to say like  when my input instance is drawn from a certain distribution and the expected time my algorithm will take is typically a much harder quantity to work and to compute with  refer slide time  30  36  the worst case is the measure of interest in which we will be working with asymptotic analysis is the kind of thing that we have been doing so far as n and and the goal of this is to analyze the running time while getting rid of superficial details we would like to say that an algorithm  which has the running time of some constant times squared is the same as an algorithm which has a running time of some other constant times ,because this constant is typically something which would be dependent upon the hardware that your using = in the previous example  and would depend upon the computer system  the hardware  the compiler and many factors we are not interested to distinguish between such algorithms both of these algorithms  one which has the running time of and another with running time have a quadratic behavior when the input size doubles the running time of both of the algorithm increases four fold that is the thing which is of interest to us we are interested in capturing how the running time of algorithm increases  with the size of the input in the limit this is the crucial point here and the asymptotic analysis clearly explains about how the running time of this algorithm increases with increase in input size within the limit  refer slide time  32  20  let us see about the ? big-oh ? o-notation if i have functions  g  n  and n represents the input size f  n  measures the time taken by that algorithm f  n  and g  n  are non-negative functions and also non-decreasing  because as the input size increases  the running time taken by the algorithm would also increase both of these are non-decreasing functions of n and we say that f  n  is o  g  n    if there exist constants c and  such that f  n  c times of g  n   f  n  = o  g  n  f  n  c g  n  for n what does it mean ? i have drawn two functions the function in red is f  n  and g  n  is some other function the function in green is some constant times of g  n   as you can see beyond the point  c  g  n   is always larger than that of f  n   this is the way it continues even beyond then we would say that f  n  is o  g  n  or f  n  is order  g  n    f  n  = o  g  n    refer slide time  33  56  few examples would clarify this and we will see those examples the function f  n  = 2n + 6 and g  n  = n if you look at these two functions 2n + 6 is always larger than n and you might be wondering why this 2n + 6 is a non-linear function that is because the scale here is an exponential scale the scale increases by 2 on y-axis and similarly on x-axis the red colored line is n and the blue line is 2n and the above next line is 4n as you can see beyond the dotted line f  n  is less than 4 times of n hence the constant c is 4 and would be this point of crossing beyond which 4n becomes larger than 2n + 6 at what point does 4n becomes larger than 2n + 6 it is three so becomes three then we say that f  n  which is 2n + 6 is o  n   2n + 6 = o  n  let us look at another example the function in red is g  n  which is n and any constant time g  n  which is as same scale as in the previous slide any constant time g  n  will be just the same straight line displaced by suitable amount the green line will be 4 times n and it depends upon the intercept  but you ? re would be like the line which is blue in color so there is no constant c such that < c  n   can you find out a constant c so that < c  n  for n more than  we can not find it any constant that you choose  i can pick a larger n such that this is violated and so it is not the case that is o  n    refer slide time  35  55  how does one figure out these things ? this is the very simple rule suppose this is my function 50 n log n  i just drop all constants and the lower order terms forget the constant 50 and i get n log n this function 50 n log n is o  n log n   in the function 7n-3  i drop the constant and lower order terms  i get 7n-3 as o  n    refer slide time  37  01  i have some complicated function like 8 log n + 5 + n in which i just drop all lower order terms this is the fastest growing term because this has as well as log n in it i just drop  n term and also i drop my constant and get log n this function is o  log n   in the limit this quantity  8 log n + 5 + n  will be less than some constant times this quantity  o  log n    you can figure out what should be the value of c and  for that to happen this is a common error the function 50 n log n is also o    whether it is yes or no it is yes  because this quantity  50 n log n  in fact is 50 times always  for all n and that is just a constant so this is o    but when we use the o-notation we try and provide as strong amount as possible instead of saying this statement is true we will rather call this as o  n log n    we will see more of this in subsequent slides how are we going to use the o-notation ? we are going to express the number of primitive operations that are executed during run of the program as a function of the input size we are going to use o-notation for that if i have an algorithm which takes the number of primitive operations as o  n  and some other algorithm for which the number of primitive operations is o    then clearly the first algorithm is better than the second why because as the input size doubles then the running time of the algorithm is also going to double  while the running time of o   algorithm will increase four fold  refer slide time  39  10  similarly our algorithm which has the running time of o  log n  is better than the one which has running time of o  n   thus we have a hierarchy of functions in the order of log n  n     there is a word of caution here you might have an algorithm whose running time is 1,000,000 n  because you may be doing some other operations i can not see how you would create such an algorithm  but you might have an algorithm of this running time 1,000,000n is o  n   because this is some constant time n and you might have some other algorithm with the running time of 2  hence from what i said before  you would say that 1,000,000 n algorithm is better than 2  the one with the linear running time which is o  n  running time is better than o    it is true but in the limit and the limit is achieved very late when n is really large for small instances this 2 might actually take less amount of time than your 1,000,000 n you have to be careful about the constants also we will do some examples of asymptotic analysis i have a pseudo code and i have an array of n numbers sitting in an array called x and i have to output an array a  in which the element a  i  is the average of the numbers x  0  through x  i   one way of doing it is  i basically have a for loop in which i compute each element of the array a to compute a  10   i just have to sum up x  0  through x  10   which i am doing here for j ? 0 to i do a ? a + x  j  a  i  ? a/  i + 1  to compute a  10   i is taking the value 10 and i am running the index j from 0-10 i am summing up the value of x from x  0   x  10  in this accumulator a and then i am eventually dividing the value of this accumulator with 11  because it is from x  0  to x  10   that gives me the number i should have in a  10   i am going to repeat this for 11,12,13,14 and for all the elements  refer slide time  41.34  it is an algorithm and let us compute the running time this is one step it is executed for i number of times and initially i take a value from 0,1,2,3 and all the way up to n-1 this entire thing is done n times this gives you the total running time of roughly  a ? a + x  j  this one step is getting executed times and this is the dominant thing how many times the steps given below are executed ? a  i  ? a/  j + 1  a ? 0 these steps are executed for n times a ? a + x  j  but the step mentioned above is getting executed roughly for some constant times thus the running time of the algorithm is o    it is a very simple problem but you can have a better solution  refer slide time  43  19  what is a better solution ? we will have a variable s in which we would keep accumulating the x  i   initially s = 0 when i compute a  i   which i already have in s  x  0  through x  i-1  because they used that at the last step that is the problem here a ? a + x  j  every time we are computing x first we are computing x  0  + x  1   then we are computing x  0  + x  1  + x  2  and goes on it is a kind of repeating computations why should we do that ? we will have a single variable which will keep track of the sum of the prefixes s at this point  s ? s + x  i    when i am in the run of this loop has some of x  0  through x  i-1  and then some x  i  in it to compute element  i just need to divide this sum by i + 1 s ? s + x  i  a  i  ? s/  i + 1  i keep this accumulator  s  around with me when i finish the iteration of this loop  i have an s  the sum x  0  through x  i   i can reuse it for the next step  refer slide time  44  15  how much time does this take ? in each run of this loop i am just doing two primitive operations that makes an order n times  because this loop is executed n times i have been using this freely linear and quadratic  but the slide given below just tells you the other terms i might be using  refer slide time  46  01  linear is when an algorithm has an asymptotic running time of o  n   then we call it as a linear algorithm if it has asymptotic running time of  we called it as a quadratic and logarithmic if it is log n it is polynomial if it is for some constant k algorithm is called exponential if it has running time of  where a is some number more than 1 till now i have introduced only the big-oh notation  we also have the big-omega notation and big-theta notation the ? big-omega ? notation provides a lower bound the function f  n  is omega of g  n   f  n  =  g  n   if constant time g  n  is always less than f  n   earlier that was more than f  n  but now it is less than f  n  in the limit  beyond a certain as the picture given below illustrates c g  n  f  n  for n f  n  is more than c  g  n   beyond the point  that case we will say that f  n  is omega of g  n   f  n  =  g  n    refer slide time  47  51  in notation f  n  is  g  n   if there exist constant and such that f  n  is sandwiched between g  n  and g  n   beyond a certain point  f  n  lies between 1 constant time g  n  and another constant time of g  n   then f  n  is  g  n   where f  n  grows like g  n  in the limit another way of thinking of it is  f  n  is  g  n    if f  n  is o  g  n   and it also  g  n   there are two more related asymptotic notations  one is called ? little-oh ? notation and the other is called ? little-omega ? notation they are the non-tight analogs of big-oh and big-omega it is best to understand this through the analogy of real numbers  refer slide time  48  48  when f  n  is o  g  n   and the function f is less than or equal to g or f  n  is less than c  g  n   the analogy with the real numbers is when the number is less than or equal to another number is for and is for =   g  n  is function and f = g are real numbers if these are real numbers  you can talk of equality but you can not talk of equality for a function unless they are equal little-oh corresponds to strictly less than g and little-omega corresponds to strictly more we are not going to use these  infact we will use big-oh you should be very clear with that part the formal definition for little-oh is that  for every constant c there should exist some such that f  n  is < c  g  n  for n >  f  n  c  g  n   for n how it is different from big oh ? in that case i said  there exist c and such that this is true here we will say for every c there should exist an   refer slide time  49  12  the slide which is below defines the difference between the functions i have an algorithm whose running times are like 400n  20n log n  2  and  also i have listed out  the largest problem size that you can solve in 1 second or 1 minute or 1 hour the largest problem size that you can solve is roughly 2500 let us say if you have 20n log n as running time then the problem size would be like 4096 why did you see that 4096 is larger than 2500  although 20n log n is the worst running time than 400n  because of the constant you can see the differences happening if it is 2 then the problem size is 707 and when it is the problem size is 19 see the behavior as the time increases an hour is 3600seconds and there is a huge increase in the size of the problem you solve  if it is linear time algorithm still there is a large increase  when it is n log n algorithm and not so large increase when it is an algorithm and almost no increase when it is algorithm if you have an algorithm whose running time is something like  you can not solve for problem of more than size 100 it will take millions of years to solve it  refer slide time  50  52  this is the behavior we are interested in our course hence we consider asymptotic analysis for this 