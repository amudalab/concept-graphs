introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  1 basic principles of counting  refer slide time  00  14  so  we will be talking about the course on probability theory and its applications somehow  when you utter the word probability to a layman  it does not sound very familiar or you know  one does not feel very comfortable with it but my attempt in this course would be  that at the end of the course you feel  that you can understand what all goes behind computing the probability of an event so  basically probability theory is estimating the possibility of outcome of an event so  this word possibility  that what are the  how possible  how probable the event is  is actually done by counting and so therefore  before i start giving you axioms of probability theory  i would like to begin with the basic concepts of counting because that helps you in estimating the possibility of the occurrence of an event and i will try to explain what we mean by an event and so on so  as we go on  hopefully  that you will understand all these terms so  let me just begin by  so therefore  the first topic i am going to talk about is counting and i will start with an example so  suppose there is a small community  which consists of 12 women and each of whom has 2 children now  if one women and one of her children  so it has to be the pair  a women and her child so  if the pair has to be chosen as mother and child of the year  how many different choices are possible ? so  let us just  very simple way of counting so  what i am saying here is  that first experiment would be number of possibilities of the  first experiment would be choosing the mother out of the 12 women  we choose one of the woman as the mother of the year and so the number of possible outcomes is 12 because there are 12 women and one of them will be appointed or chosen as the woman of the year and then we will  so second experiment would be selecting one of her children as the year as the child of the year so  once you have chosen the mother of the year  then she has 2 children so  only one of them can qualify to be the year of the child  i mean  child of the year so  therefore  the possible outcomes are 2 so  then we say  that the total number of choices is 24 so  i sort of broke up this event  though i will call it event of choosing the mother and child of the year by first saying that i will chose the mother  and then one of her children would be chosen as the year  child of the year  right so  therefore  the number of choices are 24  right  refer slide time  03  17  so  if  if now i want to sort of formulate this into the basic principle of counting  then the basic principle says that if there are two experiments to be performed and experiment 1 results in any one of impossible outcomes so  i have way of finding out  that whatever my first experiment and the possible outcomes of that event are m so  for example  here my first experiment was choosing the year  mother of the year and since there are 12 woman  out of which i have to choose the mother of the year so  there were 12 possible outcomes of this experiment any of the 12 women could have been chosen as the mother of the year so  the first experiment results in m possible outcomes now  for each outcome of experiment 1 that means  for each possible outcome  each of the m possible outcomes here then i want to know what are the possible outcomes of the second experiment ? so  in that example mother had 2 children so  it could only be one of the 2 children who would be chosen as the mother of the year so  now here we will say  that if for each outcome of experiment 1  there are n possible outcomes of experiment 2  then together there are mn possible outcomes of the 2 experiments  right so  i hope this  once you understand this basic principle  of computing  of counting  then you know  things become simple because you have to first  first find out what are the possible outcomes and then we will talk about  when we define the concept of an event  then we will try to find out in how many ways that particular event can occur so  here the total number of this thing are this now  if you want to generalize this concept of counting  so this will be generalized basic principle of counting and here  we will now say  that suppose i have r experiments  which could be 1  2  3 and whatever the number and then again we will start saying first one  the first experiment results in n 1 possible outcomes so  the first experiment results in n 1 possible outcomes now  for each possible n 1 outcomes of the first experiment  right  for each possible n 1 outcome of the first experiment there are n 2 possible outcomes of the second experiment  right and then the third stage we will then count for each possible outcomes of the first two experiments  right  because two experiments have taken place so  for each possible outcome of the first and the second  that means  now you have n 1 possible outcomes of the first experiment  n 2 for each of the experiment outcome here  you have n 2 possible outcomes so  total number of outcomes become n 1 n 2 now  for each possible outcome of n 1 and n 2  the third experiment  if possible  outcomes will be n 3 and so on so  you will go on counting this and therefore  by a simple arithmetic you can see  that the total number of possible outcomes would be n 1 into n 2 into n r that means  at each  for each experiment whatever the possible outcomes  you will multiply them all so  this gives the generalized principle of computing  refer slide time  06  25  so  let us look up at this example  example 1.2 how many 8 place license plates are possible if first four places are to be occupied by letters and last four by numbers ? that means  the first four can be any of the alphabet a  b  c  d so  there were 26 choices for the first  for first four places and then for last four have to be the numbers so  which means  there can be any of the digits 0  1  2  up to 9  right so  now again  as i quoted the generalized principle of counting  so number of the first experiment would be choosing the first place of the license plate  right so  then i have 26 choices because 26 alphabets are there then  again  for each of the alphabet i choose here  for each of the 26 alphabets i choose here  i can again choose the 26 alphabets again  right if i have a letter a here  for example  then i can choose any of the a  b  c  d  26 alphabets here so  again the next outcome  that means  the outcome for each outcome here  there are again 26 choices of the second experiment and so on so  again for the third that means  now once have chosen the first 2 alphabets here  then again for any each of these outcomes  26 into 26  i can again choose in the third place any of the 26 alphabets so  then the third choice is again the number of possible outcomes are the number of choice  choices are 26 and same  the same argument goes for the fourth place and similarly  for the numbers i have chosen 1 of the 10 numbers here then  again after having chosen all these  i can again choose any of the ten numbers here and then in the third place also any of the ten numbers and so on so  this will be and you can just see  i have left a question mark for you to compute the number it will be a big number so  this many license plates can be there if you have this kind of arrangement that the first four places have to be occupied so  it is eight letter license plate number and so the first four places have to be occupied by alphabets and the last four by digits  right now  if i change the experiment and i say  that repetition of letters and numbers is not permitted so  the moment i say that once i have chosen a letter here  then the same letter will not be repeated here  here or here so  then by a way of counting will be this now  for the first place i have any of the 26 choices  any of the 26 letters can be chosen here but once i have chosen a letter here  then that same letter is not permitted to be chosen here so  now  my choice at for the second experiment for every possible outcome here  goes down to 25 because whatever alphabet i have chosen here  i can not chose it again so  therefore  my choices here are 25 and once i have chosen alphabet for the first place and the second place 2 alphabets have been selected  then both these are not allowed to be chosen again so  therefore  my choice for the third place would come down to 24 so  out of 26  two letters have been already chosen and they are not allowed to be chosen again so  this would  choice will be 24 and then similarly at the fourth place i will be having a choice of 23 so  if you just keep using this generalized principle of counting  which i enumerated sometime ago  then you see  this is how you will  right  done the possible outcomes and similarly  for the numbers  for the first place i will have choice of 10  but once i choose a number here  then my choice is limited to 9  and after this again i can only choose out of the 8  which are not repeated  which have not been already be chosen and similarly  for the fourth place my choice will be left limited to 7 numbers  which have not been repeated so  this is the kind of … so  the generalized principle of counting helps you to come out with the possible number of outcomes of an experiment  right  or event here what we want to say  because this was  as i am counting  i am saying this is eight experiments choice of each letter for each place of the license plate and the choice of number i counted as experiment so  had eight experiments here and used the generalized principle of counting to find out the possible number of outcomes right  refer slide time  11  00  now  another possible another way of counting is done by through permutations and combinations  and let me now here try to explain the difference between permutations and combinations so  here let us say  we have collection of 3 novels and so i will just say  that authors are a  b and c  then 2 mathematic books and again i will distinguish them or differentiate them by the authors and call the authors as d and e and one physics book now  i will call the author as p so  there are 6 books and since i am distinguishing books by the authors  so it is not just novels  i am saying  that the  i mean the authors are a  b and c so  they are different novels i am distinguishing similarly  i am differentiating between the 2 mathematics novels and of course  there is one physics book so  the question is how many arrangements are possible if the books are to be distinguished by the authors so  i am  i am wanting to make arrangements of these books and arrangements would be  would be differentiated because the  i will be  i will be referring to the books by the authors so  it is not just novels or a mathematics book so  therefore  possible arrangements  now here again let us just say that we are  yeah  ok  right so  here that means  in the first place if we now count the thing  that means  i can  i can say  that there are 6 places  right so  now  the choice for the first place  that means  i am just arranging the books like this in a line  in a row  suppose so  the choice for the first place would be any one of the 6 books  right  because i am differentiating the books by the author so  therefore  for the first place the choice is 6 books once a book is placed here  then there will be 5 more left  right i am saying again so  therefore  out of the 6 experiments i am just saying what are the possible outcomes so  once i have chosen 2 books here  then i am  i am left with picking out the book for the 3rd place from among the remaining 4 books and then 3  2 and 1 so  the total number is 6 factorial  which is 720  right now  these 720 arrangements are known as permutations of the 6 books and the permutation word is essentially saying  that the permutations are the ordered arrangements of the books now  ordered  i mean  that if i am writing  say for example  ordered arrangement  i want to say ordered arrangements so  if i am writing here  say it could be  that i am  right  i have chosen all the 3 novels here  right and then of course  let us say  mathematics books you have d and e so  it may be  you have this and you  right now if i have the order b arrangement  b a c e d p  then you see this arrangement is different from this because now here is the 2nd author  if we call the book by b as 2nd novel  then the 2nd novel is occupying the 1st place and this is 1st  the novel by the 1st author is occupying the 2nd place so  here the arrangement and therefore  this  this order is also considered here in this arrangements and therefore  i will say  that this is different from this order  this arrangement is different from this order  that arrangement b a c e d p so  this is the idea  that 720 permutations are the ordered arrangements of the 6 books and so how you place them depends on  that means  i am distinguishing between which author is occupying the 1st place  which author is occupying the 2nd place and so on so  therefore  this way it will be 720 but if you do not distinguish between the  if you do not distinguish between the authors  that means  i just treat the 3 novels as novels and in that case  this and this arrangements would be the same  and right and in fact  you can see how many possible arrangements see  i can have here c a b e d p now  you can tell me 3 more because these 3 letters  a  b  c themselves  i can arrange in 3 factorial ways  that will be 6  6 ways i can arrange these 3 and therefore  all those arrangements  once if i do not consider the  i distinguish  do not distinguish between the 3 novels by the authors  as long as they are just novels  then that arrangements  all those 6 arrangements will be counted as 1 arrangement  refer slide time  16  08  so  when we are looking at the arrangement of the books  the novels  3 novels  2 maths books and 1 physics book so  once we do not order  we do not worry about differentiating the books with respect to the authors in that case  you see  as i tried to show you  that the 3 novels  since they will not be distinguished by the authors  so then for every arrangement  for every arrangement in which only the arrangement of the  arrangement of the author has been changed  the other books remain the same in that case  6 of those arrangements will amount to 1 arrangement because the 3 novels can be arranged in 6 different ways and if i leave the math books and the physics book intact  then all 6 arrangements in which only the arrangement of the novels have been changed  then those 6 arrangements will amount to 1 arrangement and similarly  corresponding to each of those  if i leave everything intact and only disturb the arrangement of the math books  then since i am not differentiating between the author  those arrangements will not be different because that 2 math books  whether the author d or e  whichever comes first does not matter to me so  in that case  i will then divide so  that means  when i am counting the arrangement where the order is not important and that comes out to be 6 factorial is  was the arrangement  total number of arrangements where the order was important but if i do not care about the order  that i mean  i do not distinguish between the authors  in that case the arrangements will become 60 so  this is what now i am trying to come to so  the permutations  the order was important and then i had total number of permutations that means  that the order of the objects was also being considered right so  now  the general principle  that i am trying to   refer time  18  08   that in general  number of arrangements of n objects  where n 1 are alike  n 2 are alike  and n are alike  n r are alike  that means  there are only r different kinds of objects and since  so therefore  surely here n 1 plus n 2 plus n r adds up to n  right so  have n objects but n 1 of them are the same  then n 2 are alike and similarly  n r of them are alike and in that case  when i am wanting to make  arrange the n objects  then the total number of objects would be  because n factorial would be the arrangements of n objects when i am distinguishing between each of them  right  whatever the way of distinguishing the object  whatever it is so  that would the total arrangement but since i had tried to show you through this example of arranging the books  that if n 1 are alike  then those n 1 can be arranged in n 1 factorial ways and they will amount to the same arrangement because i am not differentiating between the order so  therefore  i will divide this total number of arrangements here by n 1 factorial  n 2 factorial and n r factorial so  that will give me the total number of  so that becomes the number of combinations well  that means  arrangements where the order is not important would be the number of  total number of combinations now  let us look at this example so  a tennis tournament has nine competitors  competitors so  and then 3 from india  2 from japan and 4 from malaysia now  if the results of the tournament are announced by nationalities of the players in the order in which they are placed so  it is not  you know  you are not distinguishing the place by the names  only their nationality is being considered in that case  3 from india would be just 3 indians and it does not matter which one gets the first position  third position or whatever it is so  here it will be just all the 3 players would be considered the players from india so  another way of looking at it is  that you can think of these people as one entity because they  they are just representing the same country so  similarly 2 from japan would be just distinguished by their nationality and not by their names and 4 from malaysia  refer slide time  20  54  so  therefore  if you want to now find out how many such lists are possible  that means  what  what is the arrangement of the position  that these 3  the players from the 3 nationalities occupying in your list  first  second  third  up to there will be 9 positions so  then the total number of lists  that you can have would be 9 factorial so  9 is the total number of players and if i was going to distinguish them by the names  in that case  they would have been 9 factorial arrangements of the way in which the order  in which players would occupy position in the tournament but since we are not considering the names  we are only considering the nationalities so  for example  we then divide this number by 3 factorial  4 factorial and 2 factorial to get the total number of lists so  the 3 indians can occupy any of the positions and they will be the same so  that means your 6  6 lists in which if 3 indians were occupying different positions in the sense  that i just arrange  rearrange the position  that are that means  3 indians  if they just appear see  suppose you consider the 1st position  2nd  3rd  4th  5th  6th  7th  8th  9th  same thing so  if this was indian  this is an indian and let us say  this is an indian  right now  what are the 3 names ? if i see  if you had a name  here is the indian 1  indian 2 and indian 3 then  i can have indian 2 here  indian 1 here  indian 3 here and this way you can go on  right indian 2  indian 3  indian 1 and just see  that you can write  you can rearrange these 3 in 6 possible ways so  other arrangements will be the same but if these 3  i can arrange in 6 different ways  but for me they are the same because in my list it will appear as i  i  i  i  i  i so  this will not be there  right so  all these arrangements will be the same and so all these 6 arrangements will account to same therefore  i am dividing this number by 3 factorial and similarly  for the 2 from  i mean  sorry  here  in this case here  that was the example for the books so  here i am dividing this number by 3 factorial  4 factorial and 2 factorial to get the possible number of lists so  just trying to make the concept of counting clear  so that you can  then you know  when you have to compute the possibility of the occurrence of an event  all these things will come in handy so  now again  i am trying to enunciate this principle  that if you have a collection of n objects  in how many ways can we select r objects that is again the same thing because you can say  that you can put the n objects in a row and then you are picking up r out of them so  that  that is the different arrangement this is another way of saying the same thing  right so  here  by your principle of counting  when you have  you can say  that you have arranged all these n objects in a row and then you are picking of one of them so  then for the first place  that means  when i want to pickup r objects from this list of n objects  the first object  there are n possible ways of selecting the first so  we are counting the same thing again by a different way so  here you have n ways of selecting the first object then  since you have already selected the first object  you are left with now n minus 1 ways of selecting the second object  right and similarly  it goes on depleting and finally  for the rth object that you want to choose  you are left with n minus r plus 1 because you have already selected r minus 1 objects so  n minus r minus 1  this is the number so  this many ways you can select the rth object  right now  since it does not matter again because i am not distinguishing between the r objects  that means  the order is not important once you see  out of these n objects i have collected r objects so  it does not matter which one came out first  which one came out second  as long as the set of objects is the same so  that means  my way of selecting may have been  you know  because i picked  when i picked up the 1st object  that counted in the 1st object  2nd and 3rd  so on but then finally  what i have with me is the set of r objects and it  though in  in that set the 3rd or the 4th object could have been selected 1st  does not matter  right so  therefore  what we are saying is  now you have n minus r plus 1 so  that means  the total number i should have written the number here  let me write somewhere here so  the order is  when the order is immaterial  i am saying  that this is  let me  let me just write it here so  that means  what i am saying is  that the first object i could pick in any of the n ways then  for the second object to pickup i had only n minus 1 choices available with me and so on  up to n minus r plus 1  right so  this number and since what we are saying is  that the  it was not important the order in which the r objects were selected  it is only the final subset of r objects  that i have with me so  therefore  i will divide this by r factorial and so you can  right this number  you see  if you have up to this  this number  you can write as n factorial divided by r factorial n minus r factorial so  this is the final so  that means  this is the number of combinations i can have  because by selecting r objects i can call an arrangement  that was here that means  the n objects that i have  i pick up r  i put them first and then the remaining n minus r so  essentially the r objects  that you pick  it does not matter in what order you pick so  therefore  the total number of ways in which i can arrange my n objects gets divided by r factorial and obviously  the last n minus r objects also the order is not important because finally  you have divided these n objects into r n n minus r  right so  it is simply  which r objects get selected  it does not matter in what order they got selected so  therefore  the total of number of ways in which you can pickup r objects from n objects would again be given by this number and i would  normally we say n choose r this is the notation for this number n factorial divided by r factorial n minus r factorial so  this is n choose r  refer slide time  27  36  so  again let us take up an example so  a jury of 7 is to be formed from a group of 30 people  how many different juries can be formed ? so  just carry over what we discussed just know so  there are 30 people and you have to pick up 7 people from this set of 30 people  which will form a jury  right and so we want to know how many  the question is how many different juries can be formed so  this is like we discussed  n objects  you want to pickup r objects from there and how many ways are there  how many possible combinations are there  that is what we are looking at so  obviously  you can see  that the number of juries would be so  first  first person in the set can be chosen out of the 30 people then  once you have chosen that person  you are left with 29 choices and again  after these two you are left with 28 and so this number is 24 and now  what we are saying  that it was  it was not at all important as to when we have selected the 7 people since it is the subset of 7 people  it does not matter which one of them got selected first so  the order is not important it is only  that finally i have this subset of 7 people so  therefore  7 we will have to divide by 7 factorial to get the possible number of juries because this 7 set of people that you are forming the jury  you are not looking at when the first  when the  in what order they got selected  that is not important  right that is what i am emphasizing again and again  that here the order of selection is not important  it is just that you want a subset of 7 people and therefore  this will be the total number of arrangements and so here with this number we can write  because this is up to 24 remember  this is n minus r plus 1 so  here your n is 30 and your r is 7 so  when you want to divide  from 36 you are left with 24 and so this is the total number if it was important as to in what order people got selected for the jury so  it is not important  it is not being considered  it is immaterial so  therefore  i divide the 7 factorial  then this number can be written as 30 factorial divided by 7 factorial into 23 factorial  which by our notation is 30 chose of 7 now  in case the group of 30 consists of 10 women and 20 men and if it is required  and if it is required that 2 women and 5 men should form the jury so  now  we are saying  that out of 10 women 2 must get selected and out of the 20 men 5 men should get selected to form the jury so  in that case the number of groups of women that you can form out of  you know  by choosing 2 out of 10  this will be 10 chose 2 here  again the order is not important i just want to form  select subset of 2 people  2 women from out of the 10 so  that will be the total number of ways in which i can select the 2 women from the 10 women and similarly  i can  20 choose 5 is the number of ways in which i can select 5 men from the set of 20 men and so the total number would be  because for each subset  that i chose here of women  there will be this many so  i am now using here by generalize principle of counting and so the total number of ways in which i can  the number of juries of 2 women and 5 men can be formed is this so  just through examples i am trying to make the concept clear  refer slide time  31  23  and now  let us see  that you can  all of you have used binomial theorem and you know  that if you want to express  if you want to expand this number x plus y raise to n  then the formula is n choose k x raise to k y raise to n minus k  and you have done it by induction and so on  the proof now  let me give you this combinatorial proof of binomial theorem using this concept of counting  that we have learnt here we can use this and show  that the expansion of this term can be written in this way and so let me consider the product x 1 plus y 1 into x 2 plus so  there are n terms here  right now  when i am multiplying each term here  final in the product would be consisting of n factors  factor of n of the x i ’ s and y j ’ s  that means  each term of this  project  product will contain  when you count the number of x i ’ s and y j ’ s  that total number would be n because you have n factors  right but certainly  in any factor when you look at the x i ’ s and y j ’ s  if the  if an x i appears  then in the same index will not be for y because you see  x 1 and y 1 are in the same term here so  therefore  when i multiply  either i will be multiplying x 1 by the other terms and so then y 1 will not appear in that  right so  therefore  in any product  the x i ’ s and y j ’ s that you have  if an x i appears  the corresponding y j will not appear in that product  right so  in other words what i am saying is that the any term of this product  which will contain  let us say  k of the x i ’ s and then the remaining n i n minus k of the y j ’ s would be such that so  you are choosing  essentially  each term here would contain  let us say  when i am looking at the term containing only k of the x i ’ s and so remaining n minus k or y j ’ s so  then how many ways can be there ? how many such products can be there in which so  you know this is containing the each term in this product has n factors containing x i ’ s and y j ’ s so  then if i am looking at all the terms  which contain k of the x i ’ s  right  then that means  i am out of the x 1  x 2  x n  these n x ’ s i am choosing k of the x i ’ s  right and then of course  the moment i choose my k x i ’ s  then the y j ’ s got to the n minus k y y k ’ s  y j ’ s got  get select automatically because in the ones  which are not appearing in my x 1  x 2  the product x i ’ s that i have now taken  now remaining indices will be  will go to the y j ’ s right so  here  that means  and that was the way of choosing k x i 's out of the n x i ’ s x 1 x 2 x n in n choose k  right so  therefore  the number of terms  which contain k of the x i ’ s is this many terms and so this whole product  either what will happen  say for example  if you look at it  product y 1 y 2 y n  no x i appears so  either  so the k can vary from 0 to n the terms will contain either 0 x i ’ s  then 1 x i  2 x i ’ s and so on so  you want to add up all such things you are counting the total number of terms in this product and that total number will be given by summing up n choose k from 0 to n and when you choose like this  then that means  your k of the x i ’ s are here and n minus k are you are adding up  right so  these things  then i put  put of x i equal to x for all i and y j equal to y for all j so  in that case  your k of the x i ’ s  that you took from here  they all become equal to x  x raise to k y raise to n minus k so  then therefore  this product and when once you put the x i ’ s together equal y i ’ s are together  then this whole product coincides with this and so you have a nice way of  you know  proving the binomial theorem now  i can  immediate application of this is  that if you want to count  you know  have n objects and you want to count how many subsets can be there of these n objects  you  when of course  the empty also be considered as a subset that means  nothing gets chosen from the n objects so  you have subset consisting the empty set then  you can have subsets consisting of only one element from one object  from these n objects  subset containing 2 objects  3 objects and so on so  if you want to count the total number of subsets  that you can form of this n objects  then since i told you  that n c k gives you the number of subsets of size k  right  and so you want to count this number n c k from k varying from 0 to n and which  if you look at this expansion here  essentially of putting x is equal to 1 and y is equal to 1  so that this all becomes 1 and so you are summing up on this side when you put x is equal to 1 and y is equal to 1  this reduces to 2 raise to n so  the total number of subsets this is another nice way of counting the number of subsets that you can form  given n objects  refer slide time  36  52  so  extending this concept that i just enumerated for you for the binomial theorem  now we can take over  go up to multinomial coefficients so  this is a set of n distinct objects is to be divided into r distinct groups of sizes n 1  n 2  n r for the binomial theorem  r was 2 so  now it is n 1 plus n 1 n 2 n r where of course  all the n i ’ s adapt to n so  i am dividing this n objects into r sub groups and the size of each group  the first sub group is n 1  size of second group is n 2 and so on  right so  then using the same principle i want to choose form n  n 1 possible groups so  the number of possible groups of size n 1 is n n 1  n n choose n 1  right are you also  this is  actually this is also written as n c n 1 so  combinations  so n 1 combination  that means  you want to choose n 1 objects out of n so  what are the possible number of ways ? so  any of these notations is acceptable  fine so  the first group will be  the number of groups of sizes n 1 would be n choose n 1 then  since i have already chosen n 1 objects out of n  so then i want to choose the second set of objects  n 2 consisting of the set of objects must be n 2 in size and then so  out of n minus n 1  i want to choose n 2 so  therefore  each group of size n 1  the number of choices of the second group is n minus n 1 choose n 2  right and so you extend this concept and so finally  the last choice would be  because now you will be left with n minus n 1 minus n 2 minus n r minus 1  r minus one subsets r sub groups have already been chosen so  then these many  you are left out of this  you want to choose n r objects so  again the number of possible ways is n minus n 1 n 2 minus n r minus 1 choose n r right and so  we will say  that the total number of groups is the product of all these  right and so via notation this would  well the first one would be n factorial divided by n 1 factorial n minus n 1 factorial then  the second one would be n minus n 1 factorial divided by n 2 factorial n minus n 1 minus n 2 factorial and so on so  if you see  that this will be my total expression and then the terms cancel out because you have n minus n 1 factorial here and this is n minus n 1 factorial so  it cancels out so  these terms will cancel out  you know  in pairs and so in the denominator you will be left with n 1 factorial  n 2 factorial and n 3 factorial up to n r factorial and this is what  again what we are saying is  that we are deciding whatever objects we have  putting in one group we are saying they are all alike  the same principle you are using and so we  the arrangements will not matter in whatever way you choose  in whatever order you choose  it is immaterial so  therefore  again i am  i can arrange my possible objects  n objects in n factorial ways but since i am  i am grouping them into r different sub groups and each group  the number of objects is  we are not differentiating between the objects in one group so  then the total number of ways would be n factorial divided by n 1 factorial n 2 factorial and n r factorial  right  refer slide time  40  38  and now  this helps us to expand the examples this gives the multinomial theorem  that if you want to expand x 1 plus x 2 plus x 3 plus x r raise to n  then it will be  because remember  in this product  just as i showed you for the binomial theorem  you want to choose so  because each product here will consist of some powers of x 1  some powers of x 2  some powers of x 3 and x r and so here i am now saying  that this n 1  n 2  n r will vary from  because every product here will contain 0  x 1  1 x 1  2 x 2 to 2 x 1 and so on and different that means  whatever the powers  each term here you can see in the  in the product this term will appear and so your n 1 plus n 2 plus n r must be … because each term  this is raise to n so  each term in this expansion will contain n x i 's together that means  you add up the indices of x 1  x 2  x r  they should add up to n and that is what is given by this  right so  therefore  using this concept this is how you can write the expansion  right and if you look at this example  where x 1 plus x 2 plus x 3 raise to 3  then you see  i can choose my n 1 to be 3 so  that means  this subsets contains just the power of x 1  powers of x 2 and x 3 are missing here  right so  therefore  the expansion  this is 3  3  0  0  x 1 raise to 3  then here again you are choosing a subset from 3  which consists only of powers of x 2 so  0  3  0 and so it will be x 2 3 so  i showed you the  you know the idea behind this and then now i am using it repeatedly to say that how i can write the expansion of this  right and so therefore  you can see  that the way i can choose my numbers n 1  n 2  n r so  if they add up to n  so in the case when you have your r is 3 and your n is also 3  so then these numbers must add up to 3  right you are dividing your number 3 in three possible ways  so that they add up to 3 so  here these are the possible  right and the final thing is 3  1  1 when each x 1  x 2  x 3 has only power 1 so  this is the expansion and now  in  in  in the assigned exercise sheet  that we will just show you i am asking you how many terms are there in the  in the multinomial expansion and remember  because which is actually counting number of subsets  right  here essentially accounting the number of subsets  which you can have  you know  like you have r  this thing here x 1  x 2  x 3  x r so  essentially my question is how many terms there in this expansion and so i have already discussed this case with you for the binomial  how i use for answering the number of subsets of  total number of subsets of n objects so  here you have to use the same concepts and tell me how  how many terms are there in this multinomial expansion so  let me just show you the  discuss the exercise sheet  refer slide time  44  11  question 1 is straight forward  18 workers are to be assigned to 18 different jobs so  the important part here is  that each job is different from the others and therefore  this will be ordered arrangement of the 18 workers so  you can write down how many possible assignments are possible that means  an assignment would mean  that you assign one particular worker to a particular job so  then in how many ways you can do this is the idea here  right now  consider a group of 25 people if everyone shakes hands with everyone else  how many handshakes take place ? so  that means  that persons shakes heads with another person  then both have shaken hands with each other so  just keep that in mind and you can immediately write down what the answer will be for number 2 now  here in question 3  four separate awards it can  it can be  you know  somebody getting the highest marks  highest cumulative performance index  best sports man  leadership quality  etc so  you can have 4 different awards given to these  to the students the idea is to select from a class of 36 students  students who can be given this award now  in case student can receive any number of awards  then it will be different number of arrangements  that you can have or different ways in which 4 awards can be given to student or more than 1 student in number 1 the condition is  that the students can receive any number of awards so  you have to do a counting that way in number 2  we say  each student can receive at most one award so  that means  either a student receives an award or student does not receive an award so  this  this is the way you have to count now  question 4 is interesting using combinational argument prove  that n chose r that means  selecting r items from n items is equal to selecting r minus 1 items from n minus 1 plus selecting r items from n minus 1 so  you can  if you write down the expression for n minus 1 chose r minus 1 and plus n minus 1 chose r  you can show  that these two add up to n chose r but i want you to give a combinatorial argument and you can see here  in the first term it says  n minus 1 chose r minus 1 that means  i am keeping away one particular object or item from the n that are there then  i am selecting r minus 1 so  that means  the first set of numbers  n minus 1 chose r minus 1 gives you the number of ways  which you can pick up  r minus 1 objects from n minus 1 when a particular object is being selected so  when you add that to this selected group  then it will become r object from n objects now  the second says  that n minus 1 chose r that means  that particular  see the thing is  either a particular object or item  that you have picked is either there in a collection of r objects or it is not there so  the first case says  that yes  it is going to be collection of r objects so  once you add it to the set of r minus 1 objects that you have selected  then it becomes r in the second one  what you are saying is  this is a set of  this is a set of selections in which that particular object does not appear so  you have separated that objects and then from the remaining n minus 1 you are choosing r so this is a kind of combinatorial argument you are giving to prove the identity and so you see  i have already shown you  that you can  by combinatorial you can give  show  you prove the binomial theorem now  similarly you can try to prove number of such identifiers through combinatorial arguments then  question 5 we have already discussed in how many ways can r objects be selected from a set of n objects if the order of selection is to be considered ? so  question 6  one delegate each from 10 countries that include delegates from india  pakistan  bangladesh and sri lanka are to be seated in a row so  the arrangements have to be row delegates from india and sri lanka are to be seated next to each other and delegates from bangladesh and pakistan are not to be seated together  how many seating arrangements are possible so  the idea here is  that you know  you  you have 10 different positions  people are sitting in a row and you want people delegates from india and sri lanka to be seated together  right  which means  that i can treat those two as one person in that case  it will be 9 people  then who have to be arranged because delegate from india and delegate from sri lanka have to be together so  that means  the total arrangement is 9 factorial but since the people are sitting in a row  that means  the arrangement  that first the indian delegate is sitting and then the sri lankan  or the sri lankan delegate is sitting first and then the indian  so this will count as the two different arguments and therefore  the total number of arrangements would be 2 into 9 factorial in which the delegates from india and sri lanka are together now  you do not want people  delegates  bangladesh and pakistan to be sitting together so  now again consider the situation when they are sitting together so  we will subtract the number of … so  in that case  now look at the arrangements in which delegates from india and sri lanka are together and delegates from bangladesh and pakistan are together then  you know  you will have 8 different positions to arrange because these 2 delegates will be together that means  they can be treated as 1 person  right  and therefore  it will be  total number of arrangements will be 8 factorial but then again you have to  it can be 2 possible  you know  like as i told you  the arrangement can be india-sri lanka or sri lanka-india similarly  it can be bangladesh-pakistan  pakistan – bangladesh so  therefore  essentially you will be subtracting from 2 into 9 factorial  the number of arrangements in which all the four  i mean  delegates from bangladesh and pakistan are together and delegates from india and sri lanka are together so  that will be 2 square into 8 factorial and so you subtract this number from 2 into 9 factorial  that should give you the required number of people  number of ways in which you can have the required arrangement how many terms are there in multinomial expansion of x 1 plus x 2 plus x r raise to n ? so  here again i am wanting you to do this exercise see  the whole idea  either way i explain to you this expansion was  that you are essentially dividing your number n into r smaller numbers  n 1  n 2  n r   refer time  51  18   sum up to n so  in how many ways can you partition this set of n number into r subsets  so that they all add up to n this is the whole idea and so you will see  that from this identity x 1 plus x 2 plus x r raise to n you have to put all these x 1 x 2 x r equal to 1 and so you get r raise to n is equal to the number of terms that appear in the expansion  multinomial expansion of this term  right then  finally  a total of 6 gifts are to be distributed among 9 children  so that no child receives more than one gift this is exactly the same as  you know  in part 2 of 3  right  because here also we said that no student should get more than one award  should get at most one reward  award and so here also we are saying  that the total of 6 gifts are to be distributed among 9 children  so that no child receives more than 1 gift  ok introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  2 sample space events axioms of probability  refer slide time  00  17  so  today i will talk about axioms of probability so  i start talking to you about developing the theory of probability  and here to begin with this  first it is very necessary to discuss basic concepts and notations of set theory so  i will begin with the concepts of set theory and give you some notations  and then after that  it will be possible to define the axioms and then build the probability theory based on these axioms  okay now  of course  a set you have already been using this word  and so i will just formally write down that a set is a collection of objects  points  whatever you may consider  whatever the collection  and this can be finite or infinite ; the number of elements of the set may be finite or infinite so  enumerable examples  now if you have to consider a town with its population  then  obviously  the people living in the town would be a finite number so  that will be a finite set  and if you consider a set in r 2 which is bounded by a closed curve and then if you consider all the points in this set and they will finite ; in fact  they are not even countable  right so  a set in r 2 bounded by so  this will be infinite set and so on now we will always refer to when i develop the concepts of set theory  there will be a universal set which i will refer to as omega and then we will take subsets of omega and define all the possible ; whatever the operations we can do on this set of subsets of omega  right now definition 2 point 1 ; for two sets a and b subsets of omega ; that means contained in omega  we define sum joint or union referred to by two different names so  basically  the union of two subsets a b  then we define it as a union b and this is equal to all elements of omega such that omega belongs to a or omega belongs to b  right and if you look at it  diagram was why so i have this because set as my set omega  this is a  this is b  then you see if you consider all this portion ; this will be a union b  because the element which is either in a or in can be or which is in both a or b  then that constituted your union of the two subsets a b  okay then  similarly  intersection or product is other two names given to of a b  and the notation is a intersection b and this is here for all omega in capital omega such that omega belongs to a and omega belongs to b so  the common base  and here in the diagram  you see that the intersection would be this  this portion  right  which i have shaded differently so  this portion will denote the intersection of the two sets and it is not coming properly  fine then  similarly  you would define complement of a set a which means and we denote it by a c or a bar so  complement means that  okay  i did not write down the definition ; that means this is a compliment is all omega belonging to this or that omega does not belongs to a ; this is the idea  right so  if this is your a and this whole is omega  then all elements which are not in a from the set a complement  okay  refer slide time  03  56  definition 2 point 4 is difference of two sets a b is the set a minus b ; they refer to it as a minus b or a intersection b compliment so  that is all omega the universal set such that omega belongs to a  but omega does not belong to b because it is intersection b complement so  if you use the definition of the product  then the elements here must belong to both a and b complement ; that means the elements which are belonging to a but not belonging to b so  in that case  i have drawn the figure ; figure three should be so a and this is b  no  so i have to say b compliment  okay this is not shaded correctly yeah  so if i am saying that this is whole of a and this whole is b i am referring to  right  because the elements here are in a and not in b so  this is the right diagram for a intersection b compliment  right  which is a minus b so  all components all elements which are in a but not in b will be referred to by this one here  okay now let us just so what we are asking you  fl   so  i probably drew the okay so  this was the figure for this  right  okay so  we will do it here so  now it says that question is draw the event diagram for a complement intersection b so  here if you have this and if this is a and this is b  then if i want a complement intersection b  then an element which is in b but not in a so  then it will be this ; this is what i had drawn  okay so  the elements here  they are not in a but in b ; that is a by intersection b  okay again i will take some more examples omega let us say the universal let contains the numbers 1 to 10  okay  and then if i define a as a set of all odd numbers and b contains 2  3  4  5  6  then a union b would contain elements which are here as well as in b and so  the union will be 1  2  3  is here 4  5  4 is here so  it will get added here  5 is here  then 6 is in b so  that gets added  and then 7 and 9 so  this is your a union b  right  and a intersection b  you have to look for the common numbers in a and b so  3 and 5 ; 3 and 5 are the common numbers so  that forms your set a intersection b and  similarly  you can write down all the others ; for example  a compliment would be all even numbers  right  because this is all odd so  a compliment would be all even numbers  then similarly b compliment you can write down the numbers which are not present in b and then whatever other operations we have defined  you can work out the examples now i will take the case of the infinite term set so  here is you take omega to be all collection of x comma y ; that means points in r two so  these are the points in r 2 such that x is non-negative y is less than or equal to 0 so  if you consider this as a whole plane r 2  then your omega is on this ; that means here y is less than 0 and x is positive so  whole of this quadrant last quadrant ; in arc 2  this is the first  second  third and fourth quadrant so  we are in the fourth quadrant omega  obviously  then is a infinite set  okay now if i take a to be the set consisting of all points for which the x coordinate is greater than 0 less than 12  and y of course is less than or equal to 0  then of course the picture is not ; if this is my number 12 on the x axis  then you can see that the whole of this we can say set again it is an infinite set where y is less than 0 and x coordinates are between 0 and 12 that forms a  right  and b is all x between 0 to 15 and then y is minus 0 and 0 so  minus 10 and 0  okay ; so  this is minus 10 and 0  fine so  that means if i draw a line here  then my b extends like this and x is up to 15 so  now in this case your b is this set so  b is this portion  right the x is expending up to 15 and y is from 0 to minus 10 so  that is your b now you see that if you want to write a intersection b  then this will be all points x y such that x because you see in a  x is between 0 and 12 ; in b it is between 0 and 15 so  when you want to take all common points in a and b  then it will be x between 0 and 12  and here your y is less than or equal to zero so  y in a was extending up to infinity so  in this case  the common thing would be that y is between minus 10 and 0 so  that will give you the intersection  right and of course i have already used the concept that a is a subset of b or that means here a and b are subsets of omega so  here you can see that b is not a proper subset of a  because you can find points which are in b but which are not in a so  this is the other concept that you use so  here i have said that b is not a proper subset of a ; that is i showed you that there are points in b which are not in a  alright  and that you can see because the set of elements this we have already seen that when you take points for which the x coordinate is between 12 and 15 and the y coordinate is between minus 10 and less than 0 her of course x is greater than 12  because a contain x less than or equal to 12 so  if the point is not in a  then the corresponding x coordinate should be greater than 12  alright  and this is less than or equal to 15 so  these are the points which are in b but not in a so  b is not a proper subset of a so  now let me just also give you a formal definition of a proper subset ; what do we mean by a proper subset ? that is if b is a subset of a but b is not equal to a  then we say that b is said to be a proper subset ; that means when b is a subset of a and b is not equal to a  it means that there are points in a which are not in b  whereas because b is a subset of a so  all points of b are all elements of b are also elements of a but since b is not equal to a ; that means there is at least one element of a which is not an element of b and so then in that case  we say that b is a proper subset of a  and we write it as without the equality sign here so  b is a proper outset of a ; this is the notation for so  therefore  now at least whatever words i used the word not a proper subset so  now you know what is a proper subset ?  refer slide time  11  49  so  now let me continue with the definitions and with the basic concepts of set theory if a and b are said to be mutually exclusive or disjoint  if a intersection b is empty ; that means there are no common elements in a and b  fine so  for example  in the example 2 point 2 that we just considered  you know the coordinate in the subset of r 2  you see a intersection b is actually this set which has so many points and so it is not empty therefore  a and b are not disjoint or they are not mutually exclusive and so as we go along and see so many examples when a and b have sum points in common  then they will not be considered disjoint if they do not have any not points in common  they will be considered as disjoint or mutually exclusive now some more concepts dealing with laws and this thing dealing with union  intersection and complements of sets ; so  here if now i am talking of a  b and c  there are three subsets of your universal set omega  then idem potency law says that you know when you operate a with itself  then a intersection a is a or a union a will also be a so  that means the union and intersection are either the operations we have defined for the sets these two are idem potent  okay then commutative law says that it does not matter whether you add a to b or you add b to a so  therefore a union b is equal to b union a similarly  a intersection b is b intersection a so  the order is not important which is that you write first associative laws here if you are saying you are taking intersection of a with intersection of b intersection c  then you can also write this as you first take the intersection of a and b and then take the intersection with c so  it does not matter so  the associative law holds here similarly  with union also ; with respect to union also the associative law holds ; that is whether you add a to the union of b and c or you add  first take the union of a and b and then union with c ; it does not matter  they are the same now the distributive law is with respect to both the operations  intersection and union so  when you take a intersection b union c  you can write this as a intersection b and then union with a intersection c so  a gets distributed  alright and  similarly  a union b intersection c will give you a union b  then intersection a union c so  these laws hold  and just for completeness sake  i have written them down here then de morgan ’ s laws are also important and we will be using them throughout  and therefore  it is better to talk about them right now and so the first laws say that an intersection b complement is equal to a complement union b complement  fine and if you see diagrammatically of this set is omega and if this is a and this is b  then a intersection b is this  alright  the darkly shaded portion and so its complement will be the portion which is shaded by the lines  and you can see that the portion shaded with the lines is nothing but the union of a complement and b complement  alright because this portion gives you b complement and this portion gives you a complement so  the union of both the two  so the two is equal but you can also prove it otherwise see what we are saying is that if omega belongs to a intersection b complement  this implies that omega does not belong to a intersection b  right  which means that omega should not belong to at least one of them because if omega belongs to both a and b  then omega will belong to a intersection b so  since we are saying omega does not belong to a intersection b  this implies that omega does not belong to a complement or omega belongs to b compliment  aright if you do not what omega to belong to both a and b  then it must belong to either a complement or b complement which implies by our definition of union that omega must belong to a complement union b complement now remember  okay  i did not say this out in the beginning but i should have said that whenever you are wanting to say the two sets are equal  then what does it mean ? yeah  maybe i should spell it out ; a equal to b implies  yes  component wise that if omega belongs to a  this implies omega belongs to b and if omega belongs to b  it should imply that omega belongs to a  fine ; this is the way of saying that the two sets are the same so  here when i want to show that these two sets are the same ; right now i have shown you that if omega belongs to an intersection b complement  then it must belong here  but i must show the other way also that is if omega belongs here  then it should belong to this and which i am showing similarly  if omega belongs to a complement union b complement that means if it is here  then this implies that omega either belongs to a complement or omega belongs to b complement which implies that omega does not belong to a intersection b  alright  because either omega belongs to a complement which means that it does not belong to a or it does not belong to b which means that omega does not belong to a intersection b  and so it belongs to a intersection b complement so  i have shown you both ways  and therefore the two sets are equivalent  refer slide time  17  54  so  similarly  i am writing out all the other laws here de morgan ’ s laws which you can sit down and work out yourself so  there you will have to show that you first start with an element here and show that it belongs here  then you will have to pick up any element from here and show that it belongs to set on the left so  that exercise you should now sit down and do for the remaining de morgan ’ s laws but we can just look at them so  this is in a way a complement of this says that a union b complement is equal to a complement intersection b complement then if you take the complement of the complement  you get back to the set a  alright ; that of course in words you can immediately say it out and one way to classify correct wise is that one set is the subset of another so  b is a subset of a if and only if when you take the intersection  you will get the set b  fine if b is a subset of a set a  then when you take the intersections  the only element all the common elements must belong to b ; similarly  union you can characterize that if b is the subset of a  then a union b is equal to a  because b is not adding any new elements to the set a union b and therefore  a union b remains equal to a now so far i had defined union intersection complements for two or three sets but now we can extend this notion to any number of sets  and here i am just taking i to be the index set where this index set can be i can be having finite element of finite indices or infinite indices and so this holds for whatever the status of i is so  now if all these are subsets of omega i is in the index at i  then you can say that the intersection of all the subsets such that i belongs to i is omega belonging to the universal set such that omega belongs to a i for all i  alright so  if an element is present in all the a i  so then it will be present in the intersection  and union of course would imply that omega belonging to a i for at least one i  right and omega belongs to the union if omega belongs to at least one of a i ’ s  okay ; it van belong to more than one  but it must belong to at least one of the a i ’ s  right and then  similarly  using the concepts here the definitions here  you can define now that this is not written very nicely  okay so  i belongs to i if you are taking the intersection of all a i ’ s so that i belongs to i and then you take the complement so  then by this law  you immediately write it down as union a i complement  yeah  and again in words you can say it out the same thing and  similarly  here this is the equivalent of this when you are taking more than three sets or two sets ; this is union a i  i belonging to i the complement of this will be the intersection of the complements of all the a i ’ s  right  okay so  given this now let us get started with taking about how we go about defining probability of an event and so on so  before that i will simply spell out what we mean by sample space and then events and then we talk of how we go about estimating the probability of events  okay so  again i will begin with the examples to give you an idea what we mean by sample spaces so  for example  if you consider the experiment of tossing a coin ; so  a single coin is tossed and so what are the possible outcomes ? either i will get a head or a tail ; these are the two possible outcomes so  you just collect all the possible outcomes of an experiment and that will be our concept of a sample space and again i will refer to it as for that particular experiment this is my universal set similarly  if i toss two coins together  now the thing is that you are tossing two coins and so let us just name one coin as number one and the other as number two in that case  you see when both of them show heads and this will be h h now here if the first coin shows the head and the second coin shows the tail  then it will be h t and if the first coin shows a tail and the second coin shows a head  then the outcome would be the t h  alright  and in case of both of them show t t tails  then this will be t t so  this will be the set of all possible outcomes when you tossing two coins together  okay and so this will be your sample space ; this would be the sample space if you are now tossing 2 6 faced die so  here again what we will do is we will say that we will number one die as number 1 and the other die will be number 2 and so  therefore  the outcomes will be recorded as whatever the numbers shows for the first die and whatever the number shows for the second die and in that case  it will be s pair of numbers so  1 to 6  and therefore  the possible outcomes will be 1 1  1 2 and 1  6 ; that means the first die shows 1 and the second dice shows 1  2 or 6 and  similarly  you can then say that it is 2 1  2 2  2 6 so  therefore  it is important when you are throwing two die  then you have to number them as 1 and 2  so that because what shows the arrangements because here this is an ordered arrangement  and therefore  there is a difference between 1 2 and 2 1  okay and so  we have to record all possible outcomes  and therefore  here this will be the collection of all 36 outcomes  and that will constitute your sample space  okay so  therefore  i am just trying to show you that when you consider an experiment  then you have to be very careful in recording the outcomes and so here when you are tossing two coins  then we will have to number one as first coin and one as second coin  and then we can record the outcomes similarly  when you are two die  then you have to you know locate one die as number 1 and the other one as number 2 to be able to record all possible outcomes in a proper way then the possible outcomes i have not listed but this table shows that you know it can be the first one is the first die is showing one and then the second die is also showing 1  then it could be 2 up to 6 similarly  it could be 2 1  2 2  2 6 and 3 1  3 2  3 6 and so on up to this so  here the total number of possible outcomes you see will be 36  right  and again i will refer to this as a sample space so  now formal definition of a sample space can be immediately said and that is if the set containing all possible outcomes of an experiment is the sample space corresponding to that experiment  okay it is not very clearly written but you can just read it ; that means the set containing all possible outcomes of an experiment is the sample space corresponding to that experiment so  this will be our concept  and here you see that in this case of course when do any experiment  you except the outcomes to be finite and so  my sample space in this case would be the number of i will just list the number of possible outcomes and that collection of possible outcomes so  you can see that the sample space can have any kind of structure so  here in case  for example  it was h and t means these are the possible outcomes ; in this case  it was h h  h t  t h  t t and now in this case it is pair of numbers where the numbers can differ from 1 to 6 for wither this thing and so collection of those 36 pairs of numbers are the elements of sample space omega and that will be so  now i will go on defining the concept of events and then we will try to estimate the probability of events  refer slide time  26  37  now i will defined what we mean by an event so  any subset e of the sample space idea  first idea of a sample space is clear ; that means all collection of all possible outcomes now any subset of the sample space is known as an event ; we will define this way and we have seen that  if for example  two subsets are there e and f is subsets of omega ; they both are events then whatever operations we have done so far we have discussed on the subsets  then e union f  e intersection f  e complement and whatever we discussed all those various operations on the subsets  then all those will again be subsets of omega  and therefore  by our definition they will again be events so  in fact  when i told you the extended concept of union and intersection where you took number of subsets whether finite or infinite and again if you take their intersection and union and complements and so on  they will again all be subsets of omega so  therefore  you can see that the collection of events becomes very very large and in fact  it is formalized which i am not actually taking to you about ; i will just mention the name that it is known as the sigma algebra of events so  essentially what we have to remember is that  however  way we can generate subsets of omega  then those which can be obtained as through union  intersection and complement through these three operations whatever subsets of omega we can obtain  they will all the considered as events for the corresponding experiment  okay now examples are there ; when you toss a single coin  we saw that the sample space omega just contained these two possible outcomes and now the subsets can be if the single turns h t and of course we always include consider pi also as the subset so  therefore  these will be possible subsets or the events in this case when you are tossing two coins  then you see your possible outcomes were four  in fact  h h  h t  t h  and t t now you can start forming subsets ; i have just written down a few you can take this each outcome of each element of the sample space omega as subsets  and so it is an event you can put two together ; that means either head or tail or tail or head  and this will again also form an event and you can then perform in fact  in the last lecture i have shown you that if set has whatever the number of elements  then the possible number of total number of subsets of that set would be 2 raise to 4 ; remember it was an application of the binomial theorem and so on so  the number of subsets here  in fact  would be 2 raise to 4 which will be 16 so  you can list out all the possible events that can be formed for this particular experiment of tossing two coins now again as an example when you are tossing two 6-faced die  then consider the subset which has both the numbers that means both the phases show the same number  alright so  both the numbers are the same and so here the components in a would be 1 1  2 2 pairs  3 3  4 4  5 5 and 6 6 so  this will be one event ; that means you can also describe it in words that both the phases both the numbers are the same and b for example i have listed pairs which were the two numbers add up to 7 so  the sum of the two numbers adds up to 7  and this way you can go on continuing in fact  here the number of subsets will be very large because omega itself contains 36 pairs  and so the number of subsets would become this thing  right yeah  but now one word of caution and that is when we are defending the sample space  we have to be careful as to what our experiment is and here  for example  you have to ; in fact  i have to say that there are two possible cases one is with replacement wherever this is relevant  and the other possibility can be without replacement  okay so  we have to be careful on how the experiment is being conducted and then you can define your sample space that means the possible outcomes that can be there of the experiment  refer slide time  31  28  so  now consider the case that two cards are to be drawn from a pack of 52 cards  and if you are doing this drawing of the card ; that means you draw a card you look at it  note it down somewhere and then put it back in the pack and then again you draw the second part if this is your experiment  then let us say that i comma j stand for so  you note down when you take out a card  you look at the number ; you look at the card so  then the first index here tells you what card it is  what type ; that means whether it is a club  spade  diamond or heart so  i will refer to c s d or h ; that means four possibilities and j will stand for the number from 1 to 13 ; that means whether it is an ace ; that is number 2  number 3 or number 13  right so  then this pair will denote the type of the card that you got  and so your omega will be collection of all two pairs i comma j and k comma l where again k indicates the type of the card and l indicates the number so  therefore  i and k can be anything from c s d h  because you are doing replacement and then j and l are the numbers 1 to 13 so  essentially  the way you can describe the experiment is that the first draw of the card  it can be any 52 cards and  since  you have replaced it in the pack  again your choice of drawing a card is from among the 52 cards in the pack so  therefore  the total number of outcomes that are there is 52 into 52  okay and so this actually by the way denotes the cardinality of a set  which means that what is the total number of elements in the set so  here the sample space will consist of 52 into 52 such collection of pairs  okay so  to indicate you what the cards you have got but now if you are doing it without replacement  then you do not want i and k to be the same and j and l to be the same ; that means once you have drawn a card  it is not there in a pack so  it will not appear again  right ; in that case  your choice will become that means in the first draw you have a choice from among the 52 cards  but in the second draw  it will be only out of 51  because one card has been replaced is not there ; it is kept aside and  therefore  in this case you will have to be careful because your choice of the sample space will contain such pairs but there i will not be k and j will not be l so  the whole idea is to say that we just do not write out you have to be careful when you spell out all the possible points that can be there in the sample space  okay now let us begin talking about the axioms of probability ; that means how do we characterize a function or whatever we mean by a probability ; i mean what type of characteristics it should have ? so  here again i am now referring to the sample space omega and then e is some subset of omega which again is an event so  then we say that the function p which will assign so  essentially what we are saying is that p assigns  okay  i am writing capital p so  p is assigning e to a real number ; that is it takes it to p e which belongs to the real number r  right so  we can say that this is a mapping or an assignment so  here for every event e for every subset of omega  i am assigning real number and so  p e is a real number here  and p e must be between 0 and 1 ; that is the first requirement then for the whole sample space p omega should be 1  alright  and axiom three says that for any sequence of mutually exclusive events ; that means you just take any collection of events a i that means subsets of omega such that they are mutually exclusive which means that e i intersection e j is empty for all i j in i  alright so  this is the collection which can be a finite  infinite ; it does not matter  but we are referring it to as an index set i and then probability of union e i  i belonging to i should be equal to the sum of the probabilities so  because the events are mutually exclusive  they are disjoint so  therefore  when i add up the compute the probability of the union of these e i ’ s  then it should be equal to the sum of the probabilities so  these are the three characteristics that we associate with the probability function  and using this  you see that any function f p which satisfies these three axioms will define the probability and this is actually what we say is that p e is probability of occurrence of e so  remember in the beginning i started saying that we would be trying to develop the theory of occurrence of an event so  here we have now defined something which we refer to as the probability of occurrence of e so  this is and we will now see that what things you can derive so  basically using these 3 axioms  we will be able to build up the probability theory and the first simple observation that we can make is that n this case for axiom three  if you choose your e i to be the whole set omega that is your sample space and all other e i ’ s you choose as empty sets  right  for i greater than or equal to 2 because this axiom must hold so  here the union will become your set omega  right  because all other e i ’ s are empty  e 1 is omega so  union gives you omega and from here from axiom 2 p omega is 1 so  you get this okay  p omega i have to write that is secondary and that is not a big deal i mean  okay  what i am saying is that this validates the axiom because we have already assumed that p omega is 1 and so here also if you put e 1 as omega and all other e i ’ s as empty sets  then you get p omega is 1  alright now here in this case  if you look at this  you want to compute the probability of let us say h and t so  here if i take what will be my subsets here this would be in the first example  my e 1 would be h  e 2 will be t  alright so  in that case from this axiom  what i will get is that p e 1 plus p e 2  alright  is equal to 1  because e 1 union e 2 is my whole space omega ; p omega is 1 so  therefore  i get that p e 1 plus p e 2 is this but then i should be able to compute  okay then what i am trying to say is that from here  i should be able to show that p e 2 is equal ; of course  from here it follows that p e 2 is 1 minus p e 1  refer slide time  39  31  so  we got that using axiom three in the case when single dice rolled tossed and then we got that p e 1 if e 1 is the event that it is showing ahead and e 2 is the event that it is showing a t  then we got that p e 1 plus p e 2 is 1 which is equal to probability of h plus probability of t now we understand the concept of unbiased coin ; that means it is equally likely whether a head shows or a tail shows in that case  the two probabilities are equal ; that is what we mean by an unbiased coin and so  therefore  it will immediately follow from here that p h equal to p t is equal to half  because they both most add up to o1 so  therefore  what is what i am showing how you apply the axioms to arrive at the probabilities of the events so  here of course that it is an unbiased coin similarly  when a die is rolled and so you have the 6 number showing up  either of any of the six numbers can show up so  here again applying axiom three  you will see that the probabilities of all numbers but that means p 1 plus probability of p 2 plus up to probability p 6 and that should be equal to 1 and since we are again saying that all size are equally likely which means that probability of p 1 is equal to probability of p 2 means it is equal to the probability of 2 that it is equal to probability 3 and so on so  all six together ; that means essentially what we are saying is that six any of them ; this is equal to 1 which implies that p 1 is 1 by 6 which is equal to all other this thing  right  for i varying from 2 to 6 so  we immediately conclude that probability of each phase showing up is the same which is 1 by 6 now what happens is that most of the time in many  many situations  we now already because of the nature of the experiment and so on that the elements of the sample space have equally likely outcomes because that is how i showed you these two example that when you are throwing up a unbiased coin  then you know that whatever the outcome has the same probability that a head showing up or a tail showing up  they are the same similarly  as i said that if you are throwing up a die and you have no reason to say that it is loaded die or a biased die  then in that case we except that any of the six numbers have the same probability will show up the same so  we will see that and of course we have to be what i am trying to say is that i am giving you an alternative way of defining the probability of an event  but the basic assumption for this definition is that your sample space has this property that all the outcomes in the sample space have the same probability equal likely chance of occurring  right if that is there if this is satisfied  then let us just start with this definition that suppose omega has n number of points ; that means the cardinality of omega is n and the number of points in a where a is an event  okay a is subset of omega  alright  and then we are saying that the number of points in a is n  then we define the probability of a as m divided by n that means the number of points available in a or you can also there is another way of saying it that the number of favorable cases ; that means the number of points which actually are in a ; that means for occurring of a those are that points which will occur so  then the definition of the event a is number of favorable cases for a divided by the total number of cases ; that means total possible outcomes and the outcomes which are part of your event a so  then this is the definition  and now you can very quickly verify that the three axioms  because remember i said that any definition of probability must satisfy the three axioms so  since a is subset of omega  this means cardinality of a is less than or equal to cardinality of omega  right  which implies that m is less than or equal to n  alright therefore  probability a is less than or equal to 1 and also by definition  probability of a is greater than or equal to 0  because m is either 0 or it is a positive number so  therefore  this satisfies the first axiom  right  refer slide time  44  30  then  similarly  probability omega would be n by n which is 1  alright  because omega has n points so  therefore  n upon by verifying the definition ; so  this probability is 1 so  this axiom is also satisfied now if i take a set of events a i ’ s in an index set i capital i  and here  since  we are taking the omega as the finite space so  i is also a finite index set and then cardinality of each a i is m i ; that means the number of points of the sample space in a i is m i  alright then we want to look at the probability of union a i  and here the a i ’ s are disjoint  because  remember  i am verifying the axioms 3 of probability so  here a i ’ s are disjoint ; that means the elements of the sample space which are in one a i are not in any other so  all these a i ’ s are disjoint meaning that the points in one a i the elements of sigma in one a i are not in any other a i  alright so  in that case  now if you want to compute the probability of union a i i belonging to i  then this will simply be because the number of elements of omega sigma of omega in union a i will be sigma mi since  the elements in each a i are different from all others ; so  therefore  we will just add up the total number of points which are in the union here will be sigma m i and so by our definition  this will again be when you are computing the probability for this union  it will be sigma m i i belonging to capital i divided by n and now here the sigma i can write as individual sigma ’ s that means i can write this as summation of m i by n i varying from 1 to n and each m i by n so  for a particular i  the m i by n is the probability of a i and so this is the sum of the probabilities so  axioms 3 are also satisfied here so  that means this particular definition when you assume that the outcomes  the occurrences or the elements of sample space have equally likely chance of being of occurring  then i take the definition of the probability of an event as the number of elements in that events number of elements of the sample space in that event divided by the total number of elements in the sample space so  m by n if i take that as the probability here  then  since  it satisfies all the three axioms ; so  this is a very convenient way of computing the probability provided of course you can assure that the outcomes in the sample space are all equally likely and  yeah  if you can assume that if you can assure that  then we can use this way of computing the probability of any event where we can just look at the number of favorable cases for a particular event and then count them up and then divide by the total number of outcomes in the sample space  and you get this anyway now we just want to make another comment here note here and this is you know we sometimes refer to the probability in terms of percentage so  for example  if you make a statement that in a group of 20 people  ten percent are smokers ; sometimes he also refer to be probability in this way so  this would be interpreted as probability of a member of the group being a smoker is 0.1 so  10 percent ; so  10 upon 100  okay  and here if you want to interpret it in terms of your m by n  then you see your n is 20 and the ten percent of 20 is 2 so  m is 2 ; so  therefore  2 by 20 which is 1 by 10 which again is equal to 0.1 so  please remember that as the course develops  we will often be referring to the probabilities in terms of percentages and so the interpretation is simple  alright  okay you just take the fraction which is so 10 percent means 10 upon 100  and that gives you 0.1 so  that will be your probability so  exactly the same way you are counting as you are doing here m by n so  therefore  all the conditions all the axioms are satisfied so  this is also a proper definition  but of course this is valid when you can assure that the all outcomes in the sample space are equally likely  alright  okay so  i will quickly take up this example now here a committee of 5 is to be selected from the group of 6 men and 9 women  alright now if the selection is made randomly  so this is important since  the selection is made randomly ; that means that the choice of any of the men or any of the women is equally likely under this assumption  we will say that what is the probability that the committee consists of 3 men and 2 women ? so  if you want to compute this  i will apply this definition because the example here the experiment here satisfies this condition and therefore  you see now here i will apply this thing multinomial thing so  you want to select 3 men out of 6  and 2 women out of 9 women so  this gives you the total number of points in your set a  right  or the event e or if you define the event e as 3 men and 2 women are selected  then this cardinality is given by 6 3 9 2  alright and the total number of ways in which you can select 5 people from the set of 15 is 15 choose 5  and therefore  the number of favorable cases is this  total number of cases is this so  the probability of selecting a committee of 3 men and 2 women is given by this ratio and  similarly  here an urn contains n balls of which one is special if k of these balls are withdrawn one at a time with each selection being equally likely ; so  here again the same thing is stated so  if each selection is being equally likely ; that means whatever the balls are left  choosing the ball from there is equally likely  then what is the probability that the special ball is chosen so  here again the probability of the special ball is chosen so  here you see you have to choose the special ball  so 1 upon 1 ; the probability of choosing that is 1 upon 1 then from the remaining n minus 1 you want to choose k minus 1 so  this gives you the number of favorable cases the number of cases in which the special ball will get selected and then the total number of ways of selecting k balls from n balls is n c k so  that number when you compute comes out to be k by n so  the whole idea is that things become much easier if you have this condition being satisfied  then this is very convenient way of determining the probability of an event introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  3 conditional probability independence of events  refer slide time  00  14  so  after having defined the axioms of probability i am trying to  i try to show you how probability function can be obtained let me now derive a few propositions using these axioms so  the topic that i am going to talk about is simple propositions so  proving this that proposition that p phi is 0  so the axiom 3 we have taken we take e 1 to be omega and then e i s are all  all remaining e i s are empty and here we will take the index set be a finite index set so  it does not matter ; i have to prove it for  i have to just show that p phi is 0 so  whether i take ; so here it is convenient to take i to be a finite index set so  i take i to be a finite index set then all other e i s are empty sets so  therefore  the condition for axiom 3 is satisfied  because certainly e 1 is disjoint with an empty set  and all other sets are also because they all are empty so  they are disjoint so  therefore  the i write down applying the axiom 3 ; i say that p omega plus  p phi  and phi gets added i minus 1 times  because 1 has gone here ; so 1 less than the index of i  to the cardinality of i so  therefore  this is p phi into  cardinality of i minus 1 ; this has to be equal to 1 because this is p omega  right since you add up all the e i s then this all add up to omega ; remaining sets are all empty sets so  this is by axiom 2 this is 1  right ; and so and therefore  since i is a finite number which is greater than or equal to 2 because we are saying that at least 1 set which is equal to omega  and the other there is at least 1 set which is the empty set so  therefore  the number of  the cardinality of i has 2 or more than 2 ; and so this number is not 0 therefore  here  you see  because p omega  p omega cancels out ; then you get that  and also p omega is 1 so  anyway  this cancels out ; and we are left with this ; this left is equal to 0 which means that either this is 0 or this is 0  but then this number is not 0 since cardinality of i is 2 or more than 2  so p phi must be 0 ; so this is how we obtain the preposition that the p phi will always be 0 now  proposition 2 is this actually ; that probability of the  complement of the event e is 1 minus probability of the event e ; and this can be very simply derived and see here the attempt is to show you that once you define the axioms and then using the axioms logically  we can derive at so many results and build up a good structure so  that then you can estimate probabilities of more complex events and so on so  now for any event e  e union e compliment is omega  right ; either the element of omega is in e or is in e compliment  so this holds then  since e and e complement are disjoint sets  they are mutually  this thing  exclusive from axiom 2 and 3 it follows that p  e  plus  p  e c  is 1 so  from axiom 3 it say that probability of e into  probability of e union e complement is p  e  plus  probability of e compliment and then axiom 2 says that probability of omega is 1 ; so this is what holds and therefore  from here it immediately follows that probability of e compliment is 1 minus p  e   so  that is your second proposition so  therefore  now using the basic 3 axioms i have been able to arrive at the result that p phi is 0 and then now i have shown you that p of the  probability of the compliment of an event is 1 minus the probability of that event proposition 2.3 says that now  we can see that the results are getting more and more complex so  if the 2 events  e and f  subsets of omega  then probability e union f is equal to  probability e plus  probability f minus  probability e intersection f and you see that  in case  e intersection f is empty then this will be 0  because we have just derived the result that p phi is 0  so in that case p e n f will be this ; and then this is again is valid for axiom 3 because in case e intersection f is empty then e and f are disjoint  and then we said that probability of the union is the sum of the probability  right so  this is in complement with you axioms  and so on now  let us start proving this result so  i first say that e union f is e union e compliment intersection f  right ; because this set e union f  so either whatever the elements of f are e that cover  that is covered here  and the remaining elements of f are not in e  but they are in e compliment and therefore  you can write e union f as e union e complement intersection f now  by doing this  you see  i have broken up this union into  the union of 2 disjoin sets because e intersection that e complement of f is empty ; so there can not be any element which are in e compliment so  therefore  this is empty so  now axiom 3 again says because these 2 sets are disjoint ; therefore  probability of this union  so probability of e union f is equal to probability e plus  probability e complement intersection f because i could decompose this union into the union of 2 disjoint sets and so i can immediately apply axiom 3  and i get this  right now  we will try to write  again decompose up in a way so i can make use of the axiom 3 so  now  f is f intersection omega  but then omega as we said we can write as e union e complement ; i just used it here so  then f intersection of e union e complement which i can write as f intersection e union  f intersection e complement ; this is by the distributive law which i defined sometime ago for you ; so therefore  in the earlier lecture so  therefore  this is equal to this ; and here again you see that these 2 sets are  ok ; it should be union ; be careful because we have no meaning of putting a plus sign here ; these are subsets  fine so  this is equal to this ; now  here again both the sets are disjoint  refer slide time  07  29  so  therefore  when i write probability f  i can simply write it as probability e intersection f  this probability e complement intersection f  by using our axiom 3 now  from here  from this relationship i can now compute probability e compliment intersection f as equal to probability f minus  probability e intersection f  right and this  i will then substitute in 1 so  i will get p  e  plus  p  f  minus  probability e intersection f so  substituting this in 1  we obtain the desired result  that probability for any 2 sets probability of the union of those 2 sets is sum of the probabilities of the 2 sets minus  the probability of the intersection of the 2 sets and it is very intuitive argument for this  for the validity of this result now  since you see p intersection f is a subset of e and f  both  right ; e intersection f is at a common element  so they occur in e as well as in f and therefore  when you are adding up the probabilities p  e  plus p  f   probability of e intersection f  gets added twice so  i have to subtract it once to make the equation balance and therefore  this is the result  right and even through venn diagram you could explain that when you ; see this is a  this is b so  probability a is this area  probability b is this whole area ; when you put them together  you have added this area twice because this is your a intersection b you have added this area twice  and therefore  you need to subtract it once  so that the 2 equations are balanced  ok so  you may get corollary of this result p  e  union f is p  e  plus  p  f  minus  p  e  intersection f  is that if a is a subset of e then the probability of a is less than or equal to probability of e now  we can write e as  because a is a subset of e  therefore i can write e as  this subset e i can write as a union a complement intersection e  right because if this is e and this is subset of a  so then this is a and this portion is your a complement intersection e  right so  therefore  and then these 2 will be disjoint sets so  therefore  p will be p  a  plus  p  a  complement intersection e ; again we are applying axiom 3 because i have decomposed the event e into sum of 2 disjoint sets  2 disjoint events and therefore  the probability of p  e  would be p  a  plus p  a  complement intersection e and since p  a  complement intersection of a is greater than or equal to 0  therefore  this implies that from here that your p  e  is greater than or equal to p  a   so  we get consequence  and i will just put it down so that for complete in a set  otherwise one can immediately ; once you have proved this result  you can conclude this result immediately so  once you have these 3 propositions now you can see  you can get some more results ; you can compute probabilities of more interesting and complex events so  consider this example example  this says that 20 percent of indians smoke cigarettes  40 percent smoke bidis  and 7 percent smoke both cigarettes and bidis so  what percentage of people do not smoke both ? so  you are asking what percentage of people do not smoke cigarette as well as bidi so  now here if i write the event e as set of people who smoke cigarettes  and f is my set of people who smoke bidis  right then  i first compute e union f so  probability of e union f by adding the proposition i just proved is p  e  plus p  f  minus  p e intersection f  right  which is 2.2 plus 4 ; this is 20 percent  40 percent  and then minus 0.07 ; so therefore this comes out to be 0.53 and i am looking for the  what percentage of people do not smoke both so  if this is e union f  right ; so e union f  remember  again i was talking of de morgan laws  this compliment was e compliment intersection f complement  right so  this is people who do not smoke cigarettes  people who do not smoke bidis  so the intersection will give me the sort of people who do not smoke either cigarette or bidi  right so  therefore  i am computing e union f complement now  here i have used proposition 2  i think 2.2 we are also ; i have computed probability of e union f  so now  i want to compute probability of e union f complement which is 1 minus probability e union f ; and so therefore  this is 1 minus 0.53 which is 0.47  refer slide time  13  09  see  we have already  you have come across continuity of a function on the real line  now we want to introduce this concept of probability function as a continuous set function and this is very useful because often when we have to take limits of sequences  of your sequences of events  and then we need to have this notion of probability as a continuous function on the sets  so that i can inter change the limit on the  in the process of taking the limit and probability  in taking the probability so  these are what we are going to formulize see  sequence of events e n is greater than or equal to 1 is said to be an increasing sequence if e 1 is contained in e 2 contained in e n  and so on  right so  this is the notion of increasing sequence of events ; and then similarly a decreasing sequence would be when e 1 contains e 2 contains e n  and so on so  for increasing sequence e n  we define the limit of e n  n going to infinity as union i varying from 1 to infinity e i  right because  anyway  it is a increasing sequence of this in fact is e n ; and therefore  there is nothing new in the definition  because these subsets are all  events are part of e n so  therefore  union actually is  because you want to take the concept of inter changing the probability in the limit  so this is why we are doing it for decreasing sequence e n  we defined the limit of e n as if intersection i varying from 1 to infinity of e i now  the proposition is that if e n is either increasing or decreasing sequence of events then limit p e n ; so here this will be mean result that limit probability e n  as n goes to infinity is probability limit of e n as n goes to infinity so  what we are saying is that you can interchange the operation of taking the limit and taking the probability because of continuity of p on the sets so  let us just quickly look at the proof consider the case when e n is in increasing sequence ; and then we can also go with the proof when e n in decreasing sequence so  define new set of events f i as follows  f 1 is e 1  then f 2 is e 2 intersection e 1 complement so  therefore  you see whatever common components of e 1 are there  and e 2 they are there anymore ; so f1 and f 2 ; f 1 is e 1 ; f 2 is e 2 intersection e 1 complement so  therefore  you can immediately say that f 1 and f 2 are disjoint  right then finally  this way you want to find f 1 as e n intersection union  i varying from 1 to n minus e i n complement so  all the previous sets  e i s  you take the union and take its complement  then you take the intersection in the end so that is e f n so  therefore  here you can see the systematically the way we have defined f 1  f 2  f n  and so on  that these are all disjoint subsets or disjoint events  right  refer slide time  16  32  and so that is what we are saying that f i  i is greater than or equal to 1 are disjoint now  union i varying from 1 to n f i  is union e i  right  because i am not taking away anything ; it is just the common parts i am removing  and so making these disjoint but  otherwise all the elements of  all the components of e 1  e 2  e n are all there so  union f i  i varying from 1 to n is union i varying from 1 to n e i and therefore  you know  the limiting case also  this will be true  right now  probability union e i  i varying from 1 to infinity is probability this  because this wholes ; so therefore this is also probability of e i union i varying from 1 to infinity  f i and since  f i s are disjoint i can write this as summation i varying from 1 to infinity p f i  since  f i s are disjoint  right ; i can write this and now  this side you see  this is nothing but limit e n by our definition  right ; we defined that union e i  i varying from 1 to infinity is limit e n and goes to infinity so  this is this and from this side you see this is sigma p f i  i varying from 1 to infinity which can be written as limit n going to infinity of summation i varying from 1 to n p f i which ; again here this you will write as union i varying from 1 to n f i  and then this will be limit ; so this is e n  right this part is also union f i  yes ; you can see it immediately that union f i is e n because e n is an increasing sequence ; and therefore  this is this so  now this is what you wanted to show  right probability limit e n  n goes to infinity is equal to limit probability e n is n goes to infinity  for an increasing sequence now  when the sequence is decreasing then you see e n complements will be increasing  right ; because e n s are decreasing  so e n complements would be increasing ; and so you apply what we have just proved to this sequence of events e and c ; and so probability union i varying from 1 to infinity e i complement is limit probability e n complement  and n going to infinity  right but  this union is nothing but intersection of e i  i varying from 1 to infinity complement that is what your de morgan ’ s law is that we have done in lecture 2 or lecture 1  i think the previous lecture so  then this is this therefore  intersection e i this thing  from here  this is  because this is equal to this number because we have taken this as increasing sequence  and this is equal to this ; so it follows from here  and this is equal to this  right  this thing and this you can write as 1 minus probability intersection e i  i varying from 1 to infinity because this is complement  probability of the complement event ; so 1 minus probability intersection i varying from 1 to infinity e i and this is same thing ; you are writing probability of e n complement ; so this will be 1 minus p e n so  this comes to this side so  here you have this and this cancels out 1  1 and therefore  this now is by your definition because it is a decreasing sequence  so by definition i varying from 1 to infinity e i is limit e n as n goes to infinity so  therefore  you have proved the result for both and now there we will be many occasions where we will be using  i mean referring to because p is a continuous function  continuous set function ; therefore  i would be very often exchanging the process of taking the limit and the probability  refer slide time  20  35  so  now  i will define another new concept which is the conditional probability and we will just see that how starting from the 3 axioms i am able to develop more and more theory about the probability so  conditional probability again i will take an example first so  suppose you have 2 fair dice  the dice we can also call phial ; all these words are synonyms so  when you have the example we had considered of rolling or tossing 2 dice ; then if my event a is that the first dice shows 2  and b is the event that sum of the numbers on the 2 phases is  they add up to 6  right so  the first dice is already showing a number 2 now  in the conditional probability  that means knowing that the first dice has shown 2  then if i want to sum up the 2 numbers on the 2 phases to be 6 ; and now you want to find the conditional probability of the given a so  therefore  see  what will be the b intersection a ; that means  the first dice showing 2  and then you want the sum of the 2 numbers is 6  that means the other dice must show the number 4 ; so this gives you the intersection of a and b  2  4  right and here  given that your first dice ; so the probability that the first dice has shown 2  then the second dice can show any of the 6 numbers and therefore  the probability of a  because this probability is probability of p intersection a divided by probability a so  probability a will be the first dice showing the number 2  and the second dice is showing any of the 6 numbers ; so therefore this add up to here ; so the probability of 2  4 ; just one of the 36 equally likely elements because we are assuming that the dice is unbiased  both the dice are fair so  the probability of this pair occurring is 1 by 36 ; and each of these is again equally and each of them has probability 1 by 36 ; that is the 36 upon 36 which will be 1 by 6 ; and therefore the outcome is 1 by 6 so  this is how you compute the conditional probability and so we say that probability of b  given a is the conditional probability of b given that a has occurred so  once you know that this event has taken place  now you are wanting to find out the probability that b will occur so  therefore  this will be conditional probability of b  given a ; that means  you want to compute the probability of b  once you know that certain event a has already occurred now  so the formal definition would be that if p  a  is positive  that means a is an event which actually may occur then  if probability p  a  is greater than 0  we say that probability b conditional a is equal to probability of a intersection b divided by  probability a so  this is the definition ; and this is the valid one because we have already assumed that p  a  is positive so  here we can immediately say that this implies  that probability  you can also write  the way of writing probability a intersection b is  probability a into probability b conditional a ; so this is a very impotent formula which we keep using so  let me illustrate this concept through this example now  in the game of bridge 52 cards are dealt are equal to the 4 players ; that means  each player gets 13 cards so  the 4 players are a  b  c  and d a and c have both been dealt 7 clubs amongst them what is the probability that b will have 4 clubs ? this is the question now  the event that has already occurred is that a and c both together have 7 clubs amongst them now  we want to find out the probability that b will get 4 clubs so  here again i am using multinomial coefficients  and i am saying that the number of ways in which 4 clubs out of ; see  because they have been  there are 7 clubs amongst them ; number of ways in which 4 clubs out of remaining 6 ; this should be 6  sorry ; this should be 6 because 7 clubs have been dealt to a and c  so you are left with 6 more clubs ; and therefore  this will also be number 6 so  now  you want 4 of the  out of remaining 6 clubs you want 4 of them to go to player c  player b  right and so if he gets 4 clubs  then that means  since he is getting 13 cards  so after the remaining 19  so this will be then 20 so  in the remaining 20  a should get 9  right so  i have to collect the thing here also this is 6 and this is 20 so  i am make the  i have computed this probability by using the multinomial coefficients that  you know  the 2 sets of cards ; and so the choices are from 6  4 out of 6  and 9 out of 20  refer slide time  26  25  and the total ways in which it can be dealt 13 cards out of the 26 cards because 26 have already been given to a and c so  out of the remaining 26 it is given so  total number of ways in which that can happen is 26 choose 13 ; and this is this now  you have to explain this in terms of ; so i am saying that the conditional probability of b getting 4 clubs  when a and c are already been given 7 clubs  is given by that number and then i would like you to know because ; so just bringing it out how this will fit into this definition and i will come back and then discus with you again a few and figure it out how this fix into that definition now  let me give you another extension of this concept of conditional probability ; and then so just want to point out here that  you know  this is a name so  therefore  the positive will occur  we put after s this is the name of the  such a station and so those formula which we will  as we go on we will show that it is very useful way of computing certain probabilities  conditional probabilities of course ; and so we are consulting over the  telling over the formula is ; and then taking some examples to illustrate how it is so  suppose e and f are 2 events  then as i have already shown to you  i can write e as e intersection f union  e intersection f complement  right since  f and f complement are disjoint  and so e intersection f  and e intersection f complement are disjoint and therefore  in exactly we have concluded that p e  can be written as p e intersection f plus  p e intersection f complement now  we can generalize this formula ; because if i have n mutually disjoint p of e intersection f i  right if you remember this then that means  i am giving you a formula for computing probability of e  by conditioning e on the f i s so  if i have a set of these mutually exclusive f i s such that they add up to  the union is equal to my whole sample space omega ; then i can decompose p e in this way ; and then using the conditional probability formula for e intersection f i i can write this as this ; and now this is a way of computing p e by conditioning e on the occurrings of f i s  into f i or  in other words  you can also look upon this as a ; because your p f i s  summation this will be equal to 1  remember ; because this is equal to this ; they are disjoint so  probability of union f i s will be sum of the probabilities of p f i s ; and therefore that will be equal to 1 so  this is equal to 1 so  i can treat probability f i s as weights and therefore  this formula saying that p e is the weighted average of probabilities e conditional f i by the weights p f i so  whatever conditioning event you take here you multiply it by the corresponding weight so  there are many ways of looking at it now  why i am discussing this is because suppose that e has occurred then you want to find out the probability of occurrence of f i see  actually the role of the 2 events saying that suppose e  here i was computing e dependent conditional occurrence of the events f i s now  i am saying that if i already know that e has occurred then what can be the probability of the occurrence of a particular f i because  see  the thing is that f i intersection f j is empty ; and union f i is omega so  therefore only one of the events can occur here exactly  because they are mutually exclusive  so 2 events can not occur at the same time ; so this is occurred so  in that case what we are saying is that when e has occurred i want to compute the probability of f i occurring  right ; so that means  i want to compute the probability f i  given e  given that e has occurred so  again using this formula that i just wrote it  this will be p f i intersection e divided by this ; because probability e  i have just computed for you  is given by this and this is f i intersection e by my definition of the conditional probability so  this is this now  p f i  given e is the posterior probability of f i when e has occurred so  i am going to call this as the posterior probability of f i  given that e has occurred and so now  i take up an example to show you  what we mean by this  refer slide time  31  55  so  i will give you now an example of computing the base probability and here  i am considering this example ; and i you know  even in some other previous examples in the other lectures i have mentioned f i  which means that i am taking these examples from the book by shelton ross and i will give you a proper  the 2 books by shelton ross which book i referred to while preparing this lecture ; so i will give you the proper references at the end of the this section so  now  let us understand this problem very well there is an insurance company it divides its clients into 2 classes see  there is  somehow  there is this information that a sort of people  are both accident prone  then some others ; there is some ways of computing this and this may be because of the past history or something ; you know  if somebody has had lot of accidents and somebody has not had  then you know  because it shows companies they depend on the this kind of data so  let us see that class 1 is the set of people who are accident prone  and class 2 is the set of people who are non-accident prone  that means they had very few accidents in the past now  in the period of 1 year  the whole thing that we are looking at is during given period of 1 year  fixed period the probability of accidents for class 1 of people is 0.4 ; that means  the probability of accident prone  having an accident is 0.4  and the probability of non-accident prone person having an accident is 0.2  and in that fixed period of time that you have and it is also known that 30 percent of the population is accident prone that means the number of people being in set 1  the probability is 0.3  ok now  suppose the event we are looking at is that a new policy holder will have an accident within a year of purchase of the policy so  there is a person who has just bought a policy  insurance policy and now  you want to compute the probability this person will have an accident within the year  ok ; within the year of the purchase of the policy so  again using this decomposition principle i say that probability e can be written as probability e condition on i into  probability i plus  probability e condition on 2 ; so that means this is the accident prone  and this is non-accident prone so  probability e condition on 2  into probability 2 ; that means the people having accident  right ; when i said that p 2  i mean that probability of a person who is non-accident prone having an accident and here  this is the probability that an accident prone person has an accident and i have this probabilities  right i have this probability so  the whole thing is accident for set of people in i  which i am writing in short form as p i  and for this i am writing p 2 so  this we can easily compute because this conditional probability is given to me which is 0.4  right ; given that the person policy holder is accident prone ; if he has an accident that probability is 0.4 and the probability that the person in accident prone  0.3 so  therefore  this number is 0.4 into 0.3 plus  the probability that the person policy holder having accident when he is non-accident prone ; that probability is given to me as 0.2 and then the probability that he is non-accident prone is 0.7 so  when you compute this number  this comes out to be 0.26 ; that means  a new policy holder having an accident within a year of purchase of the policy is 0.26 now  i want to compute this conditional probability i  given e ; that means  an accident ; so when you look at the intersection ; so this will actually be by our definition i intersection e divided by p e  right ; which means that ; see  if you just read this  this intersection of 2 event says that a new policy holder that means  a person who has purchased a policy currently and is accident prone will have an accident within a year of purchase of the policy  right if you read carefully  the event i intersection e  e simply says that a new policy holder that was a person who has just purchased the policy will have an accident within a year ; i says that the person is accident prone so  therefore the intersection will be that if accident prone person  the policy holder will have an accident within a year of purchase of the policy so  that is this and this is divided by p e  right now  what i will do is because  so i  given e conditional e  i do not have ; but i have this probability so  therefore  using this definition of  remember i gave you the alternative definition of intersection of the set so  this is p i intersection e ; i can write this as p e  given i ; that means  accident prone and then the person is having an accident within a year into  p i divided by p e p e  i have already computed as 0.26 and so here  this is 0.4 into 0.3  this i already know  right  remember  from here the first part  and so this is ; so now this goes up to 0.4615 so  earlier probability for accident  for accident prone  right ; earlier probability for an accident prone person to have an accident was for ; earlier probability for accident for i was  sorry ; this is 0.4  right ; probability of accident for an accident prone was 0.4 but now  the posterior probability ; that means  after knowing that the person had an accident  remember  i am computing now that policy holder has had an accident so  the probability accident prone person having an accident mean that he has had an accident has now gone up to 0.4615 so  the posterior probability of accident for the accident prone has gone up from 0.4 to 0.4615 so  actually this is a little complex concept and i will keep coming back to it through examples to make sure that you  you sort of get a better feeling for these computation of base probability  ok  refer slide time  39  16  now  the moment you define conditional probability  you then come to the concept of independent events so  let me first motivate the reason  motivate the definition and so here you see what is being said is that  if this conditional probability of e given that f is occurred  is equal to p e ; that means  that the occurrence of f has no effect on the occurrence of e  right ; because this probability has remained unchanged  eventhough i know that event f has occurred so  these are the kinds of things because you want to know what kind of events can have effect on the occurrence of some events and so on so  this is also very important concept and you need to know how compute it so therefore  if this is so then you see  by definition of the conditional probability of e given f is p e intersection f divided by p f  but then we are saying that this is equal to e  probability of e  right that means  i am just trying to formulize this concept that if occurrence of an event is not dependent on some sense on the occurrence of another event  then we would be defining the concept of 2 events being independent and so this is  essentially this is what you will say ; that if this is equal to this  then occurrence of f has no effect on the occurrence of e and now  by our definition of conditional probability i will write it as this ; that since this is equal to p e  this implies that probability of e intersection f is p e into p f and so this is our concept of 2 events being independent and so i will just write down the definition 2.9 which says that 2 events e and f are said to be independent  if p of e intersection f  that means  probability of e intersection f  is equal to p e into p f  right so  let us look at this example a card is selected from an ordinary pack of 52 playing cards now  e is the event that selected card is a king  fine ; and then f is the event that the card is a club then  we can immediately show that the events e and f are independent which you can also argue intuitively also  that the king need not be a club  and so on so  let us now show that ; this gets validity by definition also see  to compute the probability of e that the selected card is a king  so since there are 4 kings in the pack  so therefore  the probability of p e is 4 by 52 and selected card is a club  so 13 cards belong to the club so therefore  the probability of f will be 13 by 52 and p of e intersection f is probability king of club  so that is only 1 card  and therefore the probability of that is 1 by 52 so  therefore  p of e intersection f is p e into p f which is 13 by 52 is 1 by 4 ; and so 4 into 4 gets cancelled and so p e into p f is also 1 by 52 so  the 2 probabilities are equal ; and i therefore  e and f are independent so  if you look at this other example ; 2 fair dices are rolled ; and i if e 1 is the event of sum of 2 numbers is 5 ; and f is the event that the first dice shows 3 then you see e 1 intersection f is simply with the event 3  2 ; that means i must have the pair 3  2  then only  you all know that this is already 3  so then this number must be 2 inorder for the sum to be 5 and this again the probability is 1 by 36 ; but p e 1 is what ? that means  e 1 is the sum of the 2 numbers being 5 ; this is  2  3    3  2    1  4  and  4  1   so  these are the 4 possible pairs which will give me the sum as 5 ; and so this probability will be 4 by 36 ; each being equally likely and the first phase showing you 3 is 1 by 6 because here again each phase is equally likely  each number is equally likely so  then this probability of e intersection f is not equal to p e into p f so  we will say that p and f are not independent events  refer slide time  44  16  now  consider the event e which is the sum of 2 phases is 7  right so  if i change the event from e 1 to e which requires that the sum of numbers on the 2 phases is 7 ; then you can see that these are the pairs which are valid  so this event and therefore  they are 6 in number so  probability e will be 6 upon 36 which is 1 by 6 ; and probability f already we have seen which says that the first dice must show number 3  so that probability is again 1 by 6 and so now you see that  if you look at the event e intersection f  since f says that the first dice has to show the number 3 so then for the sum to be 7  the second dice must show the number 4  so this is the only possible element of omega which is favorable to yield this section f so  therefore  here the probability of e intersection f is 1 upon 36 which is equal to p e into p f so  therefore you see  you can see how one can define events which given the event f ; for example  what are the event which are independent of f  and which are not in the earlier case when we took the event e 1 to be  the event of the sum of the 2 phases is 5 ; then you saw that p e n f where e 1 and f are not independent ; then if i take the sum to be 7 then it says the 2 events are independent and now  if you try to define another event e 2 phase which says that the sum of 2 phases is 8 then again you can show that f and e 2 will not be independent so  you should now play around and get a feeling for the definition by constructing different ; take the same experiment that is throwing up of 2 dices ; and then try to construct a set of events which are independent  which are not  and so on so  you can get better feeling now  continuing with the  again as you see you define a concept ; then using the axioms we come up to new propositions ; and you see the theory keeps developing so  if 2 events are independent then you will say that e and f complement are also independent which is very intuitive and if you able to rationalize it  but in any case  we will prove it analytically also so  the proof is simple if e and f are independent then by definition probability of e intersection f is p e into p f ; and i since we have already seen that you can write p e as probability of e intersection f  plus probability of e intersection of f complement so  then we want to compute this ; so this will be  from here probability of e intersection f complement will be p e minus  from here p intersection f  but then because e and f are independent so  p e intersection f  i can write as p e into p f ; and so you see this comes out to be p e multiplied by 1 minus p f i can take p e common outside 1 minus p f is probability f of complement and therefore  probability of e intersection f complement has been shown to be equal to p e into p f compliment ; and therefore  by our definition e and f complement are also independent and which says that if occurrence of f has no effect on the occurrence of p ; and when i say occurrence that means the probability we are talking of so  e and f being independent shows that occurrence of f is not equal to the occurrence of e therefore  occurrence of  non occurrence of f shows somewhat have an effect on e so  that is what we have concluded  that if e and f are independent  then e and f complement are also independent then  now here  i am again just make it a statement and i want you to construct examples for yourself  so that we are saying is that  if suppose e and f are independent  and e and g are independent  then e may not be independent of f intersection g now this may not sound very intuitive but  you can construct sets e  f and g to show this  right ; so that means  now  i have already told you to explain this the example that i took earlier and now i want you to also construct sets e  f and g  construct an experiment ; and then construct the corresponding events e  f  and g to show that if e and f are independent  and e and g are independent then e may not be independent of f intersection g and infact  you can  you know  that the throwing of 2 dices that i have taken up to experiment and there also you can construct such e  f and g to show this is valid  this statement is valid but then i can come back and discuss some examples with you now  if you want to extend the concept of independence of 2 events or more than 2  then i will just show how things start becoming difficult  even if you just take the  want to extent the concept to 3 sets  that means if 3 events e  f and g are independent then we require that not only should the probability of intersection of e with f with g and intersection with g should be equal to the product of the individual probabilities but  when you take 2 at a time  these 3 sets  from these 3 sets  then p of e intersection ; that means  any 2 subsets here should also be independent it is not just that the product of the  probability of the intersection of the 3 sets is equal to the product of the individual probabilities  that when you take 2 at a time then also that should be  the condition of independent should be satisfied so  all 4 conditions have to be met before we can say that the 3 sets  e  f and g are independent  refer slide time  51  02  so now  here again we need to construct ; and we can immediately see that the moment you have increased the number of sets  and you want to talk about their independence  then this will get more complex ; and the number of conditions will go on  becoming larger and larger so  therefore  i just leave it at this point for this thing and then one can always look up at textbooks where they will give you conditions for any independent sets  i mean  any number of subsets so  here again a interesting way to try to understand this concept would be to construct subsets e  f and g which may satisfy not all the conditions  but only some  to show that all 4 conditions are necessary for independence of the 3 events  e  f  and g so  i will now take up set of exercises too  and then we will come back to constructing examples for these situations introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  4 random variables cumulative density functions expected value  refer slide time  00  18  let me fill up a few gaps in the last lecture so  for example  this was i had discussed this card game bridge game ; there was an example number 2.7  which i was talking about a game of bridge in which 26 cards have been dealt to people to the players a and c if you remember there were 4 players a b c d so  26 cards have been dealt to the players a and c with 7 clubs so  we wanted to compute the probability that player b gets 4 clubs  right now i was trying to say that i was trying to show this as an example of computing the conditional probability that is already 7 clubs have been dealt two players a and c so  what is the probability of b getting 4 clubs ? but now i wanted to then show you that  and  of course  we solved out the problem ; i told you this is the probability  but then it is not possible to explain this through the conditional probability argument so  therefore  i just want to tell you that there are other ways of computing this probability and that is by reducing the sample space so  now  instead of you know taking the distribution of 52 cards to the four players ; i am just reducing the sample space  because 26 cards are now left  out of which 6 are clubs because 7 have already been distributed to players a and c so  then this is now your multinomial distribution so  what you are saying is that out of 6 clubs  b should get 4  and then from the remaining 20 cards  he should get the other 9 cards so  that way he gets 13 cards so  this is the number of ways in which he can get 4 clubs out of 6 and 9 cards out the remaining other 20 cards so  this is the number of ways in which this can happen  and the total number of ways in which he can get 13 cards out of 26 is 26 choose 13 so  this is the actual probability  and this we can get by reducing the sample space so  this is another technique which is very helpful and at times you can very easily compute the required probability by doing this  right so  you do not have to always go through the actual formula ; you can always play around with alternative ideas also  okay now remember i asked you to construct examples when we were talking of independence of three sets  right and in that case  i showed you that there are four conditions which have to be satisfied before you can say that the three sets are independent and then i asked you to construct a counter example to show that suppose the last three are satisfied ; that means pair wise  if we choose any two sets from here  they are independent they satisfy the condition of independence ; that means your probability of e intersection f is p e into p f probability of e intersection g is probability of e into probability of g  and similarly probability of f intersection g is product of the probability p f into p g so  you can construct situations where let us say last three conditions are satisfied  but the first one is not satisfied and so i believe into leave my hand on this example here suppose your sample space consists of these four numbers so  where each number is equally likely ; that means the probability of any number coming up as a result of the experiment has probability of 1 by 4  because they are equally likely  and there are four elements in omega your sample space now let us choose e to be as consisting of the numbers 1 4 ; f to be consisting of the numbers 2 comma 4 and g 3 comma 4  alright in that case  you see if you see the probability of p e p f and p g is 1 by 2 because there are two numbers totally four so  2 by 4  again we are using the same concept  because outcomes are all equally likely ; therefore  i am using the m by n version of the probability and so this is half for each of the sets  then probability e intersection f now e and f have only four in common so  that is one singleton  and that probability is 1 by 4 which is the product of p e into p f so  similarly  you see that the pair wise independence has been you can easily verify that the three sets are pair wise independent  but when you write e intersection f intersection g that again results in single number 4 and so this probability is 1 by 4  but this is not equal to p e into p f into p g which is 1 by 8  okay and  therefore  now you get an idea and you should try to construct one example of your own to show that pair wise independence of three sets is not enough to say that the three sets are independent i mean the three events are independent  right we should be able to construct and as i said that extending this becomes little more cumbersome and so we will leave it here only  right  refer slide time  05  41  now exercise two  of course  i have given you the corrected version  okay so  this is there  and question ten in exercise two  i want to revisit because when i was reading it last time ; i said that this needs a little thought and so let us revisit the problem so  actually you are given the data that a battery as a lifetime so  there is a probability that the battery will last for more than or equal to 10000 kilometers that probability is given to be 0.8 and the probability that it will last more than or equal to 20000 kilometers  the probability was given as 0.4 and then that it will more than or equal to 30000 kilometers also a probability is associated with it and you were asked to find that if you have bought a battery which is already run for 10000 kilometers what is the probability that it will be running for more than 20000 kilometers ; that means its lifetime will be more than 20000 kilometers if it is already run 10000 kilometers so  this is a simple case of conditional probability computing the probability that the lifetime say if i let l  denote the lifetime of the battery we are wanting to compute the conditional probability of the event that the lifetime is more than 20000 kilometers given that it is already 10000 kilometers old the battery ; it has run that much and so by our formula now when you take the intersection of these two  so obviously  this is a subset of this and  therefore  the intersection simply becomes l ; that means you are wanting the lifetime to be greater than or equal to 20000 kilometer when it is already run for more than 10000 kilometers  right so  the intersection of these two would be this  because you want the battery to run 10000 kilometers and you want the battery to run 20000 kilometers intersection would mean that you want the battery to run for more than 20000 kilometers and so this is divided by the probability of this event which is l greater than or equal to 10000 and  therefore  this is equal to 0.4 by 0.8 which is half so  this is the solution so  i just thought that if you have thought about the problem may be some of you have already done it but then this is the right answer  okay we have talked of condition probability but i just thought that should formulize this in some more in the sense that see we are defining now given an event a  then we are computing the conditional probability of events conditioned on f  right so  want to show that this is the function that you have defined here that conditional probability function satisfies the three axioms of probability and not too difficult to compute to show  because the first axiom requires that this for any event e  the conditional probability with respect to f must be within 0 and 1  alright ; that is the first axiom  so  here if you take probability e condition on f  then by definition this is this now you see that e intersection f is a subset of f  alright ; this is a subset of f and  therefore  we have already shown remember after giving the axioms  we proved some propositions and there i showed that if subset is subset of another subset  then the probability would be so  that means here probability e intersection f will be less than or equal to probability f  alright this is because this is a smaller event in the sense that it is a subset of this ; therefore  the probability of this is less than or equal to this ; this we could easily show  right and by definition  of course  probability e condition f is nonnegative  alright this is nonnegative ; this is nonnegative so  this is nonnegative so  therefore  the first axiom is satisfied  because p intersection f is less than p f so  i divide by this ; this is less than 1  and this is nonnegative so  first axiom is satisfied now second axiom said that your probability omega should be one so here for us because we are conditioning on f so  the corresponding axiom would be that probability  okay ; this should be again the same thing i have to say that omega condition on f  so what will this be ? this  and  therefore  now when you take omega intersection f  this will be probability f this is equal to 1  right  okay so  therefore  probability f divided by probability f is 1 so  probability for mega condition on f is 1 so  the second axiom is satisfied and the third one requires e i intersection f divided by p f  refer slide time  11  36  now this i can write as see here this is this  then because distributive law holds  this can be written as union e i intersection f  i belonging to i this thing now because e i intersection f are disjoint  since  e i are disjoint  right i have taken sequence of disjoint events e i is here so  e i intersection f r disjoint and probability p  the original probability function satisfy axioms three  alright and therefore  this can be written as summation of probabilities e i intersection f divided by p f  alright  which is equal to so  this can be written as summation probability e i condition f  alright  i belonging to i so  the third axiom is also satisfied therefore  the conditional probability function is also a probability function ; that is it satisfies the three axioms  okay now again i just want to continue working because conditional probability function is an important concept so  again little elaborated example that i would take gamblers oh  here fine so  this problem would be coming after i define for you the conditional probability now i want to discuss the gambler ’ s ruin problem which is interesting example of use of conditional probability so  let us see there are two gamblers a and b  and they bet on the outcome of the toss of a coin  alright now if on each toss if h occurs that means if the head shows  then a collects one unit from b and if tail occurs ; that means if t occurs  then b collects one unit from a so  this is all a simple game you toss a coin and then if the head shows  a gets the money  and if tail shows  b gets the money from a  okay now tossing of the coin continues till one of them runs out of money so  that is the gambler ’ s ruin problem  right so  one of them will end with all the money and the other one will have no money left so  suppose total money is 15 units  i am just taking a number 15 you will see that through a solution  it does not matter ; whatever the amount of money that they start with and has i units so  that means b will have 15 minus i units with him  okay now tossing of the coin are independent events  and we are assuming that the coin is biased so  therefore  probability h is p and probability is 1 minus p we will also consider the case when p is half  okay now if we want to find the probability that a ends up with all the money and we have assumed that at the starting point  a had i units of money with him  alright so  let e be the event that a ends up with all the money and let p i denote the probability because we are staring the game when a had i units so  i am just denoting it by p i which is the probability of e ending up with all the money and a had i units to start off  right  refer slide time  14  59  now we have been using this technique very often  because when you are tossing a coin  your sample space is consisting of just h comma t  right ; two points on the sample space and so you can write p e in terms of conditional probability p given h ; that means now this we are saying that we are starting the game so  the first toss of the coin either results in h or in t so  this is conditional of e ; that means this is the probability of e this is the event that a ends up with all the money starting with i units when the first toss results in head so  this is that event  right so  that into p h plus this is again the similar interpretation that a ends up with all the money when the first toss of the coin shows a tail  alright so  this is this into p t now when the first toss of the coin gives you head  then a collects one unit from b so  therefore  the money at the end of this after the first toss  a ends up with money i plus 1  alright  and if the first toss shows a tail  then a will have to give one unit of money to b  and therefore  he will have i minus 1 so  therefore  as i said in the beginning  i am denoting by this p i because a had i units of money when the game started so  therefore  this equation can be rewritten as p i is equal to p i plus 1 because this will be then the probability that now a has i plus 1 units  and you want to compute the probability that a ends up with all the money  alright  and then this into p ; probability of getting a head  then here a will lose one unit of money to b so  it will be p i minus 1 into 1 minus p so  1 minus p we can also write as q now since p plus q is 1  i can multiply this by p plus q and write this equation in this way  alright and then rearranging the terms that means see p i plus 1 minus p p i i bring here  and p i minus q i take to this side so  i get this equation from this equation  and that gives me that p i plus 1 minus p i is equal to q by p into p i minus p i minus 1 so  i get a recursive relationship between this p i ’ s  okay and boundary conditions are that if p had no money ; obviously  the probability of his ending with any money is 0  because  he will not be able to play the game  alright so  p 0 is 0 and p 15 because the moment he has won the game and so the probability is 1 so  p 15 is 1  okay  and p 0 is 0  alright so  therefore  now we use this recursion and we start with i equal to 1 so  when i is equal to 1  this will give me p 2 minus p 1 is equal to q upon p ; p 1 minus p 0 so  p 0 is 0 and therefore  i get this equation  then when i put i equal to 2 in this recursion  i will get p 3 minus p 2 equal to q by p  p 2 minus p 1  but p 2 minus p 1 from here is q by p p 1 so  it will be q by p whole square p 1 and so this way you can go on writing the differences so  p 15 minus p 14 will therefore become q upon p raise to 14  because whatever the number here and that is 1 less than this so  the power of q by p is 14 into p 1  alright adding up  we obtain ; so now i add up all these equations  then you see these things will cancel out in pairs  alright  and you will be left with p 15 minus p 1  but p 15 is 1 so  this is 1 minus p 1 is equal to and on this side q by p you can take outside so  it will be 1 plus q by p plus q by p whole square and so on up to p raise to 13 into p 1  alright and now this is a geometric series ; i can write down the sum so  this will be 1 minus q by p raise to 14 upon 1 minus q by p now this is a finite geometric progression so  therefore  it does not matter the only thing i need is that i can do this if q by p is not equal to 1  alright  because  otherwise  i will be dividing by 0  refer slide time  19  28  so  if q by p is 1  then p 15 minus p 1 you immediately get is 14 p 1 ; in the last equation you substitute q by p is 1 everywhere and so from here  you will get p 15 is 15 p 1  alright  because p 1 gets added here and  therefore  p 1 is 1 by 15  and now you can easily compute your p 2  p 3 and p i  okay ; by going backwards you can compute your this thing  fine so  we consider the case when q by p is not 1 ; in that case  what we got from the last slide is 1 minus p 1 is q by p 1 minus q by p raise to 14 upon 1 minus q by p using the geometric progression series sum so  if you take p 1 to this side  then you get this and now you just simplify  and after simplification  you will get that 1 minus q by p raise to 15 upon 1 minus q by p into p 1 is 1 so  p 1 is 1 minus q by p upon 1 minus q by p raise to 15  alright and so the required probability again from your recursion equations  you will immediately get that required probability p i ; that means when a started with i units of money would be 1 minus q by p raise to i upon this  because that sum will be up to q by p raise to i minus 1 and so you will get this so  you substitute for p 1  so 1 minus q by p will cancel out  and you will get this  alright so  now if you want to find the probability that b ends up with all the money replace p by q and i by because now for b the p is q and the money that b starts with is 15 minus i so  when you make these two replacements  you will again get the formula for using the probability that b ends up with all the money  alright  okay  refer slide time  21  31  now again continuing with some more results on conditional probability ; so this is proposition of 2 point 5 what we are saying is that suppose you are given that conditional probability of a given b is 1  then you can show that conditional probability of b complement given a complement is 1 so  here i could have also given this as an exercise  but i just thought i will show you some more ways of doing it and then you can apply it to ; for example  i think you can show that conditional probability of a complement given b will also be or okay  that will be independence  fine  alright so  right now just look at the definition so  the conditional probability of a given b is this now since this is equal to 1  it follows that probability a intersection b is p b so  the moment you get this result  you can see that a probability a union b which is written as p a plus p b minus p a intersection b this will because this thing is 0 p a intersection b minus p b so  it reduces to p a so  therefore  your probability a union b reduces to p a  alright  and  therefore  when you take the complement of a union b so  probability of a union b complement will be 1 minus p a  which is nothing but probability of a complement and so then again by de morgan ’ s law we had seen that a union b complement will be a complement intersection b complement so  this probability is  therefore  probability of a complement  alright  and hence  your probability of b complement conditioned on a complement is this now since these two things are the same  therefore this reduces to 1 so  one can go on  and  therefore  now the idea would be that you should get interested enough to try out many more results related to conditional probability  solve more examples  okay now final result on conditional probability is now this is conditional independence remember we defined independence of two events if the probability of the intersection of the two events is equal to the product of the individual probabilities now same thing gets extended so  we say that e 1 and e 2 are said to be conditionally independent given that event f has occurred so  if probability e 1 conditioned on e 2 intersection f is probability e 1 conditioned on f ; that means the occurrence of e 2 the same definition that we gave for independence of two events occurrence of e 2 has no bearing on this probability  alright so  that means when you condition it on e 2 intersection f  it is the same as conditioning on f and e 2 has no role to play  alright now in fact so we will just write it out so  this is one definition but you can come to a better result and this is we say that e 1 so  therefore  by definition e 1 condition e 2 intersection f  this probability can be written in this way  alright and this is given to be by the definition of e 1 e 2 being conditional independent ; this is probability event e 1 conditioned on f  alright so  therefore  from this two  you get that this probability is equal to e 1 f and this probability of e 2 intersection f i can write as e 2 conditioned on f into p f  alright so  this is the result and this one also again now i can condition on f so  this will give probability e 1 intersection e 2 conditioned on f into p f and this so  p f p f cancels out  because remember  whenever you talk of conditional probability with respect to the event  then that probability has to be positive ; otherwise  you can not define it so  of course  it is understood that p f is greater than 0 so  therefore  i can cancel out p f here and i will be left with probability of e 1 intersection e 2 conditioned on f is the product of the individual conditional probability is that is probability e 1 conditioned on f into probability e 2 conditioned on f so  this is you just extend the original definition of independence of two events to in the same way  and so i will take up now an example a little elaborate example to show you the use of conditional independence  refer slide time  26  18  after defining conditional independence of two events respect to the occurrence of another event  i will now take up this example it may look a little complicated  but it shows good use of concept of conditional independence so  here again this example i have taken from sheldon ross surprisingly  this book i will give you the reference later on it has lot of new and innovative examples  and  therefore  i am using a quiet few of them here in this course so  now consider the situation when there are k plus 1 coins in a box  right  and the probability of choosing the i th coin there k plus 1 coins in the box and if i pick up the i th coin and toss it then the probability of its showing a head i th coin shows a head is i by k and i varies from 0 1 to k so  that means  you can see that when i is 0 ; that means if you pick up the zero th coin  then the probability of its showing a head is 0  which means both sides must be tails then if you happen to choose the second coin  the probability of its showing a head would be 2 by k  alright and similarly  if we choose the coin the k plus 1 th coin which has the number k  then the probability of showing a head would be k by k which is 1 so  probably this particular coin the k plus 1 th coin is having head on both sides so  whatever it is  the situation is this now a coin is randomly selected from the box and is repeatedly tossed  this should be repeatedly if the first so  let me just make the correction here so  it is repeatedly tossed  okay if the first n tosses all result in heads  what is the conditional probability that the n plus first toss will also result in a head so  that means i pick up a coin at random from the coins which are there in the box then i repeatedly toss it and if the first n tosses have shown heads  then i want to compute the probability that the n plus first toss will also result in a head so  let us see ; we will start finding out how to compute this probability so  suppose c i is the event that the i th coin is initially selected and this could be any of the 0 1 to k numbered coin  alright  then f n is the event that the first n tosses resulted in heads and then h is event that we want so  n plus first toss results in head so  i want to compute the conditional probability of h given f n  given that f n has occurred so  we have had n tosses and now i want to compute the probability that the n plus first toss will also be a head ; we will show head and this is the expression so  i am going to derive it for you since  one of the k plus 1 th coin will be selected  right so  then f n can be written as f n union c i because at least one of the coins so  this probability  probability of c i union c i  i varies from o to k will be 1  alright so  f n can be written as f n union i varying from 0 to k c i  and therefore  probability h conditional f n which can be written as this  then from f n i can write this expression union f n intersection c i  alright  and again by the distributive property of intersection and union  i get that this can be written as probability of union i from 0 to k h intersection f n intersection c i  alright  because this is this and then this because you see all the c i ’ s are mutually exclusive  right  because one of the coins will gets selected so  therefore  these events become mutually exclusive and so probability of the union can be written as sum of the probabilities  i varying from 0 to k h intersection f n intersection c i divided by p f n  alright  refer slide time  30  57  now this cone i can write in terms of conditional probability as h condition f n intersection c i into probability f n intersection c i divided by p f n  alright then this remains this ; this again i can write in terms of conditional probability c i condition f n into p f n so  p f n p f n cancels because f n is given event so  therefore  probability f n can not be zero and so i get this expression which is written here  alright  okay now it is reasonable to assume that repeated tosses of the i th coin are conditionally independent this is i am using the concept ; that means to assume that the repeated tosses of the i th coin are conditionally independent with respect to of f n that means see i am considering the case when coin was picked up randomly  then it resulted in tosses showing heads and now when i tossed further  so then they will be conditional independent of f n  okay  which means that probability h condition f n intersection c i is actually probability h condition c i only so  f n has no main role to play here  right ; this is what our definition of remember we said that e 1 given e 2 intersection f if i wanted to say that e 1 and e 2 are conditionally independent with respect to f given that f has occurred  then this is probability e 1 f ; that means e 1 and e 2 are conditionally independent when f has occurred so  then e 2 has no role to play on the occurrence of conditional happening of e 1 given f so  the probability would be independent of the event e 2 so  the same thing here we are saying that here f n because it is conditional on f n so  this probability is f n has no role to play here and so probability h given c i so  this is what we are assuming here  and therefore  each of this probability is i by k  alright so  now that means i can now apply this in the formula here and this is i by k so  that means you are getting because you have got n heads have shown up and probability of each head is i by k  and i am assuming that the tosses are conditionally independent so  therefore  this is i by k raise to n and the n plus first toss gives you a head will be 1 upon k plus 1 because there are k plus 1 coin there sorry  so this probability is what am i writing here  yeah  c i f n so  h given f n so let me just check out here this is c i f n  right so  a probability of picking up the i th coin so  again if we just pick up the i th coin that probability should be 1 upon k plus 1  because any of these coins are equally independent  remember a coin is randomly selected ; so that means any of the coins is equally likely when you pick up from the box so  therefore  the probability of picking up a coin is i by k plus 1 so  therefore  this becomes this and  similarly  here  yeah  so actually what is happening is that c i f n ; yes  i missed out on the spot so  probability is c i given f n i have rewritten as this so  this is probability f n condition c i into p c i and then this is sigma j varying from 0 to k f n so  the probability f n i am writing in this way f n condition c j into p c j so  this is where so now probability f n given c i is since the things are conditionally independent  the probability of picking up a head remains the same so  when you want to pick up n heads  this will be i by k raise to n and probability c i will be 1 upon k plus 1  right and then here similarly this is summation so  j varying from 0 to k j by k raise to n and 1 upon k plus 1  because now here your j is varying ; this corresponded to the i th coin that you have chosen so  this is the thing so  this is just a computation i wanted to illustrate maybe you can say that it is an engineered problem or whatever it is  but somehow you could make use of the concept of conditional independence and arrive at this result and again through methods of calculus  you can actually show that if k is large  then this probability is approximately equal to n plus 1 upon n plus 2  okay so  therefore  it gets simplified when you have a large number of coins in the box  but  otherwise  continuously you broke up the so  here in this expression  yes  c i conditional f n ; this also i had to rewrite in this decomposed form and then apply the probabilities to get this expression so  that was missing here  yeah  okay  fine so  this is an example and often there will be situations when you would be coming across the concept of conditional independence let me discuss exercise two with you ; again i will just try to give you brief hints  refer slide time  37  02  question one says that you have to compute the probability that only exactly one of the events e and f occurs and that is equal to probability e plus probability f minus 2 and of course when we say minus 2 probability e f ; that means e intersection f so  that notation is also acceptable ; you do not write the intersection sign you simply say e f ; so that is what it means  right now if e f and g are three events  then you have to find expression so  again i am just wanting you to be familiar with how you write express events in terms of your complements  union and intersection so  here i want you to write  find expression for the events  so that of the three events e f and g  only e occurs so  if you want to write this  then in the two you have to write exactly two of them occurs  right ; exactly two of them occur so  the third one should not occur so  you can imagine that you will have to use unions and complements  right now in question three  this is actually very simple ; the slash sign the condition sign is sort of dim but anyway so  this says that if probability a is greater than 0  then show that probability of a intersection b condition on a is greater than or equal to probability a intersection b condition on a union b so  that is very straightforward actually  refer slide time  38  35  and now you have to show that the conditional probability of a intersection b given a is greater than or equal to conditional probability of a intersection b given that a union b has occurred so  it is very simple  because you see a is a subset of a union b  and as we have already discussed that probability of a union b will be greater than or equal to probability of a  right and in the left hand side when you compute the conditional probability  you will have a in the denominator numerator is probability a intersection b because a intersection b intersection a is again a intersection b so  this is what actually you have to figure out and  similarly  on the right hand side  the numerator is the same  but denominator would be probability of a union b and since probability a union b is bigger or equal to probability a  you have the required inequality so  i just gave it to you to be able to just you know figure out these things  and therefore  then you can answer the question so  if you write the expressions  you can immediately give the answer to this question now the problem four is from sheldon ross ; actually it should say sheldon ross or ross sheldon in answering a question on a multiple choice test  you know where you have more than one choice and you have to take the right one a student either knows the answer or she guesses let p be the probability that she guesses assume that a student who guesses at the answer will be correct with probability 1 by m  where m is the number of multiple choices  right  because if she is guessing  she does not know so  out of the m choices  any one of them is equally likely ; so the probability is 1 by m what is the conditional probability that a student knew the answer to a question given that she answered it correctly and i have given the answer here so  now what are we saying what is the conditional so  please enter probability what is the conditional probability that a student knew the answer to a question given that she answered it correctly ? so  use the concept of conditional probability and then you should be able to do it  right and now again this problem is from sheldon ross ; at a certain stage of a criminal investigation  the inspector in charge is 60 percent convinced of the guilt of a certain suspect  okay so  his conviction is that the 60 percent ; that means 0.6 is the probability of the person being guilty now suppose that a new piece of evidence shows that the criminal has a certain characteristic such as left handedness  baldness  brown hair  etc so  it tells out that through some eye witness who may have seen the criminals of doing the act  the eye witness can only say that the person was either left handed ; one of the characteristics is owned by the criminal is uncovered so  through some facts  it is found out that whoever committed the crime has one of the characteristics  right if 20 percent of the population possesses these characteristics that means in a town  crime has taken place and so what they are saying is that 20 percent of the population possesses this characteristics how certain of the guilt of the suspect should the inspector now be ? instead of how it should be now be  if it turns out again  yes  if it turns out that the suspect is among this group so  now this is the situation for computing the base probability because you see first initially the inspector is 60 percent convinced of the guilt of a certain person now it has been know that the criminal possessed some characteristic which it turns out that this suspect has that characteristic so  therefore  the probability of the suspect being a criminal would go up so  the posterior probability after knowing that the criminal possesses the characteristic will go up so  therefore  i want you to compute the posterior probability here problem six says a parallel system functions whenever at least one of the components work consider a parallel system of n components and suppose that each component independently works with population 1 by 2  find the conditional probability that component one works given that the system is functioning so  here you have to use concept of independence and the conditional probability  refer slide time  43  35  problem seven says that you have to either prove or give counterexamples to the following statements which are self explanatory you should be able to either show that the statement is valid ; otherwise  you construct examples to show that it is not now problem eight i am asking you to show that if e f and g are independent  then you have to show that e is independent of f union g see remember now here i am using the definition of three events being independent so  you have these four conditions that will be satisfied and then you can easily show that e is independent of f union g in fact  whatever subsets you find by operation of you know taking intersection  union or complement and then taking operations on those you can show that e will be independent of any of such event which is obtained by doing the operations of intersection  complement and so on from f and g ; this is what we are saying here now store a b and c have 50  75 and 100 employees and respectively 50  60 and 70 percent of these are women  alright  okay so  that means store a has 50 employees and of which 50 percent are women so  you can immediately say that 25 are women similarly  75  so 60 percent of the employees in store b are women and then 70 percent of the employees in store c are women  alright resignations are equally likely among all employees regardless of sex one employee resigns and this is a woman ; what is the probability that she works in store c ? so  now here again i am asking you to use bayes formula to compute the probability  okay so  one employee resigns that is given  and this is a women so  this is also given ; that means a women employee resigns  you have to find out the probability that she works in store c tenth  the probability that a new car battery functions for over 10000 kilometers is 0.8 the probability that it functions for over 20000 kilometers is 0.4  and the probability that it functions over 30000 kilometers is 0.1 so  these are all conditional probabilities if a new car battery is still working after 10000 kilometers  what is the probability that its total life will exceed 20000 kilometers and then its additional life will exceed 20000 kilometers ? so  problem ten  we will have to answer ; yeah  okay  maybe we will leave out problem ten from here and we will revisit it later on but problem eleven you can answer easily suppose that a person chooses a letter at random from reserve so  instead of chosen suppose a person chooses a letter at random from reserve ; that means it can be any of the letters r e s v and then chooses one at random from vertical what is the probability that the same letter is chosen ? so  this of course is your earlier from counting the number of combinations that are favorable to this thing ; that means see the two letters that are common between these two words are r and e ; that is it  right so  you have to now find out the number of ways in which r will get selected from both or e will get selected and you can see that for example in the first word reserve  r appears twice out of r e s e r v e and r in vertical appears only once so  you can accordingly find out the probabilities and then find out that and since the operation of choosing letter from reserve and from vertical are independent events the required probability would be the product of these two introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  5 discrete random variables and their distributions  refer slide time  00  19   i will now introduce the concept of random variables so  the whole idea is let me begin by giving some examples first suppose two dice are thrown up  and they are fair dice so  you can say that may be two fair dice are thrown up now  let x denote the sum of two numbers that show up  that means the two numbers whatever 3 4  1 2 whatever the two number show up when i throw the two dice  i add up the sum  i add up the two numbers and i denote that sum by x now  we can see that the number the values of x will vary from 2 to 12 now  since the outcome of tossing of the two dice is not certain  so that is a random phenomena  because any phase can show up  so any number can show up therefore  you see that the value of x is dependent on the tossing of the coin and whatever the outcome so therefore  this is what we mean by a random variable  so this is actually now you can see that before i start calling it a random variable i should explain more  see when x is equal to 2 when it corresponds to the point 1 comma 1 of the sample space i had earlier in my lecture shown you  when we were talking about when i introduce the concept of sample spaces i had shown you that omega the sample space will contain 36 pairs of such points i j  where i varies from 1 to 6 and j varies from 1 to 6 so  when x is equals 2  this actually corresponds to the outcome 1 comma 1 of the sample space both the phases much show one each  and therefore the sum will be 2 similarly  x is 3 then it can be either 1 comma 2 or 2 comma 1  so both of them add up to 3 and so on so  essentially trying to say  so one can now give a formal definition of random variable that is  so x is a real valued function that maps the sample space omega into real line and we call  so these x what we have described so through examples  this x is called a random variable and subsets  because these are all subsets this is the singleton  this is the subset containing two points of omega and so this is the again the number when x is 12  it will again corresponds to the singleton 6 comma 6 so  such a function which is a real valued function  and when it maps the subsets of the sample space corresponding to an experiment to real numbers  we will say that it is a random variable now  if you again taken other example considered the experiment of tossing a coin  till two consecutive heads appear so i toss a coin and unless i get two heads consecutively i will not stop now  the sample space can be if it happens in two tosses then i will get the outcome will be h h null stop here  but if you does not show head in the first trial  then it may show in the second and third  so that means this will happen in three trial  three tossing of the coin and so on so this will continue  and this may not have finite process this may not be a finite process  because you may continue throwing up to a tails so now  x is number of toss is required for two consecutive heads to appear  refer slide time  04  01  so  you see here for example in this case x will be equal to 2  then it corresponds to the outcome h h if x is 3 then it corresponds to the outcome t h h first toss gives you tail  and then the other next two tosses give you heads then x equals to 4 will correspond to this  and so you can go and writing different values of x  what will be corresponding subsets of the sample space omega so  again i will reiterate the same thing that since the value of a random variables are determine by the outcome of an experiment we can assign probabilities to the values it takes  because the probabilities associated with the outcomes of the sample space and since random variable is mapping subsets or this event from the sample space to real numbers  i can assign probabilities so  for example in throwing up of two fair dice  see even probability x is equal to 2 would be then in that case  probability of the singleton 1 comma 1 which is 1 by 36  because every pair each of the 36 pairs is equally likely  since the two dice of fair then when probability of x equals to 3 would be corresponding to the probability of the subset containing the pairs 1comma 2 and 2 comma 1  so this will be 2 by 36 so  just for your benefit  in fact you can complete you for completed the table by yourself so  this i will shown you for all different values of that x can take from 2 to 12  what are the corresponding subsets  and then the associated probabilities and since  one of the x must take one of the numbers  since x must take one of the numbers from 2 to 12  since you are throwing up two dice so  two numbers will show up and there sum will be one of the numbers from 2 to 12 so  then these are all possible around events that can take place and so  probability x equals to i from to i vary in from 2 to 12 should be 1  so this is the probability mass function  as we are i going to formally define the concept of probability mass function now  refer slide time  06  17  so  the random variables can be of different types  let me first consider the case when x is the discrete random variable so  as the names suggest  it means that it takes countable number of possible values and let say that the random variable takes the values a i  i varying from 1 to infinity now  of course when i say countable countably infinite or countabley finite  it can be either case  but the values are sort of you can enumerate the values that it will take now  so therefore we will say that probability x equal to a i is positive  because these are the values that it takes and therefore they will be positive probability associated with each of the these numbers so  this will positive and for all of the values of x it will be 0  that means when x is not equal to a 1 a 2 up to these thing  whatever the number of a i  then the probability at points which are not equal to any of these values is 0 now from axiom 3  since x must take one of the values a i  therefore when you add up the probabilities 1 to infinity  all these probabilities must add up to 1 by your axiom 3 now  this function which assigns probabilities to different values of a random variables that is called and in the case when it is a discrete random variable  we call it the probability mass function and as we have already seen the any probability function must satisfy 3 axioms so here  in short we also write pmf for probability mass function  all the time you can are go and writing these 3 letters so  normally i will be referring to it as pmf now  it helps to plot p x on the x y plane  so consider the probability mass function p  1  is 2 by 3  p  2  is 1 by 6 and p  3  is 1 by 6  so the random variables here is taking the values 1  2  3 and these are the probabilities associated with it so  you can draw a bar chart  so the idea is that you i know erect rectangles  so the height here is  this height is 2 by 3 and this height will be 1 by 6 so  that means the rectangle bar is centered at the value 1 and the height is 2 by 3  so this is the idea similarly  here this height of the bar is 1 by 6 and same as 3 now  you i have already was to give you one other random variable  which shows giving you the sum of the numbers that show up when you throw to a fair dice so  you can try to draw the bar chart for that random variable that will be a big one  because the values will takes from 2 to 12 now  so having defined random variable or the discrete case let me now associate some other functions with it so cumulative distribution function  so probability mass function we have already defined  refer slide time  09  28  now  this is the cumulative distribution function  which again i will be referring to as cdf in the short form so for every real number x the cdf of a random variable x is given by this equation so  capital f x of x is the notation for the cumulative density function  and this is actually the probability of x less than or equals to the real number x and so here this right hand side is actually the probability that your random variable x takes all values less than or equals to x  this is the idea it immediately follows that if you want to compute the probability x greater than a and less than or equal to b then this is this can be written as probability x less than or equal to b  minus probability x less than or equal to a sees that is why this is x greater than a  because you are subtracting for all sample points for which this capital x is less than or equals to a so  the probability of that  so therefore this becomes x greater than a and this in terms of our cumulative distribution function  we write f x  b  minus f x  a   now  all along the notation for this probability is cumulative distribution function  and if some place by mistake i call it as cumulative density function  then that has to be ignored the proper terminology is cumulative distribution function if you want to find out the probability of x lying in an interval  then you can define this in terms of  why should have actually said this is as f x  b  minus f x  a   so  you can immediately see  because here this is actually the equal to the event that x is less than b and x is greater than a so  x greater than a implies opposite of x less than a  so therefore minus x less than or equal to equals to a  because then this gives you the values of if you feel that you still need from explanation you can do it for yourself to say that  see for basically what you are saying is that from x less than or equal to b  you want to subtract the because a is less than b so  you want to subtract all values of x less than or equals to a  then you will get the this thing that x lies between a and b now  if x takes the value x naught see  because after all x is a discrete random variable  then the notation would be that f x  x  naught  and then f x  x  naught minus  so this actually says that your approaching the value x naught from the left so from values which are less than x naught  so where f x  x  naught minus is the limiting value of f x  y   where y goes to x naught minus and this notation means that  if you are number here is x naught  then your approaching they number x naught from the left of x naught minus this so  and this we will be clear in a minute  because so now let me just spell out the values here  so essentially what i am saying here is that if x 1  x 2  x n are the let say the finite n values that the random variable x takes  then an x 1 is less than x 2 is less than x n  see than what is happening is ? that the distribution function f x is the step function  because you see you say probability x less than x 1 then this is 0 in this case  because it is not taking any values less than x 1  and x 1 is the smallest value here so this probability 0  but then if you want to say probability x less than or equals to x 1 if you now do this  then what happens ? this is equals to probability x equals to x 1  because it is not going to take any other value any value less than x 1  only value in this region that x will take is equals to x 1 so  this is actually equals to  so in this case because is the first value this is equal to x 1 and so this is what happens ? now  so that means up to values less than just less than x 1  your when if you want to draw the graph  which i am showing you here  i am drawing the graph fine so  let me show you the graph for this first  you sees what is happening is that here the random variables taking the value 1 so  before that the value will be 0 so therefore  if i want to draw the cdf the cumulative density function for that random variable  then you see it is 0 and it is 0 till at the point 1 it takes a jump  because at point 1 when x 1 is 1 this will be equal to probability of x equal to 1 which is 2 by 3 so therefore  the function from 0 will take the jump  and so it will be this thing and then you see  for probability x less than or equal to less than x 2 if i do this then here it is again continuous to take this only  because less than x 2 or if you want to write 1 here in this case and this is 2 then as long as x is strictly less than 2 the number there is no other probability  because x is only continuous to take the value 1  and here also it takes the value 1 so  as long as x is strictly less than 2  that means as long as i am here some way here and not taking the value 2  my value of the cumulative density function remains constant so  this is like a step function  it continuous to be the same value as probability x equals to 1 and then the moment i say probability x less than or equal to 2  then this will be probability x equal to 1 plus probability x equal to 2 because now  for x less than or equal to 2 there are two possibilities x can be equal to 1  on x can be equal to 2 so  then the two probabilities will get added up  so that means it will be 2 by 3 plus 1 by 6 which will be 4 by 6 was will be 5 by 6 and you see so from 2 by 3 it takes a jump  and at 2 the value now becomes 5 by 6 and so the jump  and you can see that this jump that it takes is equals to the probability of that discrete random variable at that point  that means probability x equals to 2 so  till up to this point this was probability x equals to 1  the moment i said probability x less than or equal to 2  it become probability x equals to 1 plus probability x equal to 2 so  the value of the cumulative distribution function jump by the probability of x equal to 2 and finally  when you talk about probability x less than 3 again  it will continue to be this  because there will be no other value of x here and then the moment you make it less than or equal to it will take a jump  the figure is not accurate it will be this and so i here again  the moment i say equal less than or equals to probability of x equals to 3 will get added to it  and so again the jump will be by the probability  so that means this will be a discrete function or and a jump function or a step function whatever you can call and the point of discontinuities or the point of jumps that it takes will correspond to the values of the random variable  and the amount of jump that the functions takes will be equal to the probability of the equal to the probability of that of the random variable  taking that particular value where you considering the jump  refer slide time  17  54  to continue with the general case  when x takes the values x i  i varying how 1 to n  and x 1 is less than x 2 less than x n then value of f remains constant in the interval x i minus 1 comma x i  because it takes the value x i minus 1 and after that it does not take any other value when a variable  so the cumulative density function remains the same and you see this is the sign this say that is a closed at this end  and this is the open that means in this interval the values began from x i minus 1 to all values which are less than x i so therefore  for all these values your cumulative density function remains constant  which i will interpreter saying that because it is constants in this interval therefore  it is right continuous  because i am approaching from here  if i approach from the right hand side that means larger value then x i minus 1 then i will approach x i minus 1 this value of the function remains the same it is a constant  so it continuous and it attains the value at x i minus 1 so  the same value and therefore the function is right continuous  and what we just saw is that it takes a step or a jump equal to the size of the probability x i so that means at x i  it takes a jump which is equal to the probability of the random variable at that point x i and also we have see that it is an increasing function  and since this will be when you want to compute this  see this is equal to probability x less than or equal to x n and by this mean it has taken all the values for x less than or equal to x n means it has taken all the values x 1  x 2  x n so all the probabilities has been added up  actually so this is nothing but summation x i  i varying from 1 to n  and therefore it must add up to 1 so  this is what  now let me formulize properties of the cumulative distribution function so  as we have seen that the function has to be a increasing function so that means what do we mean by  when we say a function is increasing  that is the a is less than b then the value of the function at a must be less than or equal to the value of function at b  and this can be easily explained  i have already done it through example  but you see that the event x less than or equal to a is a subset of the event x less than or equal to b  because b is bigger than a so  all the values that are that give you this event also all the points of sample space which give you this event also are here and therefore  as we have seen from our proposition using the axioms of probability  that probability of this event must be less than or equal to probability of this event and that is what this represent  this represent for probability of this event  and this represent for probability of this event therefore  this in equality follows  and so the function is a increasing function is a non decreasing function then limit f  x  as x goes through infinite is 1  so we will take an increasing sequence  let say of values x n to x  increasing that means values keep on increasing so we approach that means if you have an x here  and you are approaching x from here  so all these values are increasing and you are reaching up to x so  then again because of this property the event x less than or equal to x n  this are the subset of the event x less than or equal to x n plus 1  because x n plus 1 is bigger than x n and therefore  limit probability x less than x n as goes to infinity actually  because this goes to infinity  so therefore this events the merge into x less than infinity  so all possible value of x get covered up just as so therefore  this becomes equal to probability x less than infinity  and therefore this must be 1 because all value of x get covered up in this event  and so this must be equal to 1 then we say that the limit f  x  as x goes to minus infinity is 0  so the argument here is same except that here we took an increasing sequence to x n there we will take decreasing sequence of this is as x goes to minus infinity  so limit f  x  is 0 so we can argue  because here i am say that as x goes to infinity f  x  is 1 so  when you take the decreasing sequence  events will be that means if i take decreasing sequence x 1  x n  where this is greater than this  then this is greater than x 2  this is greater than x n so  then the event could be when n goes to infinity  because i am taking decreasing sequences so  then it will become empty set  so this will be probability  see you will be considering the event x less than x i and this is bigger than probability x less than or equals to x i plus 1  so this is the whole idea  so just reverse the argument and so therefore as you go on  there will be nothing common as n goes to infinity this will be nothing common to … because i am saying x goes to minus infinity  and so here there will be nothing common  and so this will finally converge to this will become probability x  what shall i say here the symbol you have to uses that you have to say that x is empty  let me this becomes probability of the empty set that is what will happen ? so therefore  the limiting value of f  x  as x goes to minus infinity must be 0  because there will be no values of x that are possible  once x goes to minus infinity  so same as to then f is right continuous  because any b and any decreasing sequence b  and you take a b and any decreasing sequence to b n so  same thing i am saying your approach b from right  your approaching this of the sequence b n is coming like this from right hand side and limit f  b n  as n goes to infinity is f  b   because same thing here x less than or equal b n or decreasing events  the sequence b n convergence to b  refer slide time  24  48  so the events converge to x less than or equal to b  and so what we are trying to say that x less than or equal to b n  this event will contain the event x less than or equal to b n plus 1 and finally  will also all of them will contain the event x less than or equal to b and so therefore  probability of x less than or equal to b n will be greater than or equal to the probability of x taking the values less than or equal b n plus 1and so on and finally this  so now by the continuity property of the probability function p we get that limit f b n will be equal to f  b   because this is the value you know you are taking the limit here as n goes to infinity so therefore  because p is a continuous function probability function which is continuous  therefore this will be equal to f  b   and so these proof the right continuity of f and so now we have shown all the four properties 1  2  3  4 of the cumulative distribute function  and so any cumulative distribution function must satisfy all these four criteria and in fact  these 4 conditions are necessary and sufficient for any function to be a cumulative distribution function corresponding to the random variables x so  this is importance  so whenever you want to characterize a function which is which you says a cumulative distribution function for a random variable x  then you have to show that these 4 condition are satisfied by that function before you can take it to be the cumulative distribution function now  so if you take the example that we have been referring back to all the time this is when two dice are rolled up  and x denotes the random variable x denotes the sum of the two numbers that show up  then the expect so this is fine  so that is it now  i started give you the example  but first let me now define a very important term a commodity or quantity which we associative with the random variable expective value of a random variable x here so  if x is the descriptive random variable having the probability mass function p  x   the expectation or expected values e  x  is defined by e  x  is equal to sigma x into p  x  such that  so that means you multiply x by it is corresponding probability  and then you add up so when you add up all this products  so which is over all x so that p  x  is positive  because if p x is 0 then the contribution here will be 0  so we take this some over all possible x is for which p x is positive so  if you add up these values when we define this as the expected value of the random variable x now  so therefore we consider this example now  consider the example it which two fair dice were rolled up  and x denoted the sum of the two numbers that show up so  in that case had given you the table of you know for different values of x what will be the probabilities  so if you just refer to the table  then you can come see that this will be the thing  and this add up to 255 upon 36 which will be some number close to 7 little bigger than 7 so  this is the expective value of the random variable  that means in other words what you saying is that  if you sort of keep throwing the two dices  and at the numbers and then that means you take the average  so that means suppose you throw up the number 100 times throw up the two dice100 times and then add up the numbers that show up  and then divide that by 100 that will be close to your expected value  refer slide time  28  57  now  here if you look at this expression what does it say ? now  since p x for all x such that p  x  is positive is 1  this you can say that expected x is the weighted average of the values that x takes with weights as the corresponding probabilities so  they can be some more interesting interpretation of the expected values which are you show you right now so  e  x  can also be interpreted as the center of gravity of the masses p  x i   i varying from 1 to n located at points x i  i varying from 1 to n that means you can imagine that the p  x i  are the masses  which you place at the point  corresponding points x i and then you take the center of gravity of this distribution of masses is also which is same as the expectation x now  see that means imagine a weightless rod in which weights of masses p  x i  are located at corresponding points x i  i varying from 1 to n  so that means imagine that this rod weightless rod  and you have placed these points the masses p x 1 at x 1  p x 2 at x 2 and so on so  i have taken the points to be x 1  x 2  x n you know this one distribution  but it could be anywhere distributed but whatever the diagram will be the same  that p x 1 is the mass located at x 1  p x 2 is mass located at x 2 and so on now  the point at which the rod will balance itself is known as it is center of gravity so  from this thing you can this is the notation  and so this is exactly what is given by the expression e  x   so e  x  can be the notation it can also be referred to as the center of gravity of these different masses  which are the probabilities located at the corresponding points x i now  note that here i have just taken when i find e  x   i took x 2 i said that x takes finite number of values and hence this quantity is a finite quantity  and therefore it is defined therefore it exist so  wherever the different cases i will discuss them as that when we are right now  we also refer to e  x  as the first moment of x so  for when x is the discrete random variable and it is taking finite number of values so then i can also define expectation x square which will be sigma x i square p  x i  for all i varying from 1 to n  obviously the summation is over  all those i for which p  x i  is positive now  even if the random variable x is taking countably infinite values  then also if then i can you know take any function of x  and i can accordingly write down the expectation of that function of a random variable we will formally define expectation of you know g of x  when g of x is some function of a random variable x so  that we will take care later on  and of course for a continuous random variable also we will define in a formal way  but right now i can just say that because it is a summation sign so  and if as long as the summation is finite number  i can define these expectations and so here for example this will be the second moment  and also the linearity of expected function  because it is a summation so therefore  it is a linear function that means if i take c x plus d y two random variable x and y  then also i will be able to write the expectation of c x plus d y will be c times expectation of x plus d times expectation of y so  because of this summation thing  of course if x and y have the same to a probability mass function then so what i am saying is that right now  wherever if i am using the linearity of the expectation  then i am doing it this scenario when your x takes may be i finite values or countably infinite values  when wherever this summation is finite number i can treat e as a linear function  and also i can define the expectation as a of a any function of a random variable in this way now  here i would like to top of an example also  refer slide time  34  17  so let see  then the second moment can also be defined here  which is the second moment if this is the first moment  then the second moment would be expectation of x square  which will be summation i varying 1 to n x i square p  x i   and then very important quantity that we are associate with random variable one is of course e  x   and the second one is variance x  which is the expect that means it is now the expectation of x minus e  x  and then whole square so  you say that this is the moment second order moment of x about it is expected value see these are all for example this is the moment e  x  is the first order moment about the origin  and this is about 0 this is also the second order moment about 0  but now here this is the second order moment about it is expected value now if i open up this bracket when i get this  and now when i will take e inside  because as we have seen writes definition expected value is distributive  i can take it inside the bracket so this will be e x square minus since e  x  is finite quantity already  so they will be e  x  here  so 2 comes out constant in fact i am assuming that what i am saying is that  if you take c some constant  then this will be c times expected x  which immediately follows from the definition  because as here defining this as summation x i p  x i   so if i consider the random variable c x instead of when c x will takes the values c x i  and so here when i want to compute this will have c is present here  but since c is a constant till come out and so this will be simply c x so therefore  when i take e inside  this will be to twice e x into e  x  then this is again a constant so  therefore this is simple be e  x  square there will be no expectation again i am using the property that if random variable is taking constant value  then wills i this is not a random value essentially  this is a constant so  if x c for all possible values then will be the expectation was simply be c  because this is probability 1  so the constant whenever random variable is just equal to a constant this expectation would be just that constant value so this is this  and therefore minus 2 x square plus e  x  square  so that reduces and therefore this becomes e  x  square minus  so therefore you can also say that the variance of a random variable x is a variable of random variable x is second order moment about the origin so  expected x square minus it is expectation whole square  so this is what we and therefore we will go and computing this as we introduce our special random variables and so on so  the first one of the simplest random variable that we talk about is a bernoulli random variable  this was this is name after the swish mathematician james bernoulli  and i think 1700 something probably he define this random variable and you will see that it is a very basic random variable  and it we use this to build up on other special kinds of random variables so  this describes a situation or this random variable describe the situation in which the outcome is either success or a failure  so very simple you perform an experiment and the outcome would either be a success or failure so  for example if you toss a coin  you can say that coming of a head is a success and coming up of a tail is a failure and so  the values that x will take  we just see we associate x equals to 1 with the success  and x equals to 0 with the failure and then let us say that probability p x equal to 1 is p and so where of course p is a number which belongs to 0  1 and i am taking the open interval on both side  that means p is not 0  i am defining a meaning full random variable or a meaning full experiment  in which the outcome is either a success or a failure and so the probability x equals to 1 will be p  and probability x equals to 0 will be 1 minus p so  now if you compute the expectation or the first moment of this random variable  then this will be simply one in to p  because the random variables taking the values 1 or 0 so  1 in to p plus 0 in to 1 minus p  and therefore this is equal to p the probability of a success and the variance by this formula  so when you compute the e  x  square  so here e  x  square 1 square is 1  so 1 square in to p plus 0 square in to 1 minus p  so which again is p so  the where second order moment is also p  and so this is p minus the first order moment first squared which is p square  so p minus p square so this is the variance so  where you simple quantities which you can write away compute  and now we will further on use other special random variables discrete random variables  and then of course one will talk about continuous random variables also  refer slide time  40  14  so  let me just illustrate interesting aspect of the expected value  here i am taken this example functions in rows  a class of 120 students are driven in 3 buses to a musical concert now  36 are seated in the first bus  40 in the second and 44 in the third  when the buses arrive one of the120 students is randomly chosen  from the group of this all get down from the bus  one student gets picked up let x denote the number of students on the bus of the randomly chosen student  see now we carefully understand the event that i am telling you  x is the number of students on the bus of the randomly chosen student so  we picked up one student randomly  and then now you want to the because again that is a random process have chosen one of the student out of 120 then x is the random variable  which denotes the number of students on the bus  on which this randomly chosen student was sitting so  we have to find e  x   so find the expected value so  first of all you see that since student is chosen randomly  any student is equally likely out of the group of 120 i choose any one of them so  therefore the probability of the student in chosen from the first bus x equal to 36 is 36 by 120  then probability x equal to 40  because the second bus  so that will 40 upon 120  because that many students are travelling in that by the second bus  and finally probability x equal to 44 will be 44 upon 120 so  now if i want to find out the expected value of this random variable  then the expected value will be the random variable takes the value 36 into the probability of that bus being chosen  so it was 36 upon 120  then 40 into 40 upon 120 plus 44 into 44 upon 120 now  when you add up these numbers this comes out to be 1208 by 30 in which is 40.2667  but if you just compute the because if you look at the event that you take any bus  then the probability of being chosen is 1 by 3  it because every buses equally likely so  if you want to compute the number of students on the expected number of students on the bus of the randomly  this is later on now  on the other hand average number of students on a bus is 120 by 3  yes because i will add up  because each bus is equally likely to be chosen  so that probabilities 1 by 3  so that in to 36 plus 40 plus 44 that will be 120  so this is number is 40 now this number is less than 40.2667 and this what i want to point out here is that you see the expected number of students on the bus of the randomly chosen student is more than the average number of students on a bus so  just think about it and why is this happening  because you see the bus in which the largest number of people or i should say the more the number of students on a bus the more possibility of that student being chosen as be a student  it because you know the large number of students are coming from that bus  in which more students were travelling so  the possibility of choosing that student is higher than choosing from other students so  just think about this thing and so i thought i will end this lecture by giving you this interesting example and so you will as we go on we will see various  various implication uses of these measures expected value variance and so on will introduce some more introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  6 discrete random variables and their distributions  refer slide time  00  20  defining the distribution function  where we said that the this is equal to f b so  probability x less than or equal to b  now we can immediately write down the formula for the probability of x being in an interval using the distribution function so  here the idea that we are going to write x between a and b  so am taking script in equality here and so then you see i am writing this set the event x less than or equal to b as a union of two disjoint events x less than or equal to a  then union x between a and b  so x strictly greater than a less than or equal to b so  these are disjoint events and they add up to the union is equal to this event  then because they are disjoint when i write the take the probability  it will be the sum of the two probabilities so  probability x less than or equal to a plus probability a less than x less than or equal to b and so this probability then can be written as difference of probability x less than or equal to b minus probability x less than or equal to a and therefore this is f b minus f a  and you can see immediately that  if you want to write equality here  then this event could be x strictly less than a so  in that case we will have to write a minus and so on  so therefore since in the discrete case it matters whether equality is there are not  so therefore this is the way i have written it and then of course  if you want to also have the probability that x is equal to a and i will simply add to it  so plus it will be p a  because x equal to a again is disjoint from this set ; and so i can write here plus probability a and so on so  you can get various forms of the probabilities for x being an interval  you can write it through your distribution function  so this was for lecture 5 now  i will start defining  since we have already talked about bernoulli random variable  which was a very basic random variable  discrete random variable  so will define a discrete random variable which is known as the binomial random variable and then notation is b n comma p so  here n independent trials are performed each resulting in a success or a failure  so we just say that when you perform a trial  then either the outcome is a success or it is a failure now  probability of success we say is p and that is why the notation b n comma p that means  number of trials is n and the probability of the success is p and so x the random variable denotes the number of successes  so in n trials you want to know how many successes have occurred  because it is an uncertain event and the probability of x equal to r is given as n c r p raise to r 1 minus p raise to n minus r  so obviously if you looking for r success in n trials  then they can be any of the r trials out of the total n trials  so n c choose r  i mean n choose r and then since r success so p into r into 1 minus p raise to n minus r so  r success and n minus r failures and this is for r varying from 0  1 to n  so for any value of r you can substitute here and get the corresponding probability that x is equal to that r and now you can sum up this all the probabilities  so that means for r from 0 to n sigma probability x equal to r  then this will be summation r varying from 0 to n n c r p raise to r 1 minus p raise to n minus r and this you can see is the binomial expansion of p plus 1 minus p raise to n  that is another reason why it is called the binomial random variable so  when you write p plus 1 minus p raise to n  this adds up to 1  so therefore this is p m f and of course  so the x is the binomial random variable with probability mass function defined by 1 so  now let me again emphasize this fact that when the random variable is discrete  we describe it is probability mass function that means  when it gives you the function which specifies the probabilities for different values of the random variable x ; when that is known as probability mass function and when we talk of continuous random variable that means  when the random variable can take all possible values interval  then the function which describes the probabilities of the random variable  that is known as probability density function so  i will try to keep this thing always in mind  but sometimes may be it may happens that i have random variable is x and instead of saying the probability mass function  i may have used the word probability density function but  remember that we make this distinction that for discrete random variables it has to be probability mass function  and for continuous random variables it is the probability density function so  the notation is b n comma p  so that means binomial and you only need these two parameters  what is the number of trials and what is the probability of success and so now  you want to verify that this actually is a valid p d f and for which for this verification  i will need to say that all the probabilities must add up to 1  because x can take any of these n plus 1 values so  the sum of the probabilities for all these values must add up to 1 and you see that this is nothing but the expansion of p plus 1 minus p raise to n the binomial expansion ; and therefore  this number is 1  so 1 raise to n is 1  so that verification is straight forward  refer slide time  06  49  so then i immediately want to compute the expected value of this random variable  so that will be because this x is equal to r  so r into n c r p r 1 minus p raise to n minus r  r varying from 0 to n so  now here because this is n c r  so you will having the denominator maybe i can use the  so here if i take an outside see the thing is that n c r you can write as n factorial upon r factorial n minus r factorial so  r if i take out  then this will be r minus 1 factorial  so the r cancels out and n i have taken out from here  so this will become n minus 1 factorial so  and then n minus r you can write as n minus 1 minus r minus 1 and therefore  by taking out n here and canceling out the r  i get n minus 1 choose r minus 1 ; and since you see in this summation r is from 0 to n and when r is 0  this term is the first term is 0  so therefore no contribution so  therefore  this summation can as well be written as r from 1 to n and this what you have so  here if i take out p  then i will be left with p r minus 1  so this n p is outside  this n is outside and then you have this so  now you can see is again a binomial expansion of p plus 1 minus p raise to n minus 1  because their powers are all n minus 1  so therefore this is 1 and so you are expected value is n p so  again a straight forward computation we should  because able to figure it out and can also say that a bernoulli random variable is binomial 1 comma p  it is binomial random variable with parameters 1 and p  refer slide time  08  53  let us look at this example give taken from sheldon laws  so it says that it is known that screws produced by certain company will be defective with probability 0.01 so  the p is given here  so here defective we are treating as a success  so the probability of getting a defective screw manufactured is 0.01 and these of course  the defectiveness of the screws is independent of each other the companies sells these screws in packages of 10 and offers a money back guarantee that at most one of the 10 screws is defective ; that means  if more than one a screw is defective in a package of 10  the company will take back the package and refund the money so  the question is what proportion of package is sold must the company replace  so that means you wanting to find out the probability of packages of 10 that have more than one screw defective so  that means  you are wanting to find the if x is the number of  you say that x is the number of number of defective screws  then what is x is binomial 10 0.01 so  because we are treating a defective screw as a success  so therefore in a package of 10 the probability is 0.01  so this is binomial 10 comma 0.01 and you want to find the probability  let x is greater than or equal to 2  because when x is greater than or equal to 2  the package will be returned back and the money refund it  so here i have said that where x is binomial this so  therefore  a now this event i can write as compliment  so 1 minus probability x equal to 0 and probability x equal to 1  so these two are acceptable and if x is more than 1  then it is not  so 1 minus  so these two you can see that now  x equal to 0 is the probability  so 10 c 0 into p raise to 0 1 minus p raise to 10 and x equal to 1 will be 10 choose 1 p into 1 minus p raise to 9 and now your 1 minus p is 1 minus p 0.99 and so you write down this number  you can use your calculator to compute it  it comes out to be 0.004 so that means  0.4 percent of the package is will have to be returned  and this is you can see that this kind of calculation is very helpful to a company  which is trying to budget it is manufacturing of the screws and anywhere situation you want to know that what is the of course  nobody saying that this exactly 40 percent of the package is will have to be returned  but now the company has an idea as to 4 percent  4 percent of the package is have to be returned so  there is some idea and a guideline for the company to see what can happen now  the next thing that we want to compute about the binomial random variable is it is variance  so first we will compute expectation of x square  second order movement and so that will be given by r square n c r p raise to r 1 minus p raise to n minus r summation is from 0 to n  here again you see for r equal to 0 the first term is 0  so there is no contribution and i will do the same thing  i will cancel one r with this   refer time  12  43   one here and then one r am left with  p i will take outside and then n of course  also we should have written which i have done here so  in that case you will because left with r n minus 1 and the same thing  same trick i will do and this is it  n minus r i will write is n minus 1 minus r minus 1  so this is p raise to r minus 1 and this is the whole thing and the one r that is left here  i will write it as a r minus 1 plus 1  now you see you can break up this sum into two  so r minus 1 times this whole thing  you see now is the expectation of a so  i define why is a binomial n minus 1 comma p  so why is binomial random variable where n minus 1 trials i have taken place  probability of success is p so then you see in this summation i should have written here 1 to n  then r minus 1 into this term  this whole thing summation r from 1 to n will give you the expectation of binomial n minus 1 comma p so  therefore  that will because n minus 1 into p  so n minus 1 into p and plus 1 and then this summation this again is the say same thing p plus 1 minus p raise n minus 1  so that is equal to 1 so  therefore  you get n p times e y plus 1 expectation of y plus 1 from here  an expectation of y is n minus 1 p and this is plus 1  so n p into this so  now  for the variance you have to write n p into n minus 1 p plus 1 minus n p whole square and when you simplify you get this   refer time  14  30   and some people also write this as n p q  where q is 1 minus p so  easy way to remember and you see some more applications of and of course  as the course progresses you will continue to see where all you can use the concept of a binomial random variable  refer slide time  14  50  let us look at this proposition about the random variable binomial n comma p  so then as x goes from 0 to n  this number probability x equal to k increases monotonically and then decreases monotonically reaching it is largest value  when k is n plus you see integer part  largest integer part of n plus 1 into p see p is a fraction  so n plus 1 p may not be an integer  so when we write brackets like this  it means that the largest integer for example  if you consider 5 by 2  so the largest integer here would be 2  largest integer which is less than n plus 1 into p  so this is this similarly  if you consider what shall i say 9 by 4  here again the largest integer will be 2  because 4 times 2 is 8 and then it is 1 by 4  so this is what mean by that so  that means  the binomial probabilities they keep on increasing  reach the largest value highest maximum and then starts decreasing this is the idea and so we want to prove this result  so let us look write down probability x equal to k upon probability x equal to k minus 1 ; and so if you write down the expressions this is what you get so  then things cancel out n factorial n factorial  you have n minus k factorial n minus k plus 1  so therefore  you will be left with n minus k this will come in the numerator  so n minus this is the bracket over k minus 1 upon k p upon 1 minus p now  this should be we want know for what values of k the probabilities are increasing  so i want this to be greater than 1 and if you simplify this means that k into 1 minus p should be less than n minus k minus 1 into p or k into 1 minus p plus this is less than n p  so this give you this so  the as long as k is less than n plus 1 into p  the probabilities is  because you say this is probability x equal to k divided by probability x equal to k minus 1  so this number is greater than this number as long as k is less than n plus 1 into p so  that means  and since k is an integer  we will say that this goes on increasing till k reaches the largest integer present in n plus 1 into p  so that is what we say so  that means  k less than or equal to this integer part in this number  probabilities are increasing and when k is greater than this  because the any quality will get reversed  so then they are decreasing and if n plus 1 into p is an integer then of course  that will because the maximum value otherwise  because here it is strictly less and this is less than or equal to so  k will the probability x equal to k will attain it is maximum value for n 1 into p that means  when this is an integer  otherwise it will attain it is maximum value for the largest integer present in n plus 1 into p so  i will show you the diagram now for a particular this thing  the bar chart for a binomial distribution  so the here will look at the bar chart when the random variable is parameters are 10 comma half that means  your p is half and the number of trials is 10 ten  refer slide time  18  42  so  you see here if you look at this thing 1 by two  so that means for x equal to 0  then when k is equal to 0  the probability p 0 is 1 by 2 raise to 10 and that is depicted by this small bar here and then x equal to 1 it starts to increase and then at 5 it is maximum so  if you look at  see we said that  so what is your n plus 1 into p this is equal to 11 into 1 by 2  so this is 5 1 by 2  so the integer part is 5 so  as just now we looked at the we proved this result  that in this case the maximum will value will be attained for the largest integer present in n 1 plus n plus 1 into p which is 5 so  therefore  you see the largest bar is corresponding to k equal to 5 and then again the values start decreasing and you also see that in this case  because p is half  therefore the graph is symmetric about the value k equal to 5 so  just want to explain that this is 1 0 2 4 into p raise to k  because the horizontal axis is k and here just to otherwise numbers would have been  because probabilities are less than 1 so  therefore  just to make them whole numbers we multiplied everything by 1 0 2 4  which is 2 rise to 10  if we multiply all the probability  then they become integers so  this is what your a binomial bar chart will look like  for the particular value and p is equal to half and i have shown you also that how it will continue to the probabilities will continue to increase  reach a maximum for the integer part of n plus 1 into p and then start decreasing  refer slide time  20  55  now  let us look at the distribution function of the binomial random variable that means  you want to compute probability x less than or equal to i and here  you see the expression would be you have to sum up all these probabilities from 0 to i for the individual probabilities at the random variable takes now  these numbers can be very very large  in fact if your n is moderator large and you want to compute even for n equal to 20 and if you want to compute for  let us say i equal to 16  then you will have add up 17 terms here and this can become very tedious so  there is a very simple and nice formula which you can recursive formula  because we obtained this here in this expression i have this here  so just place k by k plus 1  then k minus 1 becomes k  so in that from that formula you get this recursion so  which says that  if you have obtained probability x equal to k  then you can obtain probability x equal to k plus 1 by this simple formula  recursion formula and you can see that to start off when x is equal to 0 when x takes a value 0  then this will be 1 minus p raise to n so  once you have compute this  then p x equal to 1 will be from this formula p upon 1 minus p k is equal to 0  so this is n and p x equal to 0 so  therefore  this will because p x equal to 1 will be p upon 1 minus p n 1 minus p raise to n  so that means you if you have already computed this number  then you have to simply multiply the probability x equal to 0 by this number to get probability x equal to 1 and then similarly probability x equal to 2 would be this number multiplied by probability x equal to 1 which we have already computed here so  a nice simple recursive formula that you have obtained and you can write this compute the program feed the values and then it will go on computing that means  you have to just feed the value n and p and then it will compute the successive probabilities for you ; so this is the computational part  because the wise things can become very tedious now  another special kind of discrete random variable is the poisson random variable and this is named after the mathematician s d poisson  who defined this random variable in 1837 and he in fact  wrote a book which was application of probability theory to law suits  criminal trials etcetera  so you see the kind of applications that the poisson random variable has and at that time in 1837 he wrote this book  where he apply the theory poisson random variable to predicting things about law suits and criminal trials etcetera so  x is a random variable which takes values 0  1  2 up to infinity  lambda is the parameter and lambda has to be positive then we define the probability that x is equal to r by this number  e raise to minus lambda lambda raise to r upon r factorial  defines a probability mass function of the random variable x and this is the poisson p d f and now you want to make sure that this defines the p d f that means  you have to show that summation probability x equal to r is 1 ; so very simple calculation will immediately give you the verification that this is indeed a p d f  refer slide time  24  55  so  to show that the probability mass function define for poisson random variable is valid p m f  we add up all the probabilities here which is equal to this  but you see lambda raise to i upon i factorial i varying from 0 to infinity is nothing but the expansion of e rise to lambda so  therefore  e minus lambda into e raise to lambda gives you 1  gives you e raise to 0 which is 1  so we have check the validity and of course  each of the probabilities defined are also non-negative so  therefore  what we have defined is the probabilities for the poisson random variable forms a valid p m f  probability mass function examples of random variable that obey poisson probability law  some of the situations am just writing down to get give you better feeling for the random variable and this is for example  number of misprints on a page or a group of pages of a book  which we believe is a random phenomena number of people in a community living up to the age of 90  which again is a random phenomena  because how long one is for how long one lives is not certain event then number of wrong telephone calls dialed in a day  a wrong numbers what i mean is wrong telephone calls dialed in a day  this could be at particular exchange or you mean take a particular number and then count a number of times the wrong telephone calls come number of customers entering a post office in a day  then number of alpha particles discharged in a fixed period of time from some radioactive material now  you see that here all the situations  there is some sort of discreteness and that is why we are saying that these situations can be modeled by a poisson random variable you can just get the feeling  because you can not have two numbers dialed simultaneously  there as to be a gap ; then number of misprints of course  will be current discretely told some gap of time and so on now  i want to show you the relationship and as we go on the discrete random variable that i defined  i want to show relationships between among these discrete random variables so  poisson approximation of the binomial random variable and this is when n is large  so for n large and p small  then you expect that n p would be a very  a moderately small number  n p and so we defined that is lambda so in other words  what you are saying is that a p small and n large and then this n p number sort of approach is reasonably small number equal to lambda now  let us look at the binomial probability for x equal to i  when x equal to i when x is equal to i  then this is the probability defined  then let me start writing  so here if i take this  then p is lambda by n so  i will make that substitution here lambda by n raise to i 1 minus lambda by n raise to n minus i  then if you cancel out the n minus i factorial part here  you will be left with n into n minus 1 n minus i plus 1 and then this n raise to i  i am writing here and i factorial is underneath  because you see am trying to converse to the poisson probability so  lambda raise to i upon i factorial and this one 1 minus lambda n raise to n and then divided by 1 minus lambda n raise to i now  this n 1 n cancels and i am left with n raise to i minus 1 and you will have i minus 1 terms here  so i take n inside and divide  refer slide time  29  07  so  therefore  each of this term becomes 1 minus 1 by n 1 minus i minus 1 by n  so the this n raise to i gets absorbed here  lambda i raise to i factorial 1 minus lambda n raise to n and this now  as n goes to infinity becomes very large  then 1 minus lambda by n raise to n will approach e raise to minus lambda  so i hope you are all familiar with this limit and then 1 minus lambda by n raise to i  because as n becomes large lambda is fix  so this number is becomes smaller and smaller and so this will approach 1  for n sufficiently large and then and all these numbers again as n goes to infinity are becomes very large  each of these numbers approach 1  so the product is 1  so therefore this is gone and this raise goes to e raise to minus lambda so  the whole thing approximates to lambda raise to i upon i factorial e raise to minus lambda  which is the poisson probability so  essentially i should say that this approaches this and this is your  so these things are actually inter linked and therefore  for large n your binomial probability is the same as the poisson probability that is one result now  they computing the expected part expectation of a poisson random variable again straight forward  sigma 0 to infinity i lambda i e raise to minus lambda upon i factorial so  here i do the same trick as i did for the binomial  so lambda e raise to minus lambda you take outside  then your i becomes  this summation becomes 1 to infinity lambda i minus 1 upon i minus 1 factorial  which is again the expansion of e raise to lambda so  lambda e raise to minus lambda into e raise to lambda it gives you lambda  so whatever the parameter of the poisson distribution that is also it is mean  so this is one result and now variance also straight forward again the same thing i will do as  i did for the binomial expectation of x square we find out  then again the i cancels lambda you can take outside and the i that is left you write it as i minus 1 plus i and this thing and just do the same argument as we did for the binomial  you will see that i minus 1  this will give you the again a poisson this thing expectation of a poisson with lambda parameter so  this will be lambda plus 1  because this should be plus 1  i minus 1 plus 1  so 1 because these are again poisson probability  so will add up to 1  so this is what you have ; and therefore  variance will be given as lambda into lambda plus 1 minus lambda square  which is the expectation so  this is a particular situation where your expectation and the variance are the same  and both are equal to the parameter of the poisson distribution now  best way to give you feeling about particular random variable is always through examples  so here let us look at the poisson error model and as i said this is same the first one there  that is your modeling the number of printing mistakes done by let us say high speed printer so  here it says that certain high speed printer makes errors at random on the printer page  on the making an average of two mistakes per page so  on the average two mistakes are made per page  assuming that the poisson distribution with lambda equal to 2 is approximate to model  the number of is appropriate actually i should say  i should say appropriate let me correct the word appropriate  appropriate to model the number of errors per page  what is the probability that obtained page is produced by the printer at least 7 will have no error so now  you want to probability that when the 10 pages are printed  7 of them are without any errors  refer slide time  33  49  so  we assume independent of error from page to page that means  number of errors that occur on one page is independent of the number of errors that occur on the second page and so on now  let x be the number of errors on a page  then as we have said that we will model this pi the poisson random variable and so probability x equal to r will be e raise to minus 2 into 2 raise to r upon r factorial  where r can vary from 0  1 to anything and we said that  since the average number of errors made by the printer on a page is 2  so am taking 2 as the parameter of the poisson random variable that am using to model this particular situation  so this is what is given to you now  if you want the probability that a page is error free that means  there are no errors  so probability of x equal to 0 is equal to e raise minus 2 now  the thing is that you want to find out the probability that at least 7 pages are error free  so you see we modeled this situation by a poisson random variable to find out the probability of a page being error free so  that i got as 0.1353  which is equal to e raise to minus 2  but now there is a next step and see that is why example is very interesting  because you see is now you will make use of the binomial random variable because  having no errors on a page is the success  let us treat that as a success and since we have said that and we are looking at a 10 pages  so i will consider scanning every page as a trial of the experiment  and if there is no error on the page then that will be a success so  this is ideal for a binomial random variable  this situation is ideal  because since pages are the errors from page to page are the independent  therefore i will treat this as 10 independent trials and if a page turns out to be error free and that is a success and what is the probability of a page being error free that is 0.1353 that means  the probability of a success our p is 0.1353 and the number of trials is 10  so this is a binomial random variable and so probability that at least 7 pages are error free  i require that 7  8  9  10 at least 7  so the error free pages can be 7  8  9 or 10 and the probabilities will be 10 choose 7 e raise to minus 2 raise to 7 into 1 minus e raise to minus 2 raise to 3 similarly  for 10 choose 8  we will write the expression e raise to minus 2 raise to 8 and so on  then 10 choose 9 e raise to minus 2 raise to n into 1 minus e raise to minus 2 plus 10 choose 10  which is e minus 2 10 and even as i have saying that here also the computations have to be done by using a calculator or a computer  so i write down the numbers this is into 10 raise to minus 4 and so the probability is 0.0007  so which is very low so  therefore  what you will say is the probability that 7 pages out of 10 will be error free is a very very low probability  has very low probability  so chance of this happening is very small now  again i will try to take as many examples are possible  so make the concepts clear  so first this question am taking  because that will lead to a poisson approximation which i want to show you   refer time  37  56   so  first consider the situation here that  n people are present in a room what is the probability that no two of them celebrate a birthday on the same day of the year so  this is the first question  what is the probability that no two people will be having a same birthday  celebrate it on the same day and then we want to ask the question how large did n be so  that the probability is less than half that means  how many people should be there in a room  so that the probability of any two of them having the same birthday is less than half we want to first look at this question and then i will take you to the how i approximate this situation and give you the through poisson and then again show you the connection between the two  refer slide time  38  52  so  the birthday problem as we saw that  if no two of them have the same birthday then of course  we will write it as 360 see the first person can have a birthday on any of the 365 days and we are of course  ruling out the leap year  so nobody has the birthday on the 29th february so  this is 365 upon 365  then the second person can have in the group  group of n people the second person can have is his or her birthday on any of the remaining 364 days and so 364 upon 365 and so on so  this will go on up to 365 minus n plus 1 upon 365  so this gives you the probability that no two of them have the same birthday and we want the number n such that  this probability is less than half so  the probability that no pair  no two people in the group have birthday on the same day  we want that probability to be less than half and we want what should be the smallest number of such people so  that this probability is less than half and so it turns out that n greater than or equal to 23  satisfies this inequality now and of course  then i started calculating backwards  so for example  for n equal to 23  for n equal to 23  365 minus n plus 1 is 343  so then i started computing 343 upon 365  344 upon 365 and so on and then just 363 upon 365 when you come up to this point  then the probability just turns less than half and so the next number is 364 by 365 which is also less than 1  so the probability will remain less than half and of course  the last number is 365 upon 365 which is 1  so therefore and in fact  if i took n to be less than 23 that specify took n to be 22  then this will not happen because  then you will be starting with 344 and then when you calculate backwards it will not turn less than half  so this is just enough and that means  if you have more than 23 people in the group  then the probability will be still less than half  so this is the idea now  here calculating it otherwise become difficult  because what is happening is that you are in the group if a and b have the same birthday  then it is possible that b has a same birthday with c and so this thing is transitive and so it is not very easy  i mean one can not daily assuming dependence to calculate the actual probability  but we will see that some approximation is possible and so we will see that but  so this is interesting to see that  even group of people having 23  i mean group having 23 persons the probability that no two people have the same birthday is less than half  refer slide time  42  01  so  let me continue with the poisson approximation of what we discussed the common birthday problem we discussed  so now suppose choosing a pair is a trial  choosing a pair of people present in the room  then there are n c 2 pairs that i can  different n c 2 pairs that i can choose now  consider e i j as a trial i j i naught equal to j such that  and of course  what i mean by this is that am choosing the i'th in the j ’ th person here  i and j are different having the same birthday so  e i j would be considered a the event  when i choose the pair i j it is the success  if they have the same birthday now  in question 7 of the exercise 3  which i will be discussing at the end of having gone through all different types of discrete random variables so  the exercise 3 question 7 am asking you to show me that these pairs the events e i j are pair wise independent so  of course  choosing of each pair is independent and then i want you to show that the pairs e i j that means  this set of events e i j i naught equal to j that means  n into n minus 1 by 2  such events they are all pair wise independent  which means that i j and e l k this is important  i must show i j and e l k  where i is not equal to l and j is not equal to k so  between different sets of pairs when you choose  different sets of events i will  so that is what i should say that when you pick up two such events from here  where i is not equal to l and j not equal to k  then any two such pairs are independent events  this you should do as an exercise at the end of this chapter now  x is the number of successes in n c 2 trials having the same birthday  so let me now start looking at the poisson approximation  so number of successes in n c 2 trials having the same birthday and this am calling as and so as i discussed with you is a binomial n into n minus 1 by 2 comma 1 upon 365 remember  i showed you that pair of people having the same birthday  the probability is 1 upon 365 and the number of trials that i have is n into n minus 1 by 2  so this is a binomial random variable if i do the poisson approximation  then we said that the corresponding poisson parameter would be n p and so that will be n into n minus 1 by 2 into 1 upon 365 so  this is my n p and now you want to compute the probability that no two people have the same birthday that means  you want to find out probability x equal to 0  which is e raise to minus n into minus n into 1 by 2 into 1 upon 365  so which is this number so  the next part of the question was what value of n that is twice this the inequality  that this is less than half  no two people having the same birthday that probability should be less than half so  we should take the logarithm of both the sides  then this is minus n into n minus 1 upon 730 l n of e is 1  this is less than minus l n 2  so minus minus cancels inequality reverses so  therefore  n into n minus 1 is greater than 2 into 730 and you can see that n equal to 23 will satisfy this equation and therefore  this also is validated  the answer that i got earlier by other arguments  now i have been able to validated by so  therefore  this is what  so these examples that am trying to show you that  how you model and sometimes your modeling can be such that  the getting the answer can be very comber some  but sometimes when you model it in the right way then you can get the answer so  here the computation was quicker  then because remember there i was solving the  i was trying to say 365 into 364 up to 365 minus n plus 1 divided by 365 raise to n  this should because less than half and so i was wanting to compute an n and you could see that  this will require trying out trial and error of lot of values of n before you get the answer and we got the answer i showed you that the answer would be 23 but now  if you model the situation through poisson random  approximation of binomial through poisson  then you get the answer in a much simpler way introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  7 discrete random variables and their distributions  refer slide time  00  15  so  i will be taking about some other discrete probability distributions so  the next one is negative  the negative binomial random variable  and this name is very suggestive we consider the binomial distribution  which where the random variable  was representing the number of successes  where the number of trials is fixed so  you perform n trials  probability of success is p  and then we asked for the probability of r successes now here it is the reverse  what we are saying is that independent trials are performed probability of success is p  p between 0 and 1 trials are conducted till r success is occur so  now it is the opposite ; that mean now you go and conducting the trials  till r success is have occurred  and so x will be the number of trials required for r successes in the binomial case  the trials were fixed  and you have to then ask for the probability r successes here the number of successes is fixed  and you are saying  what are the numbers of trials that you are required  so that r success is take place so  here the random variable is the  number of trials so  probability x equal to n and it is very simple to write it down  because so that means  see you will stop your experiment  the moment you hit the r x success ; so that means  up to n minus 1 trials if i want r successes occur in n trials  then up to n minus 1 trials r minus 1 successes should have occurred  and therefore the probability of that is n minus 1 choose r minus 1 here we are using the binomial concept  and then p r minus 1 r minus 1 successes and 1 minus p n minus r failures  and then the last one is the success so  therefore  the total number of successes add up to r  but you are here wanting r minus 1 successes to occur anywhere up to n minus 1 trials  the last trial must be … so  the n ’ th trial in this case must be a success so  your n can vary from r r because you want r successes so  at least r trials have to be conducted so  therefore  n is r r plus 1 and so on  and this number can go on up to infinity now  since the experiment continues till r successes occur so  therefore  when you add up n equal to r to infinity probability x equal to n  this must add up to 1  and therefore  this is a combinatorial argument  to say that what we have defined here  is a probability math ’ s function analytically also 1 can show  that this sum will equal one  but then you require little more mathematics so  therefore  we just satisfy ourselves  by giving this combinatorial argument  that we will continue the trials still a success occur ; the r success occur and also probability x equal to n is non negative for n varying from r r plus 1 n and so on  so this defines a p m f  so this is a valid p m f  when r is equal to 1 ; that means  if you just looking for the first success  and x is the number of trials required for the first success  then obviously  you put r equal to 1  so that becomes 1 and so this is 1 minus p n minus 1 into p ; that means  the first n minus 1 trials must end up in failure so  therefore  1 minus p rise to n minus 1  and the moment you hit a success you stop so  1 minus p rise to n minus 1 into p and n can vary from 1 onwards x is now called the geometric random variable  and the corresponding p m f is the geometric distribution now  interesting application of a negative binomial random variable  and the distribution so  this is known as the banach match problem banach was a very famous mathematician  and he was a heavy pipe smoker so  he does not waste time in looking for the match box and then lighting up a match  to light his pipe he would carry 2 match boxes ; one is in his left hand pocket  and the other one in the right so that wherever he puts his hand  he gets a match box and he lights his pipe therefore  that is how he was dependent on smoking his pipe so  each time he needed a match  he would equally likely take it from either of his pockets  refer slide time  05  21  so  it was equally likely that he would put his hand in the right hand pocket or on the in the left pocket  so probability of that is the same and now consider the moment when the mathematician first discovers  that 1 of his match box is empty so  now  assume that both the match boxes initially carried n matches so  we are asking what is the probability that the other match box contains exactly k matches so  that means  initially both had capital n number of match sticks  in the match boxes  and then when he discovers that 1 of the match boxes is empty  and the other 1 is contains exactly k matches so  this is what we have to find out the probability of this event so  let us say that  consider the case when the left hand pocket has k matches left ; that means  right hand pocket is empty  and left hand pocket has  the match box has k matches left here again i should say when the left hand pocket match box  is having k matches left  so i have left out that match box ; that is the mathematician discovers the empty pocket at the see he emptied the n match sticks in the right hand pocket  and here he emptied n minus k  because k are left in the left hand pocket  and then on the n plus 1 nth  when he put his hand in the n plus 1 nth  or when he takes out the match box at the 1 plus nth time i mean from the right hand pocket  then he discovers it is empty so  the total numbers of trials are n plus n minus k plus 1  so exactly situation of a negative so  taking out a match stick from the right hand pocket as a success so  we will     is a success so  let us say that so  we will say that  the right hand pocket  taking out or putting the hand in your right hand pocket  and of course  when you put as long as the match box has a stick  you are also taking out stick match stick so  therefore  whichever way you want to put it  but anyway taking out a match stick from the right hand pocket is the success here looking for the n plus one th success  but where actually he discovers that it is empty so  that a consequence of the match box getting empty  but essentially what we are saying is that putting his hand in the right hand pocket is a success  and putting his hand in the left hand pocket is a failure so  random variable x which is equal to the number of trials required for n plus 1 successes so  this is the exactly the case for a negative binomial distribution  and what we are saying here is  that this is actually ; that means  this is happening  when you have add this many trials n plus 1 plus n minus k and therefore  by our argument  see the last one he discovers that it is ; that means  at the 2 n minus k plus one ’ th trial  he discovers that the left right hand pocket match box does not have any sticks left in it so  this would be 2 n minus k  if you n minus 1 r minus 1 and then 1 by 2 rise to 2 n minus k plus 1  so this will be the probability but then since  either of the pockets could have emptied first so  therefore  what we have saying is twice this so  the required probability is  since either pocket can be emptied  required probability is twice of that  and so when you multiply by 2 this 1 disappears the required probabilities 2 n minus k choose n into 1 by 2 rise to 2 n minus k now  again these results i am just giving you without  because handling this thing  requires lot of mathematics  you will not do it so  i will just simply say that  expected value of negative random variable  which has parameters r and p ; that means  r number of successes are required  and p is the probability of success ; that is r by p  and the variance of a negative binomial r comma p random variable is r into 1 minus p upon p square so  for example  if you are throwing of a die ; x is the random variable which is the equal to the number of throws of a die  required till number 1 shows 5 times so  your r is 5 here  and p  because die we are assuming is fair die  so probability of each number showing up is 1 by 6 so  probability of number 1 showing up is 1 by 6 so  our p is 1 by 6 r is 5 and therefore  by this these 2 formulae  expected value of x is 5 upon 1 by 6 which is 30  and where is ; that means  at least the expected value  the expected number of trials throws of the die required  so that number 1 shows 5 times is 30  and the variance is again by this formula comes out to be 130  25 into 6 no this one 50 so  this is 150 so  that is about negative binomial and geometric distribution  refer slide time  11  27  so  another discrete random variable which is quite useful  is hyper geometric random variable so  i will demonstrate this through an example  and define this variable and corresponding distribution so  consider an urn containing n balls  out of which m are white  and n minus m are black now a sample of size n is drawn  without replacing the balls ; that is important  the experiment is conducted without replacing the balls so  i keep taking out the balls and put them aside so  now if x is the random variable  which counts a number of white balls selected so  sample of size n is drawn total numbers of white balls are m so  now  we look at the probability of the number of white balls being equal to k so  k can obviously vary from 0 1 to m  because there are m white balls so  the probability would be now here you see  we are using the multinomial distribution so  out of m white balls  you want to select k  and out of the remaining n minus m black balls  you are selecting n minus k black balls so  your total sample size is n balls  and the total number of ways of selecting small n balls from n balls is n choose n so  this we have already gone through  when we were talking about the counting procedures so  this gives you the  total number of possible ways in which you can select n balls out of n balls  and the number of ways which you can select k white balls from m white balls  and n minus k black balls from n minus m black balls now here of course  this is meaning  when k such ; that n minus k is less than or equal to n minus m  because see  there is some connection between m k and n so ; obviously  if my number m is very large  then i can select k number of balls  but then n minus k becomes negative  or n minus k is  so that means  it has to be less than or equal to n minus m  but then see  by convention if n minus k turns out be greater than n minus m  or n minus k is less than 0  then by convention we say that this n minus m choose n minus k 0 so  therefore  this has a meaning so  we do not have to worry  because then there will be the probability would be if k such that n minus k is greater than n minus m  or n minus k is less than 0  then these probabilities will be 0  and so there will be no math ’ s attached with those values of k so  this is your this thing  and again ; since when we are drawing out a sample of n balls  white ball may appear or may not appear  and a white ball numbering 1 2 3 up to m  may appear may not appear so  this takes care of all possible cases  and therefore  this is a valid p m f so  that means  what we are saying is  that summation probability x equal to k  k varying from 0 to m is equal to 1  and also these probabilities are all non negative so  therefore  this is a valid p m f so  this exercise you must do every time  we define a random variable and its corresponding probability math ’ s function now  let me just show you an example of  where we use  where we make use of hyper geometric random variable and its distribution  acceptance sampling in quality control so  what you do is  of course  i have give you the numbers here are small  but usually the numbers are much bigger than what i am using here so  suppose 200 items in the lot ; some instrument or something is being delivered by a manufacturer  the whole lot is of size 200  and the claim by the manufacturer is  that no more than 10 percent are defective so  this is the claim now ; obviously  people do not have time and energy and man power  to actually inspect all the 200 items  and usually this number is very big so  what the practice is  and that is why it is acceptance sampling so  what you do is  after the shipment is received  a sample of size 10 is taken again the numbers are all  just for convenience sake  but usually there will be more realistic numbers so  anyway a sample of size 10 is taken without replacement  and if there are at most 2 defective  the lot is accepted so  you just at random choose a sample of size 10  from this whole lot of 200 items  and then you inspect those 10 items  and you have taken out the sample by without replacement so  you inspect those and then in that sample of size 10  if you find 0 1 or 2 defective you will accept the whole lot  and you will say that it is ok  and then if there more than 2 defective  then you will reject the lot so  this is what you call acceptance sampling in quality control  refer slide time  17  33  so  let me just show you simple you know combinational exercise here i will do so  that means for example  if 5 percent are defective in the entire lot  then it contains 10 defective and 190 non defective so  here the claim by the manufacturer is that no more than 10 percent are defective so  let me consider the case when 5 percent are defective in the entire lot  then it contains 10 defective and 1  because 5 percent of 200 is 10 so  10 are defective and 190 are non-defective so  now if you want to compute the number of defectives in a sample of size 10  x is this then you want to compute the probability let x is less than or equal to 2  which means probability x equal to 0 plus probability x equal to 1 plus probability x equal to 2 so  this is what you want to compute  and i will just show you the calculations here  refer slide time  18  36  so  what i am showing you here the probability  of number of defectives being x so  that will be  this is the case when we are  say assuming that 5 percent are defective in the whole lot so  then it is 10 choose x and then 190 are non defective from the non defective am choosing 10 minus x  and then divided by 200 choose 10 so  this is a hyper geometric probability of choosing x defective ; the samples size containing x defective  our sample size is 10 hence probability of accepting a shipment that is 5 percent defective so  we are saying  if at most 2 are defective in the sample size of 10 so  that probability would be probability x equal to 0 x equal to 1 and x equal to 2  which i have written down here  and if you look at the numbers these are the 3 probabilities you add them up  and they come out to be 0.99 0935 ; that means  the probability of accepting the whole lot is 0.99 now  if there are 10 percent defective  then there are 20 defective in the whole lot and 180 non defective  refer slide time  20  01  so  in that case  the hyper geometric probability of x defective in your sample of size 10  would be 20 choose x ,180 choose 10 minus x  because you are taking a sample of 10 and divided by 200 choose 10  so this will be the probability of having x defective in your sample of size 10  which is taken without replacement so  therefore  in that case the probability  of accepting the shipment that is 10 percent defective again  we want number of defective in the sample  to be not more than 2  so it can be 0 1 and 2 so these are the numbers  and here the probability is 0.9347 so  this is less than the probability that we attain for  when the shipment had 5 percent defective that is the probability of accepting a 10 percent defective shipment is smaller  then the probability of accepting a 5 percent defective shipment so  obviously  the less the defective  the more the chance of accepting the shipment  because the probability of getting 2  at most 2 defective in a sample of size  10 will be smaller  if 5 percent are defective and when 10 percent are defective  this is what it is saying  and therefore  you can experiment with other values of the number of defective items in the whole lot  and then you can compute the probabilities accordingly  refer slide time  21  34  so  relationships among hyper geometric  binomial and poisson distributions so  let me show you i have already shown you  how binomial will approximate to poisson  when n is large and the number of trials is large  and your n p converges to moderately small number so  now here let me show you the inter connection between all these 3 ; in fact  4 discrete random variables that we have discussed so far so  now  again we say that population is an objects  and a number of a number of type a objects are there in the population  so the others are not a type and the sample of size n is drawn without replacement so  sample of size n is drawn without replacement  where of course  n has to be between 1 and n  and a has to be between 0 and n  and while discussing the hyper geometric series  i told you that even if this number is bigger than this  and by convention this is 0  so there will be no mass so  we are really do not have to worry about the values of  as to what the  when i am writing this hu sorry this is x so  now  if i want to  and let p be a by n this is the proportion of item  i am not using it now  i will be using it later on anyway this is the proportion of items  item of type a  in the original population so  i am denoting this by p  which i will make use of later on now  this probability ; that is your sample size of n  contains x objects of type a so  that will be choosing from a num x a is the total number of type a objects  you want to select  so your sample should have x of them so  this is a choose x  then remaining the population n minus a are the other kind of objects  from this you are choosing n minus x other kind of objects divided by the total ways in which you can choose a sample of size n from n now just write down these expressions so  this will be a factorial divided by x factorial a minus x factorial this will be n minus a factorial divided by n minus x factorial n minus a minus n plus x factorial and then this is the denominator  so this flips over  and you get here in the numerator n factorial n minus n factorial divided by n factorial so  let us simplify this expression what i will do is  this n factorial comes here  then x factorial and n minus x factorial this i put together and you can see that am heading towards the binomial distribution  and then you see here  a factorial divided by a minus x factorial so  the terms after a minus x plus 1 will cancel out so  you will be left with a a minus 1 a minus x plus 1  from here and this is gone and similarly here this many terms will go away so  you will because left with n minus a n minus a minus 1 up to n minus a minus n plus x plus 1 one more from here  that will be up to that many terms and then here similarly ; n factorial i have used here now here n minus n factorial  so those terms will cancel out and you will be left with n n minus 1 up to n minus n plus 1 so  this is ok from here to here  this is fine now what i am doing is so  this term this i can write as n choose x  then from here if i remove a from each of this  and this is a rise to x  because this is a a minus 1 a minus x plus 1 so  x minus 1 is comes from here and this is the accept a  so a raise to x this comes out then similarly if you remove n minus a from here  from each of them  from each of these terms n minus a  so that will also be in number n minus x  because this is n minus x plus 1  so when you include this point you will get this so  this is 1  and then this is this  and similarly here it was  would be 1  refer slide time  26  30  so  1 minus 1 upon n minus a  and this is what you had  and then n rise to n we have taken  because here  this is minus n plus 1 so  you take out n from each of them and divide correspondingly so  you will have n rise to small n  that is this here now  what i will do is  i should have written down this step here  what i am doing is  i will write this as  this is this so  i will write this as maybe i will write it here so  this is n c x  then a by n raise to x  out of this and then into divide by n so  1 minus a by n raise to n minus x  so all this  is equal to this  which is your binomial probability of choosing x items from n ; that means  your number of defective  or number of type a items  from the sample size n x this  is probability is that now  this you see here  what we are saying is that x by a small ; that means  a is a big number  large number ; that means  the number of type a objects in your total population  is large then this number is also small  and this number is also small ; that means  your n is very large  in such a situation you can see that  all these numbers go to 1 all of them  and this also goes to 1 so  this whole reduces to approximately number 1 so  this probability hyper geometric probability  of choosing particular type of objects  in your sample  that probability reduces to the binomial now i should have  i did not properly point it out here see when we conduct the binomial experiment  we say that  the trials are occurring independently  and then you keep counting number of successes so  in other words in this situation  the binomial experiment would be  when you are replacing the balls  because getting a white ball is a success  and so in the binomial situation you replaced back the ball that you have taken out so  each time the probability remains the same  of getting a white ball  which is equal to a by n ; see here a by n p so  this actually comes out to be this p raise to x 1 minus p rise to n minus x so  this is what i got so  that means  the difference between a hyper geometric and binomial is  that you know for small values of the population size  it is without replacement the hyper geometric  but if you make the population size is large  and as i said all these 3 numbers should be small  in that case the hyper geometric reduces to is approximated by the binomial probability and i have already shown you that binomial can be approximated by poisson  where we were saying the same thing  that this should be small so  in this case n into p  our p is a by n so  this number should be moderately small  then we say that for capital n being large then we say that the binomial can be approximated by poisson  or the binomial probability goes to poisson  and here i have shown you that a hyper geometric goes to binomial  and by the same argument that i have shown you here  when i talk about  when i take lambda to be n into a by n  then you can show by again manipulating the terms ; that the hyper geometric will go to poisson  already in the earlier lecture i have shown you  that bernoulli is binomial 1 p so  relationship is there that when you have n  when you add up n bernoulli random variables  you get the binomial so  this diagram shows you the relationship between the  various discrete distributions that we have discussed so far  refer slide time  31  26  let us now look at the other types of random variables  which are continuous random variables so  far we looked at discrete random variables  and their special cases now i want to describe continuous random variables  and then again we will look at the special cases of continuous random variables so  essentially  these are random variables of which possible outcomes are uncountable infinite so  here you can not count  and therefore  for example  if you take a subset in r 2  then the number of points  is uncountable  and similarly if you take an interval on the real line  and you consider all possible real numbers  that is a uncountable set examples are lifetime of a transistor  because you do not know when exactly a transistor will fail  but see you might say that  because you have finite clock  so you can say  it failed at this  you can actually say that the lifetime is finite  but then it depends on your counting system i mean as fine as you make it then you know the lifetime  you can treat this as a uncountable infinite ; the arrival of a train at station and so on so  1 can go on adding list to this  and as we go through the topic  we will come across so many continuous random variables now  one way to define a continuous random variable would be  that suppose there is a non negative function f x  define for all real x on the real line minus infinity to infinity  having the property that for any set b of real numbers the probability that x belongs to b  is integral of the function  this non negative function f by d y over b so  here by our definition we are saying that if x belongs to the whole real line  then the probability of that will be integral minus infinity to infinity  and f by d y d y is 1 so  we are putting this condition  and therefore  by definition f is now known as the probability density function  as a post to probability math ’ s function  because now this is a continuous case so  we differentiate between the continuous and discrete by so  in this case the function is probability density function  and for the discrete case  we called it probability math ’ s function so  this is for the random variable x so  if there is a function like this  and if a it satisfies these conditions so  it is a non negative function  then we say that f is the probability density function of the continuous random variable x  refer slide time  34  31  so  let me give you some more idea about continuous random variable so  you know one can also define a random variable x  as a variable whose distribution function is continuous everywhere so  actually the name continuous random variable  has come from here  because the distribution function of a continuous random variable is continuous ; that is why we call the random variable continuous so  actually there is nothing about  you know calling a random variable continuous or discrete we actually say random variable is discrete  because it is cumulative distribution function is discrete ; that means  it has jumps  and we say that a random variable is continuous  if its distribution function is  f x is continuous so  this is everywhere ; that is 1 definition another one can be  random variable x is said to be absolutely continuous  if their exist an integrable function f x from r to r so  that f x is non negative  for all x belonging to r  and its distribution function f x satisfies the equation that f x of x is equal to minus infinity to x integral of f x t d t  x belonging to r for n for n real number that means  the probability x less than or equal to small x  that probability is obtained as integral of minus infinity to x f x t d t x belonging to r and then if you see that  since the distribution function has the property that limit f x x as x goes to plus infinity is 1 so  therefore  you see the value of this integral minus infinity to infinity f x t d t will also be equal to 1  and hence these function small f x that we are saying has to be non negative  is actually the p d f  for the function x so  either way  either you define it through f  and then you say that f  the small f will be the p d f  or sometimes you may define this small p d f  and then small f to be the p d f and then you define the distribution function anyway so  the thing is that  most of the time in this course  i will not saying absolutely continuous of the time  but whatever is absolutely continuous i will call it continuous  and then i will distinguish between mixed random variable  so ; that means  discrete random variable  mixed random variable  and continuous random variable so  what i refer to  is continuous random variable  will be is actually by definition absolutely continuous  because the way we have been handling  we are defining the continuous random variables and the p d f ’ s in this course  this definition this is a right one i mean we are following this definition that capital f x x is equal to minus infinity to x f x t d t x belonging to r so  whichever way  but i just thought that ,one needs to say little more then what i said in the lecture  about a continuous random variable  and of course  through examples we will come to know  quite bit more about the various kinds of continuous random variables that we come across  and their properties now  if b is an interval  then probability x belonging to a  b will be a to b f x d x  and this what i am trying to show you ; that if this is  the curve of f x  then this implies that it is actually the area of the curve  refer slide time  38  26  and of course  i have written it out here  that in terms of your yeah i will come to that so  then and if a equal to b  then this this reduces to probability x equal to a  and that means  a to this sorry b a so  the integral will be from a to a f x d x and by again definition of the integral  this is 0 so  therefore  mass at a point for a continuous random variable is 0 ; that all the probability that a continuous random variable  assumes a fixed value is 0  this is what we are saying by this right and therefore so  i will come to this point is that see the interval i have been writing as an open interval  but here i have written as closed so  it does not matter  because where that you include the point a or the point b or both  the masses at the individual points at the fixed points a and b are 0 ; that means  no probability attains to fixed values of the random continuous random variable  therefore  it does not matter  whether i write it as this or as a i write it is in open interval and then  since the probability x less than or equal to x am sorry this is not correct i want to say here  this is x so  this is now we are defining the cumulative distribution function  the probability x is less than or equal to x  and this will be in by our definition minus infinity to x of f y d y so  this is the cumulative distribution function of x  and from the figure you can see that  this is again f b minus f a  so ; that means  this will be that area from minus infinity to a under the function f x ; that is f a and then this area up to b would be f b so  you are essentially looking for the area  between in the script inside the script and so this is area into the curve so  i have shown you that  for the x is a continuous random variable  then the cumulative distribution function  has been defined according to this  and so we can also then  have the concept of a of the probability in an interval a to b and that is the area under the curve now  let me just make emphasize 2 points here  that you see as a post to discrete random variable  where it was important whether in an interval  when you are talking of probability of random variable in an interval  then whether the n points are included in the interval or not for a discrete random variable it mattered  because every point has some positive probability  i mean are non negative now for a continuous random variable you see  it does not really matter  because there is no concept of a probability at a point  the idea that at a point the probability is 0 so  therefore  whether i say a less than or equal to x less than or equal to b or a strictly less than x less than or equal to b has no relevance so  therefore  it is understood  and see that is why am writing the integral from a to b here  f y d y so  for continuous random variable  at a point there is no concept of probability  or the mass  whatever or the density  because it is a density so  we measure it on an interval secondly  for a continuous random variable  we will call it cumulative distribution function ; that is the proper notation and here again  if some places  it may just happen that  without realizing it i may have used the word density  but does not matter the proper notation is that it should be cumulative distribution function  when your random variable x  or in fact  for this notation  holds for x continuous or discrete random variable so  the word is cumulative distribution function we saw that for a discrete random variable  it was summation  and here it will be in the form of an integral  because you are computing the probability of random variable continuous random variable over the an interval now we want to check that f x has the properties of a c d f  and so the first thing you want to check is  that this limit of f x x as x goes to minus infinity will be 0 so  i should have said that this is equal to 0 here  and of course  this is immediate  because the limit as x goes to plus infinity  would be this integral minus infinity to infinity f y d y  and since f is a probability density function by definition minus infinity to infinity  this integral should be equal to 1  so that part is so  now for this  again the argument may look repetitive  we have already used it elsewhere  but let me just repeat it so let x n be a decreasing sequence  such that x n is going to minus infinity now we define the events e n  which are all points in the sample space for which x is less than or equal to x n then you see again e n  this as n goes to from 1 to infinity  is decreasing sequence of events  and limit e n is n goes to infinity will  be empty  because you know as n goes to infinity  you will be talking of event where x is less than or equal to minus infinity so  they can be no real number  which is less than minus infinity  and therefore  e n n goes to infinity is phi  is the empty set and again by continuity of the probability function  you will say that probability of you know limit probability e n as n goes to infinity  is same as limit probability e n as n goes to infinity by continuity and therefore  this will be phi  because the probability of empty set is 0  refer slide time  44  40  so  this properties also satisfied  and will verify the other properties also  and for to show that it is monotonic  for a less than b this is f x  we want to show that f x is less than or equal to f b now since capital f x b can be written as minus infinity b then b being bigger than a  i can break up this integral into minus infinity to a f y d y plus from a to b f now this is non-negative  f is a non negative function  this is a finite interval  because b is greater than a so  again this number is something non negative  therefore  your probability or your f x b is bigger than f x a so  the function f is monotonic  and therefore  it satisfies all the conditions for cumulative density function  and hence we our definition is proper here now the question  if you just define a function like this  and you ask whether is it c d f of the random variable x  then what do we all need to verify we need to verify that  for minus infinity ; that means  you need to verify that minus infinity to 0  e raise to x by 2 d x this is equal to what see it should from minus infinity to infinity it should be 1  this should  no sorry i am showing this is a c d f so  this is not p d f am not checking is p d f so  what is happening is  e rise to x by 2 limit as x goes to minus infinity  because this is x less than 0 so  as x goes to minus infinity this should go to 0 so  that is fine  because x goes to minus infinity e raise to x will go to 0 so  this goes to 0 now  look at limit 1 minus e raise x by 2 as x goes to plus infinity so  what is happening here this portion goes to infinity so  therefore  this is going to minus infinity  and not equal to 0 so  therefore  this does not define c d f so  we can continue i mean 1 can try to see if any one of the condition fails to be satisfied here  we will conclude that the function that we are looking at  is not a c d f and similarly as we have done it for the discrete case also  we check very 5  and we define continuous random variable  that the whether it is a valid p d f or not  probability density function then i will also try to later on give you examples  where the random variable can be the mixed kind ; that means  some for some portion of the real line  it may behave like a discrete random variable  and then for some points on the real some portion of the real line it may be continuous random variable now another thing that i want to point out is  that since you are defining your c d f as this so  necessarily by the theory of integral calculus  it turns out that this has to continuous function so  that another way of differentiating between ; that means  if for a certain part of a real line  your c d f is continuous  then we will assume that the corresponding the part of the random variable is a continuous random variable and we saw that when it is a discrete random variable  your graph of capital the c d f has jumps  and the jumps are equal to the probability of the random variable at that particular point so  therefore that means  you can have now c d f  which is for in part step function  and in part it is a continuous function so  i will try to give you examples of such  and then that case we will say  that the random variable is the mixed kind so  that means  all kinds of random variables exist  discrete  mixed kind  and continuous introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  8 continuous random variables and their distributions we will go through exercises on discrete random variables when i will try to give you small hints  so that you can work them out yourself  refer slide time  00  2 now  the question 1 says that each voter is for proposition that petrol price should be slashed by rupees 5 so  people are supposed to vote for this with probability 0.9 so  the probability that a person will vote for this that the prices should be slashed by rupees 5 is 0.9 what is the probability that exactly 7 of 10 voters are for this proposition so  you should be able to guess what distribution you have to use here at least one half of an air plane ’ s engines are required to function in order air plane ’ s there is a apostrophic there so  at least one half of an air plane ’ s engines are required to function in order for it to operate so  if there are  obviously we are assuming that even numbers of engines are there so  half of them have to function in order for the plane to be able to fly so  if each engine independently functions with probability p  for what values of p is a 4 engine plane more likely to operate then a 2 engine plane so  please first write down the probability of two or more engines working for a four engine plane  and two for two engine planes  it would be 1 or 2 engines working for two engine plane in terms of p  and then write down any quality that you want the probability for the four engine plane to be higher so  what would be the values of p for which this is any quality would be satisfied question 3  a new boy purchases papers at rupees 2.50 and sells them at rupees 3 however  he is not allowed to return unsold papers if his daily demand is binomial random variable with n equal to 25 and p equal to 1 by 3  then approximately how many papers should he purchase so as to maximize his expected profit ? so  now  see you start with you do not know exactly how many news papers he buys so  let us say the number is r that means r successes binomial random variables you know the probability what is the probability ? it is when this daily demand is the binomial random variable with this  right how many papers should he purchase ? so  essentially what you have to show here is that the expected value would be a function of r  the number of news papers he buys  right and that you have to then maximize with respect to r so  that will tell you what the optimum value of r will be because here see when you take the expected value depending on the demand  it will tell you that when he is able to sell a newspaper  he earns 50 paisa if he is not able to sell a paper  then he loses 3 rupees so  accordingly you have to write down the expected profit for this newspaper boy and then  maximize it and find out the optimum value of the number of papers he must order  refer slide time  03  28  if x has a distribution function f  what is the distribution function of e rise to x ? so  you have to find that out again apply the definition what is the distribution function of alpha x plus beta  where alpha and beta are constants  alpha not equal to beta then  question 5  let n be a positive integer valued random variable show that expected value of n so  n takes positive integer values so  expected n is sigma i varying from 1 to infinity probability n greater than or equal to i so  it is a matter of writing out the expression for e n and then  rearranging the terms  so that you can get this answer six problem  if x is poisson random variable with parameter lambda  show that e raise to x n is lambda e raise to x plus 1 raise to n plus 1 now  use this result to compute e expected value x raise to 4 this is straight forward from a set of n randomly chosen people this problem i have already discussed with you in one of the lectures i explained the notation e ij that a person i and j have the same birthday assume that each person is equally likely to have any of 365 days of the year as his or her birthday so  then you have to find these conditional probabilities that i have written out here and then  i am asking the question are e 3,4 and e 1,2 independent then  what can you say about the independence of the events e 1,3 and e 1,2 and you can almost guess what the answers would be leave it anyway  you have to work it work out  and show that they are that means you have to show that the probability of e 3  4 intersection e 1  2 that means  all these four people are having their same birthday will be product of the probabilities of e 3  4 into e 1  2 and so on  right  refer slide time  05  23  a question 8 prove the recursion formula for x poisson which is probability x equal to i plus 1 lambda upon i plus 1 into probability x equal to i with lambda as its parameters so  poisson random variable with lambda as the parameter  then you have to show this and if you start with probability x equal to 0 equal to e raise minus lambda  then you can compute probability x equal to 1 so  1 from this recursion formula  then i also want you to compute probability x less than or equal to 100 when the mean of the poisson distribution is lambda 100  and you can compare your results because poisson tables are not easily available so  in the website  you can go and look at the tables for a hyper geometric random variable  determine a probability x equal to k plus 1 upon probability x equal to k so  here also i am asking you to find out the recursion formula question 10  the number of eggs laid on a tree leaf by an insect of a certain type is a poisson random variable with parameter lambda however  such a random variable can only be observed if it is positive since  it is 0  then we can not know that such an insect was on the leaf because there will be no eggs present on that leaf if we let y denote the observed number of eggs  then probability y equal to i is equal to probability x equal to i  given that x is greater than 0  where x is poisson with parameter lambda so  find e y so  i am asking you to find the conditional expectation of x question 11  each game you play is a win with probability p you plan to play 5 games  but if you win the fifth game  then you will keep on playing until you lose so  here negative binomial would be used to find the expected number of games that you play find expected number of games that you lose so  i hope you are enjoy doing this exercise  refer slide time  07  18  i will continue with the new examples and some more results about the cumulative distribution function because it is a very important concept and also  we go along with special distributions and so  we will be able to get more familiar with the whole idea so  let us consider the function g x which is defined here for x less than 0 by this  and for x non-negative by this  then we want to show that limit of g x as x goes to minus infinity must tend to 0  which it does because e raise to x goes to 0 as x goes to minus infinity similarly  limit of g x is x goes to plus infinity should go to 1  and that also you can see because this is e rise to minus x so  as x goes to infinity  this portion goes to 0 we left with 1 so  that is fine then  you want to show that g x is mono and g x is monotonically increasing so  we take the derivative here because g is a continuous function differentiable also so  i can take the derivative and if the first derivative is non-negative which it is e raise to x half this is non-negative for all x therefore  g x is monotonically increasing so  g prime x will be half e raise to x for x less than 0  and it will be this is a minus sign so  there is minus 1 will come from here so  it will become plus so  that will be half e raise to minus x for x greater than or equal to 0 so  we see that g prime x is non-negative for all x this is the non-negative function so  therefore  g prime x is non-negative for all x which implies that g x is monotonically increasing which is again a property of g that of a cumulative distribution function so  we are just verifying that this qualifies to be cumulative distribution function and then  other properties we will check g satisfies all the conditions for being a c d f  right now  we also have this result that if f is continuous in an interval  then f the integral of f from minus infinity to x  this is differentiable on that interval so  wherever whichever region f is continuous capital x  the cumulative density function would be differentiable so  that means  if you are given c d f and then  it is differentiable  then you can differentiate it and say that it will be equal to pdf wherever the function is differentiable right and also  we have seen it already that since this is equal to probability x less than or equal to x  then this is integral minus infinity to x of f y d y and this defines again the area under the curve from minus infinity to x so  now  given this since we have verified that this is the valid c d f  let us now find out the probability density function which we said that we get by differentiating the c d f so  here you see g prime x is half e raise to x if x is less than 0  and when you differentiate this part  the minus sign becomes plus so  this is half e raise to minus x which is for x non-negative so  actually this is very important that when you define the pdf  you have to specify where it is defined because that means where it is non-zero  and where it is 0 because you have to say where the mass is of the random variable so  it is very important sometimes people just forget this and you simply write this only which is not correct because you must specify the region in which it is defined that means where the mass exist now so  therefore  this and this is a non-negative function you see that right and now  you can verify that this is valid pdf by integrating it from minus infinity to infinity so  that will be minus infinity to 0 e raise to x  right and then  plus half 0 to infinity e raise to minus x d x  and you can see that the integral would be half e rise to x minus infinity to 0 that will give you  so at 0 ; it will be 1  right so  that is half and minus half so  when you integrate this  it will be minus sign half e raise to minus x 0 to infinity this again gives you half so  half plus half is 1 so  therefore  we have verified that your small f x is p d f and also  that this is c d f  refer slide time  12  19  let us take another example of this cdf now  here an electronic component functioning time before it fails can be considered as continuous random variable x  and suppose it is pdf is given by this  so therefore  you want the first question is for what value of lambda is f x ? pdf obviously  we apply the condition because it is a non-negative function so  the second condition is that from 0 to infinity  since here again you see the mass is of x  non-negative for x less than 0  it is 0  right so  i will integrate the function from 0 to infinity and e raise to minus x by 50 so  this becomes minus 1 by 50 comes to the top to the numerators of minus 50 lambda e raise to minus x by 50 from 0 to infinity so  at infinity  this is 0 and at 0  it will be 1 so  50 lambda is equal to 1 this is a condition we need  so that this is a valid pdf so  we get that lambda is 1 by 50 so  the first question has been answered now  i want you to compute probability x less than or equal to 150 so  you compute 0 to 150  1 upon 50 e raise to minus x upon 50 dx which comes out to be this and then  it is 150 so  at 0  it is 1 and then  this is minus e raise to minus 150 by 50 minus 3 so  look up the value for this from your calculator and you get the answer now  as i said that there are discrete random variables  continuous random variables and mixed kind of random variables so  i will take up this example for a mixed random variable suppose you have given this example capital f x  right so  i plot it for x less than 0  it is 0 so  this is a portion then  you note that here this is x less than 0  for x equal to 0  and greater than 0 than this part operates  right and therefore  the value jumps to 1 by 3  ok then  it continues to be 1 by 3 till x reaches 1  but it is not equal to 1 so  therefore  at this point  it is 1 by 3 and then  it is like this and here at 1 here so  you see the continuity part is satisfied there is a jump here again at x equal to 1 because at x less than or equal to 1  less than 1 is 1 by 3 the moment you attain the value x equal to 1  it jumps to 2 by 3 so  here again the jump is of 1 by 3 and then  after that you see what happens is this is x upon 3 so  if x varies from 2 to 3 at 2  see this is 2 by 3 and this is also 2 by 3  x equal to 2  right so  it continues like this this slope is of this line 1 by 3 and then  of course at 3 as long as say this is the line and then  it becomes free so  you see here you have both kinds that the functions take as jumps so  it is a step function for some values and then  after that it is a continuous function so  therefore  that is what i have said that here  and we have already seen that how we compute this difference  but i am saying that probability x equal to 0  this will be f 0 minus f 0 minus so  f 0 minus is 0  f 0 is 1 by 3 and therefore  the values 1 by 3 probability is x equal to 0  and probability x equal to 1 will be f 1 minus f f 1 minus so  that will be because f 1 will be 2 by 3 and f 1 minus is 1 by 3 so  again the difference is 1 by 3 so  the two jumps are of 1 by 3 so  this is what will happen and here again i want to point out see the result that we have shown that probability x less than or equal to x or of course  even for an interval same thing when i have shown you last time that the area under the strip would be the probability when x lies in an interval so  here this thing is valid only when f is continuous so  this is x is a continuous random variable now so  therefore  for discrete and mixed kind  we will not apply this result so  only when the random variable is completely continuous  you can apply that result so  here this is this result so  one has to be careful and say keep this in mind you can not compute this by area under the curve because see the p d f would not be this this is your cumulative density function  right so  pdf would be for these two values it will be a bar chart and then  it will be this thing so  therefore  the concept of area under the curve does not apply for mixed random variable or for discrete random variable it only applies to continuous random variable you know computation of cdf is very important you should check the idea should be very clear in your mind how you can go about doing it and the validity you must make sure that when you consider a function to be cdf  it must have all the properties that we have you know said that the cdf must have and so on so  you know this even was not enough you should work out many more problems to get familiar with this concept  refer slide time  18  15  we will talk about uniform random variable now which is one of the simplest and very widely used continuous random variable  and try to get the feeling about this particular distribution so  now see suppose we pick number at random between 0 and 1 so  this is important we pick a number at random which means that any number is equally likely been using this term  very often describing events and so on so  we pick a number at random between 0 and 1 the probability that it lies in the interval 0  x should be proportionate it would be the proportion that the length of the interval 0  x is of the length of the whole interval 0 and 1 this is what we mean by picking a number at random i will repeat that if you are saying that i pick a number here and i say that it is lying in this interval 0  x x is of course number which is less than 1  then the probability that the number lies in this interval should be the proportion that the length of this interval is of the length of the interval 0  1 and if you can recall that when we in the discrete case  i had told you number of ferule cases divided by the total number of cases it is sort of an extension over the same concept that if i am saying that the probability that the number that i pick up lies in this  then length of this interval divided by the length of the total interval should be the probability that the number i have picked lies in this interval  and this innocence captures the concept of uniform random variable or what we keep saying a number is equal likely in this interval and so on  right so  this will be when we are saying that probability of the number lies here that means  this actually describes that probability  right because we are saying number that i pick between 0 and 1 lies in the intervals 0 x that means  the number is smaller than or equal to x so  it is between 0 and small x so  therefore  this is f x and what am saying is that the cumulative density function is x upon 1 which is equal to x if x is in between small x is between 0 and 1  so i immediately get the cumulative density function of this random variable and if you draw the picture  you see it is like this because as x goes from 0 to 1 and then  it stays at 1 so  you see there is no discontinuity here  no jumps here therefore  this represents the continuous this is the graph of cumulative distribution function for a continuous random variable  the pdf of course  now we can use this fact that this is differentiable from 0 to 1 and so  the derivative of this function will give you the pdf f x equal to 1 in interval 0 1 and 0 otherwise it is so simple  right so  this is one special case when i said that the random variable is defined on the interval 0 1 so  it is uniformly distributed in that interval in general  we say that x is uniform random variable on the interval alpha  beta if it is probability density function is given by 1 upon beta minus alpha x lying between alpha and beta and 0 otherwise  so you see i will again repeat that whenever am defining pdf or a cumulative density function  i have to define the region on which it is specified so  of course for the cdf  it goes up to infinity because after whatever the values are over  then it stays at 1  ok so  therefore  you see here again this is proportionate to the length of this so  the length of the interval is beta minus alpha  so 1 upon beta so  here for example if you draw the graph of this pdf of random uniform random variable  this will be alpha and let us say this is beta  then this is the length so  this height is 1 upon beta minus alpha which is greater than 0  and you see if you look at the area under this curve  this is rectangle height so  the area is 1 upon beta minus alpha into the length length is also beta minus alpha so  this is equal to 1 so  this is a valid pdf and the area under the graph you know that concepts so  now if you are for example  if you if you want the probability that x is less than or equal to some gamma  where gamma is some number here  right then it will be this area under the curve so  this is how you can simply picturize  not go wrong with it  but just make sure that you write the probability correctly and always validate you always make sure that you have the right number and then  you want to compute the expected value of general uniform random variable this will be 1 upon beta minus alpha integral alpha to beta x d x which comes out to be x square by 2 alpha to beta so  1 upon beta minus alpha into beta square minus alpha square by 2 that leaves alpha plus beta by 2 so  very simple way to remember whatever the interval for the uniform  you just add the two end points ; divide by 2 and that gives you the expectation so  it is a middle point expectation so  what will it be ? yeah  just see here this is the alpha so  alpha plus beta minus alpha by 2  right because the length of the interval has midpoint of this interval is beta minus alpha by 2 which you add 2 alpha to get to this point  right the length here is beta minus alpha so  half of the length  this length is beta minus alpha by 2 add it to alpha and this gives you alpha plus beta by 2  right so  that is the midpoint  right the expectation x square will simply make it beta cube so  x cube by 3 and from alpha to beta  this will be beta cube minus alpha cube by 3 and you know expand this divide by beta minus alpha  you get this and then  for the variance  it will be expectation x square minus expectation x whole square which when you simplify comes out to be 1 by 12 beta minus alpha whole square so  again here it is easy to remember the formula for the variance length of the interval square divided by 12 so  the length of the interval is beta minus alpha  square it up  divide by 12 and that gives you the variance of the uniform random variable  refer slide time  26  05  let us look at this example bus is arrived at a specified stop at 15 minutes interval starting at 7 am so  that is the first bus arrives at 7  then the next bus will arrive at 7.15  then 7.30  7.45 and so on so  at interval of 15 minutes  the bus keeps arriving if a passenger arrives at the stop at a time that is uniformly distributed between 7 and 7.30 am so  this is again an example because you can not     that time of the arrival of a passenger can be sort of treated as a continuous random variable you might say that now  your clock gives you discrete time  but essentially the concept is that we will treat this as a continuous random variable so  here the distribution of his arrival time is a uniform random variable between 7 and 7.30 am with equally likely what time he arrives from 7 to 7.30 am  ok so  then you have to find the probability that he waits less than 5 minutes for a bus so  he waits for less than 5 minutes for a bus  refer slide time  27  19  see since the person should have to wait less than 5 minutes  therefore the event at we are asking for is 10 less than x and less than or equal to 15 it should be not less than or equal to because we want that waiting time to be less than 5 minutes so  equality would have been valid if we had said that the waiting time is 5 or less  but here we are saying the waiting time is less than 5 minutes so  therefore  it should be 10 less than x so  make the correction because while computing the probability  i think i have said 10 less than or equal to x similarly  here it will be 25 less than x so  see here if he has to wait less than 5 minutes  then it should be arriving so  his arrival time should be greater than 25 and less than or equal to 30 so  please make that correction  then computation i said the probability part  it does not make a difference  but here it will with the event have to be described correctly then  you see he should arrive between 10 and 15 see his time is between 7 and 7.30  right so  the first bus arrived at 7  the next is going at 7.15 so  if he has to wait for less than 5 minutes  then he should arrive to 10  right and then  it should be bet less than 15 because he has to get the bus so  this 5 minute interval if he arrives in this interval  then he will have to wait or less than 5 minutes  right similarly  it is if he arrives in this time interval 25 and 30 so  this is in minutes and then  again he will have to wait for at most 5 minutes is that ok ? so  the event that he has to wait less than 5 minutes for a bus so  these two events capture this event and since  they are disjoint  i can add up the probabilities  right this and this are disjoint because the person can not arrive at both the times  both time intervals either he arrives here or here so  therefore  these are the two events so  the probabilities add up and here the probability as i told you  this is simple when you divide i was drawing the figure for you somewhere here so  it is the length of the interval divided by the interval in which your variable lies just what example we looked at  right so  this length interval is 5 and 1 by 30 because his distribution is uniform distribution and the length of the interval is 30 so  1 by 30 is the probability of being  i mean the pdf is 1 by 30 so  therefore  this is 5 by 30 plus 5 by 30 which is 1 by 3  right now  the second part is he has to wait more than 10 minutes so  if he has to wait for more than 10 minutes  then he should either arrive in this interval because if he arrives anytime between 0 and 5 minutes in the see x so  that is what is important i should have specified x is the minutes past 7 am when the passenger arrives at the stop so  x is the random variable because the arrival itself is a random variable so  therefore it is random phenomena so  x  the number of minutes which is past 7 am when the passenger arrives at the stop so  therefore  if you want to describe this event that he has to wait for the bus for more than 10 minutes  then he should either arrive that means the x should lie between 0 and 5 or between 15 and 20 because if he arrives at 15 minutes  the bus has just left so  he will have to wait for the next bus which will come at this thing 7 if he comes at 7.15 then the other one will come at 7.30 so  he will have to wait for more than 10 minutes  right and up to 20 because if like he arrives at 7.20  then he will have to wait for 10 minutes because the next arrival would be at 7.30  right i hope that this event is described by these two again these two are disjoint so  therefore  we can add up the probabilities and this will be 5 by 35 by 30 which is 1 by 3  ok now  important usefulness of random variables because there will be many variations when we will see how uniform distribution is used for example  in simulation you need to generate random numbers from a particular pdf and simulation is the order of a day sometimes if you can not get physical data  you try to generate it  refer slide time  32  26  so  here what you will do is  you want to generate random numbers and we can use this concept of cdf very nicely here so  take x to be a random variable and capital f is the corresponding cumulative distribution function now  define the random variable y which is f x because now whatever the function f  i just place a capital x there so  this becomes a random variable again and this is uniform 0 1 so  this is the way where we will use the property of a cumulative distribution function now  you can show immediately this property because if you consider the probability of y less than or equal to small y  then this is the probability of f x less than or equal to y  right which you know will be 0 if y is less than 0  right and will be fx inverse y if y is between 0 and 1  and this will be 1 when y is greater than or equal to 1 now  i have to use the concept of f inverse here which i did not mention earlier now  a whole idea is that here let us take x to be continuous random variable in that case  your fx is monotonically increasing which we have seen through so many examples also that fx and we proved that also this is one of the properties that fx is an increasing function and therefore  x inverse fx inverse will exist so  there is no problem in case x is so  i am now giving you this property of generating of random number for a continuous random variable  but they are certainly even when x is a discrete random variable this may not be unique  but you can very usually you know there ways of determining unique value for the fx inverse which is possible so  see whenever x is not continuous random variable and is discrete  then for certain interval as we saw  the value of the function fx will remain constant so  we can decide that the inverse  when we take the inverse  we will take the smallest value of y so  that is possible so  we can define  we can determine the inverse in a unique way whether the function random variable x is discrete or continuous so  this will be valid for both of them  but here i am just now talking about x being continuous random variable so  therefore  now again this thing can be written as f x of f x inverse y and therefore  from the definition of f x and f x inverse  this comes out to be y which is that means  your capital y has a uniform distribution 0 1  right so  the idea is that you generate random numbers u1  u2  un random numbers from the uniform so  of course  you might check it how do you do that and there are methods  there are computer methods for generating random numbers  but which are actually pseudo random numbers so  there are whole lot of techniques and lot of available for generating these random numbers which are actually pseudo random numbers from the uniform 0 1 once you do that  then you will say that the x i given by f inverse of u i are random numbers from the distribution of the original random variable that you started  right so  the process is that you generate random numbers from the uniform 0 1 and then  take the x i which have given by f inverse x u i  and these would be the random numbers from the distribution of x so  now  you see you can immediate application of your uniform distribution so  you can generate any number of values from the specified pdf to you know do all kinds of analysis that you want to do about that data  refer slide time  36  27  so  i would like to revise the concept of expectation of a random variable now and for the discrete case  we saw that it is defined as summation x i p x i over all x i for which the probability is positive  right and if these values x i that the random variable x takes r finite in number  then this will be the you know finite number because you are adding up p x i are all between 0 and 1 these are finite in number  and then this will add up to a finite number so  in that case whenever the random variable takes a finite number of values  the expectation always exist  right  but we also saw that in case of poisson random variable where the values are taken by the variable r countable infinite  in that case the expectation which is the sum of this series  we could add up and show that it is actually equal to the parameter of that poisson and in fact  it is right so  this is also called the mean of the poisson distribution so  for this case where the values taken by the random variable are infinite  countable infinite  the expectation exists so  therefore  there always has to be when we define the function e x  we will say that this is the expectation provided it exists so  now look at another random variable which takes countable infinite numbers for example  take the probability of x equal to n as c upon n square takes values 1 to infinity now  since you want this to be a valid pmf  so the summation n to 1 in 1 to infinity of probability x equal to this should be capital x equal to n is this summation  right and therefore  this is equal to you know this series is a convergent series  and it is known that the sum of the series 1 to infinity 1 upon n square is actually pi square by 6  right so  your c must be 6 by pi square so  once i defined my c to be 6 by pi square  this is valid pmf  but when you want to compute the expectation  the expectation would be c sigma n into 1 by n square n varying from 1 to infinity  but then this sum series 1 by n summation 1 to infinity  we all know is divergent series and therefore  expectation does not exist  right so  therefore  one has to be cautious and careful and make sure that i mean e x is defined only if it exists similarly  in the case of continuous random variables  this integral may not always exist even if your f is a valid pdf probability density function  and i will give you an example here this is known as the pdf  where f x is equal to 1 upon pi into 1 upon x square x varying from minus infinity to infinity this is known as the koushish distribution pdf and here again  this is a valid pdf because integral minus infinity to infinity 1 upon pi 1 plus x square d x so  integral of 1 upon 1 plus x  x square is tan inverse x minus infinity to infinity 1 upon pi and then  tan inverse of infinity is pi by 2 tan inverse of minus infinity is minus pi by 2 so  therefore  this becomes plus and this is equal to 1  refer slide time  40  19  so  this is again a valid probability density function  but when you want to compute the expectation of this random variable  you have to integrate this particular integral and you can show that here you see if i make this substitution that x square is equal to  so actually this is running proper integral and i will just consider the integral from 1 to infinity let us see and if this does not exist then  obviously 0 to infinity will also not exist and therefore  this whole thing will also not exist so  let us put x square equal to t and then  your d x x d x is d t so  x d x you replace by or there will be 2 somewhere should have because this is then your 2 x 2 x d x is equal to d t so  this will be 1 by 2 here  right  x d x is 1 by 2 d t so  this is integral of this is l n of 1 plus t 1 to infinity and you know that l n of infinity is infinity so  therefore  this integral does not have a finite value so  your expectation does not exist and hence  your variance will also not exist now  since variance of x would be e x square minus e x whole square and we have just seen that e x does not exist for this particular random variable so  therefore  variance also will not exist because it has to be e x square minus this so  if this does not exist  that means  this is not finite then  obviously variance will also not be finite so  we will say that it does not exist so  i just thought that i will be putting this note here before we proceed with the other theory of probability theory  so that you can find  you know you can not always be sure that the expectation of a random variable will exist now  another very important or widely used concept in probability theory is that of normal random variable and its probability density function so  the function is defined by 1 upon root 2 pi sigma e raise to minus 1 by 2 sigma square x minus mu square  where mu and sigma are parameters of the normal pdf and x varies from minus infinity to infinity now  you can look at this thing here e raise to minus 1 by 2 sigma square x minus mu whole square so  it can be shown by people have already drawn the graph for a different values of x and mu and sigma so  this is a bell shaped curve and it is symmetric about mu that you can see from here because x minus mu whole square so  it is symmetric that means  on either side of mu you take the value  this sign will not matter and therefore  this is symmetric about the value x equal to mu and this distribution was discovered by  was defined by let us say french mathematician abraham de marvn in 1733  and can you believe that he was not very  he use to make a living  he used to spend time in a you know at that time dengue gambling house he would be sitting in the evenings  spend whole evening there and trying to help people because he used this concept of the normal distribution to approximate binomial distribution and binomial distribution he was used to help people because it was a gambling house people would come to bet money and of course  would want to win their bets so  he would give them the probability of you know winning which bet and so on and so  he actually used this concept for approximating binomial distribution and we will be discussing those approximations little later on so  this is how  but the concept he introduced is very important and very widely used one  and i think by the end of the course  you will also see how important this concept is to the probability theory and you know for various estimations that we want to make about different events and their probabilities so  now let us see whether this is actually a valid pdf so  we want to integrate this function from minus infinity to infinity and show that the integral is equal to 1 so  here what i do is  i make the transformation yeah  i have made transformation y is equal to x minus mu by sigma  so then d y is d x upon sigma so  d x upon sigma appears here which gets replaced by d y and 1 upon under root 2 pi is here then  this is e raise to minus y square by 2 this remains from minus infinity to infinity because mu and sigma are finite numbers so  then we have to now integrate this  and let me call this integral as i so  if i multiply this by another integral  this is the notation so  i square now will become a double integral 1 upon 2 pi minus infinity to infinity minus infinity to infinity e raise to minus y square plus t square by 2 d y d t see t and y are dummy variables so  it does not matter and therefore  i can say that this is also i minus infinity to infinity 1 upon 2 root 2 that becomes 2 because you multiplying them so  e raise to minus t square by 2 d t so  this is what you have and now  we want to be able to compute this integral and there this is where we will use polar coordinates so  let me show you the computations introduction to probability theory & its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  9 continuous random variables and their distributions  refer slide time  00  14  to compute that double integral  i make use of the polar coordinates  that is  i make the transformation x is equal to r cos theta y is equal to r sine theta then  you know  that dx dy  the element of area in x-y plane gets transformed to r dr d theta  that is the element of this term your r varies from 0 to infinity because r is a non-negative variable and theta varies from 0 to 2 pi this is your polar coordinate transformation so  therefore i square  then becomes 1 upon 2 pi 0 to infinity 0 to 2 pi and e raise to minus half r square because this was x square plus y square will become r square cos square theta plus r square sine square theta since cos square theta plus sine square theta is 1 so  it reduce to r square and this r dr d theta  right and again  this is in a nice form because now you see  you have r here and you have e raise to minus half r square so  again we will make this transformation  right  that r square is equal to t that is what i am doing here and so  your 2 dr  dr will be dt so  r dr will be half dt and so  that is what i have written here  half dt and this will go to e raise to minus half t so  this is and you write  and see the limits are 0 to 2 pi 0 to this thing now  here what i have done is  already theta does not appear here anywhere so  therefore  this is simply 1 so  with respect to theta this just integrates so  2 pi  which i have written here and then is only integration respect to r and to integrate this i make the transformation r square is equal to t and so  this helps me to reduce it further and this is  you know  minus 2 times e raise minus half t 0 to infinity so  this reduces to this  which is equal to 1 so  we have verified  that the normal p d f  that we have defined is valid p d f and then  now the second step is to compute the expectation and instead of computing for e x we will compute expectation of x minus mu by sigma that will be easier because we know  that the expectation of x is actually mu so  we will show  that this expectation is 0 and therefore  get the answer immediately so  here the  only in this integral you get this term x minus mu by sigma and so  again i make the substitution x minus mu by sigma is equal to y and that reduces the integral to this again it is of the same form you see  that is why the expressions may look cumbersome  but the working is not very difficult and it is just a question of little patience and you start seeing where the calculations are going so  now we have this so  again you make the transformation y square equal to t  the same steps  and you get this and so  so now  what i am saying is  that before i make this substitution i will break up this integral to minus infinity see  one way i can immediately from here conclude  that this integral is 0 because this is an odd integral  right y is here  this is here  the change of sign will not matter but here the change of sign will matter since this is from minus infinity to infinity  this integral will be 0  you know one of the … so  i just thought  that i will show you the steps so  what i am doing is  i am breaking it  breaking up this integral from minus infinity to 0 plus 0 to infinity and then  when you make that transformation  that y square is t  then you see  this becomes plus infinity because when y is minus infinity square will be plus infinity so  this is from  so this would be infinity to infinity to 0 and the integral will be e minus half t  just as we did here and then  this will be 0 to infinity so  now  it is a same integral expect that here the limits are upside down so  when you change the limits it will become minus sign so  there will be a minus sign here and the same integral with the plus sign so  when you add  the result is 0  ok so  i just showed you the steps  in case you are not very sure  but otherwise we could have concluded our computation at this step only and said that this is equal to 0 so  since this 0 expectation of x minus mu by sigma  sigma is a constant  goes out therefore  this implies  that expectation of x is equal to mu so  i had shown you that the normal p d f is symmetric about mu and this is also the mean and in fact  mu has all the properties  that too now i will show some more properties of mu  refer slide time  05  26  similarly  to compute the variance of x  which is actually  since mu is the mean  it is actually expectation of x minus mu whole square  right and this i will write in this form so  now here what you have to do is  again if you have first make the transformation  that x minus mu by sigma is t  so dx by sigma can be replaced by dt  right and the limits remain the same so  this is the simple integral and this way comes sigma square because you have x minus mu whole square so  this is sigma square t square this is it now  what i do here is  the t square i break up into t and t because this integral we have handled already  right well  computing this thing and so  therefore  we will do integration by parts this will be my first function that means  i take the integral of this  multiply by this and then  the derivative of this into the integral of this this is your formula  right so  this integral i have shown you is e raise to minus half t square  this t into this thing  and ok  no  no  why am i  ok  i am actually computing this for you so  i am saying t e raise to minus half t square dt is half  when i make the transformation t square is s  then 2 dt is ds so  this reduces to this and therefore  is this right now  applying integration by parts the integral of this i have already computed for you is  this minus e raise to minus 1 by 2 s and so  this will be t into  when i transform back again substitute for s from here  this is t square so  then t into e raise to minus half t square minus infinity to infinity  you can see  that this is 0  right  because this is t square and so  in the denominator t square e raise t e raise to infinity is much  much larger than t in the numerator so  therefore  this will be 0 you will be left with this and then  here again this is what  this is your in a normal p d f where your mu is 0 and sigma is 1 so  the 1 upon root 2 pi is missing so  therefore  this integral will be equal to root 2 pi because with 1 upon root 2 pi this will become 1  right so  therefore  this whole thing is 1 so  this is  this integral is equal to root 2 pi  so i write root 2 pi  which cancels with this and this is sigma square so  therefore  the variance of the random variable so  therefore  the parameters are  now it is very clear what the parameters denote  mu is the mean and we say normal mu sigma square mu is the mean and sigma square is the variance so  we just saw  that normal distribution  the parameter mu is the mean and sigma square is the variance now  suppose x is n mu sigma square and we consider the random variable y equal to alpha x plus beta where alpha is a positive number and alpha and beta are some real numbers  right so  i mean  i am continuing with the properties of the normal distribution so  if you want to find out the p d f of y  then we start with the cumulative distribution function so  probability y less than or equal to t is probability alpha x plus beta less than or equal to t  which reduces to this and since alpha is positive  the inequality remains in that so  this is t minus beta upon alpha  ok and so  this is your cumulative distribution function y  which is equal to the cumulative density function of x  but the parameter the t replaces is  gets replaced by t minus beta by alpha  right so  now  if you differentiate both sides  that means  differentiate with respect to t  then this will become the p d f  right and this is d dt of f x t minus beta by alpha  which will be 1 by alpha into f x of t minus beta by alpha  right the derivative of capital f x will be the p d f of the random variable x and so  when you substitute  you write down the expression for this  it will be 1 upon alpha 1 upon under root 2 pi into sigma e raise to minus 1 by 2 sigma square and your t gets replaced by t minus beta by alpha minus mu whole square this simplify the expression  this gives you t minus beta minus alpha mu whole square here  you have alpha sigma and this is 2  sorry  the alpha in the denominator comes here so  this will be  there will be a into  into alpha square also i hope you can read it  anyway i am speaking it out  may be let me just rewrite it whole thing here yeah  this is 2 alpha square sigma square and so  by our definition of the normal p d f this will be n  the mean now becomes beta plus alpha mu at the various becomes alpha square sigma square instead of sigma  right so  therefore  you see  that if you make this transformation where x is normal mu sigma square  then for y  the expectation will become alpha mu plus beta  which anyway  you can show from here also this is alpha expectation of x plus beta because beta is a constant and so  this is alpha mu plus beta and the variance will be  just think because the constant will not matter  since you will see  when you write down the variance  you will write down this minus  i mean  this minus this so  beta will cancel  alpha will come outside and so  it will become square and so  either way you can verify  that the  for the  for this random variable then mean will be beta plus alpha mu and the variance will be alpha square sigma square so  you can see  that you can carry on the properties of normal variant  refer slide time  11  55  quite easily  now immediate consequence of this result is  that if x is n mu sigma square  then z  which you write as x minus mu by sigma will be normal 0  1  right  because what is happening ? your  here alpha is actually 1 by sigma if you compare it with the expression alpha x plus beta and your beta is minus mu by sigma so  now if you substitute  because we said  that the mean will become alpha mu plus beta for that one so  here it will become mu by sigma minus mu by sigma  so it is 0  right and similarly  you can show  that the variance will be 1 so  the transformation x minus mu by sigma results in a standard normal variant and which we refer to as n 0 1 now  we have tables for computing the various probabilities for normal 0 1 and you see  that you can then compute the probabilities for any random  normal random variant through this and that is what  because  because of that transformation  right and i will work out few examples to show you how it goes so  anyway this is the standard notation for  for a standard normal variant this is your probability minus infinity to x so  that means  this is a cumulative density function so  this will be 1 upon root 2 pi minus infinity to x e raise to minus half y square d y so  this probability is given the notation now  the tables are given for x non-negative  you know  for values of x going up to … we will  we will also later on see  that we do not need the values to be tabled for very large values of x then  for x less than 0 we use symmetry of the p d f around because this standard normal so  this is  this is symmetric about the origin  right and this is your  this is this  right now  the symmetry means  that if you have x here  then the area to the right of this number is the same as the area to the left of minus x this is what symmetry means because this area  this area are equal  therefore  and since this is half area and this is 0.5  so therefore  this shaded portion here same as the shaded portion here  and so the formula is this so  if you tabled your values for x positive  then for x negative you can get by this and we can verify this formula right away if you want to compute phi of minus x  then that is minus infinity to minus x of fx dx now  if you write y as minus x  then x becomes minus y so  the limits go from infinity to y  right  infinity to y f of minus y dy  right  and there is a minus sign here so  you interchange the limits this becomes y to infinity f of minus y dy  which is 1 of minus  no  phi minus y  right  because this is now y to infinity so  therefore  by the formula this is this  but phi of minus y is phi of x so  therefore  i have shown you  that this is 1 minus phi x so  this formula has been verified so  now you can get values of the cumulative density function for negative  positive  both of x  right so  let us look at few examples suppose x is normal  2  4   that means  the mean is 2 and the variance is 4 so  then you want to find the probability  that x is between 2 and 4 so  i will use that transformation so  here  sorry  this should be z  that means  what i am doing is  i show  i will write in detail i am subtracting 2 and dividing by 2  so less than x minus 2 by 2 less than 4 minus 2 by 2 so  this probability goes here  right and now  so this is 2 minus 2  0 and this is your standard normal variant  right x minus mu by sigma is normal 0  1 for which we always have this notation of z  right and this is 4 minus 2 by 2  which is 1 so  this probability you can compute in terms of the standard normal variant in this way and by our notation this is phi of 1 minus phi of 0 and from tables i get  that phi of 1 is 0.8413 and phi 0 will be 0.5 because we have said  that the standard normal is symmetric  the p d f is symmetric about the origin so  this portion of the  so this area under the curve will be equal to 0.5 and this will be also 0.5 so  phi 0 will always be 0.5 because this is the area for phi 0  right  less than or equal to x less than or equal to 0 so  that would be half of the area  which is 0.5  right so  therefore  this is the probability so  therefore  very conveniently  once you have the tables available for this standard normal  you can compute it for any normal variant  right and again  find probability x less than 0 for this variable so  here again i make the transformation x minus 2 by 2 less than  so this will be minus 2 by 2 so  this is probability z less than minus 1  so which is phi of minus 1 and then  i use this formula  this formula so  phi of minus 1 is 1 of minus phi 1 phi 1  i already know  is 0.8413 so  this is 1 minus 0.8413  which is 0.1587  right  refer slide time  18  25  now  when you want to compute absolute x minus 1 greater than 3  so what are you saying here ? you are saying  that your x minus 1 should be greater than 3 and x minus 1 should be less than  that means  x minus 1 should be less than minus 3 and x minus 1 should be greater than 3  yeah so  from here what do you get  that x should be greater than 4 so  from 4 to infinity and from here you get  that x should be less than minus 2 so  that means  it should be from minus infinity to minus 2 so  that is what we have done i have written  that this event is equal to the  that means  x must be either here  minus infinity to minus 2 or it must be in the set 4 to infinity well  i have used a different notation here than here  does not matter now  since these two sets are disjoint  you can see  right  minus infinity to minus 2 and this is 4 to infinity so  i can write the probability as the sum of the individual probabilities and so  i get this and again  i transform my variable x minus 2 upon 2 so  this remains minus infinity  this is minus 2  so minus 2 by 2 and here  again i use the same transformation to reduce it to standard normal variant and therefore  this becomes phi of minus 2  yeah  because phi of minus infinity is 0 plus 1 minus  this will be what  this is 1 and this is infinity so  here phi infinity is 1 and this is minus phi of 1  right because yes  you all agreed  that this is phi of infinity  i mean  this phi of infinity will be 1 so  therefore  and phi of minus 2 you can write is 1 minus phi 2  again by our formula for computing negative probabilities in terms of positive this thing and therefore  this is it so  i just substitute the values phi 2 from the tables is 0.9772  this is 0.51 and so  this is the answer so  one can go on and therefore  the whole idea would be  that you sit down  calculate a few of such probabilities by yourself to become familiar now  let us just take an example here the annual rainfall in inches in a certain region is normally distributed with mean 40 inches and sigma  that is the standard  we call by the word  i did not name it  but sigma  this is under root sigma square is referred to as standard deviation  this is also known as standard deviation so  standard deviation is 4 that means  variance is 16 what is the probability that starting with this year it will take over 10 years before a year occurs having rainfall of over 50 inches ? so  let us understand the problem first they are saying  that the annual rainfall is normally distributed that means  if every year you add up the total rainfall in that particular region  then those numbers will be fitting a normal distribution  which has mean 40 inches and standard deviation 4  right so  the numbers that you get as the total rainfall in a year for different years  so that has a normal distribution  right now  they are asking for a probability  that starting with this year you go on for 10 years and within those 10 years  no year will have rainfall more than 50 inches so  it is  you know  actually compounded event  it is not a straight forward so  let us see how we go about computing this probability so  to compute the probability x greater than or equal to 50  i will do the same trick  reduce this probability in terms of a standard normal variant so  since mean rainfall was 40 inches  so x minus 40  standard deviation was 4  so this now reduces to a standard normal variant so  therefore  the required probability is the same as probability z greater than or equal to 5 by 2  which is oh  oh  oh this is 1 minus  sorry  this has to be z greater than 5 by 2 would be 1 minus 5 phi by 2  right  and so  this will be 1 minus of this 1 minus 0.9938 and so  this will not be the required probability we will have to write the number  anyway so  what we will do is  yeah  i will continue to say  that p is 1 minus 0.9938 or maybe  i will just do this so  this is 1 minus 0.9938 so  this is the probability of  is the probability of rainfall so  the probability would be standard normal variant greater than or equal 5 by 2  which will be 1 minus phi of  phi by 2  5 by 2 and that is 1 minus 0.9938 because phi 5 by 2 is 0.9938 so  this is probability is now  this we can look upon as the probability of rainfall being more than 50 inches in a year and this we will treat as a success that means  now you can say  that in a year the experiment is to measure the rain and if the rainfall is more than 50 inches  we treat that is a success  right so  that is what i said  that the problem requires because the event is complex so  first we computed the probability of the rainfall being more than 50 inches in a year  which came out to be this now  i want to find out  that in 10 years  rainfall not more than 50 inches in any year so  that means  if i treat those 10 every year as a trial  that means  the trial is  you add up the total number of rainfall in that year and then you say  you are saying  that in 10 years there should be none of the years  that you count from beginning from this year  the rainfall is more than 50 inches that means  in other words  there is no success in these 10 trials and so  the probability of no success in 10 trials would be 1 minus p raise to 10  which must be 0.9938 raise to 10 so  again please compute this number because i had made a mistake so  here this is  this will  whatever this number  you can now use your calculators to compute this probability to say that that will be the probability  that in 10 years the rainfall will be less than 50 so  this is so  i am just trying to show you  that how you first use the normal of approximation  and then i mean the standardization and then  you  you use the binomial random variable to compute the actual probability  refer slide time  25  59  so  median and mode of a normal distribution this  again see  that is why  i mean  when you look at all these properties of distribution  you  you realize  that it  it is a very interesting one and this is  suppose  what we mean by the median of distribution is the number for which the  for which your cumulative density function has the value 0.5 that means  the area of the  if you have this thing here when this is the  this is the point where this is x naught so  this area is 0.5 and this area is 0.5 and since we have already said  that the normal distribution is symmetric about x equal to mu  so that immediately clear  that the area to the left of mu is 0.5 and area to the right of mu is 0.5 so  immediately we know  that a median  the median is also at x equal to mu  right now  to define the  to obtain the mode point  this is the point at which f x  the probability density function attains its maximum value we did this for the binomial also  remember  and what was the number at which the random variable attains its maximum probability so  now  in this case  we will have to find out the maximum  the value  the value of x at which this function attains its maximum value so  this will be done by finding out the  differentiating it  finding out the critical point and putting this equal to 0 the derivative  now you see  that here this is the derivative so  this portion is not 0 so  therefore  this is the only portion  which will be 0  and therefore that gives you x is equal to mu so  x  x equal to mu is the point of maxima or minima essentially  or it could be a point of inflection but  so now  we have to look at further the second order derivative to determine the nature of this critical point and i have written down the expression for second derivative  that means  you differentiate this expression again and compute it at  evaluate it at x is equal to mu so  then you see this  this portion goes 0 because x equal to mu and here also  when you put x equal to mu  you essentially get this so  this is again e raise to 0  which is 1 so  you simply get minus 1 upon 2 pi sigma square  which is less than 0 so  if  if the second derivative has negative sign at a critical point  that point must be a point of maxima so  that much from calculus we can obtain i am sure  therefore  it is really interesting  that x equal to mu is the mean  median and mode so  it is all the things combined into 1 now  another important  as i told you  i have been  i have mentioned  that de moivre was used to  you initially defined this normal distribution to approximate binomial probabilities so  let us  formula is the procedure here so  this is de moivre laplace limit theorem  which is  that if s n is the number of successes in n trials of a binomial random variable  n  p   then for any a less then b so  here of course  for the binomial the mean is n p and the variance is n p q  right so  for any a less then b if you want to look at the probability of a less than s n minus n p upon root n p q less than or equal to b so  you see  what we have done is  we have standardized this binomial random variable of successes in n trials  number of successes in n trials so  it will be s n minus n p upon and root n p q right so  then it is the de moivres laplace theorem says  that this probability can be approximated by phi b minus phi a where phi is your cumulative distribution function for the standard normal distribution or for the standard normal variant so  this will be phi b minus phi a as n goes to infinity so  that means  for large n you can approximate this probability by phi b minus phi a and later on  we will show  that this actually is a very general  i mean  you can talk about a more general result when you do not really need to have the distribution as binomial and for any distribution  this kind of thing  which we call as a central limit theorem  we will talk about it later but right now  de moivres laplace limit theorem simply say  that if you have a binomial random variable  then if you want to compute the probability  that s n minus n p upon under root n p q so  this lies between a and b  a strictly less than this  then this can be approximated by phi b minus phi a this is the laplace theorem so  now  we will use this  refer slide time  31  38  and so we say  that now suppose  you want to compute the probability  that c is strictly less than s n is less than or equal to d and here  of course  it is understood c is also less strictly less than d  then we will standardize the whole inequality in the sense  that we will transform this to c minus n p upon under root n p q and this will be less than s n minus n p upon under root n p q  which will be less than or equal to d minus n p under root n p q and now  you see  this becomes standard normal variant and so  you ’ re a gets replaced by this in the theorem and your b gets replaced by this  right and so  i can say  that by the de moivre ’ s laplace theorem  that this probability  which is the same as this can be approximated by phi of d minus n p upon under root n p q and phi of c minus n p upon under root n p q so  this is the whole idea so  therefore  and these are  these values are tabulated so  given c d have n n p  you can look up the tables and compute this probability and of course  if you want to compute the actual probability  then we will see through an example  that it can be very  very cumbersome so  in fact  this is a very useful theorem and it in a very simple way allows you to compute  approximate these  compute this probability  right and of course  then we will continue with the computations for approximating these probabilities and what they said is  that this is good enough as long as your n p into 1 minus p is greater than or equal to 10 that means  you do not require too many very large values of n  but as long as  of course  if this number is larger than 10  you get a better approximation and that you can also for yourself experiment with problems where you try to increase the value of n and then see  that your  the estimate will improve so  anyway  but this gives good approximation as long as n p into 1 minus p is greater than or equal to 10  refer slide time  33  53  now  there is important aspect to this approximation and that is the continuity correction factor  which i will discuss here so  you see  look at this curve so  i have the binomial curve here  the bar chart and then  the red line curve is the normal approximation and you see  what we are saying here is  that if you are asking for the probability x greater than c this is the shaded portion that you are looking for so  here you want to say  that probability x greater than 7  if you are asking for this probability x greater than 7  yeah so  then if x greater than 7 means  that x is greater than or equal to 8 so  to get that event  to get that probability  if you want a good approximation  see we are the rectangle  the bar  that represents the probability at 0.8 so  that is starting from 7.5 you want to cover that whole area because you are wanting probability x greater than or equal to 8 so  therefore  you will need to say  that your approximate  approximating standard normal variant should b greater than or equal to 7.5 and not 8 so  because the  so you will want to say  for the continuity factor you will say  that you will do it from 7.5 because you want to use a  approx  include the area  which is at the point a the probability  which is represented by  at the point a by this bar  should get added to the  to your estimate  right and similarly  if you are wanting  let us say i am so  i have that table here  just look at the example so  if you have x equal to 6  that means  a single value  if you have x equal to 6  then you would want it between 5.5 and 6.5 because that is the rectangle  the bar that you constructed at 6 that stands at  from 5.5 to 6.5 and the length  the height is the probability of that x equal to 6  right so  therefore  the continuity factor  that you require would be for probability x equal to 6  it will be 5.5 and 6.5 your x must vary  then because see  the discrete situation  you are now approximating by a continuous situation then  as i said  x greater than 6 would be x greater than 6.5 and if x is greater than or equal to 6  then you are including 6  then you will have to go little further down  right that means  you will have to start from 5.5 if it is x greater than or equal to 6  then you will begin from 5.5 so  x would be greater than 5.5 if x is less than 6 that means  x is less than or equal to 5  then again you will say  that x is less than 5.5 so  that is very clear from this graph and x less than or equal to 6 would be x again see  the moment you have equal  then you have to go a little ahead of it  6.5 and if it  it is strict in equality  then so  the rule is very clear and by looking at this figure you can always … so  if you keep this in mind  then you will not go wrong because you will realize  that you have to  you have to include the area under the bar or the rectangle  which is for that particular value  the limiting end value and so  you will have to accordingly to give the correction factor  right so  this is called the continuity correction factor because you are estimating a discrete situation by this thing so  if you use the continuity correction factor  now let  let us give this thing  let us give  let me give you  show you the calculations through an example and so  let me show you an example through an example how we  what i mean by the continuity correction factor so  let x be the number of times a fair coin  so fair coin means  that the probability of showing a head and a tale are the same and that equals half  right so  lands heads when it is flipped 49 times x is the number of times head shows up when i have flipped fair coin 49 times now  find the probability  that x is equal to 25 use the normal approximation and then compare it with the exact probability so  i want to compute probability x equal to 25 and as i told  i just discussed with you  that since this is the binomial random variable  you are trying to approximate it by a normal distribution so  the bar is actually  when x equal to 25  the bar starts from  20  24.5 and ends at 25.5 so  this is the bar  right  and this  the height is the probability that you associate with x equal to 25 so  24.5 and 25.5 so  therefore i have to change the two approximate again i should say this  that the approximate this thing will be 24.5 less than or equal to x less than or equal to 25.5 so  i am now approximating this event by this event  right  because of the continuity factor and then  because the mean  yeah  i am sorry  this should not be 49 i have to write it correctly here so  now for this binomial random variable  your number of times  you flipping the coin is 49 probability  that your p is half so  therefore  n p is 49 into 1 by 2  which is 24.5  right so  it should be 24.5  right and your variance is n p q so  that is 49 into 4 divided by  divided by 4 and so  under root of that would be and that is why  i choose this 49 to make it perfect square so  that is 7 by 2 so  this is now standardized so  x minus 24.5 divided by 7 by 2 would make it standard normal and so  this is the event that you want to  you want to now find out the probability so  this is this  right and therefore  this is equal to 0 and this is 1 upon 2 by 7 so  therefore  this is equal to phi of 2 by 7 minus phi 0 now  this is phi of 0.28 minus phi 0  phi  phi of 0.28 from the normal tables is equal to 0.6103 minus 0.5  right and so  this comes out to be 0.1103 so  this is our probability that we have obtained for x equal to 25 through normal approximation and remember  the condition was  that your n p q must be greater than or equal to 10 so  in our case our n p q is how much ? n p q number is 49 by 4 so  which is more than 10  right  that is  our n p q is 49 by 4  which is equal to 42  sorry  12 point something  12 4 ’ s are 48 so  0.25 in fact  so this is more than 10  right and so  we applied the approximation and this is the result that we got  right now  exact probability if you want to compute using your binomial computations  then you see  it is actually 49 choose 25 and 1 by 2 raise to 49  49 trials and your p and q are the same if you write out this number  49 into 48 up to 25 because that will be 49 minus 25 plus 1 and then  20 factorial 1 upon 2 raise to 49 it took me almost half an hour to compute from  sitting at the computers and this number comes out to be 0.11275 so  if you just look at this here and that is what i am saying  now you compare it with  so third decimal place  the number differs the value differs and therefore  i would say  that this is a good approximation and here  you see our n p q was only  10  12.25 and if you take larger n  that means  if you had flipped the coin more than 49  then this number would have improved and just see the phenomenal calculations you had to do even for n equal to 49  i mean  multiplying these numbers  24 numbers getting 25 factorial multiplying 2 49 times and then dividing so  this this the amount of calculation  that you would have to do for the exact probability certainly is not required if you can approximate this probability by this simple method because this table  these values are already available to you and so  this is what i am trying to say  that you know  as we go on  you will see the numerous applications  uses of this concept of normal distribution and its computations  refer slide time  43  20  so  i will continue with the examples of you know  binomial  the normal approximation of binomial probabilities and this is  these are two good examples from the book by ross sheldon as i told you  that this is the book on probability theory and at the end of the course i will give you all these references so  i just thought i will  you know  give you feeling of  you know  some more examples to  to reinforce the idea that the approximations of discrete probabilities can be done by the continuous random variables and in the very effective way so  let us look at this example the ideal size of a 1st year class at a particular college is 150 students from past experience the college knows  that on the average  30 percent of those accepted for admission will actually attend the college so  therefore  you know  people tend to apply to more than one college and then they  of course  decide which is the best one for them ? so  the college has the experience  that only 30 percent of the people who have been accepted for admission will actually attend the college so  therefore  the college adopts the policy of giving admission to 450  450 students  so that finally  when they  you know  drop out  after the dropout rate  they will still be left with the  with the class of size 150 this is the idea so  they decide to offer admission to 450 students now  compute the probability  that more than 150 1st year students attend the class  right so  given that 30 percent is the  so this is the probability of a person attending who has been given admission  will attend college is 0.3 so  therefore we want to find out so  here  of course  we will say x is the number of students who attend college and so  the value of x will be equal to the  we can treat the person who has been given admission and attends college as a success so  out of 450 people x will be the number of students who attend college so  this would be a binomial random variable with n as your 450 and your p as 0.3 right so  this is binomial  450  0.3   because we are treating  that the experiment has been performed that means  admissions have been offered to 450 students and out of this those who attend  who all actually come attend the college is a success so  the number of successes we are saying is a binomial random variable  right so  therefore  you have to compute the probability so  actually you want that the class size should be  so you have to compute the probability of more than 150 that means  it should be 151  152 and so on so  therefore  when you write probability x greater than or equal to 151  then your continuity factor when you apply  then this will become 150.5  right because you are actually asking for the probability  that x is greater than or equal to 151 because more than 150 so  therefore  we just standardize this  you know  this variant and that would subtract x minus n p n p is 450 into 0.3 and then divide it by n p q so  450 into 0.3 into 0.7 and do this to the right hand side also so  you get this and then  of course  the advantage of taking in solved example is  that you have the calculations done for you so  here this is actually the phi of 1.59 so  this number reduces to 1.5 so  therefore  this is your standard normal probability from minus infinity to  sorry  this is  yeah  to 1.59 so  we are writing this as 1 minus phi of  so this number is 1.59 so  this required probability is 1 minus phi of 1.59  which comes out to be this  0.559 so  hence this reduces to 6 percent of the time more than 150 of the 450 accepted students will attend college so  the college is in good situation  because it is only 6 percent chance  that more than 150 people will actually come and attend the college those who have been offered admission so  this was one situation  refer slide time  47  57  now  another interesting problem this is  see to determine the effectiveness of a certain diet in reducing the amount of cholesterol in the blood stream  100 people are put on a diet after they have been on the diet for a sufficient length of time  their cholesterol count will be taken the nutritionist running the experiment has decided to endorse the diet if at least 65 percent of the people have a lower cholesterol count  right so  after the trial period  at the end of the trial period  you will again take a  test their cholesterol in the blood stream and if the count is lower for 65 percent of the people  then after going on the diet  so the nutritionist will  have i made the sentence complete  running the experiment has decided to endorse  so the nutritionist will endorse the diet and say  yes  it is thus proven to lower the cholesterol in the blood so  now what we want to find out is  what is the probability  that the nutritionist will endorse the diet that the nutritionist endorses the diet  will endorse  there i write  will  will endorse the diet if  in fact  it has no effect on the cholesterol level so  what we are saying is that suppose the diet has had no effect on the cholesterol  but what is the probability  that the nutritionist will still endorse it so  therefore  now the way we are arguing out and so  we have to now decide how to model the situation and the idea here is  that you know  it is either way see  people may on their own have their cholesterol count come down and so  the chance of that happening is  we know  equally likely  either your cholesterol count goes up or it comes down so  that is the equally likely situation and therefore  it is being said that ok  you can just take p equal to half so  therefore we are assuming  that the diet has had no affect on the cholesterol level so  but the since we  the count is going to be taken after the trial period and then  if it turns out that 65 percent of people have lowered their count and they will be  then the diet will be endorsed  so  therefore  we will work with p equal to half so  i hope it is clear so  what we are assuming is  that chance of the count being going up and down is equally likely so  therefore  we will take p to be half and x is the number of people whose  whose cholesterol level is lower  right then  see what  what we are looking for is  so the binomial random variable and therefore  this is  this is the probability  sigma 65 to 100 100 i half raise to 100  right  because r and n minus r  both are will up to end this is p is half so  this is nothing and of course  you can see  that this is   refer time  51  03   stupendous task  you know  trying to compute it this way so  therefore we will say  that essentially  we are looking for probability x greater than or equal to 65 and again add the correction  continuity correction factor  so it will be 64.5 and then n p would be 100 into half and  and p q will be 100 into half into half  which becomes 25 so  under root 5 and this is 50 so  this is what you are looking for and this number comes out to be 2.9 so  therefore  it is the required probability is 1 minus phi of the normal standard normal probability 2.9 from minus infinity to 2.9 and this comes out to be 0.0019 so  which is very small and therefore  the chance that you know  with p as half the chance  that the 65 people out of those 100 will have their cholesterol lowered is very low and therefore  the diet will not get endorsed so  anyway because the diet was not having as  as we said  that probably the diet has no affect on the cholesterol level  so therefore  it does not get endorsed so  no loss  nobody is lost so  this is how  you know  one can go on and look at different situations and then try to see so  i just thought  that these two will also add to your  you know  experience of handling  you know  these problems and also reinforced the idea of  you know  computing  you know computing these  what shall i say  messy probabilities by you know  approximating through continuous random variables and making your task easy introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  10 continuous random variables and their applications  refer slide time  00  19  after discussing we normal random variable  we will today talk about the exponential random variable  a continuous random variable x whose pdf for some lambda greater than 0 please note that  the parameter has to be positive then f x is equal to lambda e raise to minus lambda x for x non negative and 0 otherwise is said to be exponentially distributed  all has an exponential distribution whichever way you want to say it so  again we validate that this is the pdf indeed a pdf so  it is non-negative since lambda is non-negative so  therefore by definition this is non-negative and the integral from 0 to infinity lambda e raise to minus lambda x d x would be minus lambda upon lambda e raise to minus lambda x 0 to infinity so  it infinity it is 0 at 0 it is 1  so and with the minus sign  so minus minus plus  so this is equal to 1  so this is indeed a pdf  then you want to compute it is distribution function and here this would be 0 to a  so this is probability x less than or equal to a  therefore this is integral 0 to a and this again comes out to 1 minus e raise to minus lambda a  a greater than or equal to 0  because our variable itself is non-negative now  we verify the conditions that cdf must satisfy and so limit f a as a goes plus infinity is 1 from here you see as a goes to infinity this will go to 0 so  this reduces to 1 and i should have also written down the limit f a as a goes to minus infinity  see we have any way said that x is less than  i mean for x less than 0  this there is no math ’ s and when can i say it from here if a is less than 0 than of course  this integral is not defined  i mean if a is less than 0 than this integral is 0 are you can argue that there is no math ’ s for x less than 0 so  limit f a a goes to this is 0  then f x is monotonically increasing  so therefore  you take the derivative of f prime of f x  which is f prime x that will come out to be lambda you differentiating so  your f x would be well you treat a as x does not matter  so if you are differentiating this  so lambda would come here minus lambda minus lambda minus plus e raise to minus lambda x and since lambda is non-negative because  lambda is greater than 0 so  therefore  this is again non negative and so the function is monotonically increasing so  all the properties of cumulative density function have been are satisfied  then we find out the expectation of the random variable and that will be integral lambda 0 to infinity integral 0 to infinity x e raise to minus lambda x d x and by integration by parts i treat this as the first function so  this will be this and now you see that at 0 this is 0  so therefore  and this is 1  so the product is 0 at infinity e raise to minus lambda x goes to or if you can write it as x upon e raise to lambda x  then e raise to lambda x goes to infinity much faster than x does  so the ratio tends to 0 so  therefore  no contribution from this term and you are left with just this  so therefore  again you integrate minus 1 upon lambda e raise to minus lambda x there would be infinity that gives you 1 by lambda so  the way to remember is that if lambda is a parameter for the exponential distribution and it is defined in this way  then the inverse of the parameter is your mean or the expectation some places people define it as 1 by lambda minus 1 by lambda x so  in that case you are expectation will become lambda  so it is inverse of the parameter whatever you use for defining this  the inverse of that will come out to be the so  then to find out variance you find out the expectation x square and i have not done the calculations here but  again in the same way you will have to two iterations of the integration by parts  here x square is the second function  this is the first function and you continue doing it  so then that comes out to be 2 by lambda square and therefore  variances 2 by lambda square minus 1 by lambda square  which is equal to 1 by lambda square so  quick example normally this would be associated this distribution was would because  you know when you go to any public place where there is a service counter for example  post office or railway booking and so on now of course  it is mostly online  but still people have to go to counters for all the services  then you know the time that the clerk will take to service the customer is most of the time random variable and  so exponential variables do model that situation quite few this thing  so suppose the length of service at a post office counter in minutes is an exponential random variable with parameter lambda is equal to 1 by 15 so  immediately you can say that the exceptive number of time that the exceptive duration of service to a customer would be 15 minutes because  the expected value of the this random variable would be 1 by lambda  which is 15 minutes  refer slide time  07  00  if someone arrives immediately ahead of you at the counter find the probability that you will have to wait 15 minutes between 15 and 30 minutes to find the probability that you have to wait for 15 minutes that means  at least 15 minutes  so therefore  the event would be x greater than or equal to 15  where is x is your time for you have been to wait so  probability x greater than or equal to 15  which will be equal to 1 minus probability x less than 15 and therefore  we have computed this already while computing for x less than exponential distribution so  this would be 1 minus of 1 minus e raise to minus 15 by 15 because  your lambda is 15  so therefore  this probability comes out to be e raise to minus 1  which is 0.368 since  as i have said that because  we have already made this computation that this will be equal to 1 minus e raise to minus 15 by lambda and your lambda is 15 so  therefore  this will be equal to e rest to minus 1 and so this is 0.368 so  similarly for the second one probability 15 less or equal to x less than or equal to 30 ; that means  you are waiting time is now between 15 and 30 minutes so  that will be again by the same computations will be f 30 minus f 15 and which again would be 1 minus e raise to minus 2 because to be 30 by 15  which is minus 2 and then this is minus of 1 minus of e minus 1 and so because this is less than or equal to 15 and so less than or equal to 15 less than 15 for a continuous distribution  so it will be this the probability and  so it is e raise to minus 1 minus e raise to minus 2  which is 0.233  now i want to show you another important property of the exponential distribution so  first of all we will talk about the memory less property and we say that random variable x said to have the memory less property if probability x greater than s plus t given that x is already greater than t is equal to probability x greater than s for all s and t non negative  which means that it does not matter how long you have already waited  if you are asking for this probability x greater than s plus t then it is same as probability x greater than s so  therefore  the system we are modeling does not have memory less property and so we are talking of random variable whose distribution satisfies this condition so  now i will show you that the exponential distribution among all continuously distributed random variables are among all continuous pdf 's exponential distribution have the probability of being memory less distribution  which are discrete and which have also the memory less property but  among continuous distribution random variables  which is exponential distributed has the memory less property so  in case this random variable is exponentially distributed with parameter lambda  then you see if you write down this expression probability x greater than s plus t given that it is x is greater than t  then this will be this because  even the product of these two would be intersection of this two when should be x greater than s plus t  you would because  it is t smaller than s plus t so  this reduces to this expression x greater than s plus t divided by x greater than t  now by our definition this is because  f a is 1 minus e minus lambda s so  1 minus f a would be simply e raise to minus lambda a  so here it e raise to minus lambda s plus t divided by e raise to minus lambda t and which is this  which is equal to probability x greater than or equal to s so  exponential random variables are memory less and in fact  little more arithmetic would be required or calculus to show  that if you impose this property then you can actually show that the only exponential random variables have the memory less property so  since this is being our first course i am omitting the mathematics here  but who was interested can sit down and work it out and see that  when you start with this condition for a continuous random variable  then you will see that only exponential random variables the pdf  which will satisfy this condition will actually the exponential pdf so  let us again look at an example  suppose that the number of hours before a transistor phase is exponential distributed with mean 500 hours so  here the lambda is 100  if a person desires to go on a long trekking trip of 300 hours and uses the transistor in his radio  then we want to find out what is the probability that the transistor will not fail  refer slide time  12  27  what is the probability that the person will be able to complete his trip without having to replace the transistor so  he wants that the probability that the transistor will not fail for 300 hour long tracking trip that he is undertaking  so the solution is that affects is one upon 500 e raise to minus 1 upon 500 x because  in the problem it says that the hours the lifetime of the transistor is exponential distributed with mean 500  so as i was telling you if the mean is 500  then the parameter will be one upon 500 so  therefore  the pdf of the random variable representing the lifetime of the transistor would be given by this x nonnegative so  therefore  probability x greater than 300 is simply e raise to minus 3 by 5 because  it is e raise to minus 300 upon 500 which is e raise to minus 3 by 5 and you can compute this value from the table so  what can be said when the random variable is not exponential distributed and that case the memory less property is not there and  so this would be simply conditional probability in terms of capital f and so that is it you see the advantage of having random variable  which is memory less now  another thing that is useful and can be again for exponential random variable it gets quite simplified and that the hazard rate function or sometimes you also called the failure rate function so  if x is a random variable which is representing lifetime of some item and of course  it does not non negative variable and the cdf the pdf is given by small f and cdf by capital f then hazard rate function called the failure rate function is denoted by lambda t and is defined as follows so  lambda t is small f t that is the pdf divided by 1 minus cdf  so and the simple explanation is possible  so here again what we are saying is that x belongs to this is the bracket here  t plus delta t  delta t is very small and then given that x is already work for t now what we are saying  that it will fail just after t because  t plus delta t so  x lies in the interval t comma t plus delta t given that it has been functional till time t and  so this is probability x belongs to t comma t plus delta t  delta t is a positive quantity very small so  therefore  when you take the intersection these two you get this event divided by probability x greater than t and so this will be by our definition f t plus delta t minus f t divided by 1 minus f t so  now  you see the limit of this delta t becomes smaller  then you know you divide by delta t and multiply by delta t  so this divided by delta t remember limiting value of this is the derivative of f at t so  which becomes f prime t into d t upon 1 minus f t and f prime t is your pdf f small f t divided by 1 minus f t d t so  therefore  the definition of the failure rate because  as we see that it should fail just that t time  time t is rate has been functional up to time t then it fails  refer slide time  16  24  so  now if f t is exponential you see when you write out this will be small f t  so the pdf is mu e raise to minus mu t  i used symbol mu because  lambda is already being used here and this is 1 minus f t would be e raise to minus mu t so  you see this is mu a constant  so for exponential random variable we have that rate is a constant  it is not a function of t otherwise  as you see that this will be a function of t  so the hazard rate function is dynamically changing depending on the time that means  if you are talking of lifetime  so as it should be  but for exponential distribution exponential is simple  since it is memory less therefore  the hazard rate function does not change it is a constant so  this is the rate of failure and so because it is memory less  it does not matter how old the instrument is the probability of it is failing any time is same and so here the rate is also constant mu is therefore  also referred to the rate of the exponential distribution so  now  mu is the parameter this is also the rate of failure for exponential distribution and we saw that one upon mu will be the mean of the exponential distribution  refer slide time  17  40  so  given hazard rate of function lambda t for a continuous random variable  it is possible to determines it pdf so  we will just show because  you see lambda t i can write as d d t of f t 1 upon minus f t and then if i take the integral of both the side attach a minus sign so  there is minus sign here  this is 0 to x lambda t d t and this is integral 0 to x minus f prime t  i written this as f prime t d t upon 1 minus f t  now by formula for integration because  derivative of this is this therefore  this will be l n of 1 minus f t so  therefore  l n of 1 minus f x because  you computing from 0 to x  so there is 1 minus f x will be and this is integral minus 0 to x lambda t d t  i hope this is clear because  see this will come out to be l n of 1 minus f t and this is from 0 to x  so 0 to x when you put x here  this will be l n of 1 minus f x and at f 0 is what  f 0 is 0 so  l n of 1 is 0  so therefore  the contribution from here you get is l n of 1 minus f x  you remember limit f x as x goes to minus infinity 0 so  therefore  i am just using that so  that reduces to l n of 1 minus f x and this right hand side this is minus 0 to x lambda t d t so  therefore  you can say 1 minus f x is equal to e raise to minus 0 to x lambda t d t and so f x you can write down from here as 1 minus of e raise to minus integral 0 to x of lambda t d t so  if i know lambda t  then i can integrate here and then my f x will be of this form  so ; that means  it is enough if you know the hazard rate function of random variable  you can determinate distribution so  once you know the equality density function  you can determine the pdf also now  i will just illustrate the concept some more through an example  this is see it is said that the death rate of a smoker is at each stage twice that of a non smoker that means  this that your age gets reduced by half  if you are a smoker compared to what a non smoker so  what is the ratio of the probability of a non smoker to that of a smoker of surviving up to the age of  so suppose i am just saying that  what the both of them surviving up to the age of 60 given that both have survived up to 50 years  you want to find out the probabilities so  may be ratio part is not important all i am saying is let us find out the probabilities that non smoker will survive up to the age of 60 given that he or she has survived up to 50 years similarly  a smoker the probability what is the probability of a smoker surviving up to 60 years  given that he had survived up to 50 years so  i will define lambda s t as the hazard rate of the smoker and lambda n t as the hazard rate of non smoker so  now  let me just right now take instead of 50 just let me take some years a age a so  what we are saying is that a probability that a non smokers life time is more than 60 years given that the life time of the non smoker has been more than a is the conditional probability because  again the intersection these two because  60 is more than a  so this is probability that the non smoker has been  the life time will be more than 60  so that becomes 1 minus f n 60 divided by 1 minus f n a and from here  i will see this is 1 minus f x is e raise to minus integral 0 to x lambda t d t so  that is would be 0 to 60 lambda n t d t and 1 minus f n a will be 0 to a lambda n t d t e raise to so  this is what we just computed here and therefore  if you take this upstairs  then you see the integral this become e raise to a to 60 so  this will be e raise to minus integral of a to 60 lambda n t d t and this let me call as p n  so the probability of smoker surviving up to the age of 60  given that he has already survived up to the age of a  refer slide time  23  01  and correspondingly for a smoker this probability of surviving up to 60 years given that he had survived up to a years is lambda s t d t and i am calling it as p s so  if the belief is that lambda s t is twice lambda n t ; that means  the death rate is twice as high for a smoker compared to a non smoker  then i substitute for lambda s t twice lambda n t here so  that will be twice lambda n t and so this would becomes square of i would not writing the step i mean actually this is equal to e raise to minus a to 60 lambda n t d t square  which is probability p n square so  the effect is that the probability gets squared up for a non smoker  so the probability of surviving up to the age of 60 for a smoker is square of the probability of the non smoker surviving up to the age of 60 so  this 50 was not really because  a could be anything here  so given at that is why we said  that at any age at each stage  so therefore  it does not matter when you are making this comparison so ; however  the old both the people are after that if you want to say what is their age of surviving up to 60  when the probability for the smoker is square of the probability for the so  now  here as i said that if you take lambda n t to be 1 by 30 ; that means  remember i am taking the situation when so  that means  this is now because  this is constants  so therefore  i am taking the exponential situation  that is the random variable the lifetime is random variable is the exponential distributed  then a probability that non smoker reaches the age 60 would be because  this lambda n t is 1 by 30 so  you want to compute will it come out to be e raise minus 1 by 3  e raise to minus you are saying this is 50  60 and 1 by 30 d t so  what will that be 1 by 30 into 10 so  this is i mean e raise to minus  this is e raise to minus 1 by 3  so if this is a constant ; that means  it corresponds to exponential random variable and so this is e raise to minus 1 by 3 which turns out to be 0.7165  so for a non smoker and for a smoker it would be a square of this  which will be 0.5134 so  see how fast the probability has reduced because  person smoking  so the probability of a smoker surviving up to the age of 60 is 0.5134 and for a non smoker it is 0.7165 so  that we wanted can have many more applications and it has will go long may be i have put some problem related to hazard rate function in your exercise 4 also  refer slide time  26  42  now  we continue with some more special continuous random variables and the next one is the gamma distribution and x is said to have gamma distribution with parameter alpha and lambda  both the parameters have to be positive pdf is given by this equation so  effects is lambda e raise to minus lambda x lambda x into raise minus 1 upon gamma alpha and that is why the name  refer slide time  27  05  so  this is let me show you the calculation for the gamma alpha  so let us compute the value of gamma alpha for alpha greater than 1 so  therefore  the definition is this is equal to 0 to infinity e raise to minus y  y rest to alpha minus 1 d y right  so integration by parts and therefore  this will be the derivative here is e raise to minus y should be minus so  here this is minus e raise to minus y  y rest to alpha minus 1 0 to infinity and then this becomes plus because  minus minus is plus so  therefore  this will be plus 0 to infinity then derivate of this is alpha minus 1 y rest to alpha minus 2 e raise to minus y d y now  let us compute the values at the end points  so for y equal to 0  see this will be 0 because  alpha is greater than 1 and that is why it is important so  alpha is greater than 1 therefore  this is a positive power  so therefore  this is 0 and of course  at 0 e raise to 0 is 1  so this is equal to 0 and again y goes to infinity  then this goes to infinity faster than this here again because  alpha is greater than 1  so this exponent is positive and therefore  this will go to 0 so  therefore  no contribution by this term and so your integral  so gamma alpha reduces to just this  which by our notation will be gamma alpha minus 1 should so  therefore  i did not write  so here it relatively ; that means  this integral will be now alpha minus 1 and so for positive integral values of alpha  if i you know go and doing it iteratively so  for integer values of alpha positive integer values of alpha  this we can see is gamma alpha would reduce to factorial alpha minus 1 you can see that because  as go on  so the finally  what you will have be this will be then i should have  this is alpha minus 1 so  this should be equal to alpha minus 1 gamma alpha minus 1 from here alpha minus 1  so therefore  as you go on the next iteration it will be gamma alpha minus 2 and so as we go on alpha is a positive integer therefore  you end up finally  with just integral 0 to infinity e raise to minus y d y and so this will reduce to alpha a factorial of alpha minus 1 for alpha be positive integer now  it can also be shown that the gamma function is defined for alpha between 0 and 1  this is also possible we can also show that the integral will is defined that it will be finite value so  for all values of alpha between 0 and 1  the integral is also defined ; that means  gamma alpha is defined for alpha between 0 and 1 and one important value is gamma 1 by 2  which is root pi and this integral we will obtain this values later on in the forth coming chapters so  i will talk about fractional values of gamma alpha between 0 and 1 and there are tables available for fractional values of alpha the tables available non negative fractional values of alpha tables are available and for alpha equal to 1 the gamma distribution reduces to the exponential distribution  refer slide time  31  00  all of to check the see our gamma pdf is given by this  so when you put alpha equal to 1 this term is gone and so your pdf reduces to lambda e raise to minus lambda x and gamma alpha is also 1 so  therefore  you will be the gamma pdf reduces to lambda e raise to minus lambda x for x no negative  so therefore  for alpha equal to 1 the gamma distribution reduces to the exponential distribution so  this is one relationship and then i will show you some other relationships between many other this thing now  you want to again check that this pdf is a valid pdf and therefore  i have to show that this integral will evaluated to 1 so  here of course  you put lambda x equal to y  then lambda d x is equal to d y and immediately this integral reduces to e raise to minus y lambda d x gets replaced by d y and this is y rest to alpha minus 1 upon gamma alpha and so from here you see that divide by gamma alpha here and this equal to 1  so the validation is complete so  therefore  this is the valid pdf and now you want to compute the expectation of this gamma random variable  then you have to multiply this by x and integrate  but it is easy to manipulate because  i will add x to this and lambda also so  i divide by lambda  there i multiply by alpha and multiply here by alpha  so this becomes gamma alpha 1 by our definition so  this will be gamma alpha 1 and this will be lambda x rays alpha  so ; that means  the pdf of gamma here the parameters are alpha plus 1 and lambda so  therefore  since this is again the pdf for gamma alpha 1 comma lambda  so again it will integrate to 1 and so you will be left with alpha by lambda so  the expected value of alpha  lambda  gamma  variable is alpha upon lambda  so ; that means  if the convention to write this first and then this so  then this divided by this that is you are taking the gamma distribution alpha comma lambda  then similarly expectation x square can also be just by simple manipulation computed immediately  what i will do i need lambda square here to bring together with this so  i divide by lambda square and i multiply by alpha alpha 1 to make it gamma alpha plus 2 and this will be lambda x rays to alpha plus 1 so  again this is the pdf of gamma alpha plus 2 lambda  so this will integrate to 1 and i will be left with alpha into alpha plus 1 upon lambda square and so variance will be this quantity minus alpha lambda whole square and that gives me alpha upon lambda square  so simple calculations to tell you the required quantities  refer slide time  34  25  now  let me just show you an application and this application may be i will using a concept which we have to do  but it does not matter i still start that this would be good time to mention this application so  here see this is we are considering the case on alpha is positive integer  when alpha is equal to n is a positive integer  now gamma distribution e raise as the distribution of the time one has to wait  until the total n events have occurred so  it is like you go to a railway booking counter  then you have people ahead of you in the queue and each person as i have told you that the we will treat service time as random variable so  and remember that the i shown you that the service time being random variable can be an exponential random variable  so for each person the service time is random variable and then since there different people independent people so  each one get serviced  so then the total time would be sum of that many independent random variables and exponential distributed random variables this is the idea  so now  the what i am trying to show you is that  the gamma variable is actually the time one has to wait till all people ahead you have been serviced and you have also been serviced so  the way we will measure it is that when i am saying alpha is equal to n  so here i could be counting that you also have been serviced so  then until a total of n events have occurred and of course  later on when we do the poison process and so on  then the whole thing will become much more clear but  you can just get a feeling for the application that i am trying to discuss here  so now  let t n be the time at which the n th event is occurred so  when t n less than or equal to t this event could that mean  if and only if all the n events are occurred by time t  t n is the time at which n th event occurred so  now  t n less than or equal to t will be that by time t all the n events have should have occurred  means in our particular case all n people have been serviced by the railway ticket booking counter now  let capital n t be the number of events in 0 t  see in this particular case if the people ahead of you like say n minus 1 people ahead of you  you are the nth person then ; that means  the time span you are taking is 0 to t  then that many people should have arrived in the time 0 to t  when they are n people in the system  then only they get serviced this is how so  in this case there are n arrives in this time and so when we look at probability t n less than or equal to t  if you want to compute this probability then this is same as probability n t greater than or equal to n because  at least n events in 0 t ; that means  at least n arrives must be there can be more but  when we are talking of n people to be serviced in this span of time  then at least at many people should have arrived that many events must be there in the system so  this is what it is and this we will therefore  because this discrete thing people arriving are discrete events so  j this is to be j from n to infinity probability n t equal to j probability that there are j people in this system time 0 t and then you summit of from j equal to n to infinity  now this is the part  see very often when you talk of events discrete events occurring in span of time  under certain conditions it can be shown that these will be poison arrivals that means  the number of arrivals in a span of time would follow a poison distribution and therefore  probability n t this i will proof oftenly and we are talking about process is also one so  then in detail i will discuss how you arrive at this probability when you under certain assumptions you can show that the probability n arrivals in the time 0 t would be given by this so  you summed up j to n  so it means for n t equal to j actually n t is the poison random variable and so the mean value becomes lambda t because  you are taking the span 0 t  so this will later on we explained so  therefore  this is your poison probability is summit up from n to infinity now  this is your cumulative distribution function for t n to find out the pdf  i will take the derivative  which is f t n of t and so  we differentiate this expression with respect to t and you see first differentiate this and lambda comes out and j  so j lambda e raise to minus lambda t  lambda t rest to j minus 1 divided by j factorial minus derivative of this  which will be lambda minus lambda e raise to minus lambda t  lambda t rest to j divided by j factorial and here j varies from n to infinity and so just rearrange the things little bit j when cancels out here so  it will be j minus 1 factorial lambda t rests to j minus 1  refer slide time  40  17  so  what you see is that here the terms are from starting from j minus 1 and here it is j  so you see things will cancel out in pairs and except the first term here will be left out  which will be lambda e raise to minus lambda t lambda t rests to n minus 1 divided by n minus 1 factorial  that is only one because  when you put j equal to n plus 1 here that will be lambda t rest to n upon n factorial and here also j equal to n it will be n factorial and lambda t rests to vise it j minus 1 here because  when i am differentiating with respect to this one here then lambda t rays to j remains in that  so this is it so  therefore  this term will cancel out with the second term here and then the third term here will cancel out to the second one here and so this will process will go on only the first will be left out here  which is lambda e raise to minus lambda t lambda t rest to n minus 1 upon 1 minus 1 factorial  so this is now gamma distribution with parameters and gamma lambda so  therefore  the amount of time a person has to wait till he serviced and if there are n minus 1 people ahead of you in the queue and so that is random variable and just now shown that when the arrivals are poison  then this will be gamma distribution with parameters n comma lambda so  in this case this is also referred to as n erlang distribution that is another name in literature you might some books may referred to this distribution as n erlang so  we have got some feeling about the gamma distribution and as we go on i will give you some more inside into the thing now  the other distribution continuous variable distribution  which is of important is the beta distribution  so a random variable x with pdf given by the equation f x x is 1 upon this is the beta function a comma b x rays to a minus 1 1 minus x rays to b minus 1 x between 0 and 1 and 0 otherwise  refer slide time  42  34  the integral we denote by b a comma b  so this is 0 to 1 x rays to a minus 1 1 minus x rays to b minus 1 d x  where a and b both are positive now  again just as for the gamma distribution  we can show that for a greater than or equal to 1 and greater than or equal to 1 the integral will converge and in fact  for integer values just like we did for computation for gamma distribution  it can be shown that this integral will be equal to gamma a gamma b by gamma a plus b so  therefore  i should again correct my statement here that is the beta pdf is this function divided by this so  it becomes gamma a plus b divided by gamma a gamma b and therefore  the integral will   refer time  43  23   to be one  so the beta pdf is actually this divided by this number and so we denote this integral by b a comma b which is so  therefore  it has i will since defined for all a b positive  now for a greater than or equal to 1 and b greater than or equal to 1  you can show by integration by parts the integral will converge and will be equal to this therefore  fractional values of a and b also it can be shown that this is defined the integral is defined and it is equal to gamma a gamma b upon gamma a plus b now  many useful applications of the beta distribution and one case that it models random phenomenon whose set of possible values is some finite intervals c comma d so ; that means  all possible values of this random phenomenon occur between within a certain interval c comma d and  but   refer time  44  24   we have here defined the variable to be from 0 to 1  so then by scaling and shifting  we can transform this interval to 0 1 and of course  one obvious transformation is that y is equal to x minus c upon d minus c  so then all possible values of x which are within c d will now be  so the corresponding y variable will have all values between 0 and 1 so  and then we will see for applications of the beta distribution and will compute the other quantities related with the beta distribution now  i am just trying to give you the pictures of graphs of this beta distribution for different so  now  when a is equal to b this graph is symmetric  the graph of the beta function pdf is symmetric and for example  a equal to 3 it will be something like this and as a becomes bigger  the mass gets concentrated this the graph becomes narrow or and this is symmetric so  if you draw for a equal to 10 probably it will be something like this peak the peak will be higher and so on now  for a not equal to b the graph is asymmetric and skewed towards the left  so for example  a equal to half it is almost skewed towards the y axis and as a increases again the skewness shifts to the center and this of course  the graphs are not drawn to scale  but they indicated a upon a plus b is equal to 1 by 20  so in this situation suppose a is 6 we can find out what the value of b is and so on now  there are situations see for example  if you have a big project  in which you have lot of jobs and so of course  a big project will be made up of number of jobs and this project may not have been handled completely before  so there is lot of uncertainty about the job completion times and as a project manager he has to or he or she has to you know sometimes be have some estimate as to how long it will take for the whole project to be completed  which means that  must have a good idea as to how long it will take for each job to be completed  now in the absence of any previous experience because  jobs have not been performed for example  of course  this is no very old example that when they would trying to put a man on the moon  then it was completely new project all the job that made up the project new so  people had no idea about the how long it will take for the jobs to be completed  but there are certain finites span and then of course  you do not expect just like as for the normal distribution for example  it is a symmetric distribution but  then here there was no reason to believe that the completion time distributions will be symmetric so  therefore  beta distributions fitted the bill very well because  here were the distributions  which have they finite span and even though it is a continuous distribution and then it was not symmetric  so and so on so  then huge projects were then the time estimations were made using beta distributions  so interesting applications  so where job completion times are not protectable  you have no idea then again by integration by parts  you can show that expected value of x is a upon a plus b and where else x will be a b upon a plus b into a plus b plus 1 so  beta distributions again you want get ’ s time one can talk about i can give an idea  how the time estimates are done using a beta distributions now  as we go long we also keep coming back to distributions of large functions of a random variable and i will just do some sample functions here  and then try to give general result so  let us say suppose x is uniform 0 1 and ; that means  x is taking a non negative values  then if you define the function y equal to x e raise to n then ; obviously  x e raise to n will also remain in the interval 0 to 1  that means the range for y is between 0 and 1 and  so if i want to find the pdf of y  then probability y less than or equal to small y is the same event as probability x n less than or equal to y and this will be probability x less than or equal to y 1 by n so  remember this is because the value here are non negative  so this is the same as this inequality the n the root and now if you do differentiate both sides  this will give the pdf of y and here when you differentiate this  this will give you pdf because  now effects right this side is f x y 1 by n so  you are differentiating respect to y and so this effects y e raise to 1 by n into derivative of y 1 by n  which is 1 by n y e raise to 1 by n minus 1 and y between 0 and 1 so but for a uniform random variable this is equal to 1  refer slide time  50  11  and therefore  the pdf of y reduces to 1 by n y e raise to 1 by n minus 1 when y is between 0 and 1 and 0 otherwise  take another functions so  now  you take the function y equal to x square and this case you are not saying that x can only take no negative values  x can take negative values also then you see  when you write down this event probability y less than or equal to small y  which is probability x square less than or equal to y then this will be then equal to this event that capital x is between minus root y and plus root y because  i did not if i you know sort of put the restriction that x has to be non negative  then ; obviously  this it would have been just this part  this part would not have been there but  since i am allowing x to take all positive negative values therefore  this will be equal to this event right and so by again our this thing writing the momentums of the accumulative density function  this will be affects root y minus effects of minus root y and then so we differentiate again respect to y and d d y f f y is the  so here this will be affects root y and then derivative of root y which usually 1 upon 2 under root y  this is x and plus affects minus root y so  the minus minus will become plus because  there is minus coming from here  this is the minus here already  so plus affects of minus root y into 1 upon 2 root y  refer slide time  51  56  so  this would be your pdf are y equal to x square  now the third kind of function that i am looking at here is y equal to mod x so  x has a pdf affects  then here than in this case y will have nonnegative values  even though x is negative values  so we write down the event probability y less than or equal to small y  this is probability mod x less than or equal to y  which again can be written as x between minus y and y because  the absolute value has to be less than y y is a positive number so  therefore  in magnitude the value x even if it is negative  it has to be higher than minus y because  if you are saying that mod x should be less than or equal to 3  then you are x can not be minus 4 because  absolute value of x would be 4  which is not less than 3 so  therefore  the values of x have to be between minus y and y and therefore  this is f y minus f of minus y and when you differentiate respect to y  you get pdf of capital y  which is affects y again minus sign gets converted to plus because  there is a minus coming from the derivative of minus y so  this y greater than y equal to 0  so one can go on  but then i will just summarize all these in this theorem and so this is the x is the continuous random variable and affects it is pdf  suppose g x is a strictly monotone increasing or decreasing function  so this is now very clear and it is differentiable so  strictly monotone means that it is either going like this the function like this or it is coming like this  so monotonically decreasing or monotonically increasing then the random variable y equal to g x has a pdf given by this and it will take a few minutes to this prove this result  refer slide time  54  05  so  in this i just realized that in the statement of the theorem  this absolute value sign is missing  but that is important and i will show you why so ; that means  when y equal to when you are looking at the function g x of the random variable x and we are finding the pdf of y  then f y of small y is affects the pdf of x into at g inverse y and absolute value of d d y of g inverse y  when y is equals to g x and 0 if y is not equal to g x and of course  here what we are saying that the fourier 's values are not being consider because  when you take the inverse function to be here see it is monotone function  so the relationship between that means  this would be i do not have to worry about extra values here  so this will be fine  so now  let us look at the proof of the theorem  refer slide time  55  01  so  we start with the event that y is less than or equal to small y  which is equal to this and this i can write x less than or equal to g inverse y now because  the function is monotonically increasing so  this inequality from here  this inequality is the valid outcome because  it is increasing  so the inequality will not change a function g we have assumed is increasing function and therefore  this is equal to f x of g inverse y is it  so differentiate both sides with respect to small y then this f y y  which is d d y of this thing and in the step you get this is the pdf of capital y  which is here when the differentiate capital f x you get small f x so  that is g inverse of y into the derivative of this   refer time  55  55   and now here because  the function g is monotone  this gain a result from calculus you can show that positive derivative and f affects being the pdf of x this is non-negative  so the product is non-negative when therefore  this is non-negative  so this satisfies the condition and of course  you can verify that this is also valid pdf ; that means  the integral would be 1 and so this is it so  when you are taking the increasing function then because  the this part is nonnegative i do not have to put the bar sign here  but when g is decreasing  then you see  the probability the event g x less than or equal to y will the transform to x greater than or equal to g inverse y and that is what i am showing you that if this is the function g x  then you are saying g x less than or equal to y so  g x less than or equal to y  so beyond g inverse y are the values of which your function is less than y  in the function is decreasing and so the inequality here will reverse and that will be x greater than or equal to g inverse y and therefore  f y is 1 minus this you will write as 1 minus f x of g inverse y and then again differentiation of both sides will give you f by y  then minus f x g inverse y and derivative of this now  since g is a decreasing function  this derivative would be negative  so minus minus this will make it positive and that is why it is important that we write the absolute sign here because  your pdf can not be negative that is a first condition and which terms out to be because  when the function is decreasing his will be negative  so minus into this become non negative and so here again this would be positive so  this is for the completion sake that i wrote down this theorem  but normally what we do is we   refer time  50  00   you know do compute the pdf we write down the equivalent event  when you a function of a random variable and then of course  differentiating both the sides you try to get the pdf for the function of a random variable  but at times it also helps to be able to use the theorem  so this thing  refer slide time  58  22  now  let me just show you as i was saying that one can either obtain results directly or using the theorem so  if x is an exponentially distributed random variable with mean 1 by lambda  then you show that expectation of x e raise to k is k factorial upon lambda k  k varying from therefore  any finite value of k is what you had now  direct solution i am giving you  so solution 1 i should have said actually this is solution 1  which is a direct solution so  here because i know the pdf of x  so expectation x e raise to k will be 0 to infinity x e raise to k lambda e raise to minus lambda x t x remember we are told that the mean is 1 by lambda  so the parameter the distribution would be lambda e raise to minus lambda x t x and integration by parts treating this is the first function so  the lambda lambda cancels minus e raise to minus why i am writing t here will be lambda x into x rise to k 0 to infinity plus minus and minus sign makes it plus 0 to infinity e raises to minus lambda x and then x rise to k minus 1 d x into k so  you see this integral will come out to be this and then i again multiply and divide by lambda so  then this become my regular gamma functions  so one upon lambda  so this is we i k minus 1 into k by lambda  this integral because  when i differentiate this  this k will come out all the k should have been there  you have differentiated x k  so k is already there k is here so  that k i am writing k by lambda and then this integral is your i k minus 1  our i k was lambda e raise to minus lambda x x rises to k and d x integral from 0 to infinity so  now  this integral light denote by i k minus 1 and therefore  you expected value of x k as you go on doing it by iteratively here of course  k is a positive integer so  this is k factorial upon lambda k into i 0 finally  right if i go doing it repeatedly  so this becomes then for if i write down for i 0  this will be k factorial upon lambda k integral 0 to infinite lambda e raise to minus lambda x d x  which turns out with this  this integral is one because  anyway you know that this pdf of an exponential distribution with the parameter lambda so  therefore  this integral is 1 are you can directly show that this is 1 and therefore  this is the answer  now we want to use the theorem so  using the theorem that is you compute the pdf of the random variable x is to k ; that means  i compute the pdf of the function of the random variable and then through that root i try to compute the expected value so  if i define my y ’ s x rise to k that i am trying to compute y less than or equal to small y  which is probability x rise to k less than or equal to y  which is then x because  everything is non-negative so  therefore  the inequality will be converted to this that is x less than or equal to y rise to 1 by k and then f y y that is the pdf of y now will be f x of y rise to 1 by k into 1 by k y rise to 1 by k minus 1 because  this i will be writing this is as f x of y 1 by k right and so e y will therefore  be 0 to infinity y into f f y y d y which substitute for f y y in terms of f x so  this will be 0 to infinity y lambda e raise to minus lambda y e raise 1 by k 1 by k y rise to 1 by k minus 1 d y and  so e y is now here i can put y rise to 1 by k is s  so then 1 by k y rise to 1 by k minus 1 d y is d s so  this whole thing goes to d s and so i have now here s rise to k because  y will be s rise to k and lambda e raise minus lambda s t s and this is now we recognize that if i take divided by lambda rise to k and combine lambda here so  lambda s rise to k and so this your gamma pdf and therefore  did not pdf in sense that i must have here gamma k plus 1 so  therefore  this integral will therefore  be equal to this integral v equal to gamma of k plus 1 and then divided by lambda k so  that is another way of and since this is an integer k is an integer positive integer  so this will be k factorial upon lambda k  which we got here also  so you know whichever is convenient one can try to get the result either way introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  11 function of random variables moment generating function i will begin this lecture by discussing exercise is 4 with you  this is on random variables their pdf  cdf  and expectation  etcetera  refer slide time  00  19  so  let us look at question 1  consider the function f x given by c times 3 x minus x square  for x lying between 0 and 4 and 0  otherwise so  the question asked is could effects be a probability density function for any value of c  now without proceeding further we can just see that  since the function can be written as x times 3 minus x  so it will be negative for x greater than 3 and your interval is 0 to 4 so  density function and if the sign of c you might say that we can makes c negative  but then when x is equal to 2 say for example  then 3 x minus x square is positive so  in that case again c times 3 x minus x square will become negative  so in fact for no value of c is the current function pdf  because it is not non-negative for all values of x in the interval 0  4 now  we say that suppose we require the function to be a probability density function  when x is between 0 and 3  so that make sense  because then in the interval 0 to 3  3 x minus x square is non negative  so then c will be chosen as some number which is also non-negative  in fact positive and the condition they way you will obtain c would be you integrate the given function from 0 to 3 and then the integral must p is equal to 1  so therefore you can answer this question in this way the question 2 the probability density function of x  the life time of a certain type of electronic device measured in hours is given by  so f x is equal to 15 by x square x greater than or equal to 15 and 0  when x is less than or equal to 15 so that means the device is guarantee to run for more than 15 hours  now find probability x greater than 30  so again you can do it by finding out the c d f or integrating this function from 30 to infinity because  this is say 15 by x square is x greater than or equal to 15  what is the cumulative distribution function of x and what is the probability that 6 of such types of devices  at least that out of what is the probability that of 6 such types of devices at least 3 will function for at least 15 hours  what assumption are you making so  here of course  you see you will assume that the devices are independent of each other and then you will do the raise by finding out so  probability of 1 device functioning for more than 15 hours and then you have to say 3 out of 6  so you can understand what all you have to do  this will become a binomial probability  where the p will be the this integral for at least 15 hours so  will function for at least that 6 of such types of devices at least 3 will function for at least 15 hours  so it will be 15 and more so  i will leave it to you to do the rest  question 3 for a random variable y show that e y  the excepted value of y is 0 to infinity probability y greater than or equal to y d y minus 0 to infinity probability y less than minus y d y actually question 5 should precede question 3  in question 5 i am asking you to do the same thing for a non-negative random variable y  in that case the second part of the integral will not be there  because y less than minus y so  here in question 3  i am asking you to show that for a non-negative random variable y  e y is equal to 0 to infinity probability y greater than t d t so  once you show this then you can go to question 3 and do the rest  when y you can take positive negative values both  refer slide time  04  46  question 4  x is a random variable that takes on values between 0 and c that is probability x lying between 0 and c is 1  so show that variance x is less than or equal to c square by 4 so  i am just asking you to get an upper bound for the variance and you see the only information you have given is that  x lies between 0 in c  so all mass of this random variable is between 0 and c  refer slide time  05  15  now  there is a hint  one approach is to first argue that exception x square is less than or equal to c e x  you see this a non negative random variable  yes it should be said that because  0 less than equal to x less than c  so it imply that c is non-negative  therefore this in equality exception of x square is less than or in to c times e x  you see actually x square is less than or equal to c x  yes for all variance of x between 0 and c  because x is non negative and c is a non-negative number so  from their you get this inequality when you take the exception on either side of this inequality and then you show the rest  so i will not discuss second hint  there you should think and then get the answer question 5  we have already  now question 5 the second part is that you have to obtain exception x raise to n and show that it is equal to this 0 to infinity and x raise to n minus 1 probability x greater than x d x so  here again the hint is that you start with e raise to x n as 0 to because so therefore you write y equal to x n and then you will do this and then because of the substitution y is equal to x n  so d y will be n x n minus 1 d x and that is how you are getting this part  so this you should be able to do the question 6  the number of minutes of playing time of a certain high school basketball player in a randomly chosen games  so this should be player  so i have just cut the so  that means number minutes of playing times of a certain high school basketball player in a randomly chosen game  is a random variable whose probability density function is given in the following figure so  this is the graph of the p d f for the number minutes that a player in a basketball team gets actually to handle the ball in a sense  find the probability that the player plays over 15 minutes so  therefore  here as remember i have told you that this probability if you are saying that the player plays over 15 minutes  then you are asking for the probability x greater than or equal to 15 and so here you will integrate or you find out the see the 15 will be some way between 10 and 20  the height of the graph a different places so  the area to the right of 15 on the x axis  on the minute axis that area would be the probability that the player gets to spend more than 15 minutes on the field while playing the game then since similarly  between 20 and 35  so between 20 and 35 you the area  so this will be the area you can immediately find out just by looking at the graph  you do not have to do any integration or anything so then because any way you are this thing does not given to you the functional form of the p d f is not given so  just by looking at the graph you find out the area between 20 and 35 and that will be the probability  that the player gets that many minutes play between 20 and 35  less than 30 minutes same thing  so this will be this so  the area to the left of 30 will be the answer and more than 36 minutes it will be somewhere here  so to the right so  this we just illustrate that how when it is convenient  you can just look at the graph of the p d f and find out the required probabilities question 7  suppose that the travel time from your home to your office is normally distributed with mean 40 minutes and standard deviations seven minutes  so the time that you would spend in going from home to office is a normal distribution with 40 minutes as it is mean and standard deviation 7 if you want to be 95 percent certain that you will not be late for in office appointment at 1 pm  what is the latest time that you should leave home  so you have to read this problem at least 2 to 3 times and see the what we are asking is that you want to know the travel time  which you can be sure of the time 95 percent time that which you have to find the probability of reaching from home to the office  the time which will be possible for 95 percent of the time so  here that means  if x is the random variable denoting the time that you take from home to office  then x minus 40 and x you will say in minutes  so x minus 40 upon 7 will be the standard normal variant so now  you want to find out the probability that when this z is less than or equal to some number t is equal to 0.95  so from the tables you get the value of t so  corresponding value of x is 40 plus 7 into t minutes  thus starting time would be 40 plus 7 t minutes before 1 pm  then you are likely to be in the office 95 percent of the time in time that means  you will be in the office by 1 pm 95 percent of the time  so just read this problem carefully and then now  question 8  the median of a continues random variable this i have explain to you  that the median means that half of the area lives on one side  and the other half lives on the other side and now i want you to find out i think i have already done it for the normal distribution  i showed you that for a normal distribution x equal to mu is the median so  now  for uniformly distributed over a b and exponential with mean lambda  find out the median  so this i have discussed in the class if x has hazard rate function lambda x t  compute the hazard rate function of x of a x  a is the constant  where a is a positive constant so  you can apply the formula definition of the hazard rate function and get the answer  the lung cancer hazard rate of a t year old male smoker a t is such that this now  here i have discussed in the lecture  that if you are given the hazard rate function  then you can compute the c d f of the random variable and so assuming that a 40 year old male smokers survives all other hazards  so we are just considering the death  because of smoking what is a probability that he survives to age 50 to age 60 without contacting lung cancer so  i have discussed part of this problem with you in the lectures  he should be would do it now  finally  x is uniformly  no this is 11th problem  x is uniformly distributed over minus 1 and 1  so while discussing functions of random variables in the last lecture  i discusses this how you will handle probability mode x greater than half x is less than minus half and greater than half  then the density function of the random variable mode x  so this should be able to do it question 12  the number of years a radio functions is exponentially distributed with parameter lambda equal to 1 by 8  so that means the mean is 8  if jones buys a used radio  what is the probability that it will be working after an additional 8 years so  now remember this is an exponential distribution  it has the memory less property  so therefore you can answer question 12 also so  now i hope with all this hints you should be able to enjoy doing this exercise  refer slide time  13  18  so  let me now continue with in the last lecture i discussed functions of random variable  how you find out their c d f and p d f and p m f  now let us talk about expectation of function of random variable so  if x is discrete random variable with p x as it is p m f  then we define and g is some function real valued function i should have said that  g is a real valued function of x so  here g x is a real valued function of small x only  then expectation g x would be  because g x it is self will be a random variable  since x is a random variable  g x will be a random variable and so this is summation i  p x i  g x i  so let us see how we arrive at this form  see the thing is that you start with this summation then what i do is i group together all the x i ’ s for which the value of g x i is y j  because g may not be a single valued function  so here for all possible values of x i ’ s which give me the same value of g x i so  then i group this summation here  so i say j here and then i am summing over i where g x i is y j  so although g x i is get summed up here and then for all those g x i is y j  so then i will write y j here  that this summation goes over all i said the g x i is y j so  i am summing up all the probabilities p x i all x i for which d x i is y j and so this becomes summation y j and this probability is the add up  because the x i ’ s are discreet and distinct values so  therefore  you add up the probability  then that will give us over all i ’ s at the g x i is y j  so this becomes probability of g x is equal to y j of the even  this is a discreet case so  for all possible values of x i for which g x i is y j  so therefore this  this whole thing here is equivalent to this and so now  this becomes sigma j y j  so this is g x i equal to y j and then probability of g x equal to y j  so therefore by definition this is exception g x  so this is you are the way we definite for a discreet random variable so  the simple formula is this and i would try to validate it for you by manipulating the summation terms then in question 5  exercise 4 you have been ask to show i just discussed it with you  so we have been asked to show that acceptation x will be 0 to infinity  probability x greater than y  when x is a non-negative continues random variable so  here we are i am just writing out this expression for the case when x is a non-negative random variable  so now when i want to talk about expectation g x  i will do it for i will obtain this formula when g x is non-negative and then you should be able to take care of because remember question 3 is your general version  where x can be negative or positive both  so in that case g x can be also general function taking negative  positive values both  but once you understand this you will able to do that also for the general case so  i am doing it for g x non-negative  so expectation g x will be using this formula because g x is non-negative  so 0 infinity probability g x greater than y d y  this is i am using that question 5 of exercise 4 then here this  what i am doing is see therefore  see i have tried to show you the g x is this function  so now here i am separating out the integral what i am doing is for g x greater than y  i am integrating this f x d x so  suppose this your value y  then you are integrating this area  but then y varies from 0 to infinity  so that means from   refer time  1753   here  here  here  so the whole area this whole area and g x from 0 to infinity is being integrated here then i can always change the order of integration  i can no add the integrate in this way  so that means here it will be 0 to g x so  first of all from here i can come here 0 to infinity  then i from here i come x g x greater than 0  so here g x greater than 0  then i am integrating this way here in this way and then this is 0 to g x so  you are y  the integration respect to y is from 0 to g x and then g x is going from 0 to infinity when g x is greater than 0  i have drawn it this way it could be whatever it is g x  so you may start from here are your function may be like this it does not matter so  when you here the order of integration  first i was integrating respect to d x and now i have change the order of integration so  when i change the order of integration my y first varies from 0 to g x  so from 0 to g x d y and then my x varies from corresponding to g x positive  so this way so  therefore  i am taking this these lines and the lines corresponding to a fixed x will be from 0 to g x and then as x varies i am integrating along this lines  so this is how i am covering this area so  this is it now 0 to g x d y simply becomes g x and then this is integral x  so the g x is positive of a g x f x d x  last integral the competition has to be for all x such that g x is greater than 0  this is equal to this so  now it will be good if you can sit down and do it for a   refer time  19  54    that means you do it now for the negative part and then you can just add it up expectation for so  in other words  i am also telling you how to do you your problem 3  first do 5  then do 3 and then you can applied to get this results for the general function x g x  refer slide time  20  22  and so now  immediately you can write down that if you take a x plus b as a function of the random variable x and the expectation will be a is e raise to x plus b now  you can verify the writing the actual expression that means  you can write out this expression and then show that what you get will be a into expectation x plus b similarly  for the variance  see the expression is a x plus b minus a e x minus b whole square and b b cancels out  so you left with a square x minus e x whole square expectation of this then since a square being a constant comes out  this is a square expectation of x minus e x whole square and which is a square times variance x so  i just handled it for this  because this is very  we already use this formula in fact  so i thought let us formula is once we talk about expectations of random variables  then i talk about their expectations and so on  in the applications another interesting expectation of a function of a random variable is the moment generating function and this is a very very important because  in the since that sometimes it gives you extra information about all the information that you can sometimes get more easily here  if the moment generating function so  let us say the definition is that m x t is the expectation of e raise to t x and m x t i will write here is the moment generating function of x for all values of t  for which this exists and so some time ago i had shown you that  these need not all the time exist and so whenever for all values of t for which this exists we will say that this is the moment generating function of x so  t is a real number  so as t varies and sometimes for all values of t this may exist  but sometimes it may not exist for all values of t so  for the discreet case when x is a discreet random variable and p is it is p m f  then m x t will be expectation e raise to t x p x  because just now we note down the formula that for any function of random variable expectation g x is summation i p x i g x i  so i am applying this formula and therefore m x t for a discreet random variable would be summation e raise to t x into p x for all x  the summation is over all those x for which p x is positive  because otherwise their corresponding contribution here will be 0 then x a continues random variable with f x as it is p d f  then m x t will be minus infinity to infinity e raise to t x f x d x for all values of t for which t integral exist  this is the same thing it is only define  the moment generating function is define for those values of x for which the corresponding expectation exists  refer slide time  23  41  so  if i differentiate the expression for m x t  the moment generating function for x this is d v t of e e raise to t x and then i am taking the differentiation sign in side and this is easy explain  because in the discreet case since this expression for the moment generating function the summation is a convergent series  so therefore differentiation can be passed through the summation sign because  this is a convergent sum  so therefore of course  we are taking it for all values of t for which this is convergent so  in that case i can pass through the summation sign the differentiation sign  now if x is a continues random variable  then it is required this can be shown again  because it involves higher level mathematics  so i am not doing it here this is that if the moment generating function for x exists  for all values of t in the interval minus a comma a that means  this is some interval around value t is equal to 0 for sum a a real number if this exists then it can shown  that you can exchange the differentiation and integration sign so  in case your random variable x at is 5 these property that the moment generating function will exists for all values of t  in an interval around the origin  around the 0 then you can interchange the two signs and then therefore  when you differentiate you take the differentiation sign in sign  it will become expected value of x e raise to a t x  because you differentiating respect to t so  will write x here and the at t is equal to 0 you can see that m prime x 0 will be e x  which is the first moment and so on so  the first derivative of the moment generating function evaluated at the 0.0 is the first moment of x  the mean or the expected value of x and similarly  if you differentiate again then you will get x square here  expectation x square e raise to t x  so m double prime 0 that means  the second derivative evaluated at t is equal to 0 will be give you expectation x square which is the second moment so  in general the n th moment or the n th derivative of the moment generating function evaluated at t equal to 0 will give you the expectation of x raise to n and so once you have these moments therefore  you can make these thing that means  if you just compute the moment generating function  you can get the information about all the moments through this formula  refer slide time  26  29  so  let me now start applying the definition of the moment generating  function to special random variable that we have a gone through so far binomial random variable the expectation value of e raise to t x would be sigma r varying from 0 to n e raise to t r  because x takes the value r  so e raise to t r n c r p raise to r 1 minus p raise to n minus r this is the expression i will combine e raise to t r with p raise to r  so this becomes n c r p e raise to t whole thing raise to r in to 1 minus p raise to n minus r and this you can see is again binomial expansion of the expression p e raise to t plus 1 minus p raise to n and this exists for all values of t  because the expansion valid no matter what the value of t is  so this is and now you see what we are trying to say is that if you get an expression like 0.3 e raise to t plus 0.7 raise to n  if you given this as m g f and you can immediately say by looking at the form of the moment generating function  this is the moment generating function of binomial random variable with p as 0.3 and this is your n so  the two parameters you can immediately find out by looking at the moment generating function and if you differentiate this expression once  then see from here it will be n derivative of this p e raise to t  you should have said here e raise to t n p e raise to t  then e raise to t p plus 1 minus p raise to n minus 1 and so at t equal to 0 this number reduces to n p  which is the expectation of x  similarly if you differentiate this expression twice  this e raise to t is missing some were so  then it should have been sum of two  so will have to rewrite the expression here  so it will be see for example what i am doing is  so e raise to t is here  so i am differentiating this again  so this whole will be n minus 1 and p here  then e raise to t so  e raise to 2 t  because there is an e raise to t plus you will have to take the derivative of this  which will be n p e raise to t e raise t p plus 1 minus p and this whole thing raise to n minus 1  and in case when you compute this at the value t  then this becomes 1 so  you left to the n p and minus 1 p this also is equal to e raise to t is 1  so this is 1  1 raise to n minus 2 is 1  then here also the contribution would be n p  so is it so n p e raise to t so  the second moment i am getting as and then from here n into n minus 1 n square  so   refer time  29  54   this is not correct  so therefore this will be plus  so that means here when you put t is equal to 0 you are getting n into n minus 1 p square  this is ok and from here you will get another n p because  this is 1  this is 1 and the whole thing is 1  so this is plus n p  now it make sense  because you have a n p  so n square p square minus n square p square goes away  then minus n p square plus n p so  minus i should write out the  so minus n p square plus n p  which is n p into 1 minus p  so n p q this is the formula for the variance  so please be carefully when you are differentiating this expressions similarly  we can apply now  we can obtain the moment generating function for a poisson random variable and this will be expectation e raise to t n lambda raise to n into e raise to minus lambda upon n factorial and varying from 0 to infinity  here again i will couple e raise to t n with lambda so  this would be come lambda e raise to t n into e raise to minus lambda n factorial  so now this is what the value of the random variable that you taking  so at x is equal to n ; and this will be if you take e raise to minus lambda outside  this is the expansion of so  lambda e raise to t raise to n upon n factorial is the expansion of e raise to lambda e raise to t  so that expression where look a little complex  but handling them is not much of a problem so  here the whole thing adds up to  so therefore in this case also the series is convergent for all values of t and so that is i am saying define for all values of t and this can be rewritten has e raise to lambda e raise to t minus 1 so  if you differentiate  so here again say for example  if i get term  if i say that in m g f is say 3 e raise to t minus 1  then immediately by looking at this function  i will say that the corresponding random variable is a poisson random variable with mean 3 and m g f of a random variable x will characterize the probability distribution function of x  so even you differentiate this again  so let me go through the calculations  because they might be some error again so  first derivative of m with respect to t  here would be the derivative of this would be lambda e raise to t  so lambda e raise to t  when into e lambda e raise to t minus 1 and evaluated at t is equal to 0 that gives you lambda  which is expectation of x second order derivative  so their two terms now involving t  the first one the derivative is lambda e raise to t into e raise to lambda e raise to t minus 1 plus  the derivative of this would be lambda e raise to t lambda e raise to t and the same term here again evaluated at t is equal to 0  you get lambda from here and you get lambda square from here to this lambda plus lambda square so  variance is lambda plus lambda square minus lambda square  expectation of expectation x whole square  so therefore this is again lambda  so verification alternate ways of computing the same quantities exponential random variable with lambda as it is parameter  then this would be 0 to infinity lambda e raise to t x into e raise to minus lambda x t x and here  again i couple the terms the powers of e  refer slide time  33  59  so  i get so the moment generating function would be 0 to infinity lambda e raise to minus lambda minus t x t x  which i can rewrite as lambda upon lambda minus t integral 0 to infinity lambda minus t e raise to minus lambda minus t x t x and you can see that this integral is defined for all values of t less than lambda  because this exponent must be see this quantity must be negative  this quantity must be positive  so that minus of this is negative and then at infinity this will go to 0 and therefore  the integral is define only for lambda  for t less than lambda  for t greater than or equal to lambda the integral does not exists so  this is important to note and therefore  that is what i was saying  that the moment generative function need not exists for all values of t  we have to specify the values of t for which the integral exists  refer slide time  35  01  now  make the substitution to integrate this  you make the substitution y is equal to lambda minus t x  this gives you d y is lambda minus t d x and therefore  this integral transforms to lambda upon lambda minus t see here this lambda i wrote as lambda upon lambda minus t into lambda minus t  so to get it in the proper form so  then lambda minus t d x transforms to d y  this is d y and e raise to this thing is e minus y simple integral this this so  therefore  minus e raise to minus y 0 to infinity is lambda upon lambda minus t  m g f exists for t less than lambda and not t less than or equal to lambda  you can say that the corresponding random variable exponential with parameter lambda and if you do the simple verification here  derivative would be lambda upon lambda minus t whole square  they will be a minus sign with this  but then since this in the denominator another minus sign  and they both multiplied to be positive therefore  m prime x 0 is lambda upon lambda square which is equal to 1 upon lambda  now similarly you can compute the second order moment and then so  that is why you know that the name is very is just a moment generating function  this function generates the different moments for the probability density function normal distribution again it may look very compresum  but actually it is simple manipulation of the terms and you get the answer so  for a normal distribution the moment generating function would be  so 1 upon root 2 pi sigma minus infinity to infinity e raise to minus x minus mu whole square upon 2 sigma square plus t x  computing expectation of e raise to t x so  here i combine this in this square terms  so this becomes 2 sigma square x t  2 sigma square x t  so i collect the x terms  so the x terms are twice mu plus sigma square t plus sigma square now  i want to make a perfect square and the origin is obvious  so that the part of the integrant will add up to or integrate to 1  so you see to this i must have x minus mu minus sigma square t whole square so  therefore  i have added mu plus sigma square t whole square to make this perfect square  so therefore i must subtract  so minus mu plus sigma square t whole square and the mu square from here is determinant so  therefore  this is what you have  so this square plus mu square minus this  now if you simply this the mu square cancels out  your left with minus 2 mu sigma square t plus sigma 4 t f ’ s square so  this term i have written out here is this separated at out and this is the constant  because there is no function of x here  this is d x in fact  d x goes here and you see that this integral in that case  now this is p d f of a normal random variable where the mean is mu plus sigma square t not mu  but does not matter the other things remains the same so  this is the p d f of a normal mu plus sigma square t and sigma square the variance does not change this is under root of sigma square and this is 2 sigma square  so only the mean have shifted from mu to mu plus sigma square t and therefore this integrates to 1  the p d f of a standard normal variant this integrates to 1 and here  you left with just this part 2 sigma square t mu plus sigma square t square divided by 2 sigma square  so this is it so  when you cancel out the sigma square part you left here with mu t plus t square sigma square by 2  so a simple form here again and you can now differentiate this and that means  let just take the first derivative  what would be the first derivative this is t  so this is e mu t plus sigma square t square by 2 in to the derivative of this  which is mu plus twice  so sigma square t  so the t is equal to 0 this is 1 and this is mu so  the first derivative of the first mean  the first moment which is the mean i similarly differentiate at again and then find out the second order moment and the variance so  i think these illustrates quite well the concept of moment generating function and how you make use of it and of course  that it definitely characterizes the p d f ’ s  because by looking at the form of the m g f you can say what the distribution would be  and what would be the corresponding parameters then they still more interesting applications of the m g f  this is when i talk of jointly distributed random variables and then you can use of the concept of independents and so on so  the all these things get connected and i will try to show you the further properties of the m g f  refer slide time  40  50  so  let me now look at the moment generating function for the gamma random variable  so the expectation e raise to t x would be 0 infinity lambda e raise to minus lambda x lambda x raise to alpha minus 1 upon gamma alpha into e raise to t x d x so  again combine this thing and here you see t less than are equal to lambda  then only because this is the not define unless i mean the whole integral will become improper  if t is greater than lambda so  therefore  this integral will exists as along as t is less than or equal to lambda  so now you have the this expression so  again the trick is that i tried to manipulate the integral add  subtract  divide or multiply  so that i get in to a familiar form plus a constant into a constant  so here you see the parameter shifts of lambda to lambda minus t  so that is what i will do and that is not difficult  because this lambda i can write as lambda upon lambda minus t into lambda minus t so  this becomes my parameter here  this is e raise to minus lambda minus t x  now this lambda same thing i will do  i will replaced by lambda minus t and then divide lambda minus e raise to alpha minus 1 because  this is alpha minus 1 and the lambda raise to alpha minus 1 comes out  so you say this part is now independent of  this is independent of x  the remaining portion all these is now the integral of the p d f of a gamma distribution with the parameter lambda minus t and alpha so  instead of parameter being lambda it is now lambda minus t for any fix value of t and so the parameter will change as you  but given a value of t  then this will be integral of the p d f of a gamma distribution with parameter lambda minus t and alpha so  therefore  this whole integral this thing is equal to 1 and i am left with the term lambda upon lambda minus t raise to alpha and so this is your m g f  refer slide time  43  15  now  if you recall for an exponential distribution  the m g f is lambda upon lambda minus t  if lambda is the parameter  so what is turning out to be the exponential is gamma 1 comma lambda  that means the i been saying it out the other way so  alpha is the first  so that means here i want to say this is gamma alpha and lambda minus t  the alpha comes out to be the first parameter  this is the second so  then your exponential is 1  if you looking at gamma alpha lambda  then for alpha equal to 1 this becomes exponential lambda and here you see the  so therefore now through when i talked about jointly distributed random variables  sum of independent identically distributed random variables and so on  so there will be lot of inter connections at i would like to show so  essentially what we will be deriving here is that  first of all the result that if you have some of two independent random variable  then the m g f of the sum is the product of the corresponding m g f so  here you see applying that iteratively  it turns out that gamma alpha lambda is actually the sum of independent exponential distributed lambda variable  exponential distribution random variables each with parameter lambda  that means identically so  in case alpha is an integer  then gamma alpha lambda is some of alpha independent exponential random variables with parameter lambda  so this is what the result will be and therefore  that is what i am saying that you will be able to show these kind of things through the help of m g f  because here this is lambda upon lambda minus t raise to alpha  and this is alpha of the mu add and their independent then the m g f of the some of these alpha independent exponential random variables will be gamma distribution  because the m g f of this some would be the m g f here  which is alpha times this so  you multiply the corresponding m g f  when the variables are independent and then if you talking of the m g f of the sum so  we will develop this theory as soon as a talk of jointly distributed random variables  now just 2 questions before i finish this topic and this is x is a continues random variable with p d f x  show that expectation of absolute x minus a is minimized when a is equal to the medium so  we have defined the median for you and here  see what we are saying is this will actually come out to be a function of a write this expectation and therefore  you want to minimize that means  differentiae respect to a  the expression that you obtain for this expectation of absolute x minus a and then find out the critical value or the value at which this becomes minimum  so you will after show that it is the point at which the area under the curve is half now  i will just give you a hint  so expectation absolute x minus a would be absolute x minus a f x d x  which you can like either x is less than a or x is greater than a  for x less than a we will integrate from minus infinity to a so  then this will be a minus x f x d x  because the integrant has to be positive non-negatives  so this would be a minus x for x less than a and then a to infinity x minus a f x d x so  the idea that you differentiate with respect to a  now all of you have already done this much calculus you can integrate  so this will be when you have in differentiation and the integral sign  essentially you to apply that your limit is function of the i mean you are treating a as a variable now  because this whole thing is a function of a  so you can do this now  similarly just take an example  so let x be and mu sigma square  so x is normally distributed with parameters mu and sigma square and has m g f m t define psi t is log of m t  then show that psi double second order derivative of psi at 0 is variance x and so interesting function that you can define through your m t  we will also be talking of the characteristic function so  now  for example  m x t for a normal is this  so if you take log of this  which way we are calling as psi t  then this will be equal to mu t plus sigma square t square by 2 and so if you take psi prime t  this is mu plus sigma square t and then psi double prime t will be simply sigma square which is and therefore  this is also psi  because that is a constant so  the second order derivative of psi is a constant  so if psi square is 0 is also sigma square  so this is the answer and so one can go on i am doing lot of interesting thing with this  and i will be developing some more results here in the next lecture introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  12 jointly distributed random variables independent r.v and their sums  refer slide time  00  15  now  we going to talk about jointly distributed random variables see they may be events  which need to be describe by more than one random variable  so they may be the you know random phenomena concerned with the event or more than one dimension and therefore we need to be able to of course  then we from two dimensions we go to multi dimensions also  but right now to keep it simple  we will first talk about two dimensional random variables and then may be a extend the notion two  more than two so  if x and y are two random variables  we define their joint cumulative distribution function as follows  so probability f of x less than or equal to a comma y less than or equal to b is actually the probability that x is less than or equal to a and y less than or equal to b  a and b two real numbers between minus infinity and infinity so  essentially in this diagram  if this is b  then you are asking for y less than or equal to b and then x less than or  so it will be this whole region  if you can see this line and this line  so whole of r 2 extending from here to this end that will be a  so we are talking of the probability over this region then the moment did you find the joint cdf  a cumulative distribution function  then you can talk of the marginal cdf of a  so example for example  marginal cdf of x can be obtained from f  a  b  as follows  sorry this should be  a  b   the probability part comes here x less than or equal to a  y less than or equal to b  so therefore  from f  a  b  we can obtain the marginal cdf of x as follows  so this is the f x  a   which is probability x less than or equal to a so  this will be actually therefore  that means  this means that y is allowed to take any possible value  so therefore y probability x less than or equal to a and y less than infinity so  now let me just define it in a proper way in the sense that  this is also the same as b going to infinity so  limit that means  if i take the event x less than or equal to a  y less than or equal to b and then i take the limit  so you see what will happen as b goes to infinity  so x less than or equal to a  y less than or equal to b  you are talking of this  then when say b 1 when you talk of this y less than or equal to b 2  where b 2 is greater than b 1  then this is a bigger event this event is contained so  therefore  now you have a sequence of these events which are increasing  so increasing sequence of events b is goes to infinity and if you remember my definition of probability as a continuous function  continuous set function  so then in that case i told you that we can in that case extended  when you have a increasing sequence of sets  then when you are computing the probability you want to take the limit  then the probability of the limit is the limit of the probability so  therefore  i can take limit outside and this will be limit is b goes to infinity of the this event x less than or equal to a  y less than or equal to b so  we take the probability here and therefore  this will be limit and this is now your f  a  b  by definition  so this limit b going to infinity of f  a  b  and this will be then f  a  infinity   so f a and f  a  infinity  are the same similarly  if you want to compute the marginal of y  then will take the limit f  a  b  a go to infinity which will be f  infinity  b   so  exactly in the same way will argue out that the b remains the same and then a keeps increasing  so again you have increasing sequence of sets and so when you take the probability i can exchange the limit and the probability and get the answer so  now similarly you all to compute and then of course  you see the properties where we have defined for a cumulative distribution function must have for a single variable so  the same will apply and you can apply them to f x and f y  so through those you can get the property for the joint because of property that f x and f y possess combine them  when you can  then put together the properties that you are joint cumulative distribution function must have now  suppose you want to compute the probability of x greater than a and y greater b  so this we can write as 1 minus probability of the compliment of this event  which is x greater than a  y greater than b a compliment and then  since x and y are independent  in the sense that i can write this as now  this can be written as x less than or equal a union  y less than or equal to b  if you recall your de morgan 's law as so on so  then this will be 1 minus probability x less than or equal to a minus probability y less than or to b and then  you add probability x less than or equal to a  y less than or equal to p and this diagrammatically also you can immediately see that  this how from here we have to get here  because you are computing the probability x less than or equal to a and y less than or equal to b so  this will be you see x less than or equal to a would give you   refer time  06  23   this region  and y less than or equal to b will give you this region so  you see the region extending from here x less than a  y less than b is this region which you are have subtract it twice  because once when you do it for x less than a  probability x less than or equal to a so  it is this and then this region is coming into it  then when you subtract probability y less than or equal to b then again this whole region is coming and therefore  you add this again  so in words of your i should have written this that means  your so  therefore  i simply write this probability in terms of 1 minus f  x a  minus f  y b   so this will be equal to 1 minus f  x a  minus f  y b  plus f  a b   so  therefore  to make the equation correct i add this once and then  because i need to subtract only c i need this region  so the valid region that i require is this and therefore  from 1 i subtract this whole and so this got subtracted twice  therefore i add it once to make it proper  so this will be your that means  now one can compute whatever probabilities you want related to these two random variables  it can be done once we have made this definition  refer slide time  07  56  now  in general if x is lying in the interval a 1  a 2 and y in the interval b 1  b 2  then this can be written as f  a 2  b 2  plus f  a 1  b 1  minus f  a 1  b 2  minus f  a 2  b 1   so here again we will just simply diagrammatically look at the equality that we have here so  x is varying between a 1 and a 2 and y is varying between b 1 and b 2  then f a 2  b 2 is this whole area  in fact if it is only non negative variable then it is this region so  just assume for argument sake that this is both the variables are non negative  but otherwise it will extend to infinity and this will full extend to infinity so  anyway because this is f a 2  b 2 is probability x less than a 2 and y less than b 2  so in the case of non negative variables this is the total region  then f  a 1  b 1  is this   refer time  09  12   region  let me this here then f  a 1  b 2  is this whole thing and f  a 2  b 1  is this region here  so you see that here you are subtracting this region twice and in this a 2  b 2 you are adding it and then you are adding this  so that gets cancelled out and this region also gets cancelled out so  from the whole of f  a 2  b 2  you are finally  left with this particular region  this is the idea i am equating the probability with the area in a sense and that is what i am trying to explain so  if you this picture in mind and you can always make the right competition  refer slide time  10  08  now  in case x and y are discrete random variables  they joint mass function can be written easily because here you are simply wanting to compute these probabilities probability x equal to a y equal to b is p  a  b  this is how we will define so  if we can compute this probability  then that is the probability a  b and this for all possible values  if the appears a  b taken by x  y and then  we can also compute the marginal probability mass function of x  which will be simply probability x equal to a and this will be your summing these probabilities over  so fix the x at a and then summing it over all possible values of y so  your summing up p  a  y  for all possible values of y that will give you the probability that x attains the value a  because here the value poison is not is a material  therefore you submit of over all possible values that y will take  similarly p y  b  will be summing up this probabilities x  b when p x  b  is positive so  in this case you want to sum up overall possible values of x to get the probability that y will take the value b  and we will go through an example here so  let us consider this 3 balls are randomly selected from an earn containing 2 red  3 white  4 blue balls  so the total number of balls is 9 and now you want to find the joint distribution function of x and y  when where 3 balls are chosen from the earn and x represents number of red balls and y number of so  i pick up the 3 balls from the earn  then i note the number of red balls present in those 3 balls earn and the number of white balls  so now we want to write down the joint mass distribution function for x and y  refer slide time  12  36  so  let us now continue with the example with which they were the earn contains 2 red balls  3 white and 4 blue  total number of balls is 9 so you want to compute the cumulative mass function for the variables x  y  where x is the number of red balls and y is the number of white balls  when you pick up 3 balls from the earn so  i will just compute a few words  then you can try to complete the table i think maybe i have completed it already so  when you want to compute the probability of  0  0  that means  x is equal to 0 and y 0  so which is no red ball and no white ball  so that means all the 3 balls that you pick up from the earn must be blue so  the probability of all 3 balls being blue is 4 c 3 and total number of ways in which you can pick up 3 balls from 9 balls is 9 choose 3 and so this number comes out to be 1 upon 21  which is here ; then i should have computed p  0  1  and i think i have written it here as  so it is this number is actually  so it is got mixed up so  this is 1 by 7  so that is probability 1  0 is 1 by 7  so if you want to compute have i done it somewhere here  no so therefore let us just quickly compute this number p  0  1   so   0  1  is a probability no red ball and 1 white ball  so this will be no red ball that means  1 pi white balls in 2 blue balls  so blue is 4 c 2 and 1 white out of 3  so this is 3 choose 1 divided by 9 choose 3 so  let us quickly compute this should be 6 3 and then  from here you will get a 6 and this will be 9 into 8 into 7  so 6 3 's are 18 and this will be twice  twice 4  then 2 and 3  so this is 3 by 14  so 3 by 14 is this i have  so 3 by 14 is this number and this way i have it some computation where 0  2 you have to compute and so on  so i will shown you some computations here p  1  2   then p  1  0   p  1  1  we have computed and so you go on so  now the whole ideas is that once you have completed this  then as i was saying that if you want the marginal distribution for x then  so for example if you are looking for the probability let me just take it from here  refer slide time  15  40  so  if you add up the numbers here  this is what probability x equal to 0 when you are giving values to 0  1  2 and 3  in other words you are adding up probability  let me write it as  0  0  plus probability  0  1  plus probability  0  2  plus probability  0  3   so they can be 3 white balls  because total number of white balls is 3 so  all this will give you the probability at x is equal to 0  because when you pick up the 3 balls if it does not contain any red balls  then those 3 balls will either contain 1 white ball  2 white balls or 3 white balls so  all these probabilities add up to the probability x equal to 0 and so this will be quite similarly  when you add up the second row that will give you probability x equal to 1  said third row will give you probability x equal to 2 and this be probability x in to 3  but since this is all 0  because there are no then number of red balls is only 2  so you can not have number of red balls in the sample that you pick up as equal to 3 so  therefore  this is all zeros  similarly here you can not have the combination  3  3   because you are picking up only 3 balls and similarly  3  2   3  1  is also not possible from here  2  2  and  2  3  is also not possible so  these are the only numbers and you see this now finally  because this is probability x equal to 0  probability x equal to 1  probability x equal to 2  which are all the possible values that x can take in your sample of 3 balls  because there only at most 2 white balls that can appear in a sample so  this must add up to 1 and similarly  see when i add up these probabilities this will be give me the probability of y is equal to 0 that means  there is no white ball in the sample  when you add up these numbers this will give you the probability that y is equal to 1 and similarly this so  all these four when you add up that should also add up to 1 and that will give you good checks  so again at means when we are defining the marginal pdf and so on  then we must continue to check the validity and so make sure that your calculations are ok  because otherwise you will know that you have made a mistakes somewhere  so you can go back and check so  all these numbers  so the numbers here will give you the marginal distribution of y  here the numbers will be marginal distribution of x and so on  so this how you write down the joint probability distribution of two random variables  refer slide time  18  45  now  take another example  so that i want to make sure that you understand how the calculations are being done now  this is an example in which there is a community  in which 15 percent of the families have no children  20 percent of the families have 1 child  then 35 percent of the families have 2 children and 30 percent have 3 children now  the probability of they are the children being a boy or a girl is same  that means it is half half  so once you pick up a family at random so  the experiment that we are doing here is let you pick up a family from the at random that means  any family is equally likely  then you want to find out the number of boys and girls in that family so  both of them are random variables that means  number of boys in the family and the number of girls in the family  this family that you have picked up at random so  here again let us see i have made few calculations  so if you want to compute p  0  0  then that means  no children  so of course this is straight forward you know that 15 percent of the families have no children  so this is simply 1.5  so which we write here then when you want to compute p  0  1  that means  no boy just 1 girl  so this is the event probability of 1 girl child  now i write this as a conditional probability is saying that probability 1 child into probability 1 girl given that there is 1 child in the family so  that will come out to be 0.20 in to half  because there is only 1 child in the family  p  0  1   so that means  only 1 girl and no boys  so this total number of children in the family is 1  so that probability is 0.20 then it being a girl or a boy the probability is the same  therefore it will be in to half  so that is 0.10 that is a number you enter here and similarly  if you want to compute p  0  2   then it will be 2 children and so i am writing the conditional straight away  so 2 children probability of that and then  2 girls given their 2 children so  this is 0.35 from here  families having 2 children that is 0.35 and then 2 girls  so 1 by 2 in to 1 by 2  so divide it by 4 and so that is 0.875 then when you want to compute i have done it here  it is not very this thing  but any way it is coming maybe i can just show the calculation in a better way  so when you we want to have a  0  3  that means  all the children are girls so  this again will be probability 3 children which is 0.30 when into 1 by 8  because all the 3 are girls  so 1 by 2 raise to 3 and therefore  you divide this by 8  so this is 0.0  then 3 will be 24 then 6  then 8 7 ' s are 56 and then  40 and 8 5 ' s 40  so 0.0375 so  when you add up this numbers this will here will be the probability that x is 0 that means  no probability when you pick up a family at random from the community  there are no boys in that family so  that number will come out to be this you can add it up  similarly this will give the probability at x is equal to 1 that means  1 boy in the family  probability x equal to 2 and this will be probability x equal to 3 i am here also you can see that this these combinations and of course  because the boys and girls are equally likely  so the tables once you have computed this part  then this is symmetric  because whether having a 1 1 when you have 2 children  so it is whether girl or boy is same  therefore this will be the same then 1 2 see this one we are having    refer time  23  06   this is 2 0  i am sorry 0 1 and 1 0  so that was a number  then this number for example  2 1 and 1 2  so this two numbers so  this is symmetric  because boys and girls are equally likely  similarly here whether all the 3 children in the family are boys or all the 3 children or girls  the probability must be the  so i am sorry this should be 0.375  so make that corrections  so this will 0.0375 and then again as we had said when you add up all these probabilities  they should add up to 1 and here also you will get the marginal ’ s  so this will be probability y equal to 0  probability y equal to 1  probability y equal to 2 and probability y equal to 3 so  i would like you to complete the tables  i have made some computations for you this so this is the same  now you have to make just these two computations and then you can complete the table so  this gives should give you an ideas to how to go about computing joint  if i when the variables are discrete  how to compute the joint distribution function for discrete random variables  refer slide time  24  25  so  let us continue with the jointly distributed random variables  suppose x and y are continuous  so i will now define in other way in the sense at now i will define this through your joint pdf and so we are saying that if there exist a function f  x  y  real valued function  which is defined for real x and y having the property that for every set c a subset of r 2 that means  all the pairs of values  which are there in c  then  x  y  belonging to c that means  you see the convention is this a pair of co-ordinates  then the first value is for x  and the second value is for y so  then probability  x  y  belongs to c is this  so now this is different from the way we define the cumulative distribution function right in the beginning  so of course two will must to the same thing so we have the probability should be f  x  y  d x d y for it continuously distributed  a jointly distributed continuous random variable so  f  x  y  is called the joint pdf of x  y and if a and b are two subsets in r square  then probability that x belongs to a and y belongs to b will be integration over a with respect to d x and actually see one should make a convention that this must refer to the later one here so  i should have said this is d y and d x  because just a convention  so therefore when you writing the limits  range  then it is nice to remember that this one refers to the second integral and this is the first  so the order has to be maintained so  therefore  this is a b  so i should written d y d x of f  x  y   so the same thing is being on the sort of repeated and therefore  if your f  a  b  as we defined earlier is now x lying between minus infinity in a  y lying between minus infinity and b ; then the partial derivatives here delta square delta a delta b f  a  b  will be f  x  y   a  b   so  this is the relationship between the cumulative joint cumulative distribution function and joint pdf and then of course  the marginal distributions here  so this will be x belonging to a and y is from minus infinity to infinity so  in that case your integrating with respect to y from minus infinity to infinity and this integral  when you integrating with respect to y will be the marginal just as i showed you in the discrete case  that you add up for all the possible values of y to get the marginal and the probability of x for a certain value so  same here  the marginal respect to x will be you integrate the joint pdf from minus infinity to infinity and for the marginal of y the pdf of marginal y  this would be integrating respect to x from minus infinity to infinity then of course  depending on whatever the region of actual definition else  now let us just take up this example so  if you have this function define here  which is define for all values of x is from 0 to infinity and for all values of y from 0 to infinity  and it is 0 otherwise  so it is in the first quadrant that the function is defined  refer slide time  28  04  then verify that this is joint pdf  so therefore the total integral from 0 to infinity and this should be 1  so suppose i just integrate respect to y first  so the integral is minus e just to minus y from 0 to infinity that gives you 1  because at infinity this is 0  at 0 this is plus 1 so then this is this now you integrate this respect to x  so x is minus 3 upon 3 e just to minus 3 x going from 0 to infinity  which is equal to 1 now if you want to compute this particular probability  then your limits will be so  this time have taken care of the order  so this is 2 to infinity for x and for y it is from 0 to 1 and so again the same integral you do it respect to y first  take the limits and then this is 1 minus e just to minus 1  then you integrate this respect to x and this will be  so the final answer will be this   refer time  29  08    and so you can go on so  this is nothing new except that your dimension has increased and the same concepts are there  the same axiom will be followed and so we will now continue developing this theory and then  talk of independent random variables  jointly distributed independent random variables  then we will talk of some of random variables so  of course the thing is let this concept can be extended to more than two and expect that the writing part is in little tds  but the same thing will follow  refer slide time  29  44  so  i will just revisit this  i had shown you this probability try to computing this probability  i had drawn the diagrams  so let me just make it more clear  because i had a feeling that i did not do a very good job last time so  let us see probability x greater than a and y greater than b  then if this is my origin this is x equal to a  this is y equal to b  then this is the area that you want to compute the probability on  your region x greater than a  y greater than b is this event represented by this area so  now we said we will write it as x less than or equal to a  so x less than or equal to a is this whole area  extending on this side the whole area and then  y less than or equal to b will be this area so  therefore  all this and all this gets covered and you see this area the area that is x less than a  y less than b this is  so this portion because when you are covering x less than a  then it is all of this y less than b then it is all this so  therefore  x less than a  y less than b this particular area gets covered twice  so you and here and therefore  you get this so  therefore  1 minus of all this  that means if i write a probability x less than or a plus probability y less than or equal to b minus this  then i will get the region corresponding to this and therefore  so 1 minus of that and that will be the probability for this so  just wanted to revisit this thing and here also in the other example that we had taken  we would talking of a community in which there are families and they were probabilities associated with families having no children  1 child  2 children and 3 children so  i thought that though i asked you to compute add compute it is some probabilities for you and i asked you to compute the remaining one  but i realize that probably you need a little more working out and the so i thought i will give you the hints here for example  when you computing  1  1   then it is the probability 2 children into a conditional probability that it is either a boy girl or girl boy you see when you are saying 1  1 so then it can be  the first child is boy and the second is girl or the first child is a girl and the second child is a boy so  therefore  this will be 0.35 into  because a probability of families having 2 children is 0.35  then into actually boy girl will be 1 by 4  because each of them are equally likely what since they had two possible cases  so 2 into 1 by 4 therefore this is half  and so this number comes out to be 1 1  this is 0.175 now  for 1 2 when you want 1 boy and 2 girls  then that means the 3 children  so the probability of having 3 children is 0.3  30 percent of the families have 3 children  so this is 0.3 and the conditional probability of having a boy and 2 girls and then  with 3 children  having 3 children and then  1 boy and 2 girls so  now here again you need to say that see it could be the first child who is the boy other two are girls  then it is first girl  then boy  then girl and girl girl and boy  so these three possibilities are for there  therefore it become 3 by 8 because  each of them is half  so then when you have these three possible cases favorable for your event  then this is 3 by 8  so 0.3 into 3 by 8 that comes out to be 0.1125 and at the rest we had computed and then these are the marginal  so that means this i told you is probability x equal to or b equal to 0 and probability b equal to 1  probability b equal to 2 and probability b equal to 3 hence similarly here  this is the marginal for probability girl is 0  no girl in the family of course  so probability no there is 1 girl in the family  2 girls and 3 girls and then  you see that this adds up to 1 because  they are marginal pdf ' s are probability mass functions and so so once you find out the joint  then you find out the marginal 's and then you can do all other competitions that are required the expectation  variance and everything you can compute as we have done it for you like even for the joint also you can do it  expectation  x  y  you will do it and so you will multiply that i think i have given you the expression p  x  y  this we worked it out this into your values that x and y takes imply y is positive and so on  refer slide time  35  10  now  i will continue with some more examples of the continuous random variable  so here let us see you take a circle of radius r and let us say it centered at the origin  so the equation of the circle is x square plus y square equal to r square so  when you are taking the inside of this circle then it is less than or equal to r square  so this is the circle given to you  and we just pick a point and inside the circle  then that is a random because and we are saying that all points are equally likely to be picked up  inside the circle then let x represent the x co ordinate of the point that you are picked up y is the  capital y represents the y coordinate  so now both x and y are random variables and since any point in the circle is equally likely  therefore it will be a constant the pdf of  x  y  that joint pdf of  x  y  will be a constant inside the circle and 0 outside and this is an example of a two dimensional  two variable uniform distribution  so this represents uniform distribution  because any point in the region in on the circle is equally likely and then  now you want to find out the value of c  so we will have to say that this must integrate to 1  the whole thing and since this is simply minus infinity to infinity and minus infinity infinite d x d y  this is an element of area so  when you integrate over the whole of this circle you will get the area of the circle by everybody  so this is you have already done it in your class 12 and so on so  then c into pi r square is equal to 1  therefore your constant is 1 upon pi r square which is expected  one dimensional also i have told you that when you had uniform random variable this was the length of the so  if this was point a this was b  then the probability density function for this uniform random variable was 1 upon b minus a  which is 1 upon length of the interval in which the random variable is defined here the pair  x  y  is defined inside the circle when it is uniformly distributed this pale and that means  that the pdf must be 1 by pi r square  the area of the region  in this case it is the area of the circle now  you want to compute the marginal of x  and marginal pdf of x and marginal pdf of y  so for x you will integrate from minus infinity to infinity f  x  y  d y and this what i want to point out that is  so you are fixed value of x  if you are fixed the value of x  then how does a y vary  y varies along this card and the length of the card is because this length is x  this is r the radius of the circle  so this length is under root r square minus x square so  therefore  this point has the co-ordinates x  under root r square minus x square and this point has co-ordinates x  minus under root r square minus x square so  your y varies from minus under root r square minus x square  2 under root r square minus x square  so this is it this reduce  because there is no other   refer time  38   outside this  so this is c into d y and this c is 1 by pi r square  so this becomes twice under root r square minus x square and this is defined for all x between minus r and r  because your x varies from this point to this point along this  and see your x various along this  your y varies along this  so the whole circle gets covered similarly  because the symmetry  so your marginal of y will be twice under root r square minus y square upon pi r square  where again y varies  this got next step  this is minus r less than or equal to y  less than or equal to r  0 otherwise now  suppose you want to find out the distribution of random variable d  which is the distance of the point from the origin  so this is under root x square plus y square so  you take any point here and then  this is the distance length would be under root of x square plus y square so  we find out the distribution function of d which will be f d  r   so that means  probability d less than or equal to r  now since everything is nonnegative  distance is a non negative number  r is non negative so  this event is the same as squaring up both the sides that means  x square plus y square less than or equal to r square  the two events are the same and again by the same argument that for x square plus y square less than or r square  so all points inside the circle having radius r  all these points will satisfy this or define this event  every point inside the circle of radius small r and therefore  the area here is pi r square small r square and divide it by the pdf  which is pie r square  so you can you know want you can do it from by integrating in everything but  this is a straight forward because everything is uniformly distributed  so therefore  the probability of a point lying inside the circle small r is pi r square just as we said that the you know ; that means  this is the area  which is favorable to our event and then the density of the function is of the 2 pair is 1 up on pi square r square so  therefore  the probability the distributional of function of d is r square up on capital r square  so now  if you want to find out the pdf of d would be did differentiating this respect to small r so  2 r up on r square and small r varying from 0 to capital r because now d is a non negative random variable and the value of d will vary from 0 to r because  the point is here  then this way and this way  so you can go up to capital r and similarly we can find out the expectation of d  which will be 2 by 3 r so  you now geometry helps  you draw pictures  then you can you know get a good idea is to how to go about solving a problem so  and the moment you have more than one  you know if you consider a pair of random variables and you can see that the complexity will increase the moment to consider higher dimension you know ; that means  3 random variables together joint density function of three but  and as i go long i will try to solve some more problems relating to two random variables joint distributions of two random variables  refer slide time  42  43  so  another example on joint distribution of random variables  suppose f x y is a function given like 6 by 7 x square plus x y by 2  x is between 0 and 1 and y is between 0 and 2 so  then you want to verify this represents a pdf of the variables x y  so i just integrate from as 0 to 1 and 0 to 2 and the working out shows that this x square y plus x y square by 2  if your differentiating with respect to y because  i have written the limits with respect to y first 0 to 2  so let us integrate respect to y first and therefore  this is what you get and then you this you look at this  then integration respect to x 0 to 1 so  that will give you this function and finally  you get the integral to be equal to 1  so therefore  the function does represent because it is a non negative function  since x and y are both non negative so  this is a non negative function  the integral in the defined the specified area integrates to 1  so it represents pdf  now to compute the marginal the pdf of x or the marginal of x  you see i have already done it here because  you have to integrate this integral from 0 to 2 d y  so this integral gives me the marginal of x so  therefore  this is 2 x square plus x 0 less than or equal to x less than or equal to 1 and you see that if i now integrate this from 0 to 1  it will give me the answer 1 and hence this is also a pdf it is non-negative  in the specified region and of course  and i should also say 0  otherwise it is very important that here definition of the pdf ’ s must be complete in the sense that you must specify the region on which it is defined so  here it is in between x 0 and 1 this is the pdf is defined by this function and it is 0 otherwise  then you are asked to compute x greater than y so  if you have to compute x greater than y  then see i have written down this the line with represents x equal to y  so this is that region over which you want to compute this probability because you have specify the event so  then it will be see here  if you are integrating with respect to x then you fix a y ; that means  when i am integrating respect to x by x is varying  so y is fixed so  when you fix a y in this region how will your x vary from y to 1 because this represents 1 here is this line so ; that means  you are integrating from here to here for a fixed y and as y changes from 0 to 1  you will cover the whole area like this  so therefore  range for a variable x is from y to 1 and y varies from 0 to 1 so  this is very important and again i will keep a repeating this that draw the diagram you can two dimensions you can always do it and then you get a feeling for how the what are the ranges of a integration and  so on so  integration respect to x gives me a x square x cube by 3 plus x square y by 4 from y to 1 and that is important because i must integrate respect to x first  since limits for x are in terms of y so  then i will first integrate with respect to x and then that function as a function of y and then i integrate with respect to y  so this has to be the order you must keep this in mind and so finally  this comes out to be 15 upon 56  so the arithmetic should be correct  now here what i was saying is that suppose you had to compute the event probability y greater than x so  in that case you see what will happen is it is this region  which you have to do it  so then you see you will have to break it up in to or what you can do is may be now it is not necessary because  then if y is greater than x  you will want to write the limits ; that means  for a given x how will a y vary  that is no problem  so y will vary from here to here ; that means  it will vary from x to 2 so  i will integrate respect to ; that means  if y is varying from x to 2  so we will have to integrate respect to y here  so the limits would be x to 2 and then x varies from 0 to 1 so  this will give you this probability  if you integrate first with respect to y x to 2 the same function and then you integrate with respect to x because for a given x so  this how when you have the diagram you can immediately see that given value of x  the corresponding value of y can range from x to 2  then that is it you can compute this  refer slide time  48  27  now  just look at another example  and maybe we do not need to compute it fully  but i will give an idea here  this is f x y is defined as c into y square minus x square into e rise to minus y  now the limits for x are from minus y to y and y varies from 0 to infinity so  therefore  to draw the diagrams see what i have said is that  when y is fixed then my x is varying from minus y to y so  it has to be between the lines  this is x equal to y and this is x equal to minus y or minus x equal to y whatever whichever way so  this is this  and this is this line  so you are x is in between these two lines and your y varies from 0 to infinity so  it is this region extending to infinity  this is the region and  so once you know this  then there is no problem because anyway you was first want to find out the value of c so  find value of c sorry that this defines a pdf  so then you can integrate and you see with the what will happen is that you come up to here  now this is y cube a is to minus y so  you will have to you know do integration by parts and it will have to be done 3 times because you know you this will be a first function this is second so  you will have to in the first iteration you will get y square  then you will have to do it again to get y and then get rid of the y so  therefore  it will be 3 times you will have to repeatedly apply integration by parts to get the value of c  so that this integral finally  has to be equal to 1 and this so  once you have the diagram in front you  you can not go wrong you  you can always find out the correct limits  and then decide how to you know like what i was doing is i was dividing the region in a certain way to do the integration  which you have already done in your while you would doing your calculus course introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  13 independent r v and their sums i will start by talking about independence of random variables  when they are jointly distributed  refer slide time  00  23  so  just again an extension of the same concept that we talked about for single random variables  now here one can write it in two  three ways  x belongs to a and y belongs to b  so their two subsets a b of the real line and then a probability this should be equal to probability x belonging to a into to probability y belonging to b  and this should hold for all possible subsets a  b of r now  in other words if the events  so another way of saying is that this event and this event are independent for all a  b subsets of r another way of saying it then an equivalent definition of independence of x  y would be that you now allow you take real numbers a  b and then you are saying that x is less than or equal to a  y is less than or equal to b is equal to probability x less than or equal to a in to  this should hold for all and b and this is if and only if this or you  then by using the 3 axioms you can show that this and this are the same definitions that you can  then can take to real numbers and you can describe your events in that way so  this will immediately employ that you are distribution function  cumulative distribution function for the joint cumulative distribution function can be written as a product of the individual cumulative distribution functions now  if x and y are discrete  then we say that we can equivalent way of writing it is or this is how we can p x  y is p x  x  into p y  y  that means  individual probabilities for all x  y and surely this definition and this definition are the same  because this is the general one which covers both continuous and discrete now  if you just can take a as single term x and b as the single term y  then this follow from here  because x equal to a  so a  b that means x  y  if a is simply a single term  b is also single term y  then this becomes x  y and this is probability x into probability y of course  with respect to x and respect to y so  i mean two follows from one  when you choose the sets a  b to be single terms and the other way it is valid  because if star is valid for all x  y ; then you can you can write this definition as the first part of star as summation p x y  x belonging to a y belonging to p that is our definition but  since this is x and y are said to be independent  then this can be written as p x  x  into p y  y   where x summing over all x ’ s in a and summing overall y in b  then you can separate out the summations you can write out this way and therefore  this is probability x equal to i did not … so  probability x belonging to a into probability y belonging to b  which is the same as this  so if this is valid star follows and if star is valid  then double star follows  so this is whole idea  refer slide time  04  05  now  and of course  in equivalent condition for this  for the continuous case would be  that the joint pdf  can be written as the product of the individual pdf  so now you have so many equivalent ways of expressing the same concept i will take this example function sheldon 's law  a interesting to again show the computations and the how we make use of independence of random variables so  here a man and a women decide to meet at a certain location  if each person in dependently arrives at a time which is uniformly distributed between 12 noon and 1 pm so  they arrival time of both of them is a random  i mean for the man and the women both are random variables and this is the time is between 12 noon and 1 pm  now you have to find the probability that the first who arrive has to wait longer than 10 minutes  so therefore that is why i converted the pdf as 1 by 60 for each x and so  here let me define the random variable x as time and minutes past 12 noon when the man arrives and similarly  time in minutes past 12 noon when the women arrives at the fix part  so both are random variables and they uniformly distributed between 0 and 60  so that means the pdf will be 1 by 60 for each  so when you take the joint pdf that will be 1 by 60 square ; and will say that x and y bit vary between 0 and 60 so  the probability that you are asking for is x is the probability for the man to arrive  so if the man arrives first then x plus 10 should be less than or equal to y that means  this is the time when the women arrives so  the man has to wait because he is the first to arrive he has to wait for longer than 10  that is probability x plus 10 less than y  but since x and y are continuous random variables computation of the required probabilities alright and similarly  if the women arrives first then y plus 10 should be less than or equal to x  but since x and y are identically distributed independent assumes so  therefore  the two events are the same  so that means  the probability will be exactly the same from symmetry so  twice probability x plus 10 less than or equal to y  this what we have to compute and so you write down the limits you see for x  for x the limits are 0 to y minus 10  x is less than or equal to y minus 10 and x varies from because the arrival  the man can arrive at 12 noon itself  so x will be 0 so  x actually varies from 0 to 60  so here it is 0 to y minus 10 and the women can arrive has to  because the man has to wait 10 minutes or more  then it should be 10 to 60 ; so the arrival time of the women would from 10 to 60  so this is what is important so  once you fix the limits and the joint pdf  then computing the probabilities is not a problem  so one has to spend time in just thinking as to how to event is described very clearly so  here the limits for y for the women arrival time would be have to from 10 to 60 and this is from 0 to y minus 10 here  so therefore you integrate respect to x and they simply x  so y minus 10 by this thing and then when you integrate respect to y it will be y square by 2 minus 10 y  from 10 to 60  so this will be 2 by 60 square and this would be 1 by 2 60 square minus 10 square and then minus 10 into 60   refer time  08  27   so  we will continue from here  this was y square by 2 minus 10 y from 10 to 60  so then this becomes 60 square minus 10 square  this one by 2 and minus 10 into 60 plus 10 into  this 10 into 10  so when you compute this form 10 to 60 so  this is minus 10 into 60 plus 10 into 10 and so when you simplify the numbers this here  this would become 2500 upon 60 square and this is 25 by 36 so  desired probability is this much that means  who ever arrives first at the meeting place will have to wait for more than 10 minutes  the probability of that is 20 upon 36  refer slide time  09  25  so  let me continue with the with examples of jointly distributed independent random variables  now is the interesting examples  it is called the buffon 's needle problem  buffon was a french naturalist and so he formulated this problem it is say that table has parallel lines drawn on it and the distance between two consecutive parallel lines is d  now you drop a needle on the table and of course  one possibility is that the needle lies like this  so it does not intersect one of the lines  but suppose it does intersect one of the lines  so that is what we have to find out so  a needle of length capital l  where l is less than or equal to d  the distance between two consecutive parallel lines is randomly thrown on the table  what is the probability that the needle will intersect one of the lines  so we have to compute this probability and now here i would drawn this diagram  so this is the needle at b is the middle point of the needle and you drop a perpendicular form here to the nearest line  so that is x  so that will be a random variable  because you do not know the position so  that mean the two random variables that describe the position of the needle is the distance of the centre of the needle from the closest dearest line and the angle it makes with the nearest line  so that angle i am calling as theta so  this theta and this is a distance which is x  so these are the two this thing and we are saying that you see  this thing is if this is the centre point  then this is l by 2 a length of the needle is capital l  so this length is l by 2 and if you are o b is less than l by 2  then the needle will intersect the one of the lines  so that way geometrically this is describing so  this is making use of geometry to also explain things and probability theory  so here x is a random variable equal to the distance of the centre of the needle from one of the lines and so now  you can see that x upon in the right angle triangle o a b x upon o b will be sin theta so  sin theta in the right angle triangle o a b x upon o b sin theta or x is o b sin theta that is o b is x upon sin theta and this has to be less than l by 2  so this is our condition for the needle to intersect one of parallel lines drawn on the table so  and x varies from 0 to d by 2  because it can come up to here  because after that it is a same thing  then the position of the line will become like this so  it this can up to d by 2 and theta can vary from 0 to that means  either needle almost lies on the parallel line all it makes a  it stands like this  these are the two  so theta varies for 0 to pi by 2  so these are the ranges for the two and of course  since any position is equally likely  we will say that both the random variables x and theta are uniformly distributed  so x is uniformly distributed in the interval 0 to d by 2 and theta is uniformly distributed from 0 to pi by 2 so  you see the one of the density pdf for a uniform random variable is the 1 upon length of the interval in which this define  so here it is pi by 2  so 2 by pi and here it is 2 by d  so this is the joint pdf that is 4 upon pi d so  now you want integrate  you want to find out the probability x is less than l by 2 sin theta  this is our condition  so therefore theta varies from 0 to pi by 2 and x will vary from 0 to l by 2 sin theta  then this is to be 4 upon pi d d x d theta  so this is the integral which will give you the required probability and so that is simple enough  because respect to x see this is independent of x and theta both  so here you get integral x and so that will be l by 2 sin theta into 4 by pi d and then you integrate respect to d theta here  so that will be minus cos theta 0 to pi by 2 which is equal to 1  so the required probability is 2 l upon pi d so  one can constructs interesting examples and so here  we use the independence of the two random variables to compute their joint pdf and then which i think i probably be now so  we have already shown this that the joint pdf will be the product of the two marginal pdf ' s independent  refer slide time  14  58  now  in another preposition and this sometimes makes life easy and you can immediately find out the independence of the random variables  so this if and it holds for discrete and continuous both so  what it we are saying that random variable x and y are independent  if and only if they join density function f x of x  y can be written as a product of two functions h x and g y so  this would only a function of x  this is function of y and you see the range the limits are also independent  so x varies from minus infinity to infinity  y varies from minus infinity to infinity and since  so what we are saying is that since the integral  double integral here is equal to 1  because this is a pdf  so this implies that when you replace this by h x into g y and the integral separates into two single integrals and so this is this lap to be something like c 1 and this c 2  so this product is 1 so  therefore  see 1 upon c 1 h x will be a pdf and 1 upon c 2 g y will also be a pdf  because by definition this is c 1  so 1 upon c 1 will be 1 and here 1 upon c 2 will be 1 so  therefore  this is the thing that means  always able to convert these two  since this is the pdf and if it is a product of two such functions  single variable functions  then we will be able to convert both of them into pdf ' s this is the idea so  let us just look at few examples  if your join density function is given as 12 e raise to minus 3 x into e raise to minus 4 x  this is minus 4 x and x between 0 and infinity y between 0 and infinity  when you see i can multiply this by 3 and this by 4 so  this now is your exponential with parameter 3  immediately recognize it this also is exponential with parameter four and so both are pdf ’ s ; and so therefore  you conclude because it says if and only if  see this is the part so  we have told you already that if they are independent  then the joint pdf will be a product of the individual pdf ’ s and here i am saying that  if f x  y can be written like this  then again x and y are independent so  therefore  i can immediately conclude that x and y are independent  because your f x  y can be written as the product of two pdf ’ s then if you look at this function here  x e raise to minus x plus y  now here again i can break it up into two functions x into e raise to minus x and this e raise to minus y so  this i know immediately is exponential with parameter as 1  lambda equal to 1 this 1 and here i can quickly verify that this is also a pdf  which means that integral of x e raise to minus x from 0 to infinity d x and if you now integrate this by parts  then you you get minus e raise to minus x x take this as the first function  so 0 to infinity this gives to 0  then you have plus 0 to infinity e raise to minus x d x which integrates to 1 so  therefore  this is the pdf and this also is the pdf  so the proposition again tells us that x and y have to be independent random variables  refer slide time  18  39  so  let me now show you take another example see f x  y is 24 x y and you see here you can decompose it into a function of x and a function of y so  let us now  but the thing is that the area of integration  so this is x between 0 and 1 y between 0 and 1  but x plus y less than 1 so  you see here the connection is there and therefore  the suspicion is that the two random variables are not independent and we will see so  i have shown here the area and over which the valid region  so this is x plus y less than one  this is the line  so here in the square 1 1  this is the area on which you have to concentrate so  now  first let me verify that this is the pdf  so therefore see your range for x will be from 0 to ; that means  given a value of y  if i am integrating with respect to x then i fix a value of y and then i draw a line  so therefore  i will be my range for x is then from 0 to see when you fix 1 minus y so  x varies from fixing a y then y range for x will be 0 to 1 minus y and that is what have written here 0 to 1 minus y 24 x y d x d y and so  even you integrate respect to x this x square by 2 0 to 1 minus y and so the integral is the value of the integral is 1 minus y whole square by 2 and here just open it up take y inside and then you integrate you this is what y square by 2 minus 2 y cube by 3 and y of 4 by 4 from this is 0 to 1 right and  so this will be when you substitute the values at 1 you get this which is equal to 1 so  we have verified this is the pdf and now you compute the marginal ’ s and we will show that the product of the marginal 's is not equal to the join density function so  because that condition was if and only if remember  so here when you integrate respect to y so  gain this will be now 0 to 1 minus x ; that means  your fixed x  so once you fix an x then your y will vary like this  so from 0 to fixing x  so y varies from 1 minus form 1 minus x so  this will be the length of the range for y  so therefore  0 to 1 minus x  x y d y and again this will be x into 1 minus x whole square the same integral that we did and  so this will be 12 into x 1 minus x whole square x varies now from 0 to 1  similarly the marginal of y same integral because the symmetric the function is symmetric with respect to x and y both and the limits are also so  therefore  this will be this and y between 0 and 1  so you see that f x y is not equal to f x into f the marginal 's  so therefore  the 2 random variables are not independent so  when you say that you can break up the joint pdf into individual you know functions of the single variables  then make sure that the range is are also independent otherwise  the random variables will not be independent  so we will continue and then may be will keep coming back to so but independence is a very important concept does simplify lot of things in probability theory now  let me start talking about sums of random variables i have already told you earlier that how we can  i know get the distributions for sums of independent random variables so  here again the catch word is independent we need that  so now for example  if x and y are 2 random variables  which are independent and if f x  y is the joint pdf then  if you want to write the distribution function for the random variable x plus y this will be given by this  which will be  so now  here again the same thing that we used in this case so  since x plus y less than or equal to t  so if you are integrating with respect to x and y is    refer time  23  09   so this will be minus infinity to t minus y range for x and then the range for y will be minus infinity to infinity but  since this is x and y are independent  so this can be written as a product of the individual pdf ’ s the marginal pdf ’ s so  therefore  i can separate out my integrals minus infinity to infinity f y y d y and minus infinity to t minus y f x x d x and  so this you know gives you what  this is the probability of capital x less than or equal to t minus y  so therefore  this is your cumulative distribution function for x at t minus y this integral and this is the integral minus infinity to infinity f y y d y  so this is called convolution of because here this is the distribution function for x at t minus y minus infinity to y  well not exactly you are well i am writing small f y d y so  anyway this will be called as a convolution because this is at y and this is at t minus y  but i will make things more clear here see now if you want to if i differentiate this with respect to t then i get the pdf for x plus y  refer slide time  24  41  and you say that here this is this and remember we have done it already we can exchange the integral and the derivative sign provided this thing here is differentiable and  so i take the derivative inside this gives me this and this now f x t minus y d d t will give me the pdf of x at t minus y and this f y y d y minus so  now  this is also this you can see better as a convolution of the 2 pdf ‘ s f x and f y  so f y y then f x is t minus y  where we are looking at the event this less than or equal to t  so this is called the convolution and sometimes it comes in handy  but i will try to show you again ; that means  my philosophy is that you should try to use geometry and direct methods as much as possible to get answers the formulae are important and sometimes they are very helpful and i have shown you  that at times it has helped us to use the derive formulae to get the result  but sometimes it also helps to do things directly so  let us take this example  some of 2 uniformly distributed independent random variables x and y on the intervals 0 1 so  now  i want to find out the pdf of the random variable x plus y  where both x and y are uniformly distributed on the interval 0 1 and they are independent so  then the variable z which represents the sum  will now vary from 0 to 2 because this varies from 0 to 1  this varies from 0 to 1  so the sum can be vary from 0 to 2 so  as i am saying we will do it     using the formula directly i will try to compute the cumulative distribution function and see so  therefore  the diagram is here 0 to 1  0 to 1  x axis  y axis  now you see what happens is if your t is less than or equal to 1  see t equal to 1 gives you this line x plus y equal to 1 and this portion is covered by t greater than 1 so  as long as t is less than 1  you see this is uniform  so ; that means  uniform mass over this region  so therefore  to get this probability i just need to compute the area of this triangle so  it would get probability x plus y less than or equal to t  it is simply the area of this because  the joint density function is what  your join density function is 1 into 1  which is 1 because both are uniform on the intervals 0 1 so  the mass spread over is you know is same uniform unit and so the area of the valid region would be or probability  so here as long as t is less than or equal to 1 the area was therefore  if you take this or you take this  then it will always with the area of this triangle so  therefore  this is half t square because this side is t and this is side t  so base and height are both t  so half t square for 0 less than t less than 1 now  when t becomes more than 1  then you see it is no longer because it is this a region which is a triangle  but you need this area so  therefore  what i will do is from the total are 1  i will subtract the area of this triangle and that will give me the required probability  so this line is x plus y equal to t and therefore  it intersects x equal to 1 at t minus  so therefore  the y point is t minus 1 because t is greater than 1 similarly  this is t minus 1 1  so then both these lengths this point is 1 1  so when you do it 1 minus t of minus 1 plus 1  so 2 minus t so  this length is 2 minus t  this is length also 2 minus t  so the area of that triangle is half 2 minus t whole square and therefore  the required probability is 1 minus 1 by 2 into 2 minus t whole square  when t lies between 1 and 2 so  see looking at the diagram things become really simple and therefore  when you differentiate this respect to t  in this case it becomes t 0 less than t less than 1 and for this because this is a minus sign minus sign  so 2 2 cancels 2 minus t as t varies between 1 and 2 so  now  if you draw the picture graph of f to t between 0 and 1 it is given by this line and between 1 and 2 it is given by this line  so it is a triangle  so therefore  this is also known as triangular distributions now  i leave it to you to try out the convolution formula and then see that you should get the same answer so  you can sit down and verify for yourself the formula is clear here for different values of t you will have to so  here of course  your this thing will be from 0 to 2 because your t can vary from  but looking at the diagram things really become simple and you can  so where ever possible use geometry or direct methods  refer slide time  30  19  now  trying to look at this example  where you have x is uniform  0  1  and y is exponential with parameter 1 and x and y are independent so  now we want to look at the  so the joint density function of x and y will be just the product of the individual pdf 's  so this is for the uniform it is 1 and for the exponential it is e raise to minus should have written e minus y  so this it is ok here i just wrote here e minus y and so your y varies from 0 to infinity x is between 0 and 1  so now you want to find out the probability that x plus y is less than or equal to t that means  this is your f of x plus y t  this what you found want to find out and so you see now here what i have right now written is when 0 is less than t  less than or equal to 1  so you see the region of integration as i had told you is x between 0 and 1 and y non-negative  so going to infinite so  this is the region for integration and i was trying to tell you that we have to separate out the integration into two parts  because you see for x plus y less than or equal to t as long as t is between 0 and 1  then this is this area which will has to be covered so  therefore  for example if you take the line x plus y equal to t  if this the line  then the limits for x are from 0 to t and for y will be from 0 to t minus x so  therefore  t between 0 and 1 these are the limits and so you can  therefore integrate respect to y first  so that will be 1 minus e raise to minus t minus x  because integral of this will be minus e raise to minus y and so from 0 become 1 minus e of minus of t minus x d x and then you integrate respect to x the limits are 0 to t and so this will be x and because this is plus x  so this will remain minus e raise to minus t of minus x from 0 to t and therefore  this is your cumulative density function for t between 0 and 1 now  for t greater than 1 with lines would be like this  express y equal to t which is greater than 1 so  in that case you are for a given x your y will vary like this form 0 to t minus x  and x will vary from 0 to 1  because when you are talking of t greater than 1 this line  then x will vary from 0 to 1 and t will vary from 0 to t minus x and therefore  for t between 1 and infinity it will be 0 to 1  0 to t minus x  e raise to minus y d y d x and again the same integration this one is exactly the same and then from 0 to 1 with respect to x  so this will be minus e raise to minus t minus 1 plus e raise to minus t plus 1 so  please just verify that these are valid cumulative density functions of course  here as t goes to 0  this goes to 0  t goes to 0 this is 0 and this is 1  so 1 minus 1 is 0 and as t and from here as t goes to infinity you can see that this will go to 1 because  this will go to 0  this will go to 0 and you will be left with 1  have i written it correctly here let us just make sure  let us t goes to infinity then this goes to infinity also and so e raise to minus of t minus 1 also goes to 0  so therefore the limiting value is 1 so  this is the valid cumulative density function and therefore  now you want to compute the pdf then just differentiate so  this will be 1 minus e raise to minus t as t is between 0 and 1 and this one here would be minus e raise to minus t and then this will be plus e raise to minus of t minus 1  so this is your pdf for so  therefore  all these things as you work out and get experience  you can get a experience you can get feeling how to go about big and the diagram in of course  you can do it in two or three dimensions so  therefore  the diagram helps to tell you that you have to break up the integration into two parts  so between 0 and 1 for t between 0 and 1  the limits for x are different and when t is greater than 1  the limits become difference so  therefore  this can only you can get the feeling by looking at the figure and then you know deciding accordingly  so we continue with some more of these examples  refer slide time  35  16  so  expectation of x plus y is equal to expectation x plus expectation of y  now let us just try to first to show this under independence of x and y  so then i can write the joint density function as the product of individual density functions and so e of x plus y  this should be x plus also see your are integrating x plus y integral minus infinity to infinity minus infinity to infinity x plus y into f x  x  into f y  y  d x d y so  i have written the joint density function as the product of individual density function and so therefore  one can then separate out the integrals so  this would be x f x  x  f y  y  d x d y and here it will be y  now then since if you integrate respect to y  then integral f y of y d y will be 1  because this is a pdf of y ; and so you will be left with x f x  x  d x minus infinity to infinity and similarly  here integration respect to x will result in 1 and so you will get integral minus infinity to infinity y f y by d y and this is e x plus e y but  i want to point out that it is not necessary to show that this result  you do not need independence of x and y actually it is always true and that you can immediately verify  because if x  y is the joint density pdf of x  y  joint pdf of x and y  then e of x plus y we write in this way  integral double integral minus infinity to infinity x plus y f x y  this is this of x  y then again i write this as sum of two integrals which is this and this  but we know making the same argument that minus infinity to infinity of f  x  y  x y d y will give you f x of the marginal density of x and then so it will be come out to be integral x into marginal of x density function of x plus  similarly y you first integrate respect to x here to get the marginal of y and then you get this and therefore  this of e x plus e y  so for showing that e of x plus y is e x plus e y you do not need independence of x and y  but under independence we can show another result  which is that expectation of x y  product of x and y is actually product of the expectations so  there is a e x into e y and this for this i will need independence  because now i will write e  x  y  as this double integration x  y and the joint can be written as the product of the marginal ’ s  so f x  x  into f y  y  d x d y and now here again i can separate out the integrals  so this is integral x of x d x minus infinity to infinity into minus infinity to infinity y f y d y ; and now each of this  this is e x and this is e y  hence y gets these are the product and this result now i will prove in while showing that the under independence variance of x plus y is equal to variance of x plus variance of y  which holds only when x and y are independent so  therefore  once we have shown this result we can now derive that result  refer slide time  38  55  to compute the variance of x plus y  we will require the result that i am giving right now  we will use independence of the variables x and y so  let me just right down variance x plus y is expected value of x plus y minus e x minus e y whole square so  i open up the square term  then this will be x minus e x whole square plus  this should not there plus y minus e y whole square plus twice x minus e x into y minus e y now  from linearity of the expectation function we have seen it earlier  that it expected function is a linear function so  it follows that the expected value of the whole expression i can take expectation inside and therefore  this will be expectation of x minus e x whole square plus expectation of y minus e y whole square plus twice expectation of x minus e x into y minus e y now  this is the place where i will use the linearity of x and y  because if x and y are the independence of x and y  if x and y are independent and x minus e x into y minus e y are also independent this being a constant so  it can immediately be concluded that  if x and y are independent and then x minus e x and y minus e y are also independent  therefore the expectation of the product can be is equal to the product of the expectations and therefore  expectation of this product is equal to expectation of x minus e x into expectation of y minus e y and so now  here you see that this would be e x minus e x which is 0 into e y minus e y which is also 0  so with the whole thing is 0 and so this expression reduces to simply expectation of x minus e x whole square plus expectation of y minus e y whole square  which is equal to variance x plus variance y so  when trying to compute the variance of sum of two variables  two random variables  then i need to be able to write it like this  i need x and y to be independent  refer slide time  41  09  now  let me show you what independence means to us and of course  interesting relationship between various pdf 's that we have discussed or into special kinds of random variables now  if x is gamma s lambda that means  parameter s and lambda and y is with gamma with parameters t and lambda  so lambda is the same  but these two numbers differ  then x and y are independent then x plus y is gamma s plus t  lambda that means  the first parameters either second parameter is the same  then the first one get added up  when you add up the two random variables  at this i will show you using the m g f  because i missed out on the m g f so  m g f is also straight forward because this is expectation of e raise to t x plus y so  then this way because i will write it as e into t x and into e into t y right this function i can write as this then again i just told you that so  you might say that y are these independent that can also be shown that if 2 function are independent  then their functions are also independent of course  under certain condition  but e raise to t x and e raise to t y are also independent random variables  so when i write expectation of the product that will be the product of the expectations see this nothing much to you can actually use the again write the joint this thing  because joint density function will again with the product of individual pdf ’ s so  even when you write this function here as an integral you will separate out the integrals and again just as you prove this result exactly you can show by this expectation is equal to the product of the expectations right so  then ; that means  if x and y are independent then there m g f of the sum is the product of the individual movement generating functions so  there is a important result and that is what i am going to use here  so i am showing you that we know that when x is gamma s lambda it is movement generating function is given by lambda upon lambda minus t raises to s and the movement generating function of g t  lambda is lambda upon lambda minus t rise to t and so the sum would be the product of the m g f ‘ s  so the m g f of the sum is the product of the m g f ‘ s and so this becomes lambda upon lambda minus t raise to s plus t so  now  i am concluding immediately that this ; that means  they p d f of x plus y is gamma with parameters s plus t  lambda while defining m g f for you and looking at it is properties i had mentioned that m g f uniquely characterizes the p d f of the random variable  if you know the m g f of a random variable then can tell from what is the p d f of the random variable this can also be proved  but i will simply use the result here and so therefore  once i know that the m g f of x plus y of this form then i will conclude that this ; that means  the p d f of x plus y must be s plus t  lambda and now let me this  i had already mentioned this relationship between the exponential and gamma i said that exponential lambda is gamma 1  lambda ; that means  the first parameter is 1 and the this is the common thing so  when you have a exponential random variable it is also gamma 1  lambda now  if x and y are independent exponential lambda random variables both having the same parameter  then by this result x plus y will be gamma 2  lambda so  i am using this result here that the first parameters get added up if the second parameter is the same  since the exponential x and y both are exponential with  so they are both gamma 1  lambda  so their sum will be gamma 2  lambda and so on right so  and now what i am trying to say here is that concept of independence of two variables can be extended to many more in the discrete case i already shown you that characterizing the independence of more than 2 variables becomes tedious  but we can anyway use the end results so  here see the thing is that you can sequentially use this result you know about m g f ’ s about variance and expectations so  what we saying is that if x 2 first of all you have 2 variables x 2 and x 1 are independent then once you have this then you can apply that x 3 is independent of x 1  x 2 so  then you can apply the result ; that means  you can go on adding so  what i am trying to say here is that if you have two exponential random variables both with the same parameter i add them so  i get a gamma to 2  lambda then add x 3 to it so ; that means  i will be talking of x 1 plus x 2 plus x 3  so this will become 3  lambda so  the concept can be recursively used  so here then you will say that x 4 is independent of these 3 and so on so  finally  x 1 is independent of x 1 x 2 up to x n minus 1  so this is the whole idea so  therefore  now i can say that when you have gamma s  lambda where s is an integer so  if you look at this result then s is a integer  so gamma s  lambda is the sum of s independent exponential lambda random variables so  when s is an integer gamma distribution has been built up by adding exponential distributions as of them right and if you remember when i was talking of the gamma distribution and then we were looking at the  so we had said that suppose there is a service counter and they are people i had a few who are n minus 1 you are the another person then gamma and lambda you can ; that means  the time that you have to spend and we had said that if this time taken to service each customer is exponential with parameter lambda then the total time till the another person gets serviced ; that means  this is this includes the servicing of n minus 1 people ahead of him and then the n the person is this person so  when then total n people get serviced that will become gamma and lambda so  this was the connection and so we i had use this and i had told you that we will be able to show this prove this result also that the n exponential distributions with the same parameter lambda will add up to gamma distribution with parameters n  lambda so  i will continue this exploration more in the coming lectures introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  14 chi-square r.v sums of independent normal r.v conditional distr  refer slide time  00  16  so  after obtaining expression for e x plus y  in fact we showed that e f x plus y is e x plus e y and under independence of x and y  we showed that variance of x plus y is equal to variance of x plus variance of y then we can generalize these results for any finite number of random variables so  therefore if you have x 1  x 2  x n as a n identically distributed random variables  discrete or continuous  then expectation of x 1 plus x 2 plus x 10 will be equal to expectation of x 1 plus exception of x 2 plus expectation of x n so  want to show that say that this is you can always take the some of the expectation sorry  i mean expectation of the sum as sum of the expectations so  first these have to be identically distributed now  if the x size are also independent  then we can also extend this result at variance of x 1 plus x 2 plus x n is equal to variance of x 1 plus variance of x 2 plus variance of x n  because as we saw if the case 2 variables that the product term vanishes so  here also because independence  the product term because you will have two products of two things at a time that means of the kind you will have an expression like expectation of x i minus expectation of x i into x j minus expectation of x j so  under independence this will go inside and therefore each of the term will vanish so  you will only get  this square terms will be left when you square up this minus the expectation of the sum and therefore  you will get the sum of the variances so  under independence  you get that result now  formula for the variance of sum when the random variables are not independent will be discussed later so  we will give you a general formula when the variables are not independent so  this is one thing and so  we can use it for computing various expectations so  now let me discuss interesting result which is called boole ’ s inequality  and let me first just describe what we want to say here this is that if you have a 1  a 2  a n as n events and when corresponding to these n events  i define the corresponding indicator variable that means  x i is 1 if a i occurs i varying from 1 to n and its 0 otherwise so  therefore  then i will let x be the sum of these indicator variables  these n indicator variables so  in other words  x denotes the number of the events a i that occur fine because x i is 1 if a i occurs so  if x for example  if capital x is 5  then that means  5 of a i ’ s have occurred this will add up to 1 plus 1 for 5 events which have occurred  right and define another variable y which is equal to 1 if x is greater than or equal to 1 and 0  so otherwise means that you see if x is 1 or greater than 1  then y is 1  but if x is 0  then y will be 0 so  from definition it follows that x equal to 0 implies y equal to 0 since  your x is otherwise greater than or equal to 1 see either an event occurs or it does not occur so  if anyone of the events occurs  then x will be at least 1 and if none of the events occur  then it will be 0 so  therefore  x is always greater than or equal to 1 or it is 0 i mean if 1 of the not always what i mean is that if at least one event occurs  the next will be always greater than or equal to 1 otherwise  if none of the events occur  then x will be 0 and in that case  y will also be 0 so  therefore  it implies that x is greater than or equal to y  right because x will take value 1 or 2 or 3 your y is 1 and whenever x is 0  your y is 0 so  it is clear that x is always greater than or equal to y  and this implies that your expected value of x will also be greater than or equal to expected value of y because this being x minus y is non-negative therefore  expectation of x minus y now  i am just writing the general expression here so  that means  for example a general expression for e x minus y would be minus infinity to infinity x minus y f x y x y d x d y so  this integrant is non-negative and therefore  the integral will be non-negative so  it follows that your e x must be greater than or equal to e y  ok so  that is the important result that is how through this  we will derive the boole ’ s inequality finally  refer slide time  05  17  now  look at e x so  e x is expectation of i take it inside being linear function so  i can exchange the expectation and summation sign so  sigma i varying from 1 to n expected x i  but expected x i is what expected x i 1 into probability x i equal to 1 plus 0 into probability x i equal to 0 since  x i take values only 1 and 0 so  this is 1 into probability x i is equal to 1 plus 0 into probability x i equal to 0 so  this is 0  and this probability x i equal to 1 is probability of occurrence of a i and therefore  this is 1 into p a i which is p a i  right so  you are some of the expectations of x i is equal to sigma p a i now  x i ’ s are  you can see that x i ’ s are bernoulli random variables  right because x i ’ s take value 1 or 0 and the probability of success as you can call it is p a i for x i  right now  what is probability y ? so  probability y is probability that at least one of the a i occurs so  this is union a i varying 1 to n so  this is at least one of the a i occurs so  well which way would we are saying y is equal to 1 if x is greater than or equal to 1 and this translates to x is greater than or equal to 1 if at least one of the events a 1  a 2  a n occurs  right so  this is probability union i varying from 1 to n a i so  expectation e y will be 1 into because y is 1 if x is greater than or equal to 1 so  this is union i varying from 1 to n a i plus 0 into probability union a i complement  right probability of this complement of this event and therefore  this is also equal to e y is equal to simply probability of union a i varying from 1 to n hence  we obtain boole ’ s inequality which says that sigma i varying from 1 to n p a i is greater than or equal to probability union a i varying from 1 to n so  in other words  it says that probability of occurrence of at least one event out of given n events so  probability occurrence of at least one event is no greater than the probability or some of the probabilities of occurrence of individual events so  this in other words is your boole ’ s inequality which you might say is simple to accept  or this sounds very reasonable  but we had to go through this process to be able to derive this inequality  right so  this says at least one of the events must occur so  probability of that and that can not be greater than some of the probabilities of the individual events  ok now  let us further go on i want to again continue with using whatever we have developed about adding up random variables and then  computing their expectations and other results through summing up random variables so  now  look at the chi square and random variable so  this random variable is defined as summation i varying from 1 to n z i square  where each z i is standard  normal i varying from 1 to n  right thus  the expectation of z i is 0  and the variance of z i is 1 so  each of the z i is standard  normal  then look at these so  we want to compute first of all  we want to compute the c d f of z i square so  this will be let me write  make it clear so  f z i square y will be probability z i square less than or equal to y  and in one of the earlier lectures  i have already discussed so  what you are saying is that your z i square should be less than or equal to y  which means that your z i should be less than root y so  it should lie between minus root y and root y  your z i  right  so that the square does not exceed y so  this probability can be written as because you will be taking if this probability z i less than root y  then you want to subtract z i less than minus root y so  this is the probability  right and therefore  when we differentiate this side  i will get the p d f of z i square  this is z i square which will be equal to      so  from here we will differentiate so  see derivate of a root y will be 1 by 2 root y in to f of z i root y minus f of z i minus root y and for standard normal c you see what is your this thing is standard normal 1 upon root 2 pi because sigma is 1 is equal to e raise to minus y square so  it is root y so  it will be root y square on 2 because sigma square is 1 so  therefore  when you square up the minus root and root y  they are both give you e raise to minus y by 2 so  this becomes  so this is twice e minus y by 2 and these two  so that cancels out so  i am left with 1 upon root y 1 upon root y e raise to minus y by 2 now  this i can rewrite because you have 1 upon root 2 and 1 upon root 2  i am writing as 1 upon 2 into 1 upon 2 raise to minus 1 by 2  right i am doing this  so it is 1 by 2 is going  yeah so  1 by 2 into 1 upon 2 minus 1 by 2  you write this way and this is left by root 2 root 2 cancels out and you are left with 1 by root 2  right so  this whole thing i am writing as 1 by 2  1 by 2 y raise to minus 1 plus half root pi because this is 1 upon 2 raise to minus half so  1 upon 2 raise to minus half into 1 by 2  this whole thing is actually equal to 1 by root 2 which appears here 1 by so  this 1 by root 2  i am writing in this way  right and now  you see if you can remember your gamma distribution  then my lambda is half and my alpha is half because this is alpha minus 1 and then  this is lambda y raise to alpha minus 1 e raise to minus lambda y and then  lambda so  this is my gamma of course  when you look at the p d f gamma p d f  then it has to be divided by gamma alpha so  what i am doing is i am writing this as gamma p d f and then  multiplying by 1 by 2  gamma 1 by 2 because i have divided here this expression  this numerator i have divided and multiplied by gamma 1 by 2 so  when i divide this by gamma 1 by gamma of 1 by 2  the whole thing becomes gamma p d f with parameters half and half  and i have gamma 1 by 2 here and thus  a root pi now  since this is p d f on the left hand side  this should also be p d f and therefore  you see that these two must be equal so  this implies that earlier lecture when we were talking  discussing the  when i introduced the gamma distribution m  i told you that it take that gamma of half is root pi  but now you have an immediate justification that gamma of half must be equal to root pi and of course  as i said that for other fractional values of gamma f  this gamma function you can tables are there and for integer values we had already seen for positive integers we also saw that gamma alpha will be alpha minus 1 factorial and so on so  now we continue with this discussion so  therefore  each z i square has a gamma half  half distribution  now gamma square n sorry  chi square n is z 1 square plus z 2 square plus z n square and z i ’ s are independent so  then applying the m g f results  we see that you can add up the p d f ’ s here the parameters and you will again because each is gamma  each z i square is gamma distribution half and they are n of them  they are independent so  therefore  the sum will be gamma and by two half that means there will parameter lambda will be half and this will be n by 2 so  you see how i mean using all the results that we have so  i thought this was good way to show you how we use these tools that we are generating and then  you can see the breakup of so  once you have a gamma distribution  then you can see that by adding up these independent gamma distributions a h gamma random variables  you get a chi square n and of course  in a special way  refer slide time  15  12  so  this is another interesting result so  when you have seen that if n is an integer  then gamma n is simply n minus 1 factorial so  if n is even  then your this thing will be factorial of n by 2 because n is even then this is an integer so  gamma of n by 2 will be n by 2 minus 1 factorial  but if n is odd then you will be left with gamma half so  for example  if you say n is 7  then gamma of 7 by 2 will be 5 by 2 into gamma 3 by 2  then 3 by 2 sorry 7 by 2 gamma 7 by 2 is 5 by 2 gamma 5 by 2 which will be 3 by 2 gamma 3 by 2 and then  that will be half gamma half which is root pi here so  this you can compute so  therefore  now you know you can compute this for all values of alpha integer  non-integer you can find out  right so  this was an application of  therefore you see first you square up independent  normal  standard normal variants sum them up  you get a chi square distribution and you are showing is that for n  this is chi square with n degrees of freedom so  then chi square n is actually obtained by adding up gamma half  refer slide time  16  34  so  i should also mention the importance of chi square distribution so  if you are talking of chi square n distribution and we said that the n stands for the number of standard normal variable that you are squaring and adding up so  you can think of because you see this is x i minus mu i upon sigma i whole square so  this would be your z i  alright and your z i square so  you are summing up and so this can be treated as this this can be looked up on as you know to an attempt to estimate the errors involved and one attempt to hit a target in n dimensional space when coordinate errors are taken to be independent unit probable random variables  right so  this is you know you can difference from the mean or whatever kind of error you want to  you know talk about and talk about their distribution and so on then  chi square random variables come in very handy in that and in fact  it is most widely used distribution in statistical analysis so  chi square distribution has lot of importance and very often used for your statistical analysis so  now let me get back to sums of independent normal variables and this is if x i ’ s are independent normal random variables  x i ’ s varying from 1 to n or independent normal variables with respective parameters mu y sigma i square  right that means the x i th normal random variable mean is mu i  and the variance is sigma i square i varying from 1 to n  then sigma x i is again normally distributed with parameters sigma mu i  and that mean as sigma mu y and the variance as sum of the individual variances  because the random variables are independent so  anyway that we know already that the variance for this would be sigma i square and we also know that the mean for sigma x i will be sigma mu i these results we have already done  but to show that these sums will again be normally distributed  that is the important thing now  here again i am going to see the thing is that i have been using m g f ’ s moment generating functions to talk about summation of independent random variables  but it takes sometimes they introduce the concept of moment generating function much later so  they actually do it through you know writing the joint density function because these are independent random variables so  the joint density function will be a product of the individuals and then  they manipulate that term and actually come to the result so  maybe you should also do that to get to know better feeling  but i find that the treatment through m g f is very convenient so  the m g f of x i is e raise to mu i t plus half sigma i square t square this is for the normal mu i sigma i square and since  x i are independent i variant from 1 to n  m g f of sigma x i is the product of the individual x moment generating functions  right so  this we have done already so  the moment generating function of sigma x i would be e raise to mu 1 t plus half sigma 1 square t square and then  e raise to mu t mu to t plus half sigma 2 square t square and so on up to n  and therefore you can add up because these are the powers so  e raise to sigma i varying from 1 to n mu i t plus half sigma i varying from 1 to n sigma i square t square so  this is again as i said that the uniqueness of that means given this m g f  i can immediately conclude that the corresponding distribution is normally distributed with mean sigma i varying from 1 to n mu i and this is variance sigma i vary from 1 to n sigma i square so  using the m g f  you can get these results much quicker  otherwise you have to though the other root is also not difficult one it is just that you have to write out these long expressions and then  show that this sum of independent normal random variables will be again a normal random variable and these will be the parameters  refer slide time  21  30  so  to give you an example about how to make use of the fact that sum of independent normal random variables would also be normally distributed  let us look at this example this football club team will play 44 game seasons so  you know with during summer  they all play game so  different teams  so there are 44 games that particular teams will be playing so  26 of these with will be with class a team and the remaining 18 games will be with class b teams so  probability of winning a match against a team is 0.4 because a teams are better than b teams and probability of winning a match against the b team is 0.7 so  results of different games are independent we are not assuming that there will be any sort of dependence in winning of a game with one team and the other so  we want the ideas to approximate the probability that the team wins 25 games out of those 444 games played  and second probability that you have to compute is that the team wins more games against class a team ’ s than class b teams so  let us start by defining the random variable xa as the number of matches one against class a teams and xb is the number of matches won against class b teams  fine now  of course xa and xb are binomial random variables because win is the success and the probability of success is point 4 so  you can find out that out of 26 games played by this team with class a team  then the number of that means  if xa is equal to r  then you will find out it will be a binomial probability and similarly  xb is also a binomial random variable  right now  expectation of xa will be 26  right the formula is np so  26 games played and probability of winning match is 0.4 so  this is np so  that comes out to be 10.4 and the variance is npq  right which will be 26 into 0.4 into 0.6 is 6.24  then similarly xp being binomial with parameters 18 and 0.7 so  the expectation of xb will be 12.6 and variance xb equal to npq which will be 3.78 now  the idea is that we start approximating or remember when i told you about approximation of binomial distribution by the normal distribution the condition was that i mean it is said that if npq is greater than or equal to 10  then the approximation is considered good  but here of course that condition is not being satisfied because npq in these cases 6.24 and this case  it is 3.78 but still we are going ahead with the approximation just to get an idea because i want to show you the application of adding up normal  where required probability is that xa plus xb together that number of matches one against class a teams  and the number of matches one against class b teams  they must add up to more than 25 or more than 25 now  even though i may approximate xn xp by normal  but they are discrete random variables they are binomial so  the continuity correction factor must be used here so  this will be since this is greater than or equal to 25  this will be 24.5 because remember you have this on 25 so  your bar is like this so  the bar starts from 24.5 and you want to approximate this you want to include this area because the probability here is greater than or equal to 25 so  it will be 24.5 so  probability xa plus xb is greater than or equal to 24.5  refer slide time  25  50  now  i standardize this probability by subtracting the mean  which has 23 12.6 and 10.4 adds up to 23 and the two variances add up to 3.7 and 6.24 is 10.02 so  this is what you have this becomes standard normal variant and therefore  this probability z greater than 1.5 divided by square root of 10.02 so  this will be 1 minus pi of this number comes out to be 0.4739 so  the required probability is 1 minus the normal table  the standard normal probability of this number so  this is 0.3178 now  xa minus xb is also approximately normal minus 2.2 and 10.302 as the variance  right therefore  probability xa minus xb greater or equal to 1 because you want the probability that matches against class a team ’ s matches one against class a team ’ s is more than the matches one against class b team so  therefore  the difference must be greater than or equal to 1 can be more and so  here again we standardize so  this is xa minus xb minus 2.2 which comes plus and this is under root 10.02 which is greater than or equal to 5.5 so  here again these term continuity correction factor is used see a subtract 0.5 from here  so that becomes 0.5 plus 2.2 up on this under root of 10.02 so  that is z greater than or equal to 2.7 up on under root of 10.02 which comes out to be this from tables you look up the value which is 0.1 minus of that will be 0.1968 so  this is the probability so  in fact the probability is low of winning more matches because obviously  this probability is much lower compared to the probability of winning a match against b team so  as we go on more and more examples of all these concepts that we are talking about now  let us come back to sums of independent poisson random variables so  x is poisson lambda 1  y is poisson lambda 2 when and x and y are given to be independent random variables so  let us look at the distribution of x plus y so  now  since x and y are independent  m g f of x plus y will be the product of the m g f ’ s of x and y so  m g f of a poisson lambda 1 is e raise to lambda 1 into e raise to t minus 1 and m g f for y is e raise to lambda 2 e raise to t minus 1 so  therefore  this adds up to e raise to lambda 1 plus lambda 2 e raise to t minus 1 and this is poisson lambda 1 plus lambda 2 so  therefore  you immediately get the result and as i told you earlier that you might try to do it directly  right that means  you may obtain the cumulative density function for x plus y  distribution function for x plus y and then from there you can compute  refer slide time  29  11  so  having learnt the trick to use m g f for finding out distributions of sums of random variables  i will still write it down for binomial and poisson and so on i think poisson we have already done now  let us look at the sum of independent binomial random variables so  here again the x is binomial n  p and y is binomial m  p  then we want to look at the sum and x and y are independent so  then again m g f of x plus y will be the product of the individual m g f ’ s so  here it is p e raise to t plus 1 minus p raise to n  and for the random variable y  the m g f is p into e raise to t plus 1 minus p raise to m so  when you multiply  the powers get added up so  this is p e raise to t plus 1 minus p m plus n and therefore  it immediately follows that x plus y is binomial and plus m  p so  if the probability of success is the same  then if you are looking at two random variables in one case  the number of trials is n in the other case  the number of trials is m  then the sum will again represent the binomial random variable  either number of trials gets added up so  probability of success remains the same so  now  i have seen this thing for sum of these distributions so  whenever you come across something new  you can read it up and understand what is going on ? now  let us look at the conditional distributions also we have looked at conditional probabilities and we have looked at base conditional probability and so on so  now  let us look at conditional distributions so  remember that when e and f for two events  then we define the conditional probability of event e given that event f has occurred and this was defined as probability of e intersection f that means  both the events must occur divided by the probability of occurrence of f so  these were the events now  when you come to x and y are two discrete random variables  and you want to write down the conditional probability of x given y  where capital y is let us say small y and x  small x see if you want to compute this  then it will be again just borrowing it from here it will be probability x equal to x y equal to small y divided by probability y equal to y which you can write in your notation as p x  y upon probability y equal to small y now  sometimes i may write this suffix  sometimes i may not so  it does not matter  but you understand from the context that this is for a single variable and this is for a joint p m f  right so  this is for all y that means  this conditional probability is defined for all y  such that probability y is greater than 0 i am dividing by number  which i must ensure is positive which is non-zero and since probabilities can not be negative  so the number must be positive so  for all possible values of y for which there is a positive probability  i define it this way  right  so conditional p m f of x given this therefore  this defines the conditional p m f of x  given that y is equal to y now  conditional cumulative distribution function of x given y is equal to y would be you know f x given y so  that will be probability x less than or equal to small x  given that y is equal to y which is then probability x equal to a  given that y is equal to y and you are summing up over all a for which is less than or equal to x so  therefore  the conditional notation is the conditional probability of a given y  where a is less so  you are summing up over all a less than or equal to x  refer slide time  33  28  now  if x is independent of y  then we know that this probability  the conditional probability will be written as because here this will be the product of 2 and divided by probability y equal to y so  therefore  it will reduce to probability of x equal to x so  therefore  we are just trying to show you that whatever we did for the events  the same thing goes over for the random variables and there corresponding distributions now  just look at this example if you given that probability of 0  0 is 0.3 that means  x taking the value 0  y taking the value 0 so  therefore  your x takes the value 0 1 and your y takes the value 0 1 so  therefore  the four probabilities p of 0 1 is 0.3  p of 1 0 is 0.2 and p of 1 1 is 0.2 they all must add up to 1 so  you want to calculate the conditional p m f of x  given that y is equal to 1 so  first of all you need probability of y equal to 1  right in the denominator so  therefore  this is equal to p of 0 1 plus p of 1 1  right that gives you the marginal of y which is a probability of y equal to 1 so  that is 0.5 and hence  probable conditional probability of x given y equal to 1 so  if you want to find out  then you see the possible value of x has 0 and 1 so  you will find out both the probabilities  a conditional 0 given 1 y equal to 1 so  that will be 0 1 divided by y equal to 1  probability of y equal to 1 so  0 1 from here is 0.3 divided by 0.5 and that is equal to 3 by 5 similarly  probability x equal to 1 when y is given to be 1  so that will be p of probability 1  1 divided by probability y equal to 1 so  it will be 0.2 divided by 0.5 and so this is 2 by 5 so  similarly you can compute the p m f well  ok  refer slide time  35  42  so  this conditional  you can fix a value of x and then  compute the conditional p m f of y yes now  this is another interesting example this says that if x and y are independent poisson random variables with respective parameters lambda 1 and lambda 2  calculate the conditional distribution of x given that x plus y is n so  now  the condition is on the sum x plus y equal to n and you want to find out the conditional distribution of x so  first let us compute probability x plus y  and as i just showed you just a few minutes ago that if x and y both are independent poisson random variables  their sum will be also poisson and the parameters will get added up so  this is e raise to minus half lambda 1 plus lambda 2 lambda 1 plus lambda 2 raise to n divided by n factorial so  this is easy because we have already of course  seen the distribution for x plus y then yeah you now want to compute the probability for example  x equal to k when x plus y is n so  for finding the conditional probability of x given that x plus y is n so  now  if x is k  then this says that your y must be n minus k  right see i mean here you will be writing probability  yeah so  x equal to k and x plus y equal to n that will be product and then  divide it by probability x plus y equal to n so  intersection of x equal to k and x plus y equal to n is equivalent to the event that x is k and y is n minus k divided by probability x plus y equal to n  and since again x and y are independent  this probability i can write as the product of individual probabilities so  this will be a probability x equal to k into probability y equal to n minus k divided by probability of x plus y equal to n  and this both being x and y  both being poisson  this is e raise to minus lambda 1 raise to k divided by k factorial then  the other probabilities e raise to minus lambda 2 raise to n minus k divided by n minus k factorial this may not look very  let me rewrite n minus k factorial  but it is there and then  e raise to lambda 1 plus lambda 2 probability of x plus y equal to n which we wrote down here so  this is lambda 1 plus lambda 2 raise 1 then  there should have been e raise to  yeah lambda 1 plus minus e raise to lambda 1 plus lambda 2 and n factorial goes to the numerator so  therefore  collect these terms n factorial divided by k factorial and n minus k factorial that comes here  right and then  you see here this is lambda 1 plus lambda 2 raise to n and you have lambda 1 raise to k and lambda 2 raise to n minus k so  i break up into lambda 1 plus lambda 2 raise to k into lambda 1 plus lambda 2 raise to n minus k so  then i get that terms lambda 1 upon lambda 1 plus lambda 2 raise to k  and lambda 2 upon lambda 1 plus lambda 2 raise to n minus k and you see these two numbers that means  lambda 1 upon lambda 1 plus lambda 2 plus lambda 2 upon lambda 1 plus lambda 2 this adds up to 1 so  if i denote this by p and this number is 1 minus p  right so  in that case  then this looks like that means a conditional probability x equal to k  given that x plus y is n is binomial so  therefore  different values of k you will get these probabilities which are exactly the binomial probabilities for the parameters n  and your probability of success is lambda 1 upon lambda 1 plus lambda 2 so  i think through this course i have been trying to show you that even though you have these different random variables  you how you can get through process of addition  conditional  and so on you can see the connections between the various distributions here and therefore  you know that makes those things more interesting and of course very useful also introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  15 conditional disti joint distr of functions of r v order statistics  refer slide time  00  15  so  let me now talk about the conditional distribution when the random variables are continuous so  in that case  it will be probability density function x given y so  the notation will be this so  you will write it as the joint of f x y at x  y divided by the marginal of y at small y  right and see the way to explain this is because since we know that the continuous case  the probability at a fixed point is 0 so  therefore the way to look at it is you know if i multiply both sides by d x and then multiply and divide by here  then you see this represents  this will be the conditional probability of x given that capital wise y and x is between x comma x plus d x and here on the right hand side you can it will be you can interpret f x comma y d x d y as probability x less than or equal to x plus d x comma y less than or equal to y that means capital y between y and y plus d y  you can look at this way  d y d x are small divided by  so this will be probability capital y between small y and y plus d y so  therefore you can say that this ratio represents the conditional probability of x lying between small x and x plus d x  when you are given that capital y is between y and y plus d y so  this is what i have expressed here that capital x will belong to x  x plus d x given that y belongs to y comma y plus d y now  let us just look at an example so  suppose this is a joint density function x lying between 0 and 1  y is between 0 and 1 and you can verify that this is joint p d f that means  double integral of this expression should be equal to 1 when your x and y are between 0 and 1  but to find out the conditional so  if i wanted to write down the conditional p d f of x given y and i need to compute the marginal of y which i hope the arithmetic is  so this will be when you integrate right 3 x into 3 minus x minus 2 y this will be the expression between 0 and 1 so  this will be 9 by 2 minus 1 minus 3 y minus 3 yeah so  remember that because y  capital y is fixed at small y  yes so  this is the marginal  yeah this is the marginal y so  obviously it will be a function of y only  but i had something else in mind which i will tell you right now so  now  if you want to find out the conditional of x given y  then that by definition is this ratio f x  y divided by f y of a small y and this will be because i have computed f y y for you so  this is the ratio and therefore  this comes out to be this so  that means  for a fixed x and y  this will be the conditional p d f of x given y as so  here your x will vary between 0 and 1 now  if you have to find out this probability x greater than half given that capital y is equal to y  refer slide time  04  14  so  this will be the integration half to 1 of this conditional p d f  where y is being treated as constant  right so  you integrate respect to x and here again  this is arithmetic 3 x square by 2 minus x cube by 3 minus x square y because a 2 cancel from half to 1 and then  this is the denominator which i do not have to do anything so  i do the computations here please verify the arithmetic thing should be add up so  the final expression is this which will be the function of y because here you are given a value to x  all values of x greater than or equal to half so  therefore  this conditional probability x greater than or equal to greater than half or does not matter for a continuous case  it does not matter given that y is y it turns out to be this expression so  once we have this and i think for the continuous case for the discrete case also  we wrote down the distributed cumulative distribution function or cumulative  these things and then  you can write down the probability conditional probability mass function also exactly in the same way so  therefore  this is nothing new maybe i did not actually write down the expression  but that does not matter  refer slide time  05  44  so  let me now begin the topic joint probability distributions of function of random variables so  just before this i talked about joint distribution of random variables now  let us take the joint distribution probability distribution of function of random variables because this also we need often to compute certain probabilities and so on so  now x 1 and x 2 are jointly distributed continuous random variables with x 1 and x 2 is there joint p d f so  then suppose y 1 is a function of x 1 and x 2 and y 2 is a function of x 1 and x 2 so  g 1 represents a function of x 1 and x 2 which is represented by y 1 and g 2 is a function which represents y 2  where g 1 and g 2 have to satisfy certain conditions and this is what we were saying that if you look at these two equations  then they must be unique solution in fact  if they are more than 1 or you should be able to fix the values of y 1 and the values of x 1 and x 2  that you will take corresponding to values of y 1 and y 2 so  in other words  what you are saying that we should have the solutions in a deterministic way we should be known liquidity about it so  x 1 should be h 1 of y 1  y 2 and x 2 is h 2 or y 1  y 2 so  i can solve this set of equations to get the values of x 1 and x 2 for given values of y 1 and y 2 and then  this second condition is that this jacobian as we call it  they should be set of partial derivatives which are continuous so  the first order partial derivatives i have not written here or maybe that also has to mentioned first order partial derivatives of g 1 and g 2 are continuous so  therefore  they exist and continuous so  first order partial derivative exist are continuous then  we define this determinant which is delta g 1 by delta x 1  delta g 2 by delta x 1  then delta g 1 by delta x 2 and delta g 2 delta x 2 so  the notation is sometime some people also use a notation this will be y 1 y 2 upon x 1 x 2 and so on  because whatever you have in a denominator  there would not to other notation for the jacobian also  and this should not be a 0 for all x 1 x 2 in the valid region so  this should be a non singular matrix and therefore  its determinant is not 0 now  this quantity we called a jacobian determinant here and then  the transformation is that means  when you wanted to find out the p d f of y 1 y 2 respect to p d f of y 1 y 2  then that can be obtained in terms of the p d f of x 1 and x 2 as this f x 1 x 2 now  here of course you will substitute for x 1 in terms of because you are able to solve x 1 and x 2 in terms of y 1 y 2 so  you can substitute that here this will be the absolute value these two lines indicate an inverse of the jacobian so  you have this matrix  compute this determinant and then  take in inverse and the absolute value  ok now  i will try to give you feeling about see what this says is that the fact that this is none you can see that if it was 0 p d f of f y 1 y 2 at small y 1 y 2 is defined  since the division by 0 is not permissible  but otherwise there is no point in talking of such transformations  where the jacobian is 0 and there are so  many ways you can interpret this concept of jacobian  but i will just try to show you now one aspect here  and that says that absolute value of the jacobian determinant at a point p gives us the factor by which the function expands or swings the area and bracket volume if you ’ re talking in three-dimension near the point p so  it will swing if the absolute value of jacobian is jacobian determinant is less than 1 and it will expand if the determinant of the jacobian is greater than 1 and near the point p so  if you are the coordinates that we are considering are x 1 x 2 and y 1 y 2 in the transformed plane  then near the point p in the transform space so  the area in the x y plane in the x 1 x 2 plane will get transformed to the area element of around the point p that means we are talking in terms of element of area around p in y 1 y 2 plane by the value determinant of the jacobian  refer slide time  11  00  let us consider this example so  x 1 and x 2 are jointly distributed random variables with f x 1 x 2 as their p d f and let y 1 be equal to x 1 plus x 2 and y 2 is x 1 minus x 2 so  we defined two new random variables as function of x 1 and x 2 so  this implies that your x 1 is half y 1 plus y 2 and x 2 is half y 1 minus y 2 so  jacobian if you want to compute  then it will be the derivative of this with respect to  so here when you differentiate respect to y 1  this will be 1 and differentiate respect to that means  differentiating x 1 with respect to y 1 and y 2 so  this is 1 and 1  then you differentiate x 2 with respect to y 1 and y 2  it will be 1 and minus 1 so  the value of this determinant is minus 2 and if you take the absolute value  it will be 2 and the inverse value of the inverse of the jacobian determinant of the jacobian and with absolute value will 1 by 2 so  according to this formula  our p d f for y 1 y 2 would be equal to half f of x 1 x 2 the p d f for x 1 x 2 when you substitute for x small x and small x 2 in terms of y 1 and y 2  so this is y 1 plus y 2 by 2 and this is y 1 minus y 2 by 2  right so  what i am trying to say which i said few minutes ago is that you know you can treat if you have to take a small element of area which is d x 1  sorry d y 1 d y 2 here in y 1 y 2 plane  this is d y so  element of area we treat this density as the probability density over d y 1 and d y 2 and here  if you look at this part  this will be the probability density over the element of area d x 1 and d x 2 and in this case of course since we are taking very small element of area  i can treat i can say that this is half times the density is the relationship between the two densities i am just trying to give you feeling about this anyway and then  you can see here if you take the particular case that x 1 and x 2 are uniform 0 1  both are distributed uniform and both are random variables  uniform random variables over 0 1 then  you see your transformation and if i am taking y 1 as x 1 plus x 2 and x y 2 x 1 minus x 2  then you see here this p d f of y 1 and y 2 by that formula would be half into 1 because the uniform that i am treating as independent so  i am taking 1 into 1  right the pdf of ` both the f x 1 and x 2 would be simply product of f x 1 into f x 2 so  both being uniform  this is 1 so  this is the formula you get and the range is y 1 plus y 2 varies from 0 to 2 so  you can get individual ranges which i have drawn here so  the area when you consider x 1 x 2 variable  this is the area  right and this equals 1 the area  right now  this gets transformed to this kind of region in y 1 y 2 planes  right if you draw this y 1 plus y 2 equal to 0 and y 1 plus y 2 equal to 2  which are these 2 lines and y 1 minus y 2 equal to 0 is this and y 1 minus y 2 equal to 2 is this line so  it is this area which you get so  a gets transformed to b and you see the area here is 2 units  this is 1 unit and 2 units and this is what i want to explain that since jacobian is a constant  therefore you see this probability density is same over the whole area and that is the feeling i want to give you so  the relationship between the two areas here because now that the jacobian is a constant so  therefore  the area a  which is 1 unit goes over to area 2 in the y 1 y 2 plane in other words  you can also say that because this density and into 1 so  when you integrate over the whole of b  this whole thing we should add up to should integrate to 1  alright which is half area b which is 1 so  area b is 2 and when you equate the 2 p d f ’ s for example  do this and integrate so  see this area if you just do this  this is 1  right and this area this area also has to be 1 where i am in the integral so  i am trying to say that this integral and this integral both  this has to be 1 and this must be 1  but this is related this half so  therefore  this will be twice this so  therefore  the density will turn out to be half so  therefore  this density will be half of this because this much add up to this integration must integrate to 1  this integrate to 1 if you just took the x 1 and x 2 variables and these values half  so this is equal to twice this so  therefore  the density for this one becomes half the density for x 1 and x 2 this is my own interpretation and i am trying to give you  refer slide time  16  40  now  consider when x 1 and x 2 are independent exponential random variables with respective parameter lambda 1 lambda 2  right and their wait i am treating  again i am treating them as independent so  therefore  with a same transformation that y 1 is x 1 plus x 2 and y 2 is x 1 minus x 2  then the p d f of y 1 y 2 by that formula would be because jacobian is again inject inverse of the jacobian is half and the determinant and this will be lambda 1 lambda 2 product of the 2 pdf ’ s for x 1 and x 2 with x 1 replaced by y 1 plus y 2 by 2 and x 2 replaced by y 1 minus y 2 by 2  and the limits here would be because x 1 goes from 0 to infinity  x 2 goes from 0 to infinity so  this will be this since they both are no negatives so  this is it so  now  you can compute the individual limits for y 1 and y 2 now  finally  if x 1 and x 2 are independent standard normal random variables  then you see this will be your joint would be because you are independent so  your joint anyway it will be 1 upon  what it is ? root 2 pi e raise to minus 1 by 2 and their standard normal so  simply x 1 square is for this thing and 1 upon root 2 pi e raise to minus 1 by 2 x 2 square now  sigma square is 1 mean is zero so  these are two individual p d f so  you multiply them so  that becomes 1 by a 4 pi 1 by 4 pi into 0 root 2 pi root 2 pi so  the half the jacobian is half and this product is 2 pi so  1 upon 2 pi into 2  this becomes 1 by 4 pi and then  this is e raise to minus half y 1 plus y 2 plus whole square by 4 y a because your x 1 is x 1 i am writing as 1 by 2 so  this should be  fl   so  1 by 2 and then  y 1 by y 2 4 whole square and then similarly  minus 1 by 2 x 2 square x 2 is y 1 minus y 2 by 2 so  the square gives me y minus y 2 whole square by 4  right and the variance of y 1 plus y 2 is 2 variance of y 1 minus y 2 is 2  right because again y 1 and y 2 are independent i have computed this for you  fine we will come to this conclusion later on let me continue with this so  now what i have done is i have written this expression y 1 plus y 2 whole square by 4 plus y 1 minus y 2 whole square by 4 see the coefficient here the half i have left out just these two terms so  then they add up 2 because the product term here will be 2 y 1 y 2 plus 2 y 1 and y 2 here  it will be minus 2 y 1 y 2 divided by 4 so  that cancels out and you get twice y 1 square plus twice y 2 square so  therefore  2 upon 4  that gives you half y 1 square plus y 2 square so  this whole thing reduces to e raise to minus 2  then y 1 square plus y 2 square by 2  right and then  i can again write 1 by 4 pi as 1 upon on the root 4 pi into 1 upon on the root 4 pi so  now i am saying that this is 1 upon root 4 pi into e raise to minus 1 by 2 y 1 square by 2 into 1 upon 4 root 4 pi e raise to minus 1 by 2 y 2 square by 2 so  you see the p d f here separates out into two single variable pdf ’ s so  i will conclude that y 1 and y 2 are independent and you see that therefore  the variance y 1 plus y 2 actually i can also compute the variance of y 1  right so  variance of y 1 plus y 2 is 2 why i am saying that variance of y 1 plus y 2  where am i concluding from here ? no no no no  this is a wrong statement that is why i am saying that this is not right yeah this is because x 1 and x 2 are independent therefore  i should have written variance x 1 plus x 2 is 2 variance of x 1 is 1  variance of x 2 is 1 and these are independent so  this is this similarly  variance of x 1 minus x 2 is also 2  right  refer slide time  21  55  so  therefore  y 1 when you are looking at  so y 1 is what y 1 is y 1 is here where did i define it ? yeah  y 1 is x 1 plus x 2 and y 2 is x 1 minus x 2 so  therefore  y 1 and we have all also seen that the sum of random variables is again normal so  here the mean is 0  variance is 2 so  y 1 is normal and y 2 is normal and therefore  this is accordance with because if y 1 is normal 0 2  then you are dividing by the variance square so  y 1 square by sigma square is 2 sigma square so  this is y 1 square upon 2 sigma square 1 upon root 2 pi into root 2 because standard deviation will be root 2 so  that becomes 1 upon root 4 pi so  this is all in accordance with this and therefore  you can say that a y 1 and y 2 are also independent normal variables and this happens only because you see that is why i took three examples for the same case i first took x 1 and x 2 to be jointly uniform and then  we wrote down the p d f of y 1 and y 2 so  what that come out to be simply this  right which you can not say it is constant in this area that is all so  from here it probably will follow that this is a uniform you think about it  but when you took the distributions for x 1 x 2 to be exponential  what you did not get is any separation here so  therefore  here you can not conclude that y 1 and y 2 are independent  but when you took the x 1 and x 2 to be standard normal independent random variables  then it turns out that x 1 plus x 2 and x 1 minus x 2 are also independent and normally distributed so  this happens for a normal distribution for when x 1 and x 2 are normally distributed independent random variables then  these functions will also be normally distributed and they will be i mean for x 1 plus x 2 and x 1 minus x 2 i am not claiming that this will happen for any functions of normal random variables  but in case when the functions are x 1 plus x 2 and x 1 minus x 2  then they turn out to be independent they will be normal yes  that of course we know from the property of normal distribution already we have seen it so  this is the case  refer slide time  24  41  let me continue with another example of a function of random variables so  here x 1 and x 2 are independent random variables  each exponentially distributed with parameter lambda so  now  with the question asked is  all the random variables u equal to x 1 plus x 2 and v equal to x 1 upon x 2 independent so  therefore  we will find the joint density function of u  v and see if it can be separated out into a function of u and a function of v so  like the jacobian or the jacobian is here  this is 1  the partial derivative or v is the partial derivative of 1 upon x 2 and minus x 1 upon x 2 square so  therefore  the determinant is equal to this which can be written like this  right now  compute to the inverse functions so  here for the second equation  you see that x 1 is v x 2 therefore  this now we substitute in this equation so  for x 1  that will be if you write it down that is why i am doing here so  if you write it for x 1 plus x 2 and x 1 is u into x 2  we just said that x 1 is v x 2 so  v x 2 if you write out here you do that and therefore  when you write x 1 as v x 2  so v x 2 plus x 2 so  x 2 outside 1 plus v  your x 2 becomes u upon 1 plus v then  from here you get x 1 is u v upon 1 plus v and if you write x 1 plus x 2  that comes out to be u well  that is already given to us it is simply a verification  fine so  then you will sub that is the formula gives you the joint pdf of f u v which is cobain inverse so  x 2 square upon x 1 plus x 2 absolute value of this which is equal to this and then  because x 1 and x 2 are independents  so the joint p d f is a product so  for each  the p d f is lambda into e raise to minus lambda u lambda x x lambda x 1 and then  lambda so  here it will be lambda times x 1 plus x 2 which we have which are given to be as u so  this is your p d f for and of course  you will substitute for x 1 and x 2 in terms of u and v so  you can immediately see that x 2 square is u square upon 1 plus v square and then  x 1 plus x 2 is u so  therefore  your final function is u upon 1 plus v whole square lambda square e raise to minus lambda u now  i was trying to see we draw the picture  but again see the reason for a x 1 x 2 is a whole of first quadrant  and it looks like that for u and v also because u and v are also both no negative and both are extending to infinity so  it appears that here since the regions are infinite  therefore  i can not show you any swanking or anything and in any case  this is dependent on the point so  this jacobian is not a constant here so  it will be dependent on coordinate values x 1 x 2 and so on so  therefore  i can not do much here  but you see now this and of course  your limits for u are from 0 to infinity and for v from 0 to infinity and now  you can write this down as a product of two functions so  lambda square e raise to lambda u into u is 1 and 1 upon 1 plus v square is the other function so  since i have and remember i gave you this proposition in the earlier lecture that if there is a p d f which can be written out separately as a function of single variables  then each of them must be p d f themselves for the corresponding random variables so  now i want you to verify y that the two functions represent the p d f that means  this is a p d f from 0 to infinity show that this integral is 1 similarly  this integral from 0 to infinity is 1  right which you can do by heat iterative integration here and they both are no negative so  therefore  we will conclude which i did not write here that u and v are independent so  i will now talk about exercises 5 which is you know collection of problems from whatever we have been discussing in 3 to 4 lectures  refer slide time  29  39  let see again as usual i will try to give you some small hints and you should be able to work out the problems in question 1  3 balls are chosen without replacement from an urn consisting of 3 white and 8 red balls so  x i equals 1 if ith balls selected is white so  you know you have first  second and third balls which are chosen without replacement so  if the ith ball is white  then you put x i equal to 1 and 0 otherwise so  give the joint probability match function x 1 x 2 so  again you will make that chart we have shown you  right you know rows will be before x 1 and columns will be before x 2 and then  you can write out for different values and then  i want you to write the joint probability match function of x 1  x 2 and x 3 so  now in this case  you will have to simply write three values because it will be x 1  x 2 and x 3  all of them right so  three-dimensional i have been discussing with you  two-dimensional so far so  i thought let me include this and let see how you try this problem question 2  the joint probability density function of x and y is given by this function e raise to minus x plus y x and y between 0 and infinity  then find probability x less than y so  now  this is a event that means the region so  you will draw the line  refer slide time  31  07  so  here it is simple this is this so  the whole of first quadrant is a valid region now  you want to find the probability so  it will be under this region x is other way this is x less than y sorry so  it will be this region  right so  therefore  fix your limits accordingly and you will be able to immediately write down the limits from here because x has to be less than y so  therefore  x can not vary from beyond y so  it will be 0 to y and then  y of course varies from 0 to infinity and then  a probability x less than a so  in the b you will have to find the marginal of x first and then  compute this probability  refer slide time  31  51  yeah  this is problem 3 now  problem 3 says you are given the joint density function of x and y  which is f x y 2 if 0 is less than x less than y  y is between 0 and 1 0  otherwise x and y are independent so  now  as i told you since the limits of x are dependent on y  my immediate reaction would be that now they are not independent  but you will have to find out the marginal  so that the joint is not the product of the marginal ’ s if x and y are given by this  a new function which is f x y equal to x into e raise to minus x plus y 0 then and if now the limits for x and y are independent of each other so  in this case  again you can break up your joint p d f into x into e raise to minus x into e raise to minus y so  therefore  they should turn out to be independent  yeah next question 4 says that two dice are rolled let x and y denote respectively the largest and the smallest values obtained compute the conditional mass function of y  given x is i for varying from 1 to 2 … .6 so  let me use fixed value of i of x and then  say are x and y independent why all these two answers ? so  you are quite familiar with now rolling of two dice and how you write down the probabilities so  therefore  you should be able to answer question 4 question 5  the joint probability mass function of x and y is given by so  this is now discrete set of random variables and you are given the probabilities here compute the mass function of x given y is i varying from 1 to 2 so  there will be two conditional mass functions one for when y is equal to 1 and other is y equal to 2 are x and y independent ? apply the condition for independence and compute x y less than or equal to 3  probability x plus y greater than 2 and probability x upon y greater than 1 so  here you see the values of y are not 0  anywhere y takes the values 1 and 2 and x takes the values 1 and 2 so  all questions are valid and you should be able to answer them  refer slide time  34  19  six is again you are given a joint density function of x and y and here you see it why varies between minus and x and minus x and x draw a region  find the addition distribution of y given that x is equal to x so  i have just included all these things they are different from each other  but then you get an idea when you solve these problems x and y have joint density function given by 1 upon x square y square x and y are greater than or equal to 1 compute the joint density function of u equal to xy and v equal to x by y it should be what the marginal densities are so  anyway joint these things  density function you will compute by using the jacobian method  right and then try to draw the regions because for x greater than 1 and y greater than 1  it is simply these things when you see this is 1 and this is 1 so  in the original thing  this is the region  alright and here  of course i can give you a hint because when u is equal to xy  so you will have to write x in terms of u and v in terms of y and then  you see that the v region  how the region is transformed so  do it because i have given you an idea already and you have to then compute the marginal densities of u and v  ok  refer slide time  35  56  so  eighth question eight is once should have been suffix  but does not matter let x 1 to x n be independent exponential random variables having a common parameter lambda through all of them comes in that means  they are observed value from exponential distribution with parameter lambda determinant  the distribution of minimum x 1 x 2 and x n so  this is what i have already discussed with you  right finding out the p d f of x bracket 1 that means the smallest to the n sample values if x and y are independent binomial random variables with ith  so we just make the correction with identical particulars n and p so  x and y are the same binomial distribution i mean the same binomial distribution show analytically that the conditional distribution of x  given that x plus y is m is the hyper geometric distribution there should be have been a full stop is the hyper geometric distribution also gives a second argument that gilds a result without any computations in the ninth problem you are given to a binomial independent binomial random variables with identical parameters n and p so  you have to find the conditional distribution of x  given that x plus y is m and you to show that this is a hyper geometric distribution and this again added this problem because i have already shown you a similar one i solved the similar problem in the lecture and also  gave a second argument that gilds a result without any computations so  the hint is given here and you can argue that is given a total of m heads is the number of heads in the first n flips has the same distribution as a number of white balls selected so  you figure out the hint and then  see if it is useful  ok  refer slide time  37  43  now  the tenth problem is random variables x and y are said to have bivariate normal distribution if the joint density is given by this so  here i have not discussed in the lecture  but i thought you should be able to work on this so  bivariate normal random variable distribution is of this form  where you have this squared term with respect to x with respect to y and then  you have the product term and of course  the rho part which will by the time you get to this problem  i think i would have discussed with you which is the correlation coefficient so  this is the expression  but anywhere right now this is a so  now you have to show that the conditional density of x  given that y equal to y is a normal density with parameters so  you see the moment you fix your y  then you can rear in the terms and write name in the form  so that this becomes a mean of the conditional variable that means  conditional density of x given that y is y and the variance will become sigma x square into 1 minus rho square so  it is just a question of you know manipulating the term and since  you already know what you have to show therefore  this is not going to be difficult  so that x and y are both random variables with respective parameters mu x sigma x square and mu y sigma y square so  here you see if x and y are 2 normal bivariate  then the joint density function is given here above and then  you can show that when you do the integration for when you integrate f x y with respect to y from minus infinity to infinity  you will get mu distribution with mean mu x and variance sigma x square and similarly  when you integrate with respect to x  you will get the a marginal of y which will come out to be normal with mean mu y and variance sigma y square  refer slide time  39  51  so  part c says that show x and y are independent when rho is 0 see now here if you look at the expression f x y  then by putting rho equal to 0 you see this coefficient on the root 1 minus rho square will become 1 then  1 upon 1 minus rho square will become 1 and the product term in the exponential will become 0 so  the joint density function will become product of marginal of x and y  right you can see immediately because i can write 2 pi as root 2 pi into root pi root 2 pi  then sigma x into e raise to minus 1 by 2 x minus mu whole square upon sigma x square into 1 upon rho root pi sigma y e raise to minus 1 by 2 y minus y mu y upon sigma y whole square so  it will become product of two marginal so  therefore  2 x and y by our theorem  x and y are independent and the converse is also true that of course if that i have talked about the converse  the actual thing is that if x and y are independent  then of course rho must be 0 that is what i am saying here  so that x and y are independent when rho is 0 so  here i am asking you to talk about the converse the theorem is that if x and y are independent  then rho must be 0 so  this is what you have to show and also  what i am saying is that the converse is true that means  if rho is 0 for a bivariate  a normal random variable  the x  y being a bivariate normal distribution having a bivariate normal distribution then  if rho is 0  we can also show that x and y are independent so  we will discuss in lecture 17 also and then  later on i will show you that the covariance of a bivariate normal random variable  where x  y is given by rho so  this we will discuss much later in lecture 23  refer slide time  42  16  see in part c of question tenth  we have to show that x and y are independent when rho is 0 so  what i have we have said so far is that if eleventh problem  the joint density function of x and y is given like this and here  x varies between 0 and 1 and y varies between 0 and 2 first question is x and y are independent ? yes  you can answer because the limits are separate and the joint p d f can be separated into x into y  but i would like you to find out so  anyway you are finding out the density function of x  the density function of y and then  find the joint distribution function so  you are asked to find the cumulative distribution function and then  find e y and find probability x plus y less than 1 so  again this is i have just included this as an exercise that you get more familiar with how you work out these different integrals  refer slide time  43  51  this is another problem number 12 the p d f random variable x is shown below this is a single one find density function of 1 upon x so  this i have included because i thought we have not discussed many functions of a single random variable so  therefore  find the density function of 1 upon x  e raise to x  ln x 1n x is again the log with base e and a x plus b again  it is simply an exercise to get familiar with you know how you find the limits and so on the ranges for different functions and so if x 1 and x 2 are independent random variables with same probability distribution function as x  find the probability distribution function of x 1 upon x 2 and x 1 x 2 so  you may feel that somewhere other things are repeated it does not matter as much as practice as you can to get a good feeling about how you handle this introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture no  16 order statistics covariance and correlation  refer slide time  00  15  so  we showed that covariance of x and y is 0  but then and of course by definition also it was clear that x and y are not independent  but we can also show analytically ; and that is see just consider this conditional probability x equal to 1 and y equal to 0  given y equal to 0 so  probability  conditional probability x equal to 1  given y equal to 0 so  it will be equal to probability x equal to 1  y equal to 0 divided by probability y 0  y equal to 0  but this is by definition it is equal to probability x equal to 1 and then here it will be probability x equal to 1 plus  probability a cumulative distribution function because probability y is 0 ; so should be not yes so  this is y 0 when x is not 0 so  x is 0  x is not 0 ; that means  x is value 1  and x is value minus 1 so  therefore  this is 1 by 3 divided by 2 by 3 which equals half  but this is not equal to probability x equal to 1 see  if x and y are independent this conditional probability should have been equal to probability x equal to 1 ; so therefore  x and y are not independent  refer slide time  01  32  in the last lecture  i defined covariance and then i also defined the correlation  and just tried to show you that correlation is nothing but the dimensionless version of covariance ; and now here  a few more examples of or uses of a covariance so  you saw that when you wrote variance x 1 plus x 2  the formula was variance x 1 plus variance x 2 plus twice covariance  x 1  x 2   so  in general  if x 1 and x 2 are not independent then i afford to compute the variance of x 1 plus x 2  i need covariance  x 1  x 2   right and  in general  if you take it  if you take sum of n variables and you want to compute the variance  then by the formula it would be because again the property that we defined for the variance  you can just apply them iteratively ; and this will be sigma i varying from 1 to n  variance x i  right because it will be covariance of x 1  x 1  x 2 comma x tends to 1 and then the product terms where x i and x j are different ; i and j are different so  this will be equal to twice sigma covariance  x i  x j  if you put i less than j  because remember for the covariance also we said that covariance  x i  x j  is the same as covariance  x j  x i   so  if you impose this  i less than j  then it will become twice because covariance  x 2  x 1  i will write as covariance  x 1  x 2   so  then it will become twice this ; or you can write this as summation i j where of course  you have to say that  i is not equal to j  then it will be covariance so  whichever formula suits you  you can use that so  this will be covariance  x i  x j  simply ; without the two if you simply summing over all possible values of i and j  so that  i is not equal to j  right now  interesting  again an example to show you that how you can make use of these properties that we have enunciated for covariance so  consider the multinomial distribution  remember they were n objects and then they were k categories  multinomial distribution with k categories so  then probability of  success in 1 categories p 1  p 2  and p k ; and we have already discussed this distribution and we saw that the probabilities for successes will behave like binomial so  for example  in category 1 it will be binomial n p 1  it will be binomial n p 2  and so on so  this is how you defined the  multinomial distribution  p vector  where p vector is p 1  p 2  p k so  these are the probabilities of being a particular category which means  success in the first category  so on so  now if you want to compute covariance  x i  x j  for any i  j  then for  i equal to j  it will be the covariance  x i  x j  will be covariance  x i  x i   which is we know is variance x i ; and since each  x i  is binomial and n p i  x i  is binomial n p i so  we know from the binomial distribution formula that the variances  n p i into 1 minus p i  right now  for  i not equal to j  we want to compute covariance  x i  x j   so  let just do it for x covariance  x 1  x 2   so  the question asked is what do you expect ; should this be negative  covariance  x 1  x 2  ; see  the idea is that now after having defined correlation also  we see that this measures the linear relationship between ; and of course  we still have to talk about kosis law of equality and so on so  anyway the expectation is that this will be negative  why ? because  you see if the total number of objects is fixed which is n  right  now if large number of people or objects are in x 1  then accordingly x 2 the number will not be that large so  there will be negative correlation or negative relationship between x 1 and x 2  and that is what covariance will measure here so  and we will see after computation that it actually comes out to be a negative number so  variance  x 1 plus x 2  is variance  x 1  plus variance  x 2  plus twice covariance  x 1  x 2  which we wrote down earlier now  it turns out that we can compute these 3 things because variance x 1 is n p 1 into 1 minus p 1 plus  variance x 2 is n p 2 1 minus p 2 ; and x 1 plus x 2  again we had seen that when you merging 2 binomials like n p 1 and n p 2 then the sum will behave like a binomial  n  p 1 plus p 2   so  there must have  you must have done some exercises also or you can just sit down and obtain this result for yourself so  therefore  variance for x 1 plus x 2 would be n times p 1 plus p 2 into 1 minus p 1 minus p 2 ; and so from this relationship it is this quantity that we want to compute so  therefore  2 covariance  x 1  x 2   will be  just take this to this side  so n p 1 plus p 2  i am just opening up the bracket so  n  p 1 plus p 2  minus n p 1 plus p 2 whole square which you can write as  i do not why i have written it as so  this is plus  right ; plus 2 p 1 p 2 and then  you see the terms will cancel out because p 1 square plus p 2 square ; you see here this is n p 1 plus p 2 and this is minus n p 1 plus p 2 which cancels out  right ; and then plus n p 2 square plus n p 1 square and minus n p 1 square plus p 2 square so  everything cancels out ; you are left with  minus 12 p 1 p 2 so  therefore  this is less than 0 because p 1 p 2 and n all are positive cumulative distribution function 0 so  the covariance ; and so once you know that the covariance  x 1  x 2  is minus n p 1 p 2  you can immediately conclude that covariance  x i  x j  will give minus n p i  p j so  this was made possible because of this formula which was again written down using covariance and now for this multinomial distribution you can immediately write down the formula for a covariance  x i  x j  as this  cumulative distribution function ; relation coefficient also which will again turn out to be negative because the correlation coefficient will be simply this divided by standard deviation of x i  and this will be standard deviation x j  which we already know  right  because it will be n into p i 1 minus p i under root  and this will be n into p j 1 minus p j under root so  therefore  this computation has become so simple  refer slide time  08  57  in the example where we took x 1 to be x  and x 2 equal to x square  and i said that probability x equal to 1 is equal to probability x equal to minus 1 is half then we saw that expectation of x and it was equal to expectation x cube was 0 and therefore  you could see show that covariance  x 1  x 2  where x 1 is x and x 2 that x square is 0 now  actually what you can  you can always show this if whenever x 1 that is x is normal 0 sigma square ; that means  expectation of x is 0 ; and or x 1 has any other distribution which is symmetric about 0 because you saw that x here is symmetric about 0 so  probability  x equal to 1  is equal to probability  x equal to minus 1  is half so  this is symmetric about 0 so  now if i take  instead of this if i have taken a distribution of x to be normal 0 sigma square or any other distribution which is symmetric about the origin  then you can show that covariance  x 1  x 2  is 0 so  therefore  you can construct so many examples where covariance is 0  between 2 random variables  but they are not independent because there is a definite quadratic relationship between the 2 and so knowing one value  knowing value of one you can predict the value of 2  second variable exactly and therefore  this is what you want to  sort of through this example i thought we can show you and emphasize this fact again that covariance 0 just says that the 2 variables are uncorrelated  but their need  they need not be independence so  independence goes much deeper than that now  very interesting inquality and very powerful one which we can show  see right now ; if their expectations exist then this is the inequality ; that means  expectation of x y square  expectation of x y square  sorry  expectation x y whole square 1 minus of 1 minus r 1 t into 1 minus r 2 t so  the same principle will be used and you can show that expectation y square and  equality holds  if i know only if for some constant  a  y is a x ; that means  there is a linear relationship between x and y so  if x and y are linearly related then the kosis words inequality would be satisfied as equality  otherwise it will be restrict inequality so  now we are  in this we are assuming  let us see  y square  is a positive value random variable so  expectation y square can be either 0 or positive  right now  if it is 0 ; so we are assuming that expectation y square is positive because if it is 0  so when can expectation y square be 0 because y square again is a positive random variable so  it will take only positive values  and so when you write the expectation it will be possible values of y square into the probability with which it takes its values so  therefore  that will be positive sum so  that can not be 0 unless y is 0 so  that is clear so  therefore  if expectation y square is 0  it will imply that y is a 0 variable  y takes only 0 value  and then this inequality will be satisfied because if y is 0 this is 0 and this is 0 so  both sides you have 0  and so the inequality satisfied is equality so  therefore  it is safe to assume ; i mean  there is no harm in  no loss of generality i take it to be  refer slide time  12  43  so  f x j x will be j n c 1  f x  f x raise to j minus 1  1 minus f x raise to n minus j now  we can compute the p d f for x 1  the first order statistics independently  and then we can confirm that the  what we have obtained follows by this formula also so  let us consider the probability of x 1 less than or equal to x so  then the compliment of this event will be probability x 1 greater than x  right ; this is less than or equal to x  so then here it will be  x 1 greater than x  the compliment now  if this smallest statistic  the smallest or the statistic is greater than 1 it implies that all the statistics must be greater than x so  x 1  x 2  and x n  and all must be greater than x so  the 2 events are equivalent  and therefore  i can say that the probability x 1 greater than x is equal to 1 minus of f x raise to n  right ; because the probability for this is 1 minus or for any x  for any x i greater than x  the probability is 1 minus f x and therefore  since all of them have to be greater than n so  this is 1 minus f x raise to n  right and then  so therefore  i can write the cumulative distribution function for x 1 ; and this should be  x ; f x 1  x  will be 1 minus of this ; 1 minus of x 1  x 2  and x n  all greater than x  right and therefore  this will be 1 minus of 1 minus f x raise to n because this is what you have here ; and this is equivalent to  or for x 1 greater than small x  and then implies all these are greater than small x ; and therefore  this is the event  right and so when you differentiate both the sides you get f x 1  x  as n ; then minus minus becomes plus and the derivative of this is f x  and this is 1 minus f x raise to n minus 1 so  if you substitute  j equal to 1  here this will be 1  and ; this should have been n c j so  n c 1 which is n  then f x ; and this of course  j is 1  so 1 minus 1 is 0  no contribution  then 1 minus f x raise to n minus 1 ; so the 2 match 0  because t is a real number  so therefore  this is satisfied  refer slide time  15  22  now  if it is equal to 0 then e x plus t y whole square is equal to 0  if and only if e x y because  that means  that this equation is satisfied as equality  equal to 0 then the discrepant must be equal to 0 so  this is it  right so  this is one part and  now we have to  we want to show that under  for what value of t this will happen so  you see from here because x plus  expectation of x plus t y whole square is 0  this as we have argued earlier  the random variable itself must be 0 with probability 1  right ; x plus t y has to be 0 because otherwise its expectation can not be 0  right so  now  the thing is that from here itself you can say that we can compute the value of t which makes this happened  right ; which makes the discrepant equal to 0 but  as you see  if i do it here  if i take the expectation  here it will be e x plus t ; and let us say the value of t naught  t which is a t naught we are looking for so  this is equal to 0 so  from here we say that y can not be compute the value of t naught  but you see i can not guarantee about e y being non 0  right and so therefore  i can not compute the value of t naught from here so  what we do is if we multiply by this y  then again x y plus t y square is a 0 random variable  right  because this is 0 and so now  if i take the expectation  so this will be 0 equal to expectation of x y plus t y whole square and so then from here when you are doing expectation inside this will be t naught is expectation x y upon p y square so  therefore  kosis words inequality is satisfied as equality  if and only if  right ; if and only if x can be written as  this is t naught so  from  since this is now 0  i have computed the required t naught so  this will be x is equal to minus e x y upon e y square into y now  this is a linear relationship between x and y so  kosis words inequality is satisfied  whenever x and y are related linearly ; and this is the constant which relates x and y  right and  we will see the implications of this now  using kosis words inequality we can prove following properties of the correlation coefficient rho ; and so for any  x 1  x 2  any 2 random variables we will first show that your value after correlation coefficient lies between minus 1 and 1 ; and this is what we meant by standardization and  because covariance  the only difference between correlation coefficient and covariance is that you divide covariance by the standard deviations of x 1 and x 2 ; and then you get a standardized quantity and so this will be between minus 1 and 1 ; and if it is 1 then they are positively related for x 1 and x 2 ; and if it is minus 1 then they are negatively related so  we will just go through these properties in a few minutes  refer slide time  18  59  in the kosis words inequality  replace x 1 by x 1 minus expected x 1  and x 2 by x 2 minus expected x 2 so  then the inequality would look like expectation of x 1 minus e x 1 into  sorry  expectation of the product  x 1 minus e x 1 into x 2 minus e x 2 ; this whole square  is less than or equal to  expectation of x 1 minus e x 1 whole square and expectation x 2 minus e x 2 whole square  right because the kosis words inequality we obtained for any 2 random variables x  y so  here i can replace the variables x by x 1 minus e x 1 and y by x 2 minus e x 2 so  this is valid  right and  so which means that  which reduces to covariance  x 1  x 2  whole square is less than or equal to variance x 1 into variance x 2 so  kosis words inequality really simplifies proving these properties of the correlation coefficient so  but this is nothing but if you divide this by this then it says that covariance  x 1  x 2  whole square divided by variance x 1  variance x 2  is less than or equal to 1 so  if i take the square root then  a positive past of the square root then this will be less than or equal to 1  right so  with the  so for absolute value of the correlation coefficient is less than or equal to 1 so  the first property is easily proved using the kosis words inequality and now  you want to show that if it is satisfied as it quality ; and remember in the  when we proved the kosis words of inequality we showed that x will be equal to expected x y upon e y square into y so  this was it now  here i have replaced x by x 1 minus e x 1 and y by x 2 minus e x 2  and here to so this becomes so  therefore  this will be because of our transformed variables this is x 1 minus e x 1 is e of  expected value of x 1 minus e x 1 into x 2 minus e x 2 upon sigma square x 2  and this is x 2 minus e x 2 so  this is the linear relationship between x 1 and x 2 but  this quantity you can see is the covariance  and then you write  you need variance of standard deviation x 1 into standard deviation x 2 so  this will come here so  you know  just rewrite this expression so  1 sigma x square i keep here  the other is here ; now here i am dividing by sigma x 1 ; so i multiply ; and therefore  this is what i get now  this quantity ; i did not say here so  the 2  part 2 was we had to show that rho is equal to 1 so  we start with this so  if i start with this then in the kosis words we said that if it is satisfied as quality then we get this relationship which then the minus e x 2 and so just divide by sigma x 1 here so  therefore  this would be ; so we said that if ; so that means  you are just getting the specialized linear relationship ; you can write it little differently ; the same thing here we can write in this way because we are saying that rho is equal to 1  right so  then you can predict the actual relationship  till actual linear relationship between x 1 and x 2  if you and  similarly if rho is equal to minus 1 then there will be a minus sign here ; the same analysis will be done  right so  this is what we are trying to say is that  you know  your quantity rho is correlation coefficient ; is measures the linear relationship nicely ; it captures the relationship  linear relationship but it fails to show you the relationship when it is a quadratic or it is non-linear  and rather i should just say that when the relationship between 2 variables is a non-linear  then it fails to so  being 0 does not help you  right so  therefore  that means  you can not conclude that other variables are independent if the covariance is 0 so  now let us take this special case  and show you that in  when the 2 variables are normally distributed then you can show that the variables being uncorrelated implies independence  and the other way of course  the other way you know  if 2 variables are independent then certainly the correlation coefficient will be 0  but we will show it the other way ; that is if the correlation coefficient is 0 then the variables are independent ; and this is valid true for a normal distribution only  refer slide time  24  14  so  here just look at the bivariate normal distribution so  bivariate normal distribution you have the means are mu 1  mu 2 ; variances are sigma 1 square  sigma 2 square ; and the correlation coefficient is rho so  the expression for the p d f for a bivariate normal distribution is 1 upon 2 pi sigma 1 sigma 2  under root 1 minus rho square and therefore  you see this is valid because rho we have just shown is between minus 1 and 1 ; the absolute value rho is less than or equal to 1 so  and then exponential e raise to minus 1 upon 2  1 minus rho square ; then x 1 minus mu 1 whole square upon sigma 1 square plus  x 2 minus mu 2 whole square upon sigma 2 square minus  2 rho into the product term divided by sigma 1 sigma 2 so  this is the expression for a bivariate normal distribution  right so  the proposition is that if x 1 and x 2 are independent or x 1 and x 2 are independent  if and only if they are uncorrelated so  this is what we can finally establish after giving you so many examples where un-correlation or uncorrelated did not mean independence so  if rho is 0 then you can see immediately from here this expression simplifies  this becomes 1  this is also 1 so  it will be 1 upon 2 pi sigma 1 sigma 2 ; then e raise to minus 1 by 2  right ; and x 1 minus mu 1 upon sigma 1 whole square plus  x 2 minus mu 2 upon sigma 2 whole square ; this term is not there anymore so  now you can immediately decompose this e raise to this so  therefore  you can write this as product of 2 so  here it will be 1 upon root 2  say  2 pi i i can write 1 upon root 2 pi sigma 1 ; then the x 1 term  you know  put together here ; and the x 2 term is this and  you can see that these are 2 p d fs ; and each of them say  this is normal mu 1 sigma 1 square  right ; p d f separate p d fs  and each is normal so  therefore  in fact  so much simplification here  right the moment you say that they are uncorrelated  then they are also independent by our definition  right if the product of  if the joint p d f can be written as the product of individual p d fs or the marginal p d fs then it will be said that the variables are independent so  therefore  and so if and only if part gets proved because rho 0 implies independence  and of course  independence implies that rho is 0 so  therefore  the proposition is established ; that is if x 1 and x 2 are independent then they are  if and only if they are uncorrelated  provided x 1 and the joint p d f of x 1 and x 2 is a bivariate normal distribution so  you can see how we are relating the result that we are getting ; and then of course  all these simply  finally gets used  and you know  estimating lot of probabilities that are useful to you  refer slide time  27  41  so  in the sum i am just discussing the exercises 6 which i will be discussing at the end of this lecture so  there is a question that i have posed there  and i have asked you to show that correlation coefficient can be written as  rho x y  variance x plus  variance y minus  variance x minus y  upon twice under root of variance x into variance y so  essentially what i am saying is that the covariance  x  y  can be written as variance x plus  variance y minus  variance x minus y divided by 2  because  this anyway figures in the definition of rho  x  y   so  this answer is straightforward you start with variance x minus y  and so that will be x minus e  x  minus  y of minus e  y  whole square  expectation of this whole square  right and  open up the brackets ; so this will be expectation of x minus e  x  whole square plus  expectation y minus e  y  whole square  and minus twice product term expectation of x minus e  x  into y minus e  y   right and this can be ; so this i can bring to this side ; so therefore  immediately you have variance x plus variance y  minus variance x minus y is equal to this ; but this is nothing but your covariance so  in fact  now you can divide this by  rho x rho y  and 2 you can take to the other side so  it just because see  what happens is that all these different expressions for the same thing that you keep using are handy  sometimes it helps to  because you know these where values  because you  from the known standard distribution of these variables ; then you can immediately write down the correlation coefficient now  again see  by theme now here has been to show you as many examples as possible about  you know  the covariance other or the correlation coefficient being 0  but variables are not independent and  you can see how  you know  contrived them a look at these examples  but they make a point so  now  here x is normal 0 sigma square  and suppose y is independent of x so  x is normal distributed 0 sigma square  and y is independent of x ; and the probability y equal to 1  equal to y minus 1  is half so  therefore  and this imply that your expectation y is 0  right ; if probability y equal to 1 and y equal to minus y is half then your expectation y is 0 now  define another variable z which is equal to x  y so  you see  immediately from here probability z equal to x is half  and probability z equal to minus x is also half because y is either 1 or minus 1  right now  if you compute  probability z less than a  then this will be x less than a ; and that is with probability half  right ; because z is equal to x with probability half  and then x is equal to minus x so  if you are writing ; so you will be writing  z less than or equal to a  which is minus x less than or equal to a so  this is equivalent to  x greater than or equal to minus a  right so  that is what i have written  probability x greater than minus a  into half but remember  x is normal  normally distributed ; and if x is normally distributed it is a symmetric about the origin  and so x less than a  and x greater than minus a  are the same probabilities now  if you can carefully see  you see  in the normal because 0 sigma square so  therefore  if you take this thing here  so let us say  this is  take a to be positive and that is the same thing ; and this is minus a so  x less than a  is  you see  from the normal thing  this area and this area are the same  right so  x less than a  is this all probability ; and x greater than minus a  is this which are the same  right ; because a tails these values are the same ; therefore  this area and this area are the same  right therefore  this event is the same as  x less than a ; and though therefore  this follows from the x being symmetric about the origin and so again it is not necessary here that they should be normally distributed because i think anything which is symmetric about the origin would have done the job  right so  therefore  this is that ; and so this is equal to ; i should have put it here so  from here it follows this is probability x less than a so  that means  z and a  z and x  have the same cumulative density function from the same c d f which implies that they have the same p d f also so  x and z have the same c d f  and they have the same p d f  right  refer slide time  32  51  now  if you compute the correlation coefficient between x and z  that should be expectation  x z  minus e  x  into e  z  upon sigma x into sigma z but  e  x z  is expectation x square into y  and your e x and e z so  e x is 0  and therefore  e z will also be 0 because this is normal so  that means  you need a distribution which is symmetric about the origin so  therefore  then its expectation will also be 0 so  you therefore  i do not think you need this x to be normally distributed  fine so  then this part is 0  and this is e x square y  because x  y ; and x and y being independent this is e x square into equal to e  y   right but  e y is also 0  remember ; y is again symmetric ; y is 1  and y is minus 1 so  with probability half  both the values have equal probability so  e  y  is 0 so  e  y  being 0  you get this as 0 so  therefore  the correlation coefficient i 0  but x and z are completely dependent by definition as we saw  right ; x and z are completely different these things because they have the same c d f  they have the same p d f  but still they are uncorrelated so  this is ; again  you know  i am just  wherever i get these kind of examples i just thought i will bring them to you to show you the  ok and  so right now we have said reasonably good amount joint probability density functions which was the  so more than 1 variable ; then we talked about how we can obtain joint density functions of more than 1 variable  refer slide time  34  25  now  let me talk of order statistics ; so you know further application of the same concept so  see if you have a sample of size n  random samples  so x 1  x 2  x n  are the observed values ; and the c d f  they are coming from the same distribution  so you can say these are also identically independently distributed random variables because it is a random sample so  c d f is ; that means  the cumulative density function is denoted by f  and the probability density function is denoted by small f so  when you order the observation  so this will be smallest one so  therefore  this will be the notation ; so x 1 less than or equal to x 2  less than or equal to x n so  this is the order arrangement of the n sample values that you obtained  ok now  so the question arises  can we find of course  one would want to talk about the joint density function of all x 1  x 2  x n  and in particular you would want to find out the density function for the p d f so  either both of them are continuous or both are discrete  this is when we are defining the conditional expectation  refer slide time  35  47  so  the nature of the 2 variables should be same in the sense that either both are continuous or both are discrete  right so  then the definition is of course  straightforward because now x is equal to x  so this is fixed ; this is given to you so  now  you have to find the expectation of y  given x equal to x  would be from minus infinity to infinity  y times f conditional distribution of y  given x so  this would be the definition this is the case when  x and y  both are continuous and  in the discrete case  it will be  the summation will be for all x for which p x  x is greater than 0  because remember this conditional p d f will have p x x in the denominator so  therefore  we will only consider summation to those x for which this is positive ; and then of course  probability y  given x  for all y for which this is positive because otherwise the product will be 0 so  under this condition you can for the discrete case  when x and y are both are discrete  you can define the expected  conditional expectation by this formula  refer slide time  37  00  so  we will start from the  take this example of a discrete case  where the joint density function is given as probability x equal to x  and y equal to y so  even from this table you can immediately see  now x equal to 1 and y equal to 1 so  this is the probability so  you can read the table so  this is 1 2  1 3  1 4  and so on  right and  you see when you add up these probabilities  they give you what ? they are the values of x equal to 1  x equal to 2  x equal to 3  x equal to 4 so  you immediately get the probability for y equal to 1 so  therefore  when you add up these rows  the numbers give you the marginal p d f of or probability mass function for y  right so  this point 2 is the probability when y is equal to 1 similarly  y equal to 2 because the possible values of x are 1  2  3  4 so  when you add up these probabilities 1 2  2 2  3 2  and 4 2  you get the probability of y equal to 2  so that adds upto 0.5 and this is  similarly probability y equal to 3 is 0.3  and these 3 must be add up to 1 similarly  here when you add up the probabilities of  the conditional probabilities  x equal to 1  and y varies from 1  2 and 3  they will give you the marginal for x so  this will be the probability x equal to 1  this will be the probability x equal to 2  x equal to 3  and x equal to 4 ; and they also add up to 1  right so  now from our definition  see i am writing f where it should be ps  but does not matter because the discrete case we are used to habit of writing the p in terms of ps  the probabilities  so does not matter but  you see now here you can immediately find out probability  conditional probability of x when y is 2 so  conditional probability x 1  y is equal to 2 so  for example  here when you want to compute conditional probability of x equal to 1 given y is equal to 2 so  calculations are simple ; y is equal to 2 is given ; you are given by this  right ; and so conditional probability so you will divide by a probability y equal to 2 which is divided by the standard deviation of x 1 and standard deviation of x 2 ; y is equal to 2 is 0.1 divided by 0.5 which turns out to be 0.2 similarly  conditional probability of x equal to 2  given that y is equal to 2  will be this joint density function of x equal to 2  y equal to 2  divided by the probability of y equal to 2  which is 0.5 so  again 0.1 upon 0.5 is point 2 ; and similarly the other 2 computations and  if you remember  i have not analytically proved it  but we should be able to  maybe that is what we should do next time so  here in any case you see these probabilities also add up to 1  as they should because this is now the  you have got the conditional which is also a probability mass function ; and therefore  the probabilities here should add up to 1 so  it is 0.4 which is then 0.54 ; and so 0.54 plus 0.46 is 1 so  you just do verification  right so  now we want to define the  compute the expectation value of x given y is equal to 2 so  i mean you just take the definition that we wrote down so  here the marginal ’ s are given to you ; point  now this is be 1.4 so  the expectation here would be when x is equal to 1 then the probability that you obtained ; i am computing it for y equal to 2  sorry so  we have computed these probabilities so  when x is equal to 1  so when you are computing this expectation y is equal to 2  so then it will be value of x equal to 1 into  the probability that you get ; the probability match function when y is 2 and x is 1  right is it ok ? so  the expression that i wrote down  see here it will be  you are computing see y is fixed so  you are computing the expectation of x  given y is equal to 2 so  as x takes different values  given y ; so you will multiply by the corresponding probability when x is ; for example  x is 1 and y is 2 so  x is 1 and y is 2 ; this is the probability when x is 2  and given y is equal to 2 then this is 0.2 so  we will take those probabilities  the conditional probabilities  and multiply by the corresponding values that x takes  right so  the conditional probability are here ; this is this ; 0.14 is this and 0.46 is this so  i multiply by the corresponding values that x takes ; and therefore  this is 2.28 in fact  i am going to talk some more in terms of the functional aspect of expected value of ; in other words  in fact  we can sit here when i am talking of expectation of x given y equal to  y equal to small y so  you see  because you are taking expectation with respect to x  so then you will be  this will turn out to be a function of y so  i start giving important example  but we will discuss this in detail in the next lecture so  this will be a function of y because you have taken expectation with respect to x so  that part is gone ; x part is gone ; it is no longer a function of x  but it will continue to be a function of y  right and then we will see what kind of relationships we can predict on what  how we can use this so  but initially through this example i just want to show you how you go about computing these conditional expectations ; this is the whole idea so  similarly you can compute the expectation of x  given y is equal to 1 so  now i did not do this detail calculation here  but you can see that when you wanting to compute for example  here x is 1 and then given y is equal to 1  so x is 1 you will be writing that probability so  i will divide 0.02 by 0.2 because y is equal to 1 so  y is equal to 1 is this see  you simply have to  just as we computed the probabilities for  conditional probabilities for x equal to 1  given y is equal to 2  i simply divided these numbers by the corresponding probability  y equal to 2 so  here also  when y is equal to 1  you divide these probabilities by this  and you get the conditional probabilities of x equal to 1  y is equal to 1 and here  0.06 divided by 0.2 will give you the probability that x is to  conditional probability x is equal to 2 and y is equal to 1 so  this way you can show so  this know  so that is what all i have done ; i have divided this by 0.2 so  then i have written it as 0.1 into 1 ; so computing the conditional expectation ; so multiply by 1 then  similarly 2 times 0.06 divided by 0.2 and then  3 ; so 0.08 divided by 0.2 ; and then 0.04 divided by 0.02  and 4 into that  right so  that number comes out to be 2.7  right and  in the same way  you compute the expected value of x  given y is equal to 3 so  here i will take 0.07 divided by 0.3 into 1  and 0.03 divided by 0.3 into 2  and so on so  you will compute those expectations and now  as i am saying that if you take this expectation ; and yes  this i have just now written down this expression ; we will spend lot of time on it  trying to show you but  computationally you see  if i now want to compute the expected value here  as i told you  this is a function of y  right so  when you want to compute expectation through conditional expectation of x  y  given equal to y  then all i have to do is to multiply by this corresponding for example  2.7  i will multiply by the probability that y is equal to 1 because this is the conditional expectation of x  given y equal to 1 so  i will multiply by ; so you can treat this as a function of y so  this into the probabilities that y takes the value 1 so  that will be 0.2 into 2.7 similarly  this will be the condition ; this is the conditional expectation of x  given y equal to 2 so  this is again will be 2.88 into probability that y is equal to 2 which is 0.5 ; so 0.5 into 2.88 and similarly  here a probability that y takes the value 3  and that into the expectation  here conditional expectation so  this number comes out to be 2.82 and  we can verify that this is actually equal to e raise to x because this is the marginal density of x so  to compute the expectation of x  i will multiply 0.19 into 1 plus 0.19 into 2 plus 3 times 0.23 plus 4 times 0.39 which again gives me the number 2.82 so  the 2 numbers are equal introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  17 covariance correlation cauchy-schwartz inequalities conditional expectation  refer slide time  00  15  there order statistics so  let us just begin with the first one so  if you want to find the density function so  cumulative  we will start with c d f  because once you have obtain this  we can obtain the p d f also so  here f x j is the c d f for the j x order statistic so  which means and so  the value f x j x means that this is the probability of x j being less than or equal to x and what does this mean  if this is the j th order statistic ; that means  up to 1 2 x 1 x 2 up to x j  they should all be less than or equal to x at least so  at least j of the x 1 x 2 x n should be less than or equal to x more can be less than x  but at least i am saying  i am co computing the probability that x j should be less than or equal to x ; that means  at least j of x 1 x 2 x n should be less than or equal to x so  now i can write  since it is at least  so it can be j j plus 1 j plus 2 which are less than or equal to x so  therefore  this probability can be written as summation i varying from j 2 n though probability of exactly i of x 1 x 2 x n are less or equal to x so  should be clear so  therefore  this implies that i can write this probability as n c i  because out of the n  you are choosing i  any of the i can be less than or equal to x n c i  and then this is f i x  because i of them you want to be less than or equal to x so  this is this into 1 minus f x so  the remaining n minus i are greater than or equal to x so  because exactly i of them are less than x  so therefore  remaining n minus i are greater than or equal to x so  therefore  this will be the probability of that so  you are summing this up and now let us give it more concise form so  because this is of course  very unwieldy you can not so  now consider the integral  and this is way you look see how we can relate  you know summations with integrals and so on so  consider the integral j n c j 0 to f x t raise to j minus 1 1 minus t raise to n minus j d t  and let me call this integral i of j minus 1 so  this index and n minis j index of 1 minus the power of 1 minus t now if you integrate by parts  so integration by parts will give here let me treat this as the first function so  integral of this will be j upon t j upon j then 1 minus t is to j minus j  this computed from 0 to f x plus n minus j upon j 0 to f x t j and derivative of the second function so  the derivative would be n minus j 1 minus t raise to n minus j minus 1  so this is what you get by integration by parts so  here of course  at 0 this is 0 at f x it will be so  here i have written also the j part see this j cancels out  because both the terms have j in the denominator  refer slide time  03  32  so  this cancels out  and you are left with n c j f j raise to x 1 minus f x is to 1 minus j plus when you come to the integral this will be n minus j into n c j n minus j i of j n minus j minus 1  because j here this was j minus 1 this is minus 1 this was n minus j this is n minus j minus 1 now  very nicely you can simply just write down this expression and this  and manipulate the terms and you can immediately see that this whole this can be written like this ; j plus 1  and therefore  this will then become well the whole thing why did i write  because my i j is together so  therefore  i do not have to write this term this is note there because i am trying to say that  you manipulate this  even this is not correct i should have written the integral here only so  let me just say this is not correct let me write continue writing the integral and j so  what are we getting here ; 0 to f x 0 to f x t raise to j 1 minus t raise to n minus j minus 1 d t  and then i am saying that you manipulate this and you can write this as so  let me rewrite this  i am writing as  because now you need j plus 1 n n minus j n minus j minus 1  0 to f x t raise to j 1 minus t raise to n minus j minus 1 d t so  this whole thing can be written as i of j n minus j minus 1 so  therefore  you see  the iterative relationship is there so now  this plus integral  where the power of the term 1 minus t raise n minus j has now become n minus j minus 1  power of t is going up right j minus 1 to j and so on so  now  iteratively when i write  i will again get a term when i integrate this by part  i will get it term here plus than this actually j plus 1 f x is raise to j plus 1 then n minus j minus 1  and then another integral which will be i j plus 1 n minus j minus 2 so  this way iteratively when you do it  this power finally  becomes 0 and this will become your n so  therefore  you can show  this summation is equal into the integral  and this what i have said that is so  finally  you can show that this integral that i write down in a beginning  is equal to this sum  which is equal to your cumulative density function of x j and this you should have recognized by now  because this is see this is the beta integrant  together with the  or beta function when you want to make it p d f and since the limits are from 0 to f x therefore this is called incomplete beta function so  finally  i have been to able to replace  get this probability  the cumulative density functions  in terms of this integral so  when you differentiate both sides of a double star  you will get f x j from here it will be the p d f of x j  and this is you know differentiation under integral sign so  since this is function of x  this will become f x here  and otherwise you just substitute for t f x and so you get the same  that for special cases ; say for example  when you are sample values of from the uniform distributions  or i think from  may be from normal distribution we will see through a examples  then it is easier to get this explicit expression  for your c d f and for your p d f so  we will go through this example  to see how and of course  the question arises as to why we are doing this  and you will see that let us just go through this example and you will know why we are talking about obtaining p d f for these order statistics so  if you have a sample of size 2 and plus 1 independent and identical distributor and variables are observed  then the n plus first see n observation from this side and on this side so  n plus first is on the center  smallest is called the sample median so  when you arrange them order them  and then the n plus first 1 smallest  is called the sample median so  now let us say we want to find out the so  we have a sample of size 5 from uniform 0 1  is observed  find the probability that the sample median is between 1 by 3 and 2 by 3  and this you know when your handling data ’ s  large data ’ s  sometimes you are only interested in what the median of these sample size is so  we will go about  now obtaining the expression  because you want to find the probability of the sample median between 1 3 and 2 by 3 so  here you are actually talking about x 3 ; your j is 3 here  because sample size is 5 so  the median will be determined by the third ordered  third smallest statistic  refer slide time  09  36  so  x 3 is the median  when you of the sample of size 5 so  x 3 will represent the median of the sample  so by our formula see you remember the formula was j n c j f x f x raise to j minus 1 1 minus f x n minus j minus 1 for f x j so  put j equal to 3 here  and this will give you 5 c 3  and 3 times this  and then f x now for a uniform distribution  your p d f is just 1 the interval 0 to 1 so  this is 1  and this is given by  you know for a uniform distribution  refer slide time  10  17  so  proof of cauchy schwartz inequality  now expected value of y square can be greater than or equal to 0  it can not be negative  because this is y square so  therefore  when you integrate y square from minus infinity to infinity or whatever it is into f x which is a p d f non negative so  therefore  this must be non negative but then y expected value of y square equal to 0 would imply so  two things are possible ; either expected value of y square is 0  or expected value of y square is greater than 0 so  if it is 0  then this imply that probability of y equal to 0 is 1  because this expected values this  that needs  see you will write value of y square  whatever possible values is y square takes  into the probability of y square taking a particular value and so on  and this will imply that probability of y equal to 0 is 1 and hence  probability of x y equal to 0 is also 1  yes because this is a certain event  y taking the value 0 is the certain event ; hence probability x y equal to 0 is also a certain event and so the this probability 1  and therefore  this implies  that expected value of x y is 0  because this takes the value 0 with probability 1 so  1 into 0 plus  or you integrate or whatever it is  whichever you want to write it down  expected value of x y will be 0  and the inequality therefore  will be satisfy because this is 0 and this is 0 so  the inequality is satisfied so  therefore  we will now proof for the case  when then expected value of y square is positive x 1 less than or equal to x so  i will look at the opposite event  which is greater than or equal to x so  if first order statistic is greater than x ; this implies that all the sample values must be greater than or equal to x so  this is equal to what  1 minus f x raise to n  because if the first order statistic is greater than x  since it is a smallest  all other values of bigger than x 1  so all of them must satisfy this inequality  and therefore  this probability is 1 minus f x raise to n  and we are interested in finding out the f x c d f so  that will become 1 minus of this so  1 minus of this  which is equal to 1 minus of this  will give me my f x 1 x  this is the whole idea  so therefore  this is what you have  and which i can write as 1 minus 1 minus f x raise to n so  when you differentiate with respect to x  you get the p d f here  and this will be simply minus minus becomes plus so  n times derivative of this is small f x so  n f x into 1 minus f x raise to n minus 1 so  this will be a general expression so  now what i am trying to say is that  with this expression also and now let us just substitute j equal to 1 here so  what do you get ; this is 1 and so if you substitute in this formula  it will be n c 1 which is n  then f x and this is 1 minus 1 so  this is 1 this is 1 minus f x raise to n minus  this is minus j minus 1  how am i getting so  this is coming out to be j is 1 so  this is coming out to be n minus 2  accordingly  say for us it should be 1 minus f x raise to n  and at least from here it appears that this should be this  and i do it n times  i differentiate  and then i take this so it should be n minus 1 so  where is this other 1 missing  because you taking j to be 1 so  are you sure this is n minus j or minus n minus j minus 1 let us just verify that  what is the formula  correct formula ; it has to be n minus j it should be n minus j let us just make sure so that we do not make the mistake of n minus j so  see that helps to verify so  you see this is n minus j and therefore  j is 1 so it will be n minus 1  so both things match you can obtain it directly or you can do it through the formula  the formula that we have obtained now  just a simple example to show you  now let us see it also helps to write down the joint p d f of all the other statistics  that you see actually  what is happening is this is some arrangement of the sample values x 1 x 2 x n  and the possible arrangements of these n sample values is n factorial so  one of them will match this order and so you can you can do the thing through the regress mathematics  by showing that the  your r n region can be divided into n factorial regions  and each factorial  in each 1 of these factorial regions the  one arrangement of the sample values is there  and when you do the transformation  because you have to do it over whole of r n so  the jacobian will be one of the permutation matrices  and the value of the permutation matrices is always 1 i mean you take the positive part  otherwise the value of the permutation matrices plus minus 1 so  without going into all that  we can simply say that  the joint adjective function would be n factorial into  you see since the variables are independent  the joint density function of the sample values x 1 x 2 x n is nothing  but the product of the individual density functions  and may be if you want to feel good you can  but i am not writing this i am simply saying this is x 1 and this is x n  but they are the same so  therefore  i am not writing these indices so  all of them are the same p d f and therefore  this would be n factorial into f x 1 into f x n  this is the whole idea  so the general expression  where x 1 x 2 x n are varying from minus infinity to infinity because after all the order statistics is only one of the arrangements  and there are n factorial possible arrangements of the sample values of the n sample values so  now to find joint p d f  x will be equal to expected value of x y upon expected value of y square into y so  the minus sign is not there  see it gets cancel out so  x i x j then what is happening in this  i will integrate this so  for i minus 1 sample values  the limits of integration will be from minus infinity to x i  because i minus one of them have to be less than or equal to x i for variables between x i and x j order statistics x i x j  the limits are x i to x j  and for variables having values greater than x j  the limits of from x j to infinity so  once i do this integration ; that means  i will be integrating for i minus 1 then for variables between x i and x j  and then for all the variables having values greater than x j let me write it this way so  then once you do this  you will get the joint density function of remember  because for marginal when you had the joint density function  to obtain p d f of one of them  you would integrate respect to the other one  and then get the marginal p d f for the first variable so  here also we have done the same  and therefore  these remain intact  and for the remaining ; see this is f x i raise to i minus 1  because you are integrating from 0 to from minus infinity to x i and for variables between x i and x j  you are integrating from f x i to f x j so  this is j minus i minus 1  and this is 1 minus f x j and minus 1  so this minus 2 so  these add up to n minus 2  and then you have the remaining 2 x i and x j so  this will give you the joint density function so  out ultimate aim say therefore  see the range of the sample values is also of lot of interest  in many situations  so we want to ultimately find out the range of the sample values so  let me just define 2 random variables here  which are r is x n minus x 1 so  this is the range  and v is the largest sample value  and here of course  you should try to see that you can compute the p d f of x n directly  and then again verify from this formula so  for when you want to find out the p d f of v of x n  when you say probability x n less than or equal to x  which would mean that all the sample values are less than or equal to x so  you will immediately get  this thing to be f x raise to n so  the cumulative density function of x n will immediately come out to be f x raise to n  and you would differentiate so  n times f x small f x into f x  so raise is to n minus 1 so  here you can directly get this also anyway  so we have to find out the p d f of capital r so  can derived the p d f of ; see x 1 x n now first i need to know the joint p d f of x 1 and x n  once i obtain that  then these are functions of x 1 and x n  so i will use my transformation formula  and get the joint p d f of r and v  and from the joint p d f of r and v  i will then finally get the p d f of r  this is the whole idea so  for to derive the p d f of x 1 and x n from your this formula  i will simply write i as 1 and j as n so  i 1 this term is gone  and here also this term is gone  this term is gone so  you are left with n factorial upon n minus 2 factorial so  n factorial upon minus 2 factorial  then this f x n minus f x 1 raise to n minus 2  and then this is out  because n minus n is 0 and so this is f x 1 f x n so  this is your joint p d f of x 1 and x n once i have this  then i will make the transformation  that i will write r as x n minus x 1 and v as x n so  then from here you will go get the relationship for so  x n comes out to be capital v and x 1 comes out to be v minus r  and then you write the jacobian so  r is my first variable so  this will be minus 1 1 and then here it will be 0 1 so  the jacobian absolute value is 1 so  now  i can get the joint density function of r n v so  with jacobian as 1  absolute variable jacobian is 1  and these this transformation ; that is your x n is v and x 1 is v minus r  in this 1 we just substitute for x 1 x n multiply by the jacobian  refer slide time  23  02  so  then your f of f of r v ; that means  capital r is equal to small r  and v then this function this p d f of r and v can be obtain from this p d f n into n minus 1 f v minus f v minus r which is your x 1 this is n minus 2  and this is f of v minus r f v  and here of course  it is understood that r is greater than 0  because r represent the range and x n is greater than x 1  greater than or equal to x 1  so this is the case  and of course  we have range is 0 there is no point so  we are taking r to be some positive number so  therefore  once i get the joint p d f or r and v  now my interest is in the getting the p d f of capital r so  i will integrate this  and in general you will integrate from minus infinity to infinity well why should i say from minus infinity to infinity  it should always be from  it should be r  because you see here your x n is r plus x 1 so  since this is non-negative then i mean  ok fine in general  it would be minus iterative  because x 1 in general we are allowing x 1 to take vary from minus infinity to  this sample size is from minus for a population  which is from minus infinity to infinity so  in that case this is fine in general we can write as minus infinity to infinity now  as a special case consider  the case 1 x i r from uniform 0 1 so  as a special case consider x i i varying from 1 to n  from uniform on 0 1 then this function this p d f will reduce to whatever i written here the f r r so  i am writing this so  the p d f of the range variable would reduce to n into n minus 1  and now in this case it will be r  because as i am saying not that this is non-negative  if f all of the sample values are coming from uniform 0 1  all values are non negative  and therefore  this x n has to be greater than or equal to r plus so  in x n is your v so  when this values v and this is r so  then v has to be greater than or equal to r so  now in the joint density function  you are integrating with respect to v  to get the p d f of r so  then that will be the range will be from r to 1  because variables are from 0 to 1 so  then this will become v  this will be v minus r raise to n minus 2  and both the p d f are 1 1 so  1 1 d v  this is your this thing  and you can see the simplification v cancels out this r raise to n minus 2 d v so  the integral here would be v  which will be 1 to r 1 minus r so  therefore  this is your p d f for the range  and now you can find out the possible so  for a sample of size 10 from uniform 0 1  the probability that the range is larger than 0.8 so  these questions are of full out of interest so  you want to find out the range of values  the sample that you have observed so  if you are saying that the range is larger than 0.8 then you want to compute the probability that capital r is greater than 0.8 therefore  you will integrate this function from 0.8 to 1  and if you simplify here you get the answer is 0.6 to 4  which is a pretty large probability  of range values being more than 0.8  the range of the sample being more than 0  refer slide time  27  04  so  another example ; now from the normal distribution  because i thought we had had enough cases for uniform so  if x 1 and x 2 are identically independently distributed  from a normal 0 one ; that means  the mean is 0  and the variance is 1 so  this is a sample  x 1 x 2 is a sample from normal 0 1 so  find the p d f of x 2  which will represent the max of x 1 and x 2 so  we will again obtain this  without using any formula so  here again as i explain it to you  that if you want to find the c d f of cumulative density function for x 2  second the largest one  then this will be probability x 2 less than or equal to t  which will imply that both the values x 1 and x 2 should be less than or equal to t  and since they are independent  this is equal into probability x 1 less than or equal to t into probability x 2 less than or equal to t  and coming from t and 0 1 will be root 2 pie e raise 2 minus 1 by 2 t square d t so  this is our notation for phi t for a normal distribution so  this is standard normal distribution  so phi t so  therefore  this will be phi square t so  the cumulative density function for the max of 2 sample values x 1 and x 2 coming from normal 0 1  is given by phi square t so  then if you want to find the p d f  just this differentiate this  which would be twice phi prime t f t so  phi prime theta will be nothing  but the normal p d f  which is given by this  so it will be twice phi t into 1 by root 2 pi e raise to minus half t square  so minus infinity to t so  this one can  then you know integrate find out  whatever probability you are interested in so  it looks like in that at least the  normal if your sample is from a normal distribution  or from uniform distribution  you can you know easily obtain p d f of the order statistics in other cases also  one can see of course  there method for computing difficult integrals  by many other ways  by numerical methods now continuing with our joint distribution functions  and the other important parameters that we need to look at  and define here is ; covariance variance of sums  and correlation so  this will also have a lot of implication  and see here of the purpose of before i talk about  define the covariance and the variance  and then the correlation  simple proposition  which in fact  there was no need to prove it also  but i have written it down for completeness sack ; x and y are independent  so if x n y r independent random variables this is understood random variables  then for any function h n g for any functions h n g  expectation of g x into h y  is expectation of g x into expectation of h y ; that means  the independence carries over to  the function g x and h also so  here this is the proof is simple  because if you want to write the expectation of g x h y  it will be minus infinity to infinity  minus infinity to infinity g x h y f x  y d x d y  but since x and y are independent  the joint density function can be written as the  product of the marginal densities so  here when you write this as ; f x and into f y  then i can even separate out the integrals  because it will minus infinity to infinity g x marginal of x into minus infinity to infinity h y into marginal of y into d y  and so by definition this is e g x into e h y so  once we have this behind us  then we can talk of  define the  first of all the covariance  refer slide time  31  30  so  the idea of covariance between 2 variables x and y  is denoted by  this is the notation  and is defined by the covariance expectation of x minus e x into y minus e y  and if you open up this  if you expand this expression  this will be x y minus x e y minus y e x plus e x into e y  when i take the expectation inside  it will be expectation of x y then this will be expectation x into expectation y then this will be minus expectation y into expectation x plus this so  one of them the 2 of these will cancel out each other  and you will be left with so  this is a simpler expression to handle  when you are talking of covariance so  it is expectation x y minus e x into e y  this is the definition of covariance  and let us see what does it indicate  or why do we so  now if x and y are independent ; see if x and y are independent  then e of x y will be written as e x into e y so  then e x into e y minus e x into e y will be 0  so covariance so  therefore  if x and y are independent  this implies that covariance x y is 0 but  unfortunately the converse is not true ; that is  covariance equal to 0  does not always imply independence of the random variable very simple  i will tell you  that the converse of this result is not true so  independence always implies that the covariance is 0  but if the covariance is 0  it need not imply that the variables are independent so  let us see  we defining random variable x  which takes 3 value so  probability x equal to 0  and probability x equal to 1  and probability x equal to minus 1 is equal to 1 by 3  so all 3 are equally likely then i am defining a random variable y  which is totally dependent on x so  y 0 if x is not 0 and y is 1 if x is 0 so  now if you look at the values of this product  this will always be 0  because y 0 when x is not 0 and y is 1 if x is 0  so this product will always be 0 if the product is 0  so the random variable just takes only 0 values so  then this expectation will be 0  because variable is taking all possible values as 0 so  this is expectation of x y 0  and you see from here expectation of x is 0 see x and z having the same p d f and c d f  does not imply the that x and z are dependent  but we see here that when given x  z can only take the values x and minus x  we have just see this  and therefore  x and z are completely dependent  because what will be the expectation of x so  expectation x will be  so this 0 so  expectation of x is 0 ; therefore  from the covariance formula  this is 0  this is 0  so the whole thing is 0 so  covariance 0  but we know that x and y are not independent  yes x and y are not independent  if you want you can do this way  what was the i mean  what will you use you will use  you can show that probability x y  because they are discrete random variable  so all possible values so  in fact  x y takes all 0 values so  therefore  here you have to show that how would you want to go about doing it  normally for a discrete thing you want to show that for all possible values  of this product  the probability so  for all of them  is not equal to the product of individual probabilities but here you will have to yeah you will have to write out in detail  but anyway you can  as it is there is not much to really prove  because the way you are defining your y  it is totally dependent on x so  that gives you the so  therefore  covariance 0  does not in imply independents of the random variables  refer slide time  36  21  so  continue with this  let ’ s take another example here ; let x 1 be sine 2 pi u and x 2 is cos 2 pi u  so 2 different functions of a uniform random variable 0 1 so  u is your uniform random variable on 0 1 we consider random variables  obtained by taking functions sine 2 pi u and cos 2 pi u now  let us see  if functions sin 2 pi u and cos 2 pi u right now let us see if you compute expectation x 1  this will be 0 to 1 sin 2 pi u d u  which will be minus 1 by 2 pi cos 2 pi u from 0 to 1 which is 0  because cos 2 pi minus cos pi cos 0 both are 1 so  this becomes 0 similarly  you can show that expectation of x 12 will also be 0  and when you compute the so  therefore  the covariance of x 1 x 2  will reduce to  just expectation of x 1 x 2  but expectation of x 1 x 2 will be  you see sin 2 pi u into cos 2 pi u will be sin of 4 pi u divided by 2 so  again this is same kind of function from 0 to 1 so  that value will also be 0  but then x 1 plus  because x 2 will be 1 minus x 1 square under root so  therefore  the covariance is 0  it does not suddenly imply independence of x 1 and x 2  which you can see otherwise also  because x 1 square plus x 2 square is 1 i will come back to this example in a while now  properties of some which we can immediately show ; properties of covariance function so  this is  first of all it does not matter  what order you write  covariance x comma y  is same as covariance y comma x  because this expectation of x minus e x into y minus e y so  the order is not important then when you take both x and y to be the same  then co covariance x x  because that is expectation of x minus e x so  square this will covariance x so  therefore  this is equal to variance x  and if you take covariance e x comma y  then again by definition  because a will be here  a will be here also  you will be able to take it out  and it will be a times covariance x comma y and then you can apply this principle in general  because we have already shown it for this  and then since because of this so  you can show that if you take summation ; sigma a i x i i varying from 1 to n sigma j varying from 1 to n v j y j then again  taking all possible products here  and covariance you can take it  because its expectation function which is linear i can take it inside or the summation sign so this can be written as this  and then this is summation that will be outside  and then here this is a i b j will come outside  and this will be covariance of x i x j so  this is the general expression  and i will show you nice application of this  after a while how you can use this formulae to simplify some computations  refer slide time  39  35  now  the moments you define the covariance function  you will be immediately have define the correlation coefficient rho  and we will see the implication and the usefulness of this parameter  so if x 1 and x 2 are two jointly distributed random variables then the correlation coefficient rho  is covariance x 1  x 2 divided by variance of x 1 into variance of x 2 now  of course  this definition is valid  only when sigma x 1 and sigma x 2 are finite and in fact  there should not be zeros  because if you are x 1 and x 2 or any of them is a constant variable  taking only constant values ; that means  no randomness about it then your sigma x 1 will be 0  so you can not divide by 0 so  this quantities is defined  only when sigma x 1 and sigma x 2 are finite  and they are not 0 in fact  this applies to your covariance function also  but expectation x 1 expectation x 2  should also be defined so  in fact  i should when i defined the covariance function  i should have spelled out that the definition is valid  or as long as your expectation functions exists  are defined now  you can see  you can immediately see that here  the covariance function  the correlation coefficient  can be define nicely in this way  and once you define it this way  then it becomes dimension less  because i have standardize the way root x minus e x divided by define divided by the various standard deviation  and y minus e y divided by stranded deviation so  this becomes if you remember how this standardize your normal variate so  the same thing we are doing  and once you do this then this becomes dimension less now  if you want you can try it out here  because see the covariance you are defining as expectation of x minus e x and y minus e y so  this you are defining it is this so  here also it is  and then for the covariance you simply taking rho x and then rho y so  by this definition  i can take this inside  so there is no big deal i mean i am not doing anything manipulation here  simply taking this inside  because we have already seen ; that the constant can be take outside or inside  does not matter so  therefore  now becomes standardize      so  this is dimension less definition of the correlation now  we used the word so  if see rho x 1 x 2 0 ; obviously  is possible when the covariance is 0 so  essentially when the covariance is 0  we use the word ; that x 1 and x 2 are uncorrelated  and you have already seen  that 2 variables been uncorrelated  does not mean independence so  therefore  we have coin this word ; that 2 variables are uncorrelated  if and only if the correlation coefficient as we call it rho is 0 so  this is our terminology that x 1 and x 2 are uncorrelated  provided the covariance is 0 between the 2 random variables and we will now through schwartz inequality and so on i will show you  that the number rho  measures the relationship again between  it tries to show ; co covariance simply showed you that  whether i mean if the variable are independent then the covariance is 0 now here rho gives you much more information than that it will show you that  see we will first of all show that rho is less than or equal to 1 always  because we have standardize the thing  divided by the stranded deviations  and then we will show that rho is equal to 1  then they are perfectly related the 2 variables and this actually measures the relationship  but again here we will try to show you that  it may not always measure the it may it may predict linear relationship very well  but not non-linear relationship  but so we will come to that anyway  so this is a very useful parameter  and here also i think the same example  i was trying to take  is that if your x 1 is x and x 2 is x square  so it is the square of x then see this is the relationship between the 2 variables x 2 is equal to x 1 square  and the covariance will come out to be so  covariance will be expectation of x 1 cube minus expectation x 1 into expectation x 1 square now if i take x 1 to be a variable  which takes 2 values x 1 is 1 and x 1 x 1 is minus 1  both the values it takes it probability half then you see expectation x 1 is also 0  and expectation of x 1 cube is also 0  because this will also be 1 into half  then minus 1 into half  and this will also be 1 into half and half n minus 1 into half  and this will be 0 so  therefore  your covariance is 0  so this will imply that your rho is 0 so  the variables you are saying are uncorrelated  but certainly they are not independent now  another immediate use of the word uncorrelated  we can show here  while computing the variance of sum of 2 variables  and this can might be extended to many more  you know when you have sums of more than 2 variables so  here for example  the variance of x 1 plus x 2  you will define as x 1 minus e x 1  refer slide time  45  50  so  now we will compute the expected value of x given y  and therefore  the values of y will vary so  when you write this expression  computing it through conditional expectation of x  for different values of y so  then this will be see conditional expectation of x given y equal to 1 so  that into probability y equal to 1 plus conditional expectation of x given y equal to 2 into probability y equal to 2 plus conditional expectation of x given y equal to 3 into probability y equal to 3  and this  because we have made these computation  so you see that 2.7 into probability of y equal to 1  which is 0.2 from here  and then plus 2.88 is the conditional expectation of x given y equal to 2 so  2.88 into 0.5  which is 2.88 into 0.5 plus conditional expectation of x given y equal to 3  which is 2.833 so  that into 0.3  this is 0.3  and this adds up to 2.82 which is the same as this  which we computed from here so  this is what i want to show you  and therefore  here remember even if somewhere in the text sometimes  you find that capital letter is missing  whichever the conditional so  whenever we talk of expectation  then the whole idea is that ; this expectation of x given y  when i write the random variable here  then this is the random variable and so i can talk in terms of expectation of this random variable  and this will be of course  the probability ; that means  the value of e x given particular value of y so  you compute this expectation  for a particular value of y multiplied by the probability of that particular value y  and then you add up for all possible values of y  and then you get this so  therefore  you can break up the expectation x  also in this way so  expectation x in other words we are saying  is expectation and then again expectation conditional y e x 1 plus x 2 minus e x 2 whole square  and when you open up the square it will be x 1 minus e x 1 whole square plus x 2 minus e x 2 whole square plus twice expectation of x 1 minus e x 1 into x 2 minus e x 2 so  this is variance x 1  this variance x 2  and this is covariance x 1 x 2 so  now from here it follows  that variance of x 1 plus x 2  is variance x 1 plus variance x 2  if and only if covariance x 1 x 2 is 0 so  if and only if ; like if covariance x 1 x 2 is 0 then you get this  and if you saying this variance is equal to this  then covariance must be zero so  this is if and only if relationship  and for this result to be true  it is not necessary x 1 x 2 to be independent see earlier we had talked of independence  then i talked of some of 2 independent random variable i had shown you that this will be equal to this but now we are saying  since we have different find this term uncorrelated so  what we are saying is  that for variance of x 1 plus x 2  to be equal to variance x 1 plus variance x 2 it is enough that the covariance is 0 or the variables are uncorrelated it is not necessary for x 1 x 2 to be independent it is enough  if x 1 and x 2 are uncorrelated i can not write it here  but this is uncorrelated so  this is one advantage  one use of this function we will talk about this some more in the next lecture introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  18 conditional expectation best predictor  refer slide time  00  15  i will continue with the example  i was discussing at the end of lecture seventeen so  this was the conditional p d f of x 1 2 given equal to x 2  and you are given the marginal of x 2 also then we had to find constant c 1 and c 2 ; of course  the criteria ’ s that they should be  they are p d f so  the integral in the specified region must be one so  we made these computations in the in last lecture so  by saying this integral 0 to x 2  because given n and x 2 when you draw this  your x 1 will be varying around 0 to x 2  because this is the region of integration so  0 to x 2 integral  this equal to 1 implies c 1 is 2 similarly by integrating this from a 0 to 1  because of this marginal of x 2  then this comes out to this gives us c 2 equal to 5 so  the joint p d f of x 1 and x 2  will be conditional of x 1 given x 2 into the marginal of x 2 so  the product of the 2  which we already have now with us  since we have computed c 1 and c 2 so  that will be the joint p d f of x 1 and x 2  and that we also computed as 10 x 1 2 square  where the range for x 1 from 0 to x 2 and x 2 varies from 0 to 1 now  is this a p d f surely  because it is a product of 2  this we have verified as a p d f  this we have verified as p d f  so the product must also be a p d f so  there is no need to verify this again  though if you want you can integrate  respect to x 1 from here to here  and for x 2 0 to 1  and you can show that this is a integrate  so double integral will come out equal to be 1 so  now we have to find in that number three  is compute the probability of x 1 between point 2 five and point five so  to do this  i need to compute the marginal of x 1 marginal p d f of x 1  and that will be taking the joint p d f  and here you will be integrating respect to x 2  so given an x 1 this is the line  and therefore  your x 2 will vary from x 1 to 1 so  this is the range for x 2 so  x 1 to 1 you integrate the joint p d f  to obtain the marginal p d f of x 1  and so this comes out to be so  you integrate in respect to x 2 so  x 2 cube by 3 10 x 1  so this is the a expression for the marginal so  once you have the marginal for x 1  then you want integrate again the marginal from 1 by 4 to 1 by 2  to obtain the probability  and the number that i get is this so  maybe you need to simply this further  and get the right answer then fourth one required you to find the conditional probability  of x 1 given x 2 is 5 by 8  so this is for again 0.25 to 0.5  refer slide time  03  28  so  the conditional density function we already have ; which is c x 1 upon x 2 square  but x 2 is given to 5 by 8 so  we have to integrate this from 1 by 4 to half 2 x 1 upon 5 by 8 whole square d x 1 so  here this is the simple these things x 1 square by 2 which is 1 by 4 to half  and what you get is  12 by 25  but now since we have also talked of conditional expectation  i thought we will include that part also here so  for example  you are asked to find the expected value of x 1 given x 2 is equal to x 2 so  you will find out the expectation here ; that means  it will be the joint p d f it will be the conditional p d f of x 1 given x 2 equal to x 2  which is 2 times x 1 upon x 2 square  and since you are finding the expectation here with respect to x 1  so it will be 1 into this so  this is the integral  and of course  1 varies from 0 to x 2 and you are integrating with respect to x 1 so  2 by x 2 square come outside  and then this will be 1 square  so which is x 1 cube by 3 and 0 to x 2 so  you simplify and this is the expression 2 by 3 x 2 which is a function of x 2 so  which is to be expected  because in this integral you are integrating with respect to x 1  and the limits of from 0 to x 2  and since x 2 is given to be 2 so  this will turn out to always be a function of x 2  when you are finding expectation of x 1  given x equal to x 2  which i mentioned yesterday also we defined now this is a straight line passing through the origin so  the expectation that comes out is a function of x 2  and this is a straight line passing through the origin so  that means  here the relationship is linear ; that means  the expectation of x 1 given x 2 equal to x 2  is a linear function of x 2 then therefore  follows that expected value of x 1 given x 2 x 2  will be 2 by 3 x 2  will be a random variable see the whole idea here is  that this was repeated earlier also  what we are trying to say here is  that for a particular value of x 2 this is what you get  the expectation value of x 1  slash conditional x 2 equal to small x 2 now  as values of x 2 vary  then this becomes the expected value of x 1  condition on the random variable 2 so  the notation that we called it 2 by 3 x 2  so this is a random variable so  for the different particular values of x 2  we will get the expected value from this formula  this is the whole idea right and therefore  since this is now a random variable  we can again talk about the expected value of here  and i had done this even earlier  in the last lecture also the same thing so  therefore  the expectation of x 1 condition on x 2  will be just the 2 by 3 into a expectation of x 2  which will by the formula would be  you know integral 2 by 3 0 to 1 2 f x 2 x 2 d x  and this will turn out to be the expected value of x 1 so  when you take first expectation of x 1 condition on x 2  and that comes out to be a function of x 2  then you take expectation again  and then you will get the expectation of x 1 so  this is idea being repeated in the last lecture  and i have asked you to verify so ; that means  you will have to compute the marginal of x 1  and then which i think you already here ; yes that say conditional p d f so  you will have to compute the marginal of x 1  and then find out the expected value of x 1 independently  and verify that this it comes out to be the same  what will get from here further i will continue with this concept  and take another example to make these things clear  try to do it so  this was an example i got from the net ; roll a die  until we get a 6 so  this is the experiment you continue roll a die  until you get a 6 and let y be the random variable which is equal to the total number of rolls  till a 6 comes up so  you continue rolling the die till a 6 chose up and then you stop so  and x is the number of  once we get in this process so  when you are rolling a die  you keep noting also the number of times 1 appears  and then of the experiment stops the moment a 6 comes up so  x is the number of once you gets in this process now  you are asked to compute expectation of f x given y is equal to y ; that means  the number of times you have to roll the die  is small y  and then this process you want to compute the expectation of x  given that you had to roll the die y number of times  refer slide time  08  38  so  y equal to small y means ; that there were y minus 1 rolls the die  which one not a 6 all the numbers are appeared  but the 6 did not appear  because the experiment will stop the moment 6 appears so  y minus 1 rolls did not show a 6 now  therefore  you see an x is the number of once that comes up  before the experiment ends so ; that means  in this showing that you get  the y minus 1 rolls that you made of the die ; x is the number of ones that show up so  when you can treat x as a binomial random variable  with the number of experiment as a y minus 1  and the probability of occurrence of a 1 is 1 by 5  because remember up to y minus 1 rolls 6 is not appearing so  and the other five numbers are equally likely so  the probability of 1 showing up  is 1 by 5  and the number of experiments that you make is y minus 1 so  we will treat occurrence of 1 is success  and occurrence of 2 3 4 5 as a failure  and therefore  x can be treated as a binomial random variable  with n equal to y minus 1 and p equal to 1 by 5 so  you see the whole idea  is that how you can compute a certain quantity that is required  by just realizing how the experiment has been conducted so  therefore  immediately you can say expected value of x when y is given to be small y  is slimily because for a binomial random variable  the expected value is n p so  n here is y minus 1 and p is 1 by 5 so  without any hassle  we get to the expected value ; the conditional expected value of x given y is equal to y now  this is again a function of y ; that is as y takes values possible values 1 2 3 and so on  the points 1 by 5 y minus 1 will lie on this straight line  expected value of x by y ; that means  conditional expectation of x given y capital y is a random variable now conduct the experiment and get an outcome omega ; that is omega is string of 1 2 3 4 5  ending with a 6 so  like we conduct the experiment we keep rolling a die  till we get a 6  and we record the outcomes at each roll of the die so  it will be string of these numbers  ending with the 6  so omega is that then you compute how many numbers are there in the string  so that means  how many times we have to roll the die so  now you can say that y small y is the value of y at omega  because omega represents a string  and y counts the number of elements in this string so  this is actually our relationship small y is y at omega so  y is number of rolls of the die to get a 6 so  y omega is a random variable  surely because this can go on depending i mean when the 6 shows that is not a certain event  so there is a chance element here  and therefore  y omega is a random variable  and then you compute the expectation of x given y equal to y  which we did right now so ; that means  you are relating omega with this  because given a omega you computed the y  and then you compute the expected value of x given y equal to y so  that is expectation of x given y equal to y is a mapping ; that maps omega to 1 by 5 y minus 1  and remember i defined a random variable also is a mapping  because as i said random variables associate  with the sample base real numbers so  here also what you have to happening is that  this expected value of x given y equal to y is a mapping that maps omega to this  where y is capital y omega so  therefore  omega is mapped to 1 by 5 y omega minus 1  which is a random variable so  now when you write capital y omega so  the idea was to explain to  again in a different way why we are saying that this is a random variable  though it should be clear  because as values of y change there is a probability associated with what value y takes  and therefore  this is again a random variable you can go ahead and makes some more computations ; for example  if you look at variance so  again the conditional variance of x given y equal to small y  i know because i have said that x is a binomial random variable  so this number i know  and for this number also i know so  if you want to compute expectation of x  is square given y equal to y  then this minus this is equal to the variance and therefore  i can say that  yes and this is equal to n p q  by the binomial formula  so p q and n so  1 by 5 into 4 by 5 into y minus 1 ; so 4 by 25 y minus 1 is the variance  and expectation x given y equal to y  we already computed as 1 by 5 of y minus 1 so  therefore  expectation of x square given y equal to y  is variance plus this  which is 4 by 25 my y minus 1 plus 1 by 5 y minus whole square  which is 1 by 25 into y minus 1 whole square so  when you simplify this expression you get this y minus 1 so  this is a quadratic function of i should say here quadratic function of small y  refer slide time  15  00  so  the random variable represented by expectation x is square given capital y  is a random variable  which is this so  this becomes a quadratic function of y so  i hope this gives you a little inside into  what we mean by and now another roll that a conditional expectation place  is as a best approximation conditional expectation as a best approximation  and i thought we should talk about this to  give you some more feeling  and this is value of the random variable is observed so  suppose a value of random variable is observed  and based on this observed value  an attempt is made  to predict the value of a set second random variable y see sometimes maybe easier to observed value of the certain random variable  and then if based on that observed value  you can makes some attempt to predict value of another random variable  that helps you  because then you do not have to conduct another experiment  to obtain value of y  but of course  the value that you predict from knowing the value of x  may not be the exact one so  let g x denotes this predictor so  suppose  so some function of the random variable x so  this denotes this predictor  so that is x equal to x is observed  and then g x so  g of small x  is our predictor for the value of y  so for one value of y  and then you observed another value of capital x and g of  that value of x will give you another a predictor for the value of y  so this is the idea now  how to choose g  because you have to have some concept  as to what is the g that is acceptable to you ; of course  the quality that g must be possesses  that it should be as close as possible to y so  now  whole idea is  what do you mean by closeness here  and how can we define and of course  later on also  when we talk of limits and so on  and conversions and probability in law  these things become more clear but right now  that we say that our criteria criterion is to minimize  expectation of g x minus y whole square so  this is my criterion  then i want to choose that g  which minimizes this expectation g x minus y whole square so  expectation of this should be as small as possible now  we will show that g x equal to expectation y condition on x is a best choice so  this is a whole idea  and therefore  you see another roll that the conditional expectation place  and the proposition is so  we want to show  that expectation y minus g x whole square  is greater than or equal to expectation y minus expectation y given x whole square so  then this will establish  that this is a smallest value of this  and therefore  the best choice for g is expectation y given a conditional for expectation y given x so  we will just prove this proposition for you  refer slide time  18  37  so  before we proved this proposition  i will like to state a theorem  and fact that proof is also straightforward so  the theorem says that if x and y are 2 jointly distributed random variables  and h x is a function of x  whose expectation exists so  then if you have the conditional expectation of f x given y and then we take the expectation again  this will come out to be expectation of h x now this is on the same lines as if you say that expectation of x given y  and then you take the expectation again so  this is e x  remember we have already shown this result so  on the same lines we are trying to show that  expected value of h x conditioned on y  and when you take the expectation again it will come out to be expectation of h x provided of course  the expectation of h x exists so  i have just written down for the continuous case i have just written down the expression for x expectation of the expectation of conditional of h x on y  then it will be minus infinity to infinity minus infinity to infinity h x the conditional p d f would be f x y x y divided by f y  because this condition on y  and then since you this turn out to be a function y so  when i take the expectation again it will be f y y d y d x  and this you can see that  this will cancel out  and it will get expectation of h x now  similarly the result can be stated  that if you take a function g of y and then condition on x  then just reverse the rolls of x and y  and then you will get here a expected value of g y ; that means  your expected g of y condition on x  this will turn out to be expected value of g y provided of course  a expectation g y exists so  this is this and then proof  in case x and y are discrete random variables  you can just imitate the proof for the continuous case so  once this theorem is there  we will be using it in to prove this proposition so  let me now consider the proof of the proposition  refer slide time  20  59  so  this is i am considering y minus g x whole square  condition on x  and because my proposition i am taking condition on x so  now  add and subtract expected value y by x you was in the bracket so  then this is expected value of y by x plus expected value of y by x minus g x whole square condition on x  open up the brackets then this will be y minus e x y by x whole square  condition on x expectation of that plus the square of this expected value of y by x minus 0 whole square then condition on x expectation plus twice a product of these 2 terms so  say the condition on x separately  and then the expectation of that so  twice e of that so  then let me call this  equation as a star  denoted by star now  see for given value of x equal to x  this will be a function of x remember we have shown you that the expectation of y condition on x so  for a fixed value of x it will be a function of x so  for the purpose of taking this expectation  because that expectation with respect to  ya this will be ya so  therefore  i can treat this as a constant  and so this comes out to be expected sign so  this is a function of x and hence can be treated as a constant so  because i will be computing it for different values of x  this thing  and for every fixed value of x  this will be a constant so  i can take it out of my expectation so  therefore  y minus e of y by x condition on x into expectation of this  i can take this outside  and then this will be expectation y minus expectation y by x condition on x now  here again  you see when you bring x inside  it will be y by x y condition on x and this does not change  because this is already on condition on x so  this will become expectation of y by x i mean this of course is outside so  this portion will be expectation y by x minus expectation y by x  which is 0 so  therefore  the in the star expression this portion has no contribution  this is equal to 0 so  the right hand side  this reduces to simply the  expectation of y minus expectation y by x whole square condition on x  this expectation of expectation y by x minus g x whole square condition on x so  this is what you have  refer slide time  23  52  and since for a given value of x y minus g x is a function of y therefore  by the theorem above ; this will be a function of y only  because this will be a constant for every fixed value of x and so by our theorem  expected value of expected value y minus g x whole square condition on x so  for different values of x  this will be a function of y only so  for each fixed value of x  it will turn out to be expected value y minus g x whole square  and then for the whole different values of x to the whole thing will become y minus g x  expectation of y minus g x whole square see it is a same concept scalding over and similarly expectation of y minus expectation y by x whole square condition on x  will turn out to be expectation y minus expectation y by x whole square i mean this whole square and then the expectation ; this is what we are doing so  you get that when you you know you have this because this is equal to zero so  i got yes  where is the greater so  the right hand side  when i take the expectation  i get ; see we started out from here  you started out from here  and then this got 0  then i took expectation of both the sides so  this became expectation of y minus g x whole square  and this became expectation of y minus expectation of y by x whole square plus expectation y by x minus g x whole square so  the conditional things disappeared  and since this expectation of squares are non-negative so  therefore  i can this  because this portion ; the expected value of y by x minus g x whole square  this will non negative  y by x minus g x whole square this will be non-negative so  therefore  my equality will be convert into an inequality  and this what you have so  this is what we are trying to prove  at you know for any function of g x for any function g of x  if you take this expectation y minus g x whole square here again if you want to put this  then this will always greater than or equal to expectation of y minus expectation y by x whole square  expectation y by  and this whole square expectation of that i should first say y minus expectation y by x whole square and expectation of that so  this is what we wanted to prove so  in order words you see the process  that you are observing value of x  and then computing the expectation y given x  and in the earlier lecture when i had considered  define this conditioned expectation  and conditional expectation and taken this discrete case so  i showed you how  you change keep changing values of x  then you will compute the expectation y given x so  this in a way we are treating as a good approximation for the value of y  and when we are when our criteria criterion is  in terms of minimizing this expression  then ; obviously  no other function of x  will qualify to be the best predictor  except for the expectation y given x so  in this way we are treating or showing that this can be also looked upon as a very good approximation  for the value of x so  for the different values of x will compute this  i mean we will observe possible values of x all possible values compute this  and this will give us the different values for of y so ; that means  you can compute this expectation  for well  yes there is  still a few questions which i are not answered  and hopefully we will continue  looking at this again  refer slide time  28  11  now  take this example  you can show that for any real number a in fact  what we have shown here  can be also you know this you can show very easily  that expectation of x minus e x whole square  is always less than or equal to expectation of x minus a whole square  for any real number a and you know the same thing here  you will write minus e plus e minus a  open up the square and so on  and then again one part  when you look at this thing e x minus a so  this is the constant  and therefore  when you are taking the expectation of the product term  this will come out  and see the second factor will be expectation of x minus e x  which will be 0 so  for the same reasoning  you can show that this is always a less than or equal to this so  you can do this for  any real number a now  look at the  example of bivariate normal distribution of x and y  and we have already looked about this p d f  which is you know in terms of sigma x sigma y and rho so  these are correlated  because ; i mean i am just taking the general case  x and y are not necessarily independent so  this expression  in exercise 5 of and question 10  i asked you to show that conditional distribution of x  given y equal to y  is again a normal p d f with mean this  and variance equal to rho square now why am i writing rho square  this should be sigma square sorry so  this will be sigma square into 1 minus rho square so  this is your mean  and that is your variance so  therefore  expectation of given y equal to y  will be this mean  because this is for capital y equal to small y so  this is mu x plus rho into sigma x upon sigma y y minus mu y  which is again a linear function of y  refer slide time  30  28  so  what we have found is that  when x and y have a bivariate normal distribution  the best overall predictor  because according to our proposition  of x with respect to y  turns out to be  mu x expected value of x condition on y  is mu x plus rho sigma x upon sigma y into capital y minus mu y  and this turns out to be linear in y so  that is all we can say that the best overall predictor  in case x and y are bivariate normally distributed  then the best overall bivariate of with x respect to y  is this expression which is the conditional expectation of x given y it turns out to be this  and this is linear in y so  this is all what we can say  or to talk of this linear product linear predictor and so on ; that is another thing  that we have to go about it in a different way  and i have to first defined what we mean by linear predictor and so on so  right now all we are saying  is that the best overall predictor  in case x and y are both normally distributed ; that means  they have a bivariate normal distribution then the best overall predictor  would be a linear in y and similarly if you are talking of the best overall predictor of y with respect to  and that will be linear in x now  let us just further continue talking about a conditional expectation so  now  we will show  that expectation x y is expectation x into expectation of x expectation of y given x so  this is what a simple calculation we will do now here of course  i have not written out all the steps so for example  when you want to write expectation x y  so actually the starting expression will be x y into the joint d x d y so  this is the thing  but as we have seen that the joint p d f of and y  can be written as a product of marginal of x into the conditional of y given x so  therefore  this is what i am writing here so  expectation x y i am writing as x y f x x into f of y given x  d x d y now  the thing is that so  y integral y into f y by x conditional this  conditional p d f of y given x so  this i can separate out  and i can write this as y  because this is not of  when i integrate this is given value of x is fixed here ; f y given x so  x into small x so i integrate this respect to y and then  so i can just separate out this double integral into minus infinity to the infinity x f x  and then this will come out to be a function of x so  then that whole thing i will integrate as a function of a d x  and so you can immediately see that this is expectation y given x  and then x times f x this gives you expectation of x into expectation of y by x so  simple calculation  but again just emphasizing the fact that  this is a random variable  and therefore  becomes a function of x  and so you compute this expectation again  and you get this so  you know you were using a conditional expectation to compute expectation now  let us go through this exercise for computing rho  and of course  for different situations you can use different techniques to handle it so  now here if you are given x and y  have a bivariate normal distribution  so this is mu x mu y sigma x square sigma y square and rho so  this is the bivariate normal distribution  and you are given that a rho is greater than zero so  you have to find the conditional expectation of y between 4 and 15 given x is equal to 5 i am sorry i mean you are given that this probability is equal to 0.954 you have to determine rho so  rho is the unknown here  and therefore  you want to determine that now  from our this result  that x given y is this so  what will be this thing  refer slide time  35  21  so  from here only you can write here  that expectation of y given x  this will be mu y we just replace x y by y mu y plus rho sigma y by sigma x  and then this will be x minus mu x so  this is the formula which  i have written it already so  this is mu y plus rho times y upon sigma x into x minus mu x ; that will be this and then since x is given to be 5 and mu x is also 5 so  therefore  this part is 0  and so expectation y when x is equal to 5 is 10 so  the conditional expectation y or the mean is 10 so  y by x is normally distributed  with mean 10  and the formula for the variance would be so  variance formula for the variance y given x equal to 5  is rho y square 1 minus rho square  which is 25 times 1 minus rho square so  this is the variance  therefore  this is what i have written here so  this is normally distributed  with mean 10 and variance 25 into 1 minus rho square so  therefore  i will standardize  usual thing that we do so  now  computing this probability  i will standardize the a variate here  which means i will subtract 10  and divide by the so  divide by the standard deviation so  standard deviation is 5 under root 1 minus rho square ; this is what you have so  this becomes a 6 by 5 under root 1 minus rho square so  this is the c d f for the  probability less than or equal to this so  therefore  i mean the cumulative density function  for the standard normal so  this minus this is minus 6 this  and again from symmetry of the standard normal distribution  around the origin we can write this as twice phi of 6 upon 5 under root 1 minus rho square minus 1  because this can be written as 1 minus of phi of 6 upon 5 under root 1 minus rho square minus sign outside so  therefore  this is what you get  and you are given this is equal to 0.954 or a 6 upon this  is equal to 1.954 by 2 which is 0.955 so  if you look up these standard normal tables  the value of z which corresponds to 0.977 is 2 ; that mean  phi of 2 is 0.977 so  this you can obtained from the tables  for the standard normal and so  this means that this number 6 by 5 under root 1 minus rho square should be equal to 2 so  from here  you do a simpler arithmetic square everything  so you get 136 a 1 minus rho square is 36 upon hundred so  rho square is this so  the absolute rho is 0.8  but you are given a rho to be positive  and therefore  we will take a positive value from here  which gives you rho is 0.8 so ; that means  x and y are positively correlated if rho was minus 0.8  then we would say that and y are negatively so  the relationship between this of course  throughout this we have also been able to establish  that your correlation coefficient or the covariance can measure effectively  linear relationship between the variables  but it fails to show you a quadratic relationship and so on  so we saw that  refer slide time  39  32  so  this comes to sort of our treatment of a conditional expectation  and how this can be used  for computing various things in fact  for computing your actual this thing  because we have shown other that this result also expectation  is expectation x and so on and then here this result we have obtained for you  and then i have also shown you the roll of a conditional expectation as a best predictor  so this is it let me now discuss exercise 6 with you  which is related to what all we have discussed in the last three lectures  refer slide time  40  12  so  a fair die is rolled three times there should be a full stop instead of comma let a random variable x i be equal to the number that appears on the i th trial  for i varying from 1 to 2 3  and then we defined y as the max of x 1 x 2 x 3  so the largest numbers so  up to on the die has been rolled 3 times  then you record the numbers that were that show up  and then you take the maximum one so  y is the value of the maximum of x 1 x 2 and x 3 find distribution function and probability density function of y so  the distribution function means ; cumulative distribution function  and probability density function of y so  this is question one question seven consider the joint probability density function of x comma y  given by f x y of x comma y so  here it should be x and y as suffixes are the bigger the capital one and small x y is equal to 2 minus x minus y x between 0 and 1 and y between 0 and 1 0 otherwise now  here a part three  i want you to find so  part 1 says  find the conditional probability density function of y  given x equal to small x  and then in part 2  i want you to find the expected value of y given capital x equal to x and e y then three i want you to find out e y  though i want you to show that e y is actually equal to e conditional expectation of y given x so  what we have been doing in a lecture also we have been verifying  you know we have been computing e y independently  by first computing the marginal of y  and then its expectation  and secondly  by breaking it up into first the conditional probability conditional expectation of y given x  and then we take the expectation again so  you have to say that the 2 processes redo the same answer now  question two i already discussed with you in the lecture so  you can have an alternate expression for the correlation coefficient  when x and y are given to be 2 random variables question three  is that x and y have the joint probability density function f x y equal to one so  y lying between minus x and x and x between 0 and 1  so please be careful when you draw the boundaries for y  because you see 1 boundaries y equal to minus x and other is y equal x so ; that means  your y varies from i hope you can just make sure that so  you can  see along the x axis  you will have 1 line  y equal to and the other will be in the in the fourth quadrant y equal to minus x  and therefore  your y will be vary from minus x to x so  this is what you have to careful and then you have to draw the graph of so  given the joint density function  you will compute the conditional  because you have to draw the graph of expectation of y given x equal to x  as a function of x so  you know how to do it you have to compute the conditional p d f  and then compute the expectation y given x equal to x  and also you have to draw the graph of so  find out both the conditional p d fs ; conditional p d f y given x  and conditional p d f x given y as a function of y so  you get some feeling about the question four so  suppose the conditional probability density function of x 2 given x 1 equal to x 1  is given by this function this is the conditional p d f  so x 2 positive  and its 0 otherwise so  the reason on which it is defined so  x 1 equal to x and that f x 1 a marginal of x 1  is also given by this function  where x 1 is positive so  both the variables are supposed to be positive  take positive values  and so again i want you to find out expectation of x 1 given x 2 equal to x 2  and then also find expectation x 1  and correlation x 1  x 2 so  you should be able to do it  because you have all the tools and this thing question five ; x 1 comma x 2 to be a 2 dimensional discrete random variable about are 2 discrete random variables with joint probability functions so  now  you have to compute correlation x 1 x 2  and are x 1 x and 2 independent random variables so  remember even if your correlation coefficient is 0  it will not necessarily imply that x 1 and x 2 are independent so  to verify you will have to compute the you know show that for  or find at least 1 pair of values of x 1 and x 2 for which the probability x 1 equal to that number and x 2  equal to a particular number  is not equal to the product of individual probabilities if you can show that  then you can conclude that x 1 and question 4 not independent  but otherwise you will have to go on verifying for all possible pairs  which means you have eight pairs so  for eight pairs if you can show that the probability of the product  is equal to the product of the individual probabilities  then you can conclude that they are independent for the discrete case  this is the only way you can do it  refer slide time  46  19  question 6 ; using the result that we just obtained this result for i just obtained it for you  that expectation or i am sorry here there should be no comma so  expectation of x y so  p is removed the comma expectation x y is equal to expectation x into expectation y given x so  i just proved this result for you now using this result  show that covariance  again here this is x  expectation y given x is covariance x  y so  the comma in the last 2 terms is  but here when you saying the result is expectation x y so  comma is to be removed  therefore  you can use this result  or show this result  using what we have proved just now question seven consider the joint probability density function of x  y given by f x y of x comma y so  here it should be x and y as a suffixes are the capital once and small x y  is equal to 2 minus x minus y x between 0 and 1 and y between 0 and 1 0 otherwise so  part 1 says find the conditional probability density function y given x equal to x  and then in part 2 i want you to find the expected value of y given x equal to x and e y then three i want you to find e y  though i want you to show  that e y is actually equal to e a conditional expectation y given x so  what we have been doing in the lecture also we have been verifying  you know we have been computing e y independently by first computing the marginal of y  and then its expectation  and secondly  by breaking it up into first the conditional probability a conditional expectation y given x and then we take the expectation again so  you have to say that the 2 processes redo the same answer question eight ; is x y z are 3 random variables and a and b are 2 constants  proved that covariance of x comma a y plus b b is this so  i had done for you when the constant a was with x  now you please do this  you should not be  because remember in fact  you can immediately do it  because covariance x comma a y plus b is covariance a y plus b comma x and therefore  from that result  but then i have added up plus b here so  please work it out  and show that this result is true then the correlation coefficient of x comma a y plus b  there will be no  because you see a numerator there will be a from here  and then in the denominator also when you take the variance of a y plus b  a will come out and so  the a a will cancel and of course  a has to be positive here  because in the variance you will take out a  only if a is positive otherwise you have to take out absolute of a so  let x 1 x 2 x 3 be 3 independent random variables  each with variance sigma square so  there are three independent random variables with the same variance  if we define new random variables so  here w 1 is x 1 w 2 is root 3 minus 1 upon 2 of x 1 plus 3 minus root 3 upon 2 of x 2 and w 3 is a linear combination of x 2 and x 3 show that a correlation coefficient of between w 1 and w 2  is equal to the correlation coefficient between w 2 and w 3  which is equal to half while w 1 and w 3 are uncorrelated so  i just try to i mean the purpose of giving the exercise was that you see that  taking this linear combination some turn out to be correlated  and some pairs turn out to be uncorrelated so  this is what you have to show now  tenth question is a fair die is successively rolled  and let x and y denote respectively the numbers of rolls necessary to obtain a 6 and a 5 so in fact  the 6 part we discussed took at length and now so  you are asking for so  is the number of rolls required  till a 6 shows up and y is the number of rolls required until a five shows up so  now  find expectation x so ; that means  you will write down the probability match functions for x and y  and then compute e x  compute conditional expectation of x given y is equal to 1  and conditional expectation of x given y is equal to 5 so  it should be easy computations ; once we have already handled the case  when you had to roll the die till a 6 showed up introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  19 inequalities and bounds  refer slide time  00  15  so  the next topic we want to talk about  is inequality  statistical inequalities and of course  one we have already seen  which is the cauchy-schwartz inequality  but there some other important  once which we will talk about now now the role of inequalities  is that you get bounds on probabilities of certain events  and this is different from the approximation  because the inequalities make a very definite statement so  it is a definite fact about randomness you have some event  and you want to you are able to say that  the probability of this event  will be less than or equal to a definite number so  you give a bound  lower bound upper bound  whatever is possible mostly we will see that we talk about upper bounds and of course  another thing is that  this is different  the inequalities give you information which is different from approximations  because approximation may be good bad  but here the inequalities trying to tell you  the probability of a certain event  is less than this particular number  which the approximation does not says approximation says that the probability may be this  and then depending on so  therefore  they have a very definite role to play ; the inequality  in your statistical analysis of data and so on so  see what happens is that when  in the absence of much knowledge about the distribution of sample values  you take different kinds of samples  and then you do not know much about the distribution of the population from which you are taking the samples and then to derive bounds for probability of events  you know depending on the sample values  is is very helpful  and that is what we do through this inequalities so in fact  it may just happen that we may know  the mean or the variance of the population with the sample values are coming  and that is it  we may not know the nature of the distribution exactly so  then it helps to  be able to compute bound on the probabilities of certain events so  the first one  simple one is markov inequality  and this the statement  is that the x is the random variable  that takes only non-negative values then for any real number a greater than 0 ; probability x greater than or equal to a  is less than or equal to expected x upon a and this is not difficult to prove  because if you are now define this indicate valuable where variable so  which takes value 1  when x is greater or equal to a and 0 otherwise so ; that means  yeah so  now  when you write x greater than or equal to a this implies that 1 is less than or equal to x by a ; that is and since i is equal to 1 whenever x is so ; that means  i can write that i is less than or equal to x by a now taking expectation of both sides so  when i take expectation of both side  i get expectation i which is less than or equal to expectation x by a  but expectation x by a is 1 by a expectation x so  this i am just relating the 2 random variable i and x so  this is 1 by a this and expectation i would be  because this is i is equal to 1 with probability x greater than or equal to a so  expectation would be 1 into probability x greater than or equal to a plus x equal to i equal to 0 into probability that x is less than a  but since i is 0  so that is no contribution so  expectation i is actually equal to probability x greater or equal to a into 1 and where did we use  the fact that it ’ s non negative variable i used it from here  saying that if i is less than or equal to x by a then the expectation will also  when i take the expectation of both sides  the inequality will remain intact and therefore  this is less than or equal to 1 by a e x  or probability x greater than or equal to a is less than or equal to 1 upon a into expected x so  you see if for this event  just knowing the expectation of the random variable  i can compute a bound for the probability of this event  which is given by 1 by a into e x  refer slide time  05  10  let us look at the chebyschev 's inequality  which says that if x is the random variable  with finite mean u and variance sigma square then for any k positive  expectation of x minus mu  absolute value greater or equal to k it should not be expect probability chebyschev 's inequality is for giving an upper bound on a certain probability  which is probability absolute value of x minus mu greater than or equal to k  is less than or equal to sigma square upon k square so  mean excess of mu and its mean so  when you take so  actually this can also be written as expectation of x minus mu whole square and then divided by k square so  that is the variance and of course  i do not need the absolute sign once i have taking square so  it is this is the actually expectation of  whatever the function here so  you were taking x minus mu so  expectation of this whole square divided by k square so  we are defining this for mu as the mean of x and k some positive number so  this is the inequality so ; that means  this gives you a bound the inequality gives a bound on this probability  which has to less than or equal to sigma square by k square now we will use markov inequality to probe this  we just this markov inequality so  now  let me define y as x minus mu whole square  and this will be therefore non negative  and the markov inequality requires  is define for  is valid for random variable which takes only non negative values  which is greater than or equal to 0  and will take a to be k square so  then the markov inequality will give us  that probability x minus mu whole square  greater than or equal to k square  is less than or equal to expectation of x minus mu whole square by k square  expectation of this divided by k square ; e x so  this is e x by a  where this is a and this is your x so  then i am writing expectation my x is x minus mu whole square so  expectation of x minus mu whole square by k square so  by markov inequality this is this and then you are saying because my a k square and my x is x minus mu whole square now  just see that this event x minus mu whole square greater than equal to k square  holds if and only if this holds since  k is give taken to be positive  so if this is true than this is true  if this is true then this must be true so  if the other same events and therefore  i can replace this probability by the probability  absolute value of x minus mu greater or equal to k this is less than or equal to sigma square by k square so  the inequality is established  and then we will through examples and so  we will the various ways in which this simple inequality can be used now  the thing another  just want to make a note here that  often we are asked to obtain bound for a probability like this  which has a strict inequality so  this is probability of x minus mu absolute value of x minus mu greater than k but then we know that this probability is less than or equal to probability of absolute value of x minus mu greater than or equal to k  because you are taking a bigger subset here so  this probability is bigger than this probability  and hence and since we have a bound for this  through chebyschev 's inequality so  the bound is also valid for this probability so  that mean we can say that probability mod x minus mu greater than k  is also less than or equal to sigma square by k square  this is a whole idea and through when we discuss many examples  it will turn out that we have to actually compute  this bound for this probability so  we will see that  this can be again estimated by  not i should not use the estimate because this probability is less than or equal to this  and chebyschev 's inequality gives as a bound for this so  therefore  the same bound is valid for this probability also  refer slide time  09  47  now  one can also obtain  i mean 1 can there are more than 1 ways of obtaining these inequalities so  i will just give you the alternate proof  which says that if and so  i will start with the expression for sigma square which is  expectation of x minus mu whole square so  you are taking k on either side so  now  i can and this integral will be minus infinity to infinity of x minus mu whole square f x d x so  this integral i break up into so  minus infinity to mu minus k ; that means  this point  and then it will be mu minus k 2 mu plus k and then mu plus k 2 infinity so  i break up the integral so  the total integral minus infinity to infinity  i break it up to these three now  if you look at this expression for example  here x is greater than mu plus k it is going up to infinity  and remember k is positive number so  x greater than mu plus k implies that your x minus mu is greater than k so  it actually this is implied so  if this wherever x is greater than mu plus k  it means at x minus is greater than k  and similarly here your x is less than mu minus k so  for x less than mu minus k  it implies that your x minus mu is less than minus k and this is a  because again this is  you know x minus mu whole square you are integrating x minus mu whole square f x d x from mu minus k 2 mu plus k so  this must be a non negative quantity it can or be negative  because this is non-negative  this is none negative so  therefore  the equality if i remove this  then the inequality changes to inequality  refer slide time  11  49  secondly  as we said that in this interval mu plus k 2 infinity  x minus mu is greater than k so  here again f x is a non negative function so  if i replace this by k square then i am taking a lower value of the whole integral so  again the inequality gets strengthened  and similarly here ; your x minus mu is less than k in this interval also minus infinity to mu minus k  your x minus mu is less than minus k so  square would be  what will happen to square x minus mu whole square will become greater than k square in this interval again  because x minus mu is less than minus k so  when i square up x minus mu whole square  it will greater than k square so  then in both these integrals  i replace x minus mu whole square by k square  i am taking the lower value  underestimate of the integral  and therefore  sigma square is greater than or equal to k square of f x d x  this is minus infinity to mu minus k plus integral mu plus k 2 infinity k square f x d x but  this is nothing but k square of is a constant so  this is probability x less than or equal mu minus k plus this is probability x greater than or equal mu plus k mu plus k 2 infinity  but then if you bring mu to this side  this will be probability x minus mu less than or equal to minus k here this will be probability x minus mu greater than equal to k so  probability of absolute value of x minus mu greater than or equal to k so  what is written is this strict inequality  but it should actually be  probability of mod x minus mu greater than or equal to k so  we have the inequality sigma square greater than or equal to k square probability of absolute value of x minus mu greater than k  and so that gives us the inequality  if you wanted to prove so  this is chebyschev 's inequality this again gives you a upper bound on the probability mod x minus mu greater or equal to k  once we know the variance x so  this proof can be imitated for the discrete case also ; that is when x is a discrete random variable with finite variance  and there will be a probability mass function also defines with it  and immediate corollary is that  if you put k equal to epsilon sigma  where of course  epsilon sub non negative number then the chebyschev 's inequality becomes greater or equal to epsilon sigma ; this is less than or equal sigma square upon epsilon sigma square which is 1 by epsilon square  and if i divide here by sigma  sigma being a non positive number so  inequality does not change  and probability x minus mu by sigma so  this is  you can say standardized variable  you standardize variable x so  this greater than or equal to epsilon  is less than or equal to 1 upon epsilon square ; simpler version of the chebyschev 's inequality so  we would like to now work out some examples  to see how these bounds can be used  refer slide time  15  22  so  let us consider a few examples on these inequalities that we have just discussed this example says that is a random variable  with mean and variance  both equal to 16 so  compute a lower bound on probability that x lies between 0 and 32  using chebyschev 's inequality  because here we can not use markov inequality it is a 2 sided thing and yes and again i am fine ya so  therefore  we will use the chebyschev 's inequality here the solution says that you convert this probability to probability of 0 minus 6 so  just subtract 16 from both the sides so  it will be probability 0 minus 16 less than x minus 16 which is less than 32 minus 16 so  the 2 events are the same  and then this reduces to probability of absolute x minus 16 is less than 16 this is minus 16 and this is 16  so absolute so  now  this is in the form of well this is the opposite of the  compute the lower bound for greater so  now here i will have to write this is 1 minus probability absolute x minus 16 greater than or equal to 16 we had strict inequality here so  this was strict  and therefore the opposite event would be the compliment event would be absolute x minus 16 greater than or equal to 16 since chebyschev 's inequality gives an upper bound so  when i replace this by its upper bound minus of that will become so  the equality here will change to greater kind because i am writing ; for this i am writing a bigger number  but the minus will become a smaller number  and therefore  this probability will be greater than or equal to 1 minus expectation of x minus 16 whole square divided by 16 square  but this we know is the variance of x which is 16 so  therefore  this is 1 minus 16 upon 16 square  and so this is 15 by 16  and you can see  that is a fairly loose bound so  15 by 16 is a number close to 1 yes and there will be  but anyways so  i am trying to show you that  these bounds that you get are rather loose they are not very tight  but some situation they are quite helpful also now another example is  from fast from past experience ; a professor knows  that the test score of a student  taking her final exam  is a random variable with mean 65 ; that is not bad if the mean is 65 out of 100 then students are good so  let us see  given upper bound for the probability that the students test score will exceed 85 so  you need a upper bound for the probability so  therefore  we just know that the mean is 65  and that is it  and using that we compute  refer slide time  19  06  so  here you will to answer this  you will simply use markov inequality  and that will give you probability x greater than 85 so  your a is 85 so  this will be less than or equal to expectation x upon 85  which will be 65 upon 85  so 13 by 7 now  markov inequality says  that probability x greater or equal to a  is less than or equal to expected x by a  but we can also use this markov inequality for computing an upper bound  for the event x  for the probability of the event x greater than a since probability x greater than a  is less than or equal to probability x greater than or equal to a so  therefore  probability x greater than a will be less than or equal to expected value of x divided by a so  therefore  when to compute the upper bound for the probability x greater than 85  i could use the number e x divided by 85  and this is what we will use for future computation also that follows so  this is the answer that you get from markov inequality now  if there is a additional information  that the professor knows that the variance of a student ’ s test score is equal to 20 so  if you have knowledge of the variance  then you can use chebyschev 's inequality  and then you will say that probability absolute x minus 65  is greater than 20 so  this probability will be less than or equal to expectation of x minus 65 whole square upon 20 square  because this is your k so  that is 20 square  and therefore  since we know that the variance of x is  x obviously  is the test score so  then that is 20  so 20 upon 20 square this is 1 by 20 of course  the number are little contrived  does not matter see this event  is actually probability x minus 65 greater than 20 either this is greater than 20  or this is less than minus 20 so  and you were looking for this probability  but in any case  this is probability x minus 6 x is less than 45 so  i could write plus here  because the 2 events are disjoint so  in other words if you want a bound for probability x minus 65 x x yeah this this will  your probability x greater than 85 plus probability x less than 45  which is 1 by 20 so  in other words  your probability x greater than 85  this is less than or equal to 1 by 20  because this will be something positive so  you will subtract from 1 by 20 so  therefore  this bound is definitely  i mean there is a dramatic difference between 13 by 7 and the number which is 1 by 20 so  you see the moment you have more information about the distribution  about the random variable  you can get better bounds for the the bounds are tighter so  this was just  i think i just sat down and contrive these numbers and though  so they may not be look realistic  because 20 is a probably high number for the variance so  therefore  there is a dramatic change  because you see this this had no knowledge of the variance so  i just computed this so  this number we computed knowing the expected value so  if here the variance is much smaller  then ; obviously  this probability will also be  this bound will be higher so  this is just to show you that the difference between the two bounds now the second part of the problem is  that how many students will have to take the exam  to ensure with probability at least 0.9  that the class average would be within 5 of 65 so  how many students so suppose  we assume that there are n students  were taking the exam  and then the class average would be given by so  class average would be a summation x i  i varying from 1 to n divided by n  which in our notation we can also write is x bar so  that will be your class average so  what they saying is  that the class should be within 5 of 65 so  it is either 5 less than 65  or a 5 more than 65 so  therefore  this class have average should be within 60 and 70 so  this is the probability that you have to you are told that this probability should be at least 0.9  and then you want to know how many students should take the exam  so that this probability is at least 0.9 ; that means  its greater than or equal to 0.9 so  here again i am trying to standardize  or cut it in the form of the chebyschev 's inequality so  x bar minus 65  because mu of x bar is  the expected value of x bar is also 65  since each exercise so  therefore  the 60 minus 65 less than or equal to x bar minus 65  less than or equal to 70 minus 65  and then i can also here divide by so  what is the variance of here variance x bar will be variance of  any of the x i the same divided by n so  because variance x i divided by n square  so this becomes this  so under root of this so  that will be under root of 20 by n so  if i divide both sides by under root of 20 by n  the event does not change so  this is what i have now  and this is 1 minus probability x bar minus 65 upon under root 20 by n so  this gives me ; that mean this is my  i mean i am applying chebyschev 's inequality here ; this is greater than 5 by under root 20 by n so  this would be again  because i am writing 1 minus of this so  if you have less here ; that means  this is less than some number by chebyschev 's inequality so  minus that will become greater  and so this is 20 by n into 25  because what is the ; have i written it correctly here so  you want to chebyschev 's inequality this will be what this is this number  if i just write this number  this is less than or equal to expectation of x bar minus 65 upon 20 by n this whole square divided by  you can say 25 n by 20  but this has variance 1 so  actually it should be yes so  see this has variance 1  because i have standardize it so  expectation x bar minus 65 upon under root 20 by n whole square has variance 1 so  the number is 20 upon n 25 so  this should be  and this is greater than or equal to so  my probability and therefore  if i put this equal to 0.9  then my at least part is satisfied so  the value of n that gives me this quantity equal to 0.9 will satisfy  because the probability that i have written on the left hand side  is greater than or equal to this  refer slide time  27  42  20 upon 25 n equal to 0.1 implies n is equal to 8 and not 80 as written therefore  for n greater than or equal to 8  the class average will be within 5 or 65 so  you know lots of different kinds of probabilities you can obtain via  you know using the chebyschev 's inequality you can get the bound  you can get estimates of the numbers and so on  refer slide time  28  11  so  let us consider this example ; it says that  it cost rupees 1 to play a slot machine see now some of you have an idea that you put in 1 rupee  and then if you are lucky  some money comes out  otherwise nothing comes out so  the machine is set by the house so  wherever your this slot machine is put  the machine is set to pay rupees 2  with probability 0.4 5 and nothing with probability 0.55 so  you see you put in a rupee and then with probability 0.45  you expect to get 2 rupees otherwise with the probability 0.55 you do not expect to get anything so  you lose that rupee fine so  fine a proximate probability that after 10,000 plays of the machine  the houses winnings are between rupees 800 and rupees 1200 so  you see a winning means that when the house has to pay  to the player then its loosing since when the player puts in 1 rupee  and the house has to pay 2 rupees  then that is a loss for the house so  therefore  x i is equal minus 1 is with probability 0.45  and x i is equal to 1 probability point so  this represents the earning of the machine  in the i th play of the game  when the some slot machine is being played for the i th time so  x i is equal to minus 1 with probability 0.45  and this is 1 with probability 0.55 and of course  you can see that e x i  the expected value of x i will be minus 1 into 0.45 plus 1 into 55 so  this is 0.1 as you expect  because otherwise why would people or house want to invest money in a slot machine  if the expected earning is not positive so  this is 0.1 per game of the slot machine and similarly  the variance x i would be 0.99  because it will be expectation x i square so  once you put x i square  then this will become plus 1 into 0.45 plus 1 into 0 55 which will be 1 so  expectation x i square is 1  and then expectation x i whole square will be 0.1 square  so this becomes 0.99 so  the variance of each x i is 0.99  and earnings of the house are represented  total earnings are 1 to 10,000 so  sigma x i summation from 1 to 10,000 gives you the earning of the house  in which you know losses and incomes are included the net net income the net earnings of the house is sigma x i i varying from 1 to 10,000 and so  expected value of the earnings is rupees 1000  because this is 0.1 multiplied by 10,000 which gives you rupees 1000  and the variance sigma x i is 9900 now i have not standardized this here it is ok to carry on the computations with these values so now we have to compute the probability  that total earnings of the house lie between rupees 800 and 1200 so  here again we will do the same thing  we will try to standardize this probability  and i will subtract the expected value of sigma x i which is 1000 rupees on either side and so that gives me that absolute of sigma x i i varying from 1 to 10,000 minus 1000 is less than 200 so  again we have it in the right form  in the sense that now i will write this as 1 minus probability sigma x i i varying from 1 to 10,000 minus 1000 should be greater than or equal to 2 so  it saying between 800 and 1200  so i am taking strict inequality here so  therefore  the compliment event will have greater or equal to 200 so  i have set it right for the use of chebyschev 's inequality so  again the same reasoning  that this thing is less than i get a upper bounds  so therefore  minus of that will give me the lower bound  so minus of that so  therefore  this will be  this is less than or equal to variance of sigma x i divided by 200 square so  variance of sigma x i is  remember this is 9900 so  therefore  this is greater than or equal to 1 minus 9900 upon 200 square  which is equal to 1 minus 9900 upon 40,000  so this becomes this so  again ; that means  this close to 0.75  the probability so  you would expect that  because 10,000 place  and you know the machine the expected value from each play of the machine is point 1  expected earnings so  therefore  this is probably not a very bad bound so  at least so  here of course  the probability is at least 301 upon 400  it can be more so  it is understood that the chebyschev 's bound are not tight  but it gives you an idea it gives you a feeling about the probability of the event that you are trying to estimate  refer slide time  34  13  another example  because i feel that the there are so many different situation  where you have to learn to how to compute  how you can apply chebyschev 's inequality  and therefore  i just have collected the lot of a different examples so  let us look at another example here  which says that a fair die is rolled  and what you mean by independently 3 times  which means that there is not bias  so the outcome are independent so  the outcomes of the dies roll 3 times  whatever the outcomes are independent outcomes now you define x i as 1 the i th roll yields a perfect square so  x i denotes the random variable  which is equal to 1 if the i th roll gives me a perfect square and 0 otherwise so  first find the p m f of x i  and i need to do all this work before i apply the chebyschev 's inequality so  the p m f of the x i  and then of y is equal to x 1 plus x 2 plus x 3  then you have to find the p m f of y  and then verify chebyschev 's inequality so  we will compute the actual probability  and then also get the bound by the chebyschev 's inequality and compare so ; obviously  we expect that  since this gives us a upper bound so the actual probability that we compute  will be less than what we get by the chebyschev 's inequality this is whole idea  and i thought that we can if we you work out in detail  you will get a good feeling about a whole thing so  anyway so  let us see the solution procedure now 1 and 4 are the only perfect squares  in the sixth numbers that come up when a die is rolled so  1 and 4 are the only perfect squares  and therefore  probability x i equal to 1 will be 2 by 6  which is 1 by 3 and probability x i equal to 0  will be 4 by 6 which is equal to 2 by 3 for all i  and i ’ s are all so  and x i are independent so  now  you take y to be x 1 plus x 2 plus x 3  and y takes values 0 1 2 and 3  because none of the die show a perfect square so  then this values 0  one of them shows a perfect square  two of them show a perfect square  or all three show a perfect square so  the values possible values of y are 0 1 2 and 3  and not difficult to compute the p m f of y  because y equal to 0 means that all 3 variables take 0 value  and since they are independent therefore  it will be product of probability x 1 equal to 0 x 2 equal to 0 and so  that x 3 equal to 0 so  it will be 2 by 3 square  which is a cube  which is 8 by 27 similarly  probability y equal to 1  will be see now here  i just take this case that x 1 is 1 and x 2 and x 3 are 0  then they can be 3 such combinations ; where 1 of them is 1 and the other 2 was zero so  this will be 3 times  this particular probability  which is again using independents x 1 equal to 1 is 1 by 3 so  3 times 1 by 3 into this is 2 by 3 raise to 2  which is 4 by 9 so  the probability 12 by 27  and y equal to 2 again the same case  that if i take this particular event x equal to 1 equal to x 2 and x 3 0  then again the 3 combinations which will give me the same value of y which is equal to 2 so  three times probability x 1 equal to 1 equal to x 2 and x 3 equal to 0 so  this will give me 3 into 1 by 9 into 2 by 3  which is 6 by 27  and probability y equal to 3 requires that all 3 must be equal to 1  and that probability will be 1 by 27 now you can just make sure that  you have computed the right p m f  by adding up all these probabilities so  7 plus 6 13 13 plus 12 this is 1 and 6 7  7 and 12 19 19 and 8 27 so  all these probability add up to 1 so  this is a right p m f now  therefore  we can immediately compute expected value of y  which is 1 i mean i leave that to you  because now you have the probabilities  multiply by the corresponding value of y  and you add up and get this this similarly expected value of y square is 45 by 27 so  the variance comes out to be 18 by 27 so  now for example  probability y minus 1 greater than half  if you want an estimate for this upper bound  then this is less than or equal to expected value of y 1 whole square y minus 1 whole square into 4 1 by 2 square  the denominator will become 4 now  this certainly there is no verification is needed  because the actual probability can not be more than 1  whereas  this number coming out to be more than 1  because you have put a number 1 by 2 here are you with this  because 4 into 87 by 27  this number is greater than 1 so  here i do not need any verification so  more meaningful verification will be ; for example  i want to say that probability y minus 1 absolute value greater than 1  is less than or equal to so  this will be variance y upon 1 which is 18 by 27 so  now we will actually compute this probability  and show that it is less than 18 by 27  to make sure that this actually gives you an upper bound  refer slide time  40  25  if you observe that b is y is also distributed has a binomial distribution with the parameters 3  1  3 so  the probability of success is given by 1 by 3  and number of rolls is 3 and therefore  immediately you know that hence expected value of y will be n p so  3 into 1 by 3 is 1  and the variance of y will be 3 into 1 by 3 into 2 by 3 and p q which is 2 by 3  but we computed this independently as 18 by 27 which is also 2 by 3 now just want to we are we are testing the  we are comparing the actual computation of probabilities with the chebyschev 's bound so  if you want to look at this probability  absolute value of y minus 1 greater than or equal to 1 so  you see that here ; y minus 1 greater than or equal to 1  implies that y can take the value 0 2 and 3  because y is 0 then absolute value of minus 1 is 1 which is equal to 1 so  remember the event  is greater than or equal to therefore  y can be equal to 0 2 and 3  and in that case this probability will be equal to probability y equal to 0 plus probability y equal to 2 plus probability y equal to 3 so  you make this computation 8 by 27 plus 6 by 27 plus 1 by 27 ; which is equal to 5 by 9  but if you compute the chebyschev 's bound  then this will be variance y upon 1 1 square is 1  and this is variance y which is 18 by 27 or 2 by 3 so  you see when you compare these two numbers  you will say that chebyschev 's bound is a loose upper bound  because 5 by 9 is less than 2 by 3 ; say 15 is less than 18  when you compare by 9 is less than 2 by 3 and then let us see take another event so  this will be probability absolute value of y minus 1 greater than or equal to 2  which is simply probability y equal to 3 so  we can use the binomial probabilities here and so  y equal to 3 would be simply 1 upon 27  1 by 3 raise to 3 so  this by the chebyschev 's inequality will be variance y upon 4  because your k is 2 so  this 18 by 27 into 1 by 4  which comes out to be 1 by 6 so  when you compare 1 by 27 with 1 by 6  the gap widens this is loose upper bound  by the chebyschev 's inequality and now if you want to look at the event probability absolute value of y minus 1 greater than or equal to 0  then we can not apply the chebyschev 's bound  because this number has to be positive ; remember k greater than 0  so that is required so  therefore  i can not compute a bound for this so  you may compute the actual probability here  but chebyschev 's bound can not be computed what i have tried to show you  is of course  through various examples how to get the probability required to compute the lower bound by chebyschev 's inequality so  doing that  and then also try to give you feeling  that the bound we are computing are  loose bounds they are not tight ones and thirdly  now what i would like to show you in the next lecture is that  apart from computing bounds  it has also proved a very useful tool for showing we will be talking of conversion theorems in the next lecture  and that is where i will show you  how useful a tool the chebyschev 's inequality is so  that will be the next introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  20 convergence and limit theorem so  in the last lecture  we had introduced these inequalities – markov inequality and chebychev ’ s inequality  refer slide time  00  15  but i feel that revisiting them is necessary because some aspects need to be emphasized and in fact the markov inequality has its strength  and its simplicity and its generality  because the inequality is very simple to state  but this can be very useful and powerful at places and also the strength lies in its generality  because it just that you need to know that there is a random variable  whose expected value exists ; and that is it and then you can you know state facts about certain probabilities  refer slide time  01  01  so  let us see interesting applications of the markov inequality consider a group of 500 people now  the kind of … you are going to ask this question – is it possible that at least 90 percent are younger than the average of the group then  the next question is – is it possible that  at least 50 percent are older than twice the average age and  another question could be is it possible that more than one-third are older than three times the average so  let us try to see what kind of answers markov inequality will give you so  for the first part  of course the answer is yes and i will explain why but  if you look at the … if you try to get the bound from the markov inequality  the inequality says that  for x greater than or equal to e x – probability that x is greater than or equal to e x will be less than or equal to e x upon e x  because you take e x of this and then divide by this  which is equal to 1 so  that is no bound  because you know that  all probabilities are less than or equal to 1 and the converse of this event would be probability x less than e x  which would then be greater than or equal to 1 minus 1 – converse of this  because this is less than or equal to 1 so  this will become 1 minus 1  which is 0 so  again  does not give you any information so  that is what we are trying to say we are saying that  possible that  at least 90 percent are younger than so  younger than means that  you want to compute the probability of the event that  x is less than e x – younger this is what you want to compute so  i should have said here this is comma therefore  the markov inequality just tells us that  this is greater than or equal to 0 so  that is no help but  of course  you can rationalize the string that  the answer would be yes  because there may be some people who are very old ; and therefore  they will make the average go up to … so  even if 90 percent are younger ; that means what we are saying is that  the answer to this is yes  because 90 percent are younger even then the few people  who are very old  will lift the average and so this inequality would be … this is the probability of 90 percent are younger would be satisfied ; that means probability x less than e x is equal to 90.9 would be satisfied  refer slide time  03  33  so  to answer the second question  what we want is that  older than twice the average age ; that means you want the probability x greater than twice e x ; and you want a bound that  this is at least 50 percent people are older than twice the average age so  if i want this probability  then this is less than or equal to probability x greater than or equal to twice e x  because this event is bigger than this event and  this why markov ’ s inequality would be less than or equal to e x upon twice e x so  we divide by this and so  that is equal to 0.5 therefore  the answer would be yes  because probability that  x greater than 2 e x equal to 0.5 is a possibility yes  but probability x greater than 2 e x greater than 0.5 is not a possibility but  since this is possible  we will say that  the answer is yes that  at least 50 percent will be older than twice the average age so  interesting applications then  to answer the third part  that is  probability x greater than 3 times e x ; and you want a bound on this so  this is less than or equal to probability x greater than or equal to 3 times e x ; same argument is earlier and  this by markov ’ s inequality is less than or equal to 1 by 3 so  here you want that  at least 1-3 are greater than the probability ; that  at least one-third are greater than thrice the average age so  the answer is no  because this is less than or equal to 1 by 3 so  this can not be more than so  this event – the probability of this event can not exceed 1 by 3 so  the answer here is no now  similarly  let us look at the chebychev ’ s inequality  which says that  probability – absolute value of x minus mu greater than or equal to c times sigma is less than or equal to sigma square upon u divided by the square of this  which is c square sigma square so  this is equal to 1 by c square – 1 by c square and so  if you consider the event that  probability of absolute value of x minus mu greater than or equal to twice sigma  then this will be less than or equal to 1 by 4  which is 0.25  refer slide time  06  21  so  now  if you look  compare this with the some of the actual probabilities  then for x being distributed as normal mu with mean mu and variance sigma square and  you are looking at the probability that  absolute value of x minus mu is greater than or equal to twice sigma ; then the actual probability is 0.456 therefore  you can see that  this is much smaller than 0.25 and if you look at the diagram therefore  if this is the mean  the x-axis is this ; and then this is the pdf – axis for this pdf then  you see here you take the area ; that means what you are saying is that  this area lying between  because absolute value x minus mu greater than or equal to 2 sigma means that x lies between mu minus 2 sigma and mu plus 2 sigma so  these are the limits and so  here what we are saying is that  this area would be 1 minus 0.0456 this is the area  which we are depicting here and so  difference is quiet large and  this becomes even more significant or more glaring the difference between the chebychev ’ s bound and the actual bound or the actual probability if you take the probability of x minus mu greater than or equal to 3 sigma  then this will be less than or equal to 1 by 9  which is 0.111 by the chebychev ’ s inequality but  the actual probability is actually very small ; it is 0.0013  which is … see what here again … because of the symmetries remember ; so  here this would be mu minus 3 sigma and this is mu plus 3 sigma so  you are asking for … exactly so  that area i am showing that means between mu minus 3 sigma and mu plus 3 sigma so  this whole area i am saying is 0.9987 and  that is because we know that  by symmetry  this area – the tail – this part – tail part  and these two are the same and so  we have discussed this many times before also therefore  that means actually  the tail … that means this tail area is half of this – 0.0065 and  here also the tail is 0.0065 and so  therefore … so  the difference becomes bigger and bigger one can go on and looking at these interesting parts that these inequalities but  at times  they provide you … they are very useful tools and they … as i told you  for the markov inequality  it can answer some very interesting questions and  here also we will see various applications of the chebychev ’ s inequality markov inequality is not able to say much  but you can see … the thing is that  the answer would be yes  because you can always have small number of people who are very aged  whose ages are very big and therefore  the average … therefore  the 90 percent can still be younger than the average age  because these older people – they pull up the average therefore  the answer is yes now  if you look at the second question  then you are asking for the probability that  x is greater than or equal to twice e x so  twice the average age and therefore  by markov inequality  this would be e x upon 2 e x  which is 1 by 2  which is 0.5 so  markov ’ s inequality gives you the bound that  this probability can not exceed 0.5 and so  therefore  the answer here will be no so  the answer is no  because here they are asking is it possible that  at least 50 percent are older and twice the average age so  no ; 50 percent will not be older so  this probability would be always less than or equal to 0.5 and similarly  for the third question  probability x greater than or equal to 3 times e x – that will be less than or equal to e x upon 3 e x ; it is 1 by 3 therefore  again more than 1 by 3 is not possible ; more than 1 by 3 are greater than 3 times  because this probability – the bound – upper bound is 1 by 3 and therefore  again the answer is no so  i just thought that  this gives you another insight into the markov inequality and its uses and  one can go and discover more and more about the usage of this particular inequality now similarly  for chebychev ’ s inequality  i wanted to just point out that  if you ask for the probability that mod of x minus mu is … therefore  you have a random variable x  which has accepted value as mu and variance x is sigma square so  just a random variable with mean mu and variance x sigma square ; you are asking the question mod of x minus mu or absolute of x minus mu is greater than c sigma so  chebychev ’ s inequality – this would be sigma square upon c square sigma square ; this is 1 by c square so  in particular  if you put c is equal to 2  then this is a probability that  mod of x minus mu is greater than 2 sigma and therefore  this will be less than or equal to 1 by 4  which is 0.25 so  in other words  here if you … i have drawn the normal curve ; does not matter therefore  this is minus 2 mu and this will be 2 mu so  in this  we are asking for the area  that is  the probability that  this is greater than 2 sigma ; that means  the area on to the left of minus 2 mu and the area to the right of 2 mu so  that will give you the probability that  mod of x minus mu is greater than 2 sigma and  this is less than 1 by 4 in general ; universally true this is universally true  which is 0.25 now  if you compare this for normal n mu sigma ; that means  if a random variable x is mu sigma  then this probability is 0.0456 therefore  compared to this  this is rarely loose bound – loose upper bound but  later on we will see how … no matter … because of its universality – chebychev ’ s inequality  this is very useful improving many other results in probability theory so  anyway i just thought i will give you an estimate  because the normal curve is symmetric about mu and then it is bell shaped so  the mass is concentrated around mu for normal and therefore  this probability would be small  because the area lying on the left of minus 2 mu and to the right of 2 mu will be much smaller than compared to the area  which is around mu therefore  this … and similarly  if you take c to be 3  then the difference is more marked  because probability mod x minus mu greater than 3 sigma is less than or equal to 1 by 9  which is 0.11 anyway for … so  that means  it says is that  for most of the distributions  the area – the mass of under the curve lies the probability mass – lies within minus 3 sigma this is minus 3 sigma and 3 sigma ; then the area inside here is 0.9987 so  only this much area lies outside ; which means half of this i will have to be very sure that  this is this ; then the half of this half ; that means  further do it 0.0006 so  this is the area  which lies here and the both this area is 0.006 and that is 0.006 so  this is the idea therefore  chebychev ’ s inequality is an upper bound ; but  because it is applicable to all the distributions  therefore  it has its own uses and applications  refer slide time  14  46  now  the third inequality that we want to talk about is jensen ’ s inequality and  this inequality relates expectations instead of probabilities so  like for example  both these inequalities were giving you upper bounds for the probabilities of certain events but  jensen ’ s inequality relates the expectations but  before that  before i give you the jensen ’ s inequality  i need to define convex and concave functions and  some you may have already come across  for example  convex lenses  concave lenses – you may have heard of so  here the function is said to be convex or if it is twice differentiable … if a function is twice differentiable  real valued function and  it is said to be convex  if its second derivative is non-negative in the domain of f so  wherever f is defined  then at all those points if you are f double prime x is non-negative  then the function is said to be convex and  if the double derivative is less than or equal to 0  then the function is said to be concave so  therefore  the relationship between convex and concave is that  if f is convex  then it will imply that  minus of f x is concave so  now  here for example  i have drawn for you convex function twice differentiable and  what we are saying is that  if f double prime x is greater than or equal to 0  then f prime that … this implies that  f prime x is not decreasing if the … wherever you take a function f and if its derivative is non-negative  then we say the function is non-decreasing here f double prime x is non-decreasing so  this implies that  f double prime x is greater than or equal to 0 ; that implies that  f prime x is non-decreasing so  you see here for example  these are the tangents to the curve ; and see these angles – they are negative ; they are obtuse and  if all of you remember the graph of tan x  because slope is given by … f prime x is a slope ; tan of the angle – tan of this angle ; tangent of the angle that  the tangent at the curve makes so  you are … for example  this if you take this is 0 ; this is pi by 2 ; then this is pi and therefore  on this side of this  it is like this so  the function is obtuse angle and the curve is increasing so  as the angle becomes … and  then of course  this becomes … the angle becomes up to pi ; and so  tan of pi is 0 so  you are derivatives – the tan of these angles are increasing and then finally  at this point  it becomes 0 and then when you take this  then you can see that  the angles are increasing therefore  for obtuse angles  again  tan is increasing so  this is the idea therefore  the first derivative is non-decreasing also  that the tangent at any point of the curve lies below the curve  because you have seen see the function is like this so  the tangent is this so  tangent is always below the curve and so  here when you say that  minus f x ; minus f x means you will turn it upside down ; you overt therefore  a convex function you can say holds water ; a concave function will not hold water  because it will be upside down so  this thing will be up and a function will be like this so  this will be a concave function now  of course  here i have given you the definition of a twice differentiable but  for example  if you take y is equal to mod x  this is also convex but  of course  this is not differentiable so  none of these things … it is differentiable at these points  but not at the origin so  this holds  because it is constant see here the slope is minus 1 ; here the slope is 1 so  in any case  the slope is increasing  because this is this ; here it is not defined  but the … so  this is also a convex function and of course  there are many ways of characterizing a convex function so  now  i will state the jensen ’ s inequality for convex and concave functions  refer slide time  19  17  so  the jensen ’ s inequality says that  if f x is a real-valued convex function  then expectation of f x – this should be capital x  because function f is a function of the random variable x then  e – expectation of f of x is greater than or equal to f of e of x ; that means you exchange f and e ; then the inequality is this kind so  for x random variable with e x equal to mu finite so  the requirement is that  the mean – the expected value must exist for a random variable ; and if a function f is convex  then this would be e f x is greater than or equal to f of e x now  you can see that  if you replace this by … if you multiply the inequality by minus sign  then the minus sign will go inside and it will say that  expectation of minus f of x is less than or equal to minus f of e x and  since … so  minus as we said earlier when we were defining a convex function that  minus f will be concave if f is convex therefore  for the concave function  the inequality reverses so  this is the jensen ’ s inequality so  it is just relating the expected values and  you can … if the function is convex  then the inequality would be greater kind ; and for concave  it will be less kind now  you already know that  expectation of for example  x square – if the second movement exists  expectation x square is greater than or equal to expectation of x whole square ; that means the function f x here is x square and this we know is convex ; everybody knows it is a parabola or the second derivative is 2 – a constant  which is non-negative so  this is a convex function  but we already know that  variance x can be written as expectation x square minus expectation x whole square  and this is always non-negative so  from here also  it follows that  expectation x square will be greater than or equal to square of expected x consider the function f x equal to 1 by x then  if you just find out the first derivative  this is minus 1 by x square ; and second derivative would be see x raise to minus 2 so  minus 2 and minus sign – plus 2 upon x cube and  this is always non-negative for x positive and therefore  this is a convex function and so  by jensen ’ s inequality  expected value of 1 by x is greater than or equal to 1 upon expected x and  quite a few people often mistake this and they say that  expectation of this will be … so  now  you know better  because the jensen ’ s inequality says this will be greater than or equal to ; they are not the same thing ; expectation of 1 by x and 1 by expectation x are not equal so  this is also you can now assert by using jensen ’ s inequality you can consider the function log x log x – the second derivative is minus 1 by x square ; first derivative would be 1 by x so  when you take the second derivative  it will be minus 1 by x square and  this is less than 0 for x greater than 0 anyway the function – this is defined for x positive and so  by jensen ’ s inequality  expectation of log of x is less than or equal to log of expectation of x  because for concave function  the inequality reverses proof is simple  refer slide time  23  09  so  i will use the first property that  the tangent at any point of a convex function lies below the curve so  the curve always goes … – it is above the   refer slide time  23  18   and  of course  they meet at this point so  the tangent is at the point mu ; then the value here – the coordinates are mu  g  mu and so  if i take a plus b x as the tangent to g x at the point x is equal to mu ; then g x convex implies that  g x is always is greater than or equal to a plus b x and g mu will be equal to a plus b mu  because the curve and the tangent line – they meet at this point and therefore  since these holes … therefore  when i replace x by a random variable  the inequality remains intact so  g of random variable x is greater than or equal to a plus b of x and therefore  the expectation will also … they will not change the inequality so  when i apply expectation on either side  it will be e of g of x is greater than or equal to a plus b e of x ; a and b are constants so  this is what the proof and so  a plus b of e x is a plus b mu  which is g of mu ; and mu is your expected value therefore  this is g of e of x therefore  from here you have shown this inequality ; the simple proof using the convexity of the function ; and then the fact that  when you have inequality so  this a bigger function than this so  i hope you all agree that  because even if you are taking x to be a continuous random variable  then if the density function of course  is non-negative so  here you are taking the difference so  if you take the difference of g x minus a minus b x  which is a non negative function ; then integral – whatever the limits would be also non-negative and so  this will be satisfied therefore  from here to here is no problem therefore  you can prove the jensen ’ s inequality therefore  the figure is also quite explanatory now  an alternate proof  because since we have the definition of convexity  i will use the twice differentiability of the function now so  since f is convex ; so  it is twice differentiable instrument and  taylor ’ s expansion of f x at x is equal to mu up to second order terms yields so  now  those of you who feel comfortable with calculus  then you know about the taylor ’ s expansion that  every function can be expanded in the neighborhood of a point ; where  in the neighborhood  it has all these derivatives and so  here since i have assumed that  it is second order derivative exists therefore  i can write f x as f mu plus x minus mu into f prime x plus x minus mu whole square by 2 factorial into f double prime psi ; where  psi belongs to mu comma x so  such a psi exists in the interval so  whether it is mu comma x or x comma mu does not matter  because you are taking the square here so  there is a psi in this interval and therefore  this would be then exact expansion ; that is what taylor says so  taylor ’ s theorem says that  such a psi always exists now  since f double prime psi is non-negative  because f double prime is non-negative in the whole domain so  this is non-negative and this is a square – square of a real number so  this quantity is non-negative therefore  i can say that  f x is greater than or equal to f mu plus x minus mu into f prime x so  which … if you write this in terms of … so  f of x is greater than or equal to f mu ; i should have written the step x minus mu f prime x – f prime x ; just that as we did here in this first proof and now  you can take the expectation so  expectation f x – again this is same reasoning ; the inequality will not get reversed so  this will be f mu plus now  expectation of x minus mu is 0 so  you are left with only f mu here and  f mu is f of e x therefore  again the jensen ’ s inequality has been proved  refer slide time  28  00  so  i just wanted to point out this correction in the jensen ’ s inequality proof see i was giving you an alternate proof ; and there i had to expand the function f x by taylor ’ s expansion at the point mu and  the correct expansion is that  f x is equal to f mu plus x minus mu f prime mu plus half x minus mu whole square f double prime psi now  instead of mu  it got written as x therefore  you have to read f prime mu instead of f prime x and then of course  we know that  psi is a number  which is some number between mu and x and  by taylor ’ s theorem  such as psi always exists so  we are taking a second order expansion of the function f x at mu and so  this should read as f prime mu instead of f prime x and  as we go along  we might also see some more occasions to use this inequality but  i think this gives you a good feeling about the jensen ’ s inequality  refer slide time  29  08  so  an instructing example of the jensen ’ s inequality is that  investor is faced with two choices she can either invest all her money in a risky proposition that will lead to a random written x that has mean m or she can put the money into risk-free venture that will lead to a written of m with probability 1 so  these are the two choices she has and  suppose she bases her decision on maximizing an expected value of u r  where r is her return and u is her utility function so  by somebody ’ s advice or something  she has now decided that  she will base her decision to invest whether in the risk-free venture or the risky venture by maximizing the excepted value of u r ; where  r is the return function and u is the utility function so  u of r now  by jensen ’ s inequality  it follows that  if u is concave  then expected u x will be less than or equal to u of e x  which will be u of m so  the risk-free venture is better so  here the expected return of u x will always be less than or equal to u of e x  which is u of m therefore  it is better to invest in the risk-free venture now  if u is concave  then this implies that  e of u x will be greater than or equal to u of m so  the risky venture is profitable  because the expected return here would be greater than or equal to u of m this is u  is her utility function ; and in the risk-free venture  she gets exactly m returned therefore  this will be the total utility to her of the return that she gets from the risk-free venture and  this is because x is a random returned so  e of expected value of u x so  that will always be greater than or equal to u m in case the utility function is convex therefore  the risky venture is profitable and  there can be many more interesting examples of these inequalities that we have just studied so  the next thing that we want to talk about  which again has a very important role to play ; and these are the limit theorems and so  let us just first try to understand the concept of what we mean by these limit theorems so  the first definition that i want to make is the definition of sequence of random variables converging in probability to another random variable so  here this is at x 1  x 2  x n  is a sequence of jointly distributed random variables for n greater than or equal to 1 ; that means you must have at least more than one defined on the same samples space omega and  let x be another random variable defined on omega then  we say that  x n converges to x in probability  that is … so  the notation is that  x n goes to x in probability if for every epsilon greater than 0  limit of this absolute value x n minus x is greater than epsilon so  this limit converges to 0 so  in other words  in probability  the random variable x n is converging to x and  please understand so  here this is different from the concept of usual limit  where the p is missing so  in that case  when you say that  in value x n  the sequence is converging to x ; that means when n becomes larger and larger  the distance between x n and x will be very small  because epsilon is an arbitrary number greater than 0 so  i can go on making epsilon small and small but  here the limit is in terms of probability – probability of this event ; that means of this difference – x n minus x greater than epsilon becomes an impossible event  because the probability is 0 so  this is the idea of convergence in probability  refer slide time  33  16  then  the other definition that i want to make is that of … and  this is called … this convergence in probability ; i have already given one name ; it is also called stochastic convergence – convergence in measure – measure is the probability here or weak convergence so  this is one definition and  the other is the convergence in distribution so  we will say that  x n converges to x in distribution or in law if the limit of f x n t ; that means the cumulative distribution function of x n so  at the point t  converges to the distribution – cumulative distribution function of x at t as n goes to infinity and  this must happen at each point t  where f x is continuous ; so  that means … and  in fact  obviously  this is also continuous at that point so  limit f x n t – the cumulative distribution function of the random variable x n – this converges to the cumulative distribution function of f x t of x as n goes to infinity so  now  abbreviating the notation so  this says that  f n goes to f ; where  f n t is the cumulative distribution function of x n  and f we denote by the cumulative distribution function of x at t  refer slide time  34  40  so  notation for x n converges to x in distribution we also say that  x n going to x in distribution so  the notation that i have written down or the cumulative distribution function f n of x n  which is f n going to f – the cumulative distribution function of x in distribution and  d can also be replaced by l so  both these notations are valid so  this is also called weak convergence – weak convergence in law or weak convergence in distribution so  you can see the difference  because here it is only we are saying that  probability of this event is becoming 0 as n goes to infinity  just the … whereas  here the whole distribution – the cumulative distribution function – the whole of the function is converging to the cumulative distribution function of x at every point t  where it is defined  where it is continuous now  convergence in probability and convergence in law are very important and  we will see as we go long that  the numerous applications of these convergences ; and are easier to prove then  the less important types of convergence called strong convergence so  maybe in this course  i have a chance to look at one or two strong type of convergences also but  the more widely used are the weak convergences ; and these are law and probability  refer slide time  36  19  so  we will now define weak law of large numbers law of large numbers states that  if you have a sequence of these random variables – identically independently distributed random variables  i have said that  the expected value of each of them is mu and variance is sigma square and these are finite quantities ; that means  the variance   refer slide time  36  37   then  you define x n bar so  x n bar would be the average of the values up to n so  sigma x i ; i varying from 1 to n divided by n and then in simple terms  the weak law of large numbers says that  this sequence of averages x n bar as n goes to infinity ; that means when you take n plus 1  it will be average of x 1  x 2 of x n plus x n plus 1 so  this is a sequence that you are generating by taking averages of n  n plus 1  n plus 2 and so  on and then … so  this sequence converges to the mean of the … or the expected value of the random variables idea here is that … so  actually this will happen in probability so  the whole idea  because we say that weak law of large numbers so  the whole convergence – the concept is in terms of probability and so  what we are saying is that  since its converging in probability  the probability is high that … that means i can take … for large enough n  i can take x n bar as a good estimate of mu ; otherwise  how do we have  because we just have these sample values  which we have taken randomly and then we are wanting to estimate the mean of the distribution so  this would provide a good estimate for mean – for the value mu for example  if all x i 's are bernoulli  then we know that  mu is of course  is a good estimate of mu ; in the sense  this is also the probability p if the probability of success is p  then for the expected value of each bernoulli random variable  is also equal to p – the probability of success and so  what it is saying is that  when you take n large enough  then this would give you good estimate of the probability of success so  this law of large number provides way of estimating the mean of the distribution this is the whole idea so  formally  if you want to define this concept that … then we will say that  given delta and epsilon greater than 0 – some arbitrary numbers  then there exists a number m  which is a function of epsilon and delta such that when you write this probability x 1 plus x 2 plus x n upon n  which is x n bar ; x n bar minus mu in absolute value greater than delta this probability will be less than epsilon for all n greater than or equal to the number dependent on epsilon and delta so  this is simply just extending the notion of … or  just the same notion that you have about continuity when you talk of continuous functions when you want to say that  the function values – this and this for example  can be brought as close as you wish so  this greater than delta will be less than epsilon provided for n begin up ; that means n must be greater than or equal to some function  which is a function of number  which is dependent on which is a function of epsilon and delta so  the whole idea is that  as long as … and  is large enough given the delta and epsilon  you will be able to say that  this probability greater than delta is less than epsilon so  that means when i choose delta and epsilon small  then this is essentially saying that  the number x n bar comes close and close to mu so  this is greater than delta whatever i mean … so  the event will become impossible  because if i choose epsilon very small  then this probability is very small ; so  of this difference being greater than delta ; so  in probability so  the whole thing is being talked about in terms of probability so  the proof is simple and  here i will use chebychev ’ s inequality so  by chebychev ’ s inequality  this says that … here as we have seen already that  for x n bar  the variance … because they are identically independently distributed  will be sigma square by n and  the variance and the expected value of x n bar is mu therefore  this is x n bar minus is expected value so  this difference in absolute value greater than delta would be less than or equal to sigma square upon n delta square so  now  here i did say that  epsilon and delta are arbitrary  but see i can choose the epsilon to be sigma square upon n delta square so  in a way  epsilon is a function of delta ; that is ok so  then this is … i will choose the epsilon to be sigma square upon and delta square and then that will give me that  n must be … ; that means this number if i denote by epsilon  then this probability is less than or equal to epsilon for n so  from here n – the smallest value of n would be sigma square of epsilon delta square but  for all n greater than this number  this inequality will be satisfied and so  the number capital m epsilon delta can be chosen like this so  once we get that n is greater than or equal to sigma square upon epsilon delta square  this inequality is valid so  what we have shown is that  given epsilon and delta greater than 0  we can find an n such that this inequality is satisfied for all values of n greater than or equal to sigma square by epsilon delta square so  this is the m of epsilon delta in the definition for limit of the probability when we defined what we mean by limit in probability sense so  then this is the m of epsilon delta so  for all n greater than or equal to this given in epsilon and delta  then for all n greater than or equal to this number  this inequality will be satisfied and therefore  it follows immediately that  this limit of probability of x n bar minus mu in an absolute value goes to 0 as n goes to infinity  because as n becomes larger and larger  i can choose epsilon smaller and smaller here this was my … this is greater than or equal to delta here i have chosen ; yes and so  in my definition for when i defined the limit of a probability  then we chose … this is the epsilon we chose – sigma square upon n delta square so  what we are saying is that  this probability  that is  x n bar minus mu an absolute value greater than or equal to delta is less than or equal to epsilon so  when i want … so  if i choose this equal to epsilon  then i am saying … and therefore  as epsilon becomes smaller and smaller  n will become larger and larger and so  from my definition of limit in terms of probability  it follows that  this probability will tend to 0 as n goes to infinity so  this is what we … therefore  you see again here that  i have made a very good use of chebychev ’ s inequality to show you that  this probability – the limiting value of this probability of absolute value of x n bar minus mu will tend to 0 as n goes to infinity then  this satisfies the … so  by chebychev ’ s inequality  this will be satisfied and so  we have shown that  x n bar will converge to mu in probability so  essentially  this is what … so  when you take the limit as n goes to infinity  then this number goes to 0  because as n goes to infinity  epsilon tends to 0 and therefore  this limit of the probability x n bar minus mu will go to 0 as n goes to infinity so  essentially … now  of course  there can be different interpretations ; and one of these students interpreted this as like if somebody who is practicing to be let us say a swimmer ; so  what he will say is that  that means  no matter how hard i practice  my average performance will remain the same  because in probability  x n bar is converging to mu so  that means he says that  there is no scope for improvement but  again the fallacy in his argument is that  see here this result we are proving under the assumption that  x 1  x 2  x n – this sequence is independently identically distributed so  the identity part is not valid when you are practicing ; obviously  these things are improving so  your performance is improving every day and therefore  to say that  you will never rise above the … that means  your average performance will remain the same no matter how hard you work  is not correct  because your   refer slide time  46  31   themselves are changing ; they are no longer identically distributed therefore  this is not a good way to interpret the weak law of large numbers  but it certainly gives you a tool for estimating the value of the mean of the distribution from which the random variables are coming  refer slide time  46  55  so  we can now look at these examples to see the application of the weak law of large numbers so  for example  if the sequence is from exponential 1 by lambda ; that means  they are all identically independently distributed random … these samples you are taking from an exponential distribution with parameter 1 by lambda  that is  the pdf is 1 by lambda e raise to minus 1 by lambda x for all x positive then  this probability – if you take it x n bar here ; x n bar minus lambda in absolute value greater than delta would be less than or equal to again by chebychev ’ s inequality  because the … so  here expected x i is lambda – inverse of the parameter here  and variance x i is lambda square for the exponential distribution therefore  this would be less than or equal to lambda square upon … so  for the variance of x n bar would be therefore  lambda square by n so  lambda square by n 1 upon delta square ; and this goes to 0 as n goes to infinity so  we can interact … we can choose … for any delta  we can choose epsilon as i showed you here ; and it will satisfy the definition anyway therefore  what we are saying is that  x n bar would be a good estimate for large enough n  would be a good estimate for lambda for the mean of the distribution similarly  if you have a poisson … if you have this family ; if the sequence is coming from a poisson distribution with weight as lambda  then again this will be … so  here you have e x i is lambda and  variance also is the same for a poisson so  this is also lambda and so  for variance of x n bar would be lambda by n and so  this probability greater than delta would be less than or equal to lambda upon n delta square and  this will again go to 0  because lambda and delta are finite as we said that  we are talking about the situation  where the mean and the variance are finite so  this will again go to 0 as n goes to infinity and similarly  if you take this sample from … so  i am just giving you a few examples  but you will see that  this is universally true  because there we did not specify ; we simply said they should be dependent identically distributed random variables so  give 3 examples here and  if this sequence is from a normal mu sigma square  these are the sample values ; then again this will be less than or equal to … so  now  here again e x i is mu and variance x i of course is given to be sigma square so  variance x n bar would be sigma square by n this will also go to 0 as n goes to infinity so  chebychev ’ s inequality has proved to be a strong tool for proving weak convergence and  we will see that  the other … i showed you application of jensen ’ s inequality also and  we will also again look at some more limit theorems  where also we will make use of these inequalities therefore  the whole idea is that … again one needs to emphasize the fact that  we are not saying that  the value that  the x n bar will … in value tend to mu  what we are saying in probably – it will tend to … therefore  when we say it is a good estimate  this is in terms of probability ; if the probability is very high – of this number becoming closer and closer to mu … so  again  as i said  matter of interpretation  you might say that you go to a casino and you go on putting money in the machines – slot machine ; and say for a number of times  you are not successful ; so  you will say that  no  it will soon happen but  that is not true  because again it is the matter of probability yes  the probability is high  because the event is getting impossible ; i mean this probability is getting to 0 ; that is fine but  it may happen that you may have to go on playing at the slot machine for a long time before your luck turns ; that means the things change therefore  one should not say that  yes  surely  what we are saying here is that  it will happen ; that means if you flip a coin and you keep getting tails ; then surely after sometime you will get heads also but  it does not say when and  this is a matter of … so  the important thing to understand is that  we are talking in terms of convergence in probability and so  this gives you a good way of estimating the mean of the distribution ; that means you go on taking large enough samples and then you take the average  and that will give you an idea of what the mean of the distribution is  refer slide time  52  43  so  we will continue the discussion with the central limit theorem and what we are saying is so … here i want to address the questions for example  what does the distribution of x n bar look like ? this is one question we want to answer ; and we will use the central limit theorem to do that and then the second question would be how fast does x n bar converge to mu ? so  now  let us look at the … the central limit theorem states that  sigma x i minus n mu upon under root n sigma will converge to n 0 … that means  normal – standard normal distribution as n goes to infinity ; that means  this variate will … because this is a random variable for all n so  this will converge to the standard normal variate as n goes to infinity now  here because expected value of sigma x i – i varying from 1 to n will be n mu ; and variance of sigma x i ; i varying from 1 to n will be n sigma square ; the x i ’ s are sequence of independently identically distributed random variables so  this is … and therefore  you are standardizing by subtracting the mean of this variate so  minus n mu divided by the standard deviation  which is root n sigma therefore  this we are saying that  after standardizing the variate sigma x i  i varying from 1 to n  central limit theorem says that  this will go to n 0 1 so  in this distribution and  the weak law of large numbers said that  in probability  sigma x i  that is  sigma x i by n will converge to mu in probability but  what we are going to say here show … this is to answer the first question  that is  if you now divide by n  then this becomes sigma x i ; i varying from 1 to n divided by n and  there will be an n here and there is a root n so  that becomes root n times divided by sigma so  this whole thing and  we are saying that  this was … therefore  now  this is … and therefore  the central limit theorem says that  this converges to this variate  will converge to the normal 0 1 so  i can write down sigma upon root n here and so  essentially  what we are saying is that  x n will converge ; that means the distribution of x n bar as limiting distribution of x n bar will be … so  right now  the distribution of x n bar for large n we are saying will be close to mu normal – mean mu and sigma and variance sigma square by n and then of course  as n goes to infinity  we are saying that … so  in other words that  the central limit theorem says that  if you take any distribution  the x 1  x 2  x n were coming from any distribution ; but  then when you talk of x n bar and for large enough n  then the curve will become bell-shaped ; it will get closer and closer to the normal curve for large n and  the limiting value – this will converge to variate  which has the normal – standard normal distribution and so  clt – the central limit theorem implies the weak law of large numbers  because weak law of large numbers only said in probability x n bar will converge to mu the probability of mod x n bar minus mu will converge to 0 and so … but  here it is saying that  in distribution so  x n bar in distribution will converge to standard normal … i should not say  because if i am taking x n bar ; if i am simply taking x n bar  then this will converge to n mu of … so  i have simply said it here for x n bar ; i have not talked of the limiting value what we are saying is that  this will be approximated by normal mu comma sigma square by n so  the proper statement is that  x n bar – the distribution of x n bar for large enough n will look like a normal mu comma sigma square by n but  you can see that  as n goes to infinity  this thing will become … so  the whole mass will get concentrated on mu only for x n bar but  then if you look at x n bar minus mu  this absolute value then  we are saying that  the … or  if you are looking at x n bar minus mu upon sigma by root n ; then this will converge to … so that this can be approximated by standard normal but  when you look at x n bar  then this will be approximately normal mu comma sigma square by n  refer slide time  57  37  so  the final theorem we can now state as … so  if you have x 1  x 2  x n and so on – sequence of identically independently distributed random variables ; each x i having mean mu and variance sigma square  and this variance is finite so  if the variance is finite ; that means the variance exists ; then the means will exist so  we do not have to separately say that  mu is also finite and variance is also finite it is enough if you say that  the variance is finite then  it implies that  the mean also exists then  the distribution of – see this is important – of x 1 plus x 2 plus x n minus n mu upon root n sigma this converges to the standard normal distribution – 0 1 as n goes to infinity this is what … that is  in other words  we want to say the same thing is that  the probability that x 1 plus x 2 plus x n minus n mu upon root n sigma is less than or equal to a this will converge to form – there 1 upon root 2 pi integral minus infinity to a e raise to minus 1 by 2 x square dx for all a belonging to r  because this is the cumulative distribution function for … so  this is what you are saying is this is probability z less than or equal to a ; which i have written down here ; that is  if you define the random variable y n as sigma i varying from 1 to n of x i minus n mu upon root n sigma ; then the cumulative distribution function of y n as n goes to infinity will converge to the cumulative distribution function of the standard normal variate z  and this is for all a and  this is what remember ; earlier i had defined convergence in distribution or in law  which said that  the cumulative distribution function of sequence of random variables converges to a particular cumulative distribution function ; then we say that  this sequence of random variables converges to that particular random variable in law or in distribution and so  here this is what we are saying that  the sequence of random variables y n as n goes to 1  2  3 up to infinity ; then this sequence of random variables converges to standard normal variate in law so  now  we had looked at the central limit theorem in various forms ; its implications and of course  we will continue looking at its applications more and more introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  21 central limit theorem  refer slide time  00  14  so  we will as i said in the last lecture  we will now after having stated the central limit theorem  talk to you about its importance ; we will actually see now once i prove the theorem and then i give you applications  you will see how important the theorem is  and how widely used the theorem is so  as we said that the central limit theorem say that if you have the sequence of identically independently distributed random variables with mean and variance finite  then we say that this  sum of these random variables x 1 plus x 2 plus x n  it will have mean mu and variance n sigma square so  this will go to  this will converge to n  0  1  as n goes to infinity ; that means the distribution no matter what the original distribution of the exercise was ; now when you take the sum and you let n go to infinity  then this random variable will converge to the standard normal variant so  this is convergence in distribution  right or in other words  as we can state it in other way also  this is for any  a which is from minus infinity to infinity of finite number then  the probability of this number being less than or equal to this random variable  less than or equal to  a  will converge to the standard normal ; that means  this is your f z a  fine ; and this is your f z n a so  this converges to this as n goes to infinity so  in distribution the convergences they are  right now  in order to prove this i need to use this lemma which talks about uniqueness of the m g f  and i will not give a proof for this we will just except the lemma as it is so  this says that if z 1  z 2  z n  again is a sequence of random variables having distribution functions f z n  and m g f m z n  right ; and greater than or equal to 1 so  the distribution function is f z n  and the m g f of z n would be m z n  and greater than or equal to 1 let z be a random variable having f z as its distribution function and m z add its m g f  right so  then we  if m z n t converges to m z t that means as n goes to infinity this movement generating function converges to the movement generating function of the variant f z  then we say that the corresponding distribution functions will also converge to the distribution function of z ; that means  if  so this is  this talks about the uniqueness of the m g f that means  if the m g f  m z n t converge to m z t for the variant z  the m g f of z is m z t ; as n goes to infinity then the corresponding distribution function of z n which is f z n t will converge to the distribution function of z  for at all points t at which f z t is continuous which means that it is defined  right so  this is the idea ; that means  m g f uniquely  and while discussing m g f  i also tried to tell you that m g f uniquely give you your density function or the distribution function because the parameters you can compute ; and actually not only the parameter  but the distributions are  is the same i mean  once you get a m g f you can uniquely fix the distribution  right  of their form of the m g f function so  this is what we are stating here  which we have also been using otherwise so  now  let us ; so the proof is not very difficult to straight forward so  i am just rewriting this function  this random variable  mu is getting attaching to each of the exercise  refer slide time  04  22  so  therefore  the same thing can ; so now  i am writing the m g f of the random variable which we want to show well converge to standard normal variant and distribution so  this can be  at a point t  i am defining the m g f so  this is in fact  e raise to this whole thing into t  right the m g f of this would be e raise to whatever you want to call it  y n or something  or z n  then e rise to z n t so  m g f excepted value of e raise to z n t you can say  right ; which i can write as x 1 minus mu upon sigma root n plus  x 2 root n plus x 2 minus mu  and so on now  since x 1  x 2  x n  are identically distributed and independent random variables  so the m g f here  by again by the property of the m g f ; well  the thing is that  yes  i should have ; so yes  the order has been a little  because i will be talking of the m g f for the independent random variables  you know  more than 1 variable so  that should have come  the lecture should have come before that ; ok  anyway we can talk about it so  what i am saying here is that this m g f can be written as the product of the m g f of x 1 minus mu upon sigma root n raise to n because of the independence this anyway also follows from independence because you see  when you write this let me say  i was saying z 1 plus z n  and you are taking t so  when you write expectation of this  right  because the p d fs are so  this will be z 1 into f z n because the join density function would be this  right so  your expectation when you write of this would be whatever given  n th order integral from minus infinity to infinity  depending on if the variants are defined ; i am taking the general definition into d z 1  d z n  right so  then you see you can separate out the integrals  and so each integral will be the m g f of this ; and since they are identical it will be the same  right i am writing f z 1  f z n  where they all the same  f z 1  f z 1 so  therefore  you can immediately see from here that this will be  that this m g f can be written as this because of independence and identically distributed random variables now  this i can write as  this should have been at t ; m g f at t  right and so let me just separate out this so  this will be m g f of x 1 minus mu  and i am taking the variant to be t upon root n sigma ; so this raise to n now you expand this ; remember this is  when you writing this  so i am just expanding my t x  and this would be  this will be expectation of 1 plus t x plus t x whole square by factorial 2  and so on  and the expansion of e raise to t x so  that is what i am doing and then  i am taking expectation inside because ; so now  if you  in the central limit theorem when i assume that they have finite variance ; so another assumption i should have made is that because i am using the m g f way of  i am using the moment generating functions to prove the theorem i should have also said here that m g f x i exist and so obviously  we will be talking about all those  ts  at which the m g f exist  right  at which the m g f is defined so  therefore  i take this expectation since the m g f exists so  i can take the expectation inside because the series is convergent series  and so i can take the expectation inside so  this is what you have raise to n and  you see here  i am not considering higher powers of t because see this is square then it will be t q  t 4  and so on so  i am just writing this whole as a  you know  higher order terms of t  powers of t  right so  then see  expectation of x 1 minus mu is 0 because we have taken  assumed that each x i has mean mu so  this term is 0  and therefore you will be left with this thing so  and expectation of x and minus mu whole square would be sigma square so  this is 1 plus sigma square t upon  should be t square and sigma square ; there should have been a 2 also ; sorry  this will be 2 factorial  and so on so  therefore  there will be a 2 here  right  because t x square upon 2 factorial  and so on ; and then higher terms  higher order terms of t  right ; this raise to n now  so as n goes to infinity  you see  because n raise to half is in the denominator so  then when you say take the third power it would be n raise to 3 by 2  and so on so  these things will go to 0 as n goes to infinity so  but here ; so i will ignore this ; and then you see what happens to this ; 1 plus sigma square so  the sigma square cancels out  t square by 2 n  right ; and so if you write this as t square by 2 into n  and then raise to n so  i hope  you know  that most of you that this will converge to e raise to t square by 2 because n in the denominator and then n power so  as n goes to infinity i can safely ignore these terms so  then this will be  this will converge to e raise to t square by 2 because sigma square sigma square cancel out  and you are left with t square by 2 into 1 upon n raise to n so  this converges to t square by 2 as n goes to infinity  right and  you know that this is the m g f of random variant which is normal 0  1  right and so we have shown that using the lemma because i have shown that the m g f of this random variable  sigma x i minus n mu upon root n sigma  that converges to the m g f of a standard normal variant therefore  by the lemma i can assume that this random variable converges to n 0 1 in distribution as n goes to infinity  refer slide time  11  30  so  you know  using the m g f the proof really simplifies and so in the proof i have used expression  small o of t upon root n sigma so  the understanding is that this denotes terms of the type  t upon root n sigma raise to r  r greater than or equal to 3 ; say in that proof proving the central limit theorem i wrote down the terms upto t square  and then i wrote down that the later terms will all be having higher power of t upon root n sigma so  this is the expression and see  the understanding is that as n goes to infinity  this is for this expression ; that means  because r is greater than or equal to 3 so  any way this will go to 0 so  that means  as n becomes larger and larger the terms that become very small so  their contribution is negligible therefore  we ignore them  right this is the idea but now  for your convenience i have expressed  i have used this term for  this notation for also including the term expectation of x i minus mu raise to r so  that means  i am taking that this now denotes for me in that proof  this into t upon root n sigma raise to r for r greater than or equal to 3 but then  since we have assumed that the m g f exists for all x i  x i s are all identically distributed so  the m g f exists ; that means  all movements exists so  all movements are finite  and therefore  these numbers are finite for all r ; hence the same thing apply ; that means  if this becomes small then n becomes larger and larger ; this whole thing also becomes very small and goes to 0  right so  this is the idea that as n goes to infinity this will go to 0 so  therefore  we can neglect the term so  this is  i have used this expression elsewhere also and  so this is  the understanding is that when you write small o then it means that these are higher order terms whatever you have written down beyond that all higher order terms ; that means  of power higher than 2  here for us the way i am using it r greater than or equal to 3 so  therefore  for large n i can ignore such terms in my sum this version of c l t  central limit theorem goes under the name of lindberg levy theorem also lindberg in 1922 and levy in 1925 independently gave this theorem ; we showed  proved this result ; so independent of each other in 3 years gap so  therefore  this is also sometimes known as the lindberg levy theorem  but most commonly it is referred to as the central limit theorem so  the proof is simple it just using the independence identically distributed random variables and the properties of the m g f so  through the property of m g f you could show that this sum of the random variables which are independent identically distributed random variables will  minus n mu upon root n sigma  converges to a standard normal variant  refer slide time  14  36  so  now let us look at this interesting example this is from mishra  and i will give you the references at the end of the course so  a casino has a coin and wishes you know remember casino is people bet ; and so game is tossing a coin to show a head so  casino has a coin and wishes to estimate p the probability of the head on any toss in such a way that they can be 95 percent confident that the estimate p hat is within 0.02 of p so  obviously  they want to have  an idea is to how what is the probability that the coin will throw  show a head when it is tossed it is important to them because every  whenever a head is tossed then it will be person who is playing the game wins so  the casino has to pay so  therefore  they want to be confident that whatever their estimate is that is within 0.02 of p  the actual p  right and so weak law of large numbers helps you out here so  given an epsilon and delta greater than 0  we know that there exists a n naught ; this smallest value of n such that for all n greater than or equal to n naught  probability of x n bar minus p greater than or equal to delta is less than epsilon  right so  for all n greater than or equal to n naught  this difference is greater than or equal to delta is less than epsilon  right and so the complimentary  the event would be that probability x n bar minus p in absolute value is less than delta so  this probability is greater than or equal to 1 minus epsilon so  the casino  for the casino problem your delta is 0.02 so  that your x n bar is within 0.02 of p  right so  it can be either little less than p with ; that means  it can be p minus 0.02  and p plus 0.02 so  this is what you want so  your x n bar should be in this interval so  delta is 0.02 ; and here 1 minus epsilon is 0.95 so  this probability that your x n bar is within  is in this interval should be  the probability should be greater than or equal to 1 minus epsilon so  that means  you would be 95 percent confident ; this is the idea so  therefore  just write out this so  this is exactly what ; so once you give the values of delta and epsilon you get that probability x n naught minus p in absolute value  should be less than 0.02 so  this probability should be greater than or equal to 0.95 this i do not need to write this because now i am using the value n naught and  so when you expand this x 1 plus  x 2 plus  x n naught  upon n naught minus p  so this should less than 0.02 is greater than or equal to 0.95 so  this will ; so therefore  you can find such an n naught ; and therefore  the casino can  by tossing the coin that many times they can find out the estimate p hat for the probability of p  refer slide time  18  17  same event can be rewritten as  this has to be or it was not really necessary because since we have said that there is an n  n naught which will do the job so  therefore  i could have carried it as n only  and then i found it out  but anyway so  therefore  this is therefore  this everything is n naught here  right so  now  i have this event  and if i divide all the numbers by  under root n naught p q  because the variance of each x i is p q and therefore  the variance of x 1 plus  x 2 plus  x n naught  will be n naught p q ; and so divide by the standard deviation ; and then therefore  this event is the same as this so  the probabilities are the same  right ; 0.02 n naught  divided by under root of n naught p q so  i divide throughout by under root n naught p q to  you know  standardize and  therefore  this i am  this is my random variant now which is the standardized variant ; and by c l t theorem  this is the standard normal variant  approximately  of course  right ; approximately this is standard normal variant and  so probability is a function of  this probability would come out to be a function of because your numbers on the 2 end are  the interval in which you are founding  wanting z to be  that probability will depend on t now  the thing is that you are  see  if i find ; so here again you have to do n naught  n naught so  the whole idea is that if i put this equal to  if i put t maximum value of n naught p q here  then i will get the  because its denominator if i put the maximum value then this will be the smallest so  if ; that means  this interval will be the smallest ; for the maximum value of this number it will be smallest interval ; and so probability of this smaller interval  if this is greater than 0.95 then for any other p this probability would be greater than 0.95 ; that is the idea so  my event what i am doing here is by writing the maximum value for this  this event will be subset of all other events whatever the value of p because q is 1 minus p  right so  therefore  if this probability can be made to be equal to 0.95 or greater than or equal to 0.95  then for all values of p this will be greater than or equal to 0.95 ; this is idea  fine  refer slide time  21  02  so  therefore  the and we know that the maximum n p q is 1 by 4 for all 0 less than p less than 1  we know this ; i am sorry  for i am writing this p q so  maximum value of p q is 1 by 4  and therefore  the required probability  since by c l t theorem this is standard normal  so this will be ; now let we have started doing it so  i will write n naught everywhere so  this will be 5 of which is the  for the cumulative probability this is 0.04 so  if i am writing 1 by 4  so this will be 1 by 2 ; and so you take it here  and therefore  the 0.04 n naught  minus phi of minus 0.04 n naught  right ; from here which by symmetry of the normal  standard normal variant this is 1 minus of this 5.04 under root n naught minus 1 minus this so  this becomes twice 5.04 root n minus 1 and  now we want this to be greater than or equal to 0.95  and so when i compute the value of n for  by putting it equal to 0.95  then again for all values of n greater than or equal to n naught this inequality will be satisfied  right so  the normal tables give me that ; so if therefore  this probability becomes 1 plus 0.95 divided by 2 so  now  the normal tables tell me that corresponding to this value 0.975 that means the area under the normal curve is 0.975 that the corresponding value is equal to 1.96 that means  0.04 under root n naught is equal to 1.96 so  from the normal tables corresponding to this probability i get at this number must correspond to 1.96  and therefore  your root n naught is equal to this which is 49 ; and therefore  your n naught greater than or equal to 49 square so  that means  for that many sample value or that many trials you have so  this  with this  that this number n naught which is greater than or equal to 49 square your estimate of p which will be obtained by p hat ; so that p hat will be essentially your ; so what we are saying is p hat is summation or you can say x 4 9 square bar so  this estimate of your p will be within 0.02 of your original p with probability 0.95 so  this is  you know  interesting application of your central limit theorem and  because we could reduce the whole thing to computing the standard normal probability we got the answer here  right now  again i will just try to have a variety of examples to show use of this central limit theorem so  now  here another question that is asked is if suppose you have x 1  x 2  x n  again a sequence of identical independent distributed random variables  and this random variables  right ; probability x i equal to 1 is p  and probability x i equal to 0 is 1 minus p for all i ; and again p is unknown  right so  you want to estimate this probability and  as i told you at  of course  the greek law of large numbers tells you that x bar will  x n bar will be a good estimate  provided n is large enough  right so  now  let us see  if you put ; so now  let us define s n as x 1 plus  x 2 plus  x n ; and let us fix t so  here in this example i am trying to show you the  you know  the accuracy of central limit theorem and  obviously  we expect better answer from the central limit theorem then if i just use the chebycheu ’ s inequality so  this is the whole idea  now by doing  now wanting to do this exercise and  so here let us see that ; so the question is using chebycheu ’ s inequality how large an n will guarantee  that this s n which is the sum of these random variables x 1 to x n so  this divided by n minus p in absolute value is greater than or equal to t is ; so if i have fixed the t ; yes ; so given a  t  then you want this probability to be less than or equal to 0.01  right and  we will now here compare because how large an n so  chebycheu ’ s inequality will also give me the answer  give me a value of n ; and then central limit theorem will also give me a value of n so  we will compare the 2 values  right so  here expected s n upon n is p  and variance s n upon n is p into 1 minus p by n  right ; because they are independent random variables identical so  therefore  we will first use the chebycheu ’ s inequality  and then compute through the  an estimate n ; and then through the central limit theorem also  refer slide time  26  42  so  applying the chebycheu ’ s inequality because expect to tally of s n upon n is p and variance of s n upon n is p into 1 minus p by n so  therefore  by the chebycheu ’ s inequality probability that s n minus n minus p in absolute value is greater than or equal to t so  this is less than or equal to expectation of this square divided by t square in other words  the variance of s n upon n ; the variance of s n upon n is p into 1 minus p by n so  therefore  by chebycheu ’ s inequality we get this estimate  and here again we are applying the same logic so  i hope that you can easily see that the maximum value because if you have 0 less than p less than 1  we are  earlier this thing also i used the fact that max of p 1 minus p is equal to 1 by 4 ; you can easily check  i mean let us just spend a minute and try to see ; that means  this is the function of p  and i can find out the derivative so  the derivative would be 1 minus p by 2  right ; and so this is i put this equal to 0 so  that gives me p equal to  i am sorry ; this is 2 p because minus p square so  the derivate is minus 2 p so  this implies  let p is a half ; certainly p can not be 2 because p is lying between so  this is a critical value  and to make sure that this gives you the maximum value the second derivate that means  the second if i call  if i am saying f p is p into 1 minus p  then f prime p when you put 0 gives you p equal to half  and f double prime p is equal to minus 2 which is less than 0 ; so ; that means  the critical value that we have obtained will be maximizing value and  you see  p equal to half gives you the maximum of this  and you can also prove this by concavity  and so on  anyway so  therefore  this is less than this ; i mean here ; and if i am putting the maximum value the  obviously  this equality will convert to inequality  is less than or equal to this so  1 by 4 n t square  right ; and this should be equal to 0.01 so  we get the estimate for n ; maybe i should put something like this  1 upon 4 so  your n will be equal to 1 upon 4 t square into 0.01 which is 25 by t square so  this is your chebycheu ’ s estimate of this probability ; i mean for value of n for which this probability would be less than or equal to 0.01  fine now let us try to apply the central limit theorem and  the central limit theorem says that this variant when you take as s n by n minus p divided by  the standard deviation which is p into 1 minus p by n  right so  you divide by  that is the root n go upstairs  and this is approximately normal  standard normal  right ; for lodging of n i  you can say that this is approximately this so  now  you want to compute this probability greater than or equal to t and here again i will write this as ; so i am standardizing it and therefore  dividing it by  dividing the whole thing by the standard deviation so  that gives me the right hand side as root n t upon under root p 1 minus p so  here again because this is greater  remember so  then if i put the maximum value as again i do earlier this becomes smaller interval ; and therefore  i should have said i think we have list out of the this things  sorry ; the absolute value  right ; and here also it should be the absolute value  fine so  the interval  i said if you put the maximum value here then this becomes smallest  and so the interval is smallest so  if the probability is ; and then we are wanting the ; so for larger interval the probability would be higher so  therefore  if i am taking the smaller interval  the probability i am wanting to be what was our  this thing the problem that first  the problem stated was that this should be less than or equal to 0.01 so  if i am saying that this should be greater  and so here if i am writing the maximum value  so what will it be ; that means  i am wanting the mod z to be greater than or equal to z naught and  if i am taking the smallest value here  so that means  if this is your 0 then you are asking for  yes so  you are asking for this probability and this probability to be less than or equal to this now  if i am taking the minimum value here ; that means  i am putting the maximum value here  then  obviously  you will be taking larger area so  therefore  the value of n which satisfies for maximum value here  will satisfy for all values of p  right so  this is the idea now  let us see ; so this greater than or equal to ; so therefore  i am substituting 1 by 4 for p into 1 minus p which gives me half  and so that may comes  makes it 2 root n t  right so  it is just the same argument  you would draw the figure and you can verify yourself so  now  you see this is greater than or equal to 2 root n t so  let me just show you the details here ; that means  we are asking for probability z greater than or equal to z naught  right ; which is the same as probability z greater than z naught union  probability z less than minus z naught  right this will be the absolute value ; as i said z greater than z naught and z less than minus z naught  right now  these are disjoint events so  therefore  i can write the probability of the union as the sum of the probabilities so  this will be probability z greater than z naught plus  probability z less than minus z naught and so this becomes 1 minus probability z less than or equal to z naught  and probability z less than minus z naught ; see here again i can just show you the ; so that means  if you have they are so  if you are wanting z less than this is minus z naught ; you are wanting this probability ; but that is the same if you write z naught here  this is the same as this probability  right so  therefore  probability z less than minus z naught is 1 minus of probability z less than z naught so  z less than z naught is this whole probability so  from 1 minus i will get this which is equal to probability z less than minus z naught  and therefore  i get this so  this is 2 minus twice probability z less than or equal to z naught  where z is your standard normal variant and  so the same thing i have used here  right this is your z naught so  this whole probability is 2 minus twice phi 2 under root n t which should be equal to 0.01  refer slide time  34  37  so  like you are finding the value of n for which this will be equal  and then higher values of n this will always be less than 0.01 and so this is 0.01  therefore  this tells me that 5 2 root n t ; if you bring this to this side and this here  something wrong so  you bring this to this side  and take this to this side so  it will be 1.99 divided by 2 which is 0.995 and so you look up these standard normal tables  and corresponding to this probability the corresponding value of the variant is 2.57 so  from the normal tables i get that when this number is 2.57 the corresponding normal probability from minus infinity to 2.57 is 0.995 so  therefore  this gives me root n as 2.57 upon 2 t so  the number by this central limit theorem ; and therefore  this imply that your n is 2.57 upon 2 t whole square  right so  this is our central limit estimate  and that is our chebycheu ’ s inequality estimate ; now if you  third part of the question is compare the results for t equal to 0.01 so  for t equal to 0.01 the chebycheu ’ s inequality gives you a number value of n which is 250000  that means 250000 whereas  the central limit theorem will only ask for this many sample values so  if you want to estimate the  get the sample size say that s n upon n defers from p in absolute value by ; you know  this difference  so that means  the probability that this is greater than or equal to t is less than 0.01 so  that number for central limit theorem is much much smaller compared to the chebycheu ’ s inequality so  this was another aspect of central limit theorem which i thought we should have a look at then  another usage of central limit theorem is to how we approximate the chi square distribution for large values of n because you see that somebody is already done the calculations for the central limit theorem for the  sorry  for the normal variant  standard normal variant so  we can make use of those tables to compute chi square distribution large values ; now  for when the n is large so  the idea here is that if you take x 1  x 2  x n  are again identically independently distributed random variables  each is chi square 1 so  this implies that expectation of x i is 1  and variance of x i is 2  right and then  also we know from the reproductive property of chi square  in fact  through the joint m g f also we can show ; and even otherwise we have seen that because each of them is independent identically distributed chi square so  x 1 plus  x 2 plus  x n  will be chi square n  right through  this is  we have already seen it in one way that this when we sum of this independent identically distributed random variable so  chi square has the reproductive property so  this sum s n is chi square n and later on we will also show through use of m g f how quickly you can say that the sum will be chi square n  if each is chi square 1  right  so anyway now  by c l t theorem  s n minus n upon root 2 n  in distribution because we have standardized it  right  subtracting the mean of s n so  s n will be  the mean of s n will be n because each is chi square 1 so  therefore  this is minus n upon root 2 n that will go into distribution to 0  normal 0 1  right  as n goes to infinity so  or in other words  chi square is  the mean n normal ; approximately you can say  mean n and variance 2 n so  this is the normal whichever the way you want to put it so  therefore  you want to compute this probability  remember for large n you want to be able to compute this probabilities using the normal tables so  therefore  when i standardize this will be s n minus n under root 2 n so  this will be become a minus upon under root 2 n  right  which is the value 5 of  a minus n upon root 2 n so  therefore  when n is large  i can  the central limit theorem will give me a good approximation and so for large n this will be standard normal  close to a standard normal variant  and therefore  i can compute this probability for large chi square n by the normal  standard normal table  refer slide time  39  56  so  now i said i will show you how we can approximate the chi square probabilities using central limit theorem so  let n be 100  and we wish to ; so i shown you that  you know  the formula ; i give you the formula ; that means  you can standardize the chi square random variable  and used  by using the central limit theorem you can get the probability so  let us compare the values for n equal to 100  right and we will  so we want to approximate  a  so that chi square 100 less than or equal to the probability that chi square 100 is less than or equal to  a  is equal to 0.95  right  by using the central limit theorem  right so  central limit theorem said that this can be converted to you see that phi chi square 100 minus  mean is 100 divided by  variance is 200  so under root 200 so  that becomes phi of  a minus 100 upon under root 200 so  this will be approximately because we are saying  let us see how if n equal to 100  how good  is it large enough for a good approximation so  if you put this equal to 0.95 then by the standard normal tables the 0.95 probability corresponds to this value b equal to 1.645 so  therefore  you equate these 2 numbers  and that gives you  a equal to 100 plus under root 200 into 1.645 ; and that comes out to be 123.2638 so  using the central limit theorem  and then we just standardize this variant  right and then  we said that if n is large enough this must be approximately normal 0 1 and so from there i get this probability now  from the tables for chi square 100 if you compute the exact value  then exact value of  a  that comes out to be 124 342 so  you can see that the approximation is really very  very good ; and this is for n equal to 100 so  the point we are making is that we know if your n is larger you will get a better approximation  better than this ; even the difference will be only at the decimal places and so you can do  you can use your standard normal tables for computing these probabilities so  this was one another point that i wanted to make about using central limit theorem results so  now  another application of central limit theorem ; the question is if x 1  x 2  x n  again are identically independently distributed random variables  and you are given that expectation of each variable is mu and the variance is sigma square  and also that the expectation of x i minus mu raise to power 4 is sigma square plus 1  which is  that is an infinity because sigma you are taking to be a finite number so  the first question is does the weak law of large numbers hold for x 1 square  x 2 square  x n  i mean this sequence of square of the random variables and  the second question is to find limit of this probability where x n minus mu whole square plus x n minus mu whole square divided by n so  we are talking in terms of the squared random variables so  because this central limit  the weak law of large numbers holds for x 1  x 2  x n  because your variance and mean are finite so  now  the question is that is the  does the weak law of large number holds for x 1 square  x 2 square  and sequence of squared random variables so  therefore  we need to for the  for answering part a i need to say that the variance of each is x i square is finite  right and  for this i have just made this calculation that  you know  if you open up this expectation of x i minus mu raise to 4 because that is what you given  as sigma 4 plus 1  refer slide time  44  21  so  yes ; and we miss this point  that for the weak law of large numbers i need to say that this x i squares are identically independently distributed  and they have finite variance so  now  we have done enough of this thing to say that if x 1  x 2  x n  are identically distributed then obviously  x i squares are also identically distributed  right ; this much of probability theory we have done so far and then  that they would be independent can also  will also follow  right ; because if x 1  x 2  x n  are independent then these will also be independent so  i am sure you can work it out by all that we have done in the course by now and now  to show that the variances of this x i squares are finite which will be the same so  i have just done this exercise  and surely there may be other ways of doing it also  showing that the variance is finite so  any way i just opened up this expression ; you know  then i took expectation inside and  you can see that  here for example  expectation x i cube  then into q  and then when you can get 6 x i square ; now expectation of x i square i know which is sigma square plus mu square  right ; because that is already given to me and then this expectation x i ’ s mu so  therefore  this is what you get mu 4 minus 4  mu 4 plus mu 4 ; and here it is 6 times sigma square plus mu square into  mu square  right and  then  you can write down this thing here and  this then tells me  see if example here  this is 3 mu 4  because this 6 mu 4 minus  4 mu 4 plus  mu raise to 4 so  that is 3 mu 4 ; and this is c sigma square mu square so  you get something like me these 2 expectation of x i raise to 4 minus  4 times mu x i cube ; this is equal to a finite number and therefore  we can conclude that both are finite  right ; and so weak law of large numbers can be applied so  therefore  i needed this condition if the x i ’ s are identically independently distributed  and if the fourth power expectation about the mean is finite then the weak law of large numbers can be applied and now  this probability we just need to again standardize our  this thing so  summation  i varying from 1 to n  sigma x i square whole square now  variance of x i minus mu whole square summation  variance of each x i ; i mean when you want to compute the variance of x i minus mu whole square then you are looking for ; i should have said this is variance of x i minus  that is ok ; variance of x i minus mu whole square that expectation of x i minus mu raise to 4 minus  expectation of x i minus mu whole square  whole square  right ; this expectation is squared  right so  which now  since we are given this number which is sigma 4 plus 1  and this is expectation x i minus mu whole square is variance of x i which is sigma square ; so raise to 2 will be minus sigma 4 so  the variance of each of this x i minus mu whole square is 1  right and therefore  variance of summation i varying from 1 to n  x i minus mu ; maybe i can rewrite this nicely so that it is readable so  then what we saying is that variance summation x i minus mu whole square  i varying from 1 to n  this is equal to n because each of them has variance 1 so  by central limit theorem this summation i varying from 1 to n minus sigma square divided by root n because each had variance sigma square  mean of x i ’ s minus mu whole square is sigma square ; so then n sigma square divided by  n mean sigma square divided by  root n so  this goes to n 0 1  and distribution as n goes to infinity  and therefore  they required probability so  therefore  i have divided by  here we are doing this ; and yes  root n ; if you want to write this as ; i can just multiply by root n throughout ; something is  you are wanting this to be less than or equal to 1 i am making it x i minus mu whole square  n minus sigma square ; and then you are dividing by n  by root n ; the required  this thing  we are looking for 1 by root n so  variance x i minus ; this is summation ; variance summation x i minus mu whole square divided by n will be n upon n square which is 1 by n so  therefore  you will divide by 1 by root n  and so that  you know  if i bring 1 by root n here in the denominator then this becomes 1 so  therefore  because this goes to standard normal  this whole thing as n goes to infinity so  this required probability  see absolute this less than or equal to ; i have divided by 1 by root n ; so this becomes less than or equal to 1 so  this is twice phi 1 minus 1 we have already done this so many times in the absolute values so  this is 2 phi of 1 minus 1 ; and again from the standard normal tables this is 0.8413 ; so this number so  therefore  2 into 0.8413 minus 1  and that come out to be this so  integrate probabilities and so on  there is no n 2 in the results ; and i will try to  i mean i think i will continue with the discussion on the central limit theorem in the next lecture also introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  22 applications of central limit theorem  refer slide time  00  14  i will continue with the central limit theorem and its applications this example i have taken from sheldon ross ’ s book on probability theory see the idea here is that  civil engineers believe that w  the amount of weight in units of 1000 pounds at a certain span of a bridge can withstand without structural damage resulting is normally distributed with mean 400 and standard deviation 40 so  the weight  which the bridge can withstand is random variable and so it is normally distributed with mean 400 and deviation 40 suppose that the weight again in units of 1000 pounds of a car  is a random variable with mean 3 and standard deviation 0.3 so  the different cars will have different weights therefore again we have treated this as a random … i mean this example – the weight of a car is treated as a random variable and therefore the distribution … and the distribution is normal – approximately normal with mean 3 and standard deviation 0.3 how many cars would have to be on the bridge span for the probability of structural damage to exceed 0.1 so  at a particular time  how many cars are there  and then the weight of these cars exceeds the weight  which can cause structural damage and so you want the probability of this whole random of this event to be more than 0.1 so  you want to estimate that you want to estimate the number of cars that would be on the bridge  so that the structural damage can occur so  we begin by defining p n as the probability that  there are n cars on the bridge  whose weight exceeds w  because that is … so  the event is this that  when it exceeds w  the structural damage can occur therefore  this is same as p n so  this is x 1 plus x 2 plus x n greater than or equal to w and  that would be … we can rewrite this as probability x 1 plus x 2 plus x n minus w greater than or equal to 0 now  x i ’ s ; where  x i ’ s is the weight of the i-th car ; x i denotes the weight of the i-th car so  this is the total weight of the n cars  which are on the bridge at that time and therefore  by central limit theorem  because for n large  we have said that  when they are identically distributed random variables – independent random variables  because of weight of each car is independent of the other so  then sigma x j  j varying from 1 to n would be approximately normal with mean 3 n and variance 0.09 n standard deviation is 0.3 so  the variance of the weight of a car is 0.09 and therefore  the variance of the n cars is 0.09n so  this is approximately this  refer slide time  03  45  now  w is independent of the x i ’ s because the weight that the bridge can withstand is independent of the weights of the individual cars and therefore  where i write sigma x i minus w  this is also approximately normal ; yes and  we will again revisit all these summation of random variables and their distributions but  right now  we have enough machinery with us to say that  sigma x i minus w  because this is normal – approximately normal this is normally distributed so  sigma x i minus w is also approximately normally distributed and  the expectation or the mean of this normal variate is 3 and minus 400 with minus w so  mean of sigma x i  i varying from 1 to n is 3 n  and this is 400 and  the variance of course  becomes with the plus sign comes with the plus sign  because they are independent so  variance of this plus variance of w  which is 1600 so  this is the variance and therefore  i can standardize so  the whole idea is that  this is the variate i am looking at and  i have said that  this is standard … this is normal distributed with mean 3 and minus 400 and variance this so  when i standardize  i will say this minus the mean divided by the standard deviation so  that is standardized so  now  z is the standard normal variate and the event so  when i standardize this  this probability now can be written as probability z greater than or equal to so  on this side  it will be minus of 3 and minus 400 ; i mean bracket minus 400 divided by the standard deviation so  when i do this operation  i mean this probability is the same as this probability  because this i have standardized the normal variate – standard normal variate by subtracting the mean and dividing by the standard deviation therefore  this is equal to this and so z is approximately normal and now  we want this probability to be greater than or equal to 0.1 ; yes and so we look up the tables for the standard normal and we find that  when z is greater than or equal to 1.28  this is approximately 0.1 so  from the normal tables  i get that  this number should be 1.28 for this to be equal to 0.1 and therefore  greater than or equal to you want see the whole idea is that  if the number of cars and it is such … so  now  this number – i can say that is equal to 1.28 therefore  if you take it equal to 1.28  then you get an approximation for n and  in the sense that  if you write less than or equal to 1.28 ; then obviously  this probability will be larger and therefore  the whole thing will still be larger than 0.1 ; this is the whole idea so  i get a value of n by equating this to 1.28 and then n should be greater than or equal to 117 so  here of course  this is a little complex thing to solve  but you can do it or you can start by putting in values of n ; and then you can find out for which value of n this is almost equal to this or little less than this so  one can … there are lot of numerical ways of actually getting the value of n  which satisfies this inequality so  we can do that and therefore  it turns out that  n greater than or equal to 117 satisfies the above inequality and so … that means  if there are more than 117 cars  then these structural damage may occur with probability 0.1 so  there is a chance of 1 in 10 that  the bridge will suffer structural damage so  this was another interesting example actually  you can see the application in the sense that … and then also i chose this example for the reason that  this also is a random variable and therefore  to convert this event to this event ; and then to reduce this to use the central limit theorem and transform this to a standard normal variate ; and therefore  get the estimate of the probability that  the bridge may suffer structural damage so  the interesting example of the central limit theorem  refer slide time  08  27  this is in a town of 20,000 people  44 percent support an upcoming referendum vote say for example  currently  the hot thing is anna hazare going to form political party or not so  you might take a referendum ; that means you might ask people to vote on this whether he should do it or not so  let us say … and  it is … that  the feeling is there so  maybe this is a small town ; and  the feeling is that  44 percent will only support the upcoming referendum  but … so  then what you do is you conduct a pre-vote poll so  this happens very often ; media person do it ; lot of magazines – they do it ; they conduct their own pre-vote poll to get a feeling or the opinion – and  of the eligible voters in the town and surveys 100 people therefore  if for conducting a pre-vote poll of the eligible voters in their town and surveyed 100 people  what is the probability that the  survey will show that  the referendum will pass so  one needs to understand what we mean by the referendum will pass in order for a referendum to pass  it requires a majority vote or 51 percent see even though the feeling is there that  44 percent support  but you never know at the time of the voting  more people may vote for the referendum and so on therefore  when you conduct a pre-vote poll and you surveyed let us say 100 people  then if in that pre-vote poll  it turns out that  51 percent or more support the referendum ; then you can say that  the pre-vote poll suggest that  the referendum will pass but  actually  when the voting is done  and then if more than 51 percent people  who have voted ; people who have voted – the 51 percent of those people – if they have supported the referendum  the referendum will pass so  right now  this is just conducting a pre-vote survey of 100 people so  then you want to know what is the probability that  the referendum will pass therefore  the question is … and therefore  that means  if you are taking a referendum – if you are taking a survey of 100 people  then you want 51 people to … out of those 100 people  51 should say yes for the referendum or support the referendum this is what you want to find out so  the probability – therefore  one can model the situation using binomial random variables so  x i is … i mean if the person supports ; if the voter or the people you are surveying – they support the referendum  then x i will be counted as a success ; otherwise  it is a failure so  you will say that  sigma x i ; i varying from 1 to 100 is binomial 100 with mean as 0.44 into 100  because probability of a success ; that means  p is 0.44 so  i am writing here ; i should have written only 0.44 this is not … this is only … so  the p is 0.44 and then the mean of the binomial distribution will be np and  you want to find out the probability that  the people that you are surveying – the 100 people that you have surveyed  how many would support ; that means  number of success is here should be greater than or equal to 51  because then the referendum will pass and  that is why i chose this  because this is depicting a new situation and we are just trying to model it through this thing here and applying central limit theorem so  this is a whole idea and therefore … so  i hope this is clear that  this is sigma x i  i varying from 1 to 100 should be greater than or equal to 51 so  from this 100 people  if they get a feeling that  51 or more will support the referendum  then they can sort of advertise and they can try to influence people and say that  the pre-vote poll says that  referendum will pass and so on  refer slide time  13  00  so  standardizing this variate – sigma x i  i varying from 1 to 100 ; this will be sigma x i ; i varying 1 to 100 minus 44 – the mean of this random variable  which is np – 44 divided by the variance  which is npq so  44 into 0.56  because p is 0.44 so  q is 0.56 therefore  this is the variance and so under root of that – the standard deviation therefore  this probability is equal to this probability so  this is greater than or equal to 51 minus 44 upon under root 44 into 0.56 now  as i have been telling you that  wherever you want to approximate a binomial probability by standardizing the random variable and using a standard normal probability  then you should also use the continuity correction factor  which i have not done here so  anyway therefore … so  that would be … if you are saying greater than 51  then it will be 50.5 ; that would be the right figure but  anyways  you can do that computation later on so  right now  the whole idea is just to see that therefore so  to get a feeling for the kind of numbers that you have that  will the referendum pass or not so  this is this and therefore  under root of this comes out to be 4.96 so  this probability ; and  this is a standard normal variate therefore  probability – this is equal to ; or  we are approximating this probability by probability z greater than or equal to 7 upon 4.96  which comes out to be 1.41 so  z greater than or equal to 1.41 so  this probability  which from the tables gives you the number 0.079 therefore  this is a very small probability and hence  the chance of the referendum passing is very slim then  the town is 20,000 and you are only surveying 100 people and  when you know that  the chances of … there is a 44 percent support the upcoming referendum so  the probability of 51 percent or more support the referendum is small ; and  that is reflected here so  through the central limit theorem  you have made this approximation to the probability through the required probability and it turns out to be 0.079 so  the chances of when you survey the 100 people and ask for their opinion – whether they support the referendum or not  it shows that  the chances are very small for the people  refer slide time  15  53  so  again  i mean one can go on and on about the applications of central limit theorem and how to various different situations you can apply it when i want to get back to … and  other thing that  we had also sort of use … we had used the central limit theorem  but probably did not … and  i have said that  we will prove it later on but  i just want to add word of caution also to it so  here this is that  we had x equal to … x is a binomial n comma p ; and then we said that  if you want to compute this probability – x less than or equal to s ; then you will have to compute these numbers ; and  this can be quite messy ; i varying from 0 to s and  see i p raise to i ; 1 minus p raise to n minus 1 so  this can be quite too cumbersome to compute but  then we said that  we can approximate it by a standardizing this thing and so here this is x minus np divided by under root of npq – the standard deviation and then this is less than or equal to s minus np now  you add 0.5 remember i had talked about the correction factor when the binomial is a discrete random variable and we are approximating it by a continuous distribution therefore  this continuity correction factor is also added so  you have 0.5 and this therefore  this probability – this cumbersome thing can be approximated by the normal probability  which is s minus np plus 0.5 upon under root npq and  we look up the normal tables and we can compute this number now  the thing is that  of course  when you are approximating  the question does arise – how good an approximation it is ? and  see what happens is that  when for a binomial distribution  if p is close to half  then the binomial distribution is symmetric ; in the sense that  the values keep on increasing and decreasing in a symmetric manner and then because normal itself is also symmetric distribution about its mean ; therefore  a normal distribution will give a good approximation as long as p is close to half  because then you are approximating a symmetric distribution – a discrete symmetric distribution by a continuous symmetric distribution and so … but  when the p is away from half  then the binomial will be skewed may be to the right or to the left and  in that case  it is not necessary that  the normal distribution will give you a good approximation of the binomial probabilities now  it is said often that  if np is greater than or equal to 30 or np into 1 minus p is greater than or equal to 10  then the central limit theorem will always give you a good approximation of the binomial probabilities  but … and  these are empirical statements and  in some cases  it may turn out that  when you have np greater than or equal to 30 or np into 1 minus p greater than or equal to 10  you may get good approximations  but it can not be said that  this will happen all the time  because certainly  symmetry plays a role and  for p small and n large such that np equal to lambda is moderate ; so then in that case  poisson approximation may be a good approximation and  i had … when we were discussing discrete random variables  i had shown you that  how a poisson probabilities can approximate the binomial probabilities but  then of course  the condition was that  p is small and n is large  and np is moderately small  is reasonable number ; then poisson may give a good approximation for the binomial probabilities so  with this word of caution  of course  these approximations can be used and they are very helpful and so i just thought that  once we have talked about the central limit theorem  we have proved it and shown its applications i will just revisit what we had done earlier when we talked about approximating the binomial probabilities by standardizing the variate – normal variate and reducing it to a standard normal variate  and then computing the probabilities  refer slide time  20  32  now  which has problems for you to try on chebychev ’ s inequalities  central limit theorem and law of large numbers – weak law of large numbers now  the first problem is straightforward ; it says that a random sample of size and equal to 81 is taken from a distribution with mu equal to 128 and standard deviation sigma equal to 6.3 with what probability can we assert that  the value we obtain for x bar will not fall between 126.6 and 129 chebychev ’ s inequality so  you can see that  it will be … you will have the absolute value so  x bar minus … when you essentially … i was saying that would be greater than 129.4 and less than 126.6 so  i have given it specifically  because i want you to then convert it to the form of the … when you are saying that  it is … when you apply chebychev ’ s inequality or the central limit theorem so  we have already tried given exam … i have discussed examples  where you can compute the probabilities given that  n is 81 and the standard deviation and mean are given to you now  you just want to make a comment here is that  as we have seen through examples in the lectures that  the number n … for example  the probability that you get – the bound that you get by using chebychev ’ s inequality on the required probability would be loose bound ; and  the central limit theorem will give you a tighter bound – a tighter this thing on the probability now  the thing is … and  of course  you can also say that … but  one point that is important is that  the probability when you compute it by the central limit theorem  may sometimes depend on the distribution that you are handling ; whereas  chebychev ’ s is a universal inequality and therefore  it may give you a loose bound ; but  then the number does not change with respect to different distributions so  chebychev ’ s is the general statement – a universal statement and  later on when i have occasion  i will again point out the difference between the … even though we say that  chebychev ’ s is a looser bound  there are other advantages of using the chebychev ’ s inequality question 2 – that the random variables y n have a distribution that is binomial n  p ; prove that  y n by n converges to p in probability so  this is the use of weak law of large numbers i may have already done it for you in the lectures ; but  anyway go through it and try to prove it by yourself then  the third problem is consider the sequence x n of random variables  where p n is x ; probability of x n equal to x is 1  if x is 4 plus 2 by n and 0 otherwise so  now  here the probability … so  x n is equal to x – the probability of that is equal to 1  if x is 4 plus 2 by n does it converge in distribution to some random variable x ? so  that means  find out the … you will define the cumulative distribution function as n goes to infinity  can you find distribution bridge if so find the distribution function of x ; show that the sequence x n converges in probability to x also so  should be interesting thing  but we go by the basic definitions and then try to solve the problem  refer slide time  24  42  upon x to x n are identically independently distributed random variables with density function f x equal to 1 by theta and 0 otherwise it should be equal to this – 0 less than theta less than infinity let m n be max of x 1  x 2  x n so  m n is the random variable  which is the maximum of these n sample values ; find the distribution function f n of m n does f n converge to sum f ’ s ? yes  it will and  see but  we will not talk much about it because … the second part is a little difficult part  but you can certainly see that  f n will converge to some f so  find the distribution function f n of m n so  that part is okay ; that you can do through the tools that you have already learnt  because when you find out the … to find the distribution function  you have to say probability m n less than or equal to t now  since m n is the max of x 1  x 2  x n  this will reduce to probability that  each x 1 is less than t ; x 2 is less than t ; x n is less than or equal to t and  since they are independent  this will reduce to probability x 1 less than or equal to t raise to n therefore  you can sort of do it in the regular way  and then see if you can get a feeling for convergence of f n ; that is all ; we will not talk in detail about it  because this becomes a little complex if you have given that f x is 1 upon x square and x varies from 1 to infinity  0 elsewhere so  this is how you are defining this pdf ; and  this is the pdf of a random variable x consider a random sample of size 72 from the distribution having this pdf so  that means  the sample – identically independently distributed random variables – they are 72 of them ; compute approximately the probability that more than 50 of the items of the random sample are less than 3 see the thing is now – that the problem … i have include this problem  because these two steps see first is that  you want the probability that  more than 50 of the items of the random sample are less than 3 so  there is a probability i will use this here  refer slide time  27  23  see you are given that  f x is 1 by x square ; 1 less than x less than infinity so  you are wanting to find probability x less than or equal to 3 ; this is the problem – that more than 50 of the items of a random sample are less than 3 so  this is x less than or equal to 3 ; this will be 1 to 3 of 1 by x square dx – the probability that random variable  which has this pdf so  then the probability of x less than or equal to 3 will be given by this  which is minus 1 by x from 1 to 3 so  this comes out to be minus 1 by 3 plus 1  which is 2 by 3 so  now  what i will do is you are selecting a sample of size 72 and we will say that  if a sample has a value less than 3  then that is a success therefore  the probability of a success would be 2 by 3 so  now  this gets converted to a binomial situation ; where we are selecting a sample of size 72 and we say that  if a sample value is less than 3  then it is a success so  that means … now  the question is that  from a binomial 72 comma p – 2 by 3  i want a sample of the items so  more than 50 ; that means  you want that  if you are writing sigma x i ; so random variable x coming from binomial 72 … maybe i can write it here so  essentially  what i am treating is that  x is binomial 72 and this is this so  i am wanting that  probability x is greater than or equal to 50 and so when you standardize  this will be x minus … the mean is 2 by 3 into 72  which is … this is 24 so  48 – 48 and  that will be 1 by 3 so  minus 9 – 16 – 4 so  this is greater than or equal to 50 minus 48 ; that is  4 ; this comes out to be 9   refer slide time  29  49    so  this is the whole thing so  that is why i chose this example therefore  you have converted this to a binomial situation and then you are computing the approximate probability that  more than 50 so  here again  i am now using the central limit theorem ; i am standardizing the variate there and then … therefore  you are computing the approximate probability ; because to compute the actual probability  would be – you will have to sum up those 72  50 and beyond the binomial probabilities of 50  51  52 and 72 so  this is this problem  refer slide time  30  34  now  let us go to measurements are recorded to several decimal places each of these 48 numbers is rounded off to the nearest sum of these integers so  when you say rounding off ; that means  if the sum of the original 48 numbers ; if the decimal is below 5  then you drop the decimal number point and  if it is 0.6  0.7  then you take it to the next integer this is how we say that  when you round off the numbers is approximated by sum of these integers if we assume that  the errors made by rounding off are independent and have a uniform minus 1 by 2 comma 1 by 2 distribution  compute approximately the probability that the sum of the integers is within 2 units of the true sum so  now  here we are assuming that  the errors made by the rounding off are independent ; surely  that you can expect because the errors that occur are not dependent on each other and then this … therefore  the rounding off that  you are doing is between minus 0.5and 0.5 ; thus  i said if the number is something like 10.4  then you will round it off to 10 if the number is 9.7  you will round it off to 10 – an integer therefore  you are assuming that  the error part ; that means  the actual number minus the rounding – that difference is uniformly distributed between minus 1 by 2 and 1 by 2 the approximate probability that  the sum of the integers is within 2 units of the true sum therefore  what we are doing is … so  you have 48 errors – 48 numbers that you are rounding off so  sigma … and  each is …  refer slide time  32  33  yes  i can again write here that … see epsilon i is the error in the i-th number so  we are wanting that  summation epsilon … and  each epsilon i is … and  this is uniform minus 1 by 2  1 by 2 ; each error is uniformly distributed now  you are wanting the probability that  this thing should be less than or equal to 2 ; i think this is the question that  the sum of the integers is within 2 units of the true sum ; which means that  total error that occurs should be within 2 of the original ; so that means  sigma epsilon i  i varying from 1 to 48 – this should be within minus 2 and 2 ; the error can occur either on the … when you round down or you round up therefore  this total error we are saying  what is the probability that this error is within two of the original sum of numbers so  i have added up the errors and so this sum should be greater than or equal to minus 2 and less than or equal to 2 this is what we want to approximate – this probability and  that again by the use of central limit theorem  we will say because  now  epsilon i 's are all uniform therefore  sigma epsilon i – expectation of this i varying from 1 to 48  is because the mean is 0 so  this is 0 they are all independent ; the errors we have assumed are independent and similarly  the variance of sigma epsilon i  i varying from 1 to 48 will be sum of the variances and which will come out to be … so  the variance here is remember it is b minus a whole square raise to … b minus a whole square divided by 12 ; b minus a whole square by 12 so  this is … the variance here is 1 by 12 and so variance … this will be 48 by 12 so  the variance will be 48 by 12 and therefore  standard deviation will be under root of 48 by 12 so  i standardize and  here this is what we get ; and then by the normal this thing  it says that probability so  this is actually equal to probability mod z is less than or equal to … this is 48 by 12 so  this is 1 and  that comes out to be 0.6826 from the normal tables of course  you have to do some more competitions here and this will be … therefore ; that means the error can be kept within 2 ; the total errors of rounding up and rounding down can be kept within 2 with probability 0.6826 so  that is a very … there is high probability but  if you look at a loose upper bound ; that means if you are suppose rounding up all the numbers  then this will be 0.5 into 48  which will be 24 so  that means  an upper bound on the number of total errors – that can occur – can go up to 24 but  here the central limit theorem gives you the idea that  the probability that  the errors will be within 2 is reasonably high so  this is something about the problem i wanted to talk to you about varying from 1  2 and so on is a sequence of identically independently distributed random variables with expected value of psi and is mu  and variance psi and is sigma square now  if s n is the sum of the first n sample values  show that s n upon n goes to mu with probability p this is again just reiteration of the weak law of large numbers then  i want you to sit down and work out the proof by yourself x n … show that mgf of … as n goes to infinity ; t greater than distribution of y n … and  square see the notation because we could not get it  refer slide time  37  03  so  x n i am saying is chi square n so  we have talked about the chi square n distribution also so  here this is the notation ; it looks like … in the print  it looks like x n square  but it is actually chi square so x n is chi square n and then y n is x n upon n  because again we wrote x n instead of chi  because chi was not coming out nicely so  y n is x n upon n and show that  moment generating function of y n will go to e raise to t as n goes to infinity  for t greater than 0 so  it is defined for t greater than 0 so  this you can work out and then what is the limiting distribution of y n so  once you get the limiting mgf of y n  then you will be able to say what is a distribution of y n – limiting distribution of y n this is the whole idea through this exercise and then show that x n minus n ; where so x n is actually chi square n so  chi square n has mean n and variance 2 n therefore  now we are standardizing this so  this is actually the use of central limit theorem  because remember – central limit theorem is convergence in law so  x n minus n upon under root 2 n for n large will converge to a standard normal variate so  this is again the central limit theorem that x 1  x 2  x n are independent random variables with probability x i equal to 1 – p and probability x i equal to 0 – 1 minus p for i varying from 1 to 2n ; that means  each x i ’ s … so  x i 's are identically independently distributed bernoulli random variables ; p is of course  between 0 and 1 and it is unknown so  this is what we have to estimate i will get back to this thing so  now  if you define s n as x 1 plus x 2 plus x n and you fix the t  then the problem says using chebychev ’ s inequality  how large an n will guarantee that  the probability of s n upon n minus p is greater than or equal to t ? so  the probability of this event is less than or equal to 0.01 no matter what value unknown p has so  obviously  we are trying to say that  we want to find out how many sample values we should take – x 1  x 2  x n  so that this ratio s n upon n or the average of the sample values is different from p by … so  greater than or … t we have fixed so  this difference greater than t – probability of that is less than 0.01 so  you want to use chebychev ’ s inequality  refer slide time  39  57  so  here by chebychev ’ s inequality  as we said  this is s n by n minus p so  this you want greater than t – probability of this ; and  this you want less than or equal to 0.01 now  by chebychev ’ s inequality  because this is the variance of s n by n is because remember – now  s n is what ? each x i is a bernoulli therefore  this is binomial and so this is the variance of s n  is npq and so 1 by n ; this will be n square so  this is pq by n therefore  by chebychev ’ s inequality  this probability is less than or equal to … this is pq by n into t square and  this you want to be less than or equal to 0.01 so  now  what it says is p ’ s are known so  q is also unknown and therefore  no matter what the value of p is … now  since maximum of pq … we have already gone through this in the lecture also ; maximum pq is 1 by 4 so  if i take the … if i write the maximum value here since n is in the denominator ; so this will … i will get the value of n  which is smaller see what i am saying is that  this probability is less than or equal to 1 by pq by … this 1 by 4 into n t square and  this we want less than or equal to 0.01 so  suppose i put this equal to 0.01 and  this tells me that  n should be equal to … from here n should be equal to … if you take n to this side  it will be 0.04 into t square and  since i have written  see … so  this value has become 1 by 4  is the maximum value of pq so  now … that means  for n greater than or equal to this  this will always be satisfied – less than or equal to 0.01 ; can you see that ? see here i am writing the maximum value ; this upon nt square is less than this so  n would be greater than or equal to this so  i am taking it … so  if i put the maximum value here  then obviously  i get a value of n  which will meet this inequality  because n will be greater than … otherwise  if i write the actual value of pq  then what i get – the value of n would be smaller than what i am getting here therefore  this will always satisfy this inequality ; this is the idea therefore  by chebychev ’ s inequality  this is the thing now  part 2 says that  using clt  find the approximate n needed  so that … now  here you see it has put the word minimum of this probability and  the probability here is the compliment of the event that you had in the part a therefore  it is a same thing  because here the probability of less than t is greater than 0.99 so  exactly … but  the minimum part i will explain again here  because this is now …  refer slide time  43  24  by central limit theorem  minimum this … so  minimum this probability will be attained when i put the maximum value of this and therefore  the minimum … when you write this here  this will be twice 5 and root n into t ; and  this is 1 upon 4 so  1 by 2  so that the 2 also comes here so  this minus 1 so  that satisfies this and now  you want to compute again this you want to say is equal to 0.99 ; which means that  2 of 5 … 2 root n into t is equal to 1.99 and  now  you can continue and  in fact  you will find out the value of t  because i think … maybe we will complete the problem so  this is 2 divided by this – 0.99 ; and  the corresponding z value here ; i think from the tables if you look up  it says that 2 root n t is 2.57 ; i think that is the thing and so you can compute root n from here and now  what it says is again … since you have the numbers … in this case  n comes out to be equal to 2.57 divided by 2 into t whole square and  in the third part  it asks you to … when you fix the value of t  i think the value of t is given – 0.01 if you do this  then it wants you to compare so  for example  from here when t is this  for t equal to 0.01  n comes out to be equal to 250000 and then when you compare it with the central limit thing  i think this comes out to be … it is computed somewhere ; i have done it here – 16 so  n will be greater than or equal to 16500 so  this is the idea  because the chebychev ’ s inequality gives you a loose upper bound and therefore  the numbers will be different so  this is the idea behind this thing and now  you can sit down and work it out yourself to get a better feeling is equal to 1.99 and now you can continue and in fact  you will find out the value of t  because i think … maybe we will complete the problem so  this is 2 divided by this – 0.99 and  the corresponding z value here – i think from the tables if you look up  it says that  2 root nt is 2.57 ; i think that is the thing and so you can compute root n from here and now  what it says is again since you have the numbers … i mean in this case  n comes out to be equal to 2.57 divided by 2 into t whole square and  in the third part  it asks you to … when you fix the value of t ; i think the value of t is given 0.01 if you do this then  it wants you to compare so  for example  from here when t is this ; for t equal to 0.01  n comes out to be equal to 250000 and then when you compare it with the central limit thing  i think this comes out to be … it is computed somewhere ; i have done it here – 16 … so  n will be greater than or equal to 16500 so  this is the idea  because the chebychev ’ s inequality gives you a loose upper bound and therefore  the numbers will be different so  this is the idea behind this thing and now you can sit down and work it out yourself to get a better feeling introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  23 strong law of large numbers joint mgf  refer slide time  00  15  so  now i will talk after having discussed the weak law of large numbers  we will talk about strong law of large numbers and i will first just take the theorem  this is theorem simply says that if x 1  x 2  x n is a sequence of independent and identically distributed random variables each having a finite mean mu equal to expected x i then with probability 1  see this is the important thing now  we are saying that the probability 1  this average of the sample values x 1 plus x 2 plus x n upon n will converts to mu as n goes to infinity so that means  this is the sure event so  therefore you can immediately see the difference between the weak law of large numbers  there it sets the probability such an probability x bar converges to or x bar n converges to mu here we are saying that with probability 1  x bar n will converges to mu  so that means  this is a sure event provided the expectation of each of the x i is finite so  before we start proving the theorem  let us just interpret what does it mean and what we are saying is that if you conduct sequence of independent trails of some experiment e  some experiment suppose  you conduct independent trials of an experiment  if say for example  test tossing 2 coins so  you go on doing that and then e is the fixed event of the experiment so  you decide that you just decide one of the events that will occur when you are conducting this experiment say for example  you are tossing 2 coins and you want 2 heads to appear three times  see you know one after another suppose e is that event  so you go on tossing the coin or the 2 coins and you do the experiment till you are ok in this case i am talking of the occurrence of this thing so  maybe we can say that i toss 2 coins ten times and then i want to see how many times i get 2 heads ; that means  both the coins show head that would be event e for example so  e is a fixed event of the experiment then and let p e denote the probability of the occurrence of e on a particular trial so  this is probability of occurrence of e on a particular trial right now  define x i as 1 if e occurs on the i th trial so  i am defining an indicator variable just to show you that how we can interpret this strong law of large numbers so  it say that if x i is 1  if e occurs on the i th trial and 0 if e does not occur on the i th trial so  this will be the indictor variable of the event e ; that means  if e occurs on the i th trial will say x i takes the value 1  otherwise x i takes the value 0 right so  then what the strong law of large numbers is saying that see this sequence x 1 plus x 2 plus x n upon n this is converging to mu as n goes to infinity with probability 1 so that means  and what is this count x 1 plus x 2 plus x n x 1 plus x 2 x n is the number of occurrences of e in the first n trials right  because x i is 1 e occurs in the i th trial so  when you add up x 1 plus x 2 plus x n that will be the total number of times e has occurred  when you have conducted the first n trails you just started and then you started counting  you started your trials and you started to count the number of times e occurs and that is given by x 1 plus x 2 plus x n right so  number of and strong law of large number is saying that this ratio ; that means  the number of times e has occurred divided by the total number of trials that will converge to your expected value of x i  which is equal to p e right so  this is  if we are denoting the probability of the occurrence of e by p e so  this is the probability of e right  i mean ; i have denoted p e by the probability of occurrence of e and so this ratio will converge to e x i  which is the probability of e right and this is probability 1 so  this is certain event right so  if you interesting interpretation and therefore  this  the strong law of large numbers reinforces our concept of the way we had defined probability through relative frequency  refer slide time  05  30  now  let us prove the result so  we have assumed that expectation of x i minus mu raise to 4 is equal to k is less than infinity so  we are assuming that the fourth movement about the mean is finite and then we show that so  let us define s n as sigma i varying from 1 to n  x i minus mu then we want to compute expectation of s n 4 right  which would means that sigma x i minus mu this whole thing  i varying from 1 to n this whole thing raise to 4 expectation of this so now  if you expand this so i should have a mu here also summation so  this should be sigma x i minus mu  i am writing sigma this so  therefore  this whole thing is 4 so  this should be this right and then this whole thing is raise to 4 so  sigma x i minus mu i varying from 1 to n and i am saying s n 4 so  this whole thing raise to 4 and then this expectation so  when your x i taking the fourth power  sigma x i minus mu raise to  this whole thing raise to 4 so  therefore  i am now  expanding this by the binomial theorem so  this will be summation i varying from 1 to n  x i minus mu raise to 4 right so  this is your up to n terms each raise to forth power then you will take 2 at a time  product of 2 at a time so  it will be 4 times sigma i j varying from 1 to n  x i minus mu cube into x j minus mu  where i is different from j right and similarly then you will again take 2 at a time i and j and this will be six times x i minus mu whole square into x j minus mu whole square summation i j from 1 to n  i again not equal to j then you will take three terms at a time so i j k and that will be plus four times summation i j k all varying from 1 to n  but i is not equal to j is not equal to k so  all three in this have to be different and this will be x i minus mu whole square into x j minus mu into x k minus mu and finally  product of four terms  where again i j k l are all different  i should have said here i not equal to j not equal to k not equal to l right and this is also varying from 1 to n right so  this is x i minus mu into x j minus mu into x k minus mu into x l minus mu so  this is the expansion s n raise to 4 and so the expectation is all outside so  this is the big bracket and the expectation of this now  of course  expectation can go inside so linear function so  in the sense that yes  so expectation can be taken inside then i have assumed independence of the random variables x 1  x 2  x n so  then expectation of the product is product of 2 random variables is the product of the expectations so  e can also go inside here now inside the summation sign and since expectation of x i minus mu 0 for all i so  you see that the expectation of this will be 0 and similarly this will not be 0  but here again you have linear terms so  expectation of this and expectation of this will also be 0 and here of course  all the four expectation will be 0  because these are independent so  this will be summation expectation of x i minus mu into expectation of x j minus mu and so on so  these terms will disappear so  you are only be left with sigma i varying from 1 to n  x i minus mu raise to 4 and then 6 times summation i j varying from 1 to n  i not equal to j  x i minus mu whole square x j minus mu whole square now  we have already assumed that this is equal to k and this is less than infinity so  here you have n such terms  again independence tells you that you can just add up these numbers  you can add up k n times so  this will be n k and then here  you are saying i is not equal to j so  the choices you can have is n into n minus 1 by 2 so  this many pairs you can have such i j so  that i is not equal to j so  therefore  this will be n into n minus 1 by 2 so  that will cancels out with 6 or will be 3 3 times this is what you will get  refer slide time  10  23  what we are saying is that since variance of x i minus mu whole square  because i am assuming that this always non negative so  this is equal to expectation of x i minus mu raise to 4 right if i give write the expression for this this is the fourth movement expectation of  fourth movement about mu minus expectation of x i minus mu whole square the variance of x i minus mu whole square so  that will be expectation of the square of square of this so  just say to 4 minus expectation of x i minus mu whole square then whole square right this of course  is your variance of x i so anyway so  then since this is non negative therefore  this is from it follows that your expectation of x i minus mu square whole square is less than or equal to expectation of x i minus mu raise to 4  which we are taking to be k so  therefore  this is also finite right so  therefore  everything is finite here right these things are also finite  because this square is finite so therefore  both of these are finite so  therefore  expectation of s n 4 is less than or equal to if you want to write n k plus 3 n into n minus 1 into k  because each of them is less than or equal to root k so  that becomes k here right and therefore  when you divide the whole thing  both the sides by n raise to 4 expectation of s n 4 divided by n 4 so  this becomes k by n cube 3 k upon n square into 1 minus 1 by n so  this you can utilize for large values of n so  this will become 1 right now  since 1 upon n cube sigma 1 upon n cube n sigma 1 upon n 4 are both convergent series right remember  because sigma 1 by n cube n sigma 1 by n 4 so  n goes to infinity 1 to infinity these are convergent so now  i can take the ; that means  when i take the summation here  this is convergent series  because both these series are convergent and so i write expectation of sigma and varying from 1 to infinity s n 4 upon n 4 is equal to this  because since this is convergent series  i can take expectation inside and so i get this here right and yes so  see this is what we have shown is that this is finite right expectation of s n 4 upon n raise to 4 summation n varying from 1 to infinity  this is a finite series  refer slide time  13  10  so  therefore  with probability 1  this summation n raise to 1 to infinity s n 4 upon n 4 should be less than infinity i mean see actually  we have shown that each of this is  because each of this is k upon n cube plus 3 k minus n square into 1 minus 1 by n so  therefore  this summation  when i take the summation here  sigma 1 by n cube sigma 1 by n square they are both convergent so  therefore  this is a converge series  but because this is we can take e outside right  because of linearity so  then this is finite expectation of sigma and varying from 1 to infinity s n 4 upon n raise to 4 is finite and so we are saying that the inside thing the  this expression or this series must be finite  because if there is some positive probability that the sum is not finite if this sum is not finite then its expectation will not be finite and we have shown that the expectation is less than sigma expectation this thing and therefore  that thing is finite so  this must be finite  because if there was any positive probability that this is not finite then the expectation would not be finite so  therefore  i am saying with probability 1 so  this is the main point right i will repeat the argument that  we have said that this is a finite series  but this i can rewrite as expectation this right and why we are saying this  because this whole is finite  because of this was not finite then expectation would not be finite  but here we have this is  this whole thing is finite this is equal to this and this is finite so  therefore  sigma n varying from 1 to infinity s n 4 upon n raise to 4 is finite and if a series infinite series has a finite sum it is a convergent series then the n th term must got to 0 otherwise again from your convergence of series  you know that this is the necessary condition that the n th term must go to 0  if the series is convergent so  therefore  sigma s n 4 upon n 4  n varying from 1 to infinity less than infinity implies that the n th term must go to 0  as n goes to infinity and if the now this goes to 0 then the fourth power 1 one fourth root of this will also go to zero so  therefore  limit s n upon n as n goes to infinity is 0 right and so just replacing the value of s n here  this is sigma x i minus mu by n  n varying from 1 to such a i varying sorry  i varying from 1 to n limit s n goes to infinity is 0 right and so you can just take summation inside here so  sigma x i by n i varying from 1 to n limit n goes to infinity is mu so  this is with probability 1 so  essentially here i just needed the a fact that to prove this strong law of large numbers ; that means  first of all let us just we clear so  what we are saying is that this will happen with probability 1 so ; that means  it is a sure event and so as n goes to becomes larger and larger what we are saying is that this x n bar  your x n bar will converge to mu so  little get closer and closer to mu and this is a sure event this is happening with probability 1 in the weak law of large numbers i be just simply said that the probability of x n bar minus mu see this value greater than delta probability of this could be shown to be less than epsilon and then of course so  therefore  this was only in terms of probability now here we are this is the sure event that x n bar must go to mu as n goes to infinity ok now  the thing is n of course  here i just needed the fact that expectation of x i minus mu raise to 4  this thing is less than infinity right so  what i want to say is that if the kind of distribution that we have discussed in this course all of them i could show you the existence of m g f and i have not taken any distribution for which the m g f did not exist of which the mean and the variance did not exist so in fact  all the distribution that we have considered here so therefore  you can see that for all of them this condition will also be satisfied  because if the m g f exists then the force movement will also be finite in fact  the movement m g f you can what we mean that m g f exists when you expanded you get different powers of t raise to n upon n factorial would give you the n th movement or about the origin so  if that is finite then you can see that this will also finite right and so therefore  the strong law of large numbers also holds for all this distributions as so the weak law of large numbers and strong law of large numbers both hold and so essentially if only when you have situations where you are well actually yeah  maybe i should not really worry about that part  but essentially the proof has been  this proof has been given under the condition that expectation of x i minus mu raise to 4 is less than infinity fine and that this is the show event ; that means  here this will converge the x n bar will converges to mu as n goes to infinity with probability 1 now  just want to look at stirling formula here and see all of you know that n factorial can be approximated by under root of 2 pi n into n by e raise to n so  many times this is a very useful way of approximating the e factorial right and many limiting situations and so on  we it is very helpful to be able to replace n factorial by this and then you can get a good results so  in other words what we are saying is that n factorial upon under root 2 pi n  n by e raise to n goes to 1 as n goes to infinity  this is the idea right now  the solution what we are doing is here is  here we are saying that  lets x i be poison 1 ; that means  the lambda is 1 so  i mean this thing the parameter for the poison distribution is 1 so  let me take x i this then take n to be sigma x i  i varying from 1 to n so  this will be poison n right and for poison n your variance ; that means  variance of n is also n remember for poison lambda mean and variance are the same and they are both equal to parameter lambda right so now  if you want to estimate this probability n equal to n this using the central limit theorem  using the central limit theorem i will say that x this can be approximated using the continuity factor the x lies between n minus half and n plus half where x is your normal n n ok  so applying the central limit theorem  refer slide time  21  05  let approximate this probability by saying that the corresponding normal so for  large n we will say that n behave like normal variable with mean n and variance n right so  this is what you want to compute and therefore  in terms of so  i want to write this probability so  this 1 because x is normal i will write 1 upon under root 2 pi n  because our variance is n so  standard evasion will be root n and this will be n minus half to n plus half of e minus x minus n whole square to n d x so  this is my probability using  because i have used the central limit approximation fine now  just look at this integrant see what i am saying here is that x minus n whole square upon 2 n at the lower limit n minus half is n minus half minus n by 2 n whole square  which is 1 by 4 into 2 n so  this goes to 0 as n goes to infinity and so e raise to minus something going to 0 is 1 right and similarly when you substitute n plus half for x then again this will be 1 by 8 n right so  you see the in the limiting case as n becomes large the two limit come close right and the value of the integrant is close to 1 right  because for n large this is always 1 so  therefore  we can always say that this integral is you can  you take the maximum value of the integrant which is 1 into the length of the interval which is also 1 so  this is this upon root 2 pi n so  just apply this approximation  because the theorem from integral calculus to this integrant is throughout then you multiply that by the length of the interval so  you get 1 upon under root 2 pi n right as so this probability is approximated by 1 upon under root 2 pi n and but since this is we said this is poison random variable  because we started their option that n is sigma x i so  then this probability in terms of poison probability can be written as e raise to minus n  n raise to n divided by n factorial and so from when you equate this 2 and you get that n factorial  i mean you equate with this and then approximate by 1 upon under root 2 pi n so  your n factorial is under root 2 pi n  n by e raise to n so  you know see the interesting application i mean  i just came across that this application what i taught discussed with you about central limit theorem so  the strong law of large numbers we have sort of established  but as we saw that for us actually there will be no difference and we will continue to approximate mu by x n bar and for reasonable large values of n  refer slide time  24  24  so now  i will want to talk about joint movement generating functions we talk about the movement generating function for a single random variable and then we talked of we know we could compute for independent random variables when you talk of sum of independent random variable like two random variables x and y are independent then i could also you know  because of two independence  we could define the movement generating function of x plus y  because it was just the product of the movement generating function of x and y  but there should be a general definition of movement generating function of more than 1 variable when they are not independent so  therefore  just completing this ah this part of the theory so  what we saying is so  the definition simply says that if x 1  x 2  x n are n random variables and then the joint movement generating function of these so  i mean these n random variables so  we are given the joint density function of the n random variables then we can define the movement generating function of these n random variables as of course  right now i am not listed this simply the expectation ; that means  so you now need n real numbers t 1  t 2  t n so  we will say that the movement generating function of x 1  x 2  x n is actually and i wrote the m g f by m of t 1  t 2  t n this is expectation of e raise to t 1 x 1 plus t 2 x 2 up to t n x n for all real numbers t 1  t 2  t n for which this expectation is defined and the individual m g f can be obtained from this by putting all but one of the t i s equal to 0 and then getting the corresponding function from here  because then it will be say for example  for the i th you want to compute the m g f of or obtain the m g f of the i th random variable here then i will put all other t i s equal to 0 so  m of x i t would be e t x i right  expectation of e raise to t x i  which will be in terms of the function n here will be simply 0 0 and then t i you write as t and all other as zeros so  therefore  when you defined the joint m g f you can get the individual m g f also and just as in one variable case we had we did not proved the result  but we stated it and said that if we movement generating function uniquely defines all distribution functions so  once you have obtained the movement generating function of a random variable then you know what is distribution function and also be and of course  it is unique right so  here also joint case we will again just assume this result that the movement generating function uniquely defines the joint distribution of x 1  x 2  x n so  yeah  and now  what we want we said uniquely defines this and now under independence yeah so  therefore  if the joint density function is uniquely defined then we can conclude that  if the random variables x 1  x 2  x n are independent then i mean this is the condition if and only if your m t 1 t 2 t n can be written as the product of individual this thing so  here if you want to write you can into this also in ; that means  you can decompose your joint movement generating function into the product of individual m g f so  i mean assuming that if this result we have sought of accepting that the m g f will define the distribution function uniquely and so now  we can yeah so you want let us show the if and only part so  now  if they are independent then of course  the things follow immediately  because you will write expectation of e t 1 x 1 plus t n x n and that will be and this you can then write as product and because x 1 x 2 x n are independent the expectation i can take inside and so this whole thing this can be written as this this is because x 1 x 2 x n are independent right  product of the expectations and so it immediately follows that this is your m g f of x 1  this is m g f of x n and so you can write this  refer slide time  29  17  now  the other way  now let us show the converse that is now suppose one holds so  we want to show that  this relationship will also we can conclude from here that x 1 x 2 x n are independent random variables so  we can see if you look at the right hand side of one so  this part then this represents the m g f of n independent random variable  because its product of n m g f so therefore  and which we know  we have said that if two random variables are independent then the m g f of 2 random variables will be the product of individual random variables so  just extending that rule this represents the product of this represents the m g f of n independent random variables now  the i th of this random variable  the i th term here  m x i t i of which has the same distribution is the x i right because  so here each one of them for example  m x 1 t 1 so  this is the movement generating function of x 1 and as we have been saying that the movement generating functions characterize the p d f uniquely so  therefore  each of the terms here  each of the m g f here determine uniquely the corresponding distribution p d f or so which as of the i th variable right so  just as for a single random variable the m g f uniquely determines the distribution of the random variable the joint m g f uniquely determines the joint distribution so therefore  from here we can say that the product of the so  that the joint m g f this will give me  because this is the joint m g f of x 1 x 2 x n so  this will determine the joint m g f of x 1 x 2 x n  but then that is we have shown is the product of the individual p d f and this is how we have defined independence of the random variables x 1 x 2 x n that is if the joint p d f which i have written down here so  the right hand side of one represents the distribution which is the product of individual distribution of x i s and therefore  this is the and so here and therefore  you can expression wise also write that m of t 1 t 2 t n is equal to this expectation of t 1 x 1 plus t 2 x 2 plus t n x n into f x 1 f x 2 f x n ; that means  the joint l c d function of x 1 x 2 x n joint p d f is the product of individual p d f so this  what we are concluding  we can immediately conclude from here right  because the m g f uniquely characterize your p d f so  therefore  just using that fact i can conclude that the joint p d f is this and therefore  x 1 x 2 x n are independent random variables so  we need proof of the fact that if you can write the joint movement generating function as a product of individual this thing then it implies that the random variables are independent and if they are independent then you can also write the m g f joint m d f  m g f as the product of the individual m g f s so  we have been using some of these results  but now i have some sought of new supported it by theory  refer slide time  33  07  see in this example  i am just trying to demonstrate the use of you know joint m g f so  even though you know x and y are independent random  normal random variables each with mean mu and variance sigma square so  if you start with that then we have already shown that you know by using the method of transformation that x plus y and x minus y are also independent random variables and in fact  they are normal random variables  but now  you want to use the method of m g f to show that x plus y and x minus y are independent and then of course  once we have shown once we obtain the individual m g f then as i have been saying that once you know the m g f you can also determine the distribution function or density function of the random variable so  we will do that so  just as an illustration of what we have just discussed  i want to go through this example so  since x and y are independent and they are normal independent random variables and they have both mu and sigma square right  refer slide time  34  34  so therefore  x plus y will be normal 2 mu and then variances will get added  because they are independent so  2 sigma square and for x minus y the mean will be 0 and the variance will be again 2 sigma square so therefore  if you want to write m g f of x plus y  because its normal with mean 2 mu and variance 2 sigma square therefore  it will be e raise to 2 mu s plus half into 2 sigma square s square right this is and similarly m g f of x minus y will be because mu is 0 the mean obviously is 0 so  it will be e half into 2 sigma square into t square  this is simply t square right now by our formula we will write the joint m g f of x plus y and x minus y so  this will be expectation of e raise to s times x plus y plus t times x minus y for s and t real numbers right s and t belonging to r right  which i can by rewriting this right so  now  i collect the x terms and the y terms so  this is s plus t is the coefficient of x and s minus t is the coefficient of y so  this is what you have right now  we will use the independence of x and y  because this is simply some s plus t times x which can be your t 1 and s minus t which can be your t two so  this is e raise to t 1 x plus t 2 y  but x and y are independent random variables so  therefore  i can decompose this m g f into the individual m g f so  this will become expectation of e raise to s plus t into x into expectation of e raise to s minus t y right so now  i can use the independence of x and y  because this is written as this way and so s plus t can be treated as another real number and s minus t can be treated as different real number right and so because of independence of x and y i can decompose into this right now  let me right the m g f of  because x is again normal with mean sigma and variance sigma square and this also is mean mu and sigma is the variance so therefore  when i write the m g f s plus t e raise to s plus t into mu plus half s plus t whole square sigma square and the other will be e raise to s minus t mu plus half s minus t whole square into sigma square right and then you see we just rearrange the terms simplify the expression so  s plus t into mu and s minus t into mu will become 2 s mu right and here the product terms will cancel out the 2 s t here and the minus 2 s t it will cancel out and it will be e raise to half into 2 sigma square s square plus t square right so now  again i collect the s terms so  this is e raise to 2 s mu plus half into 2 sigma square s square and this is e half to sigma square t square and this is what exactly see this is the m g f of x plus y  because this is and that is what i am saying so  this is m g f of x plus y  because this is 2 mu and 2 sigma square and you know  you can also say that these are x plus y is normally distributed with mean 2 mu and 2 sigma square and this is the m g f of x minus y so  there you see that mu is 0 and the variance is 2 sigma square right and so since from the theorem that i had just stated and proved to you  this see that if you are joint m g f can be written as the product of the individual m g f then the variables must be independent right and so we conclude that x plus y and x minus y are independent and also we can conclude that x plus y is normal 2 mu 2 sigma square and x minus y is normal 0  2 sigma square so  you know with the series through series of examples  i will tried to revisit the results which we have already i will try to revisit the results  which we have already you know obtained especially ; i will apply this concept of joint m g f to sums of random variables and then try to show you that sometimes this method is easier and we can get the results faster so  it depends on the situation and of course  lot of experience  but this is also another important tool and i taught that this course we must define this and you know give you the results so  that you can sometimes when other methods do not work this will proved to be quite introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  24 convolutions  refer slide time  00  20  so  in this lecture i will be talking about convolution and again this is one of the tools that we will use just like m g f to sometimes compute the distribution function and their density function for different kinds of random variables of the functions of the random variables mostly the convolution is use for computing the distribution function of sums of random variables so  here the definition says that if x and y are independent random variables  the distribution function of x plus y is said to be the convolution of the distribution functions of x and y so  the distribution function that we obtain for x plus y is will be is called the convolution of the distribution functions of x and y now  if highlight f of x plus y f x and f y denote the distribution functions of x plus y x and y respectively right so  by notation it is clear that the f x plus y is the distribution function for x plus y and f x is for x f y is for capital y right now  for the discrete case the definition would be as follows so  when the x and y both are discrete random variables and they are independent random variables p of x and p of y denote the p m f of x and y respectively then p of x plus y equal to t we will write as summation of p x x  so you fix the value of capital x then the y will take the values t minus x right and of course  this summation will be over all x for which you are this probability is positive and also it should be such that t minus x the probability y at t minus x is also positive otherwise since is the product of these two probabilities whenever one of them is 0 the whole the contribution of that particular term will be 0 so  simple definition that we will see how we can apply these definition and similarly for the case when for the continuous case that means when both x and y are independent continuous random variables that let t denote the sum of the two random variable that is t is equal to x plus y then your distribution function for t at small t is probability capital t less than or equal to t and this we can write as minus infinity to infinity probability x plus y less than or equal to t condition that x equal to x just as here  we chose the value of x and then the corresponding value of y got fixed at t minus x so  here you condition it on x equal to x and then probability x plus y less than or equal to t so  then that into ; that means  this is the distribution function into the probability that x takes the value well the p d f of x at small x which will be f of capital x x into d x and your x reform minus infinity to infinity so  this is the general expression and of course  it will depend on the range will depend on the values that your random variables take so  i am use the concept of conditional distribution here and so this is the expression  refer slide time  03  59  and therefore  in terms of f f f y capital f y in small f x you can write this as minus infinity to infinity probability x plus y less than t condition on x equal to x into f x x d x so  this we can write as f y integration of minus infinity to t minus x of f y y into f x x d x upon f y x then this we can do because x and y are independent ; that means  the probability x plus y less than t conditioned on x equal to x  i am able to write break it up into f y y into f x x upon f x x d y and so because x and y are independent and there into f x x d x so  we are f x x cancels out and we are left with the integration minus infinity to infinity again integration minus infinity to t minus x f y d y f x d x so  therefore  the first part i can write  i mean the integral minus infinity root t minus x f y d y i can write as probability y less than or equal to t minus x so  whole integral is then minus infinity to infinity probability y less than or equal to t minus x into f x x d x so  i hope there is no doubt about going from here to here right  because when x is equal to x your y will be required to be less than or equal to t minus x and so that is why i have written this probability as a capital f y t minus x into this right now  differentiate respect to t since the limits are independent of your t therefore  the differentiation will just go inside so  therefore  this will become small f t t and this will be equal to so  only this thing gets differentiated this is the function of t and therefore  it will be p d f of y at t minus x and then integral from minus infinity to infinity of this function  product of these two right so  this will be your convolution you can either write it in this form or you can write it in terms of the p d fs and of course  the understanding is that wherever you know for all values of t for which this is defined as and you also take the values of x for wish this is define right now  let us so the basic definition is this and then we will just see how we applied to different cases and of course  there will be reputation in the sense that for sums of independent random variables quite a few cases by other methods by using the transformation method or by the movement generating function  refer slide time  06  48  we have already obtain the density functions for the sums of independent random variables  but here i just want to show you the working of this particular method and therefore  we will just through a few examples now  suppose x 1 is the poisson lambda 1 and x 2 is poisson lambda 2 so  then t is the sum of the two poison random variables and now you want to find out probability t equal to n so  then if i chose x 1 is equal to x then x varies from 0 to n and this will be probability x 1 equal to x into probability x 2 equal to n minus x right see from here if this is end i fix x 1 at x then x 2 will be n minus x so  you do some and now since there independent and therefore  i written it this way product of the probability so  now  this particular probability can be written as e rise to minus lambda 1 and we have missed out on the summation should have been there sorry  summation x varying from 0 to n right  e rise to minus lambda 1 so  this probability is e rise to minus lambda 1 lambda 1 rise to x upon x factorial and this probability would be e rise to minus lambda 2 lambda 2 rise to n minus x upon n minus x factorial and so here also summation x varying from 0 to n right now  then just rearrange the terms e rise to minus of lambda 1 plus lambda 2 then i have divided and multiplied by n factorial so  this is n factorial and then here it will be n factorial divided by x factorial and minus x factorial and then you have lambda 1 rise to x and lambda 2 rise n minus x now  this is the you can see that this is the expansion of the binomial expansion of lambda 1 plus lambda 2 rise to n  because your summing see thing this the independent of x  e rise minus lambda 1 plus lambda 2 divided by n factorial so  this i take outside and then this summation x  x from 0 to n of this will be your lambda 1 plus lambda 2 rise to n and so this will be now poisson with the parameter lambda 1 plus lambda 2 right  this is probability equal to n so  therefore  e rise to minus lambda 1 plus lambda 2 divided by n factorial into lambda 1 plus lambda 2 rise to n right so  you can immediately conclude that this is now poisson with parameter lambda 1 plus lambda 2 yeah another example i want you to show that x 1 plus x 2 plus x n is negative binomial and so here now we are extending this concept to more than two  some of more than two independent random variables where x size are actually i could have straight away said that x i are independently identically distributed geometric random variables and geometric random variables with probability of success is p so ; that means  probability x i ; that means  probability this is just a geometric random variable and so and the probability of success is 1 that is it when you describe a geometric random variable you just need to known the probability of success and then you want to find the probability that you will get a success in n trails so  now  here we first consider this some of two random variables x 1 plus x 2 and so probability x 1 plus x 2 equal to n by convolutions we will write as x equal to 1 to n minus 1  because they should be i mean i can not make this 0 i can not have x going to from 1 to n  because in that case when x is equal to n this will be 0 and so anyway this will be not defined on the probability will write it as 0 so  there will no contribution to this sum so  i have to take this summation from 1 to n minus 1 right and then if i fix x 1 at x that means  for the first geometric random variable the success  the first success occurs for x trails then for the second one the first success will occur at the n minus x th trial right so  the probability of x 1 equal to x is 1 minus p rise to x minus 1 into p right at the x th trail the success must occur  otherwise before that all failures and similarly here it will be 1 minus p rise to n minus x minus 1 into p so  when you rearrange the terms here see x minus 1 and this is minus x so  x minus x cancels out you left with the n minus 2 and this is p square so  this is equal to sigma x varying from 1 to n minus 1  1 minus p rise to n minus 2 p square  but you see x is not present here therefore  you just add up this terms n minus 1 times so  this is n minus 1 into 1 minus p rise to n minus 2 p square now  this you can see is the probability that out of n successes out of sorry  out of n trails to or successes and n minus 2 are failures so  that means  this is the probability of 2 successes in n trails right  where the law success occurs  where the second success occurs at the end so when the one success can occur anywhere and the n minus 1 trails so  therefore  this is n minus 1 1  you can write this n minus 1 1 choose 1 and then 1 minus p rise to n minus 2 and p square so  1 success occurs anywhere in the n minus 1 trails and then one success occurs at the end and therefore  this is probability of two success is in n trails so  therefore  x 1 plus x 2 if you let y be equal to x 1 plus x 2 we show that y is negative binomial with the parameters 2 comma p right the probability of success is p here in the example i probably denoted mention  but it is understood that probability that x i is equal to the probability of success sorry  i should say that  probability of success is equal to p i should have mention that here so  it is understood anywhere right now  we can iteratively show that if you now consider the random variable y plus x 3 then by the same argument will be able to show that this is negative binomial 3 comma p and so on so  therefore  you can show that this will be negative binomial when x i is a geometric random variable when each x i is a geometric random variable for all i and x i s are independent  refer slide time  14  00  in the in the example  where we consider the sum of the geometric independent geometric random variables all with probability of success is p then you see x i was the number of trails required for a success for one success therefore  see ah if the corresponding number is n i ; that means  the number of trails required for one success for the i th geometric random variable so  then you see when say x 1 plus x 2 this will be the number of trails required for two successive right and that number will be then n 1 plus n two so  essentially when i wore that the sum x 1 plus x 2 is 2 comma p negative binomial so  that the understanding is that you want to two success and therefore  the number of trails of course  will be equal to n 1 plus n 2 then so therefore  finally  when you go and doing iteratively this procedure of in adding on or convoluting these random variables then x 1 plus x 2 plus x n will finally  give you the number of trails required for n successive right and therefore  this was negative binomial n p right and the total number of success is trails required would be n 1 plus n 2 plus n n right now  the next part was that without any calculation you can also conclude see this was just to show you how you would apply convolution and now here we can also because by just description  because when you say x 1 plus x 2 plus x n that is means you are asking for n success and your probability of success is p and therefore  x 1 plus x 2 plus x n gives you the number of trails required for n successes when the probability of successes is p so  just by saying it aloud you know since each x 1 x 2 x n is the  is geometric random variable independent therefore  we you add up you can say that this will be a negative binomial and comma p so that is all we just do because here     required to use convolution right now  lets us consider again applied convolution to some of independent uniform random variables both are 0 1 right so  therefore  the corresponding p d fs all both be 1 as long as x and y are between 0 and 1 and it will be 0 otherwise right so  let us define the random variables t equal to x plus y now the thing is that you see will have to and this where the this part comes that sometimes of course  you can easily determine the ranges  but sometimes you can not be that easy so  here for example  you see when i write the formula f x x x and f y t minus x now  you just see this is define only for between 0 and 1 so  by t minus x also should vary between 0 and 1 and therefore  i have to get this have to write i mean after do this computation for first for t between 0 and 1  because t minus x greater than 0 implies that x is less than or equal to t see from here this is not define for t minus x being negative so  therefore  t minus x has to be non negative  which requires the t should be greater than or equal to t right  greater than or equal to x and then also t minus x should be less than or equal to 1 so  you can not take a value of and therefore  t must be less than or equal to from here t must be less than or equal to 1 plus x since x can take 0 value therefore  you see immediately from here that your t can not be more than 1 so  here we will have to the way we are defining this  it will have to be the limits for t would have to be from 0 to 1 right and then you are x can vary from 0 to 1 when you write now ; i mean i am writing the integral this way  but since for x non negative and x between 0 and 1 this is 1  refer slide time  18  10  so  therefore  this will reduce to simply integral 0 to t f t minus x d x now  when i say that my x varies for 0 to t so  this is also define and therefore  this is also equal to 1 right as long as x is varying from 0 to t  this is well defined and it is within the range of the values for y and therefore  this also is 1 so  this integral comes out to be t and t between 0 and 1 with this is what i have to drawn you  the curve here this value is also 1 right so  therefore  the p d f for the some of the two random variables and both are uniform will be given by this now  because x plus y and both can take values between 0 and 1 so  of course  the range this is from 0 to 2 right and so we have to consider the values of align between 1 and 2 and this case you see again the convolution formula is this so  t minus x less than or equal to 1 will imply that your x is greater than or equal to t minus 1 so  here immediately you see that t must be greater than or equal to 1 right or x is greater than or equal to t minus 1 so  that is why the range t greater than or equal to 1 right and then of course  it can not go beyond two so  yes therefore  again the same reasoning that this value is 1 and the valid portion region we you can define this and why i am writing so  this is t minus 1 to 1 ; that means  my x can vary from t minus 1 to 1 so t minus 1 yes so  this thing you see at t minus 1 this will be 1 because t minus t plus 1 and when this x is 1 this will be t minus 1  because your x has to be greater than or equal to t minus 1 so  therefore  the range is this and again in this range this function is equal to 1 so  the integral is t minus 1 to 1  1 into d x which comes out to be 2 minus t and that will be your  this graph will be  the function will be represented by this great line so  therefore  the sum of the two uniform random variables both independent and defined on 0 1  the p d f is triangular distribution yes so  therefore  you see here you could not have just straight away done this integration from 0 to 2 ; that means  you could not allow t to vary from 0 to 2  because that could not have given you the valid answer and here you have to break up the region of integration from 0 to 1 and then 1 to 2 and i suppose yeah  because we are writing t minus x so  we have to do it this way that it x has to be greater than or equal to t minus 1 and we are integrating with respect to x  x can not go beyond 1  therefore  this will be t minus 1 to 1 right yeah so  another example is now sum of two independent gamma random variables so  suppose x is gamma s comma lambda and y is gamma t comma lambda then and x and y are independent so  we have to obtain the p d f of x plus y so  to define t as x plus y and then by convolution formula f t a we will write as this now  here again we have to apply the same thing  because gamma p d f is defined only for non negative variables so  therefore  this has to be a minus x has to be non negative so  therefore  this a minus x no negative  this implies x less than or equal to a yes and so i can ; that means  here while integration has to be from 0 to a now  why i am writing this as yeah so right now  i am i will now write the correct range what we just right now substituting for f x x  which will be lambda e raise to minus lambda x and lambda x raise to s minus 1  because x is s comma lambda  gamma s comma lambda so  the p d f is lambda e raise to minus lambda x into lambda x raise to s minus 1 and this is p d f for y is lambda e raise to lambda a minus x into lambda of a minus x raise to t minus 1 you see as we said x has to be less than or equal to a and now we therefore  this infinity will get replaced by a and you see here e raise to minus lambda x then e raise to plus lambda x that will cancel out you will be left with e raise to lambda a and then here it is lambda x raise to x minus 1 so  if you just take out the lambda here it will be lambda raise to s minus 1 and this will be lambda raise to t minus 1 and you have lambda square here so  the whole thing will be lambda raise to s plus t minus  because this is 2 and this is minus 2 so  you have lambda raise 2 s plus t right and that is what we have written here  refer slide time  23  38  so  this is lambda raise to s plus t e raise to minus lambda a and then you left with x raise to s minus 1 and a minus x raise to t minus 1 d x now  make the substitution that x upon a is equal to z so  this will imply that your d x get replaced by a d z right and your range goes from 0 to 1 instead of 0 to a  because x by a  we have put a z so  range for z will be from 0 to 1 so  therefore  the constant terms have put outside and so this a comes from here and then you have this and this now  you see this looks familiar and this is the beta function and therefore  since we want to so therefore  we know that this integral from 0 to 1 d z will be equal to gamma s into gamma t upon gamma s plus t right so  from the definition of the beta distribution we know that this integral must be equal to gamma s into gamma t upon gamma s plus t and therefore  i replace this whole thing by this thing so  then gamma s gamma t cancel out you left with gamma s plus t and this is lambda raise to so the lambda be right outside here and then it will be lambda a raise to yeah  so this makes it s plus t minus 1 so  therefore  lambda a s plus t minus 1  1 lambda i have written out here  just to conform to the form of the gamma distribution right and so this is therefore  this is i should have written here  gamma s this is gamma s plus t lambda so  we have concluded that  if you take two independent gamma random variables  x is gamma s lambda and y is gamma t lambda then this sum and they are independent then the sum will be again gamma distribution having a gamma distribution with parameters s plus t and lambda so  the same lambda if the second parameter is same then i can go adding the gamma random variables and the first parameter gets added of course  you are adding independent gamma random variables so  corollary first is that if x 1 x 2 x n are gamma s i lambda and they are independent random variables then by repeated use as we did earlier by repeated use of convolution it follows that x 1 plus x 2 plus x n will be gamma sigma s i  i varying from 1 to n comma lambda so  here of course  this thing is immediate that is your adding with distribution is not changing just the parameter is changing and that also the second parameter the first 1 that is the common one that remains same right another corollary  which is that if you take x 1 x 2 x n are identically independently distributed exponential lambda random variables and we know that an exponential lambda here only you can see from the gamma p d f that is a gamma 1 comma lambda right then exponential lambda is gamma 1 comma lambda and so when you take x 1 plus x n exponential random variables independently distributed then this is gamma and gamma lambda because the first parameter gets added in this so  and we will see uses of all these when we talk about random process is stochastic process is which are poisson and marko and so on right so  i have tried to depict by various  because you had to you could not just blindly apply the convolution you have to make sure that you know when you are applying it you are values of the variables should be sighted this p d fs are defined and so on  so we defined this now of course  the question is see we have defined this for independent random variables ; that means  the convolution right now we the definition says that they are independent and then you take the sum and then you can talk about the convolution  but can you answer the converse can you that is if you can show that the for two random variables x and y the distribution function for x plus y can be written as the convolution of the distribution functions of x and y would it imply that x and y are independent so  this is the question and i will try to answer through a counter example to say that  no it is not necessary  you may get the distribution of this sum by the convolution  but the variables may not be independent  refer slide time  28  31  so  this example is i have taken it from dude witch and mishra and i told you i have often taken examples from this book dude witch and mishra and sheldon and rose and i have give you the references also at the end of the course so  here and this example is originally due to w t hall and you see how cleverly this has been constructed so  see as i said the  we try to answer the question that if the distribution of x plus y is the convolution of the distribution of x and y does it follow oh  does it follow that x and y are independent random variables so  you want to answer this question  because we have defined the convolution for independent random variables so  the table here gives you the joint  i should make the at least to look nice so  this is it so  therefore  this table gives you the joint probability function  probability maths function of x and y and theta is fixed number  but it is absolute value less than 1 by 9  because otherwise  the entries will become negative so  we want this to be valid table for joint probability maths function of x and y right and you can see that when you add up this for the marginal p d fs are independent of the marginal probability maths functions are independent of theta and this where i am saying that thing has been very well constructed so  see these will 3 will add up to theta  theta will cancel t plus theta n minus theta it will be 1 by 3 similarly here this minus theta and plus theta will cancel so this will also be 1 by 3 and finally  these will also 1 by 3 and your column sums also give you the marginals  which are all independent of theta right and now you want to write so  we want to verify that the distribution function of x plus y is a convolution of the distribution functions of x and y  refer slide time  30  50  so  the values that x plus y will take a minus 2 minus 1 0 1 and 2 right these are the possible values that x plus y you can take  because your x takes the values minus 1 0 1 and y takes the values minus 1 0 1 right so  we start with probability x plus y equal to 0 and we will have to verify for all possible values to make sure that this is that x plus y the distribution of x plus y can be obtained as a convolution of distributions of x and y so  here by convolution i means  i am taking x to be equal to 1 then y will be equal to minus 1 right and if you take x equal to minus 1 then y will be 1 and if you take x equal to 0 then y will be also 0 so  these are the 3 you can convolute here this right and probability for x equal to 1 by 3 right  that is what you mean by marginal 1 by 3 into probability y equal to minus 1 that is also 1 by 3 so  therefore  this is 1 by 9  similarly you can immediately see that probability x equal to minus 1 is 1 by 3 and probability y equal to 1 is also 1 by 3 and 0 zero also x equal to 0 gives you 1 by 3 y equal to 0 also 1 by 3 so this is 1 by 3 right and then similarly  probability x plus y equal to 1 so here also when you want to fix x and then the corresponding value of y so  here i put x equal to 1 then y will have to be 0 and i put x equal to 0 y is equal to 1 and you should have put if you put x equal to minus 1 then that is not valid right x equal to minus 1 then y can only take a value 0 1 or minus 1 so  this is these are only 2 ways you can convolute the some x plus y equal to 1 here and therefore  this probability is 2 by 9 right  i have tried to compute just to make sure that see  because even if for one single value the convolution does not hold then i can not say that and so for x plus y equal to 2 only one possibility  x takes value 1 and y equal to 1 so this is also  i have taken this example  because it shows you that when we write f x of x into f y of t minus x then you see you have to take only possible values of t you can not just take any so x plus y equal to 2 will be given by x equal to 1 and y equal to 1 so  this probability is 1 by 9 and similarly x plus y equal to minus 2 will be given by x equal to minus 1 and y equal to minus 1 so  that is 1 by 9 right  refer slide time  33  35  so  now we compute these probabilities without convolution so  for example  probability x plus y equal to 0 will be probability  x equal to minus 1 y equal to 1 so all pairs that make up x plus y equal to 0 plus probability x equal to 1 y equal to minus 1 and plus probability x equal to 0 y equal to 0 and so from the table we can see that minus 1 1 x minus 1 and this 1 so 1 by 9 minus theta right and then 1 minus 1 so 1 minus 1 is 1 by 9 plus theta and then 0 0 x 0 y 0 that is this which is 1 by 9 right so  therefore  this adds up to 1 by 3 minus theta and theta cancel out so  this is 3 upon 9  which is 1 by 3 similarly x plus y equal to 1 so x equal to 0 y equal to 1 so again 0 1 1 0 and so on so  0 1 0 1 will be 1 by 9 plus theta 1 0 will be 1 by 9 minus theta and that is it because the sum to be equal to 1 these are the only 2 possible pairs of values that x and y can take so  1 by 9 plus theta plus 1 by 9 minus theta is 2 by 9 so  this also matches with this and this matches with this 1 by 3 and then similarly you can see that x plus y equal to 2 simply be the pair x equal to 1 y equal to 1  which is 1 by 9 x equal to 1 and y equal to 1  1 by 9 which also matches with this 1 right and then x plus y equal to minus 2 this is x equal to minus 1 and y equal to minus 1  x equal to minus this is 1 by 9 and here also we got it as 1 by 9 so  we have checked almost for all yes well not exactly may be x plus y equal to minus 1 that is left out  but we have otherwise checked for x plus 0 1 2 2 2 n minus 2 so  that 1 was 0  but you can easily verify that for all values ; that means  the probability maths function of x plus y matches with the probabilities obtained by convolution for all theta less than or equal to 1 by 9 so  therefore  the two things match  but we know that x and y are not independent why  because you just take one pair see i just have to show that for one pair of values this does not hold that this probability x equal to minus 1 and y equal to 0 that is from again from the table is 1 by 9 plus theta  but this is not equal to sorry  yeah what i am saying is that this is not equal to probability x equal to minus 1 into probability y equal to 0 so  x equal to minus 1 from the marginals is this 1 by 3 and probability y equal to 0 this is y equal to 0  this is 1 by 3 right so  that is 1 by 9 and therefore  the 2 are not equal as long as theta some positive number of course  satisfying the condition that absolute of theta is less than or equal to 1 by 9 so  for any for a positive theta satisfying this  these two will not be equal and therefore  x and y will be independent only when theta is 0 so  this is an interesting example and must have taken them lot of time to construct such an example now  if you try to do it for when x takes only two different values  x and y takes two different values it will not be possible then you can think of no trying situation  where x and y take four values each then you have to make sure that you will have to write down this probabilities in such a way that the marginals are independent of theta right and then you can have a chance to show that to get construct such an example that the probability maths function of x plus y can be obtained by convolution  but the variables x and y are not independent so  it might be a very interesting project  but i am not sure if it possible  but here it definitely lot of effort went into it to show that convolution does not imply independence on that time  refer slide time  38  30  so  you see according to me we have developed enough machinery to able to now show you some more interesting application complex in applications of the tools that we have of the machinery that we have developed so  far of probability theory and i would like to now devote the rest of the course on stochastic processes are only simple basic once and because otherwise the  you know what subject on the stochastic process and things can get very complex  but so the first thing would be the first stochastic process that i would like to talk about would be poison process and the idea you have already talked of poison random variable and then we have also looked at exponential and gamma random variables and we will see that how these things get you know  we sought of use the different kinds of distribution that we have developed into answering questions to essentially the thing is that you know  you have it is a counting process and you have a service that is a post office or railway booking counter well there still people will go and book at the railway counters not everybody does it online is not possible for everybody do it so  whatever these services are there now you want to have an estimate us to how people are coming and what is the so  and therefore  then accordingly you can design the surveys so  that people do not have to wait for a long time to be serviced how many counters should be there and so on so  these are the kind of things we will talking about and so basically we will be defining n t as the number of people who are entering let us say post office up to time t so  we will keep a count and will measure the number of people i mean we will count the number of people who enter the post office say starting from 0 time to t time and then we will answer lot of questions depending on that  but then the thing is that because we are calling it poisson process so  this four whether the certain conditions  which have to be satisfied by you know this process because when you are modeling it then we have to have some basic conditions which are met by this particular counting process and then we will develop the structure and try to answer few questions and the other one would be the other process that we talk about we be mark o process and so they are both interesting and the basic and they we can sort of develop we will answer lot of questions through these  because we have develop the machinery to do that so  this would be my you know next few lectures would be on poisson process and then on mark o processes  refer slide time  41  40  in my last lecture i had told you that we would now we talking about some stochastic processes and in fact so and one of them is the poisson process this is you can describe this as a probabilistic model used for describing unpredictable events right  because there is a chance element for example when and or the quick will happen or when it certain person walks into a post office these are unpredictable events so  the poisson process is a probabilistic model and settles even you model a situation then they are certain rules are certain and of course  so the idea here is that you are modeling a situation where the events exhibit a certain amount of statistical regularity and that of course  this means that you know you can approximate the occurrences by probability density function so  these events they exhibit or a approximately exhibit a statistical regularity and so essentially the poison process is a counting process so ; that means  essentially these unpredictable events they get counted by the model that we will create here and then of course  lot of discussion and all lot of conclusions can be based on the counting process this is what we will see in the next couple of lectures now  the examples as i said are number of persons entering a post office or a bank up to time t so  always the measure ; that means  when i am saying n t is the time to start counting the events start at 0 and then up to time t so  we count the number of events that take place and therefore  like for example  when you counting the number of persons entering a post office or a bank then this is so  n event will occur when a person enters the post office right so  therefore  n t will give the number of people who have entered the bank or the post office up to time t counting from 0  starting time 0  0 to t number of people who have entered the bank or the post office that examples could be number of children born in a town or a village up to t days or t months which ever you know time period you want fix the time frame work is decided and then you start the counting process of course  in this case event will occur when a child is born right so  you keep counting these events now  number of goals hit by a hockey player up to time t so  when the match starts and then after that up to time t may this could be the half time or whatever it is when you identify the particular hockey player in the team and then you say number of goals hit by a hockey player up to time t and here again the events will occur when a goal is hit by this particular player right  because you counting the number of goals hit by a particular hockey player so  this situation then for example  also you can have if you want to pick up a country or a place where a volcano is and then you want to find out the number of times a volcano erupts so  here of course  your time spend may be may be 5 years or 10 years and then you may because volcanoes luckily do not erupt very often so  therefore you would your time spend would be much more then for these particular events so now  through these examples  we realize that whatever our counting process is and this n t must satisfy the following  refer slide time  45  25  so  since it has to be 0  because when this counts the number of events that have taken place ; obviously  this has to be 0 positive then n t is integer value  because we are counting the number of events and then for s less than t your n s must be less than or equal to n t so  either no event occurs in the interval this or some event occurs after s  time s so  therefore  n s must be less than or equal to n t so  this number counting process this satisfies this condition then for s less than t if you take the difference as so 3 and 4 are you can we club together also  n t minus n s is equal the number events that occur in the time interval s comma t so  here of course  n s you know you have counted the events up to time s so  after s you start counting the events at take place up to t so  this will be open at this end this interval time interval and close at this end so  s comma t so  therefore  this is this  now other things that we want to impose  because remember we are thinking of modeling this situation where you want to count the number of events that take place  but certain conditions will have to be met introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  25 stochastic processes markov process  refer slide time  00  14  so  i am going to talk about discrete stochastic processes  and without  you know  spending time on first trying to define stochastic processes and on that discrete stochastic processes  you know  in the abstraction  i would prefer to give you examples  and then  we would try to come to a conclusion and hopefully  you know  you will be able to define and in fact  you would have  by then  by that time formed your own definition of stochastic processes of course  here we are going to write  first talk about discrete stochastic processes now let us just look at one example  a watch selling shop keeps a particular brand of ladies watch ; and the d i  let d i denote the demand for this brand in the i th week so  let us just say that our planning horizon is 3 weeks and so d 1 will be the demand for this particular brand of watches in the first week ; d 2 in the second week ; and d 3 will be in the third week ; and then  these are  you know  d i  s  are random variables  because the demands are not certain commodity  because otherwise  shop keeper ’ s job will be very easy so  here d i  s  are random variables and they are identically independently distributed random variables so  this one simplification has been added here so  the d i  s  are not known ; they are not certain events  but they have the same distribution and independent ; so  that means  the demand in the first week is independent of the demand in the second week  and independent of the demand in the third week let n i denote the number of watches on hand at the end of the ith week so  let us say by saturday evening  the man takes stock of his things that he has  that he has on hand so  n i will be the same particular brand of ladies watch ; he has n i of them ; so  that means  n 1 at the end of the first week ; n 2 at the end of second week ; and n 3 at the end of the third week now  orders placed for watches on sunday evening are delivered before the shop opens on monday morning so  this could be sunday evening or saturday evening or whatever it is so  before the new week begins  so on monday morning  before the shop opens  the watches are delivered ; whatever the ordering policy now  suppose the ordering policy followed by the shop owner is as follows  if no watches in stock order for watches ; that means  by saturday evening if he realizes that he does not have any watch of this particular brand  then he will order for 4 watches  and they will be delivered by monday morning so that means  if n i is zero  order 4 watches ; if n i is 1  that means  if he has 1 watch at the end of the week in stock  then he will order for 2 watches ; and finally  if he has 2 or more watches left over by the end of the week  then he will not order any  so  do not order so  this is his policy and  of course  sales are lost when the demand exceeds the number of watches in stock so  if there is more demand  and you do not have that many watches  then you will lose that  those sales ; so  fine so  now  let us look at what would be the position in the following week  refer slide time  03  59  so  n i plus 1 will be let us say … so  this will be n i plus 1 will denote the number of watches on hand at the end of the i plus 1 th week and how will you compute n i plus 1 given n i ? so  this will be  you see  if n i is zero ; that means  so this is your i th week and this is your i plus 1 th week so  therefore  at this point you had n i watches now if n i is zero  then you ordered 4  and they were delivered by the time your i plus 1 th week started ; so  that means  then you will have at the beginning  at this point  you will have n i plus 4 watches  and then this demand d i plus 1 ; so  that means  you would meet the demand  and then depending on whether d i plus 1 is  since n i is zero  you will actually have 4 watches on hand and that is why i have written 4 here so  actually  your this thing will be 4 minus d i plus 1 and if your demand is more than this  then of course  you will say the max of this  because he can not have negative number of watches so  either you have 4 minus d i plus 1 ; if d i plus 1 is less than 4 or you have no watches left at the end of the next week so  at this point  if you are able to meet the demand d i plus 1 then whatever the difference  that will be the watches on hand at this point otherwise  it will be zero  if d i plus 1 is more than 4  right ? so  similarly  if n i is 2  what were the policies ? n i is 1 ; this is n i is 1 so  if n i is 1  then he orders 2 watches so  this will be n i plus 2 minus again whatever the demand and if this number is positive  then that will be taken as the number of watches on hand at the end of the i plus 1 th week ; otherwise it will be zero so  n i of course  you can write 1 here so  this is actually it is max of 3 minus d i plus 1 comma zero so  which ever number is positive that number you will take so  when n i is 1  and similarly  if n i is greater than or equal to 2  then you are not ordering any watches ; 2 or more you do not order so  your watches on hand at the beginning of the i plus 1 th week is n i and i minus d i plus 1 will be what you are left with at the end of the i plus 1 th week so  it will be again max of these two so  this is how you can … so  you see  the situation at the end of i plus 1 th week is dependent on your situation at the end of the i th week and the demand so  here two random phenomena on which your state of the system  if you can want to call it ; that means  the state occupied by the system at the i plus 1 th week is given to you by n i plus 1 and here this is the current state so  therefore  you can say that here your n i plus ones are dependent on just n i and d i plus 1 so  the current demand and the state in which you were at the beginning of the i plus 1 th week so  this is sort of trying to show you the dependence because the variables n i plus 1 which we are trying to  you know  tell us the state of the system at the end of every week so  this phenomena is dependent on the two random phenomena n i and d i plus 1 so  this is one example and then we will … so  now  i can sort of give you a definition here saying that n i  s  index by the number of the week form a discrete stochastic process so  then when you take these n 1  n 2  n 3  so  these are three random variables  and they form a set see the thing is that you are giving them an index  which is discrete so  n 1  n 2  n 3 and the unit of time can be anything  here it is a week  it could be month  it could be an hour  or whatever it is so  when and therefore  the discrete word so this is a random phenomenon which is being  you know  sort of index by discrete time period  and therefore  we would call this a discrete stochastic process another example and therefore  you may so  of course  this and now the next question to be asked is  why study this ? so  for example  i just tried to state one or two questions that the shop owner may want to have answered  but of course  they can be many other questions that you can also raise so  for example  the shop owner is interested in knowing the following  long term loss of sales due to his reordering policy ; you see  because if he can by some mechanism find out what is the sort of estimate  may not be the exact number  but he can estimate the number of sales that are lost  when this number is negative ; that means  he is losing out on sales whenever this number is negative so  if there is a mechanism by which he can find out what is his long term sales  loss of sales due to his reordering policy  because he wants to know whether he really has a good reordering policy or not and then  also he may also want to know the effects of changes he makes in his reordering policies in the reordering policy ; he may also want to change some of the orders there ; and then he would want to know would that make the situation better for him for example  would it reduce his long-term  say long-term word  i am using here because  you know  it takes a while for any system to settle down ; so  we will most of the time  when we talk of any stochastic process we want to analyze it  we would be talking about its long-term behavior so  whatever the disturbance is and perturbations ,they all settle down after a while  and then you want to look at the system  because  otherwise it will be very difficult to  you know  model any such process  you know  when there are initially lot of tribulations or lot of perturbations  you can not really analyze or you can not model such a situation so  therefore  it is a long-term loss of sales due to his reordering policies and then he may want to know if he makes any changes  how will it affect his again  his revenues – essentially  he is finally interested in revenues that he gets now  let us look at another example  which is probably a simpler one so  there is an automobile manufacturing company and has the policy of assigning its white collar employees so  white collar employees means who work in their offices  office of the sales and so on  to the three sections it has so  the three sections it has are production  hr  you know handling human resources  and sales so  these are the three  and then see  we will now look at this model – example  and again give you another feeling about the stochastic processes so  the three sections are production  human resource  and sales  refer slide time  11  47  so  these are three sections in the automobile manufacturing company where he wants to assign the white collar employees and then  i mean by he – i mean the owner of that manufacturing  automobile manufacturing  company ; and there is no set pattern for reassignments ; at least the employees do not know so  there must be something in the mind of the owners how they would reassign so  since there are no set patterns known for the reassignments  one does not know in which section he or she will be assigned next so  after you have been in one section for a while  suddenly you know that you will be transferred  but then you do not know to which one you will be transferred so  the next assignment may depend on the current assignment ; it is possible that wherever you are right now  it may have a bearing on where you will be next so  these are the kinds of … so  then  if we let x i denote the section assign during i  the 6 month period so  that means  now you look at one employee ’ s profile suppose ; just take one employee ; look at his profile in the sense that you want to keep on measuring so  your time period is a 6 month time period ; that means  when you get assigned to a section  it is for a 6 month period and then at the end of the 6 month period  there will be another reassignment to sections and you may either stay in the same section or you may get transferred to the another one so  any way  let x i denote the section assigned during the i th 6 month period and then  so the whole process can be ; that means  the whole process of the sections being assigned to a particular employee can be described by the sequence x 1  x 2  so on so as long as your planning horizon you will have … so  x 1 will tell you that in the first 6 months the particular employee is in this section whatever the value of x 1 ; then x 2 will tell you the section he is in the second 6 month period and so on and of course  x i can take the possible values so  let us take  let us number the three sections so  the first section is production  second section is hr  human resource and the third is sales so  x i can take three possible values whichever of the three sections so  this will describe to you if you like you take it up to x 10 so  that means  over the 5 years the sequence x 1  x 2  x 3 up to x 10 will tell you the sections to which this particular employee has been assigned so in the discrete  so this assignment of sections to the employee is a discrete stochastic process and it is indexed by the periods 1  2  3 and so on so now  you get the meaning so  it is something like the process is evolving over time and there is uncertainty about what the system  what the state  i mean where the system  would be after  you know  each time period ; one time period is over  then where will it be next ? so  therefore  there is some sort of uncertainty about the whole process  and so this is why we are calling it a stochastic process now for this particular company  an employee may ask the following questions  if an employee is working in sales  what is the probability that after two assignments  he will be working in sales again ? this particular employee may want an answer to this question ; or for example  if the employee is currently in production  how many months must pass  on the average  before he enters hr  human resource ? so  you know  as i said again just as for the first example  i am stating some questions ; you can also add some more  refer slide time  15  52  and the third one for example  is if the employee has been with the company for 4 years  how many times on the average he would have been assigned to hr – to human resource ? then what percentage of an employee ’ s assignments will be in sales ? so  these are the questions and many more now why would these questions be important ? because a prospective employee  who is going to join the company  can ask questions like this  so that he can judge about his prospects in the company basically  he would like to know whether he would professionally be satisfied with the company or not if it turns out that he comes to know that  you know  he will most of the time be with sales  then of course  he may not be wanting to continue  you know  stay with the company because he may not be interested in sales and so on so  i am just giving an example  but there can be many such questions that can be asked so  the n i ’ s of the first example and x i ’ s of the second example are not independent random variables ; that you can see in the first example  the n i ’ s for the number of particular brand of watches that were left at the end of the week that were in stock  and so  we saw that this was dependent on what your demand is in the following week and dependent on your ordering policies so  you can not say that n 1  n 2  n 3 and so on  they are independent random variables  you can see that there is some relationship and similarly  for the x i ’ s it is possible  see whatever the way they organizers or the owners of the company decide to reassign the sections  certainly where you are and how long you have been in a particular section will have a bearing on where you will be next so  you can feel that these random variables are not independent and  therefore  any kind of computations about these random variables will not be easy thing so  now we will attempt to define this stochastic process  after these two examples so  any random process for which time can be measured discretely and can be represented as x sequence of random variables so  i should add the word here  and  can be represented as a sequence of random variables ; then  this is i will call it a random process or i will call it a stochastic process ; it is called is called a stochastic process or we simply  you can simply  say it is a sequence of random variables index by time so else stochastic process and definitely you can see that it is evolving over time  and then you want to now look at its behavior and so of course  now you see that if you want to answer any of these questions that i have posed and even on the earlier one  then you see  you may want to know  you would need to know the joint density function of example  if your planning horizon is 5 years  then you may want to know  you would need to know  the joint distribution of x 1  x 2 up to x 10  since they are not independent  and therefore  you can not say that the joint density function of x 1 to x 10 will be product of individual density function so  you will have to  you will need to find out  and of course  if your planning horizon is much bigger  then you know  you can just give  you know  you can throw up your hands and say that – no  we can not compute joint density function of so many random variables so  therefore  we need to really look at the methods by which we can sort of simplify analyzing such process  or under what conditions can we try to answer questions like this when we are looking at a stochastic process  refer slide time  20  15  so  for the automobile company  just look at the … we can diagrammatically describe the profile of an employee  and so you see  here the horizontal axis is giving you the time period so  this is the beginning of the planning horizon  so zero period  that means  the start of the process ; then  this denotes the first 6 months period ; this is the second 6 months period ; third 6 months period and so on so this is  what it is and then  here you have the three sections to which the person can be assigned so  for example  what it is saying is that here in the first 6 month period he was with hr  the second section ; and then in the next 6 month period he got assigned to production  that is your first section ; i think this is production  this is hr and this is sales so  then he got assigned to in the second 6 month period he went to sales ; and then again after that  he went to sales in the next this month ; that means  1 year is over and this is the next 6 months in it so  therefore  you can see that this diagram  and here for example  here from this onwards he continued for two periods consecutively in the production section so  this you can diagrammatically describe the profile of an employee in the manufacturing company now let us just give some more terminology so  set of all possible values the random variable x i takes is called the state space so  we always describe  so when whenever the system or the process is  whatever situation it is in  so that would be described by the state space and normally what we do is we give it numbers so  the possible values in the state space we describe by the numbers so  for example  here the three sections i have numbered as 1  2  3 so  it is easier ; because  otherwise  you can not go writing the possible values that the state space contains ; it may different  different things so  we can just distinguish by the numbers and so here  for example  this will be x n is i  means the state in which the system is at time period n so  the value of x n  so  if i am describing the my x i ’ s are the variables  which are the random variables  which describe the process and then  when you change these to  that means  when the system changes from one state to another  we call such process as  the change it is called as transition or transitions now as i said that and we have seen the two examples already  simple ones we saw that the real life situations the processes will be many ; many  many processes that are stochastic because there are elements of the process which can not be determined with certainty  and then we have also seen that  you know  even in such simple examples your x i ’ s are not independent so  there will be some sort of dependence among the random variables so  therefore  as i was saying earlier  that it will be very difficult to have a combined joint density function of all the possible random variables which describe the states in which the system can be over long time period and so  you can not just analyze or answer any questions about the process so  markov suggested the following simplification so  he said that the transition from one section to another may depend on the current section occupied and here i should say the word only  the transition from one section to another may depend on the current section occupied so  when we say depend  this of course  that means  the computation of the probability  the probability with which the process will transition from one section to another  the probability would be dependent on where you are right now  so  the current section so markov suggested this simplification and for example  in the watch shop example value of n i plus 1 to depend on the values of n i and d i plus 1 only and the way i was describing to you the values of n i plus 1 which was max of the formulae i wrote down so that  from there we saw that we were computing n i plus 1 only depending on the values of n i and d i plus 1 so  that was  that was anyway according to markov ’ s definition ; this is already satisfying the markovian property  refer slide time  25  12  so  when once you have this  and then that means  in the section assignment problem what we are saying is that  we are saying that if you want to look at x i  the value of x i  then that will depend on … so the probability that you will go from  whatever the value of x i  it will depend on what is the value of x i minus 1 so  sort of the transition from here ; so this will depend on this  and then x i will affect the value of x i plus 1 with certain probability so  this is the kind of dependence we are only allowing or you can say this the simplification so  this makes the analysis of stochastic processes  which satisfies markov ’ s property quite tractable  and we will see this  as we go on  we will see that we can probably answer almost all the questions that i wrote in the beginning  about the automobile manufacturing company and the question that  the kind of questions  that an employee may be interested in knowing so  we should be  we will be able to answer the questions  because if we say that the section assignment process would satisfy the markov property now any stochastic process  which satisfies markov ’ s property  is called a markov chain or a markov process so  i will be using the word markov chain or markov process with the same meaning  synonymously so  now  what happens is that with the markov ’ s property being satisfied by the process  then we just need to compute the joint or the conditional probability mass function ; remember i am talking about discrete processes so  joint or conditional p m f of neighboring x i ’ s is computed so  it simplifies and therefore  you know  we are having two variables  you can very easily compute the joint or the conditional p m f of two variables and so  with that  we are then able to analyze the process over long term and whatever it is so  now if you want to formally state markov ’ s property  that is  see essentially what you are saying is  probability x n plus 1 is equal to j ; that means  at time n plus 1 your system is occupying state j and if you look at the past history starting from x 0 is i  then it will be x 1 is some i 1 and so on x n minus 1 is i n minus 1 and x n is i so  this is the entire past history so  if you are not assuming the markov property being satisfied by the process  then of course  to answer this  compute this probability  you would need to know the entire past history  but then  markov ’ s property simplifies it and says  that this whole thing can be made equal to probability x n plus 1 equal to j given that x n is i ; so whatever the condition ; so the current state of a system that helps you to determine  so with some probability where the system will be in the next state  next time period and so  these are known as one-step transitional probabilities and we will call them as p i j so  now here i am not writing anything else  why because i am now making one more simplification ; and what we are saying is that  this is actually equal to probability of x 1 equal to j given that x naught is i ; so  that means  the starting probability  the starting state of the system  suppose if you were in system was in i  state i  then the next period that it is in j so  we will denote that one-step transitional probability and we will say that over the long period that the process goes on  this does not change ; that means  whether at the time period n plus 1 you are considering the change from x time period n to time period n plus 1 or you are considering the change from the starting  initial state  to the first period so  those probabilities remain the same and that is why the word stationary so  what we are saying is that the one-step transitional probabilities are stationary and essentially the explanation here is that whatever process you consider  we are saying that after the initial perturbations and so on  this system has settled down to stationary ; this system has become  or the process has become  stationary so  it is not  and therefore  these transitional probabilities are not being affected by where you are considering  at what time period you are considering the transition as we go on  we will be looking at a lot of processes and lot of situations  real life situations  where we will see that to assume that we have transitional probabilities have the stationary property is not very unrealistic so  we will continue with the … i will just continue with defining and giving you how to compute these probabilities and so on once you have these probabilities  then what can you do with these ?  refer slide time  30  40  so  let us start looking at how we will now continue with the analysis of the process so  therefore  what we would need first to describe the process  and then  what are the quantities that we would require before we can continue with our analysis and trying to answer the questions related to the process so  if x naught is the … let us say x naught might be the present assignment by our notation zero so  this means  whatever value of x naught  that tells us the present assignment of the employees  and then  we are interested in his next assignment that is  we want to know the value of x 1 in the next time period so  if suppose x naught is 1  that is the man is currently in production  then x 1 can be 1  2  or 3 any of the three sections he can be assigned to so  that means  you would want to know what the probability is so  it means this has to be given to you  that is if he is already in  he is starting his career with x naught equal to 1 ; that means  he is in production right now ; and then  what is the probability that he will be again kept in production only ? so  x 1 is 1 so  we will call this as a p 1 1 and as i told you these are one-step transitions probabilities and that we are assuming stationality so  it does not matter whether it is x n plus 1 equal to 1 given x n is 1 ; or x naught is 1 given that x naught is 1 then x n is 1  so the probability so  p 1 1 and then  similarly  you would need to know if x naught is 1  then what is the probability that he will be in hr ? so  that probability is p 1 2 and the probability that he will be in sales is given by p 1 3 so  these are the first step transitional probabilities if you know where he is at the beginning of the planning horizon again if you know x naught is 1  but if x naught is 2  then of course  again their transitional probabilities will be different  in the sense that now what is this probability of going from 2 to 1 ? so that means  he is in hr and then the probability that he will be assigned to production ; so  that must be some probability you see these are the transition probabilities  which are now describing to us whatever the assignment process is so  therefore  again these three transition probabilities p 2 1  p 2 2 and p 2 3 are given to us ; and then for if x naught is equal to 3  that means if he is already in  he is currently in sales  then his probability of going into production will be p 3 1  probability of going into sales will be p 3 2  and probability of remaining and sales will be given by p 3 3 so  these we call as the … i am not all the time saying one-step transition probabilities  but that is understood so this is transitioning from state so here  these three numbers  these three probabilities  give you the transition probabilities of transitioning from state 3 to any of the three states so  therefore  the process  and now  of course  we will see that this is not a complete description of the process  and we will  as we go along we will find out what more we need ; but  let us first just look at this so  now  the nine first step transitional probabilities can also be written as 3 by 3 see  remember  because whatever the number of states  if the number of states is capital n  then your transition probabilities will be n square  because you can go from one state to any of the n states so  therefore  you will always have n square numbers and so  these transition probabilities can be written in a matrix form so  if you have n states that this system can occupy  then it will be n cross n matrix that you can you can record all these transitional probabilities in an n by n matrix so  here since our states  3 states are there  three sections so  i can record all the nine transitions  first step transition  probabilities and then 3 by 3 matrix so  p will be called transition matrix now since the man must transition from  let us say from  production to any one of these other  either he stays in sales  production or he goes to hr or he goes to sales  he must transition to one of them  because after every 6 months the assignment is announced  refer slide time  35  34  so  therefore  these three probabilities will add up to 1 and therefore  also another way of saying that these probabilities must add up to 1 is that they are the p 1 1 and p 1 2 and p 1 3 describe the conditional p m f ; remember we have talked about it while talking about  you know  conditional probabilities and conditional expectations so  this is the conditional p m f of x 1 given that x naught is 1 and  so therefore  since these three numbers describe the conditional p m f they must add up to 1 because of this in the same way you can argue that the second and the third rows must also add up to 1 ; that means  p 2 1 plus p 2 2 plus p 2 3 is equal to 1 and p 3 1 plus p 3 2 plus p 3 3 is 1 so  now  any square matrix which has  because these are probabilities  so they have to be nonnegative numbers  so any matrix  a square matrix  which has all entries or all elements nonnegative and the rows add up to 1  can qualify to be a transition matrix ; that means  we can say that there must be a stochastic process  which can be associated with such a matrix so  all entries are nonnegative and the rows  the elements of row  add up to 1  of every row  add up to 1 so  this will be  this will qualify to be a transition matrix now  another way of looking at this process  because diagrams always help  they fix ideas  and i think they also help in the understanding of the process so  let us see  i will describe the three states by the nodes of this graph so first is your production  hr and sales and if i am showing it arc from 1 to 2  then this is transitioning from 1 to 2 ; and of course  i have not entered all the probabilities  but they can be written down here and so  the arc 2 to 1 will be the transition from  one-step transition  from your hr to production and this loop describes  that means  you stay in one  that means  your transition from one to one so  you do not go anywhere  you continue with the same state so  this way you can look at this and so  you can write down the probabilities here also p 1 1 ; this will be p 2 2 ; and this will be p 2 3 and this will be p 3 2  and finally  this will also be p 3 3  and here this will be p 3 1 and this will be p 1 3 so  this diagram also helps you to look at … and you can see that currently you can transition from for example  from 1 to 2  then you can go from 2 to 3  you can come from 3  again you can come back to 2 or you can go from 2 to 2 so  actually  you can play around and you can see lot of things you can do with the … you can see how the transition is taking place and so on but  of course  this you can do when your number of states is small and if the number of states is large  then drawing a picture like this may not be a very good alternative  and so  we will have to look at other ways of handling this process ; but anyway  this makes the thing look interesting ; i mean the picture is there and you can just see how the process is evolving over time going from one state to another and going through these parts so  you see we describe the first step transitional probabilities and through a diagram and so on  refer slide time  39  23  now  suppose we want to now look at look at x 2  the random variable that describes the state of the system at time 2 now  again i will try to show you through the diagram so  if you look at this for example  you start with state one ; that means  you start with production and after two transitions you are back in production so  what would that mean ? so  the possibilities are that you start with production  then the next period you again transition to production only ; that means  you stay where you are ; and then finally  you  in the next step you again transition to production so  that means  you continue through this so  this path describes one possibility which i have written down here and then  it could be that you start from production  you go to hr  and then again  you get transition back to production so  that would be your second path so  i am talking now in terms of paths ; because this is how you will  when you go for two-step transition probabilities  this is what you will have to do  compute the probabilities of these paths and then finally  you will start from production  go to sales  and then you are back to production and that will be your third path so  just to give you  and of course  we will continue this discussion in next lecture also so if you look at probability x 2 … so  here your the arrows are in the wrong direction so  it should be x naught to 1 and then x 1 to x 2 you start from here  then you transition to production  and again you transition to production from the first period to the second period and since we have the markovian property that tells us  that  you know  we just need one-step transition probabilities  that means  the transitioning from x naught 1 to 1 and then from in the second period  from in the first period from 1 to this ; these are independent  and therefore  i can write them as the product of transition probability 1 to 1 here in the first period  and then again 1 to 1 so  now here again the second property that we have used is the stationality so  markovian property and stationary transition probabilities both tell us that  you know  the probability of the first path ; that means  transitioning from 1 to 1 in 2 periods along the first path  the probability is p 1 1 square and so  we will continue with this kind of computation  and then show you very interesting results and then  you will see that how far our analysis can go of a stochastic process which satisfies markovian property and of course  we are talking when the stationality conditions are met introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  26 transition and state probabilities  refer slide time  00  15  so  i will continue the discussion about computing the transition probabilities one step transition probabilities i showed you and we have just started talking about two step transition probability so  just consider a case in last lecture i considered the case x 2 equal to 1 x naught equal to 1 now let us look at x 2 equal to 2 and x naught equal to 1 so  in that case you see that what are the possible routes of transitioning from the initial state of 1 2  the state 2 in 2 steps so  i want to look at it and of course  three possible paths would be see at step 0 so  this is a time period 0  time period 1  time period 2 and these give you the states so  therefore  at time 0 the system is in state 1 it transitions to state 1 that is a possibility  because in one step you may transition to 1 2 or 3 and then you have to come back to state 2 so  therefore  one possible route would be from 1 to 1 and then 1 to 2 right in one step transition in one period you go from 1 to 1 and then from 1 to 2 similarly you could go from 1 to 2 ; that means  you transition to  so this was our production and this is h r so  from production to h r and then h r to again h r right  you can continue here or the third route would be from 1 to 3 ; that means production to sales and then sales to h r so  these are the 3 routes and that i have written down the 3 routes in this way these are the 3 possible ways  no other route is possible of going from 1 2 2 in 2 steps right now  we need to compute the probabilities of traversing these paths  because you want to compute two step transition probabilities now  look at the first path so  the first path i know the probability of transitioning from 1 to 1 when i am initially in state 1 and i am now transforming or transitioning to state 1 in the next time period then it is p 1 1  i know that now look at this path of the leg so  this is the 2 paths of the journey from 1 to 2 for example  so this is this so  1 so first 1 leg  i know you already know the other 1 step transition probabilities now  we use the markovian property  because you see the probability that you want to compute is going from 1 to 2 in ; that means  you are actually looking for a probability x 1 to 1 x we are in 1 at time period 1 and you wanted to transition to 2 time period 2 right so  then you see this is independent of the first leg y  because you see this is independent the markovian property says that from here to here the transition probabilities independent of where i was at time zero the initial state so  its independent of value of x zero right and therefore  i can write the probability of traversing this path as product of the first leg into the probability of the second leg so  this is the idea and this is where i am using and otherwise i would not able to write these transition probabilities two step transition probabilities if i did not have the advantage of the markovian property ok so  it is clear that  because as remember  i said that the past history is not important for computing is not required for computing the transition probabilities so  the here it is  where you are currently and where you want to transition so  this is the only thing that we need to compute the probability i do not need to know  where what was the value of x naught right and so therefore  the two are independent and since by our stationarity  refer slide time  04  06  so  the stationarity property  i should say that stationarity property gives us says that probability x 1 equal to 1 and transitioning to x 2 equal to 2 ; that means  the conditional probability of being in 1 and transitioning 2 this is same as probability x naught equal to 1 transitioning to x 1 equal to 2 right so  remember because we said that this stationarity say that probability x and plus 1 equal to j given x and equal to i is a same as probability x 1 equal to j given x naught equal to i right so  the stationarity property says that these transition one step transition probabilities remain the same no matter in which time period you are and therefore  this transition probability of going from 1 to 2 was the same as the probability x zero equal to 1 so going from here to 2 in initial stage so  therefore  we are able to write down the probability of traversing these paths and so i have written them down here for the all 3 paths  refer slide time  05  25  so  this is for the first path  this is for the second one  because you are going from 1 to 2 and then 2 to 2 why have i written it this 1 p  p 1 ? ok this was to 1 to 2 and here i am using the fact that you are going from what is this path x 2 equal to 2 so  what is the path i have written here x naught equal to 1 so 1 1 and 1 2 so  this is a path right and then you have 1 2 and 2 2 so  that should be  so this is that one and this is this one and this is a third one  1 to 3 and then 3 to 2 so  this is 1 1 and 1 2 and this is 1 2 and 2 2 so  that is the 1  which i have written here and this is the 1 corresponding to this and then this is 1 to 3 and 3 to 2 p 1 1 say  i do not know why am i writing this as x naught is 1 and then you are going to what is this path ? this will be 1 3 and then this will be 3 2  ok sorry  all these 3  i am sorry  these 3 paths together give you this probability right of x naught equal to 1 and x 2 equal to 2 yes this is so  these are the 3 possible ways of going from 1 to 2 in 2 steps right 2 steps transition so  all these 3 add up to this  i am sorry  this is the 1 right  p 1 1  p 1 2 and then p 1 2  p 2 2 so  this is p 1 1 1 2 then this is 1 2 2 2  which is this path and then it is 1 3 and 3 2 so 1 3 and 3 2 so  these are the things so  now similarly when you want to when your x zero is 1 and then x 2 is 1 ; that means  in 2 steps you want to transition 1 to 1 so  again you will have 3 possible such paths right  maybe i will just again repeat the whole things then there is no confusion so  for example  you can go from 1 to 1 and then 1 to so  this is here see the path corresponding to this will be this right so  maybe i make it this thing yeah just 2 and then what are the possible way you can go from here 1 to 2 and then 2 to 1 so  1 to 2 yes and then 2 to 1 so this is the 1 right and then the third path would be when you 1 to 3 and then 3 to 1 right 1 to 3 so you would go from 1 to 3 and then 3 to 1 so  this would be 3 paths and then for the each path you would write down the probability so  this corresponds to the three exclusive paths through which you can go from 1 to 1 in 2 steps and similarly this will be 3 so  now you have computed all the two step transition probabilities for when x naught is 1 right and then in the in 2 steps you can be in 1 2 or 3 and so similarly you will have a six more such transition probabilities  when x naught is 2 and then you want to transition to 1 or 2 or 3 in 2 steps starting from a step 2 at time 0 and then finally  it will be x naught equal to 3 so  x naught is equal to 3 so  because you do not know you could be in any of the 3 states or the beginning of the process and so x 2 is equal to 1 you are transitioning to 1 from 3 in 2 steps from 3 to 2 in 2 steps and from 3 to 3 in 2 steps right so  let p 2 denote the matrix of 2 step transition probabilities just as p we are not writing p 1 so  understood p 1 is said this is p so  this is a transition matrix of 1 step transition probabilities now let p 2 denote the matrix of 2 step transition probabilities then we will just quickly notice that p 2 is actually p square  because ya here you have written the components of this  let me just write down say for example  if you want to write so  p 2 this here will be the first one will be a p 1 1 2 you want to look at right and so that will be going from so p 1 2 p 2 1 plus p 1 3 ok  first let it be 1 1  1 1 then it will be 1 2 p 2 1 plus p 1 3 p 3 1 so  this will be a first element right  these are the 3 paths  which i had drawn in the last lecture ok so  then you see this is multiplying a p 1 1 p 1 2 p 1 3 so  first row of p and with p 1 1 p 2 1 p 3 1 so  if you multiply the first row of p is the first column of p you get the entry p 1 1 2 right and now  you can also verify this for example  this is the first row p 1 1 p 1 2 p 1 3 you are multiplying with the second column p 1 2 p 2 2 p 3 2 right so  to get the entry 1 2 in ; that means  it here if you want to get the entry 1 2 then you are multiplying the first row of p with the second column of p and therefore  you can just verify yourself quickly that p 2 the second step condition maybe nothing  but the product of p and p so  that makes like very easy and we will show that this is valid for all values of for a higher powers of p also ; that means  if you want to look at yeah so  let me just show you a systematically that we would be you are really on the path of getting a very interesting and very useful result because to be able to compute these transition probabilities any step transition probabilities by raising the power of p is a very convenient way of getting the transition probability right so  here you are want to know that what is the probability that you will be in tenth steps you will be from i to j starting in state i you will be state j then the tenth the i j th entry of p ten will give you the at probability and so on so  you will see that yeah so  basically what we have we have shown is that your 2 step transition probabilities can be expressed in terms of 1 step transition probability right  because we are just multiplying the 1 step transition matrix with itself and we are getting computing the 2 step transition probabilities right ok now  same way we can do it for any power and here again i will just want to spend time it may look like little reputation  but it does not matter  because you must get the ideas very clear so  for example  now yeah so the whole a target is now to compute p i j k ; that means  k step transition probabilities we want to compute and so here again i will just start from x 3 equal to 1 and x naught equal to 1 so  suppose now the 3 steps  you want to transition from 1 to 1 so  this again i can break up like this x naught starting with 1 you are in 2 steps in 1  state 1 and then you will be going again transition to 1 right so  this is your 2 step transition probabilities and then this is your 1 step so  again i can write down this and now these 3 paths are mutually exclusive and exhaustive right this is not because there you can go to x 2 you can be after 2 steps after 2 transitions you can be in state 1 2 or 3 right starting from x naught equal to 1 and then you have to transition finally  to a state 1 so  therefore  these are the 3 paths right and here again we are using the markov property because this one is this then this part of the path will be independent of the probability for this  because here you have x 2 equal to 2 and x 3 equal to 1 so  there only the current state is needed to compute the transition probability and this is not dependent on where you were earlier either at x 1 or at x naught  that is not important so  therefore  we will write this and again using stationarity i will simply be able to write this also again as a 1 step transition probability of going from 3 to 1 right so  therefore  you see that these 3 probabilities can be written as p 1 1 2 yes in 2 steps you are going from 1 to 1 and then again 1 step you are going from 1 to 1 so  this is p 1 1 2 and p 1 1 right similarly 2 step transition from 1 to 2 1 to 2 p 2 and then 2 2 1 p 2 1 plus p 1 3 2 and p 3 1 right  this is yeah right so  and then i can write down x 3 equal to 2 when x naught is 1 and then of course  probability x 3 equal to 3 x naught equal to 1 right this will also be equal to so p 1 1 p 1 3 plus p 1 2 p 2 3 plus p 1 3 p 3 3 so  this is the first row of and you can see that since this is your element of p square so  therefore  if you write these are the entries of your p square and then you are again multiplying by p 1 1 p 2 1 p 3 1 so ; that means  so essentially yeah ok  refer slide time  16  04  so  we saw that p 3 ; that means  if you want the 3 step transition probabilities  this will be given by p 2 p square into p so  again a third power p and so in general we will should be  we can now say that if you want to n step transition probabilities then this will simply be raising the matrix p to power n that means  multiplying p n times and the entries in p n will give us all the n step all the n steps transition probabilities that we need right now  there is a another method through walks on the transition graph  but you will soon realize that it is not a very efficient method it is fine to see what is happening when your graph is small in number of states are also not too many so  for example  when you want to look at this probability of 2 step transition probability from going from 1 to 1 right so  which would mean that you traverse this loop once and then again one more times  2 times you traverse this loop and you have this then you can compute the probability  which would mean that this is a traverse of probability of traversing the loop once is p 1 1 so  when you do it twice it will become so  the probability would be so  the probability this would be p 1 1 square right  fine then if you want to for example  compute the 3 step transition probability of going from 1 to 1 then let us see what are the we will try to see all possible paths on this transition graph going from 1 to 1 right so  of course  i have not written the detail for example  x naught equal to 1 x 1 equal to 1 and x 2 equal to 1 and x 3 equal i am just you know made the notation simpler so  here this tarsus the  you know 1 path which is you are traversing this loop four times right  i mean 1 to 1 sorry  3 time 1 to 1 then 2 and then 3  three times  because 3 to 3 transition probability so this path you would traverse 3 times ; that means  the loop you will traverse 3 times then the probability is that you go from you traverse the loop once then you go to 2 and then from 2 go to come back to 1 right so  you traverse this loop twice then you go to 2 and then 2 to 1 so  this is 1 path and therefore  here again you can write down the probability as p 1 1 square into p 1 2 plus p 2 1 right so  once you write down so  the eight possible paths  you can see that right 3 step transition and you this 3 possible states so therefore  eight possible paths and similarly like 1 to 2 so  you go from 1 to 2 then you traverse this loop 2 to 2 then 2 to 1 so  this will be p 1 2 into p 2 2 then p 2 1 right so  this way  i can write down all the probabilities and then compute the so  therefore  they are all distinct paths and you can compute the probability of each path and as i told you each leg of the path is independent so  we are multiplying the corresponding probabilities of traversing each leg of the path and so you can write down  but you see that this will become very conversion the moment your number of states become  you know if you had four to five states or even  you know easily any markov process that you consider we have seven to eight or ten states then you see the possible number of the number of paths were really go up right  exponentially and then you may it is a since its very likely that you will miss out on some of paths  because you have to inomulate all the possible paths and here in this case only you know for x 3 equal to the 3 step transition probabilities for 1 you are going from 1 to 1 you had to inomulate 8 paths now  if it becomes x four it will be 16 paths so  the number this will blow up and so  therefore  this is for large n and for large number of states ; that means  if you want to ten step transition probabilities and the number of states is also ten then it just not possible for you to inomulate all possible paths and then compute the probabilities  but for small cases and in fact  to see actually what is happening this is a good way right so  i thought i have just talked to you about it and when you are working out with small problems you can actually see this  but otherwise this is really a very efficient way of computing the higher order transition probabilities now  this is fine so  therefore  we have now a method of computing any step transition probabilities provided we are giving the 1 step transition probabilities right  refer slide time  21  06  but again we there is some more information that we need and that is see the value of x naught is not known with certainty we do not know when which a state the system has was initially or for where it started right so  this will be normal given by a probability distribution ; that means  you will be given these values so  p i naught is a probability that x naught is an state i right so  this at time 0 ; that means  that initial time the employee is in state i so  this is there is a probability attach to it now  if you want to compute the probability that the employee is in h r in human resource section division at time five so  you know ; that means  you want to compute yeah  so let us see you want to compute the probability that x 5 is equal to 2 so  the particular employee at time period five is in h r right now  let us see the column of p 5 remember the 5 step transition probabilities are given by p 5 so  the column would be p 1 2 5 p 2 2 5 and p 3 2 5 so  actually i should have written this let me write this instead of you know immediately jumping to this so  we want to say that the probability x 5 is equal to 2 given that x naught is 1 right then you will multiply this by probability x naught equal to 1 right so  i am writing this as a conditional probability then into the so  then i will have to do it for all possible values of a x naught so  to get the probability that x 5 is equal to 2 so  this will be probability x 5 is equal to 2 given that x naught is 2 so  probability x naught is equal to 2 right  plus probability x 5 is equal to given x naught is equal to 3 into probability x 3 is equal to oh sorry  x naught equal to 3 so  i break up this so  again you see mostly what you have seen that  you know the basic probability theory that we need for analyzing these chastic processes so  this is a writing probability as a  you know breaking it up into conditional events and then writing them down as the some of these conditional probabilities right and so this one gives you this is your five step transition probability from 1 to 2 so  1 to 2 5 and then into probability x naught is equal to 1  which is given to you from here so  p 1 naught so this will be p 1 naught right similarly this will be a five step transition probability of going from 2 to 2 so  this is p 2 to 5 into probability of being in state 2 at time 0 so  which is p 2 0 and this is third so  this is how you can write down the probability if you want to know that the in time period 5 the employee will be in h r right and so you can now compute in general you can say that this is now p i n will be the probability at the system is in state i at time n and see here just to make the presentation simple i am just taking all the time referring to our job assignment example  but you know that this can be made to whatever the number of states general you can have a simple k here so  k states and everything can be argued with respect to general number of states  but here i am doing it for this particular example just show that you can fixed your ideas better ok so  then p i n is probability x n equal to i ; that means  the system is in state i at time period n so  these are the probabilities and i have shown you how you will compute them so  you can write them down right here so  this will be your  i am writing this small p naught into p n so  when you want the probabilities of the system being in a particular state and time period n then this is a formula and these are called the state probabilities at time n so  this is the important right so  now we have we do also have the see we have the transition probabilities for any time period and we also have the state probabilities at for any time period n right and yes so i have written it here where these i am saying that p n is your row vector of probabilities so  this is the i th component so  then p n is ya  i should have written here so this is the i th component ya so  in general so if this is a row vector is p 1 n p 2 n p 3 n so that means  state probability of the system being in n being in 1 at time period n this is probability of the system being in state 2 at time n this is the probability of the system being in state 3 at time n so  i denote this by a row vector p n and then this can be written as p naught into p n so  this gives these state probabilities at time n right now  the markov change is completely specified when you are given the first step transition matrix p and the initial probability  initially probability was being system being in particular state so  p naught is the vector which gives you p naught 1 p naught 2 and p naught 3 so  this will be the probability in initially when the system is in state 1 2 or 3 then you can compute these and of course  you can compute the transition probability in step transition probability also  refer slide time  27  24  so  let us consider an example the same example now with numbers and so we will just go through all the concept that we have talked about the transition probabilities and state probabilities i mean higher order transition probabilities and the state probabilities so  suppose the transition matrix is given as this so  then the corresponding diagram you see for example  there is no arc from 2 to 1 so  therefore  this is missing here and similarly you do not have a loop from 3 to 3 so  it is missing the probability is 0 right  otherwise and you see that they add up to 1 all these probabilities or the rows must add up to 1 so  this is a valid transition matrix and these are other positive or zeros and they row entries and all add up to 1 so  this is valid and a comparing diagram is this  the transition diagram is given by this right now  let us compute second order transition probabilities so  i multiply p with p and i get these numbers so  for example  here you can transition from 1 to 1 in 2 steps this will be 1 to 1 so  2 steps therefore  again the same thing as i showed you that if you just want to sit on path it will be 1 by four this plus then you can go to you can not go to 2 in 1 2 steps transition  because then you can not come back to 1 right so  then it will be you can go to 3 and then 3 to 1 so  this will be 3 by 4 into 1 by 4 right see you can either stay with 1 to 1 and then you can go from 1 to 3 and then 3 to 1 this is what you can do in 2 steps if you want to transition from 1 to 1 so  2 possible paths and so therefore  this is 3 by 16 and this is 4 by 16 so 7 by 16 right similarly you can maybe look at this 1 here 5 by 16 so  this is from 1 to 2  1 to 2 you want to transition in 2 steps so  then the possible path is 1 to 2 then 2 to 1 right so  that will be what 1 to 2 is 1 by 4 into you transition from 2 to 2 will be 1 by 2 plus or you can stay from 1 to 1 and then go from 1 to 2 so  that will be a 1 by 2 into 1 by 4 right so  what how much will this be 1 by 8 plus what or what i miss something out so  this is you are going from 1 to 2  1 to 2 you are going in 2 steps yeah so  1 by 2 yeah this is a 5 by 16 and you are computing p 1 2 right so  you can go from p 1 1 into p 1 1 so  that was 1 by 4 and why did i multiplied by i want to go from 1 to 1 sorry  this is not correct  why should i have say 1 to this is simply 1 to 1 so this into p 1 2 so  therefore  this is half ha that is i wrote this plus 1 by 2 into 1 by 4 or i can go from 1 to 2  which is 1 by 4 and then transition 2 to 2 so  that comes out to be 2 by 8 and i am getting it as 5 by 16 so  let us multiply this ; that means  you want 1 and 2 so  that will be      i am missing out on the path 1 by 8 plus 1 by 8 plus 1 by 16  so 1 by if you want to go from 1 to 2 so  right i missed out on the path so  this is 1 to 1 and then 1 to 2 then 1 to 2 and 2 to 2 and then there is a another path 1 to 3 and 3 to 2 so  plus 1 to 3 is 1 by 4 and then from into 3 to 2 is 1 by 4 see that is what i am trying to say that you know even in such a small diagram i was missing out on a path so  just imagine if you had these five or six states and then you had you know  that many nodes so and then you have these so many arcs you will certainly miss out it will be very difficult to it will be very time consuming to enumerate all possible paths so  as it is you know such a small example  i could miss out on the path 1 to 3 and 3 to 2 so  that will give you now 1 by 8 plus 1 by 8 plus 1 by 16 so  that will be 5 by 16 right  1 by 8 plus 1 by 8 which will be 1 by 4 so  that is 4 by 16 plus 1 by 16 5 by 16 so  anyway you can now interpret all these probabilities you know by looking at the path or by find now  i make further computations took powers of p so  this is p 3 comes out to be this and if you make compute fourth power then these are the numbers and another aspect that i want to point out here is that for example  in this particular case you are able to transition from any state to any state even though some of the arcs are missing  but even after that  you can go from 1 to 2  2 to 3  3 to 1 again and so on so  you can transition from any state to any state maybe not in 1 step always  but in fact  here it is happening that you are able to go yeah for example  from 2 to 1 you can not go in 1 step  but you will able to go from 2 to 3 and then 3 to 1 so  in 2 steps you will be able to transition so  here in fact  the moment all your entries see at p 2 yeah so  at p 2 all your entries are positive  which shows see therefore  ; that means  your p i j 2 is positive for all i j so  this immediately makes you conclude that you have a 2 steps path from each state to from every state to every other state so ; that means  this was the word for this is communicate ; that means  all states communicate with each other and maybe not in 1 step  but at least in 2 so  if all the entries of p i j 2 are positive then ; that means  all states communicate with each other  i will formulate define that also  but essentially what i want to saying here is that you can go from any state to another state in 2 steps in this particular example and in some other example  if it is you know there is some k for which this is positive then ; that means  again there is a k step path from every state to another state  refer slide time  34  24  and ya  so now when you look at the fourth power of p these are the numbers and you can now you should carefully look at the column numbers this is 103 upon 256  102 upon 256 and 102 upon 256 so the numbers are getting closer right and you can say that almost conversing to 102 on 256 in fact  you might say that why not 103 or 102  but any one of these numbers so  in other words that you know  if you want to interpret these numbers ; that means  now the probability say for example  what is this number so  103 upon 256 is the probability of 114 ; that means  four steps you are from 1 to 1 right and then 102 upon 256 this is the probability 2 1 4 right ; that means  if you  so here it says that  if you are initially in state one then in four steps you will be back in state one so  this is the probability now  this says that if you are in state 2 in the beginning and you are transitioning to 1 in four steps then this is a probability and third one is 102 upon 256  so this is p 3 1 4 so ; that means  you are in state 3 and you are transitioning to 1 in four steps so  you see that it is becoming almost immaterial to know  where you started  because these probabilities are getting closer and we will show you then later on you will also formula is all this discussion so  essentially the state in which you were the initial time is becoming unimportant these and similarly the same thing you can interpret for the second column because it is a 85 by 256 86 by 256 and 85 so  these numbers are also getting closer to 85 and here i have written  because here its 68 by 256 68 by 256 and 69 by 256 so  you might say that why not 68  but then see remember the probabilities  which when you finally  say that all these are conversing to they must also add up to 1 right  because the system has to be in 1 of the states so  the same argument we will continue using and so here i have if i say that this converges to 102 this 2 upon 256 this is 85 by 256 then this should by 69 by 256 of course  it is possible that the  so essentially right now the probability of being in state 1 after four transitions is hovering between 102 256 so  which is a more exact statement  this is a more exact statement right similarly here also i can say the probability of being in state 2 after four transitions is between  is in the interval 85 upon 256 and 86 upon 256 right  which is a very small interval right so  difference of 1 upon 256 and similarly here it will be 68 upon 256 and 69 upon 256 so  these probabilities and if you take the fifth power then certainly you will see that the numbers are conversing and you will take about this formulae anyway yeah and also while we are talking of this see i wanted to point out that here again these probabilities  because this is now row vector  this is a row vector remember 1 by 3 we are writing so  this is 1 by 3 and this is 3 by 3 so  then again this is 1 by 3 so  the 3 atleast must again add up to 1  because at you know n after n transitions your system will be either in 1 2 or 3 so  therefore  these probabilities also must add up to 1 right  which you can see also that so  anyway these also add up to 1 and then now  suppose for this job assignment problem  if your initial probabilities are given by 1 by 4  1 by 4  1 by 2 that means  probability of being in production is 1 by 4  probability of being in h r is 1 by 4 and probability of being in sales is half then you want to ask the question that what are the probabilities of being in state in 1 2 or 3 after 2 transitions so  that will be given by this right so  1 by 4 1 by 4 1 by 2 multiplied by p square and so these are the probabilities of being in you know so  this gives you the probability of being in a production after 2 transitions right and this is the probability of so these are the state probabilities after 2 steps  after 2 time period so  this is 21 by 64 and 18 by 64 and these probabilities also must add up to 1 right so  now  we are trying to give you some more characteristics of the markov process and we will do lot of analysis in terms of these transition probabilities and the state probabilities  refer slide time  39  53  so  let us i just want to show you the limiting behavior of these steady state probabilities so  let us just graphed the values of p 1 3 p 2 3 and p 3 three for different values of n so  you see the starting vector is 1 by 4 1 by 2 and 0 so  p 1 3 for example  1 by 4 is 0.25 so  i am just start it so  these are time periods and these are your probabilities so  numbers from 0.1 to 0.5 so  0.25 see at time 1 it is in period 1 it is 0.25 then here also 4 by 16 is 0.25 so  in period 2 also this is a same then it will very slightly goes up in period 3 to 17 by 64 so  i am just showing it like this and then it comes down to 68 upon 256 now  68 upon 256 is 0.26 so  therefore  it comes down to a point this is this is my value for a 0.26 so  this is the graph for p 13 as it goes to different periods so  the values transition probabilities then  if you look at p 23 now  p 23 is starts from half right then it immediately comes down to 0.25  because this is 1 by 4 so 0.25 so  this is where it is and then in the next 1 it goes to 18 by 64 so  actually sorry  my graph for p 1 3 is this 1  because very slightly it goes up and then again it settles to here this is the graph for p 2 3 so p 2 3 the p 2 3 graph is this so  this is from 0.5 to 0.25 then it goes up to 18 by 64 so  this is above more than 17 by 64 this and then it comes to 68 by 256 so  the same value as for p 1 3  p 1 3 4 and p 2 3 4 are the same so  this is how it is and for the for p 3 3 see it is 0 in the beginning and in stage time period 1 then it jumps to 5 by 16  which is little more than 1 by 4 so  little more than 0.25 and then it comes to 16 by a 64  which is exactly 0.25  right so  i have try to just parallel it with this 1 here and then it will be 69.256 so  the line is the slightly above this so  therefore  you can see that and then as you take higher powers all 3 will settle down to this number  which we have to compute and we will do it when we find out the steady state probabilities so  you see this is the limiting behavior and so it does not matter even though the 3 had different very different starts all the three  but finally  they must to the same so  therefore  the relevance of the starting state of the process is not at all a relevant here this is what you want to show and of course  this will show this will not always be true and we will now then find out during the course of few next few lectures as to when this is valid on when this kind of limiting behavior is valid ok so  what we are going to say is that rows of p n become identical to pi 1 pi 2 pi 3 all the rows  because it does not matter the starting state of the starting state of the system and so all the rows will be pi 1 pi 2 pi 3  but it is not necessary that the 3 probabilities are the same right so ; that means  it is being so  essentially what we are saying is this is now a long term behavior we are saying that the system will be in state one so  that is a probability right then this is the probability of the system being in state 2 and this is the probability of the system being in state 3 so  the starting probabilities are not relevant  but the values long run values will not necessarily be the same and so the definition for the steady state probability is that pi j is the limit of p j n  as n goes to infinity right  remember we defined this as the  you know multiply by p 0 and p n so  this is a limiting a value of p j n  as n goes to infinity  which is actually probability x n in j right in the long run your system is occupying state j as n goes to infinity and what we are saying now is that this actually is equal to this conditional probability  but this part is becoming irrelevant right so  the i c the probability finally  is going to pi j so the i part is irrelevant here this is what we want to show you and so we will in the next lecture discuss the under what condition of course  that will come in the due course of time  but first of all we would want to know how we go about computing these steady state probabilities when we know that they are they exist so  right now we will assume that they exist  and then we will find out the method of computing them and then we will continue with the discussion as to under what conditions they always exist introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  27 state prob first passage and first return prob  refer slide time  00  14  so  through the numerical examples we saw that limit p n  p is a transition matrix  so the nth power  as n goes to infinity  if this exists  if the limit exists  then it converges to a matrix with all rows identical whatever two-three examples we considered  we saw that the limit existed  and then  we saw that the rows were becoming identical as we increase the value of n ; that means  we continue taking higher and higher powers of p we can easily show that in case limit p n exists  limit p n then goes to infinity  if this limit exists  this is always be the case ; that means  whenever this limit exists  when this will converge to a matrix whose rows are all identical so  let us show this immediately  very easily so  limit p n ; suppose  n goes to infinity so  q 1 is a row  q 2  q k ; suppose these are k rows we are considering the system when it has k states  k possible states so  then i can write limit p n as n goes to infinity as limit p n minus 1 into p  as n goes to infinity then as n goes to infinity  this and this have the same value so  this same matrix ; they will converge to the same matrix so  this will be q 1 q 2 q k is equal to q 1 q 2 q k p so  this reduces to the limiting case ; this reduces to this system therefore  from here  you can say that q i  the i th row here  would be the i th row multiplied by p  post multiplied by p so  this is it for all i and hence you can see that all rows of p are  i should not say of p ; what i want to say is  that if it converges to … p is your transition matrix so  all rows of p raised to n will converge to … so  all rows of limit p n  i should write here limit p n as n goes to infinity are identical now  if you want to solve for this  you can see that immediately  see you know that the rows of p  the rows of p have the property  because it is a transition matrix so  all rows add up to 1 and therefore  this is not a non-singular matrix and so  here you will have infinite solutions  to this system you will have infinite solutions ; but then  if you also require the elements of q i to be non-negative and they add up to 1  that means  we are looking for a solution where the q i  s   the elements of q i  form probabilities  then this will be a unique solution and i will denote this solution by q i is equal to pi 1 pi 2 pi k and these will be known as the steady state probabilities so  it means when the system has a steady state  it has gone on for a long time  it settles into a steady state  then the probability of being in state 1 is pi 1  probability of being in state 2 is pi 2  and up to pi k so  this is the whole idea  refer slide time  03  41  now we will come up with the method of obtaining these values pi 1  pi 2  pi k  the steady state probabilities so  now let us evolve the method for computing the pi i  s   the steady state probabilities see  p n can be written as p n minus 1 into p  the n th power of the transition matrix so  then  if i take limit on both sides  then this is the limit p n and n goes to infinity ; and this is limit p n minus 1  n goes to infinity into p now  as we said since we have assumed that the pi i  s  exist ; and so  each row of p n in the limiting value would be pi 1  pi 2  pi k ; so  all the rows are identical therefore  on this side also you get the matrix pi 1 pi 2 pi k  pi 1 pi 2 pi k  and so on similarly  p n minus 1 will also converge to the same matrix and this times p so  the limiting behavior  i can just break up this in this way and then do it so  if this is going to the limit  in the limiting value to this matrix  this will also go to the same matrix  and therefore  you have these equations now  this system actually  since the all rows are identical  so actually these k equations reduce to this so far  i was talking about the three-state processes so  now  let me just do this much in 3  for the general case  and then we will come back when we want to talk of specific values and examples  we will again revert back to the three-state example that we have been talking about so  let us just talk about it in general  and therefore  the system reduces to k equations ; that means  i can simply just equate the first row here to the first row here so that means  pi 1 to pi k is equal to pi 1 to pi k times the matrix p and now let us write out the equations in detail here so  pi 1  the first component here  will be this multiplied by the first column of p  refer slide time  05  33  so  the first column p is … so pi 1 p 1 1 1 plus pi 2 p 2 1 and so on plus pi k p k 1 similarly equate the second  component here  element to the second element ; that means  this multiplied by the second column of p ; so that gives us this and finally  the k th equation is pi k is equal to pi 1 p 1 k so  the k  the k th column we will take when we equate pi k with this multiplied by the k th column so  i have these k equations  but we can immediately see that these k equations are not linearly independent  since sigma p i j  j varying from 1 to k is equal to 1 so  let us just quickly check this  that is  all these equations see essentially what i am saying is that your first k minus 1 equations will give you the k th equation so  therefore  those of you who are familiar with the word rank  so  the rank of this matrix is k minus 1 or you want to show that so  let us add the first k minus 1 equations here so  it will be pi 1 plus pi 2 plus pi k minus 1 and this is equal to so  when you are adding the first k  so you will be adding p 1 1 plus p 1 2 up to p 1 k minus 1 so  it will be pi 1 into summation p 1 j  j varying from 1 to k minus 1 and similarly  pi k into summation j varying from 1 to k minus 1 p k j now  since the rows add up to the transition matrix we have to put this i mean we know this that these rows of the transition matrix will always add up to 1 so  therefore  sigma j varying from 1 to k minus 1 p 1 j is actually 1 minus p 1 k because this plus p 1 k is 1 so  therefore  this sum is equal to 1 minus p 1 k  and similarly i substitute for all of these sums by so  this one will be 1 minus p k k and now you see that when you open up the bracket  so  pi 1 plus pi 2 plus pi k so  pi 1 plus pi 2 plus pi k minus 1 cancels out  you are left with pi k  and the other things you transferred to this side then you immediately get pi 1 p 1 k plus pi 2 p 2 k and pi k p so  this is your k th equation so  because the probabilities of the rows sum up to 1  therefore  these k equations are not linearly independent so  in fact  the first k or any k minus 1 will lead you to the k th 1 essentially  because here i just choose the first k minus 1  you can choose any k minus 1 and you will be able to obtain the remaining one by adding the k minus 1 equations you have chosen so  therefore  infinite solutions  because the matrix is singular ; the equation matrix is singular  but when you impose a condition because since we are looking for these steady state probabilities and they must add up to 1  pi 1 plus pi 2 plus pi k has to be 1  because a system will be occupying one of the states  either one  two or k minus 1 or k so  when you impose the condition that pi 1 plus pi 2 plus pi k is 1  then you get a unique solution and so  so therefore  we have a very neat way of computing these steady state probabilities and we know that we have a unique solution so  you can not say that  you know  that the probability of  the long run probability of  being in a particular state of the system  here you know the probabilities are more than 1 ; that would not be reasonable solution so  now let us go back to your job assignment problem  and let us try to obtain  because i was trying to get you to have a look at the steady state probabilities by taking the powers of p  but now here  this seems to be a quicker way of and a neater way of solving  of trying to get the pi  s   so  because when you are taking the powers you really do not know when to stop ; or in fact  you would have to go on doing it till you see that the values are really closing in so therefore  this would be a better way to get your steady state probabilities and so  the three equations you see  you can see from pi 1  your this thing p 1 2 is … when you are writing the equation your p 2 1 is zero so  here you get  yes  the matrix is there in your earlier lectures so  these are the three equations essentially for solving pi 1 pi 1 pi 2 pi 3 so  therefore  i can from this equation i immediately get … so  the trick would be that since you know i do not get unique solution to this system  so i will solve for pi 1 and pi 2 in terms of pi 3 and then i will apply the condition that the sum is equal to 1 to get the value of pi 3 and then i will get all the values so  from here you see  you immediately see  that half of pi 1 is 3 by 4 pi 3 so  that gives you that … where is pi 1 ? yes  half of pi 1 is 3 by 4 pi 3 so  pi 1 is 3 by 2 pi 2  3 by 2 pi 3  and then you can substitute here for pi 1 in terms of pi 3 to get your pi 2 so  pi 2 comes out to be 5 by 4 pi 3 because this is half pi 2 and this is pi 3 minus 1 by 4 into 3 by 2 pi 3 so which makes it 3 by 8 so  5 by 8 pi 3 ; therefore  pi 2 is 5 by 4 pi 3 so  now i substitute the values pi 1 is 3 by 2 pi 3  this is 5 by … this is 5 by 4  5 by 4 pi 3 and this is 1 so  therefore  how much is this ? i suppose i will have to redo this thing or maybe this was right  i do not know so  what is it ? this will be 6 plus 5 plus 4 so  the value was ok this was a mistake here  but the value i had computed was ok so  this is this so  therefore  your pi 3  pi 3 is 4 by 15 and so  this gives you pi 2 equal to 5 by 4 into 4 by 15  the value of pi 3 so  that makes it 1 by 3 and this pi 1 would be ? pi 1 is 3 by 2 so  3 by 2 into 4 by 15  which is this  and 3 by 5 so  pi 1 is 2 by 5 and now  let us compare these values with what we had obtained by taking powers of p  refer slide time  13  07  so  our pi 1 had come out to be something because two values of 102 upon 256 and the other one was 103 upon 256 so  you see  2 by 5  does lie between these two numbers so  this was up to fourth power and when you take the fifth and sixth powers  you will see that values will get closer and you will actually reach 2 by 5 similarly  your pi 2 is 1 by 3  and this is also a number lying between 85 upon 256 and 86 upon 256 you can compare ; right this is between so  1 by 3 lies between these two and similarly  4 by 15 is a number which is between 68 by 256 and 69 by 256 so  the two things matched  but certainly that is a much better  quicker  way of obtaining your steady state probabilities now  these steady state probabilities have very useful interpretations and we will continue seeing through examples  through on  when we analyze the process further so  essentially what we have said is that pi i is a probability that in distant future one will find the system in state i so  the probability that your process will be  that means  a particular employee in the automobile manufacturing company  that particular employee  will be in lets say hr  when you know after the process has gone on for lets say for 4 years or 5 years  then we expect the person  the probability  that the employee would be in the hr division is 1 by 3 or the probability that he will be with sales is 4 by 15 so  these are the long term probabilities and as we said that the initial  that means  the division or the section in which he started his career is irrelevant here then you can also interpret this as the fraction of time the system occupies state j ; fraction of time the system is occupying the state j i am writing pi i so  it should be pi i here yes  this is i so the fraction of time the system occupies state i now  if you run many identical processes simultaneously  then you see  that the pi j would come out to be the fraction of processes that you would find in the state j ; that means  if you suppose run hundred identical processes simultaneously  and you find out that maybe 45  45 of the processes are that particular time  of course  you let the processes run for a long time  and then after a certain particular period of time  you just find out how many of these processes are occupying state j so that comes out to be 45  then your pi j would be  pi j would be approximately 45 upon 100 ; that will be the fraction of processes that you would find in state j and another interesting interpretation of the state pi j is  you know  it is a reciprocal of the mean number of transitions between recurrence of state j so  this recurrence i will define formulae after some time which is also very important so  what we are saying is that  this is the reciprocal of the mean number of transitions so  on the average how many transitions would be required to go from state j to j ? now recurrence means for the first time ; that means  you are in state j to start off  and then for the first time when you revisit j so that number of transitions  if you take the average of such transitions  then the reciprocal of that is your pi j and this also we will derive in another way  and of course  this part we will prove later on so  for example  what we are saying is that since pi 2 is 1 by 3 and pi 2  2 is our hr section so  we are saying on the average three transitions will be required for this particular employee to go from hr to hr that means  if he starts his career with hr  human resource section  then he will after 3  on the average  he would be requiring 3 transitions to get back to hr so this is the interpretation so many interpretations that we have we can give  and then  we will see how we make use of these steady state probabilities to analyze these processes further  refer slide time  17  47  so  let us now … i have taken this example from again rabindra  phillips and solberg so interesting physical interpretation of state probabilities so what he saying is that  in the  you know  job assignment problem  you know  you would consider the three states as three reservoirs so  node 1  and node 2  and node 3  they are reservoirs  and the arcs connecting the nodes are the pipes through which liquid can flow with valves to ensure that flow goes in the direction in which the arrows are there for example  there will be valve here  which will direct the flow from 1 to 3 only  and another valve which will direct the flow from 1 to 2  and then another one which will just direct the flow from 1 to 1 so  this is the idea so  just think this as a reservoir  representing a reservoir  with these pipes connecting them the reservoirs and then the valves to ensure that the flow goes in the direction in which the arrows are there and then the probabilities p i j  s  ; that means  for example  the probability 1 4 associated 1 2 would be the fraction of the liquid that is there in 1  in reservoir 1  which will be sent to 2 similarly  if you look at 2 to 3  then it is half the liquid  which is there in reservoir 2  will be send from 2 to 3 and so on so  these probabilities then can be interpreted as the fraction of the liquid in the reservoirs so  p i j is the fraction of the liquid in reservoir i  that will pass to reservoir j in 1 unit time so it will take 1 unit of time for the flow ; so that means  half of the flow from here to here in 1 unit of time will go from 2 to 3  because the probability is half so  if we think of the system as  you know  made like this  then what you do is  you pour 1 unit of liquid into the system according to these initial probabilities ; that means  one-fourth of the liquid is put in reservoir 1 ; a one-fourth is put in reservoir 2 ; and half the liquid is put in reservoir 3 and then  the liquid is allow to flow according to this plan then what we are saying is that dynamic equilibrium so what we have discussed  that the probabilities will converge and they will become irrespective of how much liquid was initial poured into the reservoirs so  finally  dynamic equilibrium will be attained and the liquid will continue to flow  but the liquid in each reservoir will equal the steady state probabilities so  our steady state probabilities … i do not have the numbers here  but whatever we had computed pi 1 pi 2 pi 3 as  for example  i remember pi 2 was 1 by 3 so  pi 2 would be the … that means  reservoir 2 will have one-third of the liquid  and then pi 1 would represent the amount of the liquid that is in reservoir 1  and pi 3 will be the amount of the liquid present in reservoir 3 so  this is the interesting part so what is being said is that  actually equilibrium will be attained and the liquid will continue to flow according to this plan  but each reservoir will settle down to  even though the starting amounts were this  each reservoir will settle down to the amount of the liquid according to these steady state probabilities ; and what do we mean by that ? so equilibrium means that for each reservoir the flow out will be equal to the flow in ; then only whatever there is  the liquid is there  the steady state liquid that is there in the reservoir will be maintained  which is according to your pi 1 pi 2 pi 3  refer slide time  21  33  so  flow out from reservoir i would be … so  the probability that you are in a reservoir i into then p i j  summation over j so  from i it can go to reservoir 1 to 2 to 3 so this is the probability that the amount of liquid flow out from reservoir i … and the amount … this you can write  when you summing up  you are summing up with respect j ; so i can  pi i can come out  and this will be sigma j p i j  but sigma j p i j is 1  all these probabilities and the i th row will add up to 1 ; so this is pi i and the flow in from other reservoirs that the flow is coming in so that will be pi k into p k i ; the flow is coming from the k th reservoir to the i th reservoir  and so this is the probability of being in the k th reservoir so this is sigma pi pi k p k ; well i am talking of probabilities  but here we are saying this is the amount that is there in the k th reservoir  and so this is the fraction which is going to i so  yes  i should actually interpret the whole thing in terms of this particular example so  here also i should not refer to pi i as the probability of being in i  but this is the amount of liquid that is there in the i th reservoir and the p i j fraction of this liquid is being sent to the j th reservoir so  therefore  flow out so  from the i th reservoir this much is the liquid  and from this  these are the fractions of this liquid which are being sent to different reservoir so this is a flow out and this is the flow in so  please just interpret it this way ; ignore my earlier remark so this is a sigma pi k p k i  and so  the two must be equal  and therefore  you again get these  if you do it for all i  then you will immediately get this equation pi is equal to pi p so i thought this was interesting way of looking at these steady state probabilities and somehow these will fixd certain ideas in your mind then another example from sheldon ross that i want to … because i really want to spend time on these steady state probabilities  so that you get the ideas  you know  understand them properly now  here this is an example where it is a production system and these are the probabilities of … transition probabilities so we have four states 1  2 and 3  4 now the states 1 and 2 are considered as acceptable or you can say when the system is up  and 3  4 are not acceptable which you have to interpret as your system is down  that means  there is a breakdown  the machines are not functioning so there are four states and this is your transition matrix from state i to state j and questions to be answered now  the question that we want to answer are  the rate at which the production process goes from up to down ; that means  the rate of breakdown so when it is up  that means  the machines are working and then there is a breakdown so you want to know the rate at which the process  the production process  goes from up to down and another question will be the average length of time the process remains down ; that is also very important  because you want to know with this kind of transition matrix  you want to know for how long the process will remain and of course  you always talk in terms of average length of time the process remains down when it goes down so  when there is a breakdown for how long will it remain in that state before it comes up  but now the new thing is that you have two states which are describing the up situation and two states which are describing the down situation so  therefore  i took up this example to again show you  of course  we will compute the p i  s  and then i will show you how to answer these and there are many more questions that have to be answered so  the third question you want to answer is the average length of time the process remains up when it goes up so  these are the three questions we will try to answer by computing these steady state probabilities  refer slide time  25  53  so  we write down the equations for the finding these steady state probabilities so  pi 1 is equal to this pi 1 pi 2 pi 3 times the first column so  you get this number  this equation then pi 2 so  you can just by looking at the transition matrix  yes the matrix p  then you can see that these are the four equations that we will obtain now  interestingly the second column here is all 1 by 4  1 by 4  1 by 4  1 by 4 so  when you write this second equation  this  you immediately get the solution for pi 2 because all these add up to 1  the state steady state probabilities have to add up to 1 so this immediately comes out that pi 2 is equal to 1 by 4 so  i have used it already here and now since i have the value of pi 2  i should be able to immediately compute the values of pi 1 pi 2 and pi 3 so  what i do is here  yes … no that is not … i have to now after having got pi 2  yes i can now see from here … yes  no even here … so  i thought that it was immediate that you could compute after you have pi 2  then yes  yes  see here  yes  you see  that is why one has to be a little clever and use inspection so  here this is pi 1 pi pi 3 and pi 4 and again the coefficients are 1 by 4 so  this i can write as 1 by 4 into 1 minus pi 2 see and i have the value of pi 2 already as 1 by 4 so  this again immediately gives me pi 1 as 1 minus 1 by 4 is 3 by 4 into 1 by 4 so  3 by 16 so  your pi 1 is 3 by 16 now  i have the values of pi 1 and pi 2 so  then from here i can immediately get pi 3 because bring this here so  this will be 3 by 4 pi 3  3 by 4 pi 3 and i substitute the values of pi 1 and pi 2 so  this will be 1 by 2 into 3 by 16 plus 1 by 2 into 1 by 4 ; that gives me 7 by 32 so  pi 3 will be when you multiply by 4 by 3 gives you 7 by 24 and then  once you have  you now have pi 2 pi 3 and pi 4 is on this side  when you bring it will be half pi 4 and so  again substituting for pi 2 and pi 3 you get these values and so  you get pi 4 so this was quick work you know this was certainly faster than computing  you know  second  third  fourth powers of p  which is a 4 by 4 matrix so  lot of multiplications if you start taking the different powers now  let us try to answer the questions  rate of breakdown so  rate of breakdown is a transition probability of transitioning from up to down ; that means  up means when your machines are working or anyone of the machines are working and then any one breakdown will mean there is a breakdown so  that means  you are transitioning from up 1 and 2 which are up states to their down states which are 3 and 4 so  that means  you want to say that if you are in state 1  so that is the probability into your transitioning from 1 to 3 or 1 to 4 so that is p 1 3 plus p 1 4 and if you are in state 2  then the transitioning from up to down is 2 3 plus 2 4  p 2 3 plus p 2 4 so  we have all these numbers or the probability of a rate of breakdown will be 9 by 3 2 because any one of the breakdowns  this means you are going from up to down so  any one breakdown or two breakdowns  whatever it is  the probability is 9 by 32 and that is your rate of breakdown now  you want to answer the second question  which is the average length of time  average length of time the process remains down when it goes down and the other one is the average length of time it is up when it goes up so both the things so  let us define u bar as the average time the system is up  and d bar as the average time the system is down then your rate of breakdown is … now we are  you know  redefining or talking in now so  then we will make the equations and try to find out u bar and d bar this is the idea so  rate of breakdown is 1 upon u bar plus d bar  because you know  see this is the average time it is up and the average time it is down so  one breakdown at the rate of 1 upon u bar plus d bar  because this is the total time when it is up and then down  average time so  therefore  1 upon this will give you the rate of breakdown  because one breakdown for this time  this much period  one breakdown for this much period  and therefore  the rate is 1 upon q bar plus t bar so  proportion of up time is then u bar upon u bar plus d bar and similarly  you will define the proportion of a down time as d bar upon u bar plus d bar now  let us try to find out so  the definition of u bar will be pi 1 plus pi 2 ; this is because … this is the … your are either in the state 1 or state 2 that is where it is up so  this is the probability of being in state 1 or state 2  and then so this is a proportion of time and this is your rate of breakdown 1 upon u bar plus d bar which we have already computed as this from here  this is your rate of breakdown ; so that is this and so this is a gives you your u bar  and then we compute d bar  and we will continue with the exercise  refer slide time  32  00  so  therefore  we saw that u bar will turn out to be 7 by 16 which is pi 1 plus pi 2 divided by u bar plus d bar which was your rate of breakdown so  that was 9 by 32 so  then we multiply and it will be 32 by 9 so  this is u bar comes out to be 14 by 9 ; that means  this is the average amount of time for which the system will be up and since u bar plus d bar is a 32 by 9  so to get d bar we will simply say d bar plus u bar minus u bar which is 14 by 9 so  that comes out to be 18 by 9  which is 2 units of time so  therefore  what we have been able to answer the three questions that were asked  the first was what is the rate of breakdown ? so  this is 9 by 32 or 28 percent of time the breakdowns occur and then  the breakdowns from the average last for 2 units of time ; so  that means  once the system is down then it will remain down for 2 units of time and the third question was the average amount of time for which it is up so  then there is average amount of time for 14 by 9 so  14 by 9 it is up  when the system is up so  it will remain up for 14 by 9 times now  the thing is certainly the system is not in a very satisfactory situation because your breakdowns on the average the breakdowns have remained for 2 units of time  whereas your actual production time is only 14 by 9 which is less than a 2 units of time so  certainly the system is not in a very healthy state and so  this again gives a warning to the manufacturer to do something about it  because the way the transition probabilities are given  this is what your conclusions are so  i hope you understand  see the way we computed this because we had to define u bar and d bar  and then of course  the other reason i took this example was that  you know  they were two states which were defining the up system and two states which were defining the down system  and therefore  we had to … these computations were not just straight forward so  i thought that will be a good example to discuss in this course so  once we have talked about these state probabilities pi i  s  which we were answering as to the  you know because this  and of course  we have also computed this so  for that means  number of transitions required to go from i to j  this was the answer  and then the pi i  s  gave you the … the pi i  s  gave you the long term probabilities of being  of the system occupying a particular state  and then all of course  we also said that this is a fraction of time that the system will be in state i so  pi i  s   i gave you these interpretations of pi i now  this other kind of questions that are needed which are now the first passage and first return probabilities so  this is also very important  because you want to know how long it will take to reach a certain state and so when you say how long will it take to reach a certain state … see the statement it means here that you know that will be the for the first time that you reached the state ; so that means  you are starting from a state i and then you are wanting to say that how long will it take for you to reach state j so obviously  the moment you reach state j you have answered that question so  therefore  this will be what you mean by this is that for the first time that you reach state j from i so  that is the understanding so  that means … now  for example  if n transactions occur before the state j is reached from state i so  suppose we want to just  you know  surmise or say that n transactions have taken place before state j is reached from state i  and then we want to know the probability that n transactions will be required for going from i to j  then you might say that would p i j raised to n be the answer  for this probability ? because p i j n also tells you the probability of transitioning from i to j in step one  but see now there is a difference  because you see  when you talked about p i j n then it does not say that you may reach j before … and a number of times before you finally reach j in n steps the various graphs that i drew for you earlier showed that you may  you know  like you had  you started from state 1 then you stay in state 1 and state 1  refer slide time  37  06  so  this was your  you know  transition probability from 1 to 1 in two steps or in three steps you stayed in state 1 so  here that is fine so  this was your p 1 1 3  p 1 1 3  of course  also included that you could go from here to here  remain here  and then come here  or you could stay here  then go here  and go here so  this is fine ; this particular path that you are taking  no you are not coming back to state 1 before so  starting from state 1  you are reaching here without going to state 1 before hand so  therefore  this is the kind of path you are looking for ; but whereas  when we were computing your p 1 1 3  we had all possible paths to reach from 1 to 1 in three steps ; that is what we were doing say  for example  if you consider p i j 4  then p i j 4  i could go to 4 in step two also ; that means  from i  i could go to j  as i said and then you could again go to j  and then j ; this would also be there then you will have i to j  and then  you could go to k  and then to j  and this way so  so many paths  but nobody is stopping you from … so  when compute the probability p i j 4  remember we said it includes all possible paths of going from i to j and so you could revisit j in between number of times because you have to  you have to enumerate all the possible paths so  therefore  this is not the answer what we are looking for so  we need to make some more definitions and some more terminology has to be introduced to compute these probabilities so  the first passage and first return probabilities we want to compute so  essentially what we were looking for is that for the first time i reach j from i so  in between i should not have touched state j  and when the first time it occurs i want to compute the probabilities of such and so  so what we will do is  we will make these definitions here so  again f i j n  i am defining as the first passage probability and so  i need to … i have written first passage here  but i will define it here so  first passage probability of going from state i to state j and remember x n was the state in which this system is at time n ; this is … we have been using this notation when we were describing the transition probabilities on the markov process so  now what are we asking for ? we are saying that f i j n is equal to the probability of x n equal to j  but x n minus 1 is not j  x n minus 2 is not j  and x 1 is not j ; it is only x naught ; x naught is … x naught is i so  starting from i in between all these n minus 1 transitions that take place you do not ever touch j  but it is only in the n th transition that you reach j so  probability of that is what we were defining by f i j n ; so  that means  probability of reaching j from i in n transitions for the first time so  if you look at f 1  f i j is 0 then f i j 0 is 0 because we can not transition ; then f i j 1 will be p i j  your … f i j 1 will be simply p i j so  now we want to compute f i j n ; that is probability of going from i to j for the first time in n steps  n transitions  for the first time so  we should not have visited j in between  less than n steps and so  this we will obtain by writing p i j n which is the total probability of going from i to j in n steps  all possible paths  which may imply or revisiting j number of times  and then finally  coming back to j so  p i j n minus in sigma k varying from 1 to n minus 1  you see  because you want to reach for the first time for y to j and n steps so  your k can be allow to vary from 1 to n minus 1 only  and then this will be f i j k so  for the first time you have visited from i to j in k steps  and then once you reach j  and then again you can go to many other states  come back to j or stay in j whatever it is in n minus k steps so  for example  if you look at p 1 1 3  then what we are saying is that you can  you know  continue staying here in state 1 for all the three transitions or you can go somewhere here  come back and then again revisit here  and whatever possible paths you can  or you can go this way  this way  this way so  many other paths you can think of so  we are ruling out all those paths so  we are subtracting ; so  that means  you have visited from i to j in k steps for the first time  and then  in the remaining n minus k you again from j go to other places or remain in j and then come back to j so  we subtract all these  then we get the probability that f i j  we subtract these from p i j n so  we get the probability that probability of visiting j from i for the first time in n steps and then we will see lot of applications and implications of these probabilities so  this is what we  how we write down the expression for f i j n so  let me … and of course  when j is equal to i  then f i i n would be the probability of going back to i from i for the first time so  you started from state i  and then when you for the first time you reach a state i again in n steps of going so  i should say from state in n transitions ; so  in n transitions so  this will be f i i n and that will be the probability of recurrence of i  state i  in n steps so  f i i n and i used the word recurrence earlier and i said we will define it later on  so that is it and we will  of course  be talking in detail about these first passage times and first return time so  first return probabilities is your recurrence probability  a probability of recurrence ; but here  of course  we are saying in terms of n transitions and then you would want to know the probability of ever returning to state i  and so  we will compute that also so  now the number of transitions to go from i to j for the first time so  transitioning from i to j for the first time is called the first passage time so  the number of transitions required to go from i to j for the first time we will define it as a first passage time and you can see that this is also a random variable because you do not know how many transitions you will require to go from i to j for the first time so  first passage time is a random variable  and if i is equal to j  then the first passage time is called the first recurrence time so  this will be when you want to come back to the same state  starting from your particular state you want to come to it for the first time  that will be your first recurrence time so  first passage times and first recurrence times are random variables ; and therefore  you can redefine this again f i j n is a probability that first passage time from  probability of first passage time from i to j in n steps ; that means  your random variables so  f i j n is the probability of the first recurrence of the first passage time equal to n so  f i j n will be because this is the time  first time return  for you go from i to j and when this value is equal to n you want to compute this  the probability of first passage time equal to n is your f i j n ; this is how we will define we will go through now a very interesting journey when we want to  you know  compute these f i j n and f i i n in fact  you would finally  want to talk about f i j ; so that means  that will be when for the first time you return from i  transition from i to j  so without the n because here this is transitioning the first passage time when it is equal to n that means the probability of the first passage time equal to n so  now you would want to then finally  compute your f i j and f i i so  we will continue with this discussion introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  28 first passage and first return prob classification of states so  we will continue our discussion with first passage and first return probabilities ; how to compute them and so on  refer slide time  00  14  so  i just recall quickly that f i j 0 will be 0  because there can not be any transition in 0 time ; then  f i j 1 that mean the first time  j is reached from i in one step  so that will simply be p i j so  the first step transition probabilities are the first-time transition probabilities also  and then for f i j n  we wrote down this formula through which we can recursively compute the f i j ’ s so  an f i j n will be p i j n minus sigma k varying from 1 to n ; f i j k into p j j n minus k and i had explained last time also that  we are … because p i j n simply gives you the probability of transitioning from i to j in n steps and in between you could number of times have visited state j so  all that is included here  because we were computing all possible paths from i to j so  that may include going to j and staying over j and so on ; and then  going from j to somewhere and then coming back to j and all that so  now  we will want to subtract those probabilities from p i j n to compute f i j n and so  this says that  here this is the first time in k steps you transition from i to j for the first time and then from j to j in n minus k so  this again will include … no  going from j and coming back to j  but in between also you can visit j any number times so  this p j j and minus k ; and here this is … you have already reached j in k steps and then all this is happening  because you are computing re-transitioning probabilities up to n therefore  we have to subtract so  these particular paths we are subtracting ; that means from i to j  suppose you have this ; and then  you go back here ; you come back to j ; then  again you go back and come back to j and so on so  n minus k steps you will be doing this ; but  in k steps  you reach j for the first time from i so  we have to subtract the possibility of traversing all such paths from this one to be able to compute the first passage probabilities and so  that is what we are doing so  i thought that  i will revisit this and explain it much better now  we can solve these iteratively from these equations given the initial conditions here but  then we need the p i j n ’ s are available for all n to compute this so  just look at this example again a job assignment problem ; we have p square is this ; and f 1 so  here i we are using the notation that  now  just as a p is a matrix of one-step transition probabilities ; p square is the matrix of two-step transition probabilities ; we will also denote the first time first passage transition probabilities by the matrix f 1 then  it will be f 2  f 3  and so on so  if you want to compute for example  f 1 2 1 ; no  what am i doing here ; this is f 2 1 2 so you want to compute the probability that a transition from 1 to 2 in two steps so  this will be by the formula p 1 2 2 minus f 1 2 1 p 2 2 see here the formula is … therefore  you reach … that means in one step  you will go from 1 to 2 and then you have to stay with 2  because there is only 1 step here and therefore  if you compute this  you get 3 by 16 so  now  what you see is that  you have to therefore  now using this formula  you can compute … you get the matrix f 2 so  you have to compute all two-step transition probabilities before you can compute other the three-step first passage transition probabilities and for computing f 3  you would need f 1  f 2 and p 3 also ; that means p  p 2  p 3  f 1  f 2 you will need to compute f 3 – elements of f 3 and so  this is lot of work and so  i will give you now an alternative method of computing these first passage probabilities without wanting to … also  without wanting the higher powers of p ; just the first transition matrix would be enough  refer slide time  05  02  so  the alternate way now  the alternate way is see the way we explain ; this is now  look at it as a one-step so  f i j n – i am writing as sigma k varying from 1 to n p i k so  one-step you transition right in the beginning ; you are starting from i so  suppose you go to k so  that probability is p i k and then  from k  the first-step transition probability … i mean first passage transition probability k to j in n minus 1 ; is it okay ? that means  k is varying from 1 to n so  for all possible states  you are starting from i and you may go to some other k ; and then  from k  you want to go to j for the first time so  here you will require n minus 1 so  if you have already computed f k j n minus 1  then you can compute f i j n by using the first-step transition probabilities and so  this is a neater and more efficient way of computing f i j n ’ s recursively so  the argument is okay because i have to move out from i to some this thing so  k should not be j obviously  because i have to visit j for the first time ; but  then in … that means i will definitely visit some other state from i to k in one-step since i want to visit j from i in n steps so  in the first step  i will definitely go somewhere  which is a state  which is different from j and then  i need f k j to n minus 1 so  from k to j  i should visit j from k for the first time in n minus 1 steps so  this is a neater way of computing the first passage probabilities and now  here we just need the one-step transition matrix p and of course  we are computing these f k j … – all of these before i compute f i j n and so  here again  i am just doing the same exercise so  if you want to compute f 2 3 2 ; so  then this will be simply p 2 1 so  remember the k does not have to be … so  k can not be 3 so  k can take the value 1 and 2 therefore  p 2 1 f 1 3 plus p 2 2 f 2 3 so  this is all and so  by taking the values because this is only p 1 3 ; so  this is p 2 1 p 1 3 plus p 2 2 p 2 3 and you can looking up the values in the matrix p  you get this now  look at f 3 1 2 ; f 3 1 2 – so  here j is 1 so  k can be 2 and 3 so  this will be p 3 2 into f 2 1 plus p 3 3 into f 3 1 and what is happening is that  what is p 3 2 ? p 3 2 is 1 by 4  but then what is f 2 1 ? f 2 1 is p 2 1 so  p 2 1 is 0 so  this is 0 then  p 3 3 is 0 into f 3 1 so  this is 0 but  then you remember if i have not drawn the diagram here ; but  if you remember  the path 3 2 1 does not exist  because you did not have the arrow from 2 to 1 in the job transition – this matrix  because this is 0 so  you do not have the arc from 2 to 1 therefore  this path does not exist so  anyway this is you can not transition from 3 to 1 in two steps first time first time  from 3 to … you can not reach from 3 to 1 for the first time in two steps in two time periods so  this is … so  this is definitely better way of computing f i j n so  now  once we know this  then let us talk about the mean first passage times so  remember n i j we have denoted as the number of transitions that you require for going from i to j for the first time so  then the mean first passage time will be expectation of the random variable n i j  which you will write as n varying from 1 to infinity and f i j n and when you put i equal to j  then it will be m i i  which will be the mean recurrence time and this we have said is equal to 1 by pi ; 1 by pi i so  the steady state probability of being in … so  this is a proportion of time being in state i over the long run so  1 by pi i would be the mean recurrence time so  that will be the time required for reaching on the average  this is a time that you will require for reaching from i to i for the first time now  to compute m i j ’ s  you would need the first passage time distributions so  you need to compute … you can not apply this formula  because you have to then have all f i j n so  again  we will look at a nicer way of computing mean recurrence time and mean first passage times  refer slide time  10  21  so  as we said that  to compute m i j by the formula  where you need all f i j n up to infinity  this is not practical so  let us now come out with another method for computing these first passage times so  you see we will condition on the state at step 1 so  see what happens is if you are computing the mean first passage time  then either the transition from i to j takes in one step so  then this is 1 into p i j ; remember you are computing the expected value of f i j n so  m i j – so  if it is one step  then probability of transitioning from i to j in one step  that is p i j so  1 into p i j so  either we will transition from i to j in one step  and therefore  1 into p i j or we go from i to k in the first step  since it has to be … either we transition from i to j in one step or from i  i go to some other state and then  from k  i will transition back to j and so  then it will be … once i do this  then the passage time becomes 1 plus m k j  because m k j is the mean time of going from k to j and so  1 plus  because one transition has already taken place so  the mean time of transitioning from k to j for the first time will be 1 plus m k j and into the probability of transitioning from i to k  where k is not equal to j so  this should be clear now  we just rewrite this expression  because here you are summing with respect to k and k is not equal to j so  p i j is missing  which is available from here so  when you add up p i j plus sigma p i k  k not equal to j so  this whole thing is the summing up the components of the i-th row of the first transition matrix this must be equal to 1  because from i  you have to transition to one of the states and therefore  this is 1 plus sigma m k j into p i k  k not equal to j and we can rewrite this as summation p i k into m k j  where k is not equal to j so  this is now again  as i said  the way we computed the formula for f i j n  this is also a simple way of computing m i j without really requiring to have the whole distribution for the first passage probabilities f i j n so  these are n equations and n unknowns ; that means  n unknowns means in the sense that  you are asking for this – m 2 j and so on  m n j so  you are asking for a first transition passage to j from anyone of the states 1  2 and n so  these are n variables  because i is varying from 1 to n in n unknowns ; n equations in n unknowns now … and similarly  we can also compute i i i ; can also be obtained this way so  the mean first recurrence times can be also obtained by solving corresponding set of equations here and let us just work out the formula this will be …  refer slide time  13  54  so  if you want to compute m 2 3  then m 2 3 will be 1 plus … and remember k is not equal to 3 so  k can take the value 1 and 2 so  it will be p 2 1 into m 1 3 plus p 2 2 into m 2 3 so  now  in order to compute m 2 3  i need m 1 3 so  i will write down the formula for m 1 3 so  m 1 3 will be … so  here again k is not equal to 3 so  this will be 1 plus p 1 1 m 1 3 plus p 1 2 into m 2 3 ; so  then two equations in two unknowns and we can … substituting the probabilities p 2 1  p 2 2  p 1 1 and p 1 2  i get these equations and so  it is not difficult  because from here you immediately get like half m 2 3 is 1 so  m 2 3 is 2 ; immediately you get it from here and then  once m 2 3 is 2  this is half so  this is 3 by 2 and when you bring this to this side  let us see ; m 2 3 is 2 so  this is 1 by 2 so  this is 1 by 2 and this is 3 by 2 and this you bring here so  this will be half m 1 3 is equal to 3 by 2 therefore  m 1 3 is 3 ; it is not just 3 by 2 ; m 1 3 is 3 ; yes  from here you can again substitute and make sure so  m 1 3 is 3 ; this is 3 by 2 and m 2 3 is 2 so  this is … what is the mistake ?  fl  this is equal to 1 plus m 1 3 – we are saying is coming out so  this is 3 by 2 plus  fl  and this is half so  this is 2 plus 1 3 so  m 1 3 therefore  that was the right solution so  this is m 1 3 is 3 so  working out always helps you  because you can find out … now  similarly  let us just look at the way we compute m 1 1 so  the first mean recurrence time for going from state 1 to 1 and here again k can not be equal to 1 so  it will be 1 plus p 1 2 m 2 1 plus p 1 3 m 3 1 and now  you need m 2 1 and m 3 1 so  three unknowns are there therefore  three equations  m 2 1 will be 1 plus … again  k is not equal to 1 so  p 2 2 m 2 1 plus p 2 3 m 3 1 and then  finally  when you write it down for m 3 1  it will be 1 plus p 3 2 m 2 1 plus p 3 3 m 3 and so  substituting for probabilities  i get these equations and again  in a very simple way  you can solve and you can check … let us see m 1 1 comes out to be 5 by 2 and if you remember the calculations for pi 1  pi 1 was 2 by 5 so  the steady state probability of being in state 1 was 2 by 5 so  the mean of first passage time will be 5 by 2 now  m 2 1 comes out to be 4 and m 3 1 is 2 so  i hope this is a right calculation  because let us see if you want to do it here  just verify see if m 2 1 is 4  then this side is 1 plus 2 and m 3 1 is 2 so  that is also 1 so  that is 4 this is coming out to be high  because remember there is no arc from 2 to 1 ; there is no direct arc from 2 to 1 so  you can of course  go from 2 to 3  then 3 to 1 for the first time  but … so  that is 2 but  then other paths when you go around  it will be so  the mean first passage time is coming out to be 4 and m 3 1 is 2 so  now  we will see … of course  see the thing is that  as i said when i have concluding the steady state probabilities and the mean first passage times  there are certain conditions under which these are valid and so  we now have to look at the situations  where these things may not be valid and in fact  i had said that  these may not even exist and so on so  we will now start looking at … so  right now  under certain conditions  which we have to specify and we will do it soon so  want to show you that  this will be true – all these ways of calculating the steady state probabilities and mean first passage time and mean recurrence times ; you will be doing it under certain conditions ; they are valid and when they are not valid  then we have other quantities to define those states so  we will talk about it  refer slide time  19  13  so  let us just recall what has been done so far see we said that  limit probability x n equal to j given that x naught is i is actually limit p x n equal to j and then  we defined this as pi j so  this was the tacit assumption that  this limit exists and that it is independent of the initial state and therefore  we said that  you can solve these pi j ’ s through the system of linear equations and that is what we did but  this was under the assumption that  this limit exists but  now  it is not really true that  this will always exist and this is what we need to now talk about and find out therefore  that means the linear equation method of solving the pi i 's depends on whether this limit exists and we said that  this limit is also independent of the starting state and therefore  we could write down the system of linear equations and say that  the solution exist under the condition that  sigma pi j is add up 1 then therefore  things were simple  life was easy therefore  we will now look at the conditions under which this limit exists second is that … and the recursive formula for f i j n that we wrote down – this formula is valid here we are not asking for any limits or anything  because the powers of p can be computed and then  therefore  through that  you can recursively compute your first passage probabilities so  that is valid but  here … and m i j again – because remember i am saying that  the m i i will be equal to 1 upon pi i so  there again the existence of pi i is assumed and even otherwise so  the linear equations for solving the m i j ’ s also needs to examined under what conditions this method will be valid so  let us start looking at examples and then we start talking about the conditions so  first suppose … so  now  you again consider the job assignment problem and you see that  the matrix p 2 had got all entries positive  refer slide time  21  36  in the first transition matrix  there were some zeros in the sense that  you were not able to go from 2 to 1 and you did not have a loop from 3 to 3 so  you had 0 entries but  when you took the square of the matrix  then all entries became positive and after that  p 3 was also … all entries were positive so  this implies that  there is a path from … remember because this is simply a transition probability in two steps from i to j so  if it is positive ; that means there is a path from each i to each j and in such a case  when you have a path from i to j and then you have also have a path from j to i  because p i j 2 is positive and p j i 2 is also positive since all entries are positive  you have this ; you have a path here again from j to i with positive probability ; after such a pair of states is said to communicate with each other so  they said to communicate and if all states communicate with each other ; and so  now  because p i j 2 is positive for all i j so  we conclude that all states for the job assignment problem communicate with each other and such a chain or such a markov chain or process is called ergodic and we will talk about this some more but  first let me say that so  now  what we will say is that  we will define a closed set as a set of states  which communicate with each other and for the job assignment problem  it turns out that  the closed set actually consists of all the states – 1  2 and 3 but  it is possible that you may have more than two closed sets or three closed sets ; whatever it is  all states may not form one closed set ; that means all states may not communicate with each other and now  let us look at this example here see this is the transition diagram so  you see that  1  2 and 3 – you can see that  they all communicate with each other ; there is a path from 1 to 3  from 3 to 2  3 to 1 and so on ; and there is a path from 4 to 5 and 5 to 4 but  there is no path from 1  2 and 3 to 4 and 5 and this you can … of course  see the thing is that  i have drawn this diagram with five states ; but  when the number of states is large  the transition diagram will be very big and it may not be again … same problem as i was talking about earlier let you know you can not possibly enumerate all possible paths when you have a large number of states … so  the recourse is to taking higher powers of p so  let us start and of course  here it is evident that  these two therefore  the two closed sets are 1  2 and 3 and 4 and 5 so  this chain is definitely not … all the states not form a closed set and … so  let us see let us start with p – the transition matrix so  you see there is no arc from 1 to 4 or 1 to 5 similarly  there is no arc from 2 to 4  2 to 5 and from 3 to this and same way  there is no arc from 4 to 1  4 to 2  4 to 3 and 5 to 1  5 to 2 and 5 to 3 there is no arc so  this is the zeroes and let us see when we take the second power ; that means p square  then these zeroes remain intact these probabilities change ; these zeroes may … like this 0 goes away but  this … and then  again when you take p 3  these zeroes do not go away and here it becomes … therefore  now  you can say that  among the states 1  2 and 3 – the closed set 1  2  3  now  you have path from each node to the other two nodes  because these are all positive so  they all communicate ; that means you need at least three transition steps to see that  there is a path from each of the nodes 1 to 3 to the other two and similarly  here this is of course  quite clear so  this is also … all the probabilities are positive here and therefore … and you see that  this structure will continue no matter what higher powers you take of p you will continue to have zeroes here and zeroes here therefore  this is a situation  where all the states do not form a single closed set and in fact  if you have more than one closed set  we call such a chain or a process reducible and if all states form a closed set – one single closed set  then it will be irreducible so  what we have been talking about so far has been irreducible chain ; and irreducible means that  all states will communicate with each other and therefore  it will also be ergodic but  again even this classification is not enough ; we need to do it further and so  continue the discussion  refer slide time  26  53  so  if a single state forms a class ; that means there is only one state in a class it is called absorbing  because obviously  the state is not communicating with any other states ; it is just communicating with itself so  then it is called absorbing ; that is … so  once the system enters in an absorbing state  it will not come out of it so  we will just look at the examples for all these – the kinds of states that we are talking about now  from the 5 by 5 matrix of the two closed sets  we just looked at this example in which you had two closed sets has formed by the states 1 2 3 and the states 4 and 5 remember there was no communication between the states 4 and 5 and 1  2 and 3  and vice versa so  these were two closed sets so  if you look at the submatrix – 3 by 3 submatrix ; see because otherwise it is all zeroes ; this is 3 … it was 0 and 0  because there was no communication from 4 to 5  refer slide time  28  06  so  in the submatrix  the entry 1 3 was by mistake written as 25 by 36 ; it should be 19 by 36  because all the rows – the elements of any row must add up for a transition matrix ; must add up to 1 and so  with 19 by 36  the numbers 1 by 6 plus 11 by 36 plus 19 by 36 add up to 1 so  make that correction and in p 3 also  the same correction has to be made  because this mistake got carried over from p 3  where it was by mistake written as 25 by 36 and not 19 by 36 so  you see that  the submatrix itself … now  the case that  we were talking about that  the matrix p n in the limit will converge to where the rows are all identical – whatever these numbers states k 1 so  this was a pi 1 to pi k and so on so  all rows were identical remember this is the case we had talked about but  now  you see it has no meaning here  because the rows … these zeroes will remain forever so  we can not say that  the rows will become identical in the sense that … these three rows will become identical maybe you can say but  then below here you have zeroes  because again 1  2  3  4 and 5 are not communicating with 1 and 2 and 3 so  you will have zeroes here and then you will have some positive entries here therefore  you can not say that  the rows will become identical these three rows will become identical ; that is what i want to show you that  if you … this is p 3 so  p 3 ; this is 1 by 6  5 by 24 and 1 by 8 so  supposedly  this number will go up a little and this number will also go up  because you need 6 by 24 is 1 by … so  you need 1 by 4 so  supposedly  you can see that  the numbers are close similarly  11 by 36  7 by 24 and 1 by 3 so  1 by 3 is 8 by 24 therefore  again the numbers are getting close and similarly  here so  you see … that means these three closed states – they themselves will satisfy the condition that  the steady state probabilities … you can compute the steady state probabilities ; and here it will not matter in which the system started but  to say that  all the rows of the 5 by 5 transition matrix will converge to the same values would not be valid now  again this is a big example i have taken from ravindran and phillips and solberg and so  this is 8 by 8 transition matrix ; and the diagram i have drawn on the other board and see i have written down this matrix though i am not making use of it right now but  it will be a good exercise for you people also to sit down and try to … if you can write it a small   refer slide time  31  16   i am sure from matlab and so on  if you feed this matrix  you can get a different powers of the matrix so  it is not too much of a problem getting higher powers and then  whatever i am saying  you can also conclude the same things by looking at higher powers of p  refer slide time  31  34  but  in any case  if we draw the transition diagram  it will look something like this and i am not writing down the probabilities  because they are here and anyway it will clutter up the diagram ; we just need to look at the connections and whatever i am concluding from that is enough ; i do not need the probabilities really  except that this p 6 6 is 1 so  fine so  now  if you just glance at this transition diagram  then you will see that  4  5  8 are connected ; 3  7 are connected ; and you may say that  2 and 6 are connected but  then when you go further  you see that  there is no arc from 6 to 2 and when you reach 6  then the probability of coming back to 6 is 1 so  this is a certain event ; so  that means once the system comes to state 6  it just stays there and so  6 is an absorbing state and this is not a closed set  because closed set 2 and 6 should communicate  and 6 and 2 communicates so  there is an arc from 2 to 6  but there is no arc from 6 to 2 so  this is not a closed set therefore  you have two closed sets  which are 4  5  8 and 3 and 7 ; that for sure  because you have an arc from 3 to 7 and 7 to 3 now  1 and 2 do not figure therefore  this is not a closed set so  states 1 and 2 do not figure in any of the closed sets and such states we define as transient  because see what will happen is that … so  first of all  they are transient and since you have more than one state – closed state in the system … therefore  this is a reducible system so  that is another thing now  thirdly  once the system enters a closed set so  for example  it enters state 5 or 4  then you see it will keep hopping amongst these states only ; there is no way of going out ; there is no arc  which is going out of 4  5 or 8 so  the system will then … for infinite number of times  go on hopping among the states 4  5 and 8 and such states we will call as recurrent  because they will keep occurring again and again so  the moment a system enters the closed set  then there is no way of going out  because if this communicated with any other states  then that will also form part of the … for example  if 4 communicated with 1  then this will become a closed set so  that is not true so  once you enter a closed set  you can not get out of it and similarly  here if you come to 3  then you will go on going from 3 to 7 or 7 to 3 ; that is all you will just go round and round or  because there is no loop here either  there is no loop here so  you will continue doing it and from here if you come to 2 and then you go to 6  then you just stay put in state 6 ; you do not get out of it so  first of all  now  after defining the recurrent state from transient state and an absorbing state  you have the closed sets what we want to say is that  each closed set if you look at  this itself behaves like now a reducible markov chain so  a subchain of the whole system  which is irreducible – ergodic in the sense that  if you just consider this and similarly  if you consider the chain consisting of sets 3 and 7  then they together form a irreducible chain and this is both of them – 3 and 7 communicate with each other and so  talk about … further classification is needed  refer slide time  35  31  so  now  i will give you another classification of these states in terms of first passage probabilities and that will also give you a good understanding and of course  another alternate way of determining whether the state is recurrent or transient or whatever it is so  now  let us define f i as the probability that  starting in state i  the process will sometimes return to state i for the first time  because f i i n was the probability that  it returns to state i from i for the first time in n steps – n transitions so  now  when we add up this from 1 to infinity  this will give us the probability of the system returning to – starting from i returning to i for the first time in any number of steps so  all possible therefore  this is will sometimes return to state i so  that is important so  this is a probability now  we say that  state i is recurrent if f i is 1 ; so  that means there is a positive probability or it is a certain event that  the system will sometimes return to the state i from which it started so  if f i is 1  then it is a certain event but  if f i is less than 1  then it is a transient state and the … so  now  you can interpret this as saying that  if f i is 1 ; that means the system will return so  starting from i  it will return to itself after sometime and then  because it is a markov process  memory less ; that means the past history is not to be considered ; then  you will again … so  the whole process starts fresh ; and then  you will again go to other states and so on  and then come back again to i so  every time you come back  the system starts fresh and since f i is 1 ; therefore  you will keep coming back to i infinite number of times therefore  the way to characterize this is recurrent state ; that means is that  once you come to i  then you will keep coming back to i an infinite number of times but  for a transient state  see what is happening is since f i is less than 1  1 minus f i is positive so  this is the probability that the system will not return to state i and so  if this is a positive probability  then we will say that  this event will also occur therefore  how you want to interpret this saying that  a transient state will be visited only a finite number of times and so  that will be the difference between a recurrent state and a transient state so  let us just interpret this now  you see if the system is in state i for exactly n periods ; starting in i and exactly for n periods  visit the state i again for n periods – n times ; then  the probability of that is f i raise to n minus 1  because f i is the probability of x returning to state i so  that into n minus 1 and again  these are independent probabilities so  that is why i am raising it to f i raise to n minus 1  because of the markov process  the markov property and then  it does not come back to itself so  for what … so  i am computing the probability that  exactly for n periods  it has visited state i starting from i ; i mean this is i am writing down the conditional probability of starting in state i and then visiting it for exactly n times – being in state for n times so  it has already started in state i so  now  it needs to revisit state i n minus 1 times so  this is the probability of revisiting state i n minus 1 – n times starting and then  1 minus f i is the probability that it will never come back after that now  this is … and for n greater than or equal to 1  this is now … this has the probabilities from a geometric distribution if you recall so  what we are saying is that  coming to itself is a failure and then not coming to itself is a success  remember so  you are asking for the probability in n trials ; you are asking for the … here this is the … the best way to say it is that  this is not coming to itself so  that happens once and then  this is coming back to itself n minus n times or  coming back to itself – it is n minus 1  because it is starting in i  but it has been in state i for exactly n periods  that is … so  there are two different things i am saying therefore  here you are saying revisiting itself n minus 1 times therefore  f i raise to n minus 1 now  when you want to compute the mean for this distribution  then it will be … that means n now varies from 1 to infinity and you compute the mean and it will be n times 1 minus f i into f i raise to n minus 1  refer slide time  40  52  and  here we can take 1 minus f i outside so  sigma n f i n minus 1 and this is a geometric distribution ; f i is less than 1 so  this is convergent ; and this is an arithmetico-geometric series and you should all know how to evaluate it ; we have done it right in the beginning of this course and so  the sum is 1 upon 1 minus f i whole square ; and so  multiplied by 1 minus f i so  this is this so  there is a finite ; this is the finite positive number ; that means the average of a … you see if it was to visit itself  infinite number of times  the mean will not be finite but  here it is the mean is finite ; so  that means  you can again interpret this as saying that  the state will not be revisited infinite number times ; only a finite number of times it will be revisited now  another way of characterizing a recurrent state ; so  you see that  we have been trying to talk about the same thing in different ways and that certainly helps you to understand other things better so  now  let us say define i n as 1 if x n is i ; that means if the n-th time the system is in state i and 0 otherwise so  this is an indicator variable and then  if you add up sigma i n from and to infinity  this will represent the number of periods that the process was in state i so  starting from time period 0 – the initial time  then this will count the number of times the system was occupying state i and now  if you want to compute this conditional expectation  that is  given x naught is i ; you want to compute sigma i n  n varying from 0 to infinity – the expectation so  i will exchange this summation sign ; that means if this thing is finite ; that means if this exists  then obviously  i can exchange the expectation so  this is also convergent ; that is all i need to interchange therefore  this is expected value of i n given x naught is i  which … but  i n is equal to 1 if x n is i therefore  this is probability x n equal to i into 1 when you … conditional probability of x n given  i given that x naught is i so  1 times ; that you will write down and  this by our definition  is p i i raise to n therefore  summation n varying from 0 to infinity p i i n so  you want to say that  sigma i n  n varying from 0 to infinity represents the number of periods that the process is in state i so  now  if … so  once you have computed this  then a proposition immediately follows a proposition says that  if state i is recurrent  that is  state i is recurrent if this is infinity  because this is the expected value and if the definition is that  the recurrent state will keep revisiting itself infinite number of times ; then  the expected value will also be infinite  refer slide time  44  18  therefore  this will be infinity and for transient  this has to be less than infinity ; so  another way of looking at it now  see interesting outcome from here is that  if the number of states is finite ; see that is important  is finite so  the number of states is finite ; then  all states of the process can not be transient – all states can not be transient and why ? because if a transient state can be visited only a finite number of times and you have finite states ; let us say the number of states are 1  2 and k ; you have k states now  this is a … if all are transient ; so  this can only be visited let us say t 1 number of times ; this can be visited only t 2 number of times  and this can be revisited only t k number of times and now  you take max of t 1  t 2 and t k ; take the maximum of this ; define this as capital t and then  now  when you consider the time t plus 1  t plus 2  what happens ? because all the transient states have already been visited ; you can not revisit  the process has to go on ; the process has to be in some state at time t plus 1  t plus 2 so  this is a contradiction  because if you have only finite number of states and all are transient  they will all get visited the finite number of times and after that  beyond that time period  the process is going on so  where does it go ? it has to transit to one of the states therefore  in a finite process  a finite process we mean finite number of states – all states can not be transient therefore  immediately  the question is asked if the number of states is not finite  then is this possible that  all states may be transient and yes so  we will also look at an example and we have already done  looked at such a process  but we did not really talk about this aspect of the process at that time so  yes  if there are number of states are infinite  then all the states maybe transient introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  29 random walk periodic and null states so  in the last lecture i had told you that it is a number of states are finite of markov process and then all states can not be transient  right we had argue rate out that if the system has to go on then because transient states will be visited only a finite number of times if they are finite number of states  then the process must come to an end in a finite number of times  but since the process has to go on  therefore if the number of states is finite  then all states can not be transient  but the argument does not hold when the number of states is in finite so  i said i will give you an example when the numbers of states are in finite  it is possible that all states of this process may be transient  right  refer slide time  01  04  this is what we want to talk about today  so giving you an example when all the states are transient now  random walk is very interesting and important process and i hope that after having you know read about  now you will be able to recognize situation processes  stochastic processes which follow behavior of it random walk so  this now a markov chain when the states space consist of the integers i mean varying from contain the value 0 plus minus 1 plus minus 2  and so on so  that means  i am numbering the states by minus 1 plus 1 plus 2 minus 2 0  and so on and so this can go on for a infinite number the number of states is not finite this is infinite states situation and then  the transition probabilities so  if you go forward ; that means  if you transition from state i to i plus 1  the probabilities is p and if your transition from i to i minus 1  then that means  if you go backwards  the probabilities is 1 minus p  and this is i varying from 0 to plus minus 1 plus so  therefore  the probabilities remain the same sensually it is going forward the probabilities is p and if you are going backward  then the probabilities is 1 minus p for some  any p varying between 0 and 1 so  therefore  for different values of p you will get different random walks this is the idea and diagrammatically if you look at the transition diagram  the transition diagram simply says that so  these forward probabilities are p and the backward probabilities are 1 minus p so  from minus 1  you can go forward and then  it will go to state and from 0 if you go backward  you will go transition to this state minus 1 and the corresponding 1 minus p and therefore  this process go on either side so  this is your transition diagram so  you see that from here that all states communicate because you can go anywhere by forward movements if you go from minus 1 to 2  you can go here and then  you can again come here so  any possible path is there  but you can transition from any state to any state so  all states communicate  ok so  therefore  either all states will be recurrent or all states will be transient because remember the recurrent states will form a class so  if they form a class  then within a class  all states must communicate with each other since  it is already true that all the states communicate therefore  all the states will either be  so they are all in one class so  they will either be recurrent or transient  ok so  here again remember i had defined for you recurrent state via the probabilities of first passage  first passage probabilities and remember we had said that if f i is equal to 1  then the state is a recurrent state because then there is positive there is the event that it will recur back to itself is a certain event  right and if f i is less than 1  then we had said that the state is a transient state and then  using an alternate characterization of a recurrent transient state  we had also said that if from here we had said that if p i summation  this will be summation p i i n n varying from 1 to infinity if this goes to infinity  then the state is recurrent and this is less than infinity then  this state i is transient so  this was another characterization so  that is what we will use here since  all states are behaving as exactly the same way because the probabilities are the same of going forward or backward so  it is enough if we consider sigma n varying from 1 to infinity p 0 0 n so  let me just look at the behavior of this expression and if i can show that this will be diversion series  then that means  it will go to infinity then  i can conclude that state 0 is recurrent and since  they are all the states from one single class  therefore every state is recurrent and if sigma n varying from 1 to infinity p 0 0 n is less than infinity  then 0 is a transient state which implies that all states are transient so  let us now start looking at this expression for example  if you look at p 0 0 n  then that means  this is wanting to know that 0  you starting from 0  you will be back in 0 in a n steps so  since you can see from here  from the red diagram that you can return back to 0 only in even number of steps  in even number of transition  right if i go here  then i can come back here so  2 if i go from here and here and then  i need another two steps backwards  right or if i go from here  then i go back here and then  in fact you can have any possible number of forwards and backwards  but they should so  if the number of transition if my n is odd  then i can not comeback from 0 if i start from 0  right so  coming back to itself requires even number of states and you can just try to draw number of paths  and you can see that you can go from here  here  then here  then you can come back here and again here and then  here so  all possible ways are thereof  but then you will require every time even number of steps  refer slide time  07  13  so  therefore  if you look at p 0 0 2 n minus 1  then this will always be 0  all right you can not transition to back to the state starting from 0 you can not comeback to 0 if odd number of steps so  those probabilities are 0 and for coming back  you need even number of steps then  you require exactly n forward transition and backward transition in any order right as i try to explain from the diagram so  this will be equal to  therefore from 2 n you chose n forward steps  forward transition and n backward transition so  therefore  the probabilities p 0 0 2 n will be like this  all right choose n from 2 n transition and then  p transition forward and 1 and 1  sorry n transition forward and n transition backward so  probabilities of backward are 1 minus p  probabilities of forward transition is p and this is 1 minus p now  let us just open up the expression here so  this is 2 n factorial n factorial n factorial p raise to n 1 minus p raise to n i will now use sterling ’ s approximation which i have already talked about in earlier lectures so  factorial can be approximated by sterling ’ s formula and so  this will be 2 n raise to 2 n plus half e raise to minus 2 n and then  under root  we left out the part p raise to n and 1 minus p raise to n so  this is and therefore  similarly n factorial can also be written by sterling ’ s approximation formula so  n raise to n plus half e raise to minus n and then  there will be 2 root 2 pi so  root 2 pi for both of them so  therefore  it will be 2 pi and raise to plus half e raise to minus n and now  we can cross out few things this and this gets canceled out and then  you can two raise to half we can cancel out from here and then  i will be left with root 2 pi  yeah and oh this is root  fl   so  root 2 pi was there because this is root 2 pi and this is 2 pi so  root 2 pi was left and then  that root 2 gets canceled by this root 2 here and then  you can just see this simplification here and this is n raise to half so  here this is n raise to 2 n that cancels out with this  right and then  there is n here and there is n half so  you are left with the root n so  this is root n root pi and then  you have 2 raise to 2 n which i bring inside here so  this is again 4 into p 1 minus p raise to n so  this is the simplification  right after using sterling ’ s approximation for the factorials i get  refer slide time  10  17  so  we saw that this series can be written approximated by the series and varying from 1 to infinity 4 p 1 minus p raise to n upon root pi n now  the terms i can breakup as sum of even terms and odd terms and here  even though i have written the index is n does not matter so  dummy index so  here it could have been m also  but the idea is that i am breaking up i am writing p 0 0 n instead of this  i am writing the odd i am adding up the odd terms and the even terms now  the odd terms do not contribute anything to this sum so  it is only the even part and so now  let us consider the case when p is equal to 1 by 2 so  in that case  this will become equal to 1  right so  this series will reduce to summation and varying from 1 to infinity 1 root by n which we know is a diversion series because the power root by of course is constant so  this will be n raise to half 1 upon n raise to half and we know that this series 1 upon n raise to p n varying from 1 to infinity is diversion for all values of p less than or equal to 1 this we already know so  therefore  this is a diversion series and therefore  since all the state  we will immediately conclude that all the states are recurrent because the time to return to this is infinity so  all states are that mean sigma n varying from 1 to infinity p 0 0 n so  this is recurrent and therefore  all other states are also recurrent  ok now  we have to consider the case when p is not equal to half  refer slide time  12  01  so  for p not equal to half  your 4 p into 1 minus p will be less than 1  remember because for p equal to half this  the maximum this as the maximum value for this term for you p into 1 minus p is for p equal to half so  for p less than half  it will be less than 1  right so  let me call this term as alpha let me denote it by alpha then  we will show that this series converges and simple you just apply the ratio test so  take the n plus 1 term divided by the nth term which will be you know the n plus yth term will be 4 p into 1 minus p raise to n plus 1 under root pi into n plus 1 and here you dividing by the n th term which is this so  you have this so  here you see you are left with 4 p into 1 minus p and then  this root n i bring in the denominator so  this will be 1 plus 1 by n raise to half and therefore  the limit of this ratio of the n plus 1th term and the nth term as n goes to infinity will be you see  this will go to 1 and therefore  it will just converse to 4 p into 1 minus p which is a number equal to alpha less than 1  whatever the value of p since  p is not equal to half  this number is will be equal to something less than 1  all right and yeah  so in that case we will conclude that all states are transient states  refer slide time  13  28  now  of course  i had told you that you can look up for whenever now that you know this random process which backward forward and of course  for the transient case  the probabilities of going forward is different from going backwards and for recurrent states  it was both the probabilities are the same so  now just on the lighter side  we know you can say that if there is a drunken man and he is trying to walk on along a straight line  then he will takes step forward then  he will take two steps backwards or he may take two steps forward and one step backward or something like this so  you know the wonderings of a drunken man you can sort of say that the process of the walking of a drunken man can be modeled as a random walk and of course  it will depend on the p then  value of p will depend on how drunk he is or something like that  ok so  that is one of the examples then  we may be we will come across some more in the process of this or otherwise  you can you know now be aware of such a process  ok then  we will continue with the classification on the states and after the transient states  they are also states which are periodic and null states which are both of which are not of much practical use and of course  there occurrence is also not that often so  now  you see we have talked as we said that the recurrent state  it is possible that recurrence state may have infinite mean recurrence time that is mathematically  this sum may not converge and remember for recurrence states even you wanted to find out the first passage time and so on we did it by finding the mean recurrence time  the m i j s and m i i and so  when we did this  then we assume that this is finite ; this series will converge  but it is possible mathematically that this series may not converge even though the series  this of course  this is your condition for state to be recurrent that is sigma f i i and n varying from 1 to infinity which is equal to sigma which is equal to f i that is the recurrence time probabilities of the state coming back to itself then  this is equal to 1 so  for recurrent state  these probabilities have to be 1 because coming back to a recurrence state is a certain event so  this series converges  but this series may not converge which is your mean recurrence time and this is such a state  we will define as a null state  ok so  not much is talked about it so  we will also not spend much  but we must complete the presentation of the states of the classification of the various states so  for the recurrence states where we assume that this is finite  because then we were solving for m i j s or m i i s  but there is possibility that this series may not converge  ok and this as i have already said these are a frail practical use and the probabilities of being in null state will also go to 0 so  therefore  we will not talk about such states  we will not spend much time on it  but just to complete the discussion  we have also considered the case when this may not converge so  this may not be finite  refer slide time  17  19  now  let us talk about periodic states so  consider the following transition may tricks and this is the corresponding transition diagram  and you can see immediately from here that from 1 you will either go to 3 or 2  4 right and also from 2  you will go to 3 and to 4 and then  again from 3  you may go to 1 or you may go to 2 and from 4  you may go to 1 and from 4  you may go to 2 so  that means  there are two classes you can immediately see because there is no communication between the states here  between among the states and states here  all right so  it is you can just i should not say classes exactly because these two are not communicating  but they are communicating to the so  you have communication between the states of this set and this set and vice versa  all right so  your system will alternate that means at any time  either the system will be occupying states 1 and 2 or it will occupying 3 or 4  right because once if you start in 1  then you will either be in 3 or 4 and then  if you are in 3  then you will either be in 2 or back to 1  all right so  you either communicate this way or you communicate this way so  your system alternates between these two classes and that you can see by these probabilities also  ok now  in fact  you can see from here that suppose from 1 i go to 3  then i can come back to this so  that will be in two transitions i can come back from 1 to itself or i can go from 1 to 3  then i can go from 3 to 2 and then  2 to 4 and then  4 to 1 so  that means  it will be then in case it will be four transitions that will be required to go from to start from 1 and come back to 1  right or look at the other thing if you may go to from 1  you may go to 4 and then  again you can come back so  again it will be two transitions  but if from 1 you go to 4 and then  you go to 2  then you will go to 2 to 3 and then  3 to 1 so  that means  you can recur back to state 1  either in two transitions for in four transitions and the same story true for state two that means  from 2 you can come back to itself  either in two transitions or in four and the same again what ? it is three and four  right from 3 you may go to 2 and then  come back  right or you may go to 2 and then  you may go to 4  then 4 to 1 and 1 to 3 so  all the states can be visited  re-visited either in two transitions or four transitions revisited i mean starting from that state  you will revisit either in two transitions or in or four transitions  right so  you can see there is a periodicity so  let us make a definition so  we will say that a state which occur at time periods m2  m3 m and so on and m is sum integer greater than 1 this is called a periodic state of period m  right so  therefore  using this definition you can say that all the states of this particular chain are periodic of period 2  all right a state for which no such m greater than 1 exist is called a periodic so  here of course  the understanding is that it will actually the word should have been a state which can occur a times period m 2 m so  that means  if you are starting from that particular state and then  it occurs again at period m2 m3 m  and then the period is m so  that part is understood here  right that you are starting from a particular state and then  if you can visit it at regular intervals of periods m  m  some integer which is greater than 1  then that state will be periodic so  in this case of course what is happening is that all the states are periodic so  this is one particular example  but of course you can have situation where you may have some recurrence states so  these are also recurrent  but not in that sense see here yeah so  we will just see that there will be no this thing there will be you can say that this series  in fact the periodic state you already know that you are going to visit it at a particular time the probabilities of visiting it at regular intervals are there it is positive probabilities  refer slide time  22  14  so  for periodic states we said that the coming back number of transition has to be a factor of some integer greater than 1 that means m 2 m 3 m and so on then  we will say that it is periodic state of period m now  of course  on the transition diagram if you can see that all walks starting from walks or paths  whatever we have been saying starting from i and returning to i are of length m 2 m and so on  where m is greater than 1 then  i is a periodic state and the period is m  right so  for example that we just considered  i showed you that any state you start from either 1 or 2 or 3 or 4  you can come back to them in either two transitions or four transitions or six transitions and so  we concluded that the period for each of the state was m  right now  if you can find a walk of length one  that means  if there is a loop for a state that means  you can come back to it one step or if you can find two walks which have relatively prime lengths that means  one step one walk may be of length m 1 and the other may be of m 2  and they are relatively prime they have nothing in common then  you can conclude immediately that the state is not periodic that means  it is periodic  right because if 2 there can be in two parts of length that is starting from that state and coming back to it  either in m 1 transition or m 2 transition and these are relative then  certainly there can not be anything common so  there can not be a period to that state  right or if there is a loop  then certainly it is not periodic state  right that is another way so  we are just trying to look at various ways in which you can characterize a periodic state and then  again if it turns out that your mth power  that means  the p m transition matrix raise to power m if this is greater than zero  that means  all components are all entries of this matrix are positive from some m  then no  refer slide time  24  17  so  actually it is not difficult to show that if you are p m s or components of the matrix p m are positive for some m  then it can be easily shown that your matrix p m plus 1 will also be positive that means all entries of the matrix p m plus 1 will be positive and this you can see immediately from here see p m plus 1 can be written as p into p m let alpha denote the minimum of p i j m greater than 0 and then  we are saying because for every element of p m is positive so  take the smallest and that smallest one  i am denoting by alpha and that will be positive  all right now  consider the ijth element of pm plus 1 so  that will be ith rho of p multiplied by the jth column of pm  right and so this is p i into p j m  right now  you see that when you multiply the ith rho with the jth column and replace each entry of the jth column by alpha because all other elements are bigger  right so  i am writing the small as possible number for each of the entrees of the jth column so  it will be p i 1 plus p i 2 plus p i n times alpha because since the rho ’ s add up to 1  so this will be equal to alpha so  therefore  the i j th entry of p i j of the matrix p m plus 1 is greater than equal to alpha which is also positive and this holds for any element i j of p m plus 1 so  therefore  matrix p m plus 1 is also positive now  since all the entries of pm are positive so  it seems that pick up any one  then p i i m is positive that means  there is a path of length m from state i to i and since  p m plus 1 is also positive  matrix p i i m plus 1 is also positive which implies that there is a path of length m plus 1 from i to i now  by a definition you see m and m plus 1 for any m integer  positive integer  there are c prime numbers so  we have shown that there are two paths from i to i of co-prime lengths and hence  by our definition  the state i can not be periodic it will by a definition  it will be periodic so  n says this is true for all i therefore  no state is periodic so  the proof was simple i asked you to do it on your own  but i realized that we can show it right here and figure it out think about it  refer slide time  27  10  now  of course  periodicity is a class property as we have shown that means  you will have just as we defined that all states in that class would be periodic and having the same period  right so  we can put together all states which are periodic of the same period  right now  consider this example that we looked at the transition diagram for four states  and we saw that everything i did not write down i think the probabilities or let us not so let us see given that matrix p then  you have p square if you now multiply p with itself  then you get this matrix  right so  your p was if we just wrote down in the last we said that 1 is going to 3 or 4 so  there were numbers here 1 by 3  2 by 3 and so on and you had positive numbers and you had positive numbers here these were zeros and then  when you take p square  the numbers  non-zero numbers shift here and the non-zero number from here shift here  right and each entry becomes half  right then  p 3 when you now take p 3 that is you multiply p 2 with that transition matrix p and then  you will get these entries will shift here and these entries will shift here so  this is how  refer slide time  28  50  so  i just want to go through powers of a transition matrix i am just trying to show you what is happening and then finally  when you take p4  the half will again shift here  ok equal to p square which you would expect because every state of system had period two so  therefore  after two iterations of two transitions  this will be the transition matrix will be the same so  p 2 will be p 4 will be equal to p 6 and so on  all right similarly  p 5 will be equal to p 3 and this is equal to p 3 this will not be equal to p that is true so  p 5 will be p 3 and then  all other powers will  all odd powers will continue to be the same because then you see p 3 tells you probabilities of going from 1 to 3 in three steps that is what will happen  right it will come back to itself and then  go back so  from here it can go to 3 and 4 and again in three steps so  either it happens you see you had 1 here and then  you have 3  right and you had 4 so  if come to 3 in one step and then  3 you can not go back to it you can not come back to from 1 to 3 you want to comeback in three steps so  you will either go here or you will go here  right to 2  right and then  you may come back to 2  3 so  it will take three steps to come from 1 to 3 so  starting from 1 if i want to come back to 3  then you will have to require three steps because in two steps  you can either starting from 1  you can either come back to 1 or 2 so  therefore  you will need odd number of steps to go from 1 to 3 or to 4 so  either in one step or in three steps  five steps and so on because even transition are reserved for coming back either to these things so  that means  within a class and that is why we said that this and this of course  they all had the same period  but here what we are saying is that you can go from 1 to 3 and then  3 to back or 1 to 4 and 4 to 1 and so on  ok so  this is what is happening and so  you see that p i i n so  if you see here the first matrix  your p i i  so 1 1 1 was 0 now  it is half and then  again in p 3  this number is 0 and similarly  all these numbers are 0 and all these numbers here in p 2 are half  right and then  in p 4 again  they are half and in p 5 when you again look at it  all the numbers  all these p i i will be 0 so  this limit does not exist  right so  limit p i i n n going infinity does not exist it actually oscillates between 0 and half so  therefore  this is for the first condition for this series will also not converge if you want to take this summation  but anyway these are not the first step transition probabilities so  all we are saying here is that limit p i n as n goes to infinity does not exist this limit so  this summation will also not exist this is not convergence series p i i n n varying from 1 to infinity  but will not be a conversion because the necessary condition for this series to converge is that the lth term must go to 0 as n goes to infinity so  here either limit does not exist so  therefore  i can not say anything about this series also  ok so  now after having looked at all possible states of markov process  the conclusion is that you know if the process is erotic  then of course  finite number of states  then the study state probabilities can be found by solving system of linear equations as we saw  right by solving this matrix equations pi equal pi p and sigma pi i i varying 1 to n is 1 with this condition because otherwise the solution here is not unique so  we saw that when you put this condition  you will be getting unique solution if your system is erotic  that is finite of number of states and all states are recurring  ok so  therefore  the system does not contain any transient periodic or null state so  this was one convenient way  but then we saw that there were other states also so  for transient and null states probabilities of being in that state is 0 and of course  periodic state also do not possess steady state probabilities  all right so  when the state possesses as study state probabilities  then we saw we can solve it by this linear equation adding this equation to it  but otherwise periodic as we have seen do not possess steady state probabilities for transient and null states  the probabilities of being in that state goes to 0 as the process continues for a longtime so  we have finally sort of completed this argument and said that when you know that the system is erotic and so on  then you can solve prostate  the state probabilities using system of linear equations we have methods how to classify and how to decide that the state is periodic and it is null or transient  ok now  the thing is that periodic and null states are not much of practical use and they do not or there occurrence is rare so  we will not talk about them  but transient state you know transient processes are there that means there are lots of practical situations where the process does not continue for a long time so  therefore  we call them to reduce markov processes and so  there transient in the sense that after a while the process comes to an end so  we would look at in more detail because there are situations where your processes are not supposed to continue for forever so  we will define them as reduces markov processes and we will talk  refer slide time  35  12  so  reducible markov chains  one or more absorbing state and number of transient states  right because we are saying that the process will not go on it will terminate after a short period of time so  therefore  there will be either one or more absorbing states and remaining will be transient states so  again by our discussion  we have seen that once you reach an absorbing state  you will not go out of that states so  the process will terminate or if you are in a transient state and the numbers of states are  then the number states are finite then  again after a finite period of time  the process will be over so  this is what we are talking about so  the interesting example and that is the gamblers ruin problem now  the idea is that the gambler at each play of the game has probabilities p of winning 1 rupee and probabilities q of losing 1 rupee so  there is a game why i will tell you ? why it is called gamblers ruin problem ? so  now  successive plays of the game  yeah it should be plays of the game are independent so  successive plays are independent that means  whatever the outcome of one play  the game goes on independent of what has happened and the gambler will quit playing when he wins rupees n so  he wants to make a fortune of rupees n he is hoping for that so  he will quit the moment he has earned n rupees so  we want to find out the probabilities that starting with rupees  i suppose he has this much money with him the gamblers fortune will reach rupees n before reaching 0  and that is what being by the ruin because if he allows the process to go on  then he will ultimately loose all the money and that will be the end of his playing gambling because then he can not bet anymore so  let us look at the transition diagram so  here what we are saying is that see with 0  he can not play because he has no money to bet so  he stays here  otherwise if he has rupee 1  then he can either loose that rupee and come back to state 0 or he will win and he will go to with probabilities p and then  he will go to 2 that means he will have 2 rupees so  the state is described by the amount of money he has  and that is how we are using these integers to describe the situation  right and then of course  again if he has 2 rupees  he bets and he loses that rupee then  he will again revert back to having rupee 1 and so that will be the state so  this is the diagram and finally  at n minus 1 when he has n minus  1 rupee  he will bet again and if he wins  he will get n rupees he will make his fortune so  we want to compute that and of course  what we are saying is that he will stop playing so  there was no one going back from here because he will just quit the game  right so  this is the whole idea so  this is now if you look at it  this is you know the duration of the processes is finite and you can see that this is an absorbing state and you may call this as an absorbing state  and all other state are transient  because the moment he has some money with him  he will bet and then he will either convey  he will either go back to 0 for example  here he will whether win and he will go to transient to this transition to this state or he loses and then  he transition here so  again this is an observing state and he loses he just looses all the money therefore  the game is over so  this is what we want to talk about and i will show the end of course the whole idea is to compute the probabilities that starting with rupees i  the gamblers fortune will reach rupees n and you can say that here of course so  the process here you can immediately see that this is the markov process because your transition and it just depends on where you are so  your transitioning to the next state just depends on where you are and it does not matter how you reached one  or how you reached two it just shows we can immediately conclude that this is the markov process and this is a short period duration that means  it will terminate if the gambler ends up with rupees n  otherwise of course or if he just loses everything and he is back here so  starting with rupees i  you want to find out the probabilities that the gambler will reach the fortune that we want to make so  the gamblers ruin problem i have to put as an exercise in exercise 10  which i will be discussing after some time so  i have after explaining the problem  i have now left it to work out the details and let us hope that you enjoy doing it  and you are able to compute the probabilities  but while discussing the exercise  i will also give some hints and try to show how to go about it introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  30 reducible markov chains  refer slide time  00  17  so  i will continue the discussion with the transient and absorbing probabilities that is your reducible markov chains now here for example  look at this transition diagram so  there are four steps and you see that from 1  you can either come back to 1 or go to 3 but then 3  once you reach 3  then probability of returning to itself is 1 so  therefore this is a certain event so  once the process from 1 goes to 3  the process will stop there similarly from 1 it can go to 2 and then from 2  if it transitions finally to 4 and 4 is the absorbing state and so your process will again stop here and similarly 2 ; so you can see that from 2 also you can go to 1 and 3 or 2 to itself and then 2 to 4 so  1 and 2  no  i am sorry  1 and 2 this should be 1 and 2 are transient and 3 and 4 are absorbing that you can immediately see just by  you know looking at the transition diagram at once and of course  you can see that over a short period 1 and 2 will be visited  because they are transient and so for a while  the process may go from 1 to 1 itself or from 1 to 2  then 2 to 1 that may go on for a while or 2 to 2  but then the moment  the process transitions to either 3 or 4  it stops so  therefore over a short period of time 1 and 2 will be visited but ultimately the process will either enter state 3 or 4 ; and then stay there so  the process will end and  so now using this  i want to talk about absorbing probabilities so for example  the questions that arise ; so i have just ; i have written the first question even though this is plural  we will talk about other questions after this so  which absorbing state will be entered ? of course  here again we will only talk in terms of probabilities ; which absorbing state or what is the probability now  just to point out the difference between the absorbing probabilities and the steady-state probabilities  you see  now just look at this example so  what i am saying is that we will answer this question by computing absorbing probabilities and  so before i start talking about the method for computing the absorbing probabilities  let me just give you a feeling what we are talking about see  here if you are in state 1  then the probability of transitioning to 3 seems higher than transitioning to 4 ; because  well  you might say that the one if it happens in one step  then this probability is half or then it can happen that  you know  you can go to itself and then transition so  that will be also then  that will be ; so this will be half plus half into 1 by 4 so  let us just compute this in two steps and then if you ; so transitioning  if you start in 1  then transitioning to t 3 ; let say in two steps so  half plus half into 1 by 4  but if you are in 2  so computing the transitioning ; so if you are transitioning from 2 to 3  then we can not do it in one step so  the two step transition probability will be ; so the path will be from 2 to 1 and 1 to 3 and so this would be 2 to 1 is 1 by 3 and 1 to 3 is half so  1 by 3 into half will be 1 by 6 so  this is the probability two step transition probability of going from 2 to 3 fine i mean  again the example that i am trying to take is  and so half plus half into 1 by 4 would be how much ? this will be 1 by 2 plus 1 by 8 which comes out to be 5 by 8 you are connected to 3 from 1 directly so  this is what we are trying to bring out through the computation of the absorbing probabilities that it looks like that transitioning from 1 to 3 ; the probability would be higher  if you are in state 1 and if you are in state 2  then the probability should come out to be lower than that so  in other words what we are trying to make a case for is that the absorbing probabilities are not independent of the starting probabilities ; that means the starting states whereas  the steady-state probabilities we saw so  unlike steady-state probabilities ergodic process  the absorbing probabilities depend on the starting states see  steady-states were independent of where the system started and therefore  we would compute  you know  simply pi equal to pi p and  it did not matter where the system was ; because remember all the rows of the matrix became identical but in the absorbing probabilities  it will depend on where you are starting and this is what we want to make sure like  this will ; now we will ultimately  when we compute the probabilities  we will show that the absorbing probabilities when you are in state 1 to 3 is higher than when you are in state 2 and similarly for 4 ; it will be higher when you are in 2 and then when you are in 1 so  we will show because here we will have to then let us say  i take three steps  four steps  four transitions  then i can show you that the numbers here when you are in state 1  transitioning to 3 will have a higher value than transitioning from 2 to 3 so  let us see it will come out  refer slide time  06  26  so  let me make these definitions a i j is the probability of reaching the absorbing state j from state i ; where i is a transient state you want to compute this now  of course one way is that you can use the first passage probability so  f i j ; that means  over the first time you are transitioning from i to j in n steps and then you sum it this up from n equal to 1 to infinity now  this is not computationally efficient right ; because we will have to compute all the higher powers of the transition matrix and then we want to compute the f i j n s so  an alternate method and  this should look familiar because we have already used this kind of argument so  now what we are saying is that if you want to compute a i j  then the transition either takes place in one step that means  in that case the probability is p i j so  this is the probability of transitioning from the transient state i to the absorbing state j so  then this is p i j plus or i transition from i to another transient state k so  that probability will be p i k and then a k j will be ultimately transitioning from the transient state k to the absorbing state j so  this will be ; this number with this probability and this is the probability of transitioning in one step from i to j so  this is the argument now  a complete set of linearly independent equations will be obtained  if the same argument will be applied to each transient state so that means  here i have done it for i so  whatever the number of transient states  from each of them i will try to find out this probability of transitioning to the absorbing state j and then i will have a complete set of linearly independent equations and we will then solve for the a i j s and then we will get the so  we will be able to answer the question that which absorbing state will be entered in the sense that you will say that a particular absorbing state will be entered with this much probability starting from the states this is the way we will be able to answer that question so  now let us just take the transition diagram so  we are considering this process and  if you write out the equations  when you see from one transition state 1  you want to go to absorbing state 3 then  if you write out these equations  it will be p 1 3 either  you do it in one step or you go to the transient state two ; p 1 2 and then a 2 3 or  you come back and follow the loop p 1 1 into a 1 3 so  this is your equation when you want to write down for a 1 3 similarly  you can write it down for a 2 3 so  this will be p 2 3 plus p 2 2 a 2 3 from 2  you can either transition to 3 in one step p 2 3 ; p 2 3 in our case will be 0 or  then you will have to go from 2 to 2 loop and again a 2 3 there will be a 2 3 so  you come back to itself and then a 2 3 ; the probability of transition from 2 to 3 then or you go from 2 to 1 and then you go to from 1 to 3 so  these are the two equations now if you substitute for the p i j s  we obtain these two equations and  you can see that here the variables are a 1 3 and a 2 3  right  because this is 0 as i said p 2 3  there is no arc from 2 to 3 so  you have two unknowns and two equations so  we should be able to solve for a 1 3 and a 2 3 here so  see if you look at these equations from here  if you bring a 1 3  here it will be 3 by 4 a 1 3 equal to half plus 1 by 4 a 2 3 and here because this is zero  so you bring a 2 3 here so  this will be 2 by 3 a 2 3 which is equal to 1 by 3 a 1 3  refer slide time  10  46  so  that immediately gives you 2 by 3 a 2 3 equal to 1 by 3 a 1 3 gives you a 2 3 is half a 1 3 and  now if i substitute for a 2 3 in terms of a 1 3 in the second equation  which is 3 by 4 a 1 3 is equal to half plus 1 by 4 into 1 by 2 a 1 3 so  then i get the equation for the value of a 1 3  which is 3 by 4 minus 1 by 8 a 1 3 is half ; that is 5 by 8 a 1 3 is half so  therefore i get the value of a 1 3 as 4 by 5 so  once my a 1 3 is known as 4 by 5  i can compute a 2 3 so  you know  even from here only one could have concluded what i was trying to show you  but of course  it what i needed at least 2 to 3 you know computations of three  four paths to get you to this that a 2 3 would be half less than a 1 3 the probability of reaching the absorbing state 3 from 2 is smaller than the probability of reaching 3 from 1 and  you know  maybe you can say that the intuitive feeling looking at the diagram because you have a direct connection here and here  you will need at least two transitions to come here so  therefore this was the feeling which you get now sort of validate by doing these computations so  therefore a 2 3 comes out to be 2 by 5 ; which is less than 4 by 5 and therefore  it is less than a 1 3 now  certainly a 1 3 plus a 2 3 will not be equal to 1 ; because we are not sure whether we will be ; yes  so a 1 3 plus a 2 3 yes because we do not know whether we will  from 1  we will definitely reach the absorbing state 3 you may also reach the absorbing state 4 so  therefore these two probabilities will not add up to 1  not necessarily but if you fix the initial state  then the system will enter one of the absorbing states if you fix the initial state  that means  if i simply say that my system is in state one  then of course a 1 3 plus a 1 4 will have to be 1 or  if my system is known to be in a state 2  then i must transition to either 3 or 4 ultimately so  therefore a 2 3 plus a 2 4 will have to be 1 so if you know this  then i can immediately compute because i have already computed a 1 3 and a 2 3 so  then a 1 4 will be 1 by 5 and a 2 4 will be 3 by 5 and  so here again the same thing gets validated that your a 1 4 is less than a 2 4 so  the probability of transitioning from 2 to 4 is higher than transitioning to 4 from 1 now  let me just make this 1 this is the whole idea now a 1 4 and a 2 4  i could have also obtained just as i wrote down the equations for a 1 3 and a 2 3 so  the same way i would write down the equations for a 1 4 and a 2 4 and i would compute them so  this is what now ; this is the method for computing the absorbing probabilities and  as we have seen that these probabilities will depend on where the system is and unlike these steady-state probabilities  which are independent of the starting state  refer slide time  14  30  now  let us just generalize this process if i now call the a as a matrix of these transition probabilities  then here your i will vary i mean  transition probabilities from transient states to absorbing states then i will be the rows of the matrix you know  these vary over the transient states and  j varies over the absorbing states so  the columns correspond to the absorbing states and this  so for example  in this case it is two by two so  in this case your matrix will be two by two and  you can see that if i wrote down the equations for a 1 4 and a 2 4 also  then i will have the matrix here corresponding to all these absorbing probabilities that i want to compute so  then in that case the system you would have been written as the matrix a and this will consist of  remember the r is the matrix consisting of transitioning from a transient state to absorbing state in one step you are writing so p i j s ; so therefore  r is a sub matrix of your transition matrix p  which has the same dimension as a and the rows  of course correspond to the transient state and the columns correspond to j because you are transitioning transient state to absorbing state in one step so  therefore r is exactly the sub matrix of p of the same dimension as a then  we wrote down q a so  remember this will consist of the transition probabilities from a transient state to another transient state ; because we were writing so  either from i to j you did in one step then  those probabilities are here or you go went from i to k another transient state and then from k  you went to j finally so i to k  this is transitioning from a transient state i to a transient state j k so  q will be that matrix and  since the columns here are transient states  so and the rows are transient states  so this matches so  this is compatible and this will be your system of a linear equations written in a matrix form when you want to compute the absorbing state probabilities so  let us see so here for example  if you bring to this side  it will be i minus q times a equal to r so  we continue with the computation through this matrix  we will look at the entries of what do we mean by so  in other words it will be i minus q a is r so  a will be i minus q inverse r and  i minus q inverse will exist  refer slide time  17  30  so  i minus q a is r so  this implies that a is i minus q inverse r so  you see  here a represents the probabilities of reaching an absorbing state from a transient state and  so when we setup the equation a valid one  then there must be a solution to this system so  that is what we are saying so  therefore i minus q ; and  it is a unique solution so  therefore i minus q inverse exist that is what we are trying to say so  i am giving the argument in this way normally  you try to first show analytically that the matrix is a non-singular and  hence the solution is exist but  here we know that the system will ultimately settle down into one of the absorbing states so  these probabilities are finite and therefore the solution exists and hence  i minus q must be invertible so  this is the whole idea so  the stars equation has a unique solution so  i minus q inverse must exist and  now we have interesting interpretations of the elements of i minus q inverse also and as i said  the question that keep arising ; we will go now answering them and then in between we will also look at the interpretation of the elements of i minus q inverse so  the second question that arises is how many times a transient state will be occupied before absorption occurs so  now the second question is how many times a transient state will be occupied before absorption occurs ; because obviously  this is  you are talking of a reducible markov chain and  so you want to know how many transitions on the average will go continue before absorption occurs and the system stops so  this is the question mark and  so for each particular transient state  we want to answer the ; answer this question so then and surely this is the random variable depending on the starting state how many times transient state will be occupied ? again  it is a random variable and it will depend on what is the starting state so  let us define e i j as a mean number to times that transient state j is occupied  given that initial state is i so  remember when computing your m i j  is which was your mean time for a transition from i to j in the ergodic case  then we also talked about the same thing while computing your f i j s and now and then the absorbing states  the probabilities of going from a transient to an absorbing state a i j s we were using the same argument which we will use here again to compute to right side write down your  you know the equations relating these various e i j s  which are mean number of times that the transient state j is occupied ; given that the initial state is i so here  this is of course a transient state i is a transient state again ; so i to j so  when i is not equal to j  then of course you will go to i to k and then k to j so  this will be the mean number of transitions that you need for transition from k to j and this is a probability of transitioning in one step to i to k  when i is not j and this summation will be over all transient k s so  this is one set of equations the other would be if i is equal to j  then you are computing e i i so  it will be one step you can go from i to i ; you transition from in one transition from i to i so  therefore the number of transitions is 1 plus  you would again transition from i to k  e k is transient and then from k to j ; so the mean number of times so  the same argument continues and  so in a matrix form these equations because now we have these relations for all i to j and this is from i to i so  the same dimension as q so  the relationship is that e is equal to i plus q e and so here now your e is actually nothing but i minus q inverse and  this is what i want to say that  you know  you can relate the elements of i minus q inverse and give them the meaning  refer slide time  22  04  and  let us just look at the entries of i minus q inverse for the example that we have ; we would discussing just with four states ; where two were transient and two were absorbing so  in that case your r was half and 0 and 0  1 by 3 this was  you know  going from one to one and this was going from three to three  sorry  two to two one and two were transient and three and four were absorbing and then q was the matrix of transitioning from transient state to a absorbing state so  the diagram ; you can just refer back to the diagram and  so this will be 1 by 4 and 1 by 4 ; that means from one transient state  you could go to 3 ; if the probability is 1 by 4 or you could go to ; sorry i will just repeat this q is basically from transient so  this is 1 and 2 and this is 1 and 2 i am sorry so  3 and 4 maybe  i will just again draw the figure so  this was 3 and this is 4 yeah and  so you had this you had a loop here  then you could come here and you could go there this was your diagram sorry so  i should you have been careful yes so  our q is a just the matrix consisting of whether rows and columns both correspond to a transient states and so in this case  this loop had probability 1 by 4 and then you could go from 1 to 2 also with probability 1 by 4 and from 2  you could go to itself with 1 by 3 and this was also and then you could go from 2 to 1  probability 1 by 3 so  you can just verify these numbers ok now  so i minus q will be this matrix and therefore  i minus q inverse will be 8 by 5  3 by 5  4 by 5 and 1 by 5 we can ; and then we also computed we made these computations so  you have matrix a  which is i minus q inverse times r is this matrix and  this agrees with our calculations that we had done 4 by 5 and 2 by 5 ; so we said that this is higher than this and then this is higher than this and these computations are all there so that is there  but now let us look at the elements of i minus q inverse so  look at e 2 1 for example ; because this is our matrix e so  e 2 1 is this ; 4 by 5 now  this is the mean number of times that state 1 will be occupied before absorption occurs  given that the initial state of the system was 2 so starting from 2  you want to find out the probability that you would be going on ; finally  going to an absorbing state and  but in the meantime the mean number of times that state 1 will be visited before absorption occurs so  that is 4 by 5 so now  you know it will be interesting you can just take up any physical process ; that  you know  can be modeled as this reducible markov chain  which has only transient states and absorbing states and then you can try to give meaning to these numbers and then if you add up now ; for example  e 1 j where  yes  this is mean number of total transitions before absorption occurs  given that the system was initially occupying state 1 so  now you want to compute these mean number of times  total transitions before because remember you computed 2 1 here then i could have also computed e 2 2 e 2 1 or for example  here if your starting state is 1  then you go to 3 or to 4 so  this is … so  we said that e 2 1 is 4 by 5 ; which is the mean number of times that state 1 will be occupied before absorption occurs  given that the initial state of the system was 2 so starting from 2  then i will occupy 1 ; on the average  4 by 5 times before absorption occurs and similarly  now if you add up e i j s  sorry  e 1 j over j which is again transient so  this will give you the ; that means  starting from state 1  and then both the transient states will be occupied before absorption occurs so  this will give you ; yes  so therefore  for example when this is 1  then in this example it will be e 1 1 plus e 1 2 so  mean number of times so  state 1 is occupied or state 2 is occupied  both are transient so  this total will give you the total transitions before mean number of total transitions before absorption occurs  given that the system was initially occupying state 1 so starting from state 1  how many mean number of transitions can occur before absorption occurs ? so  here this was a particular element which is 2 1 that means starting from 2  how many times will mean number of times 1 will be occupied before absorption occurs now  you are saying starting from 1  what is the total number of a mean number of a transactions or transitions which will occur before absorption occurs so  it will be e 1 1 plus e 1 2 ; because either 1 can be occupied or 2 can be occupied before transition  before absorption occurs so  that will be 11 by 5 and  in the case when you are starting from 2  then 2 1 plus e 2 2 ; that probability is 1  sorry  the mean number again  it is not probability it is a mean number of total transitions so when starting from 2  it will be 1 and this number is 11 by 5 so  starting from 2 ; that means  it is faster the absorption occurs faster ; mean number on the average that is what we are saying right  refer slide time  28  17   so see  the question that we have answered was that when we are starting from state 1 which is one of the transient states  how many transitions before absorption occurs ? so therefore  as when we were looking at the elements of i minus q inverse  so this is e 11 plus e 1 2 because either absorption will occur from state 1 or absorption will occur from state 2 so  therefore you add up the two elements i minus q inverse and this comes out to be 11 by 5 similarly  you can find out if you started from state 2  then how many transitions occur on the average before you transition  before you go to absorbing state ? so  that sum will be e 2 1 plus e 2 2 and therefore  so that was  you know  i thought i will just emphasize again the interpretations of the elements of the i minus q inverse ok now  a different question this is  suppose you specify an absorbing state and then you want to know how many transitions will occur before the specified absorbing state is occupied so  this is also because that will give you ideas to how long the process will continue and because once the absorption occurs before  once you occupy the absorbing state  then your process is over or  it will just continue to stay in that same situation ; ok  same state so  and of course  this question will arise if there are more than one absorbing states because otherwise if there was only one absorbing state  then you know that ultimately your process will reach that state and your process will stop or will come to an end so  if there are more than ; if there is only one absorbing state  the question can be answered by a mean first passage time so that means  you will ask the question that starting in state i in a transient state i  how many transitions on the average before you reach the state j ? j maybe in any states so  if it is there is only one absorbing state  you can find out your first mean first passage time f i j and  that will be the answer to your question but  if there are more than one absorbing states  then final transition will occur to only one of them but  you do not know it is not known to which one of them and therefore  the mean first passage time can be infinity in this case because we do not know to which absorbing state you will go so  and once you reached one absorbing state  the other one will not be visited ever and therefore  the first mean passage time will go to infinity so  therefore here when you have more than one absorbing state  then you need to compute ; make some computations to be able to answer this question that how many transitions will occur before this specified absorbing state is occupied so  what we will do is  in that case we will compute the conditional mean first passage time ; that means  given that you are in a particular state  then we want to know so  mean first ; given that passage has occurred to an absorbing state so  that is what you are saying ; here you are specifying the absorbing state and then you are so  the mean conditional ; the conditional mean first passage time is what we need to compute so  given that you are going to be occupying the absorbing state  let say j  then you so  here you were defining this m i j as the conditional mean passage time  mean first passage time it should be mean first passage time from i to j so  let m i j denote this number and this is different from of the m i j ; that means number of transitions required for going from i to j  when you are considering the ergodic process ; when all states for recurrence so  that m i j is different from this one so  here we are saying that this is the conditional mean first passage time from i to j so  you are occupying state i and you know that you want to transition to state j  which is an absorbing state  refer slide time  32  47  so  now here we will write the following equations so a i j  remember was your matrix that we had computed to compute the absorbing probabilities so  then a i j is the probability of transitioning from i to j i is the transient state  j is absorbing state  then m i j as we have said is conditional mean first passage time from i to j so  you are occupying state j  then this can occur either in one step so  1 into a i j  right  and then here it will be ; you may not transition to j right away so  you will transition to some k and p i k into a k j so  k will again be a absorbing state so  you are transitioning to p i k into a k j and k j ; right  so therefore  then the transition from k to j  absorbing probability from k to j and then m k j so  this is  you know  trying to write down the equations for m i j  so that we can have the system of equations and we can solve for these conditional mean first passage times so  is that ok so  here this is i to k ; that means  you may transition from i to another absorbing state  but then in that case and then no it has to be  sorry  if k is not ; k can not be in an absorbing state because you see  we can immediately see that the argument is not correct because if you are from i to k  then you can not transition from k to j because once you are in absorbing state  then it is done so  k is a transient state so  you are transitioning from i to k so  i is the transient state  k is a transient state and then you are finding out the absorbing probability of going to j and m k j will be the mean first passage time  right  conditional mean first passage time that means you want to go to j when you are in k ; so m k j into a k j into p i k so  this you sum up ; where k is so  i should not say that k is not equal to i so  we are saying that because we want to find the transition probability from i to j  where j is an absorbing state and  for the first time ; so first passage time  you are computing mean first passage time so  this will be that you transition from i to another transient state  then from that transient state your absorbing probability is a k j into m k j ; so the mean number of transitions that you will require or going from k to j and m k j so  this gives you an equation for relating the m i j s with the other mean first passage times to the absorbing state j this is so  if passage to state j is certain to occur  then of course  a k j will be 1 and  in fact all a i j s ; where j is fixed will be 1 so  in that case you see these equations will transform to because this will be 1  this is 1 and this is 1 so  then if you recall your equations for m i j s which you wrote down for the ergodic process  you will get the same equation ; mean first passage time that means  now you are considering that there is only one absorbing state and  so the mean first passage time equations will be valid here ok so the whole idea is  when you have more than one absorbing state  you want to see how to compute these conditional mean first passage times so  let us say that you ; now  in a example that we have been all along following the fourth state example in which 1 and 2 are transient and 3 and 4 are absorbing so  you consider the four state which is … and  you want to compute m 2 4 ; that means  you are in 2 and you want to find out the mean first passage time of going to 4 ; to absorbing state 4 so here if you look at this equation  let us just write it out so  it will be a 2 4 m 2 4 so now  2 can not be equal to so  when we will now make use of the conditional mean first passage times so  i am defining m i j as conditional mean first passage time from i to j  and i am defining the conditional mean first passage time this may be a general definition but in particular  now i want to say that suppose j is an absorbing state ; i want to talk about that only so  in that case i can write this as a i j m i j ; right because the transition probability or the absorbing probability from i to j is a i j and that into m i j  the mean ; a conditional mean first passage time then  either this transition occurs in one step or it will occur … ; that means  you will go from i to k where k i so  i need not write here k  essentially i mean that k is a transient state this is a transient state that is all i want to say so  then this will be ; you may transition to another state or 2 itself ; p i k  then a k j so  k can not be j that is all because j is an absorbing state so once i transition to j  then it is done i do not have to so  it will be p i k ; that means  i transition to another transient state from that transient state  i go to the absorbing state j so  the probability of that into the mean first passage time from k to j so  k is a transient state now if passage to state j is certain  then all these absorbing probabilities are 1 because no matter where you are  since you know that you are going go to j so  all these probabilities will be 1 and  in that case these equations will reduce to your ; you are computing the mean first passage times for an ergodic process  which we have done already so  same equation ; i mean  this will reduce to the equation for computing the mean first passage time for an ergodic process so  now let us see how we make use of these equations to compute your m i j s so  let us consist ; say for example  i want to compute m 2 4 so  that means the question here that we asked how many transitions will occur before the specified absorbing state is occupied so  of course i will compute m 2 4  then m 1 4 also  and the sum will tell me so that means your answer to that question it will be m 1 4 plus m 2 4 that will tell me the mean number of transitions that are required before i occupy state four this is what we want to compute so  let us just write down the equations here so  a 2 4 into m 2 4 this can be equal to a 2 4 which is actually 1 times a 2 4 plus  then from 2 i can transition to 1 which is the transient state  then a 1 4 into m 1 4 or i can transition from 2 to2 so p 2 2  then a 2 4 and m 2 4 so  this is clear similarly if i want to look at m 1 4  then it will be a 1 4 into m 1 4  then 1 into a 1 4 so  i will again transition from 1 to 4 and this will be a  so  this will be in one step and then i mean  the mean first passage time will be 1 plus p 1 1 p 1 4 m 1 4 plus p 1 2 a 2 4 and m 2 4 so here again  from 1 you can transition to itself or you can transition to 2 so  if you transition from 1  then again you want to compute a 1 4 and then this will be m 1 4 plus p 1 2 into a 2 4 m 2 4 so  this is the conditional mean first passage times that we are computing that if i am in 1  and then i can transition to 4 so  what is the conditional probability ? so  now substituting for p i j s i should not say p i j s substituting for a i j s and  so remember we had  for this thing  we had computed the matrix a and  if you look back at the matrix a  it is  the numbers are given to you so  a 1 4 ; for example  there are a 2 4 is 3 by 5  then this was 3 by 5 plus 1 by 3  your this was 1 ; this was 1  a 1 4 was 1 by 5  then 1 by 3 was p 2 1 anyway  you had the matrix this and you had the matrix ; the transition matrix p also the transition diagram so  looking at those if you can just revert back to a few frames earlier  then you have all these numbers and so by substituting there  i get these two equations and then solving them simply  easily gives me the answer that m 2 4 is 93 by 45 and m 1 4 is 153 by  it should be 45 only  by 43 so  as i were saying that now if you want to look at the m 1 4 plus m 2 4  then this is equal to 93 plus 153 by 45 and this will be 246 by 45 so  on the average the mean number of conditional ; that means if transitioning to four  so the number of transitions that will be required ; mean number would be 246 by 45 provided  you are transitioning to the absorbing state four so one can  you know  i have tried to look at these processes in a different ways and giving you interpretations and so you know given a physical process  there are lot of these kinds of questions because you want to know if one has to plan that one has to know  for example  these are reducible markov chain ; that means you know which the processes which will terminate in short time  then you want to have an idea about these numbers  so that you look at  you can plan accordingly and  let us hope that in future after having gone through this  you will be coming across such situations or such processes  where then you can look at them in a more meaningful way  refer slide time  44  23  so  i will now discuss exercise so  let us look at question one this is  a particle moves by the way  these questions i have taken from the book hillier and lieberman  reference to which will be given to you at the end of the course so  a particle moves on a circle through points that have been marked 0  1  2  3  4 in a clockwise order so  and the particle start at point zero ; so let us see i can just … so  here is a circle and you have 0  1  2  3 and 4 ; so this and  the idea is that you can either move from here to here or you can move backwards so at each step  the particle starts at point 0 at each step  it has probability 0.5 of moving the point clockwise so  the clockwise would mean this way or 0.5 of moving one point counter clockwise ; means either backwards or forwards and  both the probabilities are the same so you remember  this was your  we were looking at the random walk you were looking at the random walk and  when we said that probability is half  then we also showed that it will be an ergodic process ; because in that case  all these states will be recurrent so  the same situation now  let x n denote its location on the circle after step n x n is a markov chain so  we have already seen that this will be a markov chain because it will just depend on where you are  so that you know the probability of transitioning to a next step will just depend on where you are it will not depend on how you reach there so  this will be the markov chain now  construct the one step transition matrix you can do it so  it will be a five by five matrix then  determine the n-step transition matrix p n for n equal to 5  10  20  40 and 80 no  i have given up to 80  but that is because either you must be either familiar with matlab or by writing a small program of your own then  you can iteratively find out to the multiply to get the power of p raise to 5 p raise to 10 p raise to 20 and so on so  it is just to familiarize yourself then  determine the steady-state probabilities of state of the markov chain now you  so this is a little ; may become tedious because you are solving your five by five ; your transition matrix is five by five so  you will have five variables and five equations but since the values of p s are half  so therefore it should not be a difficult system to solve you should get the answer too quickly so  determine the steady-state probabilities of the state of the markov chain describe how the probabilities in the n-step transition matrices obtained in part  b   compare to these steady-state probabilities as n grows large so  want to show you see that  you should feel the … so  once you find out the steady-state probabilities and you also have ; you know p raise to 40 or 80  then you can see that in fact  at p n equal to 80 ; that means  when you have p raise to 80  then they should definitely be very close to your steady-state probabilities and in fact  you can see the pattern even when you compute the 40  refer slide time  48  10  now  question 2 is just to determine the period of each of the states in the markov chain that has the … yes so  here you have again a five by five matrix and i am asking you to determine the period of each of the states in the markov chain that has the following transition matrix so  this will be ; all the states are periodic well  you just find out so  you have to then determine the period that means you will have to compute p square  p cube and  here also you can make use of the same program that you wrote for p and then you can compute p square  p cube and so on to determine the periods of the periodic states yes  refer slide time  48  46  now question three ; a transition matrix p is said to be doubly stochastic if the sum over each column equals 1 so  you know for the transition matrix that we have seen  the row must add up to 1 so  now i am giving you an additional condition and that is  that the columns also add up to 1 so  therefore p i j as i varies from 0 to m is also 1 so  column sums are 1 in that case  such a chain is irreducible  aperiodic and consists of m plus 1 states states are already m plus 1 ; show that your steady-state probabilities in such a case  you do not have to do any computations just right away you will be able to show that your pi j s are 1 upon m plus 1 ; where j varying from 0 to m so  this is simply  you can do it or write down if you think and then make out your … so  this is now  oh  this is ok now question four ; a computer is inspected at the end of every hour it is found to be either working it means up or failed down if the computer is found to be up  the probability of its remaining up for the next hour is 0.9 ; if it is down  the computer is repaired  which may require more than one hour whenever the computer is down  regardless of how long it has been down  the probability of its still being down one hour later is 0.35 so  that means your unit of time is one hour and then you have to write down your transition matrix so  construct the one step transition matrix for this markov chain and find the mu i j  the expected first passage time from state i to state j ; for all i and j so this  you will be able to do so  here i have asked you to ; now this sort of question depends on computing the first passage times  which we have also discussed quite thoroughly  refer slide time  50  50  now  question five ; which i told you in the lecture this is  you know based on the gambler 's ruin problem and  so i thought that i leave the computations to you i just explain to you how  what the problem is now  here gambler bets ; there should have been a space between so  now this is a gambler bets dollar here it is dollar 1 on each play of a game because this is the game from hillier and lieberman each time he has a probability p of winning and probability q which is 1 minus p of losing the dollar bet he will continue to play until he goes broke or nets a fortune of t dollars now  let x n denote the number of dollars possessed by the gambler after the nth play of the game then  you want to find out ; x n plus 1 will be x n plus 1 with probability p ; right  because he has 1 more rupee if he wins and that is with probability p  otherwise he will have x n minus 1 with probability q which is 1 minus p now  here of course he continues playing  only if x n is less than t and  x n plus 1 will be x n for x n 0 or t right because if he has no money  then he can not play and therefore  he can not bet and  so he continues to be at the same state that means  he continues to be broke and if he has t dollars  he has earned t dollars ; then again he does not play because he has earned his fortune now x n is a markov chain we have already discussed this the gambler starts with x naught dollars ; where x naught is a positive integer less than t because i said ; we can say that x naught is i construct the one-step transition matrix of the markov chain so this  you will have to write down and  you could see that it will only be one step forward or one step backward the other entries will be zeroes now  find the classes of the markov chain this  i have already told you let t equal to 3 and p equal to 0.3 so  if it is a question of earning up to 3 dollars  so that means  your states will be 0  1  2 and 3 so  then i have asked you to find out the first passage probabilities f 1 0  f 1 t  f 2 0 and f 2 t ; and then again the same things  when p is 0.7 so  it will be not be difficult at all if you write down see  again the computations  the formulae are given to you for the first passage probabilities and  so once you write down the transition matrix  you should be able to complete the problem so  in the lecture i had told you that i will be asking to you to compute the probability that the gambler will end up with a rupees t or  in the lecture  it was i think rupees n or dollars n  whatever it is  that does not matter that means  the gambler with what is the probability that he will earn the fortune that he is wanting to so  that has not been asked in this question five but you see  you should be able to set up equations so  essentially it is just to define the probability p i p i minus one  refer slide time  54  08  you can interpret the same way and then it will be p i is equal to p p i plus 1 plus q p i minus 1 and then you multiply p i by p plus q ; because p plus q is 1 and then from this equation you have an iterative relationship for different values of i and then you can find out the iterative relation and then you will be able to find out the probability p i and there  of course you will use the fact that if you have 0 dollars  then the probability of making your fortune is 0 and  if you have earned t dollars  then your p t is 1 so  using this initial at boundary conditions  you will be able to solve for p i so  please do that ; because in the problem i have not asked you to do it but  you can certainly do it  refer slide time  55  02  now  question six question six is which is again a simple one a leading brewery on the west coast  labeled a  has hired an or analyst to analyze its market position if it is particularly concerned about its major competitor  let us say labeled b so  another brewery which is their competitor for this brewery a and so  they want to find out how could a competitor or how bad a competitor  this other brewery is so  analyst believes that brand switching can be modeled as a markov chain using three states with state a and b representing customers drinking beer produced from the aforementioned breweries and state c representing all other brands so  you know state a will represent ; so that means a to a in this transition matrix that is given below so  see this probability of a ; that means  somebody who is taking  using the  you know  beer from brewery a will continue to do that  use the brewery a only is 0.7  but may switch to b with probability 0.2 or to other brands with probability 0.1 similarly  you can explain the row b entries  right  and then c for other brands  when they switch to a will be 0.1 and 0.2  0.1 again to b and 0.8 ; that means  they continue with the same brand that they are already using is 0.8 ; so that point is missing here anyway  just you can make the entry ; so 0.8 now  what are the steady-state market shares for the two major breweries ? so  we want you to find out pi 1  pi 2 and pi 3 so  the answers that they are asking for is pi 1 and pi 2 so  what are the steady-state market shares for the two major ; that means  when the process has gone on for some times  you think that the choices have all stabilized then  you want to know the steady-state market shares for the two major breweries introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  31 time reversible markov chains  refer slide time  00  15  so  today we are going to look at interesting phenomena related with markov chain and that is you know time reversible markov chains so  let us just first start looking at what we mean by all these so  suppose you have given this transition matrix p i j and you have given the stationary state probabilities so  this is let us assume that the   refer time  00  38   p i s are all positive  because if this  if pi i is 0 then surely we can drop that state from the process  because it is not of any interest so  this is the ergodic process and the pi i s are all there stationary probabilities and the system is gone on for some time so  we are looking at the stationary part of the thing so now consider the sequence in the reverse order so  this is x n  x n minus 1  x n minus 2  and so on so  at this point of time you are looking backwards at the process right now  we will show that this is also a markov process so  this is the interesting part that is when you markov process is going on and you at some point you want to look backwards  and then you will see the transitions and so on so  there also the sequence will follow will have the markov property and so it will also be a markov chain or a markov process so now how do we show this ? to show this  i have to show that  you know if suppose the current time is m plus 1 then you are occupying state i or the system is occupying state i and then you want to look at the probability that in the time period just before ; that means  today and yesterday so  it was x m is equal to j so  you want to look at the probability  conditional probability so  therefore  for if you are looking at like you are today and you are looking at yesterdays situation then all these days ahead ; that means  x m plus 2  x m plus 3 and so on  all these so  the conditional probability of you know having the history future history and then x m plus 1 is i and you are wanting to know the probability of x m equal to j so  this would be when you are at time m plus 1 and you are looking backwards so  if you are looking at this thing then this is all past for when you looking backwards right so  therefore  this conditional probability should be equal to x m equal to j given x m plus 1 equal to i ; that means  it will just depend on the current situation or the current state being occupied by the process and then so this probability should be you know here all these sates occupied in the past because now we are looking backwards so  all the states occupied in the past do not matter it is so  only the current state that is occupied by the system and then so this is what you want to prove if i show this then it would imply that the backward process at any time the backward process will also be a markov process right so  present time is m plus 1 and we know that we have given that x naught x 1  x 2 this is the markov chain and as i said and the corresponding transition probabilities are p i j s and the pi i s are the stationary probabilities now  the conditional distribution of x m plus 2  x m plus 3 and so on given the present state that is given the present state x m plus 1 then the markov property tells us that the conditional probabilities of x m plus 2  x m plus 3 and so on  do not depend on x m right  because the conditional probability of the whatever state is being occupied at time m plus 2 is dependent on this right and then of course  x m plus 2 will be  x m plus 3 will be dependent on x m plus 2 and so on so  because this is the markov process  we know that the present state x m plus 1 is independent of no no  so this is conditional distribution of x m plus 2 x m plus 3 and so on given the present state x m plus 1 is independent of x m the past right and all things before hand x m minus 1 x m minus 2 right so  the conditional distribution of x m plus 2 or x m plus 3 and so on so  conditional distribution of x m plus 2 would depend on the present state which is x m plus 1 and will be independent of x m similarly  conditional distribution of x m plus 3 will depend on the state being occupied at time m plus 2 and so it will be independent of m plus 1 and x m and so on right now  we know that independence is the symmetric relation you say that x i and x j are independent ; that means  x j and x i are also independent so  it is a symmetric relationship right so  therefore  given that x m plus 1  x m given so ; that means  when you given x m plus 1  x m is independent of x m plus 2  x m plus 3 and so on so  then i can say the reverse also right see we just now said that given x m plus 1  x m is independent of x m plus 2  x m plus 3 and so on this is what we want to say  because x m plus 2 is independent of x m  x m plus 3 is independent of x m so therefore  the reverse  because this is the symmetric relationship so  i can say that x m given x m plus 1  x m is independent of x m plus 2  x m plus 3 and so on and therefore  this probability can be written as probability x m equal to j and x m plus 1 equal to i and so we immediately conclude that the backward process is also a markov process and now  we want to look at another special case of this so  therefore forward or backward markov process as this property  refer slide time  06  29  now  let us define these backward or the reverse probabilities right so  i will say that let q i j be equal to probability of x m is equal to j given that x m plus 1 is equal to i right so  i am defining the backward or the reverse transition probability so  this is present currently u r and i and so we are occupying state position j just 1 period before and ss  this conditional probability  i can write as by the conditional probability formula i can write this as x m equal to j comma x m plus 1 equal to i divided by the probability of x m plus 1 equal to i right and then again this product probability  i can write conditional as a conditional probability x m plus 1 equal to i given x m equal to j into probability x m equal to j divided by probability x m plus 1 equal to i and this  because we already have the transition probabilities for our forward process and this and the stationary probabilities pi i so  this can be written as p j i because j i right so  p j i into pi j probability x m equal j and divided by probability i that is being state i at time m plus 1 the stationary probability so ; that means  given the transition probabilities and the stationary probabilities  i can always compute the q i j s which are reverse transition probabilities so  we can compute the q i j s right and so therefore  now  i can say that this is the backward process is also a markov process and the conditional the transition probabilities the reverse transition probabilities are also available given the regular markov process then the backward process i can and once you specify the transition matrix the reverse transition probabilities the process is completely determined right ok now  the special case and the special case is in case q i j is p i j incase the reverse probabilities are the same as the forward probabilities transition probabilities so  if q i j is p i j then you see this equation q i j equal to p j i into pi j upon pi i this reduces to see you write here p i j so  it will be p i j so  p i j into pi i is equal to pi j into p j i right now  if you look at the left hand side this says so  you this is the probability of being state i and then this is the probability of transitioning from i to j so  this is the rate at which the process transitions from i to j right and in our case this is the  you know because i am assuming that currently i am in i  state i transitioning backwards to state j so  this is your probabilities the rate at which you transitioning from i to j in the backward way and this pi j p j i so  this is the probability of being in state j and then you are transitioning from j to i right so  therefore  this is your x m equal to j and then transitioning to i so  forward probability so  this is the rate at which the process transitions from j to i so therefore  now  you say that this markov chain is said to be time reversible markov chain with respect to time  because the forward transition rate and the backward transition rate are exactly the same and so now  you can see that you know  it is something like saying that  if you play a tape then you will not be able to differentiate whether it is playing backwards or forwards this is the idea right if the tape is the you know  has captured the process of a markov chain  which has the time reversible property then whether you play the tape forward or backwards it will exactly look like this it will look exactly the same you will not be able to make a difference  because the rate of transitioning backwards and forwards is the same right and this is the necessary condition for time reversibility so  once you have ; that means  if you have a set of transition probabilities and a set of probabilities state probabilities  which we will show our stationary probabilities then and they satisfy this equation for all i j then you see this system the markov process has the property of time reversibility so  this is what we are trying to say right so  and again it just maybe it is a matter of again repeating that we are saying that you are see here this is i or this we are saying is j and this is i so  then you are going backwards or you are coming this way right when you are here you are looking backwards so  then the transition the rate at which you transition is exactly the same as  if you are here and then you are transition to i right so  this is what essentially pictorially also this is what this equation says so  this is a necessary condition and therefore  now we will show that the converse of this is also true and then you know we look at some examples of time or how exactly and of course  the other advantage that we will show that reversible markov chain  time reversible markov chains posses ok  refer slide time  12  37  so  now suppose p i j s are given and s is vector of probabilities such that this condition is satisfied which is your necessary condition for so  we are looking at the converse what we are saying is that suppose you have a transition matrix and you have a vector of probabilities such that this condition the time reversibility condition is satisfied ; that means  the process that we have given the markov process is the time reversible markov process then so the process is reversible markov chain then s is the vector of stationary probabilities so  therefore  what we are saying is that in case you have a probability vector which satisfies the reversibility equations with corresponding to the p i j s  which are your transition probabilities then the s i s can be nothing else  but the stationary probabilities  stationary state probabilities so  this is a convenient way of  because … so  now we know that of course  we said that the conditional ; that means  we said that the  if s i s were stationary probabilities and these were transition probabilities and these conditions were satisfied then we defined reversible markov process so  now we are saying talking about the converse that  if any probability vector along with this given transition probabilities for a markov process satisfy these time reversibility equations then s has to be nothing but the state probability vector this is want to say so  suppose i start from here and then i sum up these equations with respect to i so  this is sigma  sigma with respect to i s i p i j is equal to summation  summation respect to i s j p j i now  since s j is independent of i so  i take s j outside and this will be summation p j i over i right  but then these being transition probabilities and you are summing up the probabilities of rho j right p j i s with respect i so  you are summing up the elements of a rho and that must add up to 1  because these are elements of a transition matrix and therefore  this is equal to s j right and so when you write down for all j this is satisfied so  this gives you the matrix equation that s  s is equal to s p and therefore  s is the  because remember we said that when you do this and you have the condition that components of s add up to 1 then you have a unique solution and that unique solution is the vector of state stationary probabilities so  therefore  we now know that any system if we can find a vector s and we have the transition probabilities for a markov process satisfying this then s must represent the stationary probability vector so  knowing this now of course  the question is we will certainly want to look some examples of reversible markov chains and then will show you that through these examples that we know computing the state probabilities becomes very easy and so you do not have to work out  you know apply matrix methods  iterative methods to solve for s  because given this you want to know this state probabilities then you have to remember we solved system of linear equations  but when the process when the number of states is very large then it will be very tedious to have to solve these equations so  now through examples we want to show you  but computing these state probabilities is very simple and of course  the process we also look at these examples so  the idea is that now here  let us look at an undirected graph with 4  5 nodes right and the links connecting and arcs connecting them now  what i am doing is that  i am writing probabilities ; that means  transition from 1 to 2  1 to 3 these are the two edges so  i am giving them equal probabilities right and that is it is called random walk  because you can wonder around this graph and what we are saying is that if for example 2  2 has four edges incident on it when it can  you can traverse any of the edges with equal likely i mean traversing or picking up an edge to go along is equally likely and therefore  i am giving probabilities like p 2 1  p 2 3  p 2 4 and p 2 5 equal to 1 by 4 so ; that means  when you are at node 2 traversing the edge to 1 2 3 or 2 4 or 2 5 is equally likely so  therefore  these are the probabilities right and then similarly p 3 1 is equal to p 3 2 is equal to half and p 4 2 is 1 and p 5 2 is 1 so  here from here you have no choice you have to go to 2 only and from 5 also you can go to 2 now  let me define d i as the degree of node i right  so that means for example  for this the degree is 2 for this the degree is 4 for this is 2 this is 1 and this is 1 and then by the definition  because of these definition you see that immediately since p i j is simply suppose you are at node 1 then your p i j is 1 by 2  because 2 nodes are incident so  this is equal to 1 by d i since we are saying that equally likely so  d i into 1 by d i similarly d j into so for example  if you are looking at 1 2 then here suppose i is 1 and j is 2 then this is half and d 1 is 2 so  this becomes 1 and then when you are here d j is the degree is 4  4 into p j i 2 1 is 1 by 4 and therefore  the product is 1 here again so  this holds for all i j right and so now  looking at this necessary conditions being satisfied so ; that means  it is a random walk where you know you can go from at any node you can traverse any edge and go on wondering around this graph that will be  so i mean what we are saying is that this is the markov process and its time reversible because it does not matter the process has gone on so  where ever you are then again you start traversing and or you look back to your this thing to your traversals before this so  it will be the same process there is no change right  because the i mean we interpreted this with the rate of going forward and the rate of going backwards is exactly the same right so  once and of course  you can look at the numbers as i have written down here now  you can try to verify for all other nodes and arcs that these conditions are satisfied so  therefore  this is an example and so now  here we would want to convert the d i s in to probabilities  refer slide time  20  05  and so what we would do is so  the probability of transferring an edge i j is equally likely for all edges i k incident on i right and so now  let me generalize this discussion and we will say that so  then i will give you process of writing down the corresponding state vector and how you define the transition probabilities so  take a undirected graph now with n nodes so  just take the general case and will define the probability vector s by saying that the i th probability is state vector is component is d i upon sigma d i you take the degrees what we had defined here and now we just normalizing so  essentially if you want to convert these two probabilities you have to just define this by the total number of edges  which will be summation d i so  you are adding up the degrees of each node so  which will actually become ? so  like for example  sigma i  if you do it here now  for this case it will be the degrees are 6  7  8 and 10 right so  summation d i is 10 right  which is twice the number of edges right so  the  when you add up all the degrees  they add up to degree twice the number of edges in the graph so  here we are normalizing so  therefore  this is d i upon sigma d i then s i s are probabilities  because when you add up sigma s i  sigma s i this will be sigma d i divided by sigma d i  which is sorry  which is 1 right so  these are probability vectors and as they will satisfy this  because i am defining this is p i j as i am saying that p i j is 1 upon d i at node i whatever the degree of the node then i take the probability of traversing each of the edges  which are incident on i as equally likely so  it will be 1 upon d i so  whatever the degree of node i and then all edges which are incident on node i  i will take the probability as so i to j so  this will 1 upon d i and similarly p j i will be 1 upon d j right so  there we are at node j then whatever the number of edges  which are incident on j then 1 upon d j and so p j i is 1 by d j so  as we saw in this example and now you can easily verify that  because you have simply divided each s i by this thing so  therefore  the equations will remain the same and so these will be satisfied so  these this probability state vector and these transition probabilities define satisfy your time reversibility equations and so we will say that no wondering around this random walk on a undirected graph can be looked upon as a time reversible markov chain right and you see here one did not have to do any hassle with solving a system of linear equations to compute your state probabilities stationary state probabilities so  just simple formula gives you the way to compute them right and this is what we really want to show that because of the property of time reversibility things become so simple right so  this is finally  our conclusion that s i s and p i j s satisfy the reversibility equation and so s i s must be the stationary probability vector ok now  you can generalize you can talk of a generalized random walk and here suppose what we are saying is that you have a weights attached to the arcs so  there is a weight w i j  which is non negative for the arc i j and if the arc i j is not there the edge  i should say actually this should be called as edge  because in the directed case it is the nomenclature is that you call them arcs when they have direction so  otherwise undirected links are called edges so  this is edge i j and so  w i j s are not negative and w i j is 0 if edge i j is not present right so  we will discard that now  what we will says that again we want to generalize these concepts so  what we will says that probability of traversing an edge i j when at node i is proportional to w i j let us say so  actually the weights here right  for example  edge 1 2 is 1 2 to 5 is 2 and so on so  i am given you the weights w i j right and now what we are saying is that the probability of traversing the edge i j is proportional to w i j so obviously  because these are numbers  integers so  they can not be probability so  i will have to normalize them now so i do this  i define p i j as w i j upon yeah  one more thing i should have spelled out here that  in this case in the random walk case  you see what is happening is that your probabilities your s i s the state probabilities are being defined by this right so  d i upon sigma d i and that means  that remember state probabilities is the stationary state probabilities also represented the fraction of time the systems spent on the particular state right so  here since s i is d i upon sigma d i you see the system will spent more time in state  in the state which has higher degree right so  the higher the d i  the more the higher the value of s i  because the normalizing factor is the same so  therefore  we magnitude of s i gets determined by the magnitude of d i and so the system will spent more time in a state  which has higher degree which has more edges incident on it and of course  i should have spent little more time on the analogy see when we said that this is a markov process so  here essentially the nodes or the state of the system we are saying that these are the states in which the system will occupied by the system and then the links are the gives you the transition from ; that means  you can transition from 1 to 2 or you can transition from 1 to 3 and so on so  the possibilities of transitioning to different states so this is the analogy so  now let us talk about generalized random walk and that is why we are saying that we will have weights attached to the edges and the weights will be 0 whenever the edge is not present right and then we will define the probability of traversing an edge as w i j divided by the total weights of the edges  which are incident on that node right so  sigma w i k summation with respect to k  so you add up all the weights so  for example  if you want to look at the probability p 1 2  so the total weights here are 5 so  p 1 2 would be the weight of the edge 1 2  which is 1  so 1 divided by 5 similarly p 1 3 would be the weight is 2 here so 2 by 5 right when p 1 4 is 0 right and p 1 5 there is an edge so  p 1 5 is 2 by 5 and so and the now  we have to define the state probabilities and to show you that again you know generalized random walk ; that means  now the probabilities of traversing an edge when you are at particular node will be given by this and therefore  this will again be this is the random this is the markov process where again the nodes represent the states and the legs the edges give you the states to which you can transition and now when i defined for you state vector stationary probability vector such that the necessary conditions for reversibility are satisfied then this is also another example more general example of a reversible markov process  refer slide time  28  31  yeah  so you see the weights attached to the edges then we see that if i define my p i j as w i j upon sigma k w i k so  now  here the notion of you know of going to an edge is equally likely that has been replaced by so  this is the weight of the edge i j and then divided by total weights of the edges which are incident on that node right so  then that is how will define p i j and you can see that if all w i j are the same then this will be the exactly the same ; that means  if you just take this as  i mean the number of edges which are incident when this p i j will reduce to 1 by the number of the degree of the node right so  this is the generalization of the random walk and so you will define p i j as w i j this so  now  we will if you write this as this then this will be sigma w i k summation respect to k p i j is w i j and of course  this condition we are imposing that w i j s w j i right so  then in that case yes so  again since i have been able to write this as this so  w j i if you take the same equation w j i can be written as p j i into see the p i j represent p j i summation w j k summation over k right  because here it was w i k so  here it will be summation w j k k  because you are at node j so from j you are transitioning to i so  therefore  weights of all the edges  which are incident on node j which are of the kind j k so  you add up all the weights of the edges incident on node j and just know so now  once you get this then you say this is your reversibility equation  because your p i j s are transition probabilities and now  i just have to define my corresponding state probabilities and then you see this will give me a reversible  time reversible markov process this is the idea so  as i we said that your s i s will be proportional to summation w i k over k and so we will normalize s i that is you let s i be take the summation of all the weights and so sigma w i k respect to summation respect to k divided by summation respect to i and k of w i k total weight right and so therefore  by our result that we proved earlier s i s are the stationary probabilities so  essentially the same concept go through and you can now  take a general case you can assign any sets of weights to the edges and then you can define the corresponding transition probabilities and you will see that this will again be this will be a generalized random walk so  you can and you can very easily see that it is you know reversible in the sense that the process can go on and but if you start going backwards then again it will be the same process that is repeated so  exactly the same forward or backward does not make a difference so  therefore  in other words we can now  get a feeling for the time reversible markov process is and the converse will also help you to fix ideas better now  what we are saying is that any reversible chain is of this form so  given a reversible chain you want to say that you will be able to associate undirected graph and give weights to the edges such that you know and then you can define the corresponding transition probabilities and your state vector you know this is simple so  therefore  now see ; that means  if you given a reversible chain and this is the set of equations ; that means  there are some s i s and p i j s which satisfy this necessary condition so  this is given to you right that the time reversibility equations are satisfied by the state vector s and the transition probabilities p i j so  some reversible chain is there now  we will start assigning will say that we can draw undirected graph and of course  the nodes will be the  so we can construct a graph with nodes as states and the edges i j for which p i j is positive so  wherever there is a positive pi j then the corresponding link will be there  otherwise it will not be their right now  let me define the weights on the edges so  w i j  i will simply define as s i p i j right and this again by the definition because say s j p j i will be w j i so  immediately you get that the weights are symmetric so  w i j s w j i so by using this question right now  you want to compute the transition probabilities and which we will show can be done in terms of the w i j s so  you want to compute probability x n is i given that x n minus 1 is j right so  this because i am constructing a undirected graph and i am associating weights w i j so  we remember with the generalize random walk this transition probability we defined as w i j upon sigma k w i k it is here right so  once given markov process i am constructing a graph undirected graph where the nodes are the states and then now  i have to when the weights are well defined through this equation and w i j s w j i so  once you have the weights then our process of you know generalizing a random walk gives us that the probability of transitioning from  oh i am sorry  this should have been oh so  let me write this as see it should have been i am writing w i j so  this should be j and this should be i sorry  right so  from i to j you are transitioning and so the probability would be w i j upon summation w i k summation with respect to k right this is exactly what the way we have defined here and now  let us substitute for w i j from here this is s i p i j and then summation if you sum up respect to j or k it is a dummy variable does not matter so  you are summing up this s i p i k respect to k now  since i is independent of k so  s i comes out and sigma p i k respect to k is equal to 1  this is 1 right  remember transition matrix and you are summing up the components of a rho so  therefore  this is equal to 1 so then s i s i cancels and of course  as earlier said it and again repeated that s i s are not 0  because if s i is 0 then the probability of being in that state is 0 and so we can always reduce we can remove that state from the process and come talk and work with reduced process right so  therefore  of course  these are meaningful only when s i s are not 0 so  s i gets cancel and you are left with p i j so  that means ; once you given this then i can assign the weights by this equation and then once  i have this weights i can now defined my transition probabilities in terms of these weights right w i j upon sigma w i k and once i have this transition probabilities i can also define my s i s we just reverting back to the process  refer slide time  36  15  so  here s i s was this and so similarly we can say that from here summation w i j is summation j is equal to summation j s i p i j so  this becomes this and therefore  this is s i so  here your s i s are proportional to summation w i j sum respect to j and since s i s have to be probabilities i can normalize them so defined by the total sum of weights and so this gives me a probabilities and so my  this thing is complete ; that means  given any markov process which satisfies the time reversibility equations  i can assign a random walk with it and assign weights i can define the weights  i can define the transition probabilities and state probabilities so  therefore  any time reversible markov chain can be modeled as a random walk and you can determine the weights and the  you can determine the transition probabilities and the state probabilities and so this is very simple in the sense that now  you really want to compute your  this and this you can do it respect to you do not have to solve system of linear equations and so this simplifies  but of course  only a small class of process is markov process  which would be which would satisfies time reversibility condition right ok so  i think this brings to an end of course  i should also just mention that the non reversible markov chains examples  one example and this is taken from burst stains lecture you know however  he has given lectures on markov processed  markov chains so  he says that you know world wide web so  you can imagine as you know each web page as a state of the system right and so web pages are states and edges so  edges again you can picture this as a graph  but this will be a directed graph right so  for example  just take 4 web pages or you may be you can take 5 web pages does not matter and then you see it is like  if you are page 1 here  where you can go from here to page 2 or you can go from here to page 3 so  these are the hyperlinks right  you are looking for some searching for some word remember you get a page you open a page and then its links you to other pages it shows the links hyperlinks they are called to other so  therefore  and this is very small example  because you know the millions and millions of web pages and they will be connected and it is any time you open a page it will link you to hundreds and thousands of pages and of course  there is a way of ranking and so on  all that algorithm is there  but in many case so  the whole idea is that you can picture this as a directed graph so  each node will be a web page and the pages which are connected to a particular node will be directed by a link so  for example  from 1 you can go to 3  but you can not go to 3 to 1 right similarly you can go from 1 to 2  but you can not go from 2 to 1 and so on  but at 4 you can go from 1 to 4  4 to 1 and similarly from 4 to 2  but not 2 to 4 so  you can immediately see that this will not be a time reversible process of course  there is algorithm to show you and then how do you compute the state probabilities and so on again there is a whole algorithm interesting one  which gives you method of not as actually having to solve system of equations again and you can compute the state probabilities and so on  but there is a way of computing the transition probabilities also so  example web pages worldwide if you look at this then this will be and searching on the web is not a it will be a markov process  because it will depend on see the way you adjust the probability or where you want to go will be this probability will not be dependent on how you reached one so  it is easy to picture that the research on the web will be a markov process  but it will certainly not be reversible markov chain ok so  i think with this i would like to end the discussion on this thing on markov process now  we would like to talk about continuous markov processes and then go on to specialized continues markov processes  refer slide time  41  01  see after having looked at the discrete markov time process markovian process is to stochastic processes discrete stochastic processes with markovian property so  we have to spent quite of you time quite bit of time on looking at the properties and characteristics of such processes we will be looking at because again the continuous time process is are also very important and especially the markovian ones and i would like to now through a series of lecturers show you particular kinds of a markovian continues time processes so  and so want to show you the transition from discrete time processes to continues time processes and same and how the markovian property also translates when you consider time as varying continuously instead of discrete time so  we say that continuous time process we describe it has x t where x is the random variable so x t comma t greater than equal to zero so  this is x t varies you get different values so  and since t is greater than or equal to zero so  it is simply varying continuously the time is varying continuously and we say that if continuous time stochastic process taking on values in the set of non negative integers so  these values would be positive integers  non negative can be 0 also and the property process is markov process if for all s and t your a non negative integers i j and x u  where u is varying between 0 and s so  these are all non negative integers probability that x t plus s is j given that x s is i so  at time s the system is occupying state i let say  because these are the non negative integers know so  the non negative integers describe the state it is occupying so  this tells you the state the value of x t will tell you the state that is system is occupying a time t so  here probability x t plus s is j given that x s is i and that x u is small x u again these are positive values as u varies from 0 to s so  given all the past history ; that means  the states which the system occupied from time 0 to s then at time s it is in i and now  at time t plus it is in j so  this probability is equal to the probability that x t plus s is j given that x s is i ; that means  this past history is redundant you so  you do not want the probability this probability will only depend on this ; that means  what is your present state and then after time t it is occupying state j so  this probability is independent of how you reached state pi at time s so ; that means  so whatever happened between 0 and s is not a material ok now  which i am saying in words here that is the conditional distribution of the future x t plus s given the present x s and the past depends only on the present and is independent of the past right and this property and of course  and if this probabilities also independent of s that means  it does not matter what time and if you remember the conditional we are saying for stationary that we was saying that probability in the discrete case we are saying that x plus 1 j given that x n is i is equal to probability x 1 is j given that x not is i so  the same property that is so it does not matter when you are considering this conditional probability whether at time 1 or at time n plus 1 does not matter so  then we said that this case these the system or the process is stationary  because it is independent of the time right so  same property is being carried over here so  if this probability is independent of s so  essentially you are saying that you know  but s is tenth day or fifteenth day or the zeroth day does not matter if in the zeroth day the system is occupying state i then at x t it will be j and this will be the same what time you have to takes right so  if this probability is independent of s then we say that the continues markov process is stationary  refer slide time  46  02  and now  just let us consider the finite case ; that means  the system  it is a continuous process  but it can occupy finite states i varying from 0 1 to m right and now  we associate a random variable t i which is the amount of time the process spends in state i so  it continuous to be in state i and how do you  how do you sort of express this property or how do you describe this t i so  we say that suppose the system enters state i at time t prime equal to s then for any fixed amount of time t greater than 0  this greater than t will be possible if it has been continuously ; that means  if x t prime is i for all t prime in the interval s to t plus s so  at time s it started it entered the state i and now you want to know for how long it will continue in that state ; that means  for all values of t  out of t prime between s and t plus s this value should continue to be i right so  this is the kind of random variable we want to so  the amount of time the process spends in state i so  these are the important thing and we have just now said that  and we say that this is the markovian property with stationary probabilities implies that probability i greater than t plus s given t i is greater than s is same as probability i greater than t right because i can take s to be 0 and then this will simply be that initially it is state 0 and then now  it is in continues to be state zero so  the probability oh in that case yeah  amount of time the process spends in state i so  i will take the time as to be 0 sorry  that is not the state so  s is 0 then simply you started in state i and so it will be it will be independent of when you are considering this probability so  as long as  so that means ; only that duration of occupying the state i  that is important it does not matter so  does not matter at what point of time you are considering this so  essentially this just means that the process has been in time in state i for time t so  therefore  this is now  this will be ; that means  t i is memory less so  the kind of continuous ; that means  when you take the continuous process and you impose the markovian property then it actually translates to saying that this random variable t i is memory less and if now you remember of course  we did not prove this part when we talked of exponential distribution negative exponential distribution we said that exponential any random variable  which has a negative exponential distribution  is memory less and exactly this property ; that means  t i would be  because the course level was such that  i could not prove the reverse thing that any distribution having memory less property has to be negative exponential i did not prove that part  but may be later on some time when you do an advance course we can see how that property proved so  in many cases since this is the markovian process memory less so  therefore  t i will have a negative exponential distribution so  now  i will be describing to you talking about poisson processes and the birth and death processes very interesting and they also you know model lot of situations and practical life and you know  lot of process is you can show how this property approximately of course  you can not say that you can always model the real situation very accurately so  we will be talking about and so … then see i will be referring to birth and death processes as m m 1 so  it will be that you know the arrival process is markovian and the departure process so  suppose you are in a situation suppose you are at a counter at a bank counter or at a post office counter and you want to people are coming in and then they get serviced and then they leave the system so  you want to model that situation so  here you describe such process by m m 1 property which means that you know the arrival process so  you can actually show that if the arrival pattern is poisson then the inter arrival times will be exponential and so the interval arrival times have a markovian property then the service times will also be shown to be under the condition of course  the condition that we will impose will be things under the service times also follow an exponential distribution so  we will call it m m and then 1 server so  this is the connection and therefore  you see that why it was very important that talk about discrete markov processes and then continuous markov processes which again have the same property  markovian property in this case can again be written down as this and this will be the memory less property which implies that the t i has a negative exponential distribution so  the birth and death processes that we will consider will have the same under this     we will consider the birth and death processes where the arrival inter arrival times have follow markovian have a negative exponential distribution  and the service times also have a negative exponential distribution so  then we can very easily describe the system to be m m 1 with 1 server and of course  you can also consider more than 1 server  and we will derive lot of interesting results for the parameters related with such distributions introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  32 poisson process  refer slide time  00  14  so  while talking of the poisson process i said we have to first talk about a counting process  and so we said that there should be some norms for the  have to be followed for the counting process and so the first one is that it should have independent increments ; i should underline increment  independent increments so  that means  that the number of event that occur in disjoint intervals are independent so  that means  say for example  if you are saying that up to 8 am you are counting the time  then n 8 would be the number of events that have occurred up to time 8 and so that n 8 will be independent of say  for example  the number of events that have occurred in the between at 8 and 10 am so  that means  n 10 minus n 8 so  both these are random variables  and so we will assume because the intervals are disjoint this is up to 8  let us say 0 to 8  and then this is from 10  8 to 10 so  the 2 intervals are disjoint  and therefore we except we want that these 2  the number of events  that means the corresponding random variables must be independent now  for the  for example a  that i see  i gave you 3 examples of counting processes ; first one was you know arrivals at a post office and so example a  this may be a reasonable assumption because we may assume that people as long as the  for the time that the post office is open  people will come in any time and so people coming say  between say  upto from  if it is open from 8 am  then 8 am to 10 am  the number of arrivals and the random variables indicating the number of arrivals  and say between 10 and 12 the arrival  the random variable  2 random variables giving the number of arrivals in these disjoint intervals are independent now  for b  which is the number of births in a particular town or a this number of births between time t and t plus delta t suppose we are taking  will be large if m t is large so  that means  at  if you taking it over a long span then at a particular time when the people  population is large then the number of births will be large so  here it will depend ; that means  it does not seem reasonable that n  t  is independent of n t plus delta t minus n  t  for any t  refer slide time  02  51  so  it will depend  see  this will depend on the number of births that occurs if you are taking upto ; or  in the sense that you are saying that the random variable n  t  and the random variable n t plus delta t minus n  t  need not be independent  if you are  ok now  for example  see  it would be a reasonable assumption so  this example c  refer to the number of goals that are hit by a hockey player so  here again if you take the time spent to be one season of hockey tournaments so  during one particular season we expect the hockey player to be either to have continue to have a good form or not have a good form see  if he has a good form then he will hit number of goals hit by him upto time t  or from t to s  t to s plus t  should be  the 2 random variables should be independent so  the time spent is important  right if i take the time spent to be 2 years then certainly it will matter because one can not maintain a form for  let us say  upto 2 years or 5 years ; so time spent so  if you restrict your time spent then c would be a reasonable assumption for c  the independent increment assumption would be reasonable the other important assumption for counting process is stationary increments  right now  here what we are saying is that the number of increments the  that occur should depend only on the length of the interval so  here  for example  if you having  s  s plus t  then the length of the interval is t ; so it will not matter what value s takes  as long as the interval time has length t  then the number of increments that occur during this interval is just dependent on the length of the interval  right now  here  we can again see whether the counting processes that we wrote down is that reasonable assumption for all those counting processes for example  for a  it is not a reasonable assumption  why ? because  for a post office  and even  similarly you can consider a bank  there may be a rush hour if there is a rush hour then certainly you can not say that this and this are independents if this is the rush hour then  you know  that there will be more arrivals  and so the random variables n 8 and n 10 minus n 8 would not be independent so  if you have the concept of rush hour  but if you sort of ignore the rush hour and then you look at the counting process for a post office then this may be  assumption of stationary increments may be a reasonable assumption now  again for b  it may not be a reasonable assumption in this case  some sort of pattern has been observed in the number of births see  somewhat times more babies may be born then during winters  and so again  if the  some pattern has been observed in the town that you are considering  then again b may not be  because it will not follow the assumption of stationary increments so  the  it will matter if your time span is during summer  so then  for the same period more babies may be born as opposed to the time span this is during winters so  for the same length of time  the 2 may not be  the number of events in the interval has the same distribution for all s so  it may be different distributions then again for c  it will be a reasonable here again  if you are saying that if the person  if the  if the player if the hockey player is involved then surely the number of goals that he hits will depend on the length of the time that he is played and so it will have the same distribution  and will depend  only the distribution of the number of goals that he hits would be dependent on the length of the interval  and not on the  when he hits if i am again restricting myself to  let us say  1 season or may be 2 seasons  if that is considered to be reasonable that a person will continue to be in form for a player will be continue to be in form for 1 season or 2 seasons  maybe sometimes  it depends ; whatever the way to look at it in that case the stationarity increment assumption would be reasonable one for c and  this is what i am trying to say is that you have to  before you start applying  modeling a situation  for example  a particular counting process  you have to see that certain basic assumptions are satisfied and in that case  you can  you know  then we will see that based on these 2 assumptions we can now talk about the poisson process so  these are the 2 basic assumptions under which we will now formulate our this probabilistic model for counting  for the counting process  and which is which we will define as the poisson process  refer slide time  08  25  so  after having defined counting process  now i would make a definition of a poisson process so  what we are saying is that the counting process n  t   t greater than or equal to 0  is said to be a poisson process if its satisfies the following conditions so  as we said that we start the counting from time t equal to 0 so  n 0 is 0  then this has independent increments which we already said that while we define the conditions for a counting process and then  we said additional properties were has independent increments then 3 is  that number of event that occur in any interval of length t has poisson distribution ; see  this is thing so  therefore  we are saying that it will be a poisson process the counting process will be a poisson process if it the number of event that occur in any interval of length t has poisson distribution with mean lambda t  where lambda is some constant  positive constant so  that means  what we are saying is that because the interval of length is t  time interval is of length t  so therefore  probability of n s plus t minus  n s equal to n because  what we are saying is that the number of events that occur in this interval  s plus t  s  ok  we can say that the length of the interval is t equal to n will be  e rise to minus lambda t  lambda t rise to n upon n factorial  n varying from 0 so  this is your probability for any value of n  here integer value of n  right so  now  since we are  since this probability is only dependent on the length of the time interval that is t  it is not dependent on when the counting process is started  the beginning of the interval so  therefore  you can immediately conclude that the process that we have defined also has the stationery increments property  right  which we said that it does not matter  it is only the number of events that occur which depend on the length of the interval and not on when you started counting so  therefore  this would be a poisson process  that is what our definition is so  now let us just look at this definition and see you can  of course  condition 1 is defined that simply says  that counting begins from time t equal to 0  which we have been saying repeatedly then  2 can be verified from the knowledge of the process that it has independent increments whether it is a valid assumption or not for the process that you are trying to model  then you can tell from the knowledge of the process itself  right now  3 says  that the number of events that occur in an interval of length of t  has poisson distribution so  it is not clear how to verify 3 and this is the whole thing ; i mean  if i am calling a process a poisson process then i am just saying that the number of events that occur here follows a poisson distribution so  it is not clear ; and therefore  this definition is not very implementable decision  or  you know  you can not really verify this condition because  right  refer slide time  12  00  so  therefore  alternate definition is needed to determine whether a counting process is a poisson process or not  we would be wanting to have another definition which hopefully would be a more easily implementable or verifiable  that a given counting process is poisson or not so  let us see so  here we will say that can the same mean lambda t  if it satisfies the following conditions so  counting process is said to be a poisson with mean lambda t  if it satisfies the following conditions so  this is same as for the first definition  n  0  is 0 now  what we are saying here is that probability n  h  equal to 1 ; that means  in the time interval h your probability that n  h  is equal to only one arrival takes place  1 event occurs this should be in this form ; that means  lambda h plus order h now  this  of course  means that your function here is of value of high order than h  when you say  this is higher order of h so  this is linear ; that means  the terms here would be square  cube powers of h in other words  you can say that what this means is  that limit o  h  upon h  as h goes to 0  is 0 so  therefore  you know  this is of higher order than h  square  cube for example  if you take o  h  to be h square  then h square upon h  limit of this as h goes to 0  is 0 so  this is the idea ; that means  higher order terms here so this and so what we are trying to say is that you can always discretize the occurrence of the event that means  if you take  if you make the interval h small enough  then you know  there will be the probability of an occurrence of an event is positive in a small interval so  therefore  you can discretize and the second one  i suppose  ok  this is third condition the second of course  is the same as that one  that process has stationary and independent increments so  these 2 properties we require for the counting process to be able to say that it is poisson process  right so  this is has to be satisfied now  this one tells you that the probability of the occurrence of event in a small interval is dependent on lambda and that you can separate out the so  in other words  the  you know  bunching of occurrences of events is not permitted here that  probability n  h  greater or equal to t  is of order h so  that means  when h is small  this probability is really very small ; of 2 or more events occurring in a very small interval of time h  so that is of order h and  since i have told you that this means the higher powers of h then linear ; so therefore  this would be  you know  when h is very small  this also be very small so  given lambda positive  same lambda we are saying here ; when i say this  that means  it is understood that lambda is greater than 0 here so  this is the alternate definition and  let us now see that obviously  when we are saying that this also describes a poisson process  that also describes a poisson process  there should be  we should be able to show that the 2 definitions are equivalent  right so  i will do it  1  both ways i will first show that definition 1 implies definition 2  and then show you the definition 2 implies definition 1 and this is very interesting and nice  simple so  here  see we start with this definition 1 says that probability n  t  plus s minus  n  s  equal to n is  e rise to minus lambda t  lambda t rise to n upon n factorial  and varies like this  right now  put s equal to 0  t equal to h  because this is for all s  t ; and n equal to 1  in this equation ; then you obtain that probability n  h  equal to 1 because this is 0 ; t is h  s is 0 so  n  h  equal to 1 is given by e rise to minus lambda h ; then lambda h rise to n is 1  and this is it  right now  just expand e rise to minus lambda h  that will be 1 minus lambda h plus  lambda h whole square by factorial 2  and so on  multiplied by lambda h so  when you bring lambda h inside  this would be lambda h plus  all terms will be of higher order because this will be square  h square ; this will be h cube  and so on so  i can write in this way  and which satisfies  right so  that means  your condition 3 implies  condition 3 here  for the definition  second definition and similarly  it is also implied from here because when you want to compute this probability n  h  greater than or equal to 2  this will be 1 minus probability n  h  equal to 0 minus  probability n  h  equal to 1 so  n  h  equal to 0  since your definition is saying that when n is o  the probability is e rise to minus lambda h  that is all  right  because your n is 0 ; so that is e rise to minus lambda h and this is probability n  h  equal to 1  we have just computed is this thing so  minus lambda h and order  minus or plus does not matter  whatever and now  you see  when you expand this because this would be 1 minus  of 1 minus lambda h plus lambda h whole square by  2 factorial minus  lambda h plus o  h  right so  then 1  see  you have a minus sign here  so this becomes plus  right  because minus and then 1 minus lambda h ; so therefore  this is  1  1 cancels out ; lambda h minus lambda h cancels out ; and you are left with something because this is order h so  order higher than h  and this is also o  h   so  therefore  the whole thing is o  h   right so  you can see that definition 1 implies definition 2 and now  we will show you that definition 2 implies definition 1 and you see that this  then we would most of the time we are working with this definition of the poisson process  refer slide time  18  27  so  let us see ; we will try to now show that definition 2 implies definition 1 and of course  then we will talk about inter arrival times later but  you see here  probability n  t plus h   so  this is  i am saying is the  probability of n  t plus h  is equal to n  this is what we are saying  what we mean by this so  this is the new notation i have started ; so p n  t plus h   that means  number of arrivals are n in  upto time t plus h now  this can be thought of as  n minus 1 arrivals upto time t ; and then 1 arrival at  within the interval h  right that means  see  from t plus  upto t plus h  you want n arrivals or n occurrences so  upto t  if there are n minus 1 occurrences  then in the interval time length of h you want 1 arrival and according to our definition 2  this is the probability of 1 arrival in the time interval h  length of interval is h  right and  since we are talking of independent increments  so this will be product  that means  i can say this ; plus  there is no  that means  there are n arrivals upto time t  and there is no arrival in time length h  this is what ; and  this will be probability n h equal to 0 which follows from 3 and 4 see  3 said that probability of 1 arrival is 1 plus  is lambda h plus order h  right ; and  probability n h greater than or equal to 2  was of order h  right now  when you say that there is no arrival  then that means  you want 1 minus probability n h because  right ; you want this to be ; so if you take the complement  so then  n h greater than or equal to 1  would that be ok ? see  if you want n h equal to 0  i  in time  so that means  arrivals have 1  2  and so on  in the interval h ; so 1 minus of that will be  right so  therefore  yes ; so this would be then 1 minus lambda h because this o h and this is lambda h plus o h  so therefore  this is what you have so  therefore  probability of n h equal to 0 is 1 minus lambda h minus order h so  again independence of events  independent increments  so this will be p n t in to this  right so  this is how you can describe n events in time upto t plus h  by breaking up the event into number of arrivals upto time t  and then n minus 1  one arrival in time h  or n arrivals upto time t  and no arrival in time n h so  this is how we will write it down  right and therefore  this will be  if you simplify this expression  p n t is coming from here plus  lambda h p n minus 1 t minus  p n t  right so  this is it plus  all terms are of higher order of h  right now  just rewrite this this is p n of t plus h minus p n t  divided by h  so that will become ; i have divided by h here  so lambda times p n minus 1 t minus p n t and this is order h upon h now  when you take the limit you can immediately see that when you take the limit as h goes to 0  this will be limit as h goes to 0 of this  and here this will be lambda  this is independent of h  and this we have seen will go to 0  right ; order  higher order of h means that this limit is going to 0  right so  this is what you have and then this is nothing but the derivative of p n t so  this will be the derivative and this is equal to lambda p n minus 1 t minus p n t now  so this is valid for n varying from 1 because you have this n minus 1 and d p 0 t upon d t is minus lambda p 0 t  because when you are looking at n equal to 0  see from here  then you do not have this ; you simply have this  right  p n t because i should have n equal to 0  and right  so it will be ; if you want me to write it down separately  see here becomes crowded so  this will be  p 0 t plus h is p 0 t ; so no arrival upto time t  and no arrival in the time intervals  so 1 minus lambda h remember  i can ignore that term because that will anyway go to 0 so  then this will be p 0 t plus h minus p 0 t  divided by h so  limit of this  as h goes to 0  it is not legible  but you can  i am talking loudly  so you can hear so  this is equal to p 0 t minus into lambda  right so  this  therefore  this is derivative  d p 0 t upon d t is equal to minus lambda p 0 t  and so you  this much knowledge you have about the differential equations so  here  from here it follows that p 0 t is e rise to minus lambda t ; and so you have these 2 sets of differential equations so  here the solution is immediate  and this is n from 1 to t so  if you put like  for example  n equal to 1  it will be d p 1 t upon d t which will be from here  minus lambda p 1 t plus lambda e rise to minus lambda t because  i am putting  substituting for p 0 t see  when n is 1 this is p 0 t  which is e rise to minus lambda t so  therefore  this is it  right now  of course  there are methods to solve these differential equations are difficult  but what we are saying is that you  if you just try p 1 t equal to lambda t e rise to minus lambda t  it will satisfy this equation  right just differentiate and substitute here  the 2 sides will be equal so  p 1 t is the solution here and then  in general  the solution would be p n t you can very easily verify that you know  for all values of n this is the solution to all general differential equation that you obtained here and this is nothing but as i have said by definition is that p n t is nothing but probability of n t equal to n ; so n arrivals upto time t so  therefore  you see all other conditions remain the same in the definition 2 and 1 this was the only thing because we were not sure how we would go about verifying in definition 1 that the number of arrivals in time interval of length t will follow poisson distribution so  now  using these properties  you know  probability of definition  of number of occurrences in the time interval h  by now given those  the third and fourth condition of definition 2 help us to show that the number of arrivals  probability of number of arrivals upto time t would be follow a poisson distribution so  a nice way of showing that and because  see therefore  definition 2 is easier to verify  we feel because that you know  to digitize and so on  you can sort of approximate the condition 3 actually  that is the important 1 in definition 2  and then that is probability of 1 occurrence in time interval length h is of this order that you can supposedly easily verify  there are methods to do it so  therefore  most of the time we would be  would now else we have established the equivalence of definition 1 and 2 ; it does not matter whichever you feel  when needed you can use it in your ; you know  when you are trying to analyze certain results  and  or obtain certain probabilities  ok  refer slide time  26  52  now  as i have written there  inter arrival times we would now like to look at the probability of  that means  the time so  here  time between 2 occurrences  because again the occurrence is overall chance events are unpredictable so  we want to now look at the  if it is possible to determine the distribution of these inter arrival times  right we have seen that probability n  t  equal to 0 is e rise to minus lambda t so  no arrival from 0 to time t  this is your so  that means  upto  and if you define x 1 as the time of the first arrival  if the time of the first arrival  and then if i want to compute the probability that x 1 is greater than t ; that means  that there has been no arrival in the intervals 0 to t so  no arrival from 0 to t is the event that n  t  is 0 so  the 2 events are the same ; that means  if the first arrival has not occurred  the time for the first arrival  see x 1 is the time of the first arrival so  if the first arrival time is greater than t ; that means  in the intervals 0 to t  no arrival has taken place which implies that n  t  is 0 so  the 2 events are the same  is just that here we have defined the random variable n  t   and here if the random variable x 1 so  therefore  and this probability is e raise to minus lambda t so  if somewhere i have written that this event can be taken as x 1 greater than or equal to t then this is not correct because  you are saying that the time of the first arrival is greater than t  so it can not be or  if you are saying that n  t  is 0 then this is equivalent to the event that x 1 is greater than t ; it can not be greater than or equal to t because  in the time 0 t no arrival has taken place so  any arrival that takes place will be after t so  this is the important thing and therefore  1 minus f of x 1 t ; so this is 1 minus of f x 1 t  if f is the cumulative distribution function for x 1 so  then this is equal to e rise to minus lambda t ; and so f x 1 t is 1 minus e rise to minus lambda t so  this gives you the ; and so that shows you that therefore  your f x 1 will be lambda e rise to minus lambda t so  if you if you differentiate this equation on both sides you will get  lambda e rise to minus lambda t now  this is exponential distribution  exponential lambda so  the distribution of x 1 is exponential lambda ; and therefore  the expectation is expected value of x 1 is 1 upon lambda so  this tells you what ? that  you know  1 upon lambda is the  you know  the mean  mean time of  you know  first arrival  right but  actually  now if you look at x 2 ; x 2 is the elapsed time between the first and the second arrival ; that means  here the first arrival occurred here  and the second arrival occurred here so  i am calling this as x 2 so  that means  if this is x 1  so the time of the first arrival is x 1  then time of the second arrival will be x 1 plus x 2 because this is inter arrival time so  x 2 is the time between the first and the second arrival so  for example  so now  if you look at  that is why i have defined here this is the elapsed time between the first and the second arrival  or second occurrence ; i keep calling arrival  but which also means occurrence now  if you want to look at this probability t 2 greater than t  condition that t 1 is s so  the first arrival took place  we are writing t 2  t 1  but here i have been writing x 1  x 2 so  it does not matter ; you can make it x 1  and you can make this as x 2  because this is x 2  so x 2 so  therefore  this will be probability n s plus t minus n s is 0 because this second arrival is not have  has not taken place upto  i mean  this length is not is bigger than t so  therefore  s plus t will be this so  n s plus t minus n s is 0  given t 1 is s so  therefore  probability n s plus t minus n s is 0  is e rise to minus lambda t so  this is again  see this will also be 1 minus f x 2  t   and therefore  you can again see that it will be exponential so  we will continue with the  you know ; so the inter arrival times are all exponential and that you can relate it with the memory less property of the exponential distribution which comes to your independent increments so  the 2 things are related  refer slide time  31  51  in this exercise 8  i will be going over some problems related with the liber theorems that we had done  and also the poisson process that we have talked about after that right so  x 1 and x 2 are  question 1  x 1 and x 2 are independent random variables ; x 1 is binomial n i  p  i 1 to 2  right so  x 1  that means  is binomial  n 1  p   and x 2 is binomial  n 2  p   so  use m g f s to find the distribution of x 1 minus x 2 plus n 2 so  here  you see  all that you have to show is  yeah ; so basically these 2 problems are on the  you know  m g f s joint density functions of random variables  and then add also introduce the concept of m g f for more than 1 variable so  now  here you see  you can rewrite this x 1 minus x 2 plus n 2 as  x 1 plus n 2 minus x 2 so  since x 2 is binomial n to p  your n 2 minus x 2 will become binomial n 2  1 minus p  right  is that clear ? because  you see  the when you consider n 2 minus x 2  so if x 2 has r successes  then x  n 2 minus x 2 will have n 2 minus r successes so  it will be ; so therefore  the  for n 2 minus x 2  the successing of x 2 would be failures here and therefore  your  see the  at the probability for a failure is 1 minus p so  that is all so  once you recognize that you can write this as  x 1 plus n 2 minus x 2  then n 2 minus x 2 is binomial n 2 n 1 minus p so  once you know this then you can immediately began  and then they will be independent so  therefore  because x 1 and x 2 are independent  so x 1 and n 2 minus x 2 are independent  and therefore  you can write down the joint m g f so  you should be able to do it  right now  question 2  x 1 and x 2 form a bivariate normal random variable ; i mean  they are bivariate random normal variables with parameters new 1  new 2  sigma 1 square  sigma 2 square  and row so  row is your co relation co efficient show using m g f s  that y and z  given by  so y is defined as x 1 minus new 1  and z is defined as x minus new 2 minus row into  sigma 2 upon  sigma 1 into  x 1 minus new 1 so  you have to show that these 2 random variables are independent  and that y and z are each random normal variables here the idea is to use m g f s  but actually there is a easier way and surely  to be able to do this problem using the m g f s  i leave it as a challenge  and maybe when i am discussing  you know  set of miscellaneous examples  we will revisit this but  right now  way to do it is  see  because y is x 1 minus new 1  so this will continue to be normal remember  because x minus new 1  the mean of y will be 0 variance will be the same  because by shifting the mean of a random variable the variance does not change so  therefore  y is again normal which means 0 and variance sigma 1 and similarly  z is also  this should be x 2 here that is missing  so x 2 minus new 2 so  here again you have shifted the mean of x 2 by this quantity new 2 plus row into sigma 2 n ; of course  this is the full idea when you write z like this  so x 1 minus new 1 upon sigma 1  that is the  because you are computing the ; so this is the whole idea  refer slide time  35  56  so  here again  the mean has been shifted and therefore  z is also normal with the same variance sigma 2  and the mean would be well ; so by definition of z  we see that z is the random variable which is given by a conditioning x 2 on x 1 and we had to  while computing the conditional p d f s  we have seen that this will also turn out to be normally distributed random variable and you can immediately see that the mean of z that is the expected value of z is 0 because expected value of x 2 is new 2 and expected value of x 1 is new 1 so  when you take the expected value of z  it will turn out to be 0  right so  therefore  we need to compute the variance and the variance will simply be expectation of z square so  which i have done here  by writing down the expectation of the square term  and then taking expectation inside as we can do it  and therefore  it will turn out to be 1 minus row square upon sigma 2 square so  this is the variance now  when you want to define the co variance then it will be y comma  co variance of y  z so  that will be expectation of x 1 minus new 1 into  x 2 minus new 2  minus row sigma 2 upon  sigma 1 into x 1 minus new 1  right and again  here we can take expectation inside so  this will be expectation of x 1 minus new 1 into  x 2 minus new 2 ; and then  minus row sigma 2 upon sigma 1  expectation of x 1 minus new 1 whole square and expectation x 1 minus new 1 into x 2 minus new 2 is the covariance the correlation coefficient row into  sigma 2  sigma 1  right because  expectation of x 1 minus new 1 into x 2 minus new 2 is the covariance  and  so that can be written as row into sigma 2 sigma 1 then  minus row sigma 2 upon sigma 1 into expectation of x 1 minus new 1 whole square is sigma 1 square so  therefore  when you substitute that value you turns out to be 0 so  y and z are uncorrelated and now  we use the result that for norm  if y and z are normally distributed then being uncorrelated is equivalent to their being independent so  therefore  y and z are independent  right question 3 is  from an urn containing 10 identical balls numbered 0  1 to 9  n balls are drawn with replacement so  the  draw a ball  and then put it back  you just notice the number in the following  let us occurrence of 0 on a draw mean that the draw yields a ball with number 0 so  draw whenever the occurrence of 0 means that you draw a ball  you notice the number or you note it down somewhere  so if it is 0 then it is a draw means  that the draw yields a ball with number 0  and then we put the ball back  right now  what is the weak law of large numbers assert about the occurrence of zeros in n drawings ? so  the mean is 1 by 10 because they are identical balls so  the probability of drawing any ball is equally likely with any of the numbers  10 numbers is equally likely and therefore  the weak law of large numbers will say  that if s n is the number  see we are denoting by s n the number that number of balls that showed up with number 0  right so  then s n by n is the relative frequency so  out of the n draws  you have s n balls have shown up with number 0 so  s n by n  as n goes  is becomes large  will converge to 0 in probability  will converge to 1 by 10 ; the mean is 1 by 10 ; so will converge to 1 by 10 in probability  that is your weak law of large numbers so  s n by n will converge to 1 by10 in probability  refer slide time  39  48  now  b part is  how many drawings must be made in order that with probability at least 0.95  the relative frequency of occurrence of zeros will be between 0.09 and 0.11 so  that means  you are wanting to know so  s n by n is the relative frequency  you want to compute this probability that the relative frequency is between 0.09 and 0.11 and this probability should be atleast 0.95  right so  therefore  now again i standardize the whole thing so  this is s n by n minus 0.1  right ; 0.1 is the expected value here  and so subtract 0.1 from either side  and so this finally  because the difference is 0.01 so  this is what you have now  establishes in the quality this number ; this probability is greater than or equal to 1 minus variance of this s n by n which is because this is now binomial 1 by 10 into 9 by 10 so  0 and nonzero that is how i am treating this is so  p  q ; p  q into 1 by n because s n by n  the variance  right so  variance of s n is n p q and that divided by n square so  this is 1 by n  fine and so this into divided by so in establishes the quality 0.01 so  therefore  we will compute the value of n when this is equal to 0.95 ; and  for higher values of n  it will be higher  right so  therefore  now you have the equality you can now get a equation for n  and you will get the value of n for which this probability would be between 0.09 and 0.11 so  you can do the rest of the problem then  part c is  use a central limit theorem to find the probability that among n numbers thus chosen 0 will appear between n minus 3 root n by 10  and n plus 3 root n by 10  fine so  here again you want this probability using central limit theorem  right ; n minus 3 root n by 10  less than s n  less than n plus 3 root n by 10 so  then i  you see  n by 10 is the mean of s n so  i write it here  this and then  you see the variance ; variance of s n will be n into 1 by 10 into  9 by 10  right because  s n is now binomial with mean 1 by 10 and  sorry  mean n by 10 and variance n p q  right so  this is this  and so under root of this will be 3 root n by 10 ; so 3 root n by 10 so  when you divide  so now this becomes a standard normal variant  and so the central limit theorem says  that probability this less than or equal to  i mean  for n large enough  less than or equal to 1 ; you want to compute  approximate so  this is the approximate probability which is 2 phi 1 minus 1  right so  phi 1  the value is given to you at the end of the problem  and so you can compute this so  this is good use of central limit theorem  refer slide time  42  59  so  now let us go to problem 4 an employee in a call center works from 8 a.m until 5 p.m  with breaks between  10.30 to 10.45  then from 12.30 to 11.30  and 14.45 to 15.00 hours assume that calls come in according to a poisson process with expected number of calls per hour equal to 6 so  lambda probability that there are atmost 10 calls during the breaks so  here the whole idea is  because you see  it does not matter for the  when the arrivals  the phone calls are coming by as a poisson process  then the inter arrival time between the phone calls are  is exponential which is memory less so  that is what you are using here so  then what we can do is we can just add up the total break up  the break time which is 15  1 hour and 15 ; so 1 hour 30 minutes right so  therefore  3 by 2 hours ; and you want at most 10 calls during this 3 by 2 hours so  therefore  you will have to write the probability  see you sum up ; that means  the calls can be 0  1  2  upto 10 so  your lambda is 6 into 3 by 2 ; 6 by  6 into 3 by 2 because 3 by 2 hours so  lambda t  lambda t becomes your parameter now and within this time  within the time 3 by 2 hours you want atmost 10 calls so  you can write down the poisson probability what is the probability that first call of the day is after 8.10 a.m so  that means  for 10 minutes you do not want any call so  0 call and therefore  again this will be ; so your time would be  you have to see  since your arrival rate is given per hour  so you have to convert the 10 minutes to the  to fraction of an hour which is 1 by 6 so  therefore  it will be e rise to minus lambda t  probability that no call comes during the time 8 to 8.10 am so  that means  1 by 10  1 by 6 into 6  which becomes e rise to minus 1 will be the probability  right actually  right  my idea is not to really give you all the answers  but just give you hints what is the probability that the employee can do something else for 45 minutes without being disturbed by a call ? so  here again we are repeatedly using the memory less property so  45 minutes can be anywhere ; and therefore  you want the break ; that means  now your time is 3 by 4 hour so  you do not want any call to come in between for 3 by 4 hours  and your lambda is 6 so  you can do this now now  consider a poisson process with parameter lambda what is the conditional probability that n  1  is n given that n  3  is n ? so  here again  this is a good question in the sense that will again help you to understand the poisson processes do you understand why this probability does not depend on lambda ? now  here you see  what is that you have to find ?  refer slide time  46  14  you have to find probability n  1  is n  given that n  3  is n so  this means  probability n  1  is n and see  actually you can interpret this as that n  1  is n  and then n  2  is 0  because n  1  is n and n  3  is also n so  that means  for 2 prime periods  3 minus 1  there has been no arrival  right so  therefore  this is this  and then divided by probability n  3  equal to n this is what you are having  right and so and you are given  and your arrival rate is lambda  right so  therefore  you have to write this  right so  n  1  is the number of arrivals which is equal to n ; n time 1 period and n time 3 period also you have given that n arrivals are there so  that means  all the n arrivals have taken place between 0 and 1 and so there are no arrivals in the time 2  2 units of time 0  right and now if you right out this  these probabilities  you see that the answer will be independent of lambda and again i want you to work out the details so  question 5 is over question 6 is  jobs to be performed on a particular machine arrive according to a poisson input process with the mean rate of 2 per hour suppose  that the machine breaks down and will require 1 hour to be repaired  what is the probability that the number of new jobs that will arrive during this time is 0 to ; so that means  essentially you are asking for 1 hour gap ; that means  the business of machine is takes 1 hour to be repaired so  then in this 1 hour you want to know the probability of 0 arrival  2 arrival  or 5 arrivals and this is the poisson process ; and the mean rate is ; so lambda is ; so the mean rate is lambda which is equal to 2  right  2 per hour so  this you can  very simple problem ; but again  i just want you to familiarize yourself with all these concepts  and therefore  i have done it here now  question 7  suppose you arrive at a single teller bank to find 4 other customers in the bank  1 being served and the other 4 waiting in line  the statement is a little this thing because here it should have said 5 people  but anyway  4 refers to the 4 people waiting in the queue  1 is being served ; and you join the end of the line  so you are the 6 person so  if the service times are all exponential with rate new  what is the expected time you will spend in the bank ? so  therefore  you see  this is 6 service times because 5 are already there  and because of the memory less property the person who is being served  again the probability of its completing  you know  so whatever service time is over is immaterial so  therefore  6 services have to be completed and therefore  the completion time for the sixth person is a gamma distribution with mean 6 new ; it will be 6  new  right ; yeah  it will be gamma  6  new  sorry so  it will be 6  new  and therefore  the  you know  what is the mean the mean would be 6 by new i think the mean should be n by new  right if it is gamma n  new  anyway just verify that so  you will find out the expected waiting time of the sixth person when he joins the queue in the bank  refer slide time  50  20  there should have been a  then this eighth one so  cars pass a certain street location according to a poisson process with rate lambda so  a certain location in the  on the street  the cars are passing at the rate of lambda and a woman who wants to cross the street at that location waits until she can see that no cars will come by in the next t time units she has some idea that she is standing at this particular place  and then she looks at the side and sees that you know  for quite distance she can not see any car coming then she will feel free to cross the street  right and that time according to her is t time units  something like that so  find the probability that her waiting time is 0 so  waiting time is 0 means ; that means  she comes to the location  and then the probability that there is no car coming for the next t units  right so  here again because your arrival rate is poisson with rate lambda  so your inter arrival times are also exponential with parameter lambda and therefore  you can find out the probability that her waiting time is 0 ; that means  no arrival in the time 0 to t so  find out the poisson probability that which is e rise to minus lambda capital t  right  no arrivals and find her expected waiting time so  now  you have this distribution  e rise to minus lambda t  as the probability that her waiting time is 0 so  you find out her expected waiting time so  this you can now do by yourself  refer slide time  51  58  to answer the second part  that is what is the expected waiting time of the woman whose  who waits at the crossing for the cars to come so  you will have to break up the  you will have to compute the expected value of the waiting time by using conditional probabilities so  i will just write down the solution for you on the board so  i hope  with all these hints  and almost the some of the problems have solved almost completely so  anyway  i hope you will enjoy doing it and i definitely will try to come up with the large list of interesting and challenging problems at the end of the course introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  33 inter arrival times properties of poisson processes  refer slide time  00  14  i will just quickly again  go over through the go over the inter arrival times that we discussed in the last lecture and then i obtained the distribution for inter arrival times so  we already said  showed that fx1 t is lambda e rise to minus lambda t ; that means  the x 1 denoted the arrival time up to the first  up to the first event that occurs so  therefore  that is exponential  in the interval is lambda the interval for the first has exponential with distribution parameter lambda then  if you want to now  compute for x 2 then let us look at the probability x 2 greater than t when x 1 is equal to s so  here you see again the idea is that the first interval the first event occurred here and now  so this was your x 1 now  this time is denoted b y x 2 and  we are saying that this is greater than t so  if this time is greater than t ; that means  there is no arrival in this time and  so you are looking at probability x 2 greater than t  condition on x 1 being s but since  we have shown already  that the inter arrival times are exponential and  so they are memory less  and therefore it does not matter see  this probability will remain the same whether it is here or here or anywhere so  it does not matter  when the first event took place the probability the conditional probability is the same as the  probability x 2 greater than t so  this is the memory less property that we have already shown so  therefore  this is equal to this  and here the same thing probability s comma s plus t 0 given that s 1 is s so  therefore  this is equal to probability that there no arrivals in the time interval s comma s plus t and  that probability is e rise to minus lambda t  is it ok ? because  here again the number that you the probability that you want to compute here  is that there is no arrival in this interval and  so the conditional has no bearing on this probability also so  therefore  this is e rise to minus lambda t  and here  this in term of your distribution function you will write this probability as 1 minus f x 2 t and this is equal to e rise to minus lambda t therefore  if we differentiate both sides  you get f x 2 t is minus lambda e rise to minus lambda t so  this goes out and therefore  you have shown that for x 2 also the distribution is  exponential lambda and now  repeated use of this argument because essentially we are using the memory less property and  so the same argument can be repeated for x 3 x 4 and so on so  we end up with this proposition  that when you take the sequence of inter arrival times these are identically  independently  distributed remember  we have assumed for the poisson process independent increments  and stationary increments so  therefore  these are inter arrival times are identically  independently  distributed exponential lambda random variables that is  the process is probabilistically starts itself  which means its memory less every time  event occurs it starts itself again so  there is no memory as to  when the last event occurred  it just starts fresh from after any event so  when you start counting the inter arrival times  it rejuvenates itself again now  just a word about the parameter lambda so  you see because this is exponential lambda so  expectation of x i will be 1 upon lambda  and i mean the theory about exponential distribution does not say anything about lambda as long as lambda is greater than zero  refer slide time  04  26  so  lambda can be any positive number so  here before i come to that see a high lambda corresponds to a small average of waiting time if lambda is large  then 1 upon lambda which is the expected value is small and  so it is saying that this is the average of the inter arrival times so ; that means  if the average is small  then the arrivals will be occurring in small intervals because the expected value is small so  when lambda is high it corresponds to a small average of waiting time between 2 consecutive occurrences so  we were saying that when lambda has a large value the corresponding expected value will be a small number and  so that would mean that the inter arrival times are smaller  in the small in the sense that the average is small so  therefore  the arrivals are occurring at smaller intervals and  in any case lambda is called the intensity of the process so  there is no therefore  it simply says that lambda measures the  so if lambda is small then this will be big  so that means  the inter arrival time average is large and  so the events are occurring at large intervals hence therefore  we are saying that lambda is called the intensity of the process also and  lambda can be any positive number  but if we think of earth quakes in indonesia say for example  and take 1 year as unit of time suppose  consider the process you know  if i am counting the number of earth quakes that have occurred  in a span of ten years say for example and  so if i take the unit of time as 1 year  then lambda should not be large because if lambda is large then what will it say that 1 upon lambda is small and therefore  it would mean that the earth quakes are occurring at smaller intervals of time  but we all know that the earth quakes of course  they are un predictable  but normally it does not happen that earth quakes occur very often so  one has to be careful that is ; why this interpretation of lambda gives you an insight into  how when you go about modeling a process ? when how should your choice of lambda be made ? our also like  if you look at moments this  i mean again this is the time this 1 d when a radioactive material sends particles then the intensity is high  the intensity is high and therefore  this is small so  the particles spread radioactive particles spread very fast and  so if you are counting at any point of this thing  how often the particle is arriving ? then the inter arrival times will be small  and therefore  this will be small so  lambda would be high so  just to give you an idea  and then you can look at many different examples  and see how the value of lambda will reflect the inter arrival averages similarly  you want to look at the parameter lambda t so  lambda t is number of events so  this is actually on the average the number of events in time t in time period t so  this is your mean arrival rate so  now number of events in 2 disjoints time intervals are independent  just now we said that they are independent increments so  therefore  if you look at the arrival in between 0 and 1  it is poisson lambda and this is poisson lambda between 1 and 2 now ; if you look at the time interval 0 2 then it will become poisson 2 lambda because  again from now  by now we have by  so many different methods shown you  that if 2 random variables x 1 of course  here x 1 is poisson lambda x 2 is poisson lambda then x 1 plus x 2 would be again poisson 2 lambda  the parameters get added so  therefore  0 2 would the number of arrivals  will be poisson 2 lambda so  therefore  in 0 t it will be poisson lambda t  this is the whole idea so  this is the important thing and therefore  in time 0 t we will say that the arrival rate is lambda t  poisson lambda t  this is the whole idea  because t can be fractional and so on so  1 can again interpret in the same way now another thing is that since we are talking of stationery increments therefore  what we have to say is that ; the arrivals over the time 0 t are distributed in a uniform way because  they are random 0 to t they are anyway random events such then when we are talking of number of arrivals for example  when i am counting n t this is the number of arrivals in time 0 to t  in the span time in the span of time 0 to t so  then we have to think the way the process is being modeled  is that in this particular time period  the arrivals can occur anywhere and  so the best way to model that is  that the arrivals are uniform in the interval 0 to t  and through an example again i will try to make you understand this concept a little better  refer slide time  10  11  so  after computing the distribution function of the interval arrival time  let the another quantity of interest is s n  which is sigma x i  i varying from 1 to n  which means x n is the waiting time for the nth event to occur so  because see you are adding up x 1 to x 2 to x n so  x n is the time  when the n inter arrival time between n minus 1 and the nth event so  therefore  s n will be the waiting time for the nth event to occur so  just added up all the see on the line  you have you are starting from 0 this is x one this is x 2 and so on and finally  this is x n so  at this point the nth event has occurred  right starting from here  this is the first event  second event and so on so  at this point the nth event has occurred so  this is the total time ; that means  this the total time you are denoting by s n so  which is you can say waiting time for the nth event to occur  for the nth you know the time the volcano has to erupt particular volcano or earth quake to occur  whatever process you are looking at  you can interpret s accordingly now  from independence of x i ’ s  and being identically distributed as exponential lambda and here  again you see in the last few lectures we have been talking about  some of independent random variables  and through convolution through m g f s and so on we have looked at the distributions of sums of independent random variables so  here it immediately follows  that s n is gamma and lambda because  here the x i ’ s are identically distributed as exponential lambda  n of them you are taking some n of these random variables exponential random variables so  the sum will be gamma  n comma lambda  and therefore  the p d f are the density function for f s n t is lambda  e rise to minus lambda t lambda t rise to n minus 1 upon  and minus 1 factorial for t non negative so  this is the thing  but now again as i said it always helps to be able to use other tools that we have developed and  so let us try to do it  and then of course  m g f again we has already been computed  for a gamma random variable is lambda upon lambda minus s rise to n so  while writing m g f of s n the s got written by mistake so  it is actually m g f of s n  which will be lambda upon lambda minus s rise to n so  the idea was that you were computing it at s so  therefore  it got written there so  this is actually lambda upon lambda minus s rise to n let us look at it in an alternate way  and that is also interesting so  let us just be very clear about this n t greater than or equal to n if and only if s n is less than or equal to t  that is if the number of arrivals by time t greater than or equal to n then  the time s n for the nth event to occur is less than or equal to t and vice versa that is if s n is less than or equal to t then it will imply that n t must be greater than or equal to n so  when you want to compute the distribution function of s n  this is probability s n less than or equal to t  which because the 2 events are the same  this is probability n t greater than or equal to n and so since n t is poisson distributed  a poisson random variable with lambda t as the parameter so  therefore  this probability can be written as sigma i varying from n to infinity e rise to minus lambda t  lambda t rise to i  upon i factorial now  let us differentiate this equation from both sides  refer slide time  14  18  and  so on the left hand side this will be the p d f of s n  and now here  let us do it term by term so  the derivative of this first so  minus lambda e rise to minus lambda t  lambda t rise to i  upon i factorial  and then the derivative of this  which we are writing as so  first function as it is e rise to minus lambda t in to  lambda rise to i remains as it is  t the power of t becomes  i minus 1 and then i factorial here  which you can you know cancel the i part here  then it will be i minus 1 factorial so  and e rise to minus lambda t i have taken outside then this summation from n to infinity so  i am not writing out many terms here  we just have to show you that you see  when you take n i equal to n  the term from here you will get lambda t rise to n upon n factorial and  this will give to lambda rise to n  t rise to n minus 1  n minus 1 factorial so  these are the 2 terms now  put i equal to n plus one so  this will be minus lambda  lambda t rise to n plus 1  n plus 1 factorial  plus lambda n plus 1 t rise to n upon n factorial so  you see this cancels with this  and then i thought  i will also write the values corresponding to i equal to n plus two so  then that will be lambda  lambda t rise to n plus 2 upon n plus 2 factorial  plus lambda n plus 2  t rise to n plus 1  and n plus 1 factorial so  that cancels out this so  you can see the pattern first  and the fourth here then the third and the fifth sixth and so on so  all these things will cancel out except this because  this is the lowest degree term after that the powers of t keep on increasing so  this is the only 1 which is left out all these will cancel out and  so you are left with e rise to minus lambda t into lambda  lambda t rise to n minus 1 upon n minus 1 factorial  same as 1  which is a gamma density function  gamma n comma lambda so  i just wanted you to sort of you know  make use of this also and therefore  you can even do it directly so  once when you generate  so many tools  it is always possible to prove result by more than 1 way  and it also helps gives you a better insight  if you can do that so  then expected value of s n will be n upon lambda  and variance s n will be n upon lambda square now  we will further prove some more properties of the poisson process  and then you know work out examples to show you how you make use of these all these machinery  that we have developed now  for example  if you take a poisson process n t  t greater than or equal to 0 then they can and they can be 2 sub processes if you remember while discussing  the joint m g f i talked about poisson process  and then i said  that if all the events that are occurring are being counted then they the probability of an event being counted was p  and event not being counted was 1 minus p and then i showed you through the m g f  that each of them  each of these process again would be a poisson so  see while talking about the poisson process  having 2 sub processes  which we call type 1 and type 2 and  so the probability that the type 1 would have occurrence with occur with probability p  and type 2 with occur with probability 1 minus p so  i have already so  the only correction i want to make is that see here  you n t is lambda p t  because we are talking about with respect to t so  then we are talking of arrival time arrival rate in the interval 0 to t so  now  here similarly your n 1 t will be then poisson  and this we showed through m g f processing of we showed that it can be both will be again poisson so  the sub processes n 1 t would be poisson lambda p t  and n 2 the process type 2  which will be so  the random variable is n 2 t will be poisson lambda 1 minus p t so  the we have to attach so  what i wrote in the lecture was  without the t part everywhere here so  this is what the correction is being made  otherwise i have explained  what we mean by these sub processes and so on in the lecture itself  so exactly the same thing  but here again i will do this  i will try to prove the same result by using the machinery that the definitions that we have made here i will try to do that because the m g thing we know so  here it is saying that the 2 types of ; that means  you must be considering  let us say immigrants from another country  and the immigrants may be hindus  muslims whatever it is so  therefore  the total process of immigrants coming from another country  may be a poisson process and then the kinds of people that are arriving  you may want to separate them into 2 streams one may be let us say hindus  the other may be muslims so  there will be type 1 arrival and the probability of 1 of the arrival immigrants being hindus is probability p  and the 1 minus p is the probability of the immigrant being muslim  refer slide time  20  23   so  we will now  prove it in a different way  in an alternate way so  as i said the proposition is that there is a poisson process  and n t is the number of arrivals in time up to time t then if there is type 1 and type 2 processes  sub processes and  so type 1 process ; that means  the type 1 event occurs with probability p  and time and the type 2 event occurs with probability 1 minus p we want to show that n 1 t is poisson with lambda p as the parameter  and n 2  n 2 t is poisson with parameter 1 minus p lambda we want to show this and as i told you  that we have already shown this result using m g f s joint m g f  but let me do it through so  we will show that n 1 t  t greater than 0 this satisfies your definition 2  which remember we said is more easily verifiable and  so let us do it quickly since n 0 is 0  this implies n 1 is 0 because your n t is n 1 t plus n 2 t if this is 0 then both of them must be zero so  n 1 is 0 now  the other part is that you know  independent and stationary increments so  which can also be easily seen because if i condition this by fixing n t equal to n then  the arrivals here are also you know they only depend on the length of the interval  and are independent of  what is occurred before so  that is the memory less so  by conditioning also you do not change the independent increment  property and the stationary increment property so  therefore  n 1 t satisfies both  now we just want to show that your probability n 1 h equal to 1 so  the property 3 should be satisfied so  let us just look at this event so  if type 1 arrival in time h is 1 then ,we can write this break up this event as saying that n 1 h is 1 given that n h is one so  total arrival is 1 and then n 1 is 1  and so this will be condition this in to probability that n h  n h is 1 all probability n 1 is h and n h is greater than or equal to two so  these are the 2 possibilities  because either n h 1 has is 1 or n h 2 is greater than or equal to two so  this would be this into probability n h greater than or equal to two so  i like the probe because just by basic definition of the process  we are able to show this result so  here see n 1 h is p  and then probability n h equal to 1 is because n is anyway poisson process so  we already satisfy the definition so  therefore  probability of n h equal to 1 is n h plus order h  this when given that there is 1 arrival so  then n 1 h the probability is p plus now again here arrival n 1 h is one so  that probability is p and then n h greater than or equal to 2 n satisfies the condition four also so  therefore  order h right and so  this will be lambda p h plus order h because p see remember  when you say a function is of order like this  then constants are all allowed because  it is only the power of h which is important  it is higher power and so  as h becomes smaller this goes to 0 so  therefore  that p gets absorbed here and therefore  this is it so  this is what ? so  therefore  this satisfies definition because lambda p is the probability now of arrival so  therefore  this will be lambda p in to h  and this n 1 h is greater than or equal to 2 is satisfies because  this probability is less than or equal to probability of n h  greater than or equal to 2 right by the definition because n h is n 1 h plus n 2 h  and since  this is order h so  this has to be also order h so  nice simple proof and i like it  of course  you we have already done it through the m g f method  but that was for a general situation now  here  we are doing it for a poisson process so  therefore  the type 1 and type 2 you can see if you have sub processes  and certainly if this can be extended to more than 2 sub processes so  if you have more than 2 sub processes  each of them and of course  the some of the probabilities must add up to 1  which it will and therefore  you can say that all these sub processes will be independent now  how do i show that n 1 and n 2 are independent  that part is also there that n 1 and n 2 are independent once we have shown and similarly  by this similar by this similar argument you will show that n 2 h is also poisson with parameter lambda into 1 minus p now  you can now use the joint m g f method to show that they will be independent so  this method i use to show that n 1 t will be poisson with lambda p s the parameter and  n 2 will be poisson with parameter lambda in to 1 minus p  to show independence you can use the m g f method  refer slide time  25  52  so  let us look at this example  suppose that people from bangladesh migrate in to north eastern states of india at a poisson rate of  lambda equal to five per day so  the question asked is  what is the probability that the expected time until the 15 immigrant arrives ? so  what is the probability that the expected time until of the expected time that the 15th immigrant arrives ? so ; that means  you are asking for s 15 so  s 15 is gamma 15 comma 5 by the result that we arrived some time ago because  it will be x 1 plus  x 2 plus  x 15 and so  that will be gamma 15 comma 5  and the expected value is 15 upon 5 remember because this is gamma this is n upon lambda so  this will be 15 upon 5  which is 3 days so  the expected arrival time that the expected time until the 15 immigrant arrives now  what is the probability ? that the elapsed time between the 15th and 16 arrival exceed 2 days so  here you are asking for x 16  because x 16 is the inter arrival time between the 15th and the 16 arrival so  you are asking for the probability that x 16 is greater than 2 and  that will be e rise to minus 2 lambda  again this is from your  this is from your exponential distribution because  when you have lambda e rise to minus lambda t  and if you are asking for this thing from let us say a to infinity then  this is  what lambda upon minus lambda e rise to minus lambda t a to infinity and  so this is e rise to minus a lambda so  this is it so  probability x 16 greater than 2 will be e rise to minus 2 lambda  which because lambda is 5 so  this is e rise to minus 10 and  i have just computed the value here  whether you can write this as e rise to minus 2 rise to 5  and e rise to minus 2 i knew the value is 0.133 so  we just rise it to 5 anyway now  if a bangladeshi immigrant is a hindu with probability 1 by 10 then what is the probability that no person of hindu origin will migrate to north eastern region in the month of march just to show you the use of you know the  what we just discussed so  here ; that means  it is lambda p t so  lambda is 5 p is 1 by 10 and the time is 31 days  march has 31 days so  therefore  the no hindu will arrive in that period  again will be e rise to minus lambda t p  which is e rise to minus 31 by 2 and  so you can compute this number so  this is the whole idea and then of course  we will look at some more properties of the poison process  and work out if you more examples  refer slide time  29  01  now  let us look at this example  where we are trying to compute the conditional distribution of n s  given that n t is n so  given that n arrivals are there in time 0 t  and s is less than t so  now  you want to look at the conditional distribution of n s  given that see through all these examples  i am just trying to familiarize you more with the working of the process  and the machinery that we are developing this is the whole idea  and is the process that makes subject quite interesting so  the solution is that and then the of course  it is been asked do you recognize this distribution  once you get once you obtain the conditional distribution  the question asked is  do you recognize this distribution ? so  you have given that n t is n  you have to find the probability  that n s is equal to k given that n t is n so  now  that means  if up to time 0 s the arrivals are k  and up to time t the arrivals are n so ; obviously  the number of arrivals in time t minus s is n minus k that is  how it will make up the number of arrivals up to time t as n so  time s the number of arrivals is k  and then in the interval s 2 t  which is the interval length and  by now  we know that we just have to worry about the length of the interval  and not exactly  where that interval is occurring so  the number of arrivals in time t minus s is n minus k so  when you write down this probability  probability n s equal to k given that n t is n this you can write as probability n s is k and comma n t the joint probability of n of t minus s is n minus k condition on the n t equal to n  and since again from the dependent increment property for disjoint intervals  s in to minus s the probability can be written as the product of these 2 probabilities so  therefore  this will be the product of these 2 probabilities  the numerator and the denominator will be probability n t equal to n so  i suppose i hope this is clear so  therefore  e rise to minus this probability is e rise to minus lambda s  lambda s rise to k upon k factorial  and this probability will be e rise to minus lambda t minus s lambda t minus s rise to n minus k upon n minus k factorial  divided by e rise to minus lambda t  lambda t rise to n upon n factorial so  as long as this part is clear that when you see this probability of course  i can write in this way and in this i can write as the product of these 2 probabilities and  so now  you see that this is e rise to minus lambda s  and here you get  e rise to plus lambda s  which cancels out then e rise to minus lambda t  and in the denominator you have e rise to minus lambda t so  the e terms all cancel out  and you are left with so  this n factorial will come in the numerator so  the first term that i have written is n factorial upon k factorial n minus k factorial  this all put together and then you have lambda s rise to k  and lambda t minus s rise to n minus k  divided lambda t rise to n so  this is what i have written here so  this whole expression simplifies to this and  now here what you can do is see again the lambda rise to k and lambda rise to n minus k is lambda rise to n  which cancels with lambda rise to n here so  you are left with s by t rise to k now  the t rise to n  i can write this as k plus n minus k so  the k t rise to k couples with this  which is s upon t rise to k and this here it will be 1 minus s upon t rise to n minus k so  see that now you can recognize this  if you treat p equal to s by t then this is a binomial probability  when we are choosing k items out of n ; that means  you are asking for k successes out of n trials and  n independent trials  and your probability of success is s by t the more important thing is that this whole expression that the conditional distribution is independent of lambda ; that means  no matter what the parameter of the poison process is these conditional this conditional probability is independent of lambda it is only dependent on the length of the time intervals ; that means  here it was n s and there it was n t so  that s and t so  i am sure there are many more interesting implications of this result  but again know you can get it nicely  by just using the definitions and so on  refer slide time  34  29  now  let me again take up this interesting optimization problem  and here again the machinery is not very complicated suppose that items arrive at a processing plant in accordance with a poison process with rate lambda  so that means the items are arriving at the you know  at the gate of the processing plant  and arrival process is poison with rate lambda now  at a fixed time all items are dispatched from the system so  the items get processed and after if time t  when they all collect they are dispatched to they came now  the problem is to choose an intermediate time t  belonging to 0 comma t  at which all items in the system ; that means  all the items which have been processed by time small t they get dispatched and then the remaining  which get processed from time t to t they will be after being processed they will be dispatched so ; that means  they have now they are not going to wait till the end of up to time t so  in between also they would like to dispatch the items  and the idea here is that this will this way  they want to minimize the total expected wait time of all items so  total expected waiting time so  this is what we have to write down the expression and then see how we minimize so  the choice of small t ; that means  the intermediate time at which you want to dispatch  whatever items have been processed  this is that has to be fixed that has to be sort of obtained by this process so  expected number of arrivals in 0 t is lambda t  remember because this is poisson with parameter lambda so  therefore  in time 0 t the expected value is lambda t and  each arrival is uniformly distributed remember  i some time ago discussed when you are looking at the poisson process  and it is properties and we said that because of the stationary increments  when the number of items that arrive in this time  they would be uniformly distributed  over the randomly distributed over the time interval 0 so  therefore  in time 0 t the expected any uniform variable distributed over 0 t has mean t by 2 so  the expected wait time is t by 2  all items which start getting processed from here till up to this so  their expected wait time is t by 2  because we have said that the  you know  the processing is uniformly done i mean in the sense that the processing is not uniformly done it is that is they arrival so  is distributed the arrivals of these items is distributed uniformly in the interval 0 t so  their expected wait time is t by 2 because they will be dispatched by the end of this time period now  so total expected wait of all items arriving in 0 t is therefore  lambda t into t by 2 so  expected wait time of any item is t by 2 because  they are uniformly distributed in this interval the items and therefore  for each of them the wait time is t by 2  and since the expected number of items that arrive in this time is lambda t so  the whole thing is lambda t into t by 2  which is this now  the similar reasoning holds for items arriving in time t to t comma t  and therefore  for these items because they will get dispatched at time capital t so  the total expected wait time will be therefore  lambda t square by 2 plus half lambda t minus t whole square so  i hope this part is clear  and this reasoning is because expected wait time into the expected number of items that arrive so  that gives me the total expected wait time of all items arriving in time  in the interval 0 t so  to minimize that to find out the minimizing value of t  i differentiate this expression with respect to t  and i get lambda t minus because there is a minus here so  2 is gone so  lambda t minus lambda t minus t is 0 and  this gives me t equal to t by 2  as you would expect because  the arrivals are uniformly distributed over the time interval  and just to make sure that this is the minimizing value  you find out w prime t and w prime t will come out to be 2 lambda  which is positive so  therefore  this gives you the minimizing value so  therefore  it says that you dispatch whatever items gets processed  in the middle of the time and then wait for the others to be processed and dispatch them at t simple which appeals to your reasoning also  but then through this machinery also we have arrived at this result  refer slide time  39  48  so  before i begin  you know  talking about queuing models  i thought  i will finish off the lecture on poisson processes with this example on exponential distribution because  it is somehow related and part of it and  so and this would be the right place to talk about it  because we have talked off exponential of the poisson process and  we have talked of people expected number of people in the system and so on and then because the inter arrival times had we have shown that each of them were identically independently distributed as exponential random variables so  i thought this would be also this can be part of it so  here the whole idea is that and of course  this is a simple example on the memory less property of the exponential distribution so  consider a railway booking counter  that is run by 2 clerks suppose that mister sharma enters the system he discovers  that mister jain is being served by the clerk at 1 counter  and mister varna is being served at the other counter so  both the counters are busy  when mister sharma enters the system now  mister sharma service will begin as soon as either mister jain or mister varna leave the system that whenever as soon as 1 of them is completes service  they will  he will leave the system and then mister sharma ’ s turn will come to be serviced by the clerk so  if the amount of time a clerk spends with a customer is exponentially distributed  with mean 1 by mu ; that means  the parameter of the exponential distribution is mu and  therefore  the mean time that a clerk spends with a customer is 1 upon mu  what is the probability that of the 3 customers ’ mister sharma is the last to leave ? so  of course  here mister sharma will only get serviced once 1 of the customer is left so  the actual question is that when mister sharma ’ s turn comes for being serviced there is 1 person 1 of mister jain or mister varna 1 of them is being serviced and  so mister sharma goes to the clerk for getting his job done  and then the idea is that who will leave the system first ? so  suppose mister jain is being serviced while mister sharma goes to the clerk because mister varna has left so  the question being asked is  what is the probability that mister sharma would still be in the system ? when mister jain leaves ? so  essentially you are asking  who will be the first 1 to leave ? either mister jain or mister sharma mister varna has already left so  but exponential distribution is memory less so  therefore  how long mister jain how long more  will mister jain take is independent of ? how long he has already been at the counter ? because we have said that it is memory less and therefore  the service gets completed is not dependent  on how long it will take for the service to be completed ? it has not depend on  how long he has already been serviced and so  therefore  its equally likely that either mister sharma will complete his service  before mister jain or mister jain will complete i am just assuming that mister jain is still in the system mister varna has left  but you can do it either way so  therefore  very simple you know use of the memory less property of exponential distribution and  so therefore  the probability of mister sharma leaving last is half  because it is equally likely  whether mister jain completes his service first or mister sharma completes his service  because of the memory less property so  i thought this will just add to the poisson process  and the other systems that we have been talking of birth and death process ; that means  when you have people arriving at a service station  and then they are being serviced and  so then we want to talk about  the you know number of people average number of people in the system then what is the average waiting time ? and so on  refer slide time  44  15  i would like to take this further because once we have been able to compute  you know arrivals  if we have been  we have discussed the poisson process one of the arrival processes is under these conditions that we have laid down and  then now  we want to look at you know for example  you have a service center  and there you have people arriving for service then you have people providing the service  and then that process is also random so  now  you want to combine these 2 and therefore  the whole the theory that you  when you study such processes is known as  queuing process and  then you want to for example  know when you have a post office you want to know  because if the average number of people arriving in the post office is large  then you would want to 1 clerk may not be enough to serve everybody and  you would and then facility how they should be and so on so  the very interesting question  but of course  we will study them at very basic level so  it will be the queuing process is where you want to compute the average waiting time of a customer you want to compute the average service time of a customer  then you want to look at the average number of people they are at any time there are in the system and so on so  such interesting questions we would want to answer and therefore  we will model the situation  where you have people arriving for service services are being rendered  and then people leave the system so  the whole thing we would want to study  and this we will try to do in the next couple of lectures introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  34 queuing models m/m/i birth & death process little ’ s formulae  refer slide time  00  15  so  i had to wait for this example  you know to discuss this example  because i had not worked on the when we talked of weak law of large numbers and strong law of large numbers  i have not  you know talked about the poisson process so  i waited till i had  you know introduce the topic of poisson process to give you this example in fact even when we are talking of law of large numbers i had shown you some examples so  this is also one of them ; one of interesting example now  here you see inter arrival times are exponentially distributed with mean 1 by lambda  right ; because the arrival rate is lambda so  we have shown that the inter arrival times will be exponentially distributed ; and the mean time would be  that means  inter arrival time would be 1 by lambda so  that means average waiting time between 2 occurrences is 1 by lambda ; and so the number of arrival  mean arrival weight is lambda  right so  hence in a time interval of length t we should expect around lambda t occurrences  right ; if lambda is a mean arrival rate  so therefore per unit times so  therefore  time interval t ; you were expect on the average lambda t occurrences  lambda t arrivals  right so  then and since our notation for the poisson process for the number of arrivals up to time t is n  t   so  therefore  we expect that n  t  and lambda  t  should be close  and this is what the weak law of large numbers and strong law of large numbers is all about so  let us just look at this  and we will show that  yes  the ratio of n  t  by  this will be n  t  by t would be close to lambda  right ; because if you want lambda  t  to be close to  n  t  to be close to lambda  t  then n  t  upon t should be close to lambda ; this is the whole idea  refer slide time  02  27  so  let us look at the proof  interesting now here  i should have written the word proof here now  let t be some positive time  right ; and then we want to show  i said it is the  we want to show that the limit of n  t  upon t  n  t  goes to infinity is equal to lambda so  this probability is 1 ; that means  this is the certain event so  as you take the limit and your law n  t  to grow large  then your ratio n  t  by t would be lambda now let us look at the proof so  see  this is the thing ; now for the poisson process when we are looking at the arrival process  and so on  then my s n  t  is the movement of the n  t  th arrival upto time t this is what we have been denoting and later on when i discuss the death birth and death process at that time s n  t  was the  you know  time arrival  because remember i was looking at the waiting distribution for the waiting time in the q ; and then i also used the symbol s n  t   but that time it was the waiting time for the n plus 1 th arrival ; that means  s n  t  denoted the time at which the n  t  th service got completed  right so  here it is s n  t  is the movement of the n  t  th arrival upto time t so  i hope the reference to the context the things will be clear because here we are only talking of the  and i have not introduced the waiting time and so on  upto this point so  therefore  it should be ok so  s n  t  is the movement of the n  t  th arrival upto time t and therefore  s n  t plus 1  will be the movement of the n  t plus 1    refer slide time  04  17  so  the inequality that we are writing here  s n  t  less than or equal t less than or equal to s n  t  plus 1  should be actually replaced by s n  t  less than or equal to t and strictly less than s n  t  plus 1 since n  t  th arrivals have occurred upto time t  and n s t is the time of the n  t  th arrival  and so therefore  when the s n  t   when the n  t  plus 1 th arrival occurs that will be the time n s  t  plus 1 so  that will have to be bigger than t so  want to make that clear  and that is why this should be replaced by the strict inequality here ; that is because we say that s n  t  is the time at which the n  t  th arrival is occurred  and upto time t ; and so s n  t  plus 1 the time arrival for the n  t  plus 1 th arrival will take  will be more than t  right after t  refer slide time  05  21  in that arrival ; in fact  i would understanding is that  you know  n  t  is the max of n so that s n is less than or equal to t ; so that means  upto time t we do not expect  there no more arrival then n  t  ; and therefore  this inequality is valid ; that means  t is greater than are equal to s n  t   but if there is one more arrival then certainly that time will x e t ; this is the whole idea  right so  upto time t  s n  t  is the number of  the movement of the n  t  th arrival this should be n  sorry ; should write here is this is n ; so that means  the time of the n  t  th arrival has to be less than or equal to t  but n  t  plus 1 th arrival will exceed the time t so  this is the understanding  right so  with this understanding you now divide the both the inequalities by n  t   and therefore  you get s n  t  by n t less than or equal to t upon n  t   this is less than or equal to s n  t  plus 1 upon n  t   right or  remember the x size are the inter arrival times so  therefore  you  s n  t  will also be equal to x 1 plus  x 2 plus  x n t so  when you add up the inter arrival times they will all add up your s n t so  sigma i varying from 1 to n  t  sigma x i divided by n  t   and this is less than or equal to t upon n  t   then this is  this  here the summation will go upto n  t  plus 1 so  you will add up the inter arrival time for the n  t  plus 1 of the arrival  upto this thing so  n  t  to n  t  plus 1 th  the arrival this will be this  right now  sigma x i s are independent  remember we have shown this ; we get the poisson process  poisson arrival process ; then the inter arrival times would be exponential distributed ; and they are independent identically distributed  each has the mean 1 by lambda so  then the conditions for your law of large numbers is  are satisfied and therefore  by the strong law of large numbers  sigma x i vary from 1 to n  t  divided by n  t  will converge to 1 by lambda with probability 1 this is our strong law of large numbers and since  this is also the same series  you know  n  t  plus 1  but you are allowing this go to infinity you are allowing n  t  to go to infinity ; so therefore  this and this have the same limit which is 1 by lambda  right  the mean of x i with probability 1 and so by the sandwich theorem  because here  you see this is converging to 1 by lambda  so t by n  t  has no choice  it has to converge to 1 by lambda and so therefore  by the sandwich theorem  limits t upon n  t  will converge to 1 by lambda with probability 1 ; or n  t  upon t will  because we have taken t to be positive  so n  t  by t will converge to lambda with probability 1 so  therefore  you know  for the poisson process ; so now  again as i told you that the situation for the law of the large numbers is basically used to estimate the mean of the population and so you go on making observations  and we say that the observations are independent identically distributed because they are coming from the same population so  then the average  we expect the average to converge to the mean of the population so  here also the same thing for the poisson process ; what we have shown is because n  t  is the number of arrivals in time t  so this ratio will converge to lambda  the mean arrival rate and therefore  you can go on observing the values  number of arrivals in a particular time  and then upto time interval t  and the ratio will converge to lambda so  if in case your lambda is large then you will have to make the observations for a longer time period because your n  t  will have to be sufficiently large ; and therefore  that of course  make sense so  therefore  this gives you a good way of wanting  trying to estimate the value of lambda  refer slide time  09  40  so  the queuing model i am going to talk about today is m m 1  it is called m m 1  and i will explain in a while why we call it m m 1 so  here the whole idea is that you have a source from which your customers are coming to some service facility ; there is a queue so  these indicate the customers who are waiting in the queue for to be serviced ; you have a service facility and then again it will depend on what kind of service facility you have and so the customer ; so one by one a customer comes here  get serviced  then exists from the system after his service  his or her services is completed then the next one in the queue comes to be ; so this is i am describing the situation when there is only one service facility or one clerk at a counter or something ; if there are more than one  then of course  the movement one of the clerks is free the  a person waiting in the queue will go and get serviced  right so  whatever it is  the service facility  the customers come  they get serviced ; and once their service is complete we expect that they leave the system ; so they are out of the system now  here  in order to discuss the model we first  so we need to specify the arrival pattern of the customers  right so  this can be either specified by the arrival rate and the distribution of the arrivals because remember the whole situation  the thing  that the scenario is that the events are unpredictable so  we do not know when a customer will walk in also we have no idea  the service times are also unpredictable so  therefore  everything has to be modeled through these probability distributions and so we will either specify the distribution of the arrivals  just as in the poisson process we say  that the arrivals are coming at a rate whatever the rate is lambda  and then they are being modeled by the poisson distribution ; and or we give the specify the distribution of the inter arrival times which we saw that if the arrivals are following a poisson distribution then the inter arrival times will be exponentially distributed and then we had  in the last few lectures we have talked about in detail what  under what conditions we can say that the arrival pattern can be modeled by the poisson distribution  right ; so stationary increments and then independent increments and so on ; and then that the probability of arrival in a small interval would be only lambda times the length of that interval  and so on so  there are huge lot of conditions under which we said that we can then model the arrival pattern by the poisson distribution  right then you have the service facility ; and here of course  you can specify the distribution of the service times as i said that it is not fixed operation each customer may take different amount of time  and so on so  we have to ; and then of course  you need to specify the number of servers so  basically if you have these 3 things specified then your queuing model is there ; and the m denotes the exponential distribution of inter arrival times  memory less this is the property or markovean which we will again when we later discuss markov processes  we will see that morkovean process is also have memory less property  right so  inter arrival times are exponentially distributed ; and x service is also  service times are also exponentially distributed so  therefore ; and then one server so  first we will discuss the case when the  this is only one server at the server facility and latter on we will try to generalize the  now s is to more than one server  refer slide time  13  58  now  just tells the specified the conditions under which we can model the arrival pattern by the poisson process  we need to look at conditions under which service times can be modeled as exponential distribution  by an exponential distribution now  if your server is performing fixed  some fixed sequence of operations for each customer  then certainly this is not memory less because  if the customer  if these clerk has to perform 10 operations  sequence of 10 operations for every customer then he is up come up to the this thing  task  then we will know that he is going to finish after next 2 so  the sort of  one can assess the time taken for example  if a server has come up to this point  i mean this task is performed  then we know that he will finish these 2  and so the time at which this service will end depends on how far he has been already with the customer ; how far he has been servicing the customer so  therefore  they are certainly not a case for modeling by exponential distribution  right ; because this is some sort of a fix sequence of operations so  therefore  here also we will have to be  basically it will have to be the memory less property if you can somehow justify that the service facility of the situation that you are modeling has this property then it will be  you know  safe to say that yes we can model the service times by the exponential distribution  and so on  right so  then and the state of the system we will always specify by the number of people in the system ; and then p n will be the probability that there are n people in the system so  you can see that it is people coming for service  after being service they leave the system so  it is  you know  our constant state of changing  because people come and go so  p n is a probability that there are n people in the system so  therefore  in time   0  t  ; yeah  here i should i have underlined this  but i sort of missed it right now so  the whole thing is being discussed under steady state situation so  now  what we are saying is that suppose there is a new restaurant that is opened in the locality then you know  the number of arrivals would vary from day to day  and there will be no set pattern for some time till people sort of get used to that restaurant or they make it a habit of whatever it is ; and there are steady number of customers who comes to the place to the restaurant so  therefore  what we are saying here is that the we are discussing all this  when the system has settled down the tabulations are all over  and it is only steady state ; that means  the probabilities have also settled down  and so on so  under steady state we are discussing the modeling of this  modeling the queuing the situation  ok so  therefore if p n is the probability that the n people in the system  but in time  0  t   so  this total time for which the system is in ; see  you can also look upon p n as the proportion of time for which the  for a unit time  proportion of a unit time in which this system is in state n ; that means  the n people remember because this is the probability  and so this is the fraction  and therefore  we are saying the fraction of time that people  the n people in the system  right and therefore  over the time interval   0  t   we will say that the total time for which the system is in state n  sorry  is not p n ; is in state n  it is p n t  right so  approximately we will say that proportion of time that there are  in this time interval proportion of time for which there are n people in the system is p n t and therefore  and number of arrivals in  0  t  that find the system in state n is roughly  lambda p n t so  we are talking in approximations and right  because the arrival rate is lambda so  the number of arrivals in  0  t   that find the system in state n would be  lambda p n t because they are lambda arrivals in a unit of time and so i mean the arrival rate is lambda so  and this is also called a birth and death process because birth refers to a new arrival to the system and death refers to a departure of from the system so  therefore  each the departure is treated as a death and each arrival  new arrival is treated as a birth so  this is also called as a birth and death process and so this birth and death process under the assumption that your arrival rate is a  process is poisson  and the service time the exponentially distributed  there is one server so  if you  diagrammatically you can describe the situation here  of the birth and death process you begin with state 0  no people in the system  then 1 arrival takes place ; should be lambda and so you go to state 1 but from state 1  you can reward back to state 0 if the departure  and that is for this so  we are saying that the exponential  the service time is exponentially distributed with rate mu  right and then again when you are in state 1  it can go to state 2 by arrival and can reward back to state 1 because if there is a departure  and so on so  that means  at each state  n minus 1  for example  you can go to the next state  and from this you can reward back to the old state ; and so therefore  this make sense that you will  this proportion of time you will be in state n  right ; because the situation keeps changing so  let us further analyze the  you know  arrival pattern  mean arrival  average arrival time  average waiting time  and so on  refer slide time  20  17  you see  when i made the statement that we are considering the system  the queuing system in steady state  so we actually i just remain that this limit probability of n  t  equal to n as t goes to infinity is p n so  this is steadying down and of course  t going to infinity is the analytical we are saying it  but essentially for a large time this system has operated and then it is settled down to steady state  that is what you mean so  these are the limiting probabilities essentially of the system so  and then for example  if you say that p 0 is 0.3  then in the long run  system will be empty of customers 30 percent of the time  right again  you know  because these are all probabilistic statements ; what we are saying is that if your p 0 is 0.3  then long run if you observe the system then you will find that 30 percent of the time the system is empty and that is what we meant when i said that p n t is the proportion of time so  this is again in the long run when you  p n t will be  approximately we proportion of time for which the system has n people in the system  the system has n people  n customers and users whatever it is so  this is the idea so  and similarly if p 1 is 0.2 then the system has 1 customer  20 percent of the time  even if you observe it for a long and so approximately for time t  we can approximately say that this is the proportion of time that the system will have n customers  fine now  we want to start getting some more  you know  we want to get some  make some computations regarding this queuing system and so we will use this concept of balance equations what we mean is therefore  each n greater than 0  the rate at which the process enters the state n  equals the rate at which it leaves state n so  this is also part of the system that  condition under which we are modeling the situation or the process so  what we are saying is that the balance is maintained in other words  what we are saying is that if you are state 1  you see  then you are leaving it here  by  because 1 more arrival has come ; or you are leaving state 1 because 1 person has been serviced so  this is how state 1 changes ; either 1 more arrival  or 1 death or 1 percent leaving the system and then again the way state 1 is reached is also from state 0 when there is a one arrival at this  so then you come to state 1 and here again  you come from state 2 when there is a departure here at this point so  this is the idea so  at each state of the system you have ; so for example  when you are at state 0 then this is the rate at which lambda p 0 so  this is the rate at which the system leaves the state 0  right ; because it is state 0 then lambda arrival ; i mean the mean arrival this is  i should not say mean ; the rate  arrival rate is lambda ; therefore  lambda into p 0 this should be  this is rate at which it will leave the system see  the system right now is in state 0  so it will leave  the system leaves that state at the rate  lambda p 0 and from p 1 it arrives to state 0 at the rate of mu p 1 and therefore  the 2 must balance so  the rate at which it changes its state from 0 and arrive at 1  and the rate at which it leave state 1 and arrives at 0 is mu p 1 so  the 2 must equal now  if you are in state 1 arrival describing you  then you see it is the 2 ways it can leave  either 1 more arrival or 1 departure so  therefore  lambda plus mu into p 1 because remember that 2 processes we assumed are independent ; service process and the arrival processes are both independent so  therefore  i can add up the these rates so  and this will be lambda plus mu into p 1 this is how it will leave the system p 1  the state p 1 and  if it is p 2 then it can again come back to p 1 at the rate of mu p 2  and here from p 0 it can come to p 1 at the rate of lambda p 0 so  therefore  we departure from state 1  the arrival to state 1  the rate at which these 2 things happen must be the same  right and so in general again same thing  that n for example  you are leaving it again because this arrival and you are leaving it because there is a departure so  therefore  these 2  lambda plus mu ; and then you are coming to state n through n minus 1 at the rate of lambda p n ; and then you are  sorry  p n minus 1  lambda p n minus 1 and then here you are coming from n plus 1 at the rate of mu p n plus 1 so  therefore  in general you can write this now  here of course  if i am only considering a very simple form here because you can also have a situation where your lambdas are also dependent on the people in the system but  we are  see  because that can happen some places where it is not a very essential service if the places crowded for example  if a restaurant  people may not want to wait and they will leave the place because you can go elsewhere to eat  right so  then you are  lambdas would be the arrival rates  would also be dependent on what state the system is in and similarly the mu s can also depend on your  the number of people there are in  the customer they are in the system so  these can be different for different states of the system  but i am right now considering the most basic case where all the lambdas ; so these are not dependent on the number of people in the system ; similarly the mu is not dependent on the number of people in the system so  the service rate continues at the same p ’ s so  now  if you solve these equations ; see here  immediately you get the p 1 is lambda by mu p naught so  let us get all these p ’ s in terms of p naught and then similarly from here if you substitute for p 1 from here then mu p 2 would be lambda plus  mu into  lambda by  mu p naught minus  lambda p naught  this goes this here  refer slide time  27  45  and then if you simplify you get the p 2 as lambda by mu whole square into p naught so  in general your solution to these equations  these balance equations is p n is equal to lambda by mu raise to n times  p naught so  all  for all n this will be the formula ; that means  this just lambda by mu raise to n p naught  right now  we can obtain p naught by using the fact that all these probabilities must add up to 1  right the system must be in one of the states from 0 to infinity and therefore  when you add up this you get this as a geometric series ; p naught is outside with common ratio lambda by mu and so p naught is 1 minus lambda by mu  because this sums to 1 upon  this series sums to 1 upon 1 minus lambda by mu  right ; so therefore  p naught for the 1 minus lambda by mu now  first this is valid only  this series converges provided your lambda by mu is less than 1 because otherwise it will explode and you can also see  of course  mathematically you know that this series will converge only if lambda by mu is less than 1 if lambda by mu is not  is greater than 1 or even equal to 1  then this will not converge so  the sum will explode and so what does it mean ? see here  when you say that lambda is less than mu  that means  lambda is less than  sorry ; lambda by mu less than 1 that it implies that lambda is less than mu  right and so this is the service rate and this is the arrival rate so  obviously  you expect that otherwise people will go on collecting in the system if you are service is lower than the rate at which people are coming or  in other words  the better way to look at it is  that 1 by mu is less than 1 by lambda so  mean service time is 1 by mu  remember  because it is exponential mu so  therefore  the mean time is 1 by mu so  mean service time is 1 by mu now  this should be less than ; and 1 by lambda is the mean time between arrivals  remember  because if the arrival process is poisson with rate lambda then the inter arrival times are exponential with rate with parameter lambda and therefore  the mean time between 2 arrivals will be 1 by lambda so  in general you expect that 1 by mu should be  that means the service  mean service time should be less than the mean time between 2 arrivals  right so  therefore  then only you expect this system not to explode ; that means  the queue will not explode and you will be able to process the customers faster than they come ; i mean in lose way you saying that it will not happen  right so  therefore  this makes senses that  and so once you get your p naught as 1 minus lambda by mu  from here you get that your p n as lambda by mu raise to n into 1 minus lambda by mu for all n so  therefore  nice way we have been able to compute the probabilities for the different states of the system  right  under these assumptions and  many more ways of explaining this  but basically the whole idea is that they should be ; even otherwise from here you see  you can just see that p naught being finite must be because it is a probability of empty system then if lambda is greater than mu and this will go on becoming larger and larger so  here they will be a positive probability for  you know  n being  well  this is yes  yeah  because p naught will take with p n can not be  but what i am saying is there will be a positive probability of the system becoming  you know  number of people increasing in the system because  lambda by mu raise to n  if lambda is greater than mu  then that will be become  this start becoming a big number  fine now  if you want to find out the average number of customers in the system  so therefore  you want to know that at any point of time  what is the average number of people and mostly when you design a facility  you base it on the average number of customers in the system because you should at least be able to cater to the average number of people in the system ; and then of course  there can be variations so  that means  l here is  we will define so  l is the average number of people in the system ; and so this will be sigma n p n vary from 0 to infinity because the probability of there being n people in the system is p n ; so n into p n the expectation of this p n  i mean of the variable denoting the  or we can say that may be l n is the  this thing random variable whose probability is n so  or we have been  sorry ; you can  we have been denoting it by  but that was n  t  ; so does not matter let us just keep it that  this way so  sigma n varying from 0 to infinity n p n  will give you the average number of people in the system so  here substitute for p n and since this is not  this is independent of n  i will just concentrate on this so  let me call this series  sigma n lambda by mu raise to n  0 to infinity ; let me call this s so  i just write it out  you know  like this then i multiply this by lambda by mu s ; and i just  because  see  the infinite term in the series i can start writing this from here  does not matter ; this sum i can just  you know  slip 1 position  and so i start writing it from here and again  both the thing are x turning to infinity now  when you subtract this from here  it will be 1 minus lambda by mu s and here you see  this is 0 ; so this is lambda by mu ; then this is 2 lambda by mu square ; and this is lambda mu by  lambda by mu whole square so  therefore  the difference is again this and this is  you know  anyway  from those of you who are familiar  known that this is an arithmetic co geometric series  yeah so  the terms are  the first term is changing as an arithmetic progression  and the second term is changing as a geometric progression or coming from a geometric progressions ; so arithmetic co geometric series  fine so  the way to sum up such a series is that you write down s and then you write down lambda by mu s  just slip to writing the terms from  you know  second position for this you write start writing from second position  and then you get  the difference comes out to be geometric series and therefore  here the first term is lambda by mu  so i will write lambda by mu into 1 upon 1 minus lambda by mu  right so  if your s is lambda by mu into  because this is this  so 1 minus lambda by mu whole square  right and so your l  because l had a  1 minus lambda by mu here so  then that will get canceled therefore  the average number of people in the system is lambda by mu upon 1 minus lambda by mu and so here you see that even if this is large  atleast if this is close to 1 ; lager distance of course  because we can not come to this expression if lambda is greater than mu ; then this does not  i mean we can not even talk about the average number of people in the system because a system would be explored it so  lambda by mu less than 1 ; if it is close to 1 then you say this number is small ; and so 1 upon this will be very large ; and therefore  again the number of people in the system we will be very large so  this definitely gives you the idea is to how  you know  the lambda by mu has to be small for efficient service and if you try  if you not able to keep lambda by mu much much smaller than 1  it will certainly will be  there will be times there will be chaos because this is only talking about the average number of people in the system  right so  therefore  this gives you an idea that if lambda by mu is reasonably small then this number will also be reasonably small ; and so most of the time  i mean on the average you will expect  that there will be not too many people waiting to be serviced  refer slide time  37  09  so  now the other characteristic of a queuing  of a good queuing model is that the amount of time a customer spends in the system should not be very high so  therefore  we want to now estimate the average amount of time a customer spends in the system so  again that will depend that will be a function of lambda and mu ; your arrival rate and the service rates  right so  let us find out this now  if an arrival finds n customers in the system  the arrival will have to wait through  n plus 1  exponential service times because n people are already in the system  and he or she is the  n plus 1  th arrival in the system so  there is  then before the  n plus 1  th arrival leaves a system  that means   n plus 1  services have been completed  right now  the thing is that there is already 1 customer being serviced because there are  n minus 1  people in the queue  and there is 1 person who is being serviced but  because of this memorialized property we can not say that  you know  this service  how long he has been at the counter  and therefore  how long he will takes more ; we can not say anything about it ; that is as much unpredictable quantity as when he started the service so  therefore  because of this memorialized property i have to count that also as 1 full service ; and therefore  we have saying that they will be   n plus 1  service is to be completed before this arrival who finds there are n customers in the system  finally leaves the system  right ; so therefore  your  s n plus 1  will be t 1 plus  t 2 plus  t n plus 1  and varying from 0  1  2  and so on so  this is the  and this is the conditional waiting time given there are n customers in the system  right ; because  s n plus 1  means your conditional waiting time given there are n customers in the system  and therefore   n plus 1   services have to be completed now  we know  since the service times are exponentially distributed we know that some of these  n plus 1  exponential identically independently distributed exponential random variables will be gamma  n plus 1  mu   so  the same parameter  but since they are n 1 of them so  this becomes a gamma  n plus 1  mu  ; here s n plus is this and so when you want to compute the probability that the average waiting time is greater than t  or that is the expected value  expected waiting time then this is sigma n varying from 0 to infinity  t n so  conditional probability ; remember  this is conditional so  p n into s n plus 1 greater than t so  you will write this as  this is probability that s n plus 1 is greater than t so  you are services the  n plus 1  services take more than t time to be completed and the probability that the n people in the system then only  n plus 1  services have to be completed so  this is sigma n varying from 0 to infinity so  substitute for p n  then you will get  lambda by mu raise to n  1 minus lambda by mu into  probability s n plus 1 greater than t so  this you can write as  1 minus f w t because this is if i am saying that f w is the distribution function of w ; and similarly  f n plus 1 t  i am denoting as the distribution function for s n plus 1 so  therefore  this is what i can write now  i can just differentiate both sides so  this of course  is 0 ; i get the ; so the minus sign  minus sign will cancel out  because so this is not a function of t  refer slide time  41  09  so  here this will be minus and minus that will cancel out ; and what you will get is that f w t is equal to this whole thing  and this is your gamma  n plus 1  mu p d f  right ; mu e raise to minus mu t  then mu t raise to n upon n factorial and now let us just simplify so  what i will do is  this is independent of n ; this is independent of n so  the only quantity you see is mu in the denominator here  mu raise to n  and this is a mu raise to n in the numerator so  the two will cancel out  and therefore  simply we left to the lambda t raise to n  upon n factorial ; the other things can be all taken out so  lambda t raise to n upon n factorial  you sum up this from n 0 to infinity and now  this is very familiar series for us ; and so this will be  e raise to lambda t so  therefore  i can combine it with this so  therefore  e raise to minus mu minus lambda t ; remember  mu is greater than lambda and so if you simplify this expression  mu minus lambda upon mu  cancels with mu so  it is  mu minus lambda e raise to minus mu minus lambda t ; and this is exponential  mu minus lambda  right and therefore  you immediately know that the expected value of w is 1 upon mu minus lambda  right and this if you remember the expression for l was  i will not see what was the expression for l  that was lambda mu minus lambda  right so  therefore  the expected waiting time is l by lambda  or what it means is that our average so  this was  the average number of people in the system will be  lambda times t  average waiting time that a customer spends so  and this is known as the famous  should be t here  little ’ s formula so  this is attributed to little who first  you know  get this differentiate between l and w so  this is again you can  we can say out in words so that you do not ; and then if you want to find out the probability that  w is greater than t  then this is we have the p d f for w ; this will be t to infinity  mu minus lambda  e raise to minus mu minus lambda t d t  which we now is this therefore  right ; e raise to minus mu minus lambda t so  what can you say here it has been if you want to say that  yeah ; so this probability that your average waiting time would be greater than t  again you can talk about in terms of mu and lambda  right ; because this is essentially equal to 1 upon e raise to mu minus lambda t so  this  if you want to this probability to be small  then obviously  your mu should be greater than lambda  quite  you know  substantially  so that this probability then is small because e raise to mu minus lambda t would be large  and so 1 upon that would be small and see  all these relationships and this quantities will help you to in modeling very efficient queuing system  and depending on what parameters you consider important you can accordingly concentrate on those  and then accordingly you know design your system so that you are mu and lambda conform to that so  that in the sense that if you want your l to be small  that means  you do not want its place to be crowded all the time then you concentrate on this and if you  it is important that people should not have to wait for a long time then you will concentrate on this  right ; but the 2 are related so  l is equal to w  and therefore  you can say if you concentrate on this  you concentrate on this  depending in respect to lambda now  the other quantity would be expected queue length see  l was the expected number of people in the system which includes the person being serviced  but now here you are talking about expected queue length ; and so that will be n minus 1 into p n because if there are n people in the system  1 person is being serviced  so then the number of people in the queue are n minus 1 and  this summation will be from 1 to infinity because if you have n people then 1 person is said to be being serviced and therefore  n minus people  n minus 1 people are waiting in the queue so  that will be ; so you want to compute the expected value of l q of the people in the queue  right  which is l q so  then this is n minus 1 into p n now  i can separated out as n p n minus  sigma n varying from 1 to infinity  p n  right so  this we know is l  because anyway when n is 0  the contribution is 0 so  this is also the same as l so  that i write as l and sigma n varying from 1 to infinity to p n is actually 1 minus p 0 because when you add p 0 then the whole thing adds up to 1 ; so 1 minus p 0 so  this is it so  l upon lambda upon mu minus lambda is your value of l ; then 1 minus  1 minus lambda by mu  this is p naught so  therefore  this becomes your ; so that means  this is essentially lambda by mu into l  right ; because lambda upon mu minus lambda is your l and this is lambda upon mu into l so  interesting this thing ; and what you can see  in fact  the little ’ s formulae also say that w q should be  at lambda times w q should be l q and we will show this also because here lambda times w is l  so lambda times w q should be l q ; one can derive this results also  refer slide time  47  23   see  w  i have used as a random variable  notation w for random variable that denotes the waiting time ; and then i computed a expected value of w  but then again in the little ’ s formulae either it should be capital l  in the little ’ s formulae i again use the word w only so  what i am trying to say is that because in the little ’ s formulae they used l capital l  capital w so  did not want to change it but then what i feel is that is not really much confusion using w  you know ; using the same notation for the random variable as well as for the expected value because you see when you are computing this probabilities like this then it is clear the w is being used as a random variable because you do not associate probability  expected value of w is not a random variable so  you will not associate probabilities with it  right so  therefore  probability  w greater than t  is to be computed that it is clear that w is the waiting time random variable and when w is used for denoting the expected waiting time  it is clear of the little ’ s formula then it is clear that this w denote the expected value  yes ; may be one could have used to different notations  but that is  ok i just want to make sure that  i will make it clear that it should be possible to see from the reference to the context in what way w is being used and the same holds for wq  because wq  i am using as a notation for denoting the random variable for the waiting time in the queue ; we know just before your turn comes to be serviced so  before that the time you spend in the system  so this is the rate random variable denoted by w q and again in the little ’ s formulae we will use the  for the expected value of w q  i am again using the notation w q only so  the same reasoning that it should not cause any confusion and one should be able to see from the reference to the context in what way w and w q are being used so  please keep this in mind introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  35 analysis of l lq w and wq m/m/s model  refer slide time  00  15  so  i will continue my discussion about the you know the queuing system you can say the features that are important in determining various aspects of a queuing system so  l denoted our average number of people in the system ; l q was the average number of people in the queue and then we also had computed the average waiting time that a person will spend in that system which includes waiting in the queue plus service time and then we will also talk about the waiting time in the queue which we show also important so  anyway  so let me just continue the discussion about l and l q and so this is as functions of rho which is your lambda by mu  that is your lambda is mean arrival rate and mu is the mean service rate so  lambda by mu denotes your innocence utilization of the queuing system  refer slide time  01  27  so  now we can see from the figure that is on the screen that as you know full utilization of the server ; that means if rho is close to 1 then you see that your graph for l and l q both are going to infinity  right so  that means  when lambda is close to mu  if rho is close to 1 that means  lambda is close to mu that is the mean arrival rate and the mean service rate are almost the same in that case you see the number of people in the system and the number of people in the queue they will the expected number will go to infinity  right you can see the vertical  the approaching  the both the curves are approaching the vertical line so  now this what we are saying is mean values ; that means l is the average number of people in the system and l q is the average number of people in the queue which are  which going to infinity so  it is not  see  it is bad if once in a while your system has infinite people or very large people or the queue has becomes very large but here it saying that it is the mean behavior that is on the average system will have infinite people  very large people  and the queue will also be very large  of course  ok so  that is not acceptable  finely but  anyway  also what we want to say here is that now in this case this does not happen in real life because if the big crowd then it turns away lot of people so  it is not that the queue continues to grow so  that does not really happen and therefore  what we are saying is that in real life there will not be a balance because the queue system  you know  how many people turn away  and so on so  it will not follow the same pattern ; and therefore  when things become so bad we can not apply the same rules that we started with  you know  our assumptions and therefore  we will say that the system is not in balance so  therefore  it can not be  you know  measured ; it can not be analyzed by any of these models that we have written down  right so  if you look at the mean length of 4 on the vertical line or then draw horizontal line from 4 then you see that it will meet the corresponding utilization is 0.8  ok so  mean queue like that ; that means  on the l q curve so  and so l q is the first curve and then l is the second curve and similarly  if you look at the value of l q equal to 5  the corresponding rho value is 0.85 ; so that means  when you allow 4 people to wait in the queue then the server will be ideal for 20 percent of the time  right ; because rho is 0.8 so  0.2 is the fraction of time that the server will be ideal ; and so 20 percent of the time the server is ideal and if you allow the queue size to be 5 then it will be 15 percent idealness so  you can see that there is a definite conflict that is if you want that your server should not be ideal for very long time or even not then as we saw that the  if the system is allowed to operate freely then your queue and the people in the system and people in the queue will become very large so  therefore  but then you do not want that to happen because then you lose out the customer  and so on ; and it becomes a chois so  there is a definite conflict between the issue  between the desire to obtain full utilization of a server and the desire to keep the mean queue length short so  you can see that so  where  wherever there is good will of the customer is very important certainly  the persons who are offering the service would want to make sure that the queues do not become too big but then there it is more important  that means  the financiers are important and you are having a service where the  you can not keep too many servers because that means  that many salaries  and so on and then of course  you are  the servers will be ideal for a long time so  therefore  you  one has to balance so  the system can ; of course  first of all this model has shown you that the system can not being balance if the arrival rate is equal to the service rate  or even if the arrival rate is close to the service rate  refer slide time  06  03  and so the ideal ratio of arrival rate to service rate is something less than 1 ; that is acceptable because your service rate must be more than the arrival rate  otherwise and that make sense and so but its specific value depends on the relative cause of idealness verses congestion so  if  for you it is very important that the system should not be congested ; there should not be too many people in the system then you make sure that your service rate is much higher than the arrival rate and  if your  you have limitations ; you may not to provide  you know  more than 1 server  may be let us say or is efficiency of service providing the service  then you know  we will go for ; so i mean  right  so idealness verses congestion so  if you want the  allow the server to be ideal you will not have that many people waiting in the system  right because  your service system will be such that your mu is much higher than the arrival rate  you will ensure that and  in that case  your  l and value of l q will be small  but if your mu is close to your lambda then there will be congestion so  one has to really strike a balance between  you know  idealness verses congestion so  this is the whole idea i mean so  therefore  you see we can  through these  this model we can study and decide what should be our level of service  and given what is your level of  you know  customers arriving to the system  right  ok so  now  even though we  the little ’ s formula told us that if you  we have already computed average waiting time in the system and now we also know that the w q can be written as rho times w ; that means  the average number of people waiting in the queue is utilization factor times the average waiting time in the system but  we will also like to compute this independently because the distribution of w q is also of importance and besides  the w q is of importance in hospital emergency rooms because  in a hospital emergency room the time that you are waiting to be  you know  taken to the doctor is important because you want to cut that shot ; it is an emergency room and therefore  people need treatment fast so  you would  therefore  w q is of importance ; and in hospital emergency rooms you would want to ensure that your w q is not very large and so we want to look at it in a greater detail and also obtain the distribution of w q so  now  of course  you can immediately write down this relationship because if there is nobody in the system when the arrival comes for emergency treatment then probability  so probability of the waiting time will be 0 because the patient will immediately be taken to a doctor for being treated so  there in that case your waiting time will be 0 so  probability the w q is 0 is p 0 ; that means  there is nobody in the system which is 1 minus rho so  now we will want to compute the distribution when person coming to the system has to wait ; that means  there is 1 row more than 1 person already in the emergency room and then the person has to wait so  this we will compute ; try to obtain the distribution for w q also  refer slide time  09  49  so  for n greater than 0 ; that means  if the any customer is already present in the system then the new arrival has to wait through n exponential service times until his or her own service begins  right so  if you want to find out the probability  the w q is greater than t  where w q is the waiting time in the queue so  then probability w q greater than t  so i will break it up into conditional probabilities and then add up so  this is will be probability w q greater than t given that there are n customers  and so we add up from 1 to infinity because there has to be atleast 1 customer to being serviced then only there will be a need to wait in the queue so  this is n to 1 to infinity probability w q greater than t given that there are n customers in the system and this then would be written as ; so now  when you write this probability then this will be p n into probability s n greater than t because if these are the n service times then s n would be t 1 plus t 2 plus t n so  this has to be greater than t because the n people being serviced see  you are in the  you are waiting in the queue  so then n services have to be completed and that takes because your waiting time is more than t ; that means  these services are taking more than time t ; and this into probability of there being n customers so  then this will be ; so i will substitute  i will write down for p n which is rho n into 1 minus rho  n varying from 1 to infinity  probability s n greater than t  right now  if i take rho outside and then i write this as rho  so this will be a rho n minus 1 into 1 minus rho  and this is probability s n greater than t now  see  at n equal to 1 the value here is rho into 1 minus rho  and this is probability s 1 greater than t  so if i rewrite this as rho outside  and now at n equal to 0  your p n would be just 1 minus rho because rho n  rho raise to 0 would be 1 so  this would be 1 minus rho so  same thing ; and here it will be s 1 greater than t so  the same event is being written here and therefore  all subsequent ones will be the same so  this helps you to  because now you have the summation ; probability sign is missing here so  please write ; this will be p in  probability of s n plus 1 greater than t ; i will just write it ; there should have been probability ; so probability s n plus 1 greater than t so  therefore  so now  you have  because the summation is from 0 to infinity  so then we can sum it up easily  refer slide time  12  42  and therefore  you can just expand this and so here this is no people then the  service time of the  sorry ; 1  rho into 1 minus rho actually would be the  you know  1 person in the system ; then the waiting time is the service time of the first person is of the 1 person already present in the system is more than t  and so on so  when you take out rho then this is what  we have  you just expanding this expression like this  this series and this  now we know ; we recognize this because when we computed the distribution for the average time in the system so  then this was  this is nothing but  and that is why we wanted the sum from 0 to infinity so  this is probability w greater than t and we already know the distribution of w greater than t ; so we know this probability so  therefore  this rho into e raise to minus mu  1 minus rho t so  we have computed this probability w q greater than t which is equal to this now  so the rho is creating the problem because i can not call this an exponential distribution  why ? because  if you write the p d f of w q  then this will be  you know  this you will write as 1 minus probability w q greater than t  yeah ; this whole thing ; so then d d t of that will give you the p d f of w q  right so  this will be minus rho into  because this is 0 ; and i will write down the  yeah ; so this one is rho into e raise to minus mu  1 minus rho t ; substitute for this here  then d d t of this  right ; rho is outside  refer slide time  14  31  so  then differentiation gives me this expression which is equal to this so  therefore  this would not be an exponential distribution because exponential distribution will be this ; rho is the extra part  right but  if you consider the conditional distribution  so now  that is important ; conditional distribution of w q  given the w q is greater than 0  does have an exponential distribution because now you will write the conditional part and  this will that be equal to probability w q greater than t because when you take the intersection  obviously  t is positive ; so w q greater than t so  the intersection of these 2 becomes just this event  and divided by probability w q greater than 0 see  late this you have to write as probability w q greater than t intersection  w q greater than 0 ; and then it will be probability w q greater than 0 ; this is what our formula for conditional probability is ; but  this is the same as this ; of course  given that t is positive so  this event is equivalent to this event  given that t is positive  right ; and then you divide the probability w q greater than 0 so  therefore  this becomes now  rho e raise to minus mu 1 minus rho t divided by rho  because probability w q greater than 0 is ; this is what we computed here ; w q is not 0  yeah so  remember our w q  probability w q equal to 0 was 1 minus rho  right because if the person does not have to wait that there is no person in the system  and so therefore  p 0 ; this probability is equal to p 0  which is 1 minus rho so  if you want probability w q greater than 0 then it will be 1 minus of 1 minus rho which is equal to rho  right so  probability w q greater than 0 is rho ; so we divide this now  the rho cancels out ; and this is e raise to minus mu 1 minus rho t so  this now is coming from ; that means  this now represents because the conditional part w q greater than t given that w q is positive so  this is this which matches with our exponential distribution ; and so the conditional distribution of w q is exponential with parameter mu into 1 minus rho t so  this is therefore  i again just want to repeat that this is not conditional distribution ; we just removed this so  it is just probability w q greater than t is that what you are computing ; you started writing out of this ; and then this is  i will just ; no  we wrote this expression and just to  so that i can relate this series with this series with probability w greater than t ; so that was helpful and then we saw that the distribution is not matching with the exponential so  it is only when you take the conditional probability that you will get  right and so this already we had seen ; and therefore  this is rho so  that is it so  therefore  and this will be useful at times you may really want to know the distribution of the ; so this will be the conditional distribution of w q which you can recognize otherwise the distribution of w q is given by this ; i mean the f q t  f w q t  right now  let us compute the expected time or the average time spent in the queue waiting for to be serviced ; so that we will now compute independently because this is only the conditional part so  you will say that the expected time in the system is equal to the expected ; so the time in the system is time in the queue plus service time ; so expected value of that so  expected time in the system is expected value of time in the queue plus  the service time right and so this can be rewritten as expected time of time in the queue plus  expected service time so  this if we denote by w q so  this is the convention way we have been following that the variable is also treated as the  s denoting the expected value of that variable so  this is expected time in the queue plus  expected service time is 1 by mu  right ; because your number of services is with parameter mu  exponential with parameter mu so  1 by mu is the expected service time so  this is what you have ; and therefore  w q is w minus 1 by mu ; and you can  so we know w  expected value of w which is 1 upon mu minus lambda minus  1 by mu so  this becomes what we had computed  rho times w so  w q is equal to rho times w  and which we have already seen through using the little ’ s formula  refer slide time  17  21  so  we saw that the conditional distribution of w q and w are both same exponential  and the parameter was  yeah ; it means  i mean the same parameter so  they  now also want to make an observation that the little ’ s formula that we obtained under special conditions  but it turns out so  that means  the relationship between l and l q  w and w q  and l and w  so they are all ; in fact  what it means is that if  you can find any one of the quantities  l  l q  w  w q  then you can find all the other 3 so  the all the 4 are related  and it turns out  fortunately that under very general conditions this formulae are valid so  therefore  you know  computing any one of them would help you to get the values of the others now  i want to continue this discussion on these quantities l  l q ; also show you how we then through these analyze these waiting systems have been queuing model so  this particular example ; it is the small one ; but  anyway this is from shelton laws ; and what it says that machinery in a factory break down at an exponential rate of 6 per hour  ok so  that means  the arrival of the machinery for repair is 6 per hour and then there is single repair man who fixes machines at an exponential rate of 8 per hour so  the arrival and the service rate as all provided to you the cost incurred in lost production when machines are out of service ; see the machines come for repair ; they are waiting ; so the repair man has to repair then so  while the machines are out of service they incur a cost because you  the lost production so  rupees 100 per hour per machine is lost to the organization  right so  the cost of lost production is rupees 100 per hour per machine ; this is what is given to us now  we want to find out what is the average cost rate incurred due to failed machines so  while this is  the machines are waiting to be repaired  they are not producing  and therefore  there is a loss to the organization ; and this is the rate so  you want to find out the average cost rate now  the average cost rate will be dependent on the number of machines which are in the system ; which are either waiting to be repaired or which are being repaired so  that will be our number l so  therefore  you see  l is lambda is 6  mu is 8 so  therefore  average cost rate we will write as 100  rupees 100 into  average number of broken machines which is either waiting to be repaired or they are waiting  or they are being repaired so  this will be rupees 100 into l ; l is the average number of broken machines which are in the system ; l gives you the average number of people or customers in the system so  therefore  this is rupees 100 into lambda upon mu minus lambda  which is 100 into 6 upon 8 minus 6 ; so rupees 300 per hour ; so the loss so  therefore  this is the very important parameter because the system would now like to evaluate whether the repair man that they have is good enough  or they need to have more repair man ; because  it depends on what is the  how much the loss to the system compared to the salary of a repair man  and so on so  that question you see will always be running through all these examples ; and you want to analyze ; and you know  this should hopefully help you in your decision process  refer slide time  23  49  let us take another example so  you have now a pump station  a single pump station ; so single pump petrol station so  there is only 1 pump  and so cars that come for taking the petrol have to wait in the queue so  1 is being serviced ; once the serviced car is done with then the other will come from which are waiting in the queue now  inter arrival times are exponential with mean 12 minutes ; and that means  inter arrival time  the average time between 2 arrivals is 12 minutes ; and the service time is exponential again with mean service time 6 minutes so  average time it takes to fill up the car is 6 minutes ; and waiting space is unlimited so  i am not put any question here  but as we go long we will see what are the kind of questions we want to answer here so  let us see ; lambda therefore  that means  the arrival rate is 5 per hour because arrival time  inter arrival time with mean is 12 so  therefore  the number of arrivals per hour is 5 and similarly  the service rate mu will be 1 by 6 into 60 because this is per minute ; this is only in minutes so  you convert to hours so  this will be 10 per hour ; that means  the service rate you can  on the average you can fill up 10 cars in an hour  right rho the utilization factor or the traffic intensity  we have lot of names for this so  rho is 5 by 10  right ; 5 is your arrival rate and 10 is your service ; so 5 by 10 and therefore  this is 0.5 so  the traffic intensity is not very high ; 0.5 is not considered to be very ; that means the petrol station is not very busy right now so  the kind of service rate and the kind of arriving rate then  if you want to look at the probability that there is no car at the petrol station ; so that will be 0.5 1 minus rho which is 0.5 again which is the high probability then  p n is the n cars at the station ; so that will be 0.5 into 0.5 raise to n  right and then the mean number of cars at the station  mean number of cars would be lambda upon mu minus lambda ; or  well  this is  why i am writing this as  how  in fact  this is  sorry ; this is rho upon 1 minus rho so  the mean number of cars at the station is 0.5 upon 1 minus 0.5 which is 1 ; and l q  the car waiting in the queue is 0.5 so  this is the idea so  now  we want to analyze the system through these quantities that we have computed and you know  like you want to again answer the question that in case the arrival rate increases then supposedly the traffic intensity will go up  because this number will go up and then what kind of numbers l and l q will be there ; the values will also go up ; and therefore  the petrol owner  the station owner may want to ask a question is  should we install a faster pump and so on or  of course  more than 1 pump you will  the system that model we will discuss later on when you have more than 1 server ; right now we are talking about only 1 server systems ; and therefore  the only option that the man may have  in case the arrival rate goes up  option would be to install a pump which is filling up cars are at higher rate so  we will just look at the analyses with the numbers  refer slide time  27  44  so  through this examples which we are just discussing  i again want to raise the issues about validity of a model so  it is very important that you keep recalling what are the assumptions under which we are working  and what are the ; so for a example here i wrote that waiting space is unlimited  but you know that in a petrol station waiting space can not be unlimited ; and usually when you have space for 2 to 3 cars so  but of course  the  with the given data right now  it did not really matter because your l was 1  and your l q was quite small  right ; l q was 0.5  i think ; l q is 0.5 so  therefore  that  right now it is not an issue whether the space is limited or unlimited  but in case your data changes then to say that your waiting space is unlimited  it is not a very valid assumption  refer slide time  28  39  so  therefore  one should always keep this in mind that the better model would be when you talk of queues with limited capacity or with limited waiting time so  that would be a better model for such an example then  the arrival pattern is state dependent ; now  here to assume that lambda will remain the same all the time is not correct because if already 2 to 3 cars waiting  the person may want to go to the next petrol station so  therefore  this is not and  arrival process is not stationary also so  it is state dependent and also not stationary because during the rush hour there may be  the lambda may be higher than corresponding to when it is lack hour so  therefore  the lambda itself may change during the day so  the lambda is not stationary ; and it is also a state dependent ; because people do not like to wait for too long  for because as you know you can always drive further and get another petrol station there may be other considerations also ; that is true but sometimes if you like to wait at a particular station because they are familiar with the people know them  and there can be other  so many other reasons then also we must keep this in mind that whatever computations we are doing  remember they are not giving us accurate information about l and l q  and the remaining other parameters w and w q but  we can certainly change the values of lambda in mu of the system ; so that means  we can study the changes in the system and then correspondingly see what are the changes in these numbers l  l q  w and w q so  this models certainly will help you to study the changes ; whatever change is taken place in the system  then accordingly find out the changes in l and l q so  that is what i want to ; so that is what i have stated here  that the real use of the model is in evaluating the effect of changes in lambda and mu  right so  for example  the station owner has the choice of  has alternative of installing a faster pump if you done that then the mean service time is reduced to 4 minutes per car ; it was earlier 6 minutes per hour on the average so  now then the average time has gone down to 4 minutes ; that means  the petrol pump can service 15 cars per hour  refer slide time  31  21  so  by installing a faster pump the mean service time is reduced to 4 minutes ; that is the pump can fill up 15 cars per hour  right ; and so your rho width now become 5 upon 15 because the arrival rate is 5 per hour and so the intensity  traffic intensity or i use to called it the utilization of the petrol pump  and so on  so that is 5 by 15 which is 1 by 3 ; and this is 0.33 so  this is less than 0.5 so  the earlier one was 0.5 traffic intensity  now it has come down to 0.33 and  the probability that there is no car at the station  so that comes out to be 1 minus 0.33  right ; because it will be 1 minus rho ; and so that is 0.67 which is greater than 0.5 ; so that means  the petrol pump would be vacant for more time the fraction of time would be higher than here because there it was 0.5 ; since rho is 0.5  so 1 minus rho is also 0.5 and  your l  the average number of people in the system or at the petrol pump  that means  the number of cars getting filled up or waiting to be filled up  so that will come out to be 0.33 by 0.67 which is also less than 0.5 so  therefore  this does not warrant installing a faster pump because your petrol pump is vacant longer  the intensity  traffic intensity has come down  and so on  yes so  if you are looking at from the view point of the petrol pump owner then certainly it does not wanted installing a faster pump in case  the arrival rate goes up  that means  you have 6 cars per hour instead of 5 cars per hour  and with the current pump that you  the man has  then this will be  rho will be 6 by 10 so  this is the 0.6 ; that means your traffic intensity will go up from 0.5 to 0.6 your probability of there being no car in the system is 0.4 ; and your l is 1.5 ; and your l q is 0.9 so  therefore  you see that is what i am saying that  now with the model you can play around ; and for different values of lambda we can figure out what is  how these numbers are changing and then if you can  as i said  you know  the losing the good will of the customer verses the cost of installing a faster pump and so on  what can be  the owner can study all those things through this model  right and therefore  that the basic contribution of this model lies in being able to study the various changes that will take place in your  you know  you can call them parameters when you change your lambda and mu change  refer slide time  34  19  so  now i will  after having discussed 1 server model we will now look at the situation when there is more than 1 server so  this is that model would be m m s  that the same  the pattern  or arrival pattern and the service pattern are the same  right ; you can say that  and therefore  and the number of servers is now more than 1 so  in that case you see as long as there are number of people is less than s  then your service rate will be because  whoever is there is in the system  if the n people in the system  all will be serviced ; and therefore  your service rate will become n times mu ; that is understandable because everybody is being serviced  and therefore  the n people who are being serviced simultaneously so  the service rate you can say has gone upto n mu  right and  if you have more than n s people in the system  then of course  it will be remain at s mu because only s people can be serviced  since your s servers and therefore  then the service rate will be s mu  but i will try to explain ; and therefore  diagrammatically if you look at the transition diagram here  then you see arrival rate is the same lambda  right ; which is  you know ; so lambda is the arrival rate  but the service rate changes so  if you have 1 percent in the system then it will be mu  right ; because there you serviced and therefore  you get back to 0 state if you have 2 people then 2 are being service simultaneously and therefore  you are at the rate at which the system can transition from 2 to 1 will be 2 mu so  this should be understood very well because so what we saying is that  that many people are being serviced and therefore  the probability of transition ; that means  the rate at which you can transition from 2 to 1 will be 2 mu and  similarly with 3 people  the rate of transition will be 3 mu  but the arrival pattern is the same ; and therefore  the arrival rate is lambda so  this will go on upto s minus 2 and then upto s minus 1 ; and when you have s people in the system if your state is  the system is occupying state s  then it will be s mu and thereafter  the service rate will remain at s mu  right the arrival pattern would be at the rate of lambda  but the service pattern  service rate would then remain at s mu so  this is the idea and so here this service rate depends on the number of people in the system ; that is if the number of people is less than s than it is n mu  and if it is more than s then it is s mu  refer slide time  37  18  now  let us understand the assumptions ; it is very important and if the  what we are assuming is that all operators operate at the same mean rate so  right now this is the simplification ; because  obviously  it will get very complicated if i have different servers with different service rates so  therefore  we are assuming that all operators operate at the same mean rate  mu therefore  i am saying that the  when there are n people in the system  the service rate will be n mu ; and when there are more than n  it will be s mu so  this is possible only if i make this assumption that all operators or all service people are operating at the same mean rate mu  right and so this makes it ; because then we do not have to keep track of which servers are busy ; you know  then we will have to accordingly keep changing the service rate ; and that will become quite problematic  right again  if i feel that this is not very  this can be treated as a realistic assumption because  you know  person may be a little more efficient than the other  but the differences can not be very  very large to really take care of them in the system  right  in the model so  this is what 1 assumption and then the second assumption which is important is that departures will be 1 at a time ; that is probability of service of 2 or more services being completed exactly at the same time is 0 so  this probability  that means  at departures because that is the important of the  you know  when we say that we looking at m m s system  and yes i will have occasion to explain so  then when we talk of markov process we will discuss in detail and so anyway  i am  when we talking of poisson process  remember i had told you that there is always a small  there is a small enough interval in which we will say that the probability of 1 arrival is probability of  we know  the is something like lambda delta t  right and then for more than 1 arrival it was of the order delta t square  a higher order right so  therefore  we were neglecting that ; so the probability was again  that means  we assume that exactly at the same time 2 or more customers will not leave the system so  the service will not get completed exactly at the same time for more than 1 people so  therefore  there will be a distinct interval between 2 departures so  therefore  we can model this as a birth  death process  because our birth and death process the assumption when we talking of m m s so  then the basic assumption is that your arrivals and departures are distinct at distinct times ; you can not have more than 1 departure or 1 arrival at the same time so  once we make that assumption ; and the second assumption is that the operators are all operating at the same efficiency ; so the mean rate is same then we can process this system as a birth  death process  right and  so now  i can write down the balance equations so  this is the first one which is easy to understand  right ; because you have  you already have 1 person then the rate at which it can depart is mu so  mu p 1 must be lambda p naught 1 person can arrive when you have 0 when you are in the 0 state ; so then this and this gives you this  right similarly  when you  i want to write for  so 2 people in the system then it will be lambda p naught you can go to p 1  sorry  to 1 ; and from here when you have 2 people then at the rate 2 mu you can go to again because 1 departure 1 person get serviced  and so you again to p 1 and here  it will be lambda plus mu  right  p 1 ; that is why the transition diagram and even when i were discussing m m1 system  i had explained to you how you can  you know  interpret the transition diagram so  it will be lambda plus mu so  it is actually not ; there is nothing new here except that you have to remember that ; so i have not written down the remaining things ; it is understood that upto s minus 2 you will have this thing and then after that you will  the movement you have s people in the system as a more ; then this is the balanced equation that you will get  right so  once you have written down these balanced equations  immediately you can start solving so  p 1 in terms of p naught will be lambda by mu p naught and then if in the second one if you substitute for p 1 in terms of p naught  then you get your 2 mu p 2 as  ok  refer slide time  42  03  so  the expression 2 mu p 2 simplifies to  equal to lambda square upon mu p naught and therefore  p 2 is equal to lambda square upon 2 mu square p naught so  note the correction  that 2 was missing so  it should be lambda square upon 2 mu square p naught so  all the probabilities can be computed in terms of p naught so  important thing is that the moment you have more than 1 server things change a little and one has to understand  and what assumptions you are now modeling the situations ; and so i try to explain to you how we will  under what assumptions we will treat this as a birth  death process so  the service is  are all at the same rate ; that means  all servers have the same efficiency  and that no  more than 1 departure at exactly at the same time so  there will be just little interval of time between any 2 departures from the system so  under this you can easily write and then of course  this service rate changes depending on the number of servers you have and so and all these 3 assumptions you can write these balance equations  and then we will try to get the probabilities in general formula  and then we will again compute your quantities l  l q  w  w q to get an idea about so  therefore  your traffic intensity also will change  right ; you can see that ; because your service rate is changing and therefore  your traffic intensity will also change so  all these again open up a very interesting this thing  you know  situation ; and we will like to look at them introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  36 m/m/s m/m/i/k models  refer slide time  00  15  so  continuing with our solutions of the balanced equations for multiple servers  so m m s system ; maybe  i can again write here this because we are continuing with the same system with multiple servers so  then you may solve equations for p 1 and p 2 and now  in general  if you want to solve it for  so at the point when you have  you know  more than s people  or it just at the boundary  so this is been lambda p s minus 1 when you have s minus 1 people so  in coming  the way you can reach p s would be through 1 arrival and then here  when you have s plus 1 people  then  you know  your service rate is s mu so  it will be  you know  again 1 person departs so  then you will be back to p s ; and here it will be 1 arrival and 1 departure so  then again you remain at p s  right so  therefore  this is the balanced equation at this stage and  we can now substitute for  because  yeah ; so i had shown you that the formula for p s  upto p s minus 1 would be this so  i just substitute for this in terms of p naught so  this would be lambda into lambda s minus 1 upon mu into 2 mu into s minus 1 mu  right ; then  plus s mu p s plus 1  and lambda plus s mu into lambda raise to s so  upto p s the same solution will go ; the same formula ; so mu into 2 mu into s mu so  let us just  yes  we simplify ; you take this to this side and then  you know  without spending time because surely you can do this calculation yourself so that  from here you will subtract this expression  right ; and you have s minus 1 mu here so  you will get a s mu in the denominator from you multiply  and so when you multiply by s mu so  lambda s  s mu term will cancel out  right ; and you will be left with lambda s plus 1 so  this is the simplification ; you can see it right away from here  right so  you will be left with only lambda s plus 1 upon  so this will be mu raise to s  and then 1 into 2 into 3 upto s  so that is s factorial so  that gives you s mu into p s plus 1 equal to this and therefore  p s plus 1 will be lambda by mu raise to s  and the lambda  so the s factorial  and then divided by s mu so  1 lambda upon  yeah  this is my lambda ; you should be able to write it ; yeah  this is lambda  lambda upon s so  that means  when it is s plus 1  you have this term into lambda upon s mu times 1 at when your rho is lambda  utilization factor is s mu  lambda by s mu now  right  s servers ; and just want to show you that the same formula will continue  and then you can generalize for n  p n so  now if you write lambda p s  then s mu p s plus 2  because after you have more than s people then if the same service state will continue so  s mu into p s plus 2 is equal to  lambda plus s mu into p s plus 1 and  this again when you substitute for p s and p s plus 1 from here  then you will get the expression that p s plus 2 is equal to lambda by mu raise to s into  lambda upon s mu raise to 2 so  this is the factor which goes on increasing ; this remains the same ; s factorial lambda by mu raise to s is common ; and then it is lambda by s mu square so  now  you can generalize for  you know  you can write the general formula  and that will be p n is lambda by mu raise to n  n factorial  p naught  no  that yeah  for n between 0 and s so  this formula is ok for n between 0 and s that is what we were using here  right ; and here  for p s so  then  but n greater than s  you are going to have lambda mu raise to s upon s factorial and then  see  we have  let me show me you so  this is then this is lambda by s mu square so  i am writing lambda by s mu  no ; i do not have to write s here so  this is lambda by mu raise to n minus 1 upon s raise to n minus s so  either s you can include with this  and it will be lambda by mu raise to n minus s so  if you are writing the formula for p n lambda by mu raise to s upon s factorial  this is the common thing  and then it will be lambda by mu s raise to n minus s  which i choose to write as lambda by mu raise to n minus s  and divided by s raise to n minus s so  it is same thing  into p naught if n is greater than or equal to s  right and so now  since we have the general expression you can use the convention that 0 factorial is 1  and therefore 1 can be replaced by lambda by mu because when you add up  see now you want to use the fact that summation p i  i varying from 0 to infinity is 1 so  when you write p 0  so therefore  n all are this are also in terms of p 0 so  the series will become 1 plus and so on  divided by the p 0 so  1  we are replacing by 0 factorial so  in that case  you see  this will be your this thing ; and here  the later part  that means  from s onwards  s plus 1  s plus 2  to infinity  the terms set you will get  you will have this power series ; and  this will be convergent if lambda upon s mu is less than 1 so  as we have anyway c in that  you know  if this is greater than 1 then your things will blow up ; if your arrival rate is more than s mu then the q size in everything will blow up so  we have to anyway work this under the system ; and this is less than 1  refer slide time  06  49  so  for any feasible if you want to consider a balanced form and stationary system  so therefore ; so this then can be written as s to infinity  lambda by s mu raise to n minus s  under the condition that lambda upon s mu is less than 1 so  this is the expression and of course  we are not going to see this no other close form for this and  when you are given the values lambda  mu  and s  you can just compute this value  right so  now start computing the expressions for l  l q  w  w q  and so on so  let us just look at the expression for l q which will be n minus s and  you can see the reason because there is a neat expression for this thing enough for the probabilities when n is s or more than s so  i am therefore  writing l q and since  i can get l from l q  therefore  it is enough that i compute this and  once i get q  i will get l  and then i get w  i get w q so  that is the thing so  let l q ; so we will write as n minus s p n where n is varying from s to infinity and here  if you want to write n minus s s j  then n is s plus j  right so  therefore  you can then say that j varies from 0 because n is varying from s ; so n plus s the j will vary from 0 to infinity  and this will be n minus s j into  p s plus j so  we can  we have a nice way of writing the probability for this so  which will be  see here  the s part is lambda by mu raise to s upon s factorial ; and then this for the j this will be lambda by mu raise to j upon s raise to j  right and  this j is there because n minus s so  you are computing l q  right ; expected number of people in the q  right ; and this is p 0  fine so  i can remove lambda by mu raise to s upon s factorial  take it outside the  and p naught outside the summation sign ; then i am left with this j into lambda by mu raise to j upon s raise to j and  here this i can ; see  lambda by s mu  one s i can take outside ; then  i will be left with lambda by s mu raise to j minus 1  right ; one lambda by s mu i take outside which i am writing as rho ; then  it will be lambda by s mu raise to j minus 1 so  j times this which is the  you know  derivative of lambda upon s mu raise to j so  this whole thing by taking rho outside is equivalent to the derivative of this  right and since  lambda upon s mu is less than 1  we know that this series is also convergence ; this is the arithmetic co geometric form with common ratio is lambda upon s mu which is less than 1 so  therefore  this is the convergent series so  i can take the  first was  i should have written the derivative outside ; and then  since this is a convergent series i can bring the derivative sign inside  and this is what you have and therefore  now this is the geometric series which adds up to 1 upon 1 minus rho  right ; this part summation  and then derivative of this  will be 1 upon 1 minus rho whole square so  actually  no no ; what i should have done is i  first i write derivative inside and then i take it outside because it is a convergent series  so you can interchange summation sign and derivative sign so  now i take the derivative outside ; then this sums up to 1 upon 1 minus rho ; and the derivative gives me 1 upon 1 minus rho whole square so  therefore  now you have a neat expression  except the p naught is a little complex one so  then you have this expression for l q and then  i can get my w q which will be l q by lambda ; and  because we said that these relationships are valid even in the general case so  1 upon ; so therefore  this is given 1 upon s mu ; when you divide this by lambda  this will be left  though 1 upon s mu  and you have this expression hence  then after that you will say  w  w q plus ; and remember  the difference between w and w q will still be that of 1 service because your departure from service is 1 at a time so  therefore  this we will not 1 by s mu  it will be 1 by mu  right and similarly  here this lambda will  l will be l q plus lambda by mu so  keeping that in mind  you have all this relationships now  let us just look at some of the ; no these  yes  and i want it to show ; the tables that i am going to show you have been taken from this book and i will give you the proper references all at the ravindran and philips books so  i have taken some tables where they have plotted the l with respect to  you know  the rho sign  rho  where s is vary for different values of s so  rho changes ; so they have plotted  refer slide time  12  03  so  let me show you the graph here so  figure 2  i would just want to explain that here you see the horizontal axis is the utilization factor ; that means  rho equal to lambda by s mu ; so different values of rho going from 0 to 1 and  the vertical axis is the steady state probability of 0 customer in the system so  look at the curves in the diagram  in the graph  then you see that the utilization factor is coming down drastically as s increases  ok so  for ; that means  for 0.8  for example  the top ; we have top line shows you the utilization factor the  you know  utilization factor versus the probability steady state  probability of nobody no has customer in the system so  these are the different lines and  you see that the neutralization factor when s is 25 is barely  is even less than 0.3 so  that of course  we also except because more the server  the lesser the utilization factor and  but there again as we said that it is always conflict between  you know  have it congestion or having more servers ; and  that depends on what your priorities are so  anyway  this  the graph actually show you what we expect ; that as this will go up the utilization factor will come down but  the other important contribution of this graph is that  you know  you can plot because  remember  the expression for the steady state probability when you had more than 1 server  the expression was lengthy one so  now you can actually plot for different say ; that means  if you know the utilization factor  say  for example i know the my utilization factor is 0.7  and then if i want to find out what the corresponding value of p naught will be  so then i will go along this vertical line of 0.7 and  if my number of servers are 4  then you see whereever this curve s equal to 4 cuts the vertical line 0.7  so that point  and i go horizontally then across to the vertical line  so i can then find out the corresponding value of the p naught and so that will help me because then i have to make my computations for l  l q  and so on  or even for p n s  i will need the value of p naught so  then it will help me to just plot the value  given utilization factor and the number of servers ; then i can find out the corresponding value of p naught so  this is the contribution of figure 2  and later on when i work out  when i worked out any  i will use the values  refer slide time  14  53  now  i will show you another graph this is the utilization factor  the verses so  we are plotting the utilization factor on the horizontal axis  and steady state expected number of customers ; so number of customers in this system  right so  utilization factor and therefore  it says the n for different servers as you except so  for example  if your utilization factor is 0.3 for s equal to 25 you can see that ; well  let us see ; this is at utilization factor 0.4 ; that means  your lambda bar  lambda upon s mu is 0.4 and then  if you go up then you see that for s equal to 25 the number of people will be 10 so  now  total number of people ; but you have this is the steady state expected number of customers which is l so  the number l would be around 10  winning of 25 servers in the system now  if you come down  that means  if you come down to or if you go higher  then of course  these as the utilization factor increases  then we know that the number of people in the system will go to infinity  and the  because it is never advisable to have your s mu equal to lambda so  therefore  this should never come very close to 1  the  your rho  right so  that of course  is depicted by as we saw it for ones server  the same phenomena is shown  is repeated here also but  this again gives you an idea is to the utilization factor verses the number of servers you have and the number of customers you will have in the system so  for different values you can just plot and see  right ; for what is the number of ; so if for example  for 0.5 if you go again the number of people in the system will come  will be again round 11 or something ; you can say that for 25 but  then if you have only s equal to 1 and 0.5  then you expect only 1 person to be in the system so  this is the kind of ; so therefore  this  i mean the conclusions are the ones that you except  right ; but they  sort of  give you more accurate you  and you can accurately find out for number of the utilization factor  number of servers  what will be the expected number because computing p naught  so you can from here only just find out the different values of rho ; you can find out n for number of servers ; you can find out the excepted number of people in the system so  once you can do that  then if you have computed l  then you can find out l q  you can find out w q  and you can find out your w so  this is just to give you a feeling about the multiple servers  and how these quantities l  l q  w  w q  behave  refer slide time  18  00  so  you see  now interesting example from ravindran  phillips and sol berg  actually there are 3 authors ; so ravindran  phillips  and sol berg so  now they are trying to show you that pool verses separate servers  and what would be the conclusion so  let us look at this example so  the 2 business working  business men working in adjacent offices ; each requires secretarial service ; and they each produce an average of 4 letters a day ; well  this is simplification but anyway  whatever the work  what we are saying is  average of 4 letters a day to be typed  and a secretary can be excepted to require an average of 1/ 5 of a day to type 1 letter ; that means  the rate of typing letters by secretaries 5 letters a day  and the business men each is producing 4 letters a day to be typed so  the question is should they get together to form a 2 person secretarial pool ; the pool means that whenever anybody has a letter ready  when anyone of the 2 secretaries who are free  they will type the letter so  it is not that  you know  1 secretary to the 1 business man  and so she will only work for particular  for her boss only  and only when the letter is ready by the boss she will type it so  by pooling  it will be possible for each of the business men to access both the secretaries ; that is the idea or should each men have his own secretary ; so this is the question and let us try to answer through this model of m m s which we have just now talked about  refer slide time  19  39  and you see  so let us see so  if you take a single system then it will be just input is in 4 letters a day and their secretary is typing 5 letters a day so  each system can be considered as a m m 1 system  right so  and therefore  your rho will be 0.8 ; the utilization factor 4 by 5 is 0.8 ; and the mean delay which is w q will be lambda upon mu ; mu delay means that the letter has to wait for sometime before it gets started to be typed by a secretary so  then w q is lambda upon mu into mu minus lambda which is 0.8 ; so that means  on the average a letter will sit for  you know  4 th  5 th of the day  on the secretaries desk before it is being typed  before it starts being typed  typing begins on that letter so  the mean delay is 4th 5th of the day  right now  and the same applies to the second business man also because they are identical systems m m 1 systems with the same data so  therefore  the second business men also will have the same thing happening to his letters that for 4 5th of the day now the letter will be waiting on the average  and then just typing begins now  suppose  you pool the system then your input will be  you know  8 letters a day  and you have 2 servers now  each them producing  typing 5 letters a day so  then this is a m m 2 system  right and  your rho will be again lambda upon 2 mu which is 8 by 10 so  therefore  this is 0.8 and your lambda by mu is 1.6  right so  then p 0 ; now this is where you are  the graph that i had talked about come in handy ; of course  this is the small system  and so therefore  i have shown you the calculation even otherwise ; this is this  right i have shown you the calculation  but see  you can see from  that means  for lambda by s 2 mu  s mu is 0.8 ; so corresponding to 0.8 and 2 servers  refer slide time  21  52  if you look at the graph here  figure 2 so  0.8  and you want to go up to 2 so  you see this is little above 0.1 so  0.11  right you can see in the graph  lambda by s mu equal to 0.8 and 2 servers so  this is just above 0.1 ; so 0.11  right ; and which also by our calculation comes out be 1 by 9 so  this is 0.11 so  larger systems your graph is plotted ; you can just check the value  you know  look up the value for p naught without having to do the lengthy calculation  refer slide time  22  13  and therefore  your l q would be again by the formula and then so w q ; that means  so by formula we have w q s  this number which is 0.35 so  therefore  by pooling the mean delay has come down to 0.35 ; earlier the mean delay was we have computed it was 4th 5th of the day  right ; which was  right and so here now it is 0.35 which is much less than 4 by 5  right because  if you multiply this is  mean delay here  what is it  4 5th of the day so  if you want to compute it in ; this is 0.8 ; mean delay is 0.8  so which is much less than point  which is much very very high compared to 0.35 so  by pooling definitely your mean delay will come down so  it might not be  you know  if you put the ego side apart ; you know  like having your own secretary ; and of course  probably this goes against intuition also because you may feel that if you have 1 person to exclusively to do your job  then you should get it done faster  but certainly the data here shows that this is not the case ; by pooling it will always help you to get your work done faster now  mean delay we had computed that 0.8 so  therefore  this is very high compared to this number now  let us see  we can again play around with few numbers suppose you say that this data was particularly till i had  so that their difference is so much 0.8 and 0.35 now  suppose 1 of the business men has only 2 letters a day then the mean delay for is the letter getting type will be 2 upon ; so this is the number of let mu mu upon lambda  lambda minus mu  sorry ; i have said the wrong way 2 is the number of letters that arrive per day so  lambda is 2  mu is 5  because 5 letters get typed ; the secretary can type 5 letters a day ; mu is 5 so  this is  lambda is 2 ; so lambda upon mu into mu minus lambda so  this will be 2 by 15 which is 0.133 so  with his own secretary the mean delay would be of the order of 0.133 now  if we pool the 2 secretaries then your lambda becomes 6 because the first business men is  one of the business men is sending  getting 4 letters to be typed ; and the other one has only 2 so  lambda equal to 6 ; and 2 mu will be 10  because each of them can type 5 letters a day so  therefore  p 0 is 1 by 3 now  this we get from the figures that i have  should  given you so  therefore  for lambda and mu  for these values of lambda and mu  you find out p naught which it comes out to be 1 by 3 from the figure and therefore  your w q would be 0.11 ; that means  the mean delay would be 0.11 which is still less than 0.133 so  you see pooling definitely is a better option with 2 letters and the secretary and the man using his own secretary  even then the delay that he encounters is more than what he would encounter if he  if the 2 secretaries service is a pooled up and then they type letters as they come so  you see  even though as i said in the beginning in somewhere in the last lecture that  you know  you can not take the values that we compute through this such models as exact  but they do definitely give you  you know  they have good guiding ; they give you  provide you with good parameters to make  to help you make your decisions  right see  even though the numbers may not be so exact like 0.35 and 0.8  but it definitely shows that the difference is there and so you can  the efficiency of the system gets improved by pooling so  your services that you have ; you know  like so many banks in so many other places  in public places if you see  that sometimes even at airport can not counters and so on  you feel that  you know  separate queues because once you  once up the customer joins a queue then he or she can not change the queue so  you see  that way you can immediately see that  i mean  this kind of model shows you that lot of time is being wasted ; i mean the system is not working efficiently because you are not pooling the resources so  somehow the feeling that separate queues will be more efficient and your work will get done faster  so that belief is not supported by this model ; and it is a reasonable correct model  in the sense that it gives you ideas to what happens when you pool up the resources so  this is a all about it ; and we will continue with the so  figure 2  i would just want to explain that here you see the horizontal axis is the utilization factor ; that means  rho equal to lambda by s mu ; so different values of rho going from 0 to 1 ; and the vertical axis is the steady state probability of 0 customers in the system so  first of all if you look at the curves in the diagram  in the graph then you see that the utilization factor is coming down drastically as s increases so  for  that means  for 0.8  for example  s equal to 1 you  the top  way of top line shows you the utilization factor the  you know  utilization factor verses the probability  steady state probability of nobody no has customer in the system so  these are the different lines and  you see that the neutralization factor when s is 25 is barely is even less than 0.3 so  that of course  we also expect because more the server the lesser the utilization factor  and  but their again as we said that it is always conflict between you know have a congestion or having more servers  and that depends on what your priorities are so  any way this  the graph actually show you what we expect ; that as the number of servers will go up  the utilization factor will come down but  the other important contribution of this graph is that  you know  you can plot because  remember the expression for the steady state probability when you had more than 1 server  the expression was lengthy one so  now  you can actually plot for different ; that means  if you know the utilization factor so  for example  i know the  my utilization factor is 0.7  and then if i want to find out what the corresponding of p naught will be  so that i will along this vertical line of 0.7 and  if i number of servers are 4  then you see wherever this curve s equal to 4 cuts the vertical line 0.7  so that point ; and i go horizontally then across to the vertical line  so i can then find out the  in a corresponding value of the p naught and so that will help me because then i can make my computations for l  l q and so on  or even for p n s i will need the value of p naught so  then it will help me to just plot the value  given my utilization factor and the number of servers then i can find out the corresponding value of p naught so  this is the contribution of figure 2 and later on when i work out  when i worked out an example  i have used the  i will use the values of p naught from this graph  refer slide time  30  42  so  i will take up this  taken up this case study from the state hospital in ; and this is from the book hillier and leeber men ; again this reference will also will be given at the end of the course and  see  the state hospitals in the us are called county hospital so  the data was collected from the county hospital  and the emergency room is considered because that can be modeled really well so  here emergency room and the arrivals  and we are considering the morning shift ; have i written something from where here  yes so  this data refers to the early morning shift so  early morning shift and that  i do not know  for some reason this is what happens ; that often the emergencies are in the early hours of the day  early hours of the morning so  arrivals are 1 per half hour  right ; so that means  your arrival rate is lambda equal to 2 and  here again  it is  it was found suitable to model the thing y poisson arrival ; and of course  the service process is exponential  negative exponential so  that means  since 1 every half hours  so 2 arrivals per hour ; then doctor requires an average of 20 minutes to treat a patient which means that mu is 3 patients per hour so  your this thing also ; if it is negative exponential then the inter arrival times  the services  the service times would follow negative exponential distribution now  there are 2 alternatives which the hospital management has to consider they have 1 doctor to manage the emergency room  so either they continue with the  with 1 doctor  or to add another doctor ; that means  your number of servers will go up to 2 so  these are the 2 alternatives ; this for a morning shift ; it is not for the whole day because for the rest of the day  your lambda may change and even your mu may change so  for the morning shift this is the  these are 2 alternatives which are being considered  refer slide time  32  55  so  now let us look at the data and so all the calculations have been made with s equal to 1 and s equal to 2 and so let us look at the data so  this is steady state results from the m m s model so  there should be a gap between s and model  for the m m s model  for the county hospital problem  right now  for s equal to 1  the rho  the traffic intensity is 2 by 3 but  when it is s equal to 2  it will become mu lambda by 2 mu so  this will be 1 by 3 so  intensity will come down to 1 by 3 p naught  your probability  when there is no patient in the system  in the emergency room  this is 1 by 3  and here it is 1 by 2 then  p 1  the computed value of p 1 also  at 1 patient it will be 2 by 9 for s equal to 1  and 1 by 3 for s equal to 2 so  again the number of patients  the probability of p 1 will be 1 by 3 then  p n for n greater than or equal to 2 is 1 by 3 into 2 by 3 raise to n ; and here it will be for s equal to 2 it will be 1 by 3 raise to n so  everything  obviously  we except all these numbers to come down  but the drastic difference is seen where in l c  l q is 4 by 3 so  a patient has to wait  right ; the q is 4 by 3 whereas  for s equal to 2 it is 1 by 12 ; so that is really remarkable difference then your number of people in the system on the average would be 2 ; whereas  here it will be 3 by 4 for s equal to 2 then  w q  the time  average time spent in the queue waiting for to be treated by doctor  here its 2 by 3 hour ; and for s equal to 2 it becomes 1 by 24 and so you see in an emergency room it is very  very crucial that a patient gets treatment as fast as possible because it is a matter of life and death so  here w q being 2 by 3 if only one doctor is attending to the patients  then it is a  then the waiting time is high ; whereas  it comes down drastically to 1 by 24 hours if your s is 2 then  w  the number of people waiting ; that means  q n service is 1 hour ; whereas  here it is 3 by 8 hour so  you see these are the figures which immediately tell you that it will definitely be  to the  it will be advantages to have 2 doctors because after all in an emergency room we do not want patient  patients to die because they have not got immediate attention and then  probability w q greater than 0 is 0 667 when s is 1  but it is 0.167 when s is 2 ok so  that means  the patient coming into the emergency room will have to wait ; that is high ; 0.667 when s is 1 but  the moment you have 2 doctors attending it comes down to 0.167 and similarly  probability w q greater than half would be 0.404  for s equal to 1 ; whereas  it will be 0.022 for s equal to 2 so  therefore  this is also you know damaging because they  in a hospital emergency room if you have to wait for more than 1 by 2 of an hour then this is bad  and the probability is 0.404 when s is 1 so  this is not acceptable and  similarly  w q greater than 1 hour is 0.245 which will be less than half  right so  that is the waiting time so  that will be 0.245  but for s equal to 2 it will be 0 003 see  if you just look at the numbers the other 2 are not that important but  anyway  so this data ; so therefore  we are able to then conclude that single doctor will give you a long waiting period which is not very desirable for a emergency room  for hospital emergency room  but 2 doctors you expect from service and so therefore  anybody looking at this data ; and this is what this model has helped us to generate the data and see that it will compare very  you can compare the performance of the emergency room  and there is 1 doctor remain  and when there are 2 doctors so  if financier is not a consideration it would be very helpful to have 2 doctors  refer slide time  37  31  and then  again i just want to make a point about pooling that what we were talking the example i gave you in the earlier so  pooling  we saw that if the waiting time is the main consideration then pooling will always have  because we saw that even with  you know  when 2 business men having their own secretaries they had to  the letters had to wait longer  but when the after when the services of the 2 secretaries were pooled the waiting time for the letters to be typed came down  right and  if there is some registration or something then it is a different thing ; that you can not  you have to have separate queues  but otherwise if the main consideration is to avoid long delays  then pooling is the answer so  there  another  we know  again the model helped us to arrive at that conclusion now  let us look at another kind of model which is limited of finite q variation of the m m s k model so  here the ideas that you can not allow queue  more than k people in the system so  you could just take the example of an emergency room in hospital ; you know  it may not be possible to because people come  they need beds  they are  it is an emergency  or they are on stretches so  then you definitely need room for these patients arriving for emergency service  refer slide time  38  58  so then  you  the space is limited ; and therefore  you can not allow for infinite q size  right then  you can also have many other ; and as we said that  you know  a petrol station  if you may not  you could not have infinite number of cars waiting to be serviced so  therefore  again you have limited space for the cars to be waiting and that the number usually ; if you are big  even that it can not be more than 5 to 6 cars which can be accommodated by the petrol station where they are waiting to be serviced  depending on the number of pumps the petrol station has  anyway so  this is very reasonable ; and this model realistic situations where your limited space ; that means  your finite q ; you can not allow for infinite queue so  the only change that you would have to make in the m m s model would be that your lambda n will be lambda  for n varying from 0  1  to k minus  1 ; and for n equal to k  it will be 0 so  that means  you will not allow people to come ; even once you have k people in the system then you will not allow people to enter the system essentially  right and here  the q will reach a steady state even if lambda is greater than s mu see  remember  for infinite size we had to restrict lambda less than s mu  but  because otherwise the number would have blown up  right ; your l  the average number of people in the system  and so on  would blow up if lambda was greater than s mu  in case you allowed infinite q size so  here  because you are not permitting your queue size to be more than k  so then lambda greater than s mu is also permissible  right and so the q size will never exceed k minus s ; and the total number of people in the system will not exceed k see  your s servers and your k size can not be more than k minus s also  so as i came with example is emergency room of a hospital ; also you see there are situation the places where the customers are choosy and they would not like to wait ; they would not like to enter the system as they are more than k people already ; i mean  they might consider that k number to be a crowd  and therefore  there would go away now  such phenomena is called bulking because you are losing outer customers  since you have limited space so  you are losing customers ; and you may also be losing out good will so  we will look at this aspect and  essentially  one would like to know what kind of business you are losing now  because your people are  your customers are being turned away because there you do not have enough room and  of course  for emergency rooms in a hospital registration requires  that if you can not accommodate a patient right away  then you have to send them to another person  another hospital so  there the registration requires that you turn away patient if you do not have enough room for them so  all these considerations are there so  we will look at a bolking  and we will try to 3 examples try to see how you estimate the loss of revenue because you have lost customers and then  of course  that might also encourage you to invest in increasing the waiting space  waiting room  so that to compensate for the loss in business so  now of course  i will give you the expressions for m m s k also  but right now it will be easier to just write down the balance equations from m m 1 k model ; and then the arguments for m m s k will also not be much be different except that you will have to take care of the s server so  for m m 1 ; that means  1 server  but you have finite q so  the balance equations will be ; of course  when there is nobody there in the system then 1 arrival comes  and then you can go from p 1 to 1 departure so  therefore  this is the balance equation  right and  so that gives you p 1 equal to lambda by mu p naught and so here you see the transition diagram is no different from m m 1 except that there will be no state after k and so therefore  you will have only that many balanced equations so  that is only the difference ; that is why i did not draw the transition diagram  anyway and so for  when there are n people in the system  then lambda plus mu  1 arrival  1 departure ; again you are back with n people in the system ; then this will be n minus 1 people ; you can reach p n  you can reach n by 1 arrival and  when you have n plus 1 people then you can reach again state n by 1 departure and  this will be valid for n  1  2  to k  minus 1  right and then  the last one when you have k people  when only departure is allowed  because no arrival  right and so from p k minus ; so that means  from k minus 1  again you can reach k by 1 arrival so  this will be the last equation  right surprisingly  you do not answer therefore  that is ok ; this makes sense because you can not go away from here ; and you can not have any  allow any arrival here so  this will be the equation and  the interesting thing is that we will not leave this equation actually  when you are obtaining values of p 1  p 0  p 1  p 2  because from here  see  when you put n equal to k minus 1  p k value will be available u from here so  we do not write we needed  but just for completeness sake we want to write it down and so now  one can solve these balanced equations to get the corresponding relevant probability  refer slide time  45  10  so  just as for m m 1 model  we will solve this balanced equation ; and  you will get p n is equal to lambda by mu raise to n p naught  n varying from 1 to k so  let me just show you the calculations for ; as i told you that the last equation will not be needed ; the last but 1 equation can  will give us the value of p k so  the last  but one equation is lambda plus mu  p k minus 1  is equal to  lambda p k minus 2  plus mu p k  right ; because when there k people in the system  no arrivals are allowed so  this is your last but 1 equation ; and since you have obtained the formula for p k minus 1  and p k minus 2  so i just substitute so  therefore  your mu p k is equal to lambda plus mu  times lambda by mu raise to k minus 1  minus lambda times lambda by mu raise to k minus 2  into p 2  p naught  right everything is in terms of p naught so  therefore  just simplify ; lambda by mu raise to k minus 2  you can outside so  then you will be left with this expression ; and here you can simplify so  mu lambda ; and lambda again you can take out side so  it will be lambda plus mu  minus mu by mu ; lambda is outside here so  this gives you lambda by mu ; and therefore  this becomes lambda square by mu but then  you have your mu p k here  so therefore  p k will be lambda by mu raise to 2 into lambda by mu raise to k minus 2 so  the whole thing is there so  therefore  you  there is no problem in solving your balanced equation and then  since all the probability is must add up to 1  so you get the expression for p naught which is the geometric series here and  of course  except that rho should be not equal to 1 ; and otherwise you can add this and that gives you 1 minus ; because when rho is equal to 1 you will have a simplification so  that can be written down immediately so  therefore  this is your value of p naught ; and so you get first form for the p n which is lambda by mu raise to n into 1 minus rho  upon 1 minus rho raise to k plus 1 so  this is valid for n varying from 0 to k  right now  you want to find out the average number of people in the system so  this will be sigma n p n  n varying from 0 to k and  so you just substitute for p n ; that is what you get and again  we will use the same trick that lambda  n lambda by mu raise to n so  this can be written as derivative of lambda by mu raise to n  respect to rho ; so rho raise to n so  n rho raise to n ; so that will be an summation of course  you are n varying from 0 to k so  if you take a rho outside  then it will be ; so this will be then rho  derivative of rho is 2 n and then again  so finite series i can interchange so  d by d rho outside the summation  n varying from 0 to k rho n ; and that gives you again geometric series ; and the summation is this so  derivative of this d by d rho on minus rho raise to k plus 1 upon 1 minus rho so  differentiate the numerator ; this is minus k plus 1 rho raise to k  into 1 minus rho  minus  1 minus rho raise to k plus 1  into derivative of this which is minus 1  right ; divided by 1 minus rho whole square and just simplify ; and finally  you will get this as so  i have just separated out the 2 terms  rho upon 1 minus rho minus  k plus 1 rho to k plus 1 divided by  1 minus rho raise to k plus 1  ok so  this 1 minus rho cancels here so  you are left with 1 minus rho  the power 2 is gone  and then the rho part here so  rho 1 minus rho  i have written out here ; and there is a 1 here so  then this gets coupled with this so  minus k plus 1 rho raise to k plus 1 ; rho is outside here ; divided by 1 minus rho k plus 1 so  this usually you can see  simplifies to this expression  fine  refer slide time  49  34  now  we just want to look at the long  the behavior  if you allow k to become large  you want to look at this so  for rho less than 1  rho k plus 1 will go to 0 as k goes to infinity and earlier  we have shown that this series is  this converges k sigma raise to  sorry ; rho raise to k  summation ; the series converges to rho upon 1 minus rho whole square we have already seen this because this arithmetic co geometric series  right and so if a series converges then the necessary condition is that the n th term must go to 0 as s k goes to infinity  right so  therefore  k rho raise to k  must go to 0 which implies that k plus 1 into rho k plus 1 goes to 0  as k goes to infinity so  now  if you look at this here  this is going to 0  so this reduces to 1 ; and k plus 1  rho k plus 1 goes to 0 so  therefore  your limiting value of l when rho is less than 1 and s k goes to infinity so  the limiting value of l is rho upon 1 minus rho which is the m m 1 case so  you see  you can immediately conclude that  you know  when you have the m m k s ; that means  you have a limited space for people to wait ; that is a k people can wait ; units can wait ; then we  so this model relates to that but  if you make this space unlimited ; that means  there is no restriction on how many people can wait in the system then the system reduce  that then the whole process reduce this to the m m 1 case so  this validates the m m k k s ; that means  whatever we have derived  the values of l and so on  they are valid in the sense that they correspond to the m m 1 case  in case your space becomes unlimited  so as many people as you want can wait for to be serviced so  in that case  it will be m m 1 case  right so  you can  you know  so there are many ways in which you can also try to validate the model that you have constructed so  this is one of them introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  37 m/m/i/k and m/m/s/k models  refer slide time  00  14  see  the last lecture we talked about m m 1 case  and i will just continue with that and the basic thing to be noted is that see the difference between m m 1 case and m m 1 k case since only the q size that is you are restricting the number of people in the system so  for m m 1 k the number of states only go up to k  for m m 1 the states were  it could go up to infinity so  therefore  the derivation as i have showed you in the last lecture  the derivation was straight forward and then see i also showed you that as k goes to infinity  and if of course  here in this case here  we require that o is less than 1  and that i am saying is that the formulae these are all valid  when rho is not equal to 1  because otherwise you can not divide by 0 so  a for rho less than 1  we showed that as k goes to infinity l will go to rho upon 1 minus rho  which is the k infinite case that is which is the m m 1 case  as it should be because  when you allow your k to become large then it reduces to the m m 1 case  and similarly the derivation for l q so  this is l q l minus 1 minus p0  you can see that from the formulae for l q because it will be n minus 1 raise to into p n summation so  you get this and therefore  this is the expression  and here again you will see  so i write the expression for l and  this is for 1 minus p0 and therefore  you can simplify this and finally as because again this portion will go to for rho less than 1  and as k goes to infinity so  this portion will become 1 because  rho is less than 1  so i can again divide by so  you will be simply left with rho here  k goes to infinity so  this portion you can show will go to 1 and therefore  this will be rho upon 1 minus rho  minus rho  which will be equal to rho l so  again the same as m m 1 case see  here we can there is so many ways in which you can actually show that this quantity will go to 1  just as we worked out for the l case the same tricks you can use here  and show that this quantity will go to 1 so  therefore  this is the 1 case and now just let us look at the probability p k  which is a very important quantity here  refer slide time  03  04  so  p k is rho k into 1 minus rho upon 1 minus rho raise to k plus 1  when rho is not equal to 1 and it is 1 upon k plus 1 and rho is equal to 1 so  this part of course  i have asked you to do it as an exercise now  p k is the probability that the system is full because  you can not have more than k people in the system so  p k is the probability that the system is full  which can also be interpreted as fraction of time over the long run see remember  we are always talking in terms of steady state probabilities so  over the long run this also can be interpreted as the fraction of time  that an arriving customer will find the system full because  it already has k people so  therefore  no more entries can be allowed and  so this will be a fraction of a time of the time when an arriving customer will find the system full so  therefore  the number of customers blocked per unit time would be the arrival rate lambda into the fraction of time the system is full and  so p k into lambda is the is the important number that tells you  the the number of customers blocked by unit time and  so this is your lost business  lost revenue so  this is this number is useful in determining increase in waiting space so  i have been talking about this  what i am saying is that ; see now  you can the loss of earnings because  of lost customers can be made up by allowing for more customers to join the system so  therefore  now the management has a very important guiding tool  this is you know you can find out that if you are losing that many customers per unit time then over day or a week or over a year  whatever your planning horizon  how many customers would have been turned away and therefore  you can compute estimate the revenue that you would have earned if those customers  who are allowed in and then you can you know  compare it with the cost of increasing your services or allowing for more waiting space and so on so  therefore  one can then very comfortably come up to a decision  has to if you lost customers this number is large then you would certainly consider increasing your waiting space  and allowing for more people to be serviced  and come to the system so  as i have been saying that you know these are a really useful models  and they help you and  the management or the people concern people can always use these as guidelines  not again go by exact number  but at least they can be very good guidelines they give very good guidelines now  as i said special case when rho is equal to 1 is an exercise  in the problem sheet  which we will be discussing at the end of this lecture exercise nine so  i have put this you know just for you to compute very simple  but you can then see that the all the quantities can be computed  when rho is equal to 1 that means that is this implies that lambda is equal to mu so  the service rate  and so here again  there is no question the system growing up because  it is a finite space or a finite space model so  now  the case that again i will not go in to detail  but it needs to be mentioned and  i have written down the formulae for completion sake so  this is m m s k model so  now  you have s server s greater than 1  and again finite space if i not allow more than k people in the system  and certainly your number of servers have to be less than or equal to k  otherwise ; it does not make sense if you are allowing for only ten people to be in the system  and you have 12 servers so  certainly the 2 servers will always be idle so  therefore  s is less than or equal to k and this is nothing really to spend time on arriving all these formulae because  the transition diagram is the same as for m m s case  just as here the things were exactly the same as for m m 1 case  except that you had we have to stop at after state k and here  m m s case these 2 are similar  except that here again you are chopping off after the state k is reached and  so therefore  the same transition diagram and you can write the same balance equations  and then we can obtain the value for p n so  this will be lambda by mu raised n upon n factorial p0  for all values of n from 1 to s  and for values of n greater than s  s plus 1 to k this will be lambda by mu raise to n upon s factorial then  1 upon s raise to n minus s and p0.so  then p0 can be written as this by summing up all the probabilities so  this is your value for p0 now  again we will write down the formula for l and l q the derivation is exactly the same as for m m s  and then you know go on with the other this thing  refer slide time  08  40  so  when the expression for l q will be derived exactly as for the m m s case  but k is infinity and  the argument will be the same exactly  you will be summing up sigma n minus s into p n upon n varying from 0 to k  instead of 0 to infinity that is all so  therefore  that is why this portion has come in so  otherwise when k goes to infinity  and for rho less than 1  you will see that this expression will be gone  and  so you will be left with this  which is exactly equal to your l q for m m s case so  that you can derive that and this is surely your rho is this and  so far k becoming very large  the your rho has to be less than 1  this has to be less than 1 and then the expression for l can be then obtained from l q  and so that is all i mean you just write down the expressions  i am doing this for the completeness sake so  that you can yourself if you want to derive them then you can check that the answers are ok now  expressions for w and w q for both m m 1 k and m m s k  are not simple so  what we basically do is ; we use the computer calculations to given the values of k  and then value of s and lambda mu we will simply put these values in  and write a small program to compute the values of w and w q and of course  some people in some textbooks you may find  just as we plotted graph for a m m s m m s case you know we could plot p naught against the values lambda and s and mu  and so on so  you will find these values tabulated somewhere  now the interesting case out of this is the 1 in which your number of servers is equal to the number of people allowed in the system ; that means  you allow only as many people in the system as you have servers and of course  an immediate example is your telephone network with s trunk lines right so  if you have s trunk lines  callers get a busy signal when all routes are busy so  therefore ; obviously  they can not make a call unless some route becomes free so  therefore  the special case is of lot of interest  when the number severs is equal to the number of people allowed in the system and of course  the other extreme case could be  when you know when you go to a restaurant it is self service so  then ; that means  the number of servers is equal to the number of people in the system so  that of course  is also there then  maternity ward of your hospital because there also see  the number of beds that is available only you can only entertain that many patients  that many women  who are going to deliver ? and so you have to turn away other people  refer slide time  11  42  this case is also of interest  and here  in this case p s will be the will represent the fraction of time the system is full so  otherwise in these 2 cases it was p k  but now since s is equal to k so  p s will represent the fraction of time the system is full  and therefore  again you can find out so  the number of customers lost per unit time will be then given by lambda p s if the lambda is your arrival rate then it will be the number of people who are turned away now  this is also called the erlang ’ s loss see  erlang ’ s  a.k erlang was a danish telephone engineer and  he is considered to be the founder of queuing theory in the early 20th century so  you see it is amazing  how as a telephone engineer ? he had you know excess to these you know the queuing systems and therefore  he sort of initiated lot of ideas you know  where these the whole theory has now been developed now  i like to just look at these m m s k case  through an example  and i have just adapted see  this is from ravindran  phillips and soldberg  but i have adapted it to our system and so i have just named it the hospital as a lady harding medical college  which is it is not school  college the lady harding medical college  which is in new delhi and  this is the maternity being of the lady harding medical college so  suppose there are 12 deliveries per day now  the thing is that only the labour rooms  where the people where there were people come ? when the pregnant ladies come with labour pain so  then they have to wait and then the actual so  the labour rooms are the bottle neck because  that is where the patient lie till  the delivery has to be has to take place so  delivery rooms are used for actual delivery  and do not take long  and the recovery rooms are not a problem because  once that a babies delivered then they can be put in a general ward whatever ; any because there is no special medical attention is needed at that time so  the recovery rooms are also not a problem on the average a labour room is occupied by a patient from 3 to 5 hours  and then half an hour is taken for rating the patient for the delivery so  therefore  this is where the bottle neck is because  this occupy the longest by a patient so  and therefore  the idea here is that you can say that may be 6 deliveries per day so  the deliveries that can so  1 labour room can accommodate 6 deliveries  1 labour room can accommodate 6 patients a day and of course  your arrival rate is 12 per day  refer slide time  14  58  so  we just now look at the parameters l q  and the number of patients  who get turned away and so on so  since the number of labour rooms is the bottleneck so  we will call the servers  number of servers is the number of a labour rooms so  therefore  as we saw that system can be modelled as a m m s s the maternity being of the lady harding medical college  which is also has the hospital attached to it so  that will be treated as an m m s s case since  we are taking the arrival and the service pattern to the morkovain so  and then the fraction of maternity patients turned away is p s into lambda so  this is the fraction of time that the system is blocked  and then a lambda is the arrival rate so  this is the fraction of maternity patients that will be turned away rate of the maternity patient turned away  which the formula for that would be lambda by mu raise to s upon s factorial into 1 upon so  your p0 would be just adding up to  this whole thing the formula is  we have obtained it number of times by now so  p0 will be 1 upon this only  because you will not go beyond s and therefore  this is lambda by mu raise to n divided by n factorial n varying from 0 to s so  this is the formula for the number of fraction of maternity patients  that will be turned away because  your labour rooms are all occupied so  compute the occupancy rate of the labour rooms  we compute expected value of p n  which is for which our notation is l ; that means  the average number of people in the system  and this is will be summation j varying from 0 to s j into p j  because either you do not have any patient or you have 1 2 3 up to s only because  you only permit as many patients as there are labour rooms so  therefore  l q is 0 there will no waiting queue  there will be no people waiting in the queue  and summation so  1 minus sigma p j j varying from 0 to s minus 1 is equal to p s so  with these conditions we can compute this  and that will give us the occupancy rate of the labour rooms now  let us compare the ah situation ; that means  the hospital has the college the college authorities have a choice  whether to continue with the current 2 labour rooms or to increase the labour rooms so  that you do not call this comfort  and you do not turn away too many people because  that certainly has a reputation on the hospital if you are saying that all the time your beds are full your labour rooms are busy so  when s is 2 because your lambda is 12 and your able to the labour room can be used  occupied the number of times it can be occupied is 6 so  we will say that the service rate service rate is 6 and the arrival rate is 12 so  twelve by 6 square into p0 right your p s from here and your p0 will be so  this is 2 square upon 1 plus 2 plus 1 by 2 into 2 square  because your s is two so  just apply this formula  and when you do the computations it comes out to be 4 by 5 because  your p0 is 1 by 5 and this is 4 so  4 by 5 is your  which is you can see is high four ; that means  the fraction of time you turn away patients is 4 by 5 and  the number of patients turned away so  the rate of number of patients turned away per unit time will be 4 by 5 into 12  which is 48 by 5 i mean per day you are turning away 48 by 5 patients  you are not able to accommodate them when you have 2 labour rooms  and these of course  see here this i do not consider this is really important because  this will depend on the since your only allowing as many people as there are servers  the number of labour rooms so  therefore  this is just as you that as you are calling the occupancy rate of the labour rooms  refer slide time  19  31  this is 6 by 5 now  for s equal to 3  when you make the computations your p0 is comes out to be 3 by 19 because  now you will go up to 3 the summation  sigma n varying from 0 to 3 so  this is the computation and therefore  it comes out to be  which is 3 by 19 so  therefore  p0 is of course  the probability that there is no there is no patient in the labour rooms  and here your p0 was 1 by 5 this was 1 by 5  and this is 3 by 19 then  p 3 comes out to be 4 by 19 and therefore  the loss of patients is 4 by 19 into 12 which is 48 by 19 so  this is definitely less than 48 by 5 in fact  much less than this number so  therefore  the loss of patients drastically comes down  by increasing 1 labour room so  with 3 labour rooms  the average number of patients present in the hospital in the maternity ward l  will be given by p 1 plus 2 p 2 plus 3 p 3 and so  that will be this number into 3 by 19  which is your p 0 and so  this turns out to be 30 by 19  which is much higher than 6 by 5  because 150 and this is 114 so  therefore  what is being said is that ; which of course  is obvious in the sense that l is higher for 3 labour rooms  then when you had 2 labour rooms so  this was your traffic intensity or utility whatever you want to call it  for with 2 labour rooms and this is so  why ? because  you are turning away less patients  and if good will counts then certainly it is more important to have lot of good will in the community  and so 3 labour rooms may be worthwhile  then 2 labour rooms know considering the expense of having another labour room one more doctor 1 more labour nurse and so on  but anyway so  this is something for the organization to consider  but anyway the numbers tell you something  and this is could measure to see that your utility would be higher 3 labour rooms obviously  but important thing is that you are turning away less patients so  that you know the whole idea it was actually in this course  the idea was not to discuss queuing theory extensively but  i essentially wanted to show you because  after having developed probability theory  i thought it was important if you  get insight into why this theory is so  useful and therefore  i started talking about you know its applications in the sense that so  you have seen that throughout your discussion of queuing theory  we have almost used all the concepts of probability theory that we developed and  other stochastic process is also  that we have the markova process that we have discussed already there also you see that you will be using  that we have used the concepts of probability theory so  the whole idea was that while you know seeing these applications  you get a good insight  and good understanding of the probability theory so  that was a basic idea it is not that we would trying to really cover the markova processes  and queuing theory extensively so  now i will just discuss exercise 9 where i have collected some problems  and then we will continue with some more discussions of some more applications of the probability theory we have used  may be through reliability i want to show you the applications of probability theory to reliability which will come later  refer slide time  23  36  so  exercise suppose  that at fixed time instance t 0  which is positive the number x t 0 of so  now  since i have collected these problems  from different books so  the notation may be a little different so  here x t0 is the number of customers in an m m 1 stationary queue  we have been refereeing to the number of customers in queue as n t 0 so  does not matter and is smaller than or equal to 4 so  at a fixed time the number of customers in an m m 1 stationary queue  is smaller than or equal to 4 calculate the expected value of the random variable x t0 as well as its variance if lambda is mu by 3 so  you have given rho  rho is 1 by 3  and you are asked to compute the expected value of the random variable so  therefore  see what are the possible values of x t 0 ? all you have told is that it is less than or equal to 4 so  therefore  the possible values can be 1  0  1  2  3 and 4 so  we just have to compute the probability  conditional probability  that probability x t 0 equal to say  i given that x t 0 is less than or equal to 4 so  you can do this  whatever we have learnt enough methods to compute your conditional probabilities so  once you have the conditional p m f of x t 0 you will be able to then find out expected value  and the variance of this random variable so  i have given the hint also  i have said that compute the conditional probability density function of x t 0  given that x t 0 is less than or equal to 4 now  question 2 says that for m m 1 k model  compute the probabilities p n  and 0 1 2 k  when lambda is mu so  i had said that in the in the lecture also  that when your rho is 1  we want to find out the probabilities  and also the values of l and l q so  the value for p and i have already given to you as  1 upon they all will be the same so  therefore  it will be 1 upon k plus 1 and now  you have to compute l and l q fine so  that is straight forward question 3 is that x t 0 is number of customers in a birth and death process  and with t non negative let the state space b consisting of 3 states which are 0  1 and 2 that is the system can have no customers  1 customer or 2 customers so  birth and death rates are given by so  the transition diagram you can see that lambda 0 will be lambda  but when lambda 1 will be 2 lambda  and mu 1 is mu  mu 2 is mu so  here they have defined the arrival rate  and the departure rate so  the arrival rate is the when the 1 then it is 2 lambda it becomes 2 lambda  refer slide time  26  57  so  set up the balance equations  and find the steady state probabilities p0  p1 and p2 so  i have deliberately given this because  this is departure from your  we have not really discussed the case when lambdas also change but  since there are only 3 possible states you should be able to write down the balance equations and therefore  then compute your the probabilities p 0  p 1 and p two so  i hope you enjoy doing this  then question 4 is again a this is an m m queue in equilibrium  with lambda equal to 2 mu by 3 find the probability that there are more than 4 customers in the system  given that there are at least two so  again this is a computation of a this thing so ; that means  you are saying that your n t if you know for a fixed time t your saying that n t is greater than or equal to 4  given that n t is so  there are more than 4 customers means l t is greater than 4  and then and your given that n t is at least two so ; that means  n t is greater than or equal to two so  conditional probability of n t more than 4 given that n t is greater than or equal to 2 so  again a simple computation of the conditional probability  refer slide time  28  16  now  let us come to question 5  consider a 2 server queuing system so  they are s s 2  where all service times are independent and identically distributed  according to an exponential distribution with the mean of 10 minutes now  the problem 5 and 6  i have taken from hillier and lieberman ’ s book and so  therefore  the statements are little different  in the sense that see the service times are independent  and identically distributed  which we have been referring to as markov process so  with a mean of 10 minutes so  remember the mean is 10 ; that means  the parameter for the exponential distribution will be 1 by 10 when a particular customer arrives  he finds that both servers are busy  and no 1 is waiting in the queue so  then what is the probability distribution including its mean and standard deviation of this customers waiting time in the queue ? see  you are asked to find out  what is the customer comes in to the comes to the system both the servers are busy ? so  you are asked to find the probability distribution of this customers waiting time in the queue so  w q  when 2 servers are busy  now  what will be the see since the 2 servers are busy ; that means  any 1 of them can get serviced  and then his turn will come so  his waiting time is till  1 of the service is gets completed right ok and so therefore  his waiting time is over in the queue the moment 1 of the services is completed so  now  since there are 2 servers  and each of them is you know with the mean time of 10 minutes so  once service over ; that means so  see what we have been doing so  our mu is 1 by 10 so  now  when there are 2 servers our  this thing mu will be 2 by mu 2 by 10 so  which is 1 by 5 and therefore  the corresponding mu will be the mean service time would be 5 minutes so  therefore  you can then compute the so ; that means  it will again be exponential with mean as 5 minutes and therefore  you can compute the variance i am just giving the hints  and within time in the system now  you can also determine the expected value  and standard deviation of this customers waiting time in the system so  in the system when you want to compute that it will be the waiting time plus your mu because  his own service see the mean service time is 10 so  therefore  your w is w q plus mu  and your mu is 10  the mean waiting service time see  that is not confuse here i am calling mu as 10 so  1 by mu will be 1 by 10  which is the parameter for the exponential distribution so  i am calling the mean service time  whichever way you like if you if you still want to refer to mu as 1 by 10  then here it will be 1 by mu because  his w q has a mean of 5  and his own service time has an average of 10 minutes so  then it will be 15 minutes so ; that means  in the system his mean time mean time in the system would be 15 so  correspondingly you will have mean  and the variance  because for the exponential distribution if mu is if 1 by mu is the mean  then 1 by mu square is the variance so  you can compute accordingly so  let us go to problem 6  refer slide time  32  00  now  consider an m m 2 queuing system with lambda equal to 4 and mu equal to 3  determine the mean rate at which service completions occur during the periods  when no customers are waiting in the queue determine the mean rate at which service completions occur during the periods  when no customers are waiting in the queue so  so here it is lambda is 4 mu is 3 and  so you will compute see here  little departure and again i thought  i will give you i have put the problem in to just to show you see you will compute p 0  p 1 and p 2 because there are 2 people in the system 2 servers there are 2 servers so  therefore  either no people in the system 1 person in the system or 2 people in the system so  mean rate  when no customer in the queue so  the mean rate  when no customer in the queue i am writing as  the formula for that is so  mean rate when no customer in the queue  refer slide time  33  09  so  this i am defining as mu 0 p 0  plus mu 1 p 1 plus mu 2 p 2  which is and divided by p 0 plus p 1 plus p 2 you see  by definition mu 0 is 0 since no service is completed when no 1 is in the system so  then your mu 1 is 3  but your mu 2 becomes 6 right twice mu mu 1 this is twice mu 1 so  mean rate when no customer in the queue  and this is how we are defining it so  you compute p 0  p 1 and p 2 and then for an m m 2 queue and you can then write down this now  7 th is that server in an m m 1 queuing system works twice as fast  where there are at least 2 customers in the system this means that your mu and t is mu if n t is 1 and so now  i am back to my notation because  here n t is the number of people in the system at time t up to time t so  therefore  this mu or at time t that is better way to put it so  mu and t is mu if n t is 1  and mu and t is 2 mu  if n t is greater than or equal to 2 so  here again  just change the system a little  and now  you can write down the balance equations for this system and  then what is the condition for the existence of the limiting probabilities  and you can compute the probability i have kept the thing so  small and therefore  you can you know do this changes in experimental that question a tells  what is the average number of customers in an m m 1 queuing system ? in equilibrium given that the number of customers is an odd number  which is you have to find expected value of n t  where n t is an odd number so  here again i have taken this problem from hillier and lieberman  now see remember you have to just compute the expected value so  your n t will be equal to 2 n plus 1  as n varies from 0 1 to n since we are asking for odd number of people in the system so  to find the expected value this is the conditional expectation so  expectation of n t given that n t is odd so  which you will write as 2 n plus 1 summation n varying from 0 to infinity  2 n plus 1 into probability that there are 2 n plus 1 people in the system and then divided by number of the probability of they are being odd people in the system  which is sigma n varying from 0 to infinity  probability 2 n plus 1 there is a customer  who was unable to enter an m m 1 c so  here again c means your k ; that means  finite capacity queuing system at time t 0 decides to comeback at t 0 plus 2  what is the probability that the customer in question is then able to enter the system given that exactly 1 customer arrived in the interval  and was unable to enter the system so  this i will leave for you people to you know really think about it because  this is interesting and it is challenging problem so  let us see that you are able to crack it so  the whole idea is that between t 0 and t 0 plus 2 somebody arrives the system is still full so ; that means  exactly at t 0 plus 2 there is 1 vacancy ; that means  one of the services has been completed and therefore  this person is able to so ; that means  at t 0 the system was full and then exactly at t 0 plus 2 the system is empty has 1 vacancy and so  this person can enter so  you have to work out this problem so  i hope you enjoyed doing this assignment sheet introduction to probability theory and its applications prof prabha sharma department of mathematics & statistics indian institute of technology  kanpur lecture  38 application to reliability theory failure law  refer slide time  00  15  so  now the last topic that i want to consider in this course is applications to reliability theory that means  again the concepts that we have learnt during the course of probability theory  want to show you some applications of course  some  everything may not be new  but still we want to put them altogether  so that you have a good feeling about and of course  see the reliability theory is very  it has become very important now with systems  the systems  very complex systems  you know  coming in  and then besides that you know  you have lot of dependence on the systems ’ functioning  otherwise if something fails  then lot of things connected with it also fail and you know  there is a chaos so  so there is a very growing area and we see that the applications are really interesting and very meaningful so  you can model situations here also through the tools  that we have learnt during the course now  so first of all let us first understand what we mean by reliability of a system now  just for example  consider a steel beam under load and so you have whole structure  you know  resting on a beam and there is a heavy load  then you have a fuse inserted into a circuit  so the source of stress so  you know  there are systems and then there are some source of stress so  here and for example  an aeroplane wing  the planes fly at high speed  there is a lot of friction and so there is some sort of stress on the aeroplane wing also then  electronic device you have  this is  when it is functioning again  that is  that is sort of a stress and therefore  so one can go on writing the number list can be very  very big  you know  anything that you use as a tool and then so  when  when you are using it there is some stress  some kind of stress on the tool and so things will change or things will happen so  that means  so you have source of stress  you have a system that means  a component or a whole system  and then you talk of state of failure so  what can happen ? the beam can crack  right and similarly  a fuse can burn out or the aeroplane wing can buckle because of pressure or stress and an electronic device can just fail you suddenly find  that your pc is not working or your  you know  electric kettle is not working or whatever it is  right so  therefore  you know you can write down your own this things you can take a component or a system  you can talk about what kind of stress that system is facing  and then you can also define the way the system will stop functioning so  essentially what we are saying is  that we have this so  now here we can and suppose we  i define  so therefore  so we need to talk about time to failure or life lengths and it can  it can  it will be a random variable and why because you see  if you take identical components under identical stress may fail at different and unpredictable times you really have no idea  sometimes things just stop working so  some fail early  some may fail at later stages and so on so  therefore  you can see  that whatever the systems we have talked here and talked about and many other  you see  that you can not really  of course  sure say  that ok  this component or this system will work for so long so  there is lot of unpredictability if they are not so  these things can not be predicted very well and therefore  because you never know how the stress works on a particular component or a system and also the manner of failure also varies  as i told you  because the beam will crack  the fuse will burn out and so on  ok  refer slide time  04  45  so  yeah  so the manner of failure  you can say  fuse working one moment will fail the next moment  right suddenly you find  that the thing is not working you are having good output  the radio was functioning very well  broadcasting and suddenly it goes away  goes out so  that the beam  you know  steadily over a long period  it becomes weaker and weaker and then cracks  right so  here again and and many other situations you can talk about so  therefore  it is  it is reasonable or it is appropriate to  to construct a probabilistic model and then treat the life time of the system or the component as a random variable so  this seems to be very appropriate and now  we will  what we will do is  we will talk about different models  that we can  that we can use for predicting or for the life time of a component or a system and we will be using lot of tools that we have learnt so far but so first of all let us define because now with the understanding  that what we mean by system failing and the manner of failure can be very different and the unpredictability of these components or systems failing under different situations so  we can now define reliability of a component or a system at time t say by r t so  we will define so  r t will be the  we will define the reliability of a system and we will say r t is equal to probability t greater than t so  at time t we want to know the reliability of  of a system  then this is equal to probability t greater than t  where t is the life length of the component so  suppose let us  we are talking about a component  then t is the life length and you want to know the probability  that t will be greater than t and r t is defined as the reliability function so  this is the reliability function and so for different values of t we can get the value of this function  which will tell us the probability that the system is functioning at that time  right so  essentially when we say  that r t  when we are computing this way this probability  so if t is the life length  that means  here it is saying  that life length  this more than t so  that means  at time t when you are computing this  the system is functioning  right so  the probability is not 0 well  i am not saying that i am saying  that probability  that t is greater than t  that means  the life length is greater than … so  the system is still  that is how you will interpret this because this is the life length so  life time of the component is greater than t so  at time t  that means  it is functioning  the system is functioning so  this is what  right now  for a particular item  suppose r t 1 is 0.95 so  at time t 1 you compute this and it turns out to be equal to 0.95 this means  that the  that approximately 95 percent of such items used under similar conditions will be functioning at time t 1  that is what we mean so  the 95 percent of the items will still be functioning  will be functioning at time t 1 so  this is what we mean by so  probability being 0.95 so  probability  that the life length is more than point is more than t 1 so  this here  this you will write as equal to probability  that t is greater than or equal to t 1  sorry  t greater than t 1 so  that is equal to 0.95 so  this probability is 0.95 that means  95 percent of such items and the similar conditions will be functioning at time t 1 and we continue with the …  refer slide time  08  59  so  you see  we saw that if f is the pdf of t  the random variable t  probability density function so  in that case we can write the reliability function r t as t to infinity because remember  this is probability t greater than t  right so  therefore  this will be the integral of f s from t to infinity so  because we were saying  that this definition tells us  that the reliability gives you the probability  that the system is functioning in the interval 0 t so  it has not  that it is not  sorry  the way to say it is  that the reliability tells you  that the system is functioning  has not failed in the interval 0 t that is the better way to put it  right  because the life time is greater than t that means  the system has not failed in this interval  right so  it can fail anywhere in the interval t to infinity  that is what reliability is  right  probability t greater than t so  that will be written as t to infinity integral of f s from t to infinity  which it is a capital f as we denote the capital f as the cdf of cumulative density function of t  then this is 1 minus f t  right so  this is what we can express the liability function as now  we will associate another function with reliability and which is with the random variable t  which is the in failure rate z and this is also called the hazard function now  if you recall  while talking about exponential distribution  i had introduced this hazard function and of course  we did not talk much about it  only i simply i showed you  that if the  if the pdf of random variable t is exponential  negative exponential  then the hazard function will be a constant and so we will see many more interesting kinds of hazard functions and  but anyway  we had come across this at that time  but now i am using this  that is why i said  that some of the things  which i talk about here may already have been discussed  but we are putting them all together  so that it becomes a complete unit so  now  failure rate we are defining as z t is equal to f t upon r t so  the pdf divided by the reliability function  which you can write as f t upon 1 minus f t  right  from here defined and of course  this is defined for f t less than 1 because this  remember f t is your  f t is probability  t less than or equal to t so  if f t is equal to 1  that means  and so this will say  that the life time is less than or equal to t so  if this is 1  then this  that means  it is a certain event  f t equal to 1 so  f t equal to 1 implies  that by time t  the system has definitely failed  is a certain event  right so  therefore  this has meaning only when the system is still functioning and therefore  this is reasonable condition to impose  that this is defined for f t less than 1 because f t equal to 1 would mean  that the system has or the component has failed so  therefore  so this is a failure rate and why  why is this  why are we calling it is a failure rate ? this is the definition  but now let us understand why this does covers the failure rate of the system so  consider the conditional probability t  capital t lying between small t and t plus delta t  given that capital t is greater than t so  since i am asking for  see the failure rate has to be after time t so  here you have to consider the inequality  strict inequality i can not allow equality here because my conditional event is  that t must be greater than t so  that is why  you can not write less than or equal to here so  this is what we have to consider this  i mean  what i am saying is  that the event should be described properly so  then the probability  this less than or equal to  so t lying between  so this is strict inequality and that is less than or equal to t plus delta t so  then by our rule  because this and this when you take the intersection actually means just this event  right  because capital t is greater than t is already satisfied  which is here so  therefore  this conditional probability can be written as probability capital t between small t and t plus delta t divided by probability t greater than t and this integral form  if i take f to be the pdf  then this would be my failure law then  this will be t to t plus delta t f s ds divided by r t  right now  for small delta t  you see  i can take this to the  by the mean value theorem or ok  here you do not need small delta t so  by the mean value theorem of integral calculus  this integral can be written as delta t  the length of the interval of integration into so  there exist a value  a point  real number psi between the interval t and t plus delta t such that this integral can be written as delta t into f psi so  this is well known for a mean value theorem of integral calculus divided by r t now  for small delta t when i can say  that this approximately z t into d because your failure rate is f psi of f t upon 1 minus f t so  then i can  because my delta t is small  then this interval is very small so  i can treat this as the value at t and therefore  this will become f t because if this interval is small  then your psi is close to t and so approximately i can say  this is equal to z t into delta t because your z t is f t upon r t and so this is what your and therefore  z t represents the proportion of items  that will fail between t and t plus delta t  right that means  during the time span delta t  this is the proportionate  proportion of items and that is why  we call it the failure rate so  among those items  which have not failed till time t  remember  because we are computing this  so this is p t greater than t so  all items  which have not failed till time t  then the proportion of those  which continue to work in the interval t t plus delta t so  that is represented by z t so  this is  you know  an interpretation of what i defined here  z t as f t upon 1 minus f t right so  this was the conditional probability so  life time is more than t and therefore  this is  so therefore  z t is the rate of failure  right so  that make sense  right  refer slide time  16  28  now  we could  we could define z t given the pdf f of t  right so  given the pdf of t  that means  the f determined z t  z uniquely  the failure rate the converse is also true  that means  if you are given the failure rate  then you can determine your t uniquely  determine your pdf f uniquely and once you know f  then you know  the cumulative density function also  right so  let us see that so  the theorem is  that if t  the time to failure is a continuous random variable with pdf f and if f 0 is 0  where f is the cdf of t  sorry  where capital f is the cdf of t  then f can be expressed in terms of the failure rate z t as follows so  then f t can be written as z t into e raise to minus integral 0 to t of z s d s so  that means  once i know z  then through this function i can compute my pdf so  if  if suppose you are  you somehow know the failure rate  you know  empirically or somewhere  then you can sort of compute the pdf also of t  right and of course  this make sense what  what are we saying  that f 0 0 implies  that r 0 is what  1 so  that means  certainly the function  this is  we are not going to be  the time is 0  then your system is not going to fail it will take some  require some time we will start the function  the system working or the component is working  then only after little lapse of time this is a possibility  that the system may fail or something so  the reliability will be 1 at 0 time and so this is not < you know  this is a reasonable assumption  that f 0 is 0 because you are talking of reliability and the reliability comes only when the system starts functioning so  some time has to lapse before you can say  that ok  the component has failed so  with this condition  now let us start computing f from given z from the given failure rate so  let us see  r t is equal to 1 minus f t  differentiate both sides that will give you r prime t so  the derivative of f t is the cumulative density function is the pdf so  this is minus f t  right so  r prime t is minus f t and therefore  your z t  which is defined as f t upon r t so  for f t you are going to write r prime t so  this minus r prime t upon r t  right so  f t is minus r prime t and therefore  if you integrate this from 0 to t  this is of the kind 0 to t r prime s because that is what you have here so  this is 0 to t z s ds and this will be so  now  you have this integrant of the kind where you have numerator as the derivative of the denominator and so immediately you know  that this is the integral of this is minus ln  minus sign is here so  ln of r s log of r s from 0 to t  right and now  here you see this that means  this will be  yeah so  if you write it out  this will be minus ln r t plus ln r 0  right this  what this integral will be  but then since f 0 is 0  r 0 is 1 and log of ln of 1 is 0 so  therefore  this is  there is no contribution from here and you have minus ln r t so  this is what  since r prime f 0 is 0  therefore r 0 is 1  right and so from here  yeah z t is this so  i should write  therefore r t r t  i wrote down this way and this  this i just integrated 0 to t so  r t is  so this is ln r and this is ln r t so  you have the equation  that z t  z t  i am sorry  yeah so  what about have you obtained  yeah ? now  let that that be there  yeah so  the long  equation has become long that is why so  what we obtained is 0 to t z s ds is minus ln r t  right so  from here we are  i am saying  that this implies that r t is so  ln is so  e raise to  remember when we write ln  it means  to the base e so  this could be e raise to minus 0 to t z s ds and now  you have it from there see  from this equation  our original definition because you want to compute  yeah so  i should have finished it here so  once you have this  now your z t is f t upon r t so  therefore  f t is r t into z t and r t we have just computed as this so  therefore f t is z t into e raise to minus integral 0 to t z s ds this is what our result was  we wanted to show this and so given a failure rate z  i can compute the pdf of the life length random variable t uniquely  refer slide time  22  17  so  there is an interesting relationship between the reliability function r t and the mean time of failure so  expected t would be the mean time to failure  right and so why i want to show you that so  this is the theorem  it says that so  the t is the random variable and r is the corresponding reliability function so  want to show you  that e t  the expected mean time  expected value of t is nothing but the integral 0 to infinity r t dt so  in other words  if you have this  then you can integrate this function and also compute e t there is nothing much so great about it  we  it can use the same concept that we have so  remember your definition of r t is  so probability t greater than t so  integral 0 to infinity r t dt will be integral 0 to infinity probability t greater than t dt now  this was  so i think i gave you this as an exercise in one of the earlier exercises when we were defining expected value of a random variable but let me now just spend time and show you why this will be true so  t greater than t  f integrating  now this i can write as integral t to infinity of f s ds  right  probability t greater than t was per  thus what we wrote down just now so  it is a t to infinity f s ds and then 0 to infinity now  let us integrate by parts so  i will treat  you know  this one as a first function and this as a second function so  integral of the first function would be simply t  right and so we want to have this t into integral t infinity f s ds from 0 to infinity  right  plus  why will it be plus ? because when you differentiate this  so integral of the first into the derivative of the first  second and the integral of the whole so  when you want to differentiate this  you see the lower limit is the function of t so  it will be as it as when you do the  you know  first integral  the integral of the first function into the second function minus  it is a minus sign but since this is the limit is the function of t  the lower limit is a function of t so  there will be another minus sign so  and the derivative of this will be 1 so  then f t  so plus so  therefore  this sign will become plus and this will be 0 to infinity t f t d t so  if you apply integration by parts to this  treating this as the first function and this whole thing as a second function  then you can write this now  you can immediately see  that there is a limit at the 0 point so  this whole thing has to be integrated  has to be computed between 0 and infinity so  at 0  this is 0 and this will be 0 to infinity f s d s  which is equal to 1 because remember  f is the pdf and the  and that variable t varies from 0 to infinity so  this integral is equal to 1 so  the f is 0 and now  here this is little complicated  but we can see  that limit here as t goes to infinity so  you see here  as t goes to infinity this part becomes 0 and this is going to infinity so  it can be shown  that the product here  the limit of this product will go to 0 so  once that happens  then that integral reduces to simply 0 to infinity r t d t  which is  i mean  it reduces to simply this  which is t f t d t from 0 to infinity and this is your p t  right  and so you have this relationship so  either way you can use  i mean  if you  if you know this  when you can say  that this integral is equal to this or if you know r  then you can  by integrating this you can compute the expected value over random variable t  refer slide time  26  49  so  now it is we want to study various failure laws that means  we want to find out the different pdf ’ s  which will be suitable for different situations where we want to study and of course  we will keep it very simple here  not going to complicated results but just look at various distribution  some of the distributions and we will show why they are appropriate for modeling certain situations for reliability  ok so  after defining your reliability function and your failure rate we are going to show how important tools they are to  you know  study these failure models  that we will be discussing so  these are the two basic tools that we need and continuously will be making use of them now  the questions  that arise  the first question  of course  then we will ask what underlying failure laws are reasonable to assume there is  what should be the appropriate form of the pdf of t we want to know and of course  people have  you know  computed data  i mean  collected data and then try to fit this various probability laws  which are  which are normal exponential and so on so  that is what  say  at some of the tested pdf ’ s we are going to look at and tested  by tested we mean  that you know  you try to  you have the data  you know system is going on and then you compile the failure times and so on  of the components and then you try to fit curve and these  the ones test we discussed  now have been very well tested and you know  found suitable for the some particular data that is we are going to talk about  right so  when there is wearing effect on the components  just as we said  that you know  been under heavy load  so slowly  gradually there is a wearing effect  and then breaks down so  for such situations where the wearing effect is the one  which is the cause of the failure  then normal failure law is considered to be appropriate ; considered in the sense  that again it has been tested and by fitting the data  by fitting  you know  having the particular kind of data  which is  you know  which is for components failing under the wearing effect  and then you know  finding out  that yes  normal failure law  the pdf  normal pdf seems to give the quite accurate results so  now  therefore  we want to and there are many situations where the wearing effect is the prominent reason for the failure of the  or the breakdown of the component or the system now when you look at the normal law so  because the normal law is such  that you know  if mean is the mean expected value  so mu is  yeah so  i am looking at the normal law  which is mu sigma square so  mean is mu  the expected value is mu and variance is sigma square  then this has the bell shape  the normal so  we have already studied in this course  i do not have to spend time on describing the normal curve to you  right and we know  that if you  if you take the area between mu minus 2 sigma and mu plus 2 sigma  then area under this  this two is 0.9572 and if you go up to 3 sigma mu minus 3 sigma mu plus 3 sigma  then of course  very little area is left out so  almost  i think  0.99 something the area within these two limits and you also see  that for t is equal to mu  this point is the mean as well as the mode that means  the maximum failure will occur at around the time t is equal to mu  right but since our variable t takes only non-negative values  therefore we will consider the normal distribution  that is  only the portion from 0 to infinity and not from minus infinity to infinity so  this is the  refer slide time  31  06  so  normal failure law implies  that most of the failures occur around t is equal to mu  which is the expected value and number of failures decrease as t minus mu decreases in absolute value on either side  right so  the number of failures will decrease and the probability goes down and so for example  if you take normal failures law  means  that 95.72 percent failures take place for t satisfying this mod t minus mu less than so  that means  if your t is in this area  then so it will be from 0 to infinity only  only this portion so  we do not have to worry about this  yeah so  whatever the mean  the expected value  the maximum failures will occur this time now  if you look at r t  the reliability function  then the reliability function  yeah  so r t is equal to 1 minus probability capital t less than or equal to small t  right because this is r t is equal to probability t greater than t  which can be written as this and now  here you can write this probability for in terms of the standardized normal variant  which we have been doing all along in this course so  this would be equal to 1 minus probability t minus mu divided by the standard deviation so  this is less than or equal to t minus mu by sigma  right and so this becomes 1 minus phi t minus mu by sigma  which is equal to 0.9  that i was just considering the value so  this is the  this is the function  functional form for your reliability function   refer time  26  49   and if you plotted here on the t axis  then it will be something like this so  at  at 0  t equal to 0  your probability t less than or equal to 0 is 0  right  because t has  takes only non-negative values so  this probability is 0  at small t is equal to 0 so  therefore  this is equal to 1 so  at 0 your value of r t is 1 and when you take r mu  then this will be t less than or equal to mu now  since t is normally distributed  we know  that area  this  this area  that means  this whole area is equal to 0.5 right half  the area is on this side and half the area  it is a symmetric curve so  therefore  this would be 1 minus 0.5  which is 0.5 so  therefore  for mu equal to  so this is at mu t equal to mu  the value of r t is equal to 0.5 so  this is the kind of curve when  then it goes to  as t goes to infinity  this goes to 0 so  the reliability function decreases with time now  yeah  so i was saying  that see what you can see from here is  this is your reliability function if you want high value for the reliability function  then obviously  so that means  you want this whole thing to be high  which that is  what i was saying here so  suppose this is equal to 0.9 and this implies  that this must be small and if  for this to be small you can again tell by the graph  that t must be away from mu this is the whole idea  right because as we said  that maximum failures will occur around t equal to mu  and as you get away from mu  the values become smaller so  if you want this whole thing  if you want high reliability  then your value of t must be removed from mu  right so  for example  if this is 0.9  then this implies  that your phi of t minus mu by sigma should be 0.1  right this you bring here  then 1 minus 0.9 would be 0.1 and so that will make it  make t minus mu by sigma equal to minus so  you look up the tables  right again i do not have to spend time on this  the standard norm because this is now standardized normal variant so  you look up the numbers table  among the tables corresponding to 0.1 area you look up so  it will be somewhere here for the standard normal thing so  it will be somewhere here point because you want only area 0.1 up from up to this point so  it will be very small  right so  this is minus 1.2 and so t comes out to be minus 1.2 times sigma plus mu so  that much remove from mu  your value of t is  if you want reliability of the order of 0.9 so  take another example now  here suppose the failure rate  the time  life line  life time of a component is normally distributed with mean mu and variance 100  that is  right so  the standard deviation is 10 suppose  this is this and you are told  that the reliability for the 100 hours is 0.99 so  r of 100 is 0.99  you have to find the value of mu  that is  the expected value of t you have to find so  since we know the functional form for r t  that means  again 0.99 is 1 minus phi of so  we standardize the normal this variant t  which is 100 minus mu upon 10 standard deviation  right so  this is phi 100 minus mu by 10 so  that gives you  that phi of 100 minus mu by 10 is 0.01 so  again we look up the standard tables corresponding to the area 0.01  this value  the value of z is equal to minus 2.33 so  the tables so  see this smaller  this becomes the  further away you go from the mean value  that is what we are saying and so this implies  that mu is  see here you will multiply this with this  and then so it will become 23.3 and mu comes to this side  this gets added to 100 so  this will be then 123.3 hours so  the mu  that means  the mean is here and so you see  this is removed from the mean  this is 123.3 hours so  at 100 hours if you are asking for a reliability 0.99  then your mu is this so  this is the whole idea  that you  if you have  if you  if your data or your experience with the system that you are working with is  that the normal distribution is appropriate for studying the failure rates then so  here of course  you should also look at what your z t will be  right so  if you want to compute  which may not be very so  for example  your z t  we said  is f t upon r t  alright so  which will be 1 upon root 2 pi sigma  ok let me just  so this will be equal to your f t is 1 upon root 2 pi sigma e raise to minus 1 by 2 sigma square x minus mu whole square divided by 1 minus phi of t minus mu by sigma so  something like this this is your failure rate so  if you want to compute z  you will get this complicated expression  but it seems  that here your reliability function is the one  which is more useful and as a simple form because all you have to do is to  for a fixed value  for a given value of t mu and sigma given  then you just have to look up the normal tables and compute the reliability of the system at any given time t  refer slide time  39  11  failure law  i said  to be applicable we want this  because obviously  the time to failure can not be less than 0 with only when this apparatus or the instruments start functioning  then you talk about its failure time and so on so  time to failure so  therefore  since this is less than or equal to 0 and normally  r  r  the normal distribution extend from minus infinity to infinity but what we saying here is  that the most of the curve should lie to the right of 0 so  that means  here is  so the curve who should be like this so  very small area is to the left of 0 so  most of it lies to the right of 0  then the computations would be fine so  this is very important so  that means  this probability t less than or equal to 0 should be essentially 0  negligible  very small that is what you want to say now  another way to handle this situation could be  that i consider the truncated normal distribution that means  you truncate when you  you may have your normal distribution  this and then you truncated this portion and so that means  then you would consider but  then since it has to be a pdf  so then you will have to so  that is what i am trying to say  that you know  truncated normal distribution so  if you consider the truncated normal distribution  truncated to the left of t 0  then the pdf would be this but that is not defecting the actually situation because by this what we are doing is  since i want to call this a pdf  so this integral  and of course  is 0 for x less than 0 so  this is from 0 to infinity so  what we are saying is  that this will be from 0 to infinity this will integrate to 1  but this is not what i want because i want the normal failure law  but it should be side that the most of the curve lies to the right of 0 of t equal to 0 so  that is the meaning and therefore  this of course  this will complicate your computations also  but besides that it will not give you the desired results so  therefore  the truncated normal distribution is not to be considered it is simply  that keeping this in mind we have to make  show  that you know  most of the curve lies to the right of 0 so  therefore  well  we compute the probabilities they would be approximately alright for as i said  that the normal failure law is for the ageing where the ageing is permanent so  now  we will study  we look at the other failure laws  which have again been tested for different situations and have proved very  very  have to prove to show good results so  this would be exponential distribution and viable distribution and some others  refer slide time  42  08  so  let us look at the exponential failure law now  of course  obvious way to define the exponential failure law would be by defining the pdf so  we say  that the pdf t is alpha is e raise to minus alpha t where t is positive  takes positive values  and then alpha is also some  positive constant  right and  then we can obtain r t and z t  but  but that is not really have that dramatic effect as when you say  that the law  we say  that the failure rate that means  z t is a constant  is equal to alpha  right so  here i have just said  that alpha is some constant  but actually when your law is exponential law failure law is exponential  then negative exponential  then your failure rate  sorry  yeah your failure rate would be a constant  right is a positive constant  is equal to alpha actually so  alpha is your failure rate so  this is constant  right and immediate consequence of this is because remember we said  that we can  given z we can uniquely determine the pdf and also  given the pdf  we can uniquely determine the function z the failure rate so  here you see  the definition was  that f t would be z t e raise to minus integral 0 to t of z s f s so  here z is a constant so  therefore  this is alpha into d s so  integral  this leads to t so  t alpha and here z t is alpha again so  this is alpha e raise to minus alpha t for all t non-negatives so  therefore  this is your  so immediately you compute the pdf of t and the converse is also immediate because if you are given  that the f t is alpha e raise to minus alpha t  then this we have already done this computation  but anyway let us just go through it again so  z t is f t upon 1 minus f t  which is r t and so f t is alpha e raise to minus alpha t and your  you know  that 1 minus f t is e raise to minus alpha t this is probability t greater than capital t greater than small t and so it will be e raise to minus alpha t and so comes into alpha so  this is the constant so  your z t  the failure rate is constant so  immediately we can write down this theorem that and so if i remember correctly  we had not done this part  that means  given the failure rate when i had talked about the exponential  even we would  we had just introduced the exponential distribution  i had defined the hazard function or the failure rate but i did not  at that time discuss this part  that given z t you can obtain your pdf uniquely  right so  now  we can immediately write down this theorem because i have shown you both ways  that is  if and so for constant failure rate the only pdf that can be there is your negative exponential and if the pdf is negative exponential  pdf of the life time random variable t  then it has to be  the failure rate has to be a constant so  immediately we have the theorem  that let t the time to failure be a continuous random variable assuming all non-negative values  then t has a negative exponential distribution if and only if it has constant failure rate so  this is now neat  neat way to present the whole thing  that is  there can be no other pdf  which satisfies the condition  that the corresponding failure rate is a constant so  constant failure rate would always mean exponential pdf ’ s  refer slide time  46  04  and constant failure rate implies  that it is time independent  right so  no matter  that is  the failure does not change with time  the failure rate does not change with sign so  no matter so  therefore  this will be appropriate for situations where there is no wearing effect  right so  that means  no matter how long the component has been working  it does not matter  it has no bearing on the failure of the component  it will only be some external  may be  i will come out with in the next lecture i will try to show you some more  you know  ways of describing the situations where these different failure laws can be appropriate so  essentially now try to think of this situations where the failure is not because of because of the wearing effect that means  not because of some kind of stress or load  but it is so  therefore  as we try to say  that if you take a fuse  then fuse can be working fine for a long time and then suddenly it fails so  it is not because may be  because of high current or something high current is come  then the fuse burns out otherwise it may continue for a long time so  therefore  such situations would be very appropriately modelled by the exponential failure law and one can  you know  the now  that you read about this yourself  you know  try to think of components or systems where the failures are not because of the wearing effect or this kind of some kind of load or stress  but it is a different kind of failure and therefore  this can be model by exponential law and you can see  that how effectively it will give you the parameters that you will require for  you know  predicting things about the model introduction to probability theory and its applications prof prabha sharma department of mathematics and statistics indian institute of technology  kanpur lecture  39 exponential failure law weibull law  refer slide time  00  14  so  i will continue discussing the exponential laws very important one and any way there are some many aspects that there may be some repetition also  but does not matter so  we said that for example  i have been giving the example of queues  which does not show the varying out effect and are similarly a jewelled bearing you know you have them in watches so  there is no bearing out effect on such components and they are as good as new while they are functioning right it does not matter how long they have been functioning they are as good as new and you have fuse has not burnt out it is like a new one  a jewelled bearing does not wear out so  this is again and again i am trying to give you examples of component  which for which and therefore  for such components the exponential law is appropriate and is supported by empirical evidence ; that means  when you collect the data for such components how long it takes for them to fail and so on so  then and then fitting the curve to the data it turns out that exponential law is an appropriate one was such components so  another way of saying that there is no wearing out effect is as follows consider the conditional probability that capital t the life time lies between t and t plus delta t  given that capital t is greater than t right now  the intersection of these 2 events is simply this right  because here also t is greater than t and it is less than t plus delta t so  therefore  the intersection of these 2 events is this so  then their conditional probability can be written as probability of the intersection of the 2 events divided by probability that t is greater than t right now  this you can see immediately is the probability t less than or equal to t plus delta t minus probability t less than or equal to t so this event right and since this is 1 minus e rise minus alpha t plus delta t minus of 1 minus e raise to minus alpha t right so  the 1 1 cancels out and you will be left with e raise to minus alpha t minus e raise to minus alpha of t plus delta t divided by this probability  which is e raise to minus alpha t yes  of course  i am showing you for the exponential law so  therefore  this is 1 minus e raise to minus alpha delta t  which is nothing but the probability that t lies between 0 and delta t so  tells you that this probability is independent so  this conditional probability is independent of t depends only on delta that is depends only on the length of the interval that you are considering ; that means  you want to consider so that means  the here from t to t plus delta t so  the length of the interval is delta t so  this probability this conditional probability is independent of t and depends only on delta t right so  therefore  this is another way of saying that it is memory less or it the varying effect is not there that means  is not it does not matter for how long the system is already will working  but now when you want to look at the probability that it will be working in the interval t to t ; that means  it fails before t plus delta then that is dependent only on delta t so  this is the whole idea right and so we have seen that there are many situations where this is a very appropriate law now  see this want to make a note here that even though this will  this probability will all if would say t less than or equal to capital t less than or equal to t plus delta t this will also come out to be the same as this one right but since  we are considering the conditional probability that t is greater than capital t so  therefore  we have to consider this event right and not this event so  sometimes inadvertently may be one can i may have written it like this  but the when you looking at this conditional probability then it has to be t strictly less than capital t and here it is less than or equal to t plus delta t so  that would be the right way to write the event and the even though  because of the continuous case the 2 probabilities may come out to be the same this is the important so  thus as long as the component is working it is as good as new  refer slide time  04  47  now  in this equation suppose  i expand the right hand side so expansion for e raise to minus alpha delta t right so  all of you should be familiar that much calculus everybody has done so  you can write down the expansion for the e raise to minus alpha for delta t  which will be 1 minus alpha delta t plus sorry  this should have been 2 factorial and so on  powers of delta t and then when you open up the brackets 1 cancels out and then will be have alpha delta t plus higher power terms containing powers of terms like delta t square delta t q and so on fine now  when delta t is small  we can just ignore these terms and therefore  for small delta t probability of failure in time delta t is proportional to alpha delta t so  this is what again just reiterating what we have been saying so  now  in fact  we have given it better expression from here this is more you can immediately you conclude quite a few things from here so that means  in a small interval no matter where the time interval is length delta t is the probability of a failure in that time period is proportional to time period itself delta t now  this is if you again see i am saying the same thing again which i said so  this is nothing but your poisson process this is the one of the basic assumptions of a poisson process in fact  what you can say now here is that  suppose you have a electronic device and you have lot of components  which have the same  which follow the same exponential failure law and they have the identical distribution that is the same the same parameter lambda let us say right and then your … and of course  the components behave independently so  that that condition also for a poisson process is satisfied that is the  you know arrivals are independent and so here the components will behave independently so  their failures will also be independent of each other so  that assumption plus the assumption that with an in a small interval the probability of a failure is proportional to alpha delta t ok so  then in that case with those 2 assumptions you can then say that  if you are considering let us say time period 0 comma t then the number of failures within this time interval will follow a poisson process so  you can see that the arrival and the inter arrival times that will talk in detail later on so  the inter arrival times and the arrival pattern so  inter arrival times would be exponential and the arrival patterns would be poisson and so on so  we will continue with that discussion so  now  because again we want to say this thing now that since the for the exponential failure law  the failure behavior of an item depends only on the length of the time period being considered and not on its past history right so  therefore  and for the non exponential just like  we have so far considered the normal failure law so  for non exponential failure laws  we pass this matter it does matter right  when you are under we know stress then the varying out effect is there and so it depends on how long the stress has been and so on so  for non exponential failure laws we pass thus matter so  therefore  it is important to understand that when you talk of the time t  you know life length so  for the exponential failure law t will denote the time in service up to failure right  because it does not matter when you start counting it is if the component is functioning then you start counting the time from then so  up to failure t will denote the time it does not matter when you start counting it right  but for other for non exponential components t will denote the total life length up to failure so  you started functioning from whatever time you count your time form that and so  capital t will in that case the normal the random variable will be will denote the total life length up to failure so  total means at you whenever use start surveys or whenever you start using the item then you start counting your time from here whereas  here it does not matter you start counting from any point and then up to failure so  the life length will denote that so  t will denote that time period so  it is important understand these 2 differences between you know  how you count the time for exponential failure law and for a non exponential failure law  refer slide time  10  09  let us look at the various graphs connected with the exponential failure law so  this is the familiar one right  at t equal to 0 this will be 1 it will be equal to alpha right and then it will go down this way right  as t goes to infinite this will go to 0  and then correspondingly you see z your failure law of a rate of failure z t is alpha right which is the constant right and so  it continuous to be alpha value alpha for all values of t this is your t axis this is your z t axis then f t would be of course  so 1 f t would be what 1 minus e raise to minus alpha t right  oh sorry  this function right so  1 minus e raise to minus alpha so  that t equal to 0 this will be 0 and then s t goes to infinity this goes zero so  the function finally  goes up to 1 and then your r t the failure function ho sorry  the reliability function yes  the reliability function r t  which is 1 minus f t and therefore  this is equal to e raise to minus alpha t and so here again f t equal to 0 the value will be 1 and then it will go down s t goes to infinity so  the reliability goes down as t goes to infinity ok so  this is the graph for the p d f of an exponential failure law so  t equal to 0 t equal to alpha and then it goes down to infinity as t goes to infinity then we know that the failure rate z t the hazard function this is a constant right and the constant value is alpha then cumulative density function which is f t equal to 1 minus e raise minus alpha t would again at t equal to 0 it will be 0  because this will be 1 so  1 minus 1 is 0 and then it goes up to 1  the reliability function would e rise to minus alpha t so at t equal to 0 this is will be 1 and then it goes down to infinity so  these are the 4 graphs the 4 functions relate with the exponential law and you have picture of the all 4 of them now  let us look at this example if the parameter alpha is given and reliability is also given ; that means  r t is specified we can find t so ; that means  given alpha ; that means  your specified the failure law and then you are asking for certain level of reliability so  you want to know what would be the time required for the equipment or the component to operate to achieve that reliability right so  the number of hours of operation required for the specified reliability level i should say now  let alpha be 0.01 and reliability is 0.9 so  you want this to be obtained and your parameter is 0.01 so  if alpha is 0.01 then your mean will be what ? so  for exponential distribution the mean is so  expected t would be 1 by alpha  which is 1 upon 0.01  which is hundred hours  if you are talking if a unit of time is hours then this is hundred hours ok so  now  so therefore  the number of offers that are required is given by to achieve this reliability level then you are saying that e rise to minus 0.01 t  remember this is the function reliability function so  e rise to minus 0.01 t should be equal to 0.9 so  you want that value of t  which will satisfy this equation so  you take log of both sides and this will then give you minus 0.01 t is equal to l n of 0.9 and remember l n of number less than 1 is negative so  therefore  this is so this is minus sign here right and so if you  now  divide by 0.01 then you get that the t is equal to hundred into l n of 0.9 which comes out to be if you look up the values of l n 0.9 then multiplied by hundred that gives you 10.54 hours so  therefore  the way you can depict this is that out of hundred components all above working simultaneously and ninety what we are saying is and if they all operate for 10.54 hours then our expectation is that ninety of them will not fail so  after 10.54 hours ninety of them will be working so  this is what we mean by the reliability level and so on so  therefore  you know essentially it is question of given what and then what will you can compute so  sometimes you may be given the time then you can compute the reliability level right so  if you given t then you will be able to determine this number and if you are given this reliability level then you can give determine the time or if you given time and reliability then you can determine the parameter ; that means  you can uniquely determine the exponential failure law  because you only need the parameter alpha to determine the failure law  exponentially failure law ok  refer slide time  15  55  let us look at another example so  here you given the cos c interms of mu so c is 3 mu square be the cost of producing an item  where mu is the mean time to failure so  again we talking of exponential distribution  exponential failure law and mu is the mean so  therefore  if mu is the mean then remember the distribution the failure law would be minus 1 by mu t right  this is what you have now  this cost is 3 times mu square so  which means that  if mu is small then the cost is small  if mu is large then your cost would be accordingly large right ok  which makes senses so may be  because if your mean time to failure is small then you expect that the cost is also small and if the mean time to failure is big is large number and ; that means  you expect the component not to fail very early i has a long life time and then that case the cost of producing that item would be also high so  it is reasonable to assume the cost in this way right now  suppose rupees d are earn for every hour  the item is in service so  you earn a profit of d rupees per hour  when the item is functional now  you want so therefore  profit for item is given by the profit would be d in to t  if the life time is t hours then d into t minus the cost 3 mu square right and t is the number of service hours right so  find the value of mu for which the profit is maximized so  expected profit so certainly  because this is a random variable so we will maximize the expected profit so  the expected profit is these right  because d of e t this is a  i mean this is not a random variable this would be some fix number so  then d of e t minus 3 mu square and e t is mu so therefore  d mu minus 3 mu square so exactly what ever  i saying that yeah so  this is  so therefore  to maximize this expected profit  i would differentiate this is respect to mu is a function of mu and put it to zero so  that gives me d minus x mu is equal to 0  which implies that mu is d by 6 and of course  only critical value and  but still you need to verify the d square by d mu square is of the function is minus 6  which is less than zero so  therefore  the critical point is a point of maxima so  the value that we get of mu here is value which maximizes the expected profit ok so  therefore  u mu is equal to d by 6 is maximizing the profit and the maximum profit is d square by 12 rupees so  just trying to give you a feeling for the failure law  exponential failure law and the kind of problems that can be discussed and that arise corresponding to these so  again the level is at very basic you know  the level is very basic  because this is just trying to give you a gleams of how these probability tools at we have learnt can we used for answering so many questions about day to day operations of you know systems  service systems and so on so  this is the whole idea right otherwise reliability theory has become very complex and in fact  the next failure law that we will discuss is a complex one and we just try to understand the basics of that of the weibull failure law  refer slide time  19  55  so  let us the talk about the weibull failure law and you can see that now  the degree of complexity is going up and we have not so for discuss this distribution probability law also so  let us look at it and the idea here is to  because the constant failure rate was only applicable to a special kind of components  which were not let us say  for which there was no wearing out effect right so  that was a special situation and we have seen that there are so many almost electronic devices or you know behave that way and so the exponential noise appropriate for them so  now  if you want to modify this constant rate then the weibull failure law was thought of and this is alpha beta t raise to beta minus 1 so  now  you have introduced power of t of the time and of course  two parameters and they can more than 2 also so  we are talking of a 2 parameter weibull failure law and so here alpha and beta are positive and t is greater than 0 as usual  because its 3 time lifetime wherever so  therefore  has to be non negative now  you can look at i have drawn various pictures of z t when for values of beta and different values of alpha and beta and so may be will just look at it  let me just first compute your f t so  remember we said that we can compute f t uniquely given the failure rate functions z t so  then this z t e raise to minus integral of 0 to t of z s d s integral 0 to t of z s d s right  this is our formula for computing f t given z t so  then here if you substitute for z t this is alpha beta into t raise to beta minus 1 e raise to minus integral 0 to t alpha beta s raise to beta minus 1 d s right so  if you just look at this integral let us just compute so  this will be s raise to beta minus 1 d s from 0 to t and the integral here is 1 by beta is raise to beta 0 to t so  therefore  this is 1 by beta t raise to beta so  if i make that substitution here  i get my f t s this so  this is the p d f connected with a weibull failure law and the failure law is specified there so  yeah the weight looks it is it will complicated  but just see when you put alpha equal to 1 and beta equal to 1  alpha equal to 1 beta equal to 1 then this is 1 and this will be e raise to minus t so  e raise to minus t would be your yeah  so this would be your p d f right the exponential with parameter 1 and that is the 1 i have drawn here right then if you look at the value alpha equal to 1 and beta equal to 2 so  therefore  in this case the  beta equal to 1 this will be exponential and the failure rate will be constant which will be 1 so  of course  here i have drawn it only for beta equal to 1 so  alpha is as it is  this 1 is of course  you put alpha equal to 1 also so  anyway this is your function for the failure rate then when you put alpha equal to 1 and beta equal to 2 then i have drawn this one  this is the 1 for beta equal to 2  of course  not a very accurate  not very accurate figures so  you can always google search and then you can find nice pictures very accurately drawn graphs so  beta equal to 2 now  you look at this thing here this is alpha 1 beta equal to 2 so  this is twice t ; that means  it is a linear function of t so  therefore  you see of different values of beta things are changing so  if alpha equal to 1 beta equal to 1 you got constant  alpha equal to 1 beta equal to 2 you get and in fact  any value of alpha  alpha does not have to be 1 then in that case it will be a linear function of t right  if beta is beta is 2 right and so i have here of course  i have drawn it for alpha equal to 1 and beta equal to 2  the diagram then and the corresponding p d f will be 2 t e raise to minus t square then for beta equal to 3 for example  i have drawn the picture here also for beta equal to 3 so  then this starts taking a bet more well shape and beta equal to 3 alpha equal to 1 will be 3 times t square so  that will be ; that means  z t is quadratic function of t and correspondingly you are this thing will be so  here when beta is 3 then of course  this is t square and then e raise to something right so quadratic into exponential function now  and for beta equal to 5 for example  it will become more steep like this and then as beta goes to infinity  you see  you can show that will simply be a spike no just a spike  because beta is going to infinity sorry  i mean yeah  beta is going to infinity then this will simply just spike into this thing  which will  which you call as a delta function so  at the point yeah  so some way here it will become a spike as p term goes to infinity yeah so  the thing becomes narrow and narrow or as your beta goes up so  here beta is the shape parameter therefore  you see beta is shape parameter and 1 by alpha is the scale parameter so  why you scale the whole thing right ; that means  when you drawing the thing when you so  failure rate is proportional to power of power beta minus 1 of t so  therefore  this is the generalization that we have made to the constant failure rate and so this is the failure rate is now proportional to t raise to beta minus 1  refer slide time  26  33  so  you can see that yeah and then this also gives you that good feeling now  if an example  if your beta is less than 1  if beta is less than 1 then this will become negative so  t will be in the denominator and so alpha beta upon t raise to 1 minus beta and that will be for as t goes to infinity so  the denominator will go to 0 and therefore  this will let me show  alpha beta upon t raise to 1 minus beta right so  as t goes to 0  this goes to infinity  the denominator t goes to 0  this goes to infinity and so no it should be the other way i want to show that for beta less than 1 for beta less than 1 this is negative so  when i take it here it will be positive this power is positive and so as yes  as t goes to 0  this goes to infinity  because this goes to 0 so this goes to infinity as t goes to 0 right yeah  this should be and therefore  it is this way and then s t goes to infinity this goes to 0 and so failure rate decreases with time now  failure rate decreases with time let me see essentially defective items fail early and the failure rate decreases over time as the defective items have been we did out so  all the defective items have been we did out from the population so  that case the failure rate will decrease with time right so  all defective items fail early and therefore  as time progress is your failure rate will decrease so  this is the situation that is gets small moderal when you by putting beta equal to less than 1 so  all values of beta between 0 and this thing here right so  we should take this  then this is the situation it will suppose to moral and beta equal to 1 we have already discuss thoroughly now  here of course  since the failure rate is constant so  as time goes on the failure rate does not change so  this is because random external events are causing the failure that could be one of the reasons so  random external for example  if a fuse  fuse will blow out if the high current comes suddenly in the line right so  therefore  that is an external event and many others can be explained high wind and so on  for other you know ten high tension wires you can snap and so on so  therefore  beta equal to 1  because the failure rate is constant it is understood that external events would cause the failure could be the reason for the failure and for beta greater than 1 as we have seen failure rate is increasing with time and therefore  this modules the situations were aging process has a role to play in the failure of the system and that is parts are likely to fail as time goes on and this is when the stress part so  you see this certainly captures it is a more complex and it will more comprehensive failure law  which captures more than one situation and you can play around by manipulating the value of beta and alpha and try to get accurate results so  this is the whole idea and we will continue with the discussion on weibull distributions  refer slide time  30  13  so  let us make this have computations about the expected value and the variance of a weibull distribution so  e t the theorem says that e t is alpha raise to minus 1 by beta gamma of 1 by beta plus 1 so  we are know the gamma function and then v t is the variance would be alpha raise to minus 2 by beta  gamma of 2 beta plus 1 minus gamma of 1 beta plus 1 whole square right  which is we are using the formula that variance is e t square minus expected value of t square minus expected t whole square right now  so just apply the  because we have already computed the f t the p d f for t when t e has a weibull failure law then this is t into alpha beta t raise to beta minus 1 e raise to minus alpha into t beta d t right ok so  yes so now  you can see that  this t beta minus 1 and t beta so  this prompts you to make the substitution that t beta is y no so we will do this so  again you are familiar with this part of the calculus you can do this integration so  t raise to beta is y that will make beta t raise to beta minus 1 d t is equal to d y the limits will not change will remain from 0 to infinity  since beta is positive so  for t equal to infinity y will also be infinity and t 0 y 0 so  now  therefore  this thing whole thing gets replaced by d y so  you have a beta t beta minus 1 and d t so  this we will replace by d y  when you are left with t and alpha and then e raise to minus alpha y  because t raise to beta is y so  therefore  this  what you have  alpha e raise to minus alpha y and y raise to 1 by beta and there is a yeah  so y raise to 1 by beta  because you have a t here so  t will be y raise to 1 by beta so  therefore  this is what you have now  you see this looks familiar  because you can now relate this with the gamma function gamma p d f so  here alpha e raise to minus alpha y then you have to have alpha y here as the variables alpha y raise to 1 by beta now  y 1 by beta is there so alpha 1 by beta m adding here so  therefore  i will divide by alpha 1 by beta and then i need a gamma of 1 by beta plus 1 so  this integral d y to be 1  because this is the p d f of a gamma distribution with parameters alpha and 1 by beta so  then be i am left with this and this final so  therefore  the expected value of the random variable t where t is has a weibull failure law is given by gamma of 1 by beta plus 1 into alpha raise to minus 1 by beta right and then the second part should be straight forward so  you had this so  therefore  i need to compute expected value of t square and so that will be t square alpha beta t raise to beta minus 1 so  now  you see you are again beta t raise to beta minus 1 and e raise to t raise to beta would become this thing yeah i am sorry  i mean beta t raise to beta minus 1 d t that will be d y from here right and then you have t square so that will be y raise to  i am not written the integral here so  anyway this will that is reduce this will be equal to 0 to in  i have written t this is 0 to infinity yeah  this will be 0 to infinity so  y raise to 2 by beta and then you have an alpha and then you have t raise to minus alpha y d y right as so here again i will do the same trick that i did here so  alpha e raise to minus alpha y is there  then this you need to write this 0 to infinity alpha y raise to 2 by beta alpha e raise to minus alpha y this is the same thing and then you will divide by alpha raise to 2 by beta then you need a 2 by beta plus 1 right and you will multiply by 2 raise to beta y gamma of 2 beta plus 1 2 by beta plus 1 and so this whole thing will be and there is a d y right so  then you will be left with gamma of 2 by beta plus 1 into alpha raise to minus 2 by beta so  this is the expected value of t square right and therefore  the variance will be this minus the expected t whole square  refer slide time  35  01  so  you take out alpha raise to minus 2 by beta common and then you have so this is just for you now come and they here again we could make use of the gamma distribution computations to compute the expected value on the variance now  again so we have seen that weibull distribution represents and appropriate model all if failure law whenever the system is compose of number of components right and the failure is primarily due to the most severe flow how many large numbers of flows in the system so  this is what is happenings  you have lot of components and lot of parts in the device that you have using and each one of them has a flow  but then it will be govern by the most severe flow of among all the components this is what the  you know you can say that this is the representation of there is a situation  but which weibull distribution represent and your alpha beta and of course  you have seen that you know by changing the values of beta you can either have a increasing failure rate or a constant failure rate or a decreasing failure rate so  this we have already seen right and yeah  so here you know i have just being able to give you  you know  short glames into the how what these distribution can do and one needs to really work at lot of examples to understand the implications or the importance or the importance of this distribution now  let us just look at this example so  each of the 6 cubes of a radio set has a life length e years so  our time unit is year which may be considered a random variable so  the lifetime of a radio tube in a radio set in number of years should we consider as a random variable suppose these tubes function independently of each other so  that is important where working independently of each other what is the probability that note you will have to be replaced during the first 2 months of surveys so  will after you know translate this to years  because the  our unit of time is and years now  the p d f of the failure time to failure is given by this 50 to t e raise to minus 25 t square so immediately you can recognize that  this is weibull distribution and since t has power 1 so  your beta is to 2 right  this is beta is equal to 2  because t raise to beta minus 1 so  therefore  if beta is 2 then alpha is an of course  from here alpha is 25 so  this is alpha beta  alpha beta into t raise to beta minus 1 e raise to minus 25 t square  because this is beta so  this is the weibull distribution right now  of course  we have not made this computation for the weibull distribution  but certainly you can do it and may be you can use in my recover method so  essentially yeah  it is a weibull distribution with these are the parameters then you since the tubes of functioning independent of each other and you do not want and of course  let me say that your t is 1 by this is 2 months so 1 by 6  which i have written it here right so  t is 1 by 6 you want to  you have capital t right so  yeah  so we want their 6 tubes there working independently of each other we do not want anyone of them to fail so therefore  in the first 2 months so  the probability of let us say the first tube not failing in the first 2 months is t 1 greater than or equal to 1 by 6 so  time unit is 1 by 6 and then since all of them are independent of each other we do not want any of them to fail so  then this would be probability t 1 greater than or equal to 1 by 6 raise to 6 so that is we will  you know this is not a difficult integral again you know  because see you have seen my computations here for e t and variance t so  you can just use those you can use the gamma distribution computations to do the computations here and then you can find out this probability raise it to 6 so  the answer is approximately 0.5 raise to 6 so  this integral you can handle now  since i have given you the method out computing e t was so exactly it just twice on to that so  different per values of t and so on right ok so  now  this does not exhaust the failure loss  i have only as i told you and i have been repeating it that we have only considering very basic failure laws here and my of course  aim was to since we have discussed the probability theory and so the various tools you have learnt about so  i just thought that i would like to show you the various applications also of these tools that we have learnt in the course so  that has been the whole you know  whole idea the theme across the course that you learnt the theory and then you learnt to muse it also and so markov process is discrete markov processes then we will we have talked about continuous markov processes and the process special case is which are poisson and exponential distributions and then birth and death process since and finally  applications to reliability theory and here also the basic concepts have been given to you  but as i said it is a very growing large growing area very important and a lot of applications of of course  probability theory and the many more people have come up with failure laws  which probably supplement the theory that has been discussed introduction to probability theory and its applications prof prabha sharma department of mathematics & statistics indian institute of technology kanpur lecture  40 reliability of systems now  having discuss the reliability of a component or a device  where we are assuming that a single piece  single component let me now talk about reliability of systems  where there are more than 1 component so  here again the treatment will be simple so  that is why i have stated in the beginning only  the simple cases will be consider  but once you learn the basic technique  refer slide time  00  40  then  you can always divide you know break up  complex device into smaller systems and then you can try to compute the reliability of the whole system so  let us see we can now  here i have adjusted beginning with this simple case that 2 components are hooked up in series so  this how they are right c 1  c 2 there are 2 components and there in series  and so for the in order for the system to work  both components must be functioning there in series  may be performing different tasks for the whole device and  so they both have to function if any of them fails  then the system will fail so  this is the whole idea they working in series now  we also make the assumption  and of course  this is important otherwise ; things will get complicated  and we have to learn to methods for handling dependence also but  right now  we just assume the independents to show you the  how to develop ? how to compute the reliability of the system ? so  if they are functioning independently then the reliability r t of the system can be obtained  in terms of the reliability r 1 t and r 2 t of the 2 components so  i am just denoting the reliability of the first component by r 1 and the reliability of the second component i should probably write just this small t  into value of the so  therefore  i can compute the reliability of the system in terms of the reliabilities r 1 t and r 2 t of the 2 components when this is a simple computation we have already done it  so many times so  here your asking for probability greater than t  and this would be this can what it means says that your t one ; that means  t 1 is the life time of the first component  and t 2 is the life time of the second component then we are asking for probability t 1 greater than t  and probability t 2 greater than t both must be functioning up to time t if you are saying that the system for the system  the functioning time are the is you know greater than or equal to t so  now  because of independents this joint probability can be written as  probability t 1 greater than t into probability t 2 greater than t this is because  we have assume that the 2 components of function independently and  so this is r 1 t into r 2 t now  because these are probabilities so  they are each of the numbers is less than 1 so  therefore  this product would be less than the smaller of the 2 because  if r 2 t is less than r 1 t then i am multiplying r 2 t by number less than 1 so  the whole product is still less than r 2 t similarly  if r 1 t is the minimum of the 2 then i am multiplying r 1 t by number which is less than 1  and therefore  the product is again less than r 1 t so  essentially what we are saying is that the reliability that the function r t  here again  i should use small t so  r t is less than or equal to minimum of this so ; that means  the reliability goes down if you have components hooked up in series  then the reliability the system goes down  because this is less than or equal to minimum of the 2 so  whatever the numbers the 2 numbers here  this will be r t will be smaller than the minimum of the 2 numbers at any time t  refer slide time  04  41  now  one can now generalize this result  and to say that if n components functioning independently are connected is series  and if the i th component has reliability r i t then  the reliability r t  i have this habit of writing capital t i do not know then reliability r t of the system is given by the product of the individual reliabilities because  we are assuming that the components are functioning independent of independently of the other components so  therefore  you have this general formula  and you see the movement you have the components hooked up in series  is many components they lower the reliability  because you require all of them to be functioning for the system to function now  consider a case when n is equal to 2 and the failure law of the i th component is an exponential so  then your reliability for the system  when 2 components will be e raise to minus alpha 1 t into e raise to minus alpha 2 t  which is this is e raise to minus alpha 1 plus alpha 2 t and  your therefore  the p d f for the system for the failure time of the system  would be minus r prime t which is alpha 1 plus alpha 2 e raise to minus alpha 1 plus alpha 2 t so  this is negative exponential with parameter alpha 1 plus alpha two so  again we just repeating  what we have already learn that ; if you have 2 two exponentials distributions  their corresponding random variables are independent then the some would be  i mean no  here we are asking for i over taking the … so  the p d f becomes negative exponential where the parameters get added up so  this is exponential essentially this is so  i will written it down here  alpha 1 plus alpha 2 into e raise to minus alpha 1 plus alpha 2 t so this  what happens if you 2 components and both are exponential both have the failure law exponential failure law  and they functioning independently then for the system  if you want to make the computation for the reliability then it will be parameter added up so  it will be alpha 1 plus alpha 2 t and e raise to minus this  and the p d f for the time to failure for the system would be exponential negative exponential distribution  with parameters alpha 1 plus alpha 2  this is it so  now  we can look at some more examples  and then we will look at some more another kind of system  which is when you have components a raised in parallel i have taken this example  you know from a book which got published in 1961 so  this is beznesky reliability theory and practice prenties hall may be the book is not available now  but i have basically chosen the example because  you know these figures  i am not easily available we know we failure wait for a silicon transistor composition transistor and so on so  just for that reason and i wanted to show you the numbers because you see  what we are saying here is … so  let me read out the problem first so  you consider an electronic circuit consisting of own silicon transistors 10 silicon diodes  20 composition position resistors  and 10 ceramic capacitors in continuous series operation so  they are all hooked up in series  and under certain stress conditions that is prescribed voltage current and temperature each of the items has the following constant failure rate so ; that means  the failure law is exponential so  for silicon diodes  it is in hours so  the your parameters 0.000002 ; that means  if you convert this into ; that means  the mean failure time  mean failure time will be how much ? 1 2 3 4 5 6 so  you will you will have to write 1 0.000002 so  it is a very fairly large number so  this exactly so  i thought that since bezensky has some where got this data from and so  we can use it and actually the example appears in minus book  which for which the reference i will give you at the end of the lecture so  any ways so  the mean failure time is you know  millions of hours will be there right 2 4 6 yes so  thousands of hours you can see similarly  these are the various numbers so  the parameters ; that means  each has a exponential failure law follows the exponential failure law  and we are assuming that they are hooked up they are they are failure i mean they are functioning independent of each other so  therefore  just now as we saw that we just add up the parameters to get the distribution for the parameter for the failure law of for the whole system  and that will also be exponential we just saw  it can be easily shown that of course  i showed it to you for two  but the same thing will easily can be shown for any number of … so  if you have lot of components many components hooked up in series  each is following an exponential failure law then  the when you look up failure law for the whole system then that will be simply again exponential with the parameters added up so  you have  how many you have  10 silicon diodes and so  the parameter is this so  therefore  10 times the parameter for a silicon diodes then silicon transistors they are 4 of them 4 silicon transistors of 4 times this parameter  which is 0.00001 plus 20 times we have 20 composition transistors so  this is 20 times this plus 10 ceramic capacitors 10 times this  refer slide time  11  15  so  the parameter for the exponentially distributed see the time to failure for the entire circuit is exponentially distributed  and the parameter will be equal to since they are 4 of them so  10 into would see the numbers are given to you so  this adds up to 0.001 so  earlier in the computation i had written 4 zero ’ s  but actually  when you do the addition multiplication and addition it will come out to be 0.001 so  that is your mu and thus for a 10 our period of operation the probability that the circuit will not fail will be e raise to minus mu in to 10  so mu ten so  the time period whatever the time period the parameter gets multiplied by that for the corresponding parameter during that period so  e raise to minus 0.0001 into ten  which is e raise to minus 0.001 so  the final answer was given correctly  which is 0.999  and therefore  your e t will be 10000 hours so  therefore  probability is very higher ; obviously  because these diodes and capacitors have life time mean life time in thousands of hours so ; obviously  for 10 our period you do not expect another system to fail so  the probability is very high so  therefore  we would expect the system to will be the high probability the system will continue to function for 10 hour without any failure this is the idea  refer slide time  12  53  so  again you may say simple examples  but just to drive from the point that this kind of thinks you consider now  other system that we would like to there is a parallel system so  here the system fails to function only if the of all the components fail so  you knows the diagrammatically  you can repeat this for 2 component  if you have the component arrange in parallel when you it is like this so  the input comes and then you have either it can go this way or it can go this so  the system will fail to function only if both of them fail  because this long as 1 them is functioning  they will the things can be the input can the input can be go this if this fails when this will go this way and it will go out this way so  this still operation will be performing  and if this fail and it will go this way so  the operation will be still be performed so  therefore  for the system to fail both of them have to fail so  that is what to mean ; when we say that all the components have to fail  and again and independence so  if we are saying that function independent of each other  and that what is expected if you have in parallel then the each component to functions parallels independently of the other so  then if you want compute the … i do not why i keep writing capital t here so  this is if you want to compute reliability for the system  when this is probability t greater than t which is 1 minus probability t less than or equal to t so  there in that case this is what you want that 1 minus probability t 1 less than or equal to t and t 2 less than or equal less than or equal to t both of them should not be functioning by 10 t so  therefore  because of independence you would write this as the product and therefore  this becomes  so probability t 1 less than or equal to t is 1 minus r 1 t  because r 1 t is probability t 1 greater than t so  this will be 1 minus r 1 t into 1 minus r 2 t now  when open out multiplied the 2 terms and then you get this so  this call reduces to r 1 t because  1 minus 1 cancels out r 1 t plus r 2 t minus r 1 t into r 2 t so  this is expression for the and of course so  once we get this expression  which i can because 1 cancels with the minus 1 so  you will be left with r 1 t plus r 2 t minus r 1 t r 2 t now  you see that this is this is the reliability for the 2 systems because  this is r 1 t into r 2 t n where assuming that 2 two systems function independently so  therefore  you see that this is a number  which is less than r 1 t and r 1 t both so  considered see for example  r 1 t is larger than r 2 t then this whole number is bigger than r 1 t so  if r 1 t is maximum of r 2 and r 1 then this number this whole number because  r 2 minus r 1 t r 2 t something non negative and therefore  r 1 t plus something non negative this is going to come out to be and hence i can immediately conclude so  that is what i have written that since r 1 t r 2 t is less than or equal to both r 1 t and comma r 2 t therefore  it follows that your reliability  when you have you know 2 components working in parallel see  i have shown you that the 2 system have working in parallel so  in that case the reliability of system because is greater than or equal to max of the reliability of the 2 components so  that immediately shows that systems compose of component functioning independently  in parallel that reliability will be higher than the reliability of the of each of that components  that are in parallel so  parallel components often used to increase reliability if you want to now  generalized to n components  which are functioning in parallel then this will be r t into 1 minus of 1 minus r 1 t into 1 minus r 2 t into 1 minus r n t so  the same principle will be used  and you can show that so  this is the important thing that when 2 so ; that means  here we are considering the case when 2 components are working in parallel  and system has to fail only when both of them fail because  all components have to fail  in that case the reliability of the system will be greater than or equal to reliability of both the components so  therefore working in parallel having in components in parallel and having components in series so  this is the basic the way you make up the devices  and then i can say you can decompose them  and you know into smaller this thing where you can consider component arrange in parallel  when components arrange in series  then put them together so  i will try to show you some more examples of you know system  you know system  of components arrange in different orders  refer slide time  18  29  so  let see take the consider the example  where 2 component are in parallel  and each of whose failure law is exponential distribution and of course  we are assuming that first component has parameter alpha 1 the other 1 is alpha 2 then the reliability of the system when since they are in parallel so  reliability is given by formula we just obtained r 1 t plus r 2 t minus r 1 t into r 2 t because they have functioning independent of each other and therefore  this will be your reliability function and then the e t the expected time to failure for the system would be because  you know when you take the expectation will be integrating each of them separately  this t into d t this t into d t integral of 0 to infinity t into this  each them is exponential distribution so  it will be 1 upon alpha 1 plus 1 upon alpha 2 minus 1 upon alpha 1 plus alpha 2 and you can now  since you have the old machinery with  you do all any competition that you want to do once you know the functional form of the  you know of the reliability function you can make these computations  refer slide time  19  44  now  again just to drive of the point that  parallel arrangements of components definitely increases the reliability of the system and i have take this example from meyer ’ s book which again is very old one  but very good 1 and so  the thing is that yes so  any way i have just given reference i will give you reference  but the book may not be easily available does not matter suppose  3 unit are operated in parallel  assume that each has the same constant failure rate alpha equal to 0.01 so  there are identical components so  all have the exponential failure law  follow the exponential failure law with parameter 0.01 hence reliability of each unit for a period of 10 hours is  e raise to minus 0.01 into 10  which e raise to minus 0.1  which is 0.905 or about 90 percent so  if each component is functioning by itself then the reliability is in 10 hour period that it will not fail is  you know 90 percent now  how much of an improvement can be achieved  in terms of increasing reliability of the system by operating 3 such unit in parallel so  by our formula this is of course  i am not looking at the expanded form this is 1 minus 1  1 minus p probability of t less than t raise to 3 so  that is what will it will be this is what you see that i got after opening up the brackets  but if you do not do it see this whole thing you wrote as  1 minus 1 minus 1 minus r 1 t into 1 minus r 2 to t so  this was the formula which by which then we opened up into 1 1 got cancelled and so on so  i am just and since they are identical so  it will be the same function so  it will be 1 minus r 1 t square in our case it will be q and  so this is 1 minus 0.905 it because argue of this came out to be 0.905 so  1 minus of that raise to 3  and that cancel to be this therefore this is equal to 0.99914 and therefore  reliability has g 1 up to 99.9 percent so  the numbers drive on the point  and that is why it is important  that you individually if you just had 1 component in the system then  for the probability its operating for 10 hours would be only 90 percent  you expect 90 percent of the time it will be function still at the end of the 10 hours period but  if you have 3 in parallel then you will almost be showed that the device with 3 parallel components  will still be functioning at the end of 10 hour period right so  this is the idea when therefore  the reliability can improved upon  but i had said that it has to be verses reliability verses cost reliability verses volume of the device and so on so  you can not just go on having components in parallel now  see the thing is that as our saying that i discuss the very basic arrangements for you  basic systems and then you can have things like you know series parallel so  you have these 3 components here in series  these 3 components in series  and then parallel so  there is no problem because  you can complete the reliability for this  and for this  and then you know how to compute the reliability for the parallel because  when they 2 are parallel so  we just have to you know iteratively do this arrangement we compute this we shall be the product  and this will be the product  and then it will be you know 1 minus of so  what we have been doing  so for n similarly  if you have arrangement paralle,l and series then these are parallel so  you can compute the reliability of this you can compute the reliability of this so  this will be form your r 1  and this form you r 2  and then you are doing it in series so  that is what i meant that all complex devices can be broken up into you  whether either they are series parallel  parallel series and so on and then you want to put them together so  most of time you should come up whether reasonable functional form for the reliability of the of the whole device and  you thing just and of course  i will discussing if you problem like this in the exercise  which will follow so  that exercise on problem related to whatever we have discussed about reliability theory  refer slide time  24  45  so  let me give you the reference that i have the books that i have been referring to all along in this course  and yes i agree that so  of them are out of print  but in any case the idea is that even though like this is a 76 edition and that 1 is 71 edition of course    refer time  25  05   8 th edition have just come  and i think even the 9 th 1 may be ready  refer slide time  25  11  so  any way the thing is to get the basic material i have to refer to these old books  but certainly substitute will be there and now lot of materials is available on the net so  you just have to type the word that you would want  whatever subject matter you want and lot of thing come out so  therefore  but in any case i just want to refer to this books  because i have use material from these books so  the first 1 is the introduction to probability models 10th edition by sheldon ross this is elserser academic press this i think is that 2010 addition  and may be this 1 will keep coming with new addition so  therefore  no problem getting a copy of this book  operation we search principle and practice don t phillips  a ravindren and james solberg this is 76 th book  but some treatment or some topic have been treated very well so  i have use a lot of example are fall from here and i have whenever i use figures  i have refer to that part also so  this is 76 th book then introduction to operation search by hillier and lei berman eighth edition mcgraw hill i do not remember the for this particular year  this is being come out with new addition so  therefore  no problem this is mcgraw hill so  cheap edition i should be available easily  and 4 th 1 that i have used is introductory probability and statistical applications  second addition pl meyer this is classical book  and very neatly and simply  the material has been presented so  reliability theory portion  i have use this book and this is the addition wesley 1971 book so  in any case this is  what i of my source is  where and now  you can as i told you google search for any subject matter that you need  and that i hope you get interested enough topic to read more  refer slide time  27  17  now  let me just discuss the last exercise 11 with you  which is on based on probability theory let us just look at question 1  suppose ; that t the time to failure of an item is normally distributed with e t as 90 that is mu hour and standard deviation 5 hours in order to achieve reliability of 0.9  0.95 and 0.99  how many hours operations may be considered ?  refer slide time  27  55  so  now you know the reliability function this is 1 minus 5 t minus mu upon sigma so  this would be if for example  you put it equal to 0.9 and you know you do not mu is it mu is given to you sigma is also given to you now  perform the normal tables you are looking for pi t minus mu  i have d 1 problem will give like this is equal to 0.01 0.1,1 minus 0.9 is 0.1 so  then give mu 1 sigma you will look up the tables and for corresponding 0.1 what is the value here and they corresponding value of t will be available so  similarly when you put 0.95  0.99 you can accordingly get the value of t so  how many hour of operation may be considered ? so  you can answer for all the 3 value of the reliability level question 2  suppose  that the life length of an electronic device is exponentially distributed  it known that the reliability of the device for a 100 hour period of operation is 0.9  how many hours of operation may be considered to achieve a reliability of 0.95 ? so  first the first data that is given to you you will compute the parameter for the exponentially for the exponential failure law of and then once you get the alpha then you can compute the time we have corresponding to the reliability level of 0.95 question 3  suppose  that the life length of a device has constant failure rate c0 for 0 less than t less than t 0  and a different constant failure rate c 1 for t greater than or equal to t 0 obtain the p d f of t the time to failure  and sketch it this is sketching part i will level to you  but see here all that is saying is that you have so  up to t 0 you have 1 failure law  and then after t 0 you have another failure law so  therefore  but at the point t 0 the 2 you must meet right so  therefore  you what you will say is that c 0 so  you see the required density will be c e raise to minus c 0 c as long as t is between 0  and t 0because  this is the failure law so  the rate of failure is c 0 and is exponential failure law so  therefore  for t less than or equal to t 0 ; that means  laying between 0 and t 0 you will write this and  for t greater than t 0 it will be c 1 e raise to minus c 0 t 0 plus  refer slide time  30  09  so  this is e raise to i should  and then you see c 1 t 0 minus t so  since t is greater than t 0  when you write it as t minus t 0 then it will be minus here anyway so  this is now this will be the probability density function so  to show that f t is a p d f  we have to show that integral from 0 to infinity  would be equal to 1 and then particular so  the first part we will integrate from 0 to t 0 and the second part of the function f t we will integrate from t 0 to infinity and therefore  the calculation shows  that the integral comes out to be equal to 1 so  this is the required p d f and for question 3 and then you can try to sketch it suppose  failure rate z is given by so  now  4 is special case of 3 so  here your time between 0 and a the failure rate is 0 and for t greater than a it is c so  it is constant so  again it is the same thing as 3 except that now  c 0 is 0 and for c 1 is c fine and  so  therefore  you can because  we have obtain the form for the failure law in 3 ’ s now just substituting this special values you can compute you can compute the …  refer slide time  32  07  let me just see so  here you have to find the p d f associated with t the time to failure so  that you can find out because  i have already obtained for you and now  put in the value of c 0 c and of course  your t 0 is a  and evaluate e t so  then you also a evaluate by actual integration now  let us look at question 5  suppose  that the failure law of a component has the following p d f so  this is f t is r plus 1 into a r plus 1 divided by a plus t raise r plus 2 t greater than 0 so  for what values of a and r is the above a p d f we can look at it i can look at it … suppose  that the failure law of component has the following question 5  suppose that failure law of a component has the following p d f  f t is r plus 1 into e raise to r plus 1 divided by a plus t raise to r plus 2 t greater than 0 so  it should not be difficult because  all we have to do is hence we have to say that for what value of a and r is the above a p d f and i think if my this thing is right then it really does not matter it is a p d f for all a and r because  you see simply we write the integral as a plus t raise to minus r minus 2 and then integrate  from 0 to infinity and then you just have i think the value of a will cancel out and r so  you will get the integral as equal to one without specifying any values for a and r anyway so  now you can do this and then you can obtain and expression for the reliability function and hazard function and show that the hazard function is decreasing in t so  i let you do this problem  refer slide time  34  09  now  question 6 suppose  that the failure law of a component is a linear combination of k exponential failure laws  that is the p d f of the failure time is given by f t is equal to sigma j varying from 1 to k c j beta j e raise to minus beta t  t n beta j from all j is positive so  for what values of c j is the above p d f so  now  when you integrate because  this is finite sum so  i can take the integral inside and  so when you integrate beta j integration integral of 0 to infinity beta e raise to minus beta  it should be there is missing  let me write it down i think you f t should be  refer slide time  34  58  this happen the typing errors take tripping so  this is j being from 1 to k and this is c j beta j  e raise to minus beta j t this is for t greater than 0 and beta j greater than 0 for all j so  this is beta j make the correction so  when you integrate this from 0 to infinity d t will be integrating all separate 1 this is 0 to t d t so  therefore  now this is equal to 1 so  therefore  this whole thing will add up to sigma c j  j going from 1 to k so  this is the condition that all and of course  c j have to be non negative  and then you say that sigma c j while  actually it say linear combination so  i will just to be on safe side say that c j be non negative and they add up 1 so  this becomes convex combination in that case  of all these different exponential law  and so this is also again and p d f this will be a p d f then  obtain and expression for reliability function and hazard function  obtain a function expression for mean time to failure see here again because it the summation so  you will have to integrate if you have to compute this integral  the same principle you will use for the reliability thing you will have to show r t  when you do t to infinity so  you again then integrate separately and so  it will be a convex combination of all the separate reliability functions  r 1  r 2  r 3 so  it will c 1 r 1 plus c 2 r 2 plus c k r k so  straight forward this is not right and then answers b and c beta j equal to beta for all j and of course  obtain an expression for the mean time to failure so  the mean to failure would be  see for each of them 1 by beta j so  it will be summation so  mean the failure ; that means  your e t will be summation c j beta j  j going from 1 to k now  let us go to next problem  then the question 7 expected life time this 3 by 2 years so  which means that lambda is 2 by 3 again  exponential failure law and  probability that it is still functioning after 2 years will be e raise to minus so  it will be e raise lambda t  which is minus 4 by 3 after 2 years so  this will be e raise minus 4 by 3 now  you want to probability the 2 still functioning after 2 years so  2 still functioning after 2 years at least so ; that means  you may have after 2 years either 2 of them are functioning or 3 them so  when 2 of them are functioning it will be 3 c 2 e raise to minus 4 by 3 into 2 because  2 of them are functioning  and 1 of them is not functioning so  it will be 1 minus e raise to minus 4 by 3 and all you have all 3 of them functioning so  it will be e raise minus 4 by 3 into 3 ; that means  here this is so  actually it will be e raise to minus 12 by 3 so  this will be required probability  refer slide time  38  42  now  this figure refers to problem 8  i think 3 independently functioning components are connected into a single system  as indicated in figure above so  2 are parallel and then 1 series  suppose that reliability for each of the components for an operational period of t hours is given by  e raise minus 0.03 t so  now by now  we have discussed all this so  therefore  you have 3 these 2 has parallel so  then you compute the reliability of these component  and then this together with this component c 3 in series so  now  you do it  and they all identically distributed the failure law for the 3 components so  therefore  you first compute these 2 in parallel  and then it will be  so which will be … i will give you the formula for this and then that into c 3 so  that will be you know multiplication  refer slide time  39  41  so  you can do that and let us say what are else is ask so  if t is the time to failure of the entire system  what is the p d f of t ? that you can find out well  you will first find out the reliability function or you can try to find the p d f directly  what is the reliability of the system ? how it compares with e raise to 0.03 t ? so ; obviously  i think your guess should be that it will definitely improve the reliability because  they are 2 components in parallel so  definite even though see  the thing is that the reliability of this component consisting of c 1 and c 2 will go up  but c 3 will have the same and since when the take the combination in series  when you hope then up in series then your reliability is the minimum of the 2 so  therefore  you can not say much it will almost with the same in fact  it will not be the better e raise to 0 or minus 0.03 t in fact  it will not be better than e raise minus 0.03 t  refer slide time  40  53  now  i have given you a big system here so  this is suppose  that n component are hooked up in a series arrangement then k such series connections are hooked up in parallel to form an entire system so  the figure below is given  if each component has the same reliability say r  for a certain period of operation  find an expression for the reliability of the entire system for that same period of operation so  you should enjoy doing a just sit down patiently write down the first for these series connection  you write the reliability function for this and these it will be the same and then you do the parallel thing so  their k in parallel  and you have how many n in series so  just patiently sit down  and you can write down expression for the reliability function for the whole system  should be able to do it  refer slide time  41  40  now  i am saying the suppose  that each of the above component obey an exponential failure law  with failure rate 0.05 suppose  further more that the time of operation is 10 hours and that n is 5 so  now  i have give the numbers and determine the value of k in order that the reliability of the entire system equals 0.99 so  you will enjoy do this problem because  case not give to you  but then when you write down the reliability function  it will be a function of k and then you put value for 10 hours your t 10 hours then you substitute that in the expression  and put the whole thing equal to 0.99 then you will get the value of k so  interesting problem  i am sure you will enjoy by doing it now a component has reliability 0.9 when use for a particular purpose  component b which may be used in place of component a has a reliability of only 0.75 so  a has reliability of 0.9 in for a certain period  and component b which may be used in place of component a has reliability only 0.75 so  what is the minimum number of component type b that would have be hooked up in parallel ? so  now  you can write down the reliability function suppose  k you can take k number of b component and then hook then up in parallel you know the reliability function  and then you want say that its reliability should be equal to 0.9 so  that also again you can use in the formulas that have give you for computing the reliability  when they are hooked up in parallel then when you 0.75 reliability of 1 component  then how many should be there so  that reliability goes up to 0.9 so  these are the kind of question which i am sure you will  that is it so  i think this is the last lecture  and effort has been made to equinity with probability theory  basic probability theory i would say  and then its applications and i have try to trough exercises  try give you good in site into the subject  and i hope you enjoy doing these exercises 