computer networks prof sujoy ghosh dept of computer science& engineering iit kharagpur lecture 11 routing and wavelength assignment in wdm all optical networks  refer slide time  00  48 min  good day in this lecture we are going to continue our discussion on wavelength deviation multiplexing specifically we are going to talk about routing and wavelength assignment ?  refer slide time  01  02 -01  04  routing and wavelength assignment to what ? well  routing and wavelength assignment means that we have some stream of packets or whatever data or whatever communication is going from one source to one destination now these sources and destination  first of all  if there is point-to-point connection they directly send it through the fiber that is simple ; but in general  they will not be directly connected they will go through a network ; they go through some intermediate notes to reach the destination so for this stream we have to route this ; that is one problem and the other thing is that may be the stream rides on some particular wavelength for the time being let us assume that it is continued on the same wavelength ; we have to assign one wavelength  so we have this problem of routing and wavelength assignment  refer slide time  02  09-02  19 min  in wdm and all optical networks of course we can do routing etc very easily in the electronic domain ? that is known ? but we have not yet discussed routing in the electronic domain  how it is done etc we will discuss it later on in this series of lectures but in routing  we are talking about simple kinds of routing problem here so we will talk about routing and wavelength assignment  refer slide time  02  39 03  11 min  the optical wdm networks are future backbone for wide area networks the reason we want it is because the bandwidth demand from the users is going up at a very fast rate ; of course  we have to go for fiber  we have to go for higher speed and then we have to pack in a lot of these channels over the same fiber so we require an optical wdm network  refer slide time  03  18 ? 03  57 min  the speed of electronics compared to optics is a major constraint at the backbone so it is always preferable to handle the traffic at the optical layer  where we can achieve much higher speed and the whole thing is transferred the physical topology that we will consider at the optical wavelength routers is connected by some fiber links so these are the same kind of topology we had talked about ; that means there are some nodes  which are connected by some communication links in this particular case  the communication links happen to be optical fibers  refer slide time  03  58 05  10 min  most of the node pairs in the backbones are not physically connected so we have 30 or 40  let ? s say 40 nodes now for 40 nodes  there are 780 possible pairs  that is  40 c2  that is  40 ? 39/2  that is  780 pairs  which is a very large number of course  only few nodes are connected actually through physical fibers so they can reach each other only through other intermediate nodes a light path or connection  this is the concept that we will be talking about most in this part of the lecture this is the path between two end nodes and a wavelength on that path  so we want to route  that means  we want to find this path between two end nodes and we want to select the wavelength on which to send all our communication from the source node to the destination node  refer slide time  05  11-05  21 min  the intermediate nodes can cross connect that particular wavelength from the incoming fiber to the outgoing fiber do you remember our discussion on digital cross connect ? may be through mems  that means  a particular wavelength is coming through one particular fiber  we direct it through some mirror to another fiber on that same wavelength it is as simple as that thus with programmable optical switches  the traffic can be routed entirely in the optical plane  refer slide time  05  51-06  14 min  so no wavelength conversion for the present  and any light path uses the same wavelength on all the links its path spans so 16 or 32 wavelengths in each fiber are common these days and hundreds of ? s are being talked about a single fiber could theoretically accommodate as many light paths  refer slide time  06  13-06  39 min  what are the basic concepts of the light path ? end users use light paths to communicate  each light path passing along the same fiber occupies different wavelengths ; that means on the same fiber there may be different light paths going through the same fiber  each of them would be writing on a different wavelength or different lambda two ? s two light paths with the same wavelength can not share a fiber  that means two different light paths who are on the same wavelength they can not have any fiber in common because then their signals will get mixed up with each other of course  we can have  refer slide time  06  52-07  36 min  wdm with wavelength conversion also as i mentioned in the previous lecture that wave length conversions are possible although they are quiet costly so it is possible in different extents  for example none that means no wavelength conversion or we can have a partial wavelength conversion that means some of the nodes have wc capabilities while others do not have or it may be full if you have wavelength conversion we get some kind of flexibility in routing and wavelength assignment we will not concentrate on that but you can understand that if we could convert the wavelength midway that means  as the signal is going  we can convert the signal midway  then maybe we can have better possibility of accommodating many more light paths for our purpose  we will be concentrating only without wavelength conversion  refer slide time  08  00-08  21 min  so how to establish light paths ? two parameters to be decided  path from source to destination ? this is the routing part ? and wavelength along the path  which is the wavelength assignment part traffic types subjected to optical networks may be static or dynamic ; that means you know the specific source destination pairs  which have to be connected in advance and that is quiet stable so now you may run some centralized algorithm kind of things and find the best way to assign the light paths the other situation could be dynamic ; dynamically there is a request from some node for a connection to some other node and you want to set up the light path on the fly and take it down that is a slightly more complex situation  refer slide time  08  59 09  52 min  so two versions of rwa are realized depending on the characteristics of the traffic applied  static light path establishment or dynamic light path establishment now routing and wavelength assignment several  signals can share a single fiber all signals must have different wavelengths  so these are the constraints of course  technology sets the upper limit to the number of wavelengths you can not have unlimited number of wavelengths  you can have a large number these days but even then this is not unlimited so these are the constraints  which you will have to respect while doing the routing and wavelength assignment the problem is how to choose a route and a wavelength to each connection  so that signals won ? t block each other how can signals block each other ? well  the signals can block each other in this way for example  suppose you have routed two particular source destination pairs in a certain manner using a certain wavelength  let us say ? 1 another pair of source destinations was  let us say  n1n2 ; then we want to put a connection between n3 n4  for which the route happens to share some of the links in these links now you can not use ? 1 for this  because ? 1 on those links is already occupied by the link from n1 n2 so if n3 n4 share even one link  you can not use the same ? 1 ; you will have to use ? 2  but then ? 2 has to be blocked because of some other links and so on  refer slide time  10  52-11  23 min  so the objective of sle  that is  static light path establishment  is to minimize the total number of used wavelengths connecting the maximum number of nodes they are the same ; if you can connect some particular set of nodes using the minimum number of wavelengths  using the number of wavelengths  which are given to you  you may connect the maximum number of nodes other objective functions we may also consider are the load in the most loaded link  the total number of optical switches  etc  refer slide time  11  24-13  48 min  so this is an example of light path establishment suppose you have these a b c d e connected so in the first part the left half of the figure what we have is the physical connection from a to b there is a connection and b to d and so on in this  i show some rw routing and wavelength assignment has already been done and some of the wavelengths and some of the links have been used so here only two wavelengths are used let us say a to b are not connected ; say a light path has been established via b for a to c at b  there will be a switch  which will switch this dashed line  which is ? 1 so ? 1 coming through this fiber from a to b is switched to ? 1  using the same wavelength to the outgoing fiber from b to c so we have light path established between b to c similarly  from c to d there is a light path ; there is a light path from b to d ; there is a light path from d to e ; there is a light path from e to f ; there is a light path from d to f and so on  using the same ? 1 then i want to connect e to c now i can not go from e to c after say ? 1 has been assigned  i can not go from e by ? 1 to anywhere because all the outgoing fibers of the ? 1s have been used up this side for a  this side for b  and this side for f so  in order to connect from e to c  i use another wavelength  say ? 2  which connects me via d and the d cross connect will connect this particular ? from this fiber to this fiber so we will get a direct light path from e to c similarly  we will get a light path from b to f using ? 2  a to d using ? 2 and this way they are all connected as you can see  a large number of light paths have been established using just two ? s  refer slide time  13  49-14  35 min  dynamic light path establishment  on the other hand  is appropriate for network having dynamic traffic  where the traffic pattern changes very dynamically and a communication request may arrive at any time the goal is to maximize the number of the incoming communication requests accepted well  if it so happens that you have already made some kind of reservation and some kind of allocation to an earlier request and when a new request comes  you find that there are no paths on which a ? is consistently free throughout so in that case  you have to block that request or regret that request so we want to minimize such regrets and maximize the number of incoming communication requests that can be accepted that is the goal of dle  refer slide time  14  36-14  57 min  in order to solve this problem  let us see what the complexity of the problem is the rwa problem is difficult ; it can be divided into two sub-problems ? routing and wavelength assignment both of these sub-problems are np complete and tightly linked together if you remember  by np complete we mean that class of problems for which no polynomial time algorithm is known and so  if you can solve any one of them in polynomial time  all others can be solved in polynomial time it is not known whether any polynomial time algorithm exists  but since the number of such problems is so large and people have thought about these problems in so many different guises  it is very unlikely that you would suddenly come up with a polynomial time solution to any of these and of course  when an algorithm has an exponential complexity  it takes a lot of time so that is a difficult problem in that sense ; both its parts are np complete so there is no exact solution so we can not expect to get the so-called ideal solution or the optimal solution in all cases  but we can try good heuristics  refer slide time  16  00 16  31 min  now what we want from a good algorithm ? maximize the number of connections ; use the shortest routes ; and minimize the number of wavelengths if you can maximize the number of connections  this is of course our basic requirement if you use the shortest routes or the number of hops should be minimum  delays and all kinds of things should be minimum so that is another good thing to have  and if you minimize the number of wavelengths that have been used  future requests can also be possibly accommodated  refer slide time  16  32 17  06 min  so for routing  there are different techniques like fixed routing ; that means the path that is predefined is used ; that means the for all pairs we have some fixed paths and fixed alternate routing  meaning multiple predefined paths are there and one of them is selected so the criteria could be shortest path  least loaded path  least congested path  and so on  refer slide time  17  07-17  27 min  there could be adaptive routing techniques ; the path is found on the fly that means as the network is in operation dynamically  you find the least congested path or the most suitable path depending on the current situation in the network  and once again we may try to find the shortest path or least loaded path  refer slide time  17  28-18  03 min  now how do the wavelengths affect routing ? there can not be two signals with same wavelength per fiber for two different light paths ; that is not possible so the shortest route may be blocked by other signal and in the worst case all the routes are blocked then  of course  either you have to reassign the wavelengths of other earlier assignments or you have to block this request if the wavelength conversion is possible  the signal can use other free wavelengths but the conversion is not always supported  refer slide time  18  04-18  15 min  wavelength assignment problem arises under the wavelength continuity constraint ; that means the wavelength has to be continuously available in all the links down the line and there are various algorithms for that one of the most commonly used one is the first fit  which means  you have decided on the path by some means ; that is the routing path once you have decided on the path you have a list of these wavelengths  ? 1 to ? n  and you try them in order the first wavelength  which is free on all the links in the route is the one which is assigned to this particular light path request that is called first fit  and it has some good points in the sense that since you are always trying from the same end  you tend to use up these earlier ? s more and more  giving you very good utilization of the ? s so you may be having a lot of other ? s in the network you have them on reserve to accommodate the request so that is a first fit algorithm but then again you must remember this is just a heuristic  in the sense that there is no way you can prove ? as matter of fact you can disprove it in some cases  this would not give you an optimal algorithm in some cases it may give you an optimal algorithm in many of the cases  it has been found that this gives good results  but in some cases  it may give very bad results it may be random you may want to distribute the load all over  so it may be random or people have used the least used ; that means the least used ?  which is most free  is the one that is picked up when you try all the ? s one by one  you reach the ? that can fit this particular route so this will have the opposite effect  in the sense that this will try to distribute the load evenly across all the ? s or the most used ones ; it need not be the first fit or the least loaded  etc so these are the different algorithms or different heuristics  which you might use for assigning your ?  of course  what you could do also is that at some point you could go back and instead of asking about your routing path you can ask  give me the next alternative path so from the shortest path  which it might have given in the first instance  it might give you the second shortest path on which you may try the same kind of wavelength assignments using that so all kind of combinations of routing and the wavelengths  all these strategies are possible  refer the slide time  21  18-21  34 min  what are all the good points about wavelength routing ? setting up a light path is like setting up a circuit you remember we have talked about circuit switch network and packet switch networks ? so in circuit switch networks  specifically the telephone circuits  even today may be majority of their networks are circuit switches ; that means  a call from one node to another  one caller to one callee  a continuous circuit is set up all those things have become more complicated as we have seen because of the tdm and all kinds of packets and all these things are coming in between anyway  the essential circuit switching is that the circuit is switched just in the same manner  when we are assigning a particular light path to two nodes  which have to be connected  it is just like setting up a circuit and once the light path is set up  the route is fixed and the wavelength is assigned and the light path is set up then these two nodes can communicate  pumping as many packets as they like through this  of course limited by the technology constraints but this is quiet a high constraint so the inherent advantages of setting up this circuit switching is that in this particular approach to the problem specifically the quality of service is good what we mean by the quality of service is smooth traffic and qos guarantee can be given due to fixed bandwidth reservation and sle is easy to manage  that means static light path establishment is easy to manage that is the advantage of wavelength routing  refer slide time  23  22-23  39 min  the disadvantages are the following  long circuit set-up time this circuit time will be in the order of tens of milliseconds actually the circuits are set up in such a way that the source sends some request and the request goes down all the nodes on the way the local switches have to be set up in that particular fashion and then they will acknowledge and say that ok the light path has been set up so all this communication takes the order of tens of milliseconds now tens of milliseconds may be a lot of time depending on the situation when a very high-speed communication is going on  then tens of milliseconds is a lot of time but if you are going to set up a light path and then use it for one month or one year  then tens of milliseconds may not be much so it depends on the situation ; but if your traffic is changing dynamically then you want to adopt what light paths you want to assign etc  in a dynamic fashion  then tens of milliseconds may be a lot of time the other problem is that the huge capacity of 1 ? can carry how much traffic  let us say of the order of 2.5 gbps or something like that or may be even more these days its capacity is very huge the point is that for just two nodes communicating  it may be a gross underutilization if proper traffic grooming is not done at the edge what you mean by traffic grooming ? you remember that at the edge  first of all  when we are talking about the edge  we are talking about the backbone network  which is where usually all your wdm systems will be deployed so we have this backbone network and these backbone networks have been fed by all different networks  are routed from different networks etc  so number of streams are coming into this backbone network they are converging and then traveling to the backbone  and then going out on the other side so  the routers which communicate with this backbone are the edge routers and the light path you have got from n1 to n2  as we have seen is the granularity is quite coarse ; that means a quite high amount of traffic can be handled so if the edge router get together a number of streams from different sources and then uses it  it ? s good traffic roaming ; it loads it quite well then that is good so we are achieving high efficiency if it is two single users and the two end then it is a gross under utilization of this ?  unfortunately in this circuit inherently you can not have less than 1 ? for a circuit  if you are setting up a circuit you have that capacity but you are underutilizing it this is the same problem that we had seen in circuit switching versus packet switching  and as a matter of fact there is a development as we will see for the packet switching part also  which we will see in the next half of this lecture  refer slide time  27  03-27  13 min  so bandwidth is inefficient for bursty traffic this is another term that you should know  if you remember i told you while discussing about the telephone traffic that the bell telephones people had done a lot of study about what kind of traffic is there  and how long the people talk and how frequently they talk at different times of the day  etc we know that this is the some kind of poisson distribution with exponential inter arrival time etc  so those are very well-behaved kind of systems unfortunately  in recent years first of all the voice traffic has shrunk to may be less than 5 % of the overall traffic in the network  95 % of it is data traffic and this data traffic has seen to be very bursty they also follow some kind of statistics  but it is a complicated kind of statistics  the whole thing is that the data traffic seems to come in bunch when they come lot of packets are coming and then for a long time there is no traffic it is also self similar  and it is complex kinds of statistics but in anyway the point is  for long time for which when it is not sending anything  the circuit is remaining unutilized ; so this is a gross under utilization of the circuit the busy time versus the lean time may be of the ratio of 1  500 or something like that so that is why this becomes an inefficient way another disadvantage is wasted bandwidth during either off or low traffic periods for sle or too much overhead  that is  delay  due to frequent set up or release in dynamic light path establishment that means if you want to put it down and then set it up again  in that time frame this becomes too much of an overhead because  if you remember  for setting up a light path we require may be tens of milliseconds so you can not do it very fast  refer slide time  29  16-30  05 min  particular ? path specific pros and cons are that  they have very coarse granularity  as we have discussed i.e  oc 48 and above oc 48 if you remember is 2.5 gbps or above that they have limited number of wavelengths and number of light paths ; no aggregation  that is  merging of the light paths inside the core so inside the core  there can not be any aggregation etc traffic grooming can only be done at the edge so this may be complex or inflexible that oxc has a millisecond kind of switching time so these are the pros and cons of ? paths  refer slide time  30  06-30  10 min  so this takes us to the next half of our lecture  where we will have a look at the other way and other approach to this whole problem  namely  optical burst switching just as the previous one was circuit switching  where we were doing circuit switching ; we were setting up light paths here we will try to take the packet route ; that means we will send them packet by packet how that can be done ? originally  the packets may have originated from some say tcp/ip or ethernet or some computers as small kinds of packets doing it at that particular level becomes difficult at the optical level so we have some technology for that ; we will look at this now we will discuss the next topic  which is optical burst switching  refer slide time  31  13-32  19 min  first of all  let us do one quick comparison between electronic versus optical switching data is transmitted optically in wans  mans and even some lans electronic switch uses digital switching fabrics ; converts data from optical to electronic for switching and then from electrical to optical for transmission that means what we are doing is that  we are trying to do the switching in the electronic domain as mentioned a number of times before  the electronic switching always has problem ; at high speeds it is very costly and this is not very easily upgradeable  scalable  etc so that is a problem ; but if you have done the switching in the electronic domain  there will be no problem the kind of switching and kind of logic  kind of algorithm that we use in the other parts of the network could be put over there but we want to avoid electronic switching and do optical switching as much as possible so let us see how that can be done  refer slide time  32  20-32  33 min  the cost of electronic switching goes up steeply as the speed requirement increases and optical or photonic switching uses optical switching fabrics  keeps data in the optical domain  refer slide time  32  35-32  51 min  so  why not we keep the status quo ; that means that do the switching in the electronic domain only ? well  the trouble is that the data traffic growth is still doubling every year and this is different from what we have in the computing domain in the computing domain or moor ? s law  it doubles may be in one and a half years and this is doubling every year actually if you see over the long range  although the computational speed has increased many fold  the communication speed has grown even more  by an order of magnitude more maybe so the point is that electronics is unable to move and that is not possible for developing at that particular rate of development so pure electronic processing and switching can hardly keep up electronic mux  demux  space power consumption  heat dissipation  etc  are always a problem because heat dissipation is more  it requires most space etc there is no transparency  meaning  it depends on the kind of system and the kind of the modulation system  the kind of multiplexing system that you are using  which you have to use in the electronic components so when the technology moves on  these intermediate nodes will also have to be changed  whereas  the optical switching  since it is transparent  does not matter if you change what you are sending through that pipe  refer slide time  34  33-34  51 min  the cost factor  of course  weighs the heaviest though the cost of oeo at 0c-48 is going down  the overall cost including wdm system at 0c-48  is still a dominant factor oeo at 0c-192 and higher in the future will still be a dominant cost factor  refer slide time  34  52-35  18 min  so we want to go to optical switching  whose advantage is that  low cost and high capacity  transparency ; that means it is independent of bit rate  format  protocol  etc it is synergetic to optical transmission and future proof ; that means when we upgrade  all these things might change but my intermediate node will not change in the optical switch  refer slide time  35  19-35  41 min  opaque  that is oeo switches  are more mature and reliable  of course so still they need some electronic processing and control ; that means  when we are doing in the optical domain  we still require some electronic processing and control what we do is  we try to minimize this  and optical 3r and performance monitoring are hard you remember that we can amplify a signal quite easily but if you want to do all the 3rs that means regenerate  reshape and retime  then we prefer to take it to the electronic domain  refer slide time  35  58-36  30 min  packet switching  a packet contains a header ; that means addresses and the payload it is a variable or fixed length the advantage of packet switching is that it has some kind of statistical multiplexing ; it can be sent without circuit set-up delay ? if the line is there just simply send it it also enables statistical sharing of link bandwidth among packets with different sources and destinations so that makes it more efficient ; bandwidth usage is more efficient  refer slide time  36  31-37  04 min  so packet switching is done usually this way store and forward at each node  it buffers the packet  processes its header  and sends it to the next hop this is how usually it is done in the electronic domain ; we will look at the details of this later on but usually what would happen is that  when we are using a circuit switching  the circuit is set up from n to n and then we can send whatever we like but when it comes to packet switching  since it is coming packet by packet  each packet has to be processed independently we have to look at this packet  look at this header  see what the destination is  decide on which next link to take  etc  and send it so you have to store this packet in a buffer and then examine  do some processing and then forward it ? this is the store and forward paradigm this is usually done in packet switching  refer slide time  37  37 ? 37  43 min  we have some problems with that optical domain  as we will see it is statistical multiplexing and is inherently bandwidth efficient  refer slide time  37  43 ? 38  25 min  now if you have a packet core  well  we have the access or metro networks  optical buses  passive star couplers  etc sonet wdm rings or token rings are used we will talk about token rings later it uses switched networks or gigabit ethernet so these are the kind of technologies that are deployed in the lan/man side  whereas in the wan side  we have the ? routed virtual topology  i.e  circuits or leased lines we have dynamic ? provisioning ; that means circuits on demand and optical burst switching  which we are talking about now  refer slide time  38  27 ? 38  54 min  the technology drivers for this are the explosive traffic growth  as i already mentioned  bursty traffic pattern  and to increase bandwidth efficiency to make the core more flexible  naturally a packet ? s system would be more flexible than those fixed light path kind of system to simplify network control and management and making the core more intelligent  refer slide time  38  54 ? 40  05 min  how important is this bandwidth efficiency ? we are always talking about the bandwidth efficiency well there are two views to it ? one is the user ? s point of view well  user wants some bandwidth today and if the bandwidth becomes cheaper and as it becomes available  he immediately thinks of another application and his bandwidth demand will grow previously  people were very happy to send some simple text now  they are downloading  then they want to download songs  files  they want to download entire videos  then they will try to do video conferencing with each other so these are very bandwidth intensive applications and they require a lot of bandwidth so from the users ? point of view  the more the bandwidth you give  i will bring lot more applications and i will just use it up so with more available bandwidth  new bandwidth intensive applications will be introduced high bandwidth is like an addictive drug  can not have too much of bandwidth from the users ? point of view  refer slide time  40  05 ? 40  38 min  from the carriers ? and vendors ? point of view expenditure rate is higher than revenue growth sometimes ; so longer-term equipment investment can not keep up with the traffic explosion so  you have to see that whatever i invest today  how long in future i can take so that my investment is lower we need bandwidth efficient solutions on the infrastructure existing today that will be competitive so these are the different issues which  refer slide time  40  39 ? 42  07 min  brought us to optical packet switching or optical burst switching i will come to that later on but this is our goal ; there are two problems ; and one of them is the lack of optical buffer in the optical domain  if some packet is coming  means some light pulse is coming now  how do you store them in the optical domain ? there is no good buffer for optical domain ; there is a thing called fiber delay lines this is really a very bulky and not very good stuff  you can put it in the fiber delay line as it comes  it goes to that fiber delay line and comes out of the other  the whole thing would be delayed a little bit ; that is something akin to buffer in it but there are severe limitations on how much you can delay  that is one thing secondly  it is bulky  expensive and not very good so fiber delay lines are bulky and provide only limited and deterministic delays store and forward with feedback fdls lead to fixed packet length and synchronous switching so we can not use because of this simple store and forward  and the other thing is that tight coupling of header and payload requires stringent synchronization and fast processing and switching so these things are difficult  refer slide time  42  07 ? 43  49 min  so we go to this optical burst switching or obs ; a burst has a long and variable length payload so first of all  variable length payload means we want to keep it as flexible as possible ; that is one good aspect of it that means we want to keep it as flexible as possible the other thing that we want it to be is it is long  why is it long ? because we have to do some processing  some setting up  etc  for these burst of packets to travel so what we do is  we will do some grooming in the electronic domain we collect a number of packets together forming a burst  which has the same source ? destination pair and then we set up the path and send this burst along all in the optical domain so that is the essential approach to optical burst switching a burst has a long and variable length payload  if it is long and has low amortized overhead and no fragmentation a control packet is sent out of band  that means using some other ? control and reserves bandwidth ? that is ? data reserves a particular bandwidth along a particular path ? and configures the switches so it is like setting up a temporary light path from the source to the destination a burst is sent after an offset time ; it arrives at a switch after it has been configured so no buffering is needed our original problem is of not having optical buffer  so buffers in the optical domain are avoided in this fashion  refer slide time  43  49  44  51 min  we have to do a burst assembly and disassembly at the edge at the source side that means the client data may be the ip packets  which are the most dominant ones they are assembled together into bursts ; and burst switching or reservation protocol is done  that means  we send the control packet  an offset time t ahead of burst so within this offset time  all the switches down the line will do their programming that means they will set up all their mirrors or whatever it is their cross connects  etc so that later on  when the burst does arrive  we do not have to do any processing on that and if you are do not doing any processing on them we do not need to store them either they can go straight away in the optical domain there is a dedicated control channel  which is out of band signaling for the control packets  refer slide time  44  52 -45  25 min  the advantage is no fiber delay lines nor oeo conversions for burst at any intermediate nodes  photonic burst switching fabric inside the core that means it leverages best of optics for burst switching and electronics for control packet processing and fabric control so just for the control part  we do this oeo and for the bulk of it  the burst  we do not have to go to the electronic domain at all  refer slide time  45  25  45  55 min  this is a diagram  say assembly queues for different egress nodes ; these are going to different channels this is an atm cell ip packet or sonet  and we have an ip packet over here we have a sonet frame over there because if you are sending things in the purely optical plane  you do not really care what the payload contains it may be an ip packet  it may be a sonet frame  it may be some cell  it may be anything else we do not care intermediate optics is transparent to all that so what happens is that  refer slide time  45  16 ? 47  18 min  we use the atm cell for the control packet purpose so we make a control packet  which assembles a burst  and as it assembles a burst  it knows what the time or length threshold reached is the length of the burst may be variable  as we said the burst could be long and of variable length but when all these different ip packets frames  sonet frames etc  are put together  what happens is that a control packet is generated and sent out the control packet now knows the source  it knows the destination  it knows the length of the burst  so it sends through a separate control channel  so this control channel goes through the control plane as we will see  refer slid time  47  18 -47  44 min  so we have the assembly queues for different egress nodes ; that means the destinations  for different destinations  all these packet frames etc  are getting queued up and forming into bursts  refer slide time  47  44  48  04 min  now we see fiber delay line ? as i just mentioned it fiber delay line  feed forward or feed backward so there is no optical ram for store and forward ; every fdl provides only limited delay and can not perform most of useful buffer functions so fdl units are bulky  affect signal quality etc  refer slide time  48  04 ? 48  24 min  now going back to this obs  we have various schemes still involving in an active area of research i will just present a simple scheme called just enough time or jet there is an offset time between cp and burst so what is done is that the control packet is sent and after the control packet is sent  there is a delay we give a delay and then we send a burst ; this delay is to cover all the programming time on the intervening nodes  refer slide time  48  43 ? 49  05 min  so an offset time between cp and burst  no fiber delay line required to delay the burst  when cp is processed and switch fabric is configured cp carries the burst length info  facilitates delayed reservation for intelligent efficient allocation of bandwidth and fdl if any  including look ahead scheduling we need not go into the details  refer slide time  49  10-49  53 min  we have the control packet here  which is moving in the control plane  and we have a burst over here and there is offset time t and we have just enough offset  jet  which we require for programming these intervening optical nodes so cp arrives at oeo node at time  let us say  t1 but the control packet is being taken to the electronic domain for processing  because this will have to be processed etc so it is better done in the electronic domain  refer slide time  49  54 ? 50  05 min  then cp goes through the optical to electrical conversion and configure the switch fabric and then it will move on  refer slide time  50  06-50  12 min  cp goes through eo conversion and leaves the oeo node at time t1 + ?   refer slide time  50  13-50  53 min  so what will happen is that  this will now move towards the other end  to the next node  and here this will again go through the o to e and then do the switch configuration and then again e to o and go to the next hop and this delay is calculated in such a fashion that when the burst arrives  what happens is that at the intermediate node  the switch fabric is already configured so you do not have to store it ; you simply pass through in the optical domain  refer slide time  50  54-51  16 min  offset of course is now t ? ? because it spent delta amount of time over here so without any delay  the burst goes through the optical switch fabric depending on how many intervening nodes are there  you have to have this original t so that finally when t is exhausted  offset is exhausted but you have also reached your destination  refer slide time  51  17-51  37 min  that is just enough time and finally to conclude  obs is a programming switching paradigm that offers many advantages over the existing technologies  but is not likely to be the end-all kind of solution obs has several variations and adopting obs will be an evolutionary process this is another problem ? when you have a new scheme and there are different researches  they will try to do research and come up with different suggestions and then at different places some different things may be adopted but then  in order for the entire network to work in a very smooth fashion  you have to come to some standard  so obs has not come to that standard yet  but it is a quite a promising approach now  we have talked about the two approaches in wdm  namely  this circuit switching path  that is the light path routing and wavelength assignment and setting up of light path  and we have talked about optical burst switching in the next lecture  we will talk about sonet infrastructure the sonet  which we have talked about  a lot of it is also in fiber optics then we have all these fiber optics ; that means packet oriented fiber optic infrastructures are also coming in that means large routers  etc  are coming into this picture  one thing we did not discuss although we mentioned it a while discussing about sonet was that this has an inherent capacity of fault recovery  recovering from fault so that is one thing that we would like to discuss in the next lecture ? not only in sonet  in optical network  but in general  how do you handle faults that is very important  because this optical network is at the core of the network and if the core of the network fails  its repercussion is tremendous  both economic and other repercussion may be tremendous so we like to put in lot of reliability into all this fiber infrastructure that we have  and how exactly that is done  we will discuss in the next lecture thank you preview computer networks prof  sujoy ghosh dept of computer science& engineering iit kharagpur lecture 12 protection and restoration  refer slide time  53  37-53  41  good day in this lecturer  we are going to discuss the various protection and restoration mechanisms  which are usually employed in optical networks  refer slide time  53  54-53  57 min  we will be talking about protection and restoration  now of course we have to discuss  what is protection and restoration why we need them ?  refer slide time  54  05-54  16 min  what is protection and restoration  comparison between the two and the different schemes of rotation ? this could be our general outline of presentation  refer slide time  54  19-54  25 min  network is unreliable somehow  so many failures can occur  node may fail a link  may get cut  some fiber optic line may cut in between because somebody cut it  while digging a whole or something or node might fail there may power failures at nodes and so many things so there are failures in the network but if you remember that one of the most important places where we deploy optical networks is in the core of the network and the core of the network connects so many people  to so many other people it is so very vital that we can not allow the services to be a severely desalted because that would have very grave consequences anyway the service provider attempts to give a very high level of service so although failures are unavoidable in real life  we have to find a some way of combating this  that means if there is a failure  we want to recover from it as soon or as fast as possible so that  is what protection and restoration is all about another thing is that when we want to give some reliability  protection  restoration etc we always in some form  always have to bring in some redundancy without any redundancy a system can not be protected  it can not be restored without any replacement etc  so there has to be some redundant capacity in some form in the network  in order to achieve protection and restoration how this is done that is what we will discuss  refer slide time  56  14-56  25 min  so first let us talk about path protection  it uses more than one path to guarantee that data is sent successfully so if you look at this graph  it will be having a six node graph  where 1 and 6 are communicating on the top through the dash line we show the primary path  which is the primary connection between 1 and 6 what might happen is that the link between 2 and 3 might snap due to some reason so we have already got a backup route which is calculated going through 1 4 5 & 6  we will channel our communication through the backup link and please note that this backup or secondary path from the source of the destination is link this channel does not share any link with the primary path  so that is the requirement if any link in the primary path fails  i am assuming only one failure which means that the backup link is all intact and you can switch to the backup path for this particular communication  refer slide time  57  24-57  47 min  dedicated link protection is not always practical  sometimes it may have it shared link protection is practical  it is quiet often and it is implemented and it may fail  when this link protection may cause failure here you are only provisioning for the failure of the link  but if a node fails  then it may lead to some complications as we will see  refer slide time  57  48-58  07 min  so to compare between path switching and line switching path  switching of course is a coarse scheme and line switching is a finer scheme and line switching is can again be span protection  span would may be a several links together and that may be a span or a line protection  refer slide time  58  08-58  37 min  in mesh networks  of course the restoration is possible only if the graph is 2 edge connected that is by connected which means that there are 2 edge connected disjoint paths between any pair of nodes so that no single edge failure can disconnect the network so this is a necessity and usually try to keep that way  unless it will be difficult or it is not a cost  effective etc   refer slide time  58  37-59  21 min  protection in a mesh networks of course more complicated  then a ring simple minded scheme would be 2 edge node  no disjoint paths for each connection 1 + 1 not as is mentioned here  this not very efficient there may be many paths and provisioning double the number of paths  which are pair wise mutually node are edge disjoint that may be very difficult provisioning in the network better approach would be line protection which of course have the problem of coordination i will show the later on are protection cycles in mesh net  again i will show this computer networks prof sujoy ghosh dept of computer science& engineering iit kharagpur lecture 12 protection and restoration  refer start time  00  43  good day in this lecture we are going to discuss the various protection and restoration mechanisms which are usually employed in optical networks  refer slide time  00  57-00  59  we have to discuss what is protection and what is restoration and why we need them  refer slide time  01  08-01  18  what is protection  what is restoration  comparison between the two and the different schemes of protection would be our general outline of presentation   refer slide time  01  19-01  26  network is unreliable ; and then so many failures can occur ? a node may fail  a link may fail or a link may get cut  some fiber optic line may cut in-between because somebody cut it while digging a hole or something a node might fail  there may be power failures at nodes and so there are failures in the network but if you remember  one of the most important places where we deploy optical networks is in the core of the network the core of the network connects so many people to so many other people and it is very vital that we can not allow the services to be severely disrupted because that would have very grave consequences and anyway the service provider attempts to give a high level of service although failures are unavoidable in real life  we have to find some way of combating this ; that means if there is a failure we want to recover from it as soon or as fast as possible that is what protection and restoration is all about another thing is that when we want to give some reliability  protection  restoration  etc  in some form or the other we always have to bring in some redundancy without any redundancy  a system can not be protected  or it can not be restored without any replacement  etc there has to be some redundant capacity in some form in the network in order to achieve protection and restoration so how this is done is what we will discuss  refer slide time  03  20-03  25  protection and restoration are the mechanism to recover from network failure  their difference will be discussed in the following parts  refer slide time  03  26-03  37  why we need protection and restoration is now clear  to recover from network failure  to prevent the lot of data loss now another point is what would we mean by prevent lot of data loss ? the point is that we will be talking about protection at the optical level  at the lower  transport level  that is  the low physical level above this physical level  there are a whole lot of other layers like data link layer  network layer  transport layer  etc they may have their own protection mechanism and they might be able to tolerate in some cases  if such a protection is sort of implemented at higher level  such protection usually would tolerate a small amount of data loss  which they will retransmit or do something in the protocol to take care of that we will be talking about this later on within that limit we do not have a 100 % tight case  but we have something to play with within that limit  if the physical layer can come back up  then that is nice ; then the end user who is sitting at the top of the application layer would not notice that a failure has actually occurred so this is our general goal and  of course  to prevent lot of data loss  refer slide time  05  13-05  18  to provide reliable communication service is a reason for having protection and restoration  refer slide time  05  19-05  39  protection is the primary mechanism ; this is fast and routes are usually preplanned ? we will come to this part later on ? whereas restoration is the secondary mechanism  used to provide more efficient routes or additional resilience  etc  over and above protection we will see both of these later on  refer slide time  05  40-06  11  techniques for protection  we could protect a path  which is called path protection ; we could protect a link ; that is called link protection there are various schemes of protection  like 1 + 1 protection  1  1 protection  1  n protection  m  n protection this depends on what kind of redundancy we have built into the network so we will look at some of these techniques one by one  refer slide time  06  12-06  26  so what are the considerations and tradeoffs that we have for protection ? for support for fast protection  time is dictated by the client layer this is what i was talking about earlier ? in the client layer  whatever the higher layer we are talking about  all of them are clubbed together  and we are calling them client layer  let us say in the client layer we may have some resilience ; that means  we can tolerate some small amount of data loss so depending on that  and beyond that  it will be taken that the service will fail this is dictated by the client layer and that is the constraint within which we try to do our protection or restoration at the bottom layer  that is  the physical layer we require some switching technologies  refer slide time  07  13-07  33  as we will see  and how to implement protection it could be through dedicated hardware or through software here we will only be talking about ? since we are talking about the physical layer ? hardware protection  where some hardware has been put in order to take care of this protection  refer start time  07  34-07  51  support for low priority traffic ? that is another consideration we might have so low priority traffic supported using the protection bandwidth ; traffic dropped in case of a failure as i mentioned earlier that in order to give some protection capability into the network we have to build in some kind of redundancy over there now when there is no failure  naturally the redundant link would be idle what you could do is that if you have some low priority traffic  which could be dropped whenever there is a problem  under normal circumstances you can use your provision in the network to carry the low priority traffic  and as soon as there is a failure  where naturally the provision is going to be used up for providing protection  restoration  etc  the low priority traffic would be discontinued so that is one thing we could do  refer slide time  08  46-09  03  support for mesh topologies ? mesh topologies are bandwidth efficient  fast signaling mechanism  flexibility in choice of routes by preplanned routes  etc if we have support for mesh topologies  it is also nice as a matter of fact  if you remember our discussion about different types of topologies ? we have star  tree  ring  mesh etc  so these are the different possible topologies out of all these  point-to-point connection  ring and mesh are the three topologies  which dominate most of the wan when you want to communicate between two points  you first set a point-to-point link now consider that link to be quite important then what you would like to do is that you would like to put in some kind of reliability over there  by making it into a ring for example  we discussed sonet a sonet gear quite often is put in the form of ring  rings that would touch  mutually touching rings for example  the telecom people put up all these sonet rings through fiber optic networks the rings are quite easy to handle and we will discuss the protection mechanism in ring quite a lot but if you go to a wider geographical area ring  it may not to be feasible due to various reasons what you have is a mesh a mesh  if you recall  is just a graph  where the nodes are connected in some fashion it has to be a connected graph and actually later on we will see that for giving proper protection  it has to be not only a connected graph  it has to be biconnected graph as well that means between the two nodes  which are communicating  there have to be two alternatives paths  which are linked somehow otherwise  you will not be able to give protection giving protection in mesh networks is also an important consideration  refer slide time  11  17-11  55  other important considerations are maintenance of large distributed routing tables  that is  precomputed routes or up to date topology maps so you have to maintain this dynamically  because a network is a very dynamic thing as links come up or go down or nodes come up or go down  this may have to be recomputed and stored in a distributed fashion we would like to have support for all failure modes  node failure for mesh networks and for ring networks  so or it may be of course ring failures  refer slide time  11  55-13  05  first  let us talk about path protection it uses more than one path to guarantee that data be sent successfully if you look at this graph  it will have a 6-node graph where 1 and 6 are communicating and on the top  through the dashed line  we show the primary path  which is the primary connection between 1 and 6 now what might happen is that the link between 2 and 3 might snap due to some reason we have already got a backup route  which is calculated going through 1  4  5 and 6 so we will channel our communication through the backup link please note that this backup or secondary path from the source to the destination does not share any link with the primary path that is the requirement  if any link in the primary path fails  assuming there is only one failure  which means that the backup link is all intact and you can switch to the backup path for this particular communication  refer slide time  13  06-13  16  now path protection  there are various ways to protect a path  that is  various ways of provisioning the extra bandwidth capacity in the network so that you can give protection you need to build in some kind of redundancy in the network so there are various ways you can build in the redundancy and the schemes may be divided as dedicated path protection   refer slide time  13  40-13  50  or shared path protection dedicated path protection may be shown as 1 + 1 protection and shared path is 1  1 protection or 1  n protection so we will look at this one by one  refer slide time  13  51-15  31  this is an example of 1 + 1 protection so you have the source on the left  and then  you have destination on the right so it is communicating what you can see is that from the source  the signal is coming to the splitter if you remember  the splitter is going to split it into two halves  may be of equal power or something  and then the same signal is been carried through two different links and over there  we a switch the switch determines which signal is better and may be switches to that and a communication is going on if that particular link  say  this top one fails  it automatically switches to the other protection link so this is some kind of hot redundancy we have that means there is redundant source of information in the destination side ; so if the primary one fails  the secondary one is already on so protection would be very fast the only trouble is that for each such path  you will have to give an alternate path  which is also being used at the same time this is a dedicate path protection ? for this particular path there is a dedicated alternative path ; although this is very good  it is costly  refer slide time  15  32-16  57  now we come to shared mode protection ; in the shared mode  the figure looks almost the same  expect if you note  this splitter on the left has been replaced by a switch so what we have is we have a working fiber and we have a protection fiber unlike the 1 + 1 protection  this is not a hot standby this is cold in the sense that the protection fiber  to start with  is not carrying any signal  let us say the source is just simply passing through the switch  the signal from the source is passing through the switch  then down the path through the destination switch to the final destination if the working fiber goes down  then this switch will flip and the protection fiber would be in place since this is not a hot standby  meaning that since it is not carrying any signal under normal circumstances  you could share this path with something else you can use this to send some other channel or some other information  etc so that is why this is a shared mode of protection  refer slide time  16  58-19  35  generalizing this  we get this 1  n protection  where n line is sharing 1 protection line we have the inputs from 1 to n lines  so these are the n sources  and let us say so many destinations so they may be going ? 1 to 2 and n to n and so on ; this is the normal mode of operation this part of the network is for normal mode of operation and each of them is connected to a switch over here another link from the switch comes to one bigger switch  so this is an n input port over here and then there is a single link from this switch to this switch  on the destination side  which again feeds to all the switches what would happen is that in case there is a failure in any one  let us say  ith link from 1,2 to n  out of that  the ith source to ith destination  which is going through the ith link and the ith link fails  what this ith switch could do is that the ith switch could switch the signal from the ith source to this particular switch at the bottom and now the protection fiber would be carrying the signal that was flowing down ith channel over there and then again it will feed it to the ith switch on that side of course these two switches have to communicate that the ith one has failed over here  so you switch it to your ith mode  or this switch may sense it that this line has gone down  so it will take signal from this line this one protection fiber is been shared by these n working fibers  and as i mentioned earlier  when everything is fine this protection fiber could be carrying some low priority data when everything is fine these n working fibers are actually carrying the most of the important traffic so some low priority data could be flowing down the protection fiber as soon as there is any failure anywhere  the low priority data would be stopped or it will be dropped and then this protection fiber would switch to give the services between the nodes that have experienced a link failure just as we have a path protection that means for a path you try to give an alternate path  similarly you could do it at the link level also in general  it may be more efficient or more proper to do that because if you have n nodes and if it is slightly large  potentially you have very large number of paths through the networks and for each path having an alternate path may not always be a very good idea so we concentrate at the link level and for each link level we may give a protection  refer slide time  20  21-20  43  so use an alternate path if the link has failed this is the primary where the link may have failed so i have an alternate path to that from 2 to 3  2 to 4  4 to 5  5 to 3 this alternative  please note  is for the link from 2 to 3 we will have another diagram for that  refer slide time  20  44-21  09  dedicated link protection is not always practical although sometimes we may have it ; shared link protection is practical and it is quite often implemented this link protection may fail because here you are only provisioning for the failure of a link  but if a node fails  then it may lead to some complication as we will see  refer slide time  21  10-21  28  to compare between path switching and line switching  path switching is a coarser scheme and line switching is finer scheme ; and line switching can again be a span protection span may be several links together ; that may be span or a line protection  refer slide time  21  29-21  57  in mesh networks of course restoration is possible only if the graph is two edge connected i.e  biconnected  which means that there are two edge disjoint paths between any pair of nodes so that no single edge failure can disconnect the network this is a necessity and we usually try to keep it that way unless its very difficult or very cost it ? s not cost effective  etc  refer slide time  21  58-22  42  protection in a mesh network is more complicated then a ring simple minded scheme would be two edge or node disjoint paths for each connection  1 + 1 as is mentioned  it is not very efficient there may be many paths and provisioning double the number of paths  which are pair wise mutually node or edge disjointed may be very difficult that may be a lot of extra provisioning in the network a better approach would be line protection  which of course has the problem of coordination i will show that and protection cycles in mesh net later on  refer slide time  22  43-23  24  in the path layer and mesh protection  there is protection of mesh networks to protect the mesh at the single unit pre-computed routes means all possible routes and alternative routes are pre-computed 1 + 1 protection is protection route per light path  protection route per failure we will discuss this later but  as i said  this is a costly alternative or what we might do is that we can do on-the-fly route computation ; that means it is not pre-computed as there is a failure  centralized route computation and coordination route computation and coordination are done at end nodes or distributed route computations ? all these are possibilities  refer slide time  23  25-24  03  this is an example of mesh network  where let us say this is the primary path and this is an alternate path this alternate path may be pre-computed or it may be computed on the fly when there is a failure similarly  from here to here this may be the primary path and this is an alternate path please note that this communication as well as this communication are going through the same fiber maybe they are going through different wavelengths or maybe they are combined together ; so there are various way of handling this  refer slide time  24  04-24  51  let us look at some diagrams  this is a mesh network naturally once again  it has the same 6-node network and this is the normal operation  that is  communication from this node  node 1 to node 6 now there is link failure over here ; what you might do is you might switch the entire path like this so this was the pre-computed path for this path you switch to that ? this is one possibility or this particular span  the span could be live from here to here or from here to here that may have an alternative path  to which you switch  refer slide time  24  52-25  50  or this particular line may have this alternative ; that means from this node to this node if this is the link  the alternative to this link is this section from here to here to here to here it is trying to go through the same path  but then it takes a diversion when there is a link failure through the alternative  which is provided for this particular link i have shown only one node coming into this but you can appreciate that this path may be very long so you do not have to re-compute the path over the entire length ; rather locally  you can re-compute that for this particular link as an alternative so the alternative may well be through some local nodes only so this path just gets a slight diversion ; that is line protection  refer slide time  25  51-25  59  we talked about protection cycles in a mesh network  now for protection cycles  what we do is that for each of the paths we try to form a cycle ? cycle of provisioning of light paths  let us say the point in the cycle is that suppose we are going through some arc of the cycle and if some link in-between breaks  you can always go in the other direction so you try to form these cycles in the mesh which you keep ready and pre-computed so whenever there is a failure you can switch you can see here  refer slide time  26  38-27  03  there are pairs of a fibers going in both the directions and there you can form cycles over there one of them would be protection edge  maybe the inner one ; and one of them would be the working edge if one of them fails  the other will automatically take over ; the other direction will automatically take over  refer slide time  27  04-27  25  so this is another example of a network with both working and protection fibers the working fibers have been shown in solid lines whereas protection fibers have been shown with dashed lines once again you must realize that you may not provide the same level of protection to all paths or to all parts of the network ; depending on which part you consider more sensitive or more important  you may put your protection there a mesh network may be partially protected some of the parts may be protected or some of the parts may not be protected  refer slide time  27  51-29  53  so some more cases  line protection in a mesh network what we have is a unidirectional light path from node a to node d ; so from node a to node d we have an unidirectional light path going may be like this through nodes b  c  and e we are talking about this path a to b to c and then to e now after the link bc fails  the light path is rerouted by nodes b and c along the route a b f e c e d the unidirectional light path was going from a b c e and then to d ; so this was the path a b c e d now bc has failed ; so a b f e c e d you can see what has happened is that there was no point in coming from e to c and then back from c to e what has happened was that we were doing line protection ; that means  for bc my protection was from b to f to e to c because i wanted to go from b to c so i am going from b to f to e to c and so now bc has failed so that is what i do and from that point i continue wherever i was going and actually i was going from c to e to d  so once again from c  i go back to e and then to d such a thing is possible because we are taking a local decision ; that means  for this particular link what to do in the case of failure that has already been pre computed ? we are not taking a global picture ; here i have shown you a very small graph so you can immediately see the entire global picture with your own eyes but for local nodes we may not have the global pictures where this node is coming from and where this path is finally going to so all the intermediate nodes may not have the global pictures because if all of them had the global pictures maybe they could have computed a better path but this is for line protection  refer slide time  30  41-31  57  now line protection in mesh network  here what might happen is that erroneous connection due to the failure of a node is being treated by its adjacent nodes as link failure this is one case of the so-called race condition what might happen is that node 1 has failed ; so what would 6 do is that it may assume that the link from 6 to 1 has failed  whereas 2 may assume that the link from 2 to 1 has failed so both of them perceive as two different failures  so they take some local decisions  and it might lead to a funny situation where you are going in a cycle maybe other kinds of things may happen after node 1 fails ? node 5 gets connected to node 4 after node 6 and 2 invoke line protection independently if they perceive the same failure  the actual failure was that of node 1 ; but if they perceived differently as failure of link 6 1 and failure of link 2 1 and they have independent actions  it may lead to race conditions  refer slide time  31  58-32  14  the advantages and disadvantages of protection  we will also be talking a little bit of restoration protection is simple ; it ? s quick ; does not require much extra process time ? and this is the important part  since this is quick as i mentioned earlier  there will not be a lot of data loss for example  a sonet ring would sort of come back up from a failure in a less than 15 milliseconds so that is a benchmark ; you are back in action in less than 15 milliseconds  so whatever little you might have lost during that time would be taken care of by the higher layer protocols  refer slide time  32  51-33  08  but usually they can only recover from single link faults if there are multiple link faults  all kinds of funny things may happen there is inefficient usage of resource  because protection needs a lot of resources  even if we are sharing them  refer slide time  33  08-33  19  dedicated protection needs even more resources ; we talk about path restoration and link restoration  refer slide time  33  20-33  30  what we do is that we compute the path after the failure and the resource is reserved and then used so in restoration what you try to do that is that you try to look at the current actual situation you try to have some protocol for keeping track of the present situation and then you compute some root and then you reserve the path and then restore the original service this has got some software parts  so some data has to be processed  etc this usually takes more time  so this has a hardware as well as software aspect to do it   refer slide time  34  00-34  25  the path is discovered at the end nodes of the failed link ; but this is more practical than path restoration we have both path restoration and link restoration path restoration means the path may be long and to find out an alternative  it may be more difficult  whereas links are between the adjacent nodes so they may quickly find an alternative  refer slide time  34  26-34  53  advantages and disadvantages of restoration are the following  usually it can recover from multiplex element faults because you are sort of having some protocol to exchange information and then find the current situation and form the alternatives  etc there is more efficient usage of resources ; it is more complex ; it is slower ; it requires extra process time to set up path or reserve resources  refer slide time  34  54-35  19  so for comparison between protection and restoration  in protection the resources are reserved before the failure ; they may not be used in restoration the resources are reserved and used after the failure so this is the main difference between the two route  in protection it is predetermined  in restoration it can be dynamically computed resource efficiency  in protection it is naturally low and the restoration is comparatively high  refer slide time  35  20-35  55  time used for protection is short ; for restoration it is longer reliability  protection is mainly for single fault  whereas restoration can survive under multiple faults well  it is not that it can always survive under multiple faults ; it depends on the where the faults are  but if it is survivable after multiple faults  it will take global view and say that ok  still i can give the services so restoration will take care of that  whereas in protection it may not be possible to handle multiple faults implementation  protection is simple and restoration is naturally more complex  refer slide time  35  56-36  21  for optical networks  we not only talk about physical links we talk about virtual wavelength paths so in light paths also routing can be centrally controlled or distributed ; resource reservation  forward reservation  as well as backward reservation are done as we do in optical networks we will talk more about this later  refer slide time  36  22-37  15  now let us come to this all-important topic of fault management in ring networks as i said  ring networks are very ubiquitous in wan all the telecom people will love these things because naturally it allows them to give very high level of service so we have so many rings ; these sonet rings are very common  and rings are a very common kind of topology one of the chief attractions of the ring topology is its capability to allow some kind of protection and restoration with some redundancy in-built  as we will see we will look at two different cases  unidirectional path switch rings and bidirectional line switch rings or upsr and blsr  refer slide time  37  16-39  22  this is a diagram of upsr we have ab  means a to b and ba  means b to a first of all you see that we have these two rings ? we have this working fiber as well as a protection fiber working fiber is going in only one direction and protection fiber is going in the other direction  in the counter clockwise direction so for connection from a to b and from b to a ? this is a  and this is b ? my working fiber is going in this direction a to b is really going in this direction ; b to a is coming in this direction so a to b  b to a  this is the protection fiber part  a to b the working fiber is going in the other direction a to b is going like this and b to a is coming all the way like this let us say the outer one is a working fiber  it is through the outer ring for a to b  this is the path ; and b to a  this is the path  whereas for protection purpose ? and please note that this is a 1 + 1 scheme ; that means for this the alternative is already provisioned and maybe it is something like a hot standby so a to b is through the protection fiber and now this path from a to b is going via d and c  so a d c b  that is a to b and b to a the protection path is from this through the protection fiber so if there is a failure anywhere  this can still continue  so this is a unidirectional path switched ring  refer slide time  39  23-40  29  there are some limitations of upsr it does not spatially reuse the fiber capacity ; so what is happening is that since this is unidirectional  what is happening is that even if two nodes are side by side  if they are in wrong direction then it has to come all the way through and naturally all those links ? even if we are talking about particular ? s i mean wdm systems ? in the ring are entirely sort of covered by this otherwise even if we are talking about a wdm system what is happening is that at least one ? around the whole ring is getting occupied because two side by side things want to communicate so it does not spatially reuse fiber capacity and if there is some  you could use it for some other purpose that is not possible in a unidirectional ring each bidirectional sonet sdh connection uses up capacity on every link that is the thing ; if you look at the previous picture  refer slide time  40  30-40  44  we are just talking about a connection from a to b and b to a ; that ? s all  so this entire ring now has been used up assuming only one wavelength the entire ring now has been used up ; these adms of course are the adms of sonet  refer slide time  40  45-40  50  so it is efficient for lower-speed access networks  one to multipoint only  refer slide time  40  51-41  27  and the other point  which may become a problem  is that delays are different for the two paths because one of them is small and the other one is quite large  all the way around the link the relays in the two paths are quite different a remedy could be bidirectional lines ; that means  bidirectional line switched rings or blsr so we were in upsr  now we will be talking about blsr  bidirectional line switch rings this provides spatial reuse capabilities and additional protection mechanisms and adopts span as well as line protection we will have a look at both of these  refer slide time  41  28-42  26  this is a four-fiber bidirectional line switched ring ; so once again we have two working fibers  say  the outer two ones and two protection fibers or the inner ones so we actually have four fibers this is a four-fiber system and it is going  so we are using two such working fibers one of them is going in one direction the other is going in the other direction  so this is bidirectional we can communicate both ways  so if a to b and b to a both can communicate on the working fiber in this part at all  the rest of the space can be used for other communication so spatial reuse is much better for bidirectional line switched rings  and the protection fibers are there because if one of them fails then the protection fiber may take up  refer slide time  42  27-43  10  this is a span protection so we are talking about bidirectional traffic supports  maybe 16 nodes or some distances  etc  from a to b you may pre-compute a span that if this span goes down what is the alternative span if this is the case of line protection  if this line fails what is the alternative line ? now the alternative line of course may go in the other direction  depending on what the failure is so there are many different possibilities with this blsr  refer slide time  43  11-44  24  there is also two-fiber version of blsr  namely blsr/2 here both the fibers are working as well as protection fibers that means if one of them fails the other one will give the protection in the other direction of the ring if you note  the rings are going in the opposite directions and there is a line failure in both of these working as well as protection fiber that means a to b is communicating in this direction  b to a is communicating in this direction but if one of them fails  the other one will give the protection by going in the other direction in that case we have to go all the way round  then you will have to reserve the resource and if there is something already going on here  you may be blocked or this may have to be dropped and so on so naturally you have two fibers  we have less flexibility but with two fibers we can get this bidirectional thing going on  refer slide time  44  25-46  19  comparison of different types  these are all self healing rings what we mean by self healing is that the nodes  these adms and the sonet  etc  are programmed in such a fashion that as soon as they sense a failure they know what local action to take and how to adjust the switch internally  so that it automatically switches from the working fiber or from the working span or working fiber or whatever through the protection side that is why these are self healing rings  so they heal automatically and as i said these sonet rings really do this in less than 15 milliseconds ; the entire thing will again be up so we can compare the three  upsr  blsr/4  and blsr /2 for example  fiber pairs 1  2 and transmission receiver pair 2 4 and 2 spatial reuse in upsr it is none  in blsr it is there  and in blsr/4 it is there production capacity is equal to the working capacity link failure is path protection in the case of upsr or span or line protection in the case of blsr/4 in case of blsr/2  it is only line protection because it will have to go in the other direction node failure  it is path protection  line protection and line protection restoration is faster in upsr ; somewhat slower in blsrs and restoration speed is this node complexity is low  high and high another thing we talked about is the dual homing  refer slide time  46  21-47  50  by dual homing we mean that suppose we want to deploy your network in such a way that it is very mission critical and no failure is acceptable and we want a hot standby so what you might to do is that you may get connected through two different hubs and what you want to do is that you want dual home to these two hubs and these two hubs take independent paths to your destination this shows a dual homing to handle hub on node failure ; so we have these four adms  once again four nodes  let ? s say a b c d so the end node is a and these are the two hubs  b and c what we want is that not only some link failure but even if one of the hubs fails  i should still be able to communicate so what you do is on this ring you communicate with hub 1  let us say you are communicating with hub 1 through this a d c b and you are communicating with hub 2 through a b c as we will note  even if one of the hubs fails  you can still communicate through other one so this is another kind of protection  refer slide time  47  51-48  14  and finally i have mentioned this point before ? just a reminder that a network consists of many layers and each layer may have its own protection mechanism built in  independent of other layers so there are both advantages and disadvantages to this we have already talked about the advantages  refer slide time  48  15-49  51  this is an example of a wdm link carrying sonet traffic so there is a wdm link  so there is a sonet adm this is a working fiber pair and protection fiber pair please note that the pair has been shown as one line over here because usually as you know that fiber optic line is a simplex line ; that means it goes in only one direction ; there is a source in one side and the detector on the other side usually these fibers always come in pairs the other side is for the communication in other direction so we have a working fiber pair over there and protection fiber pair through this wdm link look at this 1  2 protected scheme what is happening is that there is one protection fiber pair  there may be protection fiber pair and through the working fiber there may be multiple virtual links going through the working fiber using different wavelengths a is a normal operation and b link is cut and the traffic is restored by the optical layer that means you automatically assign new wavelengths and new paths through the fibers etc  to bring it up so this you may do at the optical layer rather than at the electronic layer  refer slide time  49  52-51  58  but the case we are talking about here is that the sonet is riding on the optical layer so we have the optical layer at the bottom then you have a sonet on top of it on top of sonet also there will be the data link layer and then so on all the other links what we are saying is that each layer may have its own protection mechanism so for example i mentioned that the sonet will also have a protection mechanism of its own so if a sonet lte  i.e  the sonet line terminal equipment  senses that it can not communicate to the next lte  this will automatically reroute the traffic and try to reroute the traffic in the other direction sometimes it is good to have multiple protections at multiple layers but what might also happen is that they might sort of cancel each other or they might go into a race condition so these are the disadvantages of having protection at various layers there could be some disadvantage also if they are not very well coordinated  which usually would not be because these layers are sort of independent of each other they talk only to their peers and go through their own protocol and give protection apart from these of course the other disadvantage is that you may redo some part of the protection unnecessarily you may be unnecessarily duplicating the work at various places so these are the disadvantages of having protection at multiple layers  refer slide time  51  59-52  34  what is the advantage of optical layer protection ? speed and efficiency limitation would be detection of all faults may not be possible ; protects traffic in units of light paths so this is another problem as i mentioned  in light path the granularity is very coarse it may be 2.5 gbps ; so you are really giving the protection at a level of granularity  which may be quite high as i just now mentioned ; it could lead to race conditions when optical and client layers both try to protect against the same failure  refer slide time  52  35-53  28  of course  on the optical layer you have one more dimension to play with  which is in the case of a wdm that means you have different wavelengths  so instead of 1 + 1 link  you can talk about 1 + 1 wavelength path selection you can sort of try to select two independent light paths and the signal is bridged on both protection and working fibers if you are doing 1 + 1 protection kind of thing ; the receiver chooses the better signal in case of a failure  the destination switches to the operational link that is operational light path ; there is revertive or non revertive switching ; that means  if the original link comes back  it may revert or it may not revert ; and no signaling is required  refer slide time  53  29-53  30  so that is the unidirectional light path i have just shown you some of the schemes which are used for protection and restoration and as i mentioned  the schemes may be partially deployed and some of the parts may be protected and some of the parts may not be protected and so on but the essential idea is the same ? that you build in some kind of redundancy and the redundancy may be in the form of entire fibers or the redundancy may be in the form of light paths or wavelengths it may be pre-computed and pre-reserved like 1 + 1 ; it may be pre-computed but not pre-reserved like in a shared one or it may be computed as and when the failure occurs ; that is  in the case of restoration so there are various approaches to it depending on how critical the problem is or how critical the application is  what is the cost and how much extra provisioning you can do  you can choose your own way of protection and restoration thank you preview of the next lecture lecture ? 13 multiple access good day so today we will talk about multiple access ok now what is multiple access  refer slide time  54  59-57  54  if you remember that we had seven layer in the so called osi stack the top on being application then we have presentation session transport network link and physical ok we had been mostly talking about the physical layer till now although for optical networks we sort of ventured into some of the hired layers but from this lecture onwards we want to concentrate on the link layer ok now what medium access does is it coordinates competing request request for what for medium that means that there is a medium which may be an object of contention meaning that i mean several nodes may want to use it and this medium access control protocol has to do with how to handle that so sharing of link and transport of data over the link that is an general the description of what the data link layer does so when we share a link there is a question of committing request and we have to have some way of reserving that and of course there is a also question of transport of data over a link link if you remember when we say a link i mean that two nodes which are connected the nodes may be or computers routers switches etc they are two networking nodes they are directly connected now the when i do like this it might mean cable copper cable or a fiber or it might mean a shared medium like the free space ok so there is a but there is some way of communicating directly between these two nodes that is what we mean by link that means that is just one hop in the network that is what we are talking about in the data link layer so there is a question of reliable transfer of data over these link and if this link like when you have a free space transmission with so many nodes in the network now so many people would like to transmit so there is a question of sharing this medium and there is a question of who would access it when and just as i said free space could be a shared medium similarly if you remember that if you have some kind of a bus if you remember our discussion about topology of networks when we have some kind of a bus from which the number of nodes are hanging and that bus may also be an object of contention so that bus is the medium through which communication is taking place and there is an there is some kind of competition or sharing between the of this shared medium between the nodes so we have to handle that that is the other thing so examples of contention based or aloha and slotted aloha  refer slide time  57  57-59  00  these refers to some protocols which we are used in satellite communication so we will discuss these and we talk about satellite communication we have csma it stands for carrier sense multiple access or csma cd which is carrier sense multiple access with collision detection there are other variance of these like carrier science multiple access with collision avoidance and things like that so these aloha slotted aloha for satellite csma csma cd or specific specifically csma cd is used by ethernet in many situations and then we have csma ca may be for cellular communication etc so these are contention based mac and round robin there are these are token based protocols and so two very common ones are token bus and token ring so actually we will discuss these in the next in this lecture as well as the next we will be discussing these computer networks prof sujoy ghosh dept of computer science and engineering iit kharagpur lecture name # 13 multiple access  reference time  00  45  good day today we will talk about multiple access what is multiple access ?  refer slide time  00  55  00  55   refer slide time  00  56  02  21  if you remember  we had talked about 7 layers in the osi stack  the top one being application  then we have presentation  session  transport  network  link and physical we had been mostly talking about the physical layer till now  although for optical networks  we sort of ventured into some of the higher layers but from this lecture onwards  we want to concentrate on the link layer what medium access does is  it coordinates competing requests for medium ; that means  there is a medium  which may be an object of contention  meaning that several nodes may want to use it and this medium access control protocol has to do with how to handle that sharing of link and transport of data over the link is in general the description of what the data link layer does when we share a link  there is a question of competing requests and we have to have some way of resolving that  and there is also a question of transport of data over a link a link if you remember is two nodes  which are connected the nodes may be computers or routers  switches  etc  the two networking nodes are directly connected ; it might mean a cable  a copper cable  or a fiber  or it might mean a shared medium like the free space there is some way of communicating directly between these two nodes ; that is what we mean by link that means it is just one hop in the network that is what we are talking about in the data link layer there is a question of reliable transfer of data over this link and if when you have a free space transmission with so many nodes in the network  many people would like to transmit so there is a question of a sharing this medium and there is a question of who would access it when just as a shared free space could be a shared medium  similarly  if you have some kind of a bus from which a number of nodes are hanging  that bus may also be an object of contention bus is the medium  through which the communication is taking place and there is some kind of competition of sharing between this shared medium between the nodes so we have to handle ; that is the other thing so actually this  refer slide time  03  52 04  14  link layer may be divided into two sub layers  so to say  the upper one is the logical link control and the lower one is the medium access control we will talk about logical link control later we start with medium access control ; there are a number of medium access control protocols and techniques we will discuss a number of them  refer slide time  4  15-5  00  the situation we have is computers in a shared network environment and although the medium is shared  it is taken that only one computer can transmit at a time if two computers try to use the same line at the same time for transmission  i.e  when one is transmitting one or more may receive receiving is not a problem ; but when two computers want to transmit at the same time  their messages get garbled we say that there is a collision how can we organize the transmission so that all computers are given an opportunity to exchange messages ? if you remember  when we were talking about multiplexing  that is also in some sense sharing a medium so we had this time division multiplexing and frequency division multiplexing ; actually we also have time division multiple axis and frequency division multiple axis  etc  over here the difference between the two cases is that in the multiplexing case  the lines are all coming together into the multiplexer  whereas in multiple access  the points are all geographically distributed and they may not know about each other there may not be much of a coordination ; in some schemes we do have some coordination in some schemes we do not have any coordination so all these cases we will see there may be  refer slide time  06  03  06  26  point-to-point links in a network like ppp for dial-up access  etc  which is quite common ? point-to-point link between ethernet switch and a computer so these are examples of point-to-point links ; we will come to this later on then there are broadcasts  like a traditional ethernet  upstream in an hfc hfc is a hybrid fiber coaxial ; some part it is fiber and some part of it is coaxial  and the upstream traffic there also uses that medium as a shared medium then we have 802.11  which is a wireless standard we will have a separate lecture on this wireless networking  etc 802.11 is the number of the standard  which defines some form of a wireless networking wireless is a shared medium because it is sharing our common shared electromagnetic field that we already mentioned there may be a single shared broadcast channel   refer slide time  7  14  7  44  there may be many also  or more than one also two or more simultaneous transmissions by nodes will mean interference only one node can send successfully at a time multiple access protocol is a distributed algorithm ; so this is where it differs from multiplexing it is a distributed algorithm that determines how nodes share channels ; that is determined when a node can transmit communication about channel sharing must use the channel itself ; that means  we have what we earlier called in-band control usually that means if you have a  let us say  wireless network  if you are running any kind of protocol for control purpose  etc  that would also be using the same medium the same question of how to coordinate that with all the other competing nodes ? which are trying to transmit data ? all that comes into play  refer slide time  8  15  9  03  there are centralized approaches to a mac  i.e  medium access control the centralized approach is simpler in the sense that there is a controller  which grants access to the medium it is simple  has greater control  priorities  quality of service  etc ? all this can be implemented very easily for example  if you want to give higher priority to one particular node the controller simply just takes note of the priority when allocating the medium to a particular node but there are problems with centralized approach also one is that a single point of failure is a big problem when we have a centralized system and if that system fails  then the whole network is down  which may not be a good idea in many many situations secondly  there will be a performance bottleneck ; meaning  first of all everybody is communicating to it but when the network becomes bigger  the demand on its computational capacity  its control mechanism  etc  goes up proportionately and that is also another problem in centralized approaches in decentralized schemes  refer slide time  09  46  09  57  all stations collectively run mac to decide when to transmit so in a decentralized scheme we are running some kind of a distributed algorithm  refer slide time  09  58  10  55  there are various kinds of mac protocols  one is called something like a round robin mac in round robin there are a number of stations and each station takes its turn in a round robin fashion there are some protocols based on round robin mac so here  each station is allowed to transmit ; a station may decline or transmit that means  if it has nothing to transmit  it may decline otherwise  it will transmit it could be centralized ; for example  polling  or distributed ; for example  token ring control may be centralized or distributed of who is next to transmit when done  the station relinquishes and the right to transmit goes to the next station this is efficient when many stations have data to transmit over an extended period so that may be a good scheme  refer slide time  10  56-11  18  there are scheduled access macs  like time is divided into slots just like our time division multiplexing ; station reserve slots in the future ; multiple slots for extended transmissions and suited to stream traffic there is a question of reservation of some slots that would be a part of the protocol about how reservation will be done  who can reserve  and if two people want to reserve simultaneously then what happens so we have to handle issues like that this is the scheduled access mac  when it is scheduled  some reservation is done beforehand then there are some contention based macs  refer slide time  11  41  12  14  contention means there is hardly any control ; there is no control stations simply try to grab the medium this is distributed in nature and surprisingly  for no control  it performs quite well for a bursty traffic  but it can get very inefficient under heavy load actually  the round robin mac that i mentioned before  and the contention based mac are very common the most common example is the ethernet  which we will see especially later on ; how it is done  or how satellite communications use contention based mac that means nodes simply track and try to grab the control but over a long period of time  the amount of data or the number of times the nodes on an average try to communicate and the transmission time ? these two factors together define the load on the system if the load is light then this contention based protocols very surprisingly are much simpler and may be cheaper to implement so examples of contention based are aloha and slotted aloha  refer slide time  13  06  14  08  these refer to some protocols which we use in satellite communication ; so we will discuss these when we talk about satellite communication we have csma ? it stands for carrier sense multiple access or csma cd  which is carrier sense multiple access with collision detection there are other variants of this  like carrier sense multiple access with collision avoidance and things like that aloha or slotted aloha are for satellite  csma  csma cd  specifically csma cd  is used by ethernet in many situations ; and then we have a csma ca  may be for cellular communication these contention based macs round robin  are token based protocols and two very common ones are token bus and token ring actually  we will discuss these in this lecture as well as in the next  refer slide time  14  09-15  38  we can sort of summarize ; first of all we can divide the networks into two types  depending on their topologies ? one is the bus type bus means some communication channel and everybody is connected to the same communication channel it may be a coaxial cable or some fibers or it could be a ring then we have this token bus  which is one particular mac protocol it has got ieee standard number 802.4 or polling in 802.11 we will come to this later on these are examples of bus type topologies using round robin techniques token ring is a ring type topology and 802.5 is the standard number fddi is a round robin  but the topology is the ring there are scheduled approaches to medium access like dq db or distributed queue dual bus 802.6 we will be talking about this also contention based are csma cd  csma ca in 802.4 and 802.11 the first one is ethernet and the second one is a wireless network ; so we will look at these in later lectures  refer slide time  15  39  15  49  what is the ideal of a multiple access protocol ? suppose we have a broadcast channel of rate r bps well  any broadcast channel would have some maximum limit or the rate you can communicate over ; that depends on the characteristics of the medium if their medium is different  this rate r may be different ; for example  the rate for a fiber optical cable would be much higher than the rate for a coaxial cable but the point is that there is always an upper limit due to various reasons ; we need not go to that in this lecture due to various reasons of how we communicate  etc  there is a maximum rate r  which you can achieve on a particular medium using  let us say  the technology  which is present now when one node  refer slide time  16  43 -17  52  wants to transmit  it can send at rate r there is no problem ; it can send all the way up to rate r if the technology permits when m nodes want to transmit  this r is not going to change so what you want to do is that you want to divide up this rate r and distribute it among these m nodes  which want to communicate so each can send at an average rate r/m if that happens  naturally we have an ideal multiple access protocol ; we can not do better than that but it is difficult to achieve this theoretical rate because there will be some overhead for the protocol itself  which will eat up something none of the protocols is 100 % efficient secondly  we would ideally like it to be fully decentralized so there is no special node to coordinate transmissions  no synchronization of clocks and slots lastly  it will be simple naturally if it is decentralized  no synchronization  etc  that is one aspect of simplicity then the protocol itself will be simple this is the other thing ; and we want a fully decentralized scheme  i mean we preferred them because there would be no failure of single nodes  etc  and then there is no bottleneck these problems should be avoided if you have a fully distributed system in multiple access  refer slide time  18  18  18  57  as i mentioned  many users are sharing a resource at the same time ; it is needed because users must share the cells first let us talk about three different multiple accesses  frequency division multiple access  time division multiple access and code division multiple access frequency division multiple access and time division multiple access are very simple we have already talked about multiplexing ; only thing is that the connotation is slightly changed over here code division multiple access is somewhat different ; so we will discuss it in some more detail so they use the same frequency  same time  but different codes ; we will come to that  refer slide time  18  58  19  16  let us start with fdma fdma is frequency division multiple access just like frequency division multiplexing  channel spectrum is divided into frequency band each station has an assigned fixed frequency band unused transmission time in frequency bands goes idle this is the simplest possible scheme it is also not very efficient because many of the stations will be idle and that frequency band for that particular time is sitting idle ; that part of the bandwidth is wasted also  we know that in a data networks the net traffic is very bursty ; that means people want to transmit for a very short amount of time suppose the transmission time is t ; then may be for 500 ? t amount of time  it just sits idle it is very bursty ; so a frequency division multiple access would be very inefficient but this is the oldest ; you know  radio stations are doing multiplexing since the communication is only one way but if you are using some other kind of say radio frequency transmission using fixed channels  when there is both way of communication  then it is some kind of multiple access also so suppose we have six stations lan 1,3  refer slide time  20  26  20  34  and 4 have some packets to send so they are sending ; frequency bands 2,5,6 are idle this happens quite often an fdma  refer slide time  20  35  21  26  this is another picture ; we have tried to show with colour the graphs of the different channels the channels are differently colored  these bars   and we have the three accesses ? f is the frequency  c are the channels and t is the time there is only one channel at all times that uses the particular frequency ; another channel for all times uses another frequency  and so on another frequency means it is not a single frequency ; this is a frequency band kind of thing you always require a band ; you can not communicate anything with a single frequency that will be just a single tone  refer slide time  21  27  21  56  frequency division multiple access for each channel gets a band  range  of frequencies used in traditional radio  tv  first generation cellular  etc advantage is that there is no dynamic coordination ; it is absolutely distributed disadvantage is that it is inflexible and inefficient if channel load is dynamic and uneven by today ? s standards  it is quite high  but at one point of time it was a quite good  refer slide time  21  57 -22  10  we will see another version of this fdma  which is wdma wdma means wavelength division multiple access ; and as you can suspect  now we are talking about fibers we just have a frequency division multiplexing and wavelength division multiplexing they were actually the same thing ; the only thing is that for fiber we choose to call it wavelength division multiplexing here also  we are talking about wavelength division multiple access previously all our fiber links that we talked about were point to point suppose the fiber link somehow is used for multiple access  two stations in a very dynamic fashion  we want to give this bandwidth a number of stations can connect to the same fiber through some splitter  coupler  etc so we are not going into that suppose somehow they are hooked into this fiber and we want to use wavelength division multiple access let us just look at the scheme  refer slide time  23  03  23  56  each station is assigned two channels ; a narrow channel for control and a wide channel for sending data frames the channels could also be of the same size  does not matter  but then for control we do not require so much bandwidth for a particular node  these two are assigned a node ? s control channel is used by other stations to contact that node so its control channel is fixed some other station  if it wants to communicate with a  will first talk to a on its control channel both channels are divided into n + 1 slots  which repeat endlessly slot 0 is especially marked to synchronize the nodes in each channel  there are  say  n + 1 slots and then a number of nodes ; let us say  three nodes  b  c and d can communicate with a at the same time because of communicating to a it has to send to a in the channel or the wave length which has been assigned to a but how can all three send at the same time ? if there are slots in that channel and if they have booked separate slots  in different slots their data can go so b  c  and d simultaneously communicate with a  refer slide time  24  33  25  42  each station has two transmitters and two receivers first it has to have a fixed wavelength receiver for listening to its own control channel its control channel is fixed  so it requires a fixed wavelength receiver then it wants to communicate to somebody else ? s control channel for that it requires another transmitter and that has to be tunable because a may want talk to b at one point of time and then talk to c at some other point of time b and c ? s control channels are different so we sort of have to have a tunable transmitter we have a fixed wavelength transmitter for outputting data frames suppose it wants talk to b it can talk to b ? s control channel  when a wants to communicate over the wavelength assigned to it then it can output the data frame at a fixed wavelength  refer slide time  25  43  26  09  it requires the tunable receiver for selecting a data transmitter to listen to a is talking to b  so for talking to or listening to b it requires a tunable transmitter because it may want to listen to b now and later on  it may want to listen to c the data channels for each station contains a special slot where the status of both the channels  which slots are free  etc  are reported  refer slide time  26  10 -26  36  when station a wants to set up a connection oriented channel to station b  it tunes to b ? s data channel and waits for the status slot it puts in the request in any of b ? s free control channel slots b ? s status slot will tell whatever control channel slots are free so b just puts in a request over there when b sees the request  it assigns the slot to a and announces it to others  refer slide time  26  37  28  18  there is a problem in a distributed system  in the sense that you always have to worry about this kind of thing if two stations grab the same control slots simultaneously  both of them want to talk to b and both of them sort of want to grab that same control slot by some chance simultaneously when we say simultaneously  they both are close together  and so the information will get garbled so naturally if both of them are trying to put things in the same box the information will get garbled and both of them will notice in that case both will back off for a random amount of time when they do back off for a random amount of time  the random number generated by one station and the random number generated by the other station will be different so both of them will back off for two different amounts of time  and which ever has the shorter waiting time  comes back and tries to put again on this control slot hopefully there will be no collision this is one kind of collision and backing off this kind of scheme is used elsewhere also ; we will come to that for two-way communication  b repeats the same algorithm for a for variable bit rate traffic this is for synchronizing  so one slot can be sort of reserved for this communication between a and b for variable bit rate traffic  slots in data channel are not booked so they can be sent by some other mechanism let us not go into that at the moment  refer slide time  28  19  29  59  next  we come to time division multiple access if you notice the figure  this looks just like time division multiplexing we have the information or signal from this top one  high one coming and then it is sort of interspersed with the signal from this source go they are going in a time division multiplex fashion only thing to notice over here is that this line and this line they may not be actually physical wires that is why some wireless has been put over here so they are actually sharing the same medium so immediately you see the problem ? what happens if this synchronizing behavior breaks down so somehow you have to make sure that they do not break down and they do communicate at precise slots of time  which is assigned to them then you have the additional trouble of ensuring that the clocks synchronize if he is running a clock of different zone these two clocks may not agree  so how to synchronize them  etc these are the problems which you solve in a tdma  time division multiple access otherwise the basic approach is the same as time division multiplexing  refer slide time  30  00  30  15  tdma is time division multiple access it enables access to channel in rounds each station gets fixed length slots  length is equal to packet transmission time in each round the unused slots go idle ; this is a simple scheme  refer slide time  30  16  30  49  for example  suppose we have six stations  lan 1,3,4 have packet and slots 2,5 and 6 are idle this kind of frames sequence keeps on repeating in each frame  1 will have a slot  2 will have a slot which is going idle  3 will have a slot  4 will have a slot  5 and 6 will also have slots which are again going idle and so on so this is a tdma system  refer slide time  30  50  31  33  each channel gets entire spectrum for a certain time period  rotating time period so whenever the time is allotted to that particular channel it gets the entire spectrum to itself  so it can send the data at a very high rate the advantage is that it can assign more time to senders with heavier loads by doing that  it gains some kind of efficiency advantage over fdma and another side of the same point is that you can reduce the power consumption the disadvantage is that it requires precise synchronization  which we talked about earlier this is a diagram for the  refer slide time  31  37  31  59  time division multiple access the entire frequency band is given to one particular channel for a short amount of time then  for the next short amount of time  another channel gets the entire frequency band and so on as it is there in standard time division multiplexing  the same thing applies  refer slide time  32  00 -32  51  now we can combine tdma and fdma each channel gets a certain frequency band for a certain amount of time an example is gsm ; we will come to this may be in slightly more detail later on so  this is combining both tdma and fdma ; that means  we are breaking it up not only in the time domain but also in the frequency domain the advantage is that there is more robust against frequency selective interference because for a particular communication the frequency is sort of changing ; there is much greater capacity with time compression ; and there is inherent tapping protection so it has got a lot of advantages and it is quite efficient the disadvantage is that  once again  just as in tdma  we have to synchronize the clocks  etc so here  frequency changes must also be coordinated  refer slide time  32  52  33  09  this is the picture ; basically  we have small blocks so for this particular yellow block over here  at this particular time  this particular frequency range is given to this channel and so on  refer slide time  33  10  33  46  next we come to channel partitioning or cdma cdma is code division multiple access this may be a little interesting and new we have a unique code assigned to each user  that is  code set partitioning what is that code ? we will come to that it is used mostly in wireless broadcast channels like cellular satellites  etc all users share the same frequency  but each user has his own chipping sequence  that is  code  to encode data we will come to the details encoded signal is the original data ;  refer slide time  33  54  34  13  and then there is some operation with the chipping sequence we will come to what is chipping sequence decoding is the inner product of encoded signal and chipping sequence ; it allows multiple users to coexist and transmit simultaneously with minimal interference if codes are really orthogonal  refer slide time  34  14  34  27  we have a number of stations sharing a number of channels each station transmits over the entire spectrum all the time  which means that it is not excluded either in a time dimension or in a frequency dimension each channel can go on communicating in the entire frequency band all the time now how will that happen ? because other people are also communicating in the entire frequency band all the time all their signals will get mixed up ; as a matter of fact  they do get mixed up  but the point is that the signals are encoded in such a clever fashion that from that mixed signal you can separate out all the different streams of communication that have gone into it so multiple simultaneous transmissions  refer slide time  35  06  35  20  are separated using coding theory there is an assumption that the signals add linearly ; if they do not  then you have to do some adjustment  etc we will not go into that  refer slide time  35  21  35  23  cdma is a form  refer slide time  35  29  36  17  of spread spectrum multiple access it is spread over the entire spectrum instead of sending b bits per second for a particular node  we send m b chips per second what is a chip ? each bit is encoded by m number of chips they are sort of tiny fragments of bits and these chips may again be 0 and 1 there is a 0 1 sequence code for these bits of one particular station ; another station will have another code a 1 mhz channel with 100 stations gives 10 khz per station with fewer than 100 chips per bit  the effective bandwidth is higher and the channel allocation is also done at the same time ; we will see how  refer slide time  36  18  36  29  this is the picture  which is funny because for the entire time for the entire frequency band  all the channels are using it at the same time  refer slide time  36  30  37  09  now each channel has a unique code all channels use the same spectrum at the same time but orthogonal codes it is bandwidth efficient ; its capacity also is quite good  when i talk about simple tdma but you can sort of mix up fdma and tdma and get a good efficiency over there also this fight between gsm and cdma is ongoing and it will go on for some time the disadvantage is that it has more complex signal regeneration so this is how it is implemented  refer slide time  37  10  37  24  as i said  each bit time is subdivided into short intervals called chips and typically there are 64 to 128 chips per bit that means for each bit we have a code  which is 64 bits long the chips are again in a sequence of 1s and 0s so we are sending a long sequence of 1s and 0s for sending may be 1 but we are sending it very fast ; and we can send it very fast because we are using the entire spectrum the entire spectrum is at our disposal ; so we can send it very fast  refer slide time  38  04  38  12  each station is assigned a unique m bit code or chip sequence  which is used by the station to transmit 1 ; its complement is used for 0  refer slide time  38  13  38  39  we will see an example  two codes  s and t  are said to be orthogonal ; we have been talking about orthogonal codes if under a certain operation we have s let me call it a dot product kind of thing at the moment so s dot t is equal to 0 and s dot s is equal to 1 you see that this is very similar to dot products in vector if you have two orthogonal vectors  the dot product is going to be 0  whereas on the same vector when we take its dot product with itself it is going to give some value we are representing it as 1 we define the following let us  refer slide time  38  57  39  19  define this dot operation for our case so s dot t is equal to 1/m ? summation of si ti ; i is equal to 1 to m and this will be equal to 0 if and only if s is not equal to t we will see this  refer slide time  39  20  39  29  if one and zero are represented by + 1 and ? 1 respectively  we find that s dot s equal to one this is a very simple because if the ones have been represented as one and zero has been represented as a ? 1  so s dot s so ? 1 will get multiplied with ? 1 giving you + 1 and one and one will also give you one so all of them would be one so all m of them would be one the sum total in the previous if you look at the previous definition the sum  refer slide time  39  53  40  16  si si is going to be a sigma si si is going to be m ; you divide that with m so that will give you a 1 so s dot s would be 1 whereas for any other code  any other t  where the t is orthogonal to s  this sum is going to come out as 0 that is how we cleverly assign the codes  refer slide time  40  17  42  35  consider a code t where the number of chips of t  which are the same as those in s is the same as the number of chips of t  which are different consider what it is saying  at code t  where the number of chips of t  which are the same as those in s are the same as the number of chips of t which are different  the number of chips of t which are the same as those in s so the corresponding chips  when multiplied together  will give you so many 1s if it is the same as the number of chips of t which are different  now if the chips are different in t and s when the corresponding chips are multiplied  they would give you ? 1 the number of + 1s and the number of ? 1s  if they are the same when you add them together in the previous summation  the sum total will become 0 s dot t will be zero note that s dot not of t ; not of t is the complement of t that means the 1s and 0s are presented with 1s and ? 1s so 1s and ? 1s are flipped in one of them so naturally the number of chips which are different become the number of chips which are the same and the number of chips which were same earlier  the chip positions which were same earlier  now become different but any way their numbers are equal so once again we have s dot not of t is 0 and s dot not of s ? all the 1s in s will be ? 1 in not s and all the ? 1s in s would be 1 in not s so in either case  we will get a product of ? 1 m ? 1s added together will give you ? m divided by m will give you ? 1 we have s dot s equal to 1 ; s dot t is equal to 0 ; s dot not of t is equal to 0 ; s dot not of s equal to ? 1 so these are the nice properties if we have orthogonal codes  refer slide time  42  36  43  44  so consider the following codes  suppose this u  r  s  and t are four different stations here a simple example has been shown using only eight chips you note that between u and r  in one position they are same ; in this position they are same ; two they are different ; in this fifth position they are same that is the number three of the position in which they are same and then there is the number four position  which is the seventh position  where they are the same in four positions they are the same and four positions namely the third position  fourth position  sixth position  and eighth position they are different the number of positions in which they are the same is the same as the number of positions in which they are different we know that if instead of 0 we have a ? 1 these codes will come out to be orthogonal similarly you would see that u  r  s  t are all orthogonal to each other so the above codes are all orthogonal under the operation defined  refer slide time 43  45 -45  09  note that s dot t plus r is s dot t plus s dot r  which means that under normal addition  if you take this is normal addition  this dot product is going to distribute thus under the assumption of linear addition of signals  s dot sigma of ci is equal to s if and only if s is in ci that means suppose there are a number of channels  which are transmitting in that case  we have already assumed linear addition of signal strengths this is nothing but some of the signal strengths like q  t  r  u  s  etc  have been all added up now s dot will distribute over this summation  so we have s dot t and s dot r etc if s happens to be in this set ci  then that s dot s will come out as 1 it should be 1 if and only if s is in ci ; otherwise it will come out as 0 assuming during any bit time u  r  s  and t transmit 101 and nothing  u is trying to transmit 1  r is trying to transmit 0  s is trying to transmit 1  and t is not transmitting at all if you use the code shown in the previous slide over here  refer slide time  45  10 -45  13  and then if you do the calculation   refer slide  45  14  45  30  this will come out to be like this  the signal strength as we see it  will come out as ? 1 + 1 ? 3 + 3 ? 1 ? 1 ? 1 + 1 ? so these are the eight signal levels we get  refer slide time  45  31  45  50  now if we do that  c dot u will get a + 1 that means c dot is trying to send 1 ; c dot r will be ? 1 ; that means r is trying to send 0 ; c dot s will be + 1 ; that means s is trying to send 1 ; and c dot t would be 0 ; that means c is not sending any thing at all if you remember   refer slide time  45  51  46  01  101 that means a s r  u and t are transmitting in this fashion  refer slide time  46  04  46  33  one implicit assumption in the above is that all stations are synchronized and transmit with the same power in practice  perfect synchrony is difficult to achieve resulting in the use of longer chip sequences and lower channel capacity secondly  to tackle the problem of power  each mobile transmits to the base station at the inverse of the received power so there are practical limitations although this looks very nice  what happens is that there are practical limitations and the theoretical maximum that we could achieve is less than that but this is an elegant system now we will look at some  refer slide time  46  50  47  18  mac protocols  two of them  two small ones we will discuss in this lecture  and then  in the next lecture  we are going to take two of the more involved ones taking turns macs protocols  do you remember that we had channel partitioning mac protocols and random access mac protocols and taking turns protocols ? in taking turns  what it tries to do is that it sort of allocates the turn and we will see how  refer slide time  47  19 ? 47  55  one could be through poling by a master node  which is some kind of a centralized system there is poling of overhead  latency  single point of failure  etc  we are not going to discuss this at this point of time we are going to focus on this in the next ; that is token bus control a token is passed from one node to the next sequentially ; there is a token message that concerns token overhead  latency  single point  etc we will see some systems based on tokens now  which are sort of using mac taking turns  refer slide time  47  56  48  00  and the first example we are going to talk about is the token bus  refer slide time  48  01  49  05  so they may be mainly used by assembly line factory it is used in factories for the main reason that in the other kind of system  which is the contention based system  there is some randomness in the way communication can happen there may not be any hard and fast guarantee  which people in process control and factories  etc may not like so they may use this token bus  which has got the ieee number 802.4 token bus is just like a common bus and the principle is like a token ring token is passed from high to low number of station what is a token ? token is some kind of a bit pattern  which is passed from high to low number of stations the station with token will transmit it is difficult to add and remove stations in this particular case  refer slide  49  06  49  50  so ieee 802.4 determines the logical ring of the physical bus by the numerical value of the addresses a mac or llc data unit provides the utility for the lowest address to handle the token to the highest address otherwise  the higher address gives the token to the lower address so the predecessor gives the token to the successor then the successor gives the token to the next successor and so on  all the way down the chain then there is some protocol for sending from the lowest one to the highest one in one group then the token is passed from a predecessor station to the successor station so this a sort of taking turns kind of thing  refer slide time  49  51  50  35  the token is passed from stations to stations in a descending numerical order of station address when a station hears a token frame  that means it gets a token frame addressed to itself  it may transmit data frames that means when it gets the token  which is addressed to itself  and which has been sent by the node which is just higher in number  which is its predecessor  that will be sending the token address to the next station at that point of time  it may transmit its data frame when a station has completed transmitting data frames  it passes the token to the next station in the logical ring so if all of them are trying to transmit they will sort of form a nice queue and then they will come back in a very regular fashion ; that is the worst case  refer slide time  50  36  50  35  at some particular point of time  a node may not have anything to communicate in that case  it will simply pass on the token to the next lower address  next lower mac address by the way  i have used the term mac address earlier also mac is for medium access control ; for that  we require some kind of address a particular node  if it has nothing to transmit  will give the control or the token to the next lower mac address and then the next lower mac address will  if it has something to transmit  will transmit what is the worst case ? the worst is that when everybody wants to transmit ; that will take some time  but there is a bound to that time and after that time your turn will come back again so there is a bound to the worst case performance in this token bus but this is not very efficient  and not very fast so it is getting replaced now  but even in some factories it is still there we are going to talk about another technology  named dqdb  which was once proposed ? it also had a name s m p s ? as a solution for metro networks and that means for metro networking  dqdb was suggested and some were implemented but dqdb is once again going out it has a similar kind of principle ; only thing is that instead of a single bus we now have two buses so let us look at dqdb very quickly  refer slide time  52  20  52  23  dqdb is 802.6  refer slide time  52  24  52.54  so it is for a metropolitan area network spanning may be 50 to 100 kilometers and operating at a 34 to 45  even 155 mbps speed was talked about at one point of time this did not work out quite well later on ; but any way  that is a difference story it was originally designed like fddi ? we will be talking about fddi in the next lecture ? for connecting lans ; expanded to service packet switching at 2 mbps and isochronous services isochronous means nearly synchronous  refer slide time  52  54  53  30  it features fixed length packets like 53 bytes long  and we will see atm later  which was inherited from this dqdb later on atm is still a strong technology even today empty cells are generated by the head ends so there are two buses as i mentioned  and then  at the end of the bus  there are these head ends  which generate a stream of empty cells the streams of cells move in the opposite direction in the two buses and finally fall off the other end  refer slide time  53  31  54  20  so to transmit to a destination  the node has to know which bus to use ; that means whether it is to the left or right  or up or down so it has to know which bus to use so every node must be having this information it sets a request bit in some cell  which is going in the opposite direction this is for telling suppose the node to which it wants to communicate is downstream  say towards the left  then it tells all the other nodes towards the right that it wants to a communicate to this node on the left it defers to downstream requests  counting such requests as they pass by ; nodes are not greedy so this is the heart of the protocol actually what it does is that if you simply get an empty cell and want to put in your data  then those nodes  which are towards the end  are favored i mean it is not a fair system any longer but then  in this scheme  if you think about it  you will queue the request on a first come first serve manner and that is why you put in your request to the other side so that those nodes on the other side would know that he is going to send something  refer slid time  55  00  55  06  so to transmit to a destination  the node has to know which bus to use  etc  and the nodes are not greedy  refer slide time  55  07  55  18  its primary importance today is its close affinity to atm  and the consequential association with sonet and sdh  for which we shall see atms provide the approved a switching fabric thank you in the next lecture  we are going to discuss two more token-based protocols  namely  token ring  which was more common than this token bus or dqdb and fddi thank you  refer slide time  55  37  55  39  good day in the last lecture we talked about various multiple access schemes and a one of this set of schemes in token bus and dqdv etc where using tokens ok now we will use the we will see two other variance of it namely token ring and a  refer slide time  56  05  56  10  fddi so we are going to talk about token based mac and specifically  refer slide time  56  11  56  29  so they are some kind of round robin macs that means a the chance to transmit comes to each of the station in a round robin fashion and this can be done as i mentioned earlier through poling or token busing here we will be specifically talking about token busing  refer slide time  56  30  57  03  so the first a system that will talk about is the token ring so as as the name itself suggests that it is a ring topology it is a ring on a token ring mac works with a special pattern or token which is three bytes long so it is a three bytes words of bits called token which moves from one computer to the next priority indicators are used within the token how the priority indicators are used we will see later so  refer slide time  57  04  57  35  so data rate may be four sixteen or hundred mbps medium may be utp stp or fiber signaling may is usually differential manchester we mention this earlier what is differential manchester that how you represent here zeros and ones by electrical signals or optical signals as the case may be and the maximum frame size would be about this four thousand five hundred and fifty bytes or write up to eighteen point two kilo hertz  refer slide time  57  38  58  11  now let us talk about the type of network stations which may be a connected to an fddi ring one is a dual attached station which is connected to both the rings that means it is a station which is connected to both the rings that is why it is called dual attached then we have dual attached concentrator dac which is connected to both rings and provides connection for additional stations and concentrators it is actually the root of a tree this is where the tree comes from i have a  refer slide time  58  12  58  35  a picture so we have a so this is the picture of an fddi concentrator so you can see that this the concern this is the main part of the concentrator and the two rings are there the counter rotating this is the primary ring and this is the secondary ring so the primary ring is coming like this from a to b and the secondary ring is going like this it has some additional ports from which other stations may hang computer networks prof sujoy ghosh dept of computer science & engineering iit kharagpur lecture  14 token-based mac  refer slide time  00  45  good day in the last lecture  we talked about various multiple access schemes and one of this set of schemes is token bus dqd etc we will see two other variants of it  namely  token ring and fddi  refer slide time  01  08-01  15  we are going to talk about token-based mac  refer slide time  01  15 ? 01  34  they are some kind of round robin macs that means the chance to transmit comes to each of the stations in a round robin fashion this can be done as i mentioned earlier through polling or token passing here we will be specifically talking about token passing  refer slide time  01  34 ? 02  07  the first system that we will talk about is the token ring as the name itself suggests  it has a ring topology a token ring mac works with a special pattern or token  which is 3 bytes long  called token  which moves from one computer to the next priority indicators are placed within the token we will see later how the priority indicators are used  refer slide time  02  07  02  42  data rate may be 14  16 or 100 mbps medium may be utp  stp or fiber signaling is usually differential manchester ; we mentioned this earlier differential manchester is how you represent your 0s and 1s by electrical signals or optical signals as the case may be ; and the maximum frame size would be 4550 bytes or right up to 18.2 kb  refer slide time  02  42 ? 03  11  in token ring  like a token bus  a token is passed around the ring  and within the token is an indicator that senses the ring as free or busy if the token is busy that means some frame is being communicated at that time  the token circles continuously around the ring are passing each station each station is required to examine the token  refer slide time  03  11 ? 03  38  if a station wishes to transmit data and the token is empty  it seizes or captures the ring by modifying the token to a start of user frame indicator  appending the data and control fields and sending the frame around the ring to the next station the next station will now get the token as well as the frame  which will pass on till we get  refer slide time  03  38 ? 05  41  to the node where the data is copied only if it is to be passed to the end user application attached to the node that means there is a destination address when the destination node sees that data  it knows that this is for him so he absorbs  that means  he copies it back he makes a copy of it and sends it to the application layer in that particular node through all the other layers ; we are not concerned about that at the moment but the token and the frame continue circulating in the ring till it comes back to the center when the token arrives back at the original site  the token is once again made free and placed onto the network you see in this scheme only one frame ? i mean if the ring busy at all then one frame ? is traveling along it it has left the source station  then it has been copied by the intermediate nodes on to the frame as well as the token with the busy indicator over there then it finally comes to the end station and at the destination station  it makes the copy of the data for its own use and keeps on circulating this frame and the token right up to it when it comes back to the original sender  the original sender will now strip all these data  make the token free  and put it on the ring now  some body else who ever wants to transmit next  will capture the token and send it in this fashion this shared medium  namely the ring  is shared by all these nodes attached to it  refer slide time  05  41 ? 06  05  when a station wants to transmit  it has to wait for the token  then it has to seizes it  and then it transmits the frame when the station seizes token and begins transmission  there is no token on the ring nobody else can transmit there is no contention or collision as such  because only the station that has got the token can transmit ; so all others do not transmit  refer slide time  06  05 ? 06  44  what is the expected performance of token passing ? first of all  it is fair because it is going in a round robin fashion so everybody will have his chance ; each computer is given in turn an opportunity to transmit even when the traffic is high however  even if only one computer needs to transmit a message  it has to wait till the time that it receives back the token until it receives the token  it can not start the transmission  so it has to wait again  long messages should not be allowed because otherwise one computer may hold the token for too long  refer slide time  06  44 ? 07  49  several tokens are there some variations of it use slotted rings  where several tokens or slots are used these may be more useful and make it more efficient because if it is a very long ring and only one frame is traveling down it  it is rather inefficient way of using the system so what we can do is that we may allow multiple frames  that means multiple slots  which are sort of distributed over the space for example  if the speed is 200 m/ ? s of the frame  the data rate is 10 mbps these ten bits will span over 200 m over the ring so a 2 km ring can hold 100 bits ; that is the kind of performance with a single frame  refer slide time  07  49 ? 08  42  let us look at how the priority works in the token ring ; because what we can do is that we can do differential priorities to the nodes in the network and this is how it works let us go through one example ; assume a token ring has five stations attached to a priority ring station a has priority access of 1 1 is  let us assume  the lowest priority ; stations b and d have priority of 2 ; and stations c and e have priorities of 3 so c and e have the highest priorities once again  assume that a had already seized the ring and is transmitting data frames the token has a bit set to indicate that the token is busy and that means because a has already put a frame in it  it is being sent from a  refer slide time  08  42 ? 09  36  station b receives the frame it has data to transmit let us say that all of them also transmit some data to station b  which receives the frame it has data to transmit but it can not transmit at the moment because the ring is busy but it places its priority of 2 in a reservation field within the token ; it puts 2 over there in that reservation field  and sends the token and the frame sent by a along to c it then passes the token to c station c also determines the ring is busy ; it has data to send  so it places 3 in the reservation field  thus displacing the 2  which was inserted by b ; 2 gets replaced by 3 in the reservation field  other thing remains as it is it is still a ? s frame  which is moving along  refer slide time  09  36   station c then passes the frame to d d must defer because  if you remember  we had the priority of 1 to a  2 to b and d  and 3 to c and e so it came from a to b  b put a reservation and its priority of 2  then c over wrote this with its priority of 3 now d sees that there is a priority 3 that is waiting and d has only has its priority of 2 ; so it has to defer it can not do anything so d must defer ; it can not place its priority of 2 into the field because the priority of 3 is already there consequently  it passes the frame to e  which examines the reservation field upon seeing the 3 in the field it does nothing because since its priority is also 3  e is also a priority of 3  so e can not do anything so e simply sends it along  refer slide time  10  39 ? 11  11  station a receives the frame back ; it makes the ring free by resetting the token and passing the token to b b is not allowed to use the token because the reservation field inside the token is equal to 3  one higher that the priority of b although b wants to transmit and the ring is free  b can not start really transmitting because somebody with a priority 3 is waiting  refer slide time  11  11 ? 12  07  c is allowed to seize the token because the priority field in the token says 3 and c has the priority of 3  which means that c is the first node with that level of priority  which has got the token so this sort of seizes the token ; it places the data on the ring and sends the transmission to d now d is allowed to place its priority of 2 although c is sending  c has already put its frame and d sees that naturally the reservation field is reset now d can place its priority of 2 into the reservation field it does so and passes the frame to e e also wants to send ; so e replaces d ? s priority of 2 with its priority of 3  and passes the frame to a  refer slide time  12  07 ? 12  25  a also wants to send again  but a must defer any reservation placement since its priority is 1 b must also forego any priority allocation since its priority is 2 c receives its transmission back ; it is required to make the ring free it does so and transmits the token to d  refer slide time  12  25 ? 12  42  d is not allowed to seize the ring  since its priority of 2 is less than the reserved priority  which has been put there by c this is the priority indicator of 3 ; so it passes the token to e e seizes the ring because its priority of 3 is equal to or greater than the reservation of 3 this is the way the priority ring works ? if you see  whoever put the reservation earlier at the same level  it come backs to him so he puts the frame out there  but if the higher priority nodes have finished reservation  transmission  etc  then the lower parity nodes can start transmitting and so on so you can set these priority levels in the token this is how not only you can have a pure simple round robin  where everybody has the same priority  but you can have priority based token ring also  refer slide time  13  28 ? 13  49  there is a variation of this dedicated token ring  which is called dedicated token ring there is a central hub ; there is a more centralized system  which acts like a switch and it ? s more like a full duplex  a point-to-point link and the concentrator acts as frame level repeater  and there is no token passing  refer slide time  13  49 ? 15  09  next we will take up another system called fddi this is still in use in some places where some specific applications are there  but then again fddi is also sort of going out because other new technology is taking its place fddi was originally conceived as a high-speed network and this network could be used in a lan  wan or backbone as high-speed data when it was conceived  at that time  100 mbps was considered very high speed ; of course technology has changed  but still it is instructive to look at these technologies first of all  we ? ll see how different mac schemes can work  and new mac schemes for new technology  etc are also coming up all the time we will  just as an instructive thing  will look into fddi in some detail  refer slide time  15  11 ? 16  04  so fddi was conceived as a high-speed backbone technology it has a dual ring topology as just like the sonet rings ; we talked about dual ring topologies in the optical networks by the way  this is based on fibers this is fiber distributed data interface that forms the acronym fddi it uses dual ring topology  using fiber optic cable used to transmit light pulses optical fiber channel operates at a rate of 100 mbps well  we can say 100 mbps only today  but at one point of time  it was the standard in 1980s  which was proposed to be very high speed it is frequently used in lans to connect buildings together  refer slide time  16  04 ? 16  27  so ring circumference can extend to 200 kms ; the distance between nodes can be up to 200 kms fddi network can host up to 1000 nodes on one optical fiber that is how it was conceived this optical fiber is not just continuous optical fiber this optical fiber goes from hub to hub  that is  from node to node  refer slide time  16  29 ? 17  54  this is an fddi topology ; we have two rings a is known as the primary ring  which is shown in black the primary ring is the one  which usually carries all the data  and then  there is a secondary ring  which is used for fault tolerance purpose as matter of fact  this is one reason fddi is still used in some places where the reliability of the network is of very high concern we can not allow it to remain down for any length of time fddi can quickly switch from the primary to the secondary ring this is a production kind of system as you can see  because there is one ring fully dedicated as a secondary ring  which is there in case of a fault either of a link or particular node  we can quickly have another ring in its place  refer slide time  17  54 ? 20  14  the fddi standard specification came up in the 1980s this has various parts  one is the media access control  mac part  which deals with how the medium is accessed  the frame format  token handling  addressing  and error recovery fddi has a somewhat more complex mac protocol because fddi allows both synchronous as well as asynchronous traffic if some traffic is synchronous  that means  if it is carrying some kind of voice or something  then you know that is 125 microsecond length ; it is very sacred and sacrosanct over there every 125 microseconds  some channel may have to send something  as well as we can have packets or data flowing in the network  may be with some kind of lower priority so this can handle a mixture of both synchronous and asynchronous traffic that is a peculiarity of fddi system  which makes its mac somewhat more complex than a plain vanilla token ring so we will see details of this mac later on the physical layer protocol defines the data encoding and decoding  how data is encoded and decoded we will see later the clocking requirements and framing under the physical layer  we will see medium characteristics of transmission medium  fiber optic link  power levels  bit error rates  optical components  connectors  etc that is also a part of the standard for the physical layer medium there is a standard for the station management  which defines station and ring configurations  initialization  scheduling  collection of statistics  fault isolation  and recovery from faults as i said  the recovery from faults was and still is a very strong point of fddi ? one reason fddi may be preferred for some applications  refer slide time  20  14 ? 20  36  so  as mentioned earlier  the topology of fddi network consists of two independent rings ? primary ring a is used for data transmission  while secondary ring b provides an alternative data path ; this has already been shown and secondary ring remains idle  unless primary ring fails  refer slide time  20  36 ? 22  37  optical fiber rings are counter rotating ; that means one is moving in one direction while the other is moving in the other direction two signal paths are provided  one in each direction why do you make the rings counter rotating ? well  we had seen this in our recovery lecture also ; the reason is that if there is a node failure what you can do is that suppose you are a station and there are two counter rotating rings passing through you that means in one  the signal will pass in this direction and in the other the signal will pass in this direction in optical fiber  this is quite fixed because you want to have proper transmitter on one side and the receiver on the other side so one ring is moving like this  the other ring is moving like this now what might happen is that suppose the next station has failed and this station understands that there is something wrong either with the link or with the next station so what it might do is that it might make a quick connection over here so that the ring coming in this direction may take this other path and still we can make one ring this ring will not have any fault tolerance ; there will be one ring by using part of the two rings a and b so we can get a recovery through that ; that is why we have two counter rotating rings with two signal paths provided  one in each direction a station is a computer  workstation  or node connected to fddi network there are some network nodes also ; we will talk about this or a station must be connected to both in order to use secondary ring as an alternate data path if it is connected to only one of them  it can not use the alternate path  refer slide time  22  37 ? 23  05  media is  as i said  1300 nanometer optical fibers  transmission method is base band ; that means  there is no modulation only the pulses in the raw form travel down the ring ; data rate is 100 mbps and topology is a physical ring of trees and a logical ring why is it a ring of trees where do the trees come from ? we will talk about that  refer slide time  23  05 ? 23  41  now let us talk about the type of network stations  which may be connected to an fddi ring one is a dual attached station  which is connected to both the rings that means  it is a station  which is connected to both the rings that is why it is called dual attached we have dual attached concentrator  dac  which is connected to both rings and provides connection for additional stations and concentrators it is actually the root of a tree this is where the tree comes from  refer slide time  23  41 ? 25  33  we have this picture of an fddi concentrator  so you can see that this is the main part of concentrator the two rings are there ; they are counter rotating ? this is the primary ring and this is the secondary ring so the primary ring is coming like this from a to b and secondary ring is going like this it has some additional ports from which other stations may hang and  actually  what might happen is that we may have a tree hanging from a concentrator we have a tree of nodes here ; so that is why this main fddi ring may be a ring of trees the way fddi is actually deployed is also interesting in the sense that you may have a large ring ; that is possible what is done is that we make a very small ring in the core of the system  like wherever your main server is we make a very small ring just within a room and what happens is that we have concentrators connected to this ring and from this concentrators  a tree spans out to all the other  may be near by buildings or whatever  so that all of them are connected to this fddi backbone  but the backbone has got two rings this backbone is fault tolerant so that is a good thing about fddi ; that is one way fddi may be deployed so we have a very small ring and tree is spanning out and going out of the building  may be to other building  and so on or alternatively  you can have a large ring also  refer slide time  25  33 ? 25  42  so we have this dual attached stations and dual attached concentrators ; concentrators could be the roots of trees  refer slide time  25  42 ? 26  15  dual attached stations and dual attached concentrators are more costly we have a cheaper variety you think that it is good enough which is a single attached station which is attached only to the primary ring we have single attached concentrators which is connected to only the primary ring through a tree  a double attached station or concentrator can reconfigure the dual ring as mentioned earlier into a single ring in the event of a failure  refer slide time  26  15 ? 27  03  what are the physical interfaces like ? as opposed to a basic token ring network  in which at any instant there is a single active ring monitor  which supplies the master clock for the ring  in fddi  this approach is not suitable because of the high data rates that is one thing ; and the other thing is that the ring could be very large so if the ring is quite large then having the central clock becomes difficult each interface has its own local clock and the outgoing data are transmitted using this clock  refer slide time  27  03 ? 27  43  all data to be transmitted are encoded  as i mentioned earlier  prior to transmission using a 4 of 5 group code  which means there are nearly 32 possibilities so  for 4 bits of data  we actually have 5 bits  which are going over there the additional capacity is used in some other way for control purpose ; that we will see later this means  for each 4 bits of data  a corresponding 5 bit code word or symbol is generated by the encoder some of these symbols or combinations are used for link control functions  refer slide time  27  43 ? 29  13  now let us go through the ring operation ? there are two aspects to it one aspect is similar to the token ring  which we have already discussed the sending station waits for a token ; sending station captures and strips token and then transmits frames ; sending station issues token at the end of transmission now this is one point where the fddi is different from a token ring in a token ring  if you remember  only when the transmitted frame with that busy ring etc  comes all the way back to the sender  the sender makes this token free and puts it back on the ring since fddi was perceived as a high-speed ring  what was proposed was that as soon as its transmission of its frame is over  it can put a new token on the ring multiple frames may be circulating in the ring at the same time bringing up the speed so sending station issues token at the end of transmission  destination station copies the transmitted frame and sets the a and c  which is the address recognized by the frame copied indicators that means it has already copied the frame like what we have in a token ring  refer slide time  29  13 ? 29  46  the sending station removes the data from the ring by stripping the sent and acknowledged frame  etc so it takes out the frame ; the first few bytes of the frame are not stripped ? this is for some technical reason  we need not go into the details here ? and continue to circulate on the ring as a fragment each repeating station strips 1 byte from the fragment and the transmitting station completely strips it so there are some fragments also apart from the frames ; some fragments are also moving around in the ring  refer slide time  29  46 ? 30  52  now we come to token passing scheme it uses token passing protocol to move data around ; the ring uses another protocol based on timers we will look at this protocol later on timing is very critical to token passing scheme  as it is designed for delay sensitive synchronous data as i mentioned earlier  the fddi ring carries a mixture of data it may carry lower priority packet data kind of thing  which we have been talking about  in the token ring it may also carry synchronous data  which is time sensitive and which has somewhat higher priority than this other one this is based on some timing protocol we will go into timing protocol now fddi allows for high data rates  where each ring interface has its own clock all outgoing data are transmitted using this clock  refer slide time  30  52 ? 31  15  a node will get packets within a specified amount of time we are discussing the timing part of it a node will get packets within a specified amount of time as a packet circles the ring with a token behind  each station retimes and regenerates the packets  refer slide time  31  15 ? 31  35  so this increases probability frame fragments  which will be propagated on the ring ? how fragments are eliminated early token release is required because of the high speed and extensive distance provided by fddi  refer slide time  31  35 ? 32  00  fddi rotation time  fddi uses time to ensure equal access to the ring ; measures rotation time by calculating distance of segments  processing time  and number of stations this is the time you expect a packet to move around the entire ring rotation time refers to how it takes a signal to propagate around the ring  refer slide time  32  00 ? 33  36  so rotation time is used to control the priority operation of fddi ring we have several timings  one is measured by the clock that times the period between the receipt of tokens called the token rotation time  that means  how long is it that the token takes to come around the ring the operation of mac layer is governed by a mac receiver and is calculated by target token rotation timer that means there is a target rotation time  which is prefixed and there is a trt  which is measured usually you would expect under the normal conditions  when the load is moderate  the token rotation time would be less than the ttrt when the node is moderately noted by comparing trt with ttrt  we can find out how loaded the system is if you have a synchronous link going through the synchronous traffic that is going through this fddi ring  the synchronous traffic will have to be given the first priority and the asynchronous traffic of some lower priority data traffic  will be put on the ring or will not be put on the ring  depending on how loaded it is and this is how it is calculated  refer slide time  33  36 ? 33  56  there is a pre-negotiated target time called ptt ptt is coordinated for the arrival of a transmission each node measures time it takes for the token to return to it ; that is the trt it compares time to a pre-negotiated target time ptt for its arrival  refer slide time  34  01 ? 34  36  a node is allowed to transmit as long as its full transmission stream does not exceed the ptt so there is a pre-negotiated target time  which is allowed  and the node is allowed to transmit as long as its full transmission stream does not exceed the ptt if the token comes back sooner than ptt threshold  it is deemed as a light network load if the token comes back later than ptt  it indicates the heavy traffic load low priority traffic must then be deferred until load on the network becomes lighter  refer slide time  34  36 ? 35  26  there is a token holding time  tht if you look at the last point tht is actually equal to ttrt minus trt it is used to calculate maximum length of time a station can hold the token to initiate asynchronous transmissions the point is that there is a target time and there is an actual measured time  by which the token has come back if the actual measured time is low  that means the network is lightly loaded  you can put some asynchronous traffic that is why tht is calculated it calculates the difference between the arrival of the token and the ttrt it keeps track of the amount of time a host can transmit this is the formula  and then you have the following rules  refer slide time  35  26 ? 36  21  if tht is less than zero that means traffic is heavy  the total rotation time is actually more than the expected time  which was expected earlier this means that all asynchronous traffic has to wait the synchronous traffic will go through so if the tht is less than zero  it is a heavily loaded station stations can only transmit synchronous traffic if tht is greater than zero stations can transmit both synchronous and asynchronous traffic during tht so it first sends the synchronous traffic and then sends the asynchronous traffic till tht falls to zero if tht is equal to zero  the host can not start any new packet tht increases and number of stations decreases  refer slide time  36  21 ? 39  59  the fddi frame format  fddi is a technology  which is not moving forward very much these days as the matter of fact  it may be slowly on its way out because we have other ways of achieving the main point of fddi  which is its fault tolerance the speed of fddi has become 100 mbps  which is rather not very fast as far as the backbone is concerned ; it is taken as a very low speed these days so fddi may be on its way out it is also expensive and the support to it is also dwindling the reason we are looking at how different issues are handled by a typical mac protocol is that this business about framing is common to all kinds of data link protocol so later on  when we talk about ethernet  which is the most common kind of network in the world today  we will see that it has some frame format and if you remember our first day ? s discussion  when we were talking about these different layers  we said that they are at the same level ? that means a network layer to network layer ; network layer in this node to network layer in this node ; similarly the transmission layer in this node to transmission layer in that node  etc ? and have some protocol running how do these protocols run ? these protocols run by adding some header and in some cases a trailer also to the main payload so whatever it gets from the upper layer is the payload to it for running its own protocol it adds some header ; that means  adds some information to the beginning of the frame and adds some information to the end of the frame to make a complete frame the corresponding layer in the other node strips this particular information  does whatever it has to do  because it is also running the same protocol so it knows what to do and then may be either it goes up or it goes down again to the next station and so on this is an example frame format of fddi fddi frame format has some preamble we will not going to the details of this because this is not very important any more  but we will just mention that such fields are common in many frames we have a start delimiter ; we have a frame control ; and we have a destination address this has to be there because otherwise the destination will not know that this particular packet is meant for him we have a source address field  so we have a da and then an sa field ; we have the data  frame check sequence for some error control by the way  error is not handled by fddi ; error allows other layers to handle the error if there is an error but we have to check the error ; so there is frame check sequence  end delimiter  and frame status  refer slide time  39  59 ? 40  30  fddi encodes all data prior to transmission  uses a 4 or 5 group code method  which was mentioned earlier the encoder generates a corresponding 5 bit word or symbol for every 4 bits transmitted  fddi creates a 5 bit code bits provide clocking for the signal itself the status of bit reflects a change of state of the light on the other side  refer slide time  40  30 ? 41  57  symbols are light ; taken with another symbol they form one byte so there are 16 data symbols issued with 5 bits you can have 32 different symbols ; out of it  16 data symbols are reserved for data this is for 0 to f so if you write your scheme of bytes in hex  that means in groups of 4 bits each  each of these 4 bits has got its corresponding code in the fddi symbol and then  we have 16 other symbols  which are left ; so 8 are used as control symbols and 8 as violation symbols the control symbols are called q  h  i  j  k  etc coding the symbols prevents the occurrence of 4 consecutive 0s in a row this is necessary to ensure each station ? s clock is in sync with other stations for the transition that takes place when you go from a 0 to 1  that transition ? s edge is used for synchronizing the clock this is the very common method of synchronization ; that is why we have the codes in such a manner  so that we do not have a long string of 0s because then the synchronization might drift  refer slide time  41  57 ? 42  16  token has the following fields  we have a preamble ; we have a start delimiter ; we have a frame control ; and we have an ending delimiter as i said  one of the main points of fddi is the  refer slide time  42  26 ? 44  14  fault tolerance that it provides there is a ring wrap i mentioned this earlier that in a dual attached concentrator  if it senses that on the other side the node has failed  it can make a connection between the primary and the secondary ring within itself  so that the ring  while coming like this  starts traveling like this and completes its round that is because if you have the node on the other side  the corresponding concentrator will also make a connection between the primary and the secondary ring the failed node is essentially isolated on both the sides there are connections within the concentrator  and instead of a single ring  you have two rings now the primary and secondary ring are fused together and then  suppose this was the primary ring coming  then it goes back to the secondary ring and then to the other concentrator on the other side and the connection is completed you have one ring ; that is why the physical diameter of an fddi ring is kept within 100 miles if there is a failure  the total ring diameter does not exceed 200 miles  which is the standard ring wrap technique is the technique that we mentioned earlier when we talked about protection and restoration ; the technique is used to manage failures when a station fails or a cable is damaged  dual ring is automatically wrapped two adjacent ports connecting to a broken link will be removed from the ring and both stations enter wrap state  refer slide time  44  14 ? 44  33  fddi concentrator switches to a wrap state and the ring is doubled back onto itself data continue to be transmitted on fddi single ring performance is not negatively impacted during wrap state so this is the good thing about fddi when you have very mission-critical situations  fddi is kept as a strength for very critical situations like  may be  stock exchange or may be some thing else  where even few seconds of network down time is not acceptable to anybody so there you could deploy this kind of technology with its inherent fault tolerance so this is the another picture of fddi ring wrap  refer slide time  45  13  45  33  as shown over here  you have one station 4  which has gone down so that 2 adjacent stations  namely  2 and 3 wrap around and we have a single ring now going around so this is clear  refer slide time  45  33 ? 47  40  we have discussed earlier how this is done we have optical bypass switches used for two or more failures to occur by the way  what would happen if more failures occur ? suppose there was a one single failure  one single node failure  and the two rings primary and secondary and the two adjacent concentrators were wrapped back and we had a single ring like this  what would happen if another node fails in-between ? what would happen is its adjacent concentrators once again wrap around but now  instead of only one single ring  which we had earlier in the case of a single failure  now with this double failure we may have two rings these two rings are not connected to each other so these two rings individually would still keep working there is a part of the protocol  which i have not covered it is that if there is a single token  which was on the other side  and now the token is lost ; there is no token there is a protocol for reclaiming and regenerating a token now what would happen is that  two individual rings will come into operation on the two sides  but they will not be able to do so the nodes  which are connecting to this sub-ring and the nodes  which are connected to the other sub-ring  will not be able to communicate with each other across  but within themselves  they will very well communicate as usual so rings are segmented back into two independent rings incapable of communicating with each other additional failures can cause further ring segmentation optical bypass switches can eliminate failed stations to prevent ring segmentation we have all seen how this is done ? actually this is all done with mirrors  refer slide time  47  45   so optical bypass switch has optional optical mirrors that pass light from ring directly to das station during normal operation das station experiences a power loss ; optical bypass switch will pass the light through itself it uses internal mirrors to maintain ring integrity  refer slide time  48  04 ? 48  54  the other technique of this protection  etc  which we had seen earlier is dual homing this dual homing is also used in an fddi context ; a router or a das ? das you remember is a dual attached station ? is connected to two concentrator ports on fddi concentrator one port provides a connection to active fiber link  while the other port is in hot standby mode actually there are two nodes  a and b ; usually the a node is in hot standby mode and b node is operating so the port is in hot standby or passive mode ; hot standby is constantly tested and will take over if the primary link fails  refer slide time  48  54 ? 49  08  a typical das configuration has a b port ; it is designated as active port ; and a port is configured as the hot standby when the primary link fails  passive link automatically activates and hot standby becomes operational so this is the same dual homing principle  which we had seen earlier when we were talking about recovery and protection with this  we come to an end of the discussion about token bus and token ring and fddi we have discussed the number of these token-based protocols  namely  token bus  dqdb  token ring  and fddi the fddi was quite good only thing was that fddi was also quite costly these technologies are actually going out in some sense if you remember  when we were talking about dqdb  we said it can handle 53 byte cells ; that came down to atm and atm is that sort of the technology that is still quite alive today we will have an extensive discussion about atm regarding the wan technology  two other technologies  which are once again on their way out  are x 25 and frame relay well  frame relay is still there in many parts ; x 25 is sort of going on but still we will just have a quick look at these then we have to consider these mac levels this is how the next set of lectures will go what will happen is that once we finish this  then we will talk about the data link layer and specifically about the mac sub-layer of the data link layer then we will have to talk about the llc  that is  the logical link control so we will discuss that and the other important functionality of this data link layer  which is the error and flow controls because whenever you have a transmission  somehow you have to assume that errors may occur depending on the medium and the technology  errors may be more or less frequent ; for example  in a fiber  the error may be very low  error probability may be very low when you are using wireless  the error probability is high but  anyway  you have to consider the possibility of some error and how errors are handled that means  we are talking about bit errors  which may come in due to noise and other things into the data in a particular link that is one thing and if there is a flow control to be done  that means  if there is a congestion or not because you are sending from one side whether the other side is receiving it or not  that you have to some how make out we will take up these things next thank you preview computer networks prof sujoy ghosh dept of computer science & engineering iit kharagpur lecture  15 data link protocols  refer slide time  52  17 ? 52  18   refer slide time  52  18 ? 52  20  good day so today we will start our discussion on data link layer as a matter of fact we have discussed a part of data link layer namely the mac sub layer  refer slide time  52  30 ? 53  16  we will see how that all fix in but to fit it into the broader picture if you remember when we were discussing the seven layer osi protocol starting from the application layer the bottom most layer was the physical layer so we have finished our discussion on physical layer and just above the physical layer we have the data link layer so we will look at the different components of data link layer and how they will be used different protocols etc so that is what we will do so our this main thing is data link protocols which are the protocols which are used in the data link layer  refer slide time  53  16 ? 54  03  now what are the main tasks of data link layer it transfers data from the network layer of one machine to the network layer of another machine so actually this is the part of the service it gives to the upper layer do you remember that above the data link layer we have the network layer so below the network layer we have the data link layer so the data link layer gives some service to the network layer and this service is the transfer of data from one network layer to another network layer so that is the service it gives it to the network layer and this in its turn uses the physical layer so it converts raw bit streams of the physical layer into groups of bits etc or frames  refer slide time  54  03 ? 55  07  so this is how we can look at it so this is one node and this is another node above this there may be other layers we are not concerned about this upper layers at the moment so this gets some data to be sent from the network layer and this data link layer sends it to the next data link layer remember once again that the network layer is concerned with transfer of data etc across the network that means it may take several such hubs but data link layer is just concerned with the single hub so this is how we simply the problem the problem of going multi hub so this multi hub part we leave it to the network layer for this single hub so multi hub will naturally constitute the number of such single hubs and data link layer would handle the transfer of data from one from one node to the next  refer slide time  55  08 ? 56  34  so what are the kinds of services types of services that the data link layer gives one is unacknowledged connectionless so no attempt to recover lost frame if some frame is lost due to noise error etc etc there is no attempt to recover this and because there is no acknowledgement from the other side it is a connectionless system suited for low error rate network or for fault tolerant applications such as voice what you mean that voice is a fault tolerant application we mean that even if some of the bits in a voice stream digitized voice stream that is even if some of bits drop obviously there will be some degradation on the other side if your are do not doing any kind of correction etc but to the human ear it may not be very perceptible for example i am talking even if there is a momentary glitch you will more or less make out what i am talking about so that is why in that sense it is more inherently fault tolerant so that is un acknowledgement unacknowledged connectionless service that is one kind of service acknowledged connectionless service this is another kind of service so each frame is acknowledged by the receiver so this is suited for unreliable channel so require this acknowledgement for the special reliability  refer slide time  56  36 ? 56  49  acknowledged connection oriented service ensures that all frames are received and each is received exactly once and these services are accomplished using as i said simplex not usual but half duplex or full duplex channels  refer slide time  56  49 ? 57  33  so this is some examples not very important sorry so is a reliable message stream it may be connection oriented service or it may connection less service and it may be a reliable message stream or reliable byte stream so reliable message stream sequence of page reliable byte stream they say remote login so they are coming byte by byte here it is coming page by page unreliable connection like digital voice unreliable datagram so these are but when you come to datagram this becomes connectionless service unreliable datagram acknowledged datagram request reply etc  refer slide time  57  32 ? 57  40  now let us look at just one thing that where does this all these data link layer exact exactly where does it exist physical medium we understand it is a cable or it is this electromagnetic field this free space etc or fiber so we can see it we can fell it but where does the data link layer resides so to say  refer slide time  58  00 ? 58  25  now frames could be fixed length like atm so atm cells are of fixed length so you know once you have synchronized you know that they are going to come with fifty three byte kind of regularity but frames could be variable length also in which case we use this byte count byte stuffing bit stuffing generic framing procedure manchester encoding etc computer networks prof sujoy ghosh dept of computer science and engineering i .i .t kharagpur lecturer name # 15 data link protocols  start time  00  45   slide time  00  53  00  54  good day today we will start our discussion on data link layer as a matter of fact  we have already discussed a part of the data link layer  namely  the mac sublink layer we will see how it all fits in to fit it into the broader picture  if you remember when we discussing the 7-layer osi protocol  starting from the application layer the bottom most layer was the physical layer just above the physical layer we have the data link layer we will see the different components of data link layer and how they are used  we will discuss different protocols  etc  slide time  01  33  01  38  these are protocols which are used in the data link layer  slide time  01  39  02  27  the main task of the data link layer is that it transfers data from the network layer of one machine to the network layer of another machine this is a part of the services it gives to the upper layer if you remember  above the data link layer  we have the network layer the data link layer gives a service to the network layer  and this service is the transfer of data from one network layer to the other  and this in turn uses the physical layer it converts the raw bit stream of the physical layer into groups of bits or frames  slide time  02  28  03  33  this is how we can look at it  this is one node and this is another node above this is there could be other layers ; we are not concerned with these at the moment this gets some data to be sent from the network layer and the data link layer sends it to the next data link layer remember that the network layer is concerned with transfer of data  etc  across the network that means it may take several such hops ; but data link layer is concerned with just a single hop this is how we simplify the problem of multi hop ; this we will leave to the network layer for the single hop so  multi-hop will constitute several such hops and data link layer will handle transfer of data from one hop to the next hop this is another way of looking at it  slide time  03  34  03  51  there is a virtual data path from layer three to layer three  but actually this goes through the data link layer and this is the actual data path  which goes through the physical layer and some physical transmission medium  slide time  03  52  06  06  now  why do we require any controls in the main data link ? these are the main functions of the data link layer actually  all the combinations are not used in all the situations  but these are the general categorizations of data link the frame synchronization  the beginning and end of a data block  that means  a frame  should be recognizable that means when you are sending number of bytes from one machine to other  they are formed into blocks at that time  the other machine should be able to recognize the beginning and end of the block so you have to organize these bytes into frames that is the first job of the data link layer second job of data link layer that it might or might not do is flow control the sender should not send frames at a rate faster than the receiver can receive and process them  because the sender may not know everything about the state of the receiver at that particular point of time if it goes on sending data  the receiver may be forced to drop some of the data in some cases  this is ignored but in some cases  it is relevant and the data link layer may do some floor control the third thing is error control  where any bit errors introduced by the transmission system should be corrected whenever you are sending something through a transmission medium there is always a chance of some error  and the data link layer has to take care of this error  slide time  06  24  08  00  addressing  on a multipoint link like lan the identity of sender and receiver must be specified in such a case  the identity of the receiver would be very important because in many such links  especially in broadcast links  what happens is that the data reaches everybody the receiving station must know whether or not one of these frames is meant for him the addressing of receiver is important for that reason for all the above points  we require some data link layer protocol to run between the two layers in order for this protocol to run  these two nodes need to have some kind of control or management information the control and management information will be transmitted on the same medium control and data flow on the same link the receiver must be able to distinguish control information from the data being transmitted we also require link management ? the procedures for the management of the initiation  maintenance and termination of a sustained data exchange  slide time  08  08  09  22  these are the different functions of the data link layer the link layer services are framing and link access it encapsulates datagram into frame  adding header or trailer what the header or trailer contains depends on the protocol that you are using on that link ; some do not have a trailer  some do not have header ; some have both header and trailer this is the part that is used for the protocol to run channel access is also there if it is a shared medium mac protocol is a part of it ; if it is a shared medium  the medium access control has to be used mac addresses are used in frame headers to identify source and destination ; it is different from another address we have over the entire network  called the ip address right now  we will be concentrating on mac addresses  slide time  09  23  10  58  link layer services offer reliable delivery between adjacent nodes if the medium is prone to noise or introduction to errors  the data link layer has to address the problem apart from this link  you may require resilience at a higher link because a particular node of the network link might fail so  whatever protocol you might have for the data link might not work  so the chain may break down this is for making individual links of the chain as good as possible this is one of its jobs ? reliable data delivery just as fiber may have low error bit  similarly  some links like wireless links have high error rates we have just discussed why it gives both link-level and end-end reliability  slide time  10  59  11  34  the flow control is pacing between the adjacent sending and receiving nodes they should always be in sync  whatever the sending station sends  the receiving station should be able to absorb that much for that  you may require some explicit controls sometimes we will look at floor control later on  in a later lecture the other service is error detection  which includes errors caused by signal attenuation and noise receiver detects presence of errors ; that is the error detection part once you detect that there has been some error  you may ask for some retransmission from the other side so that you may get the correct data  or you might be able to look at that faulty data and correct it locally the receiver identifies and corrects bit errors without resorting to retransmission all these would happen on the line  and the line could be simplex  half-duplex or full-duplex simplex is not very common  because simplex can go only in one direction  slide time  12  16 -12  46  in half-duplex nodes at both ends of link can transmit  but not at the same time  slide time  12  47  14  16  dll offers unacknowledged connectionless and acknowledged connectionless services in unacknowledged connectionless  there is no attempt to recover lost frame and there is no acknowledgement from the other side it is suited for low error rate networks or for fault tolerant applications such as voice by voice tolerant application  we mean that even if some of the bits in a digitized voice stream drop  there will be some degradation on the other side but to the human ear  it is imperceptible that is why it is fault-tolerant in acknowledged connectionless service  each frame is acknowledged by the receiver and it is suited for unreliable channels  where acknowledgement is required for special reliability  slide time  14  17  14  31  acknowledged connection-oriented service ensures that all frames are received and each is received exactly once and these services are accomplished using simplex not the usual  but half-duplex or full-duplex channels  slide time  14  32  14  36  these are some examples it is a reliable message stream it may be connection-oriented service or connectionless service it may be a reliable message stream  sequence of pages  or reliable byte stream  reliable login   in the latter it is coming byte by byte and in the former  it is page by page an example of unreliable connection is digitized voice ; unreliable datagram  electronic junk mail  is connectionless service  slide time  14  37  14  38  the data layer link exists in the network interface card if you have a pc that is connected to a network  it is probably connected through an ethernet card  or network interface card  nic  or something like that the card has a socket where the ethernet cable will be plugged in so  there is a network adaptor the adaptors implement most of these data link functions  so it is the adaptors that are communicating the datagram from a higher layer is made into a frame by the adaptor and it is then sent  following the link layer protocol  to the other node the adaptors communicating have two nodes  one sending node and one receiving node  slide time  14  39 -15  14   wrong slide ?  the link layer in adaptor is also called nic  examples of which are the ethernet card  pcmci card or the 802.11 card on the sending side  the adaptor encapsulates the datagram in a frame it adds error-checking bits  rdt  flow control  etc on the receiving side  it looks for errors  rdt  flow control  etc  extracts datagram and passes to the receiving node the adaptor is semi-autonomous and communicates directly with link and physical layers the adaptor has some hardware and some in-built software  slide time  15  15  16  48   wrong slide ?   slide time  16  49 -17  19   slide time  17  20 -17  45   slide time  17  59  18  42  the data link layer is divided into two parts one is the mac and the other is the llc so in any broadcast network  the stations must ensure that only one station transmits at a time on the shared communication channel that is the mac part of it the protocol that determines who can transmit on a broadcast channel is called medium access control  mac  protocol we have seen a number of mac protocols already  slide time  18  43  19  26  the data link layer is divided into two sublayers above the data link layer  you see two network layers and below it is the physical layer the data link layer itself is divided into two parts  the medium access control part  which is closer to the physical layer  and the logical link control the mac protocols are implemented in the mac sublayer  which is the lower sublayer of the data link layer the higher portion of the data link layer is often called logical link control or llc  slide time  19  27  20  20  this is the broad picture  we have been referring to some numbers like 802.1  2  3  4 etc so ieee 802 is a family of standards for lans  which define an llc and several mac sublayers so 802 encompass all these this 802.2 is the llc part and below the 802.2 there are various kinds of medium access controls there are 802.3  4  5  6 and then 10  11  12 etc  and now we have 15  16  etc above the data link layer  there is a higher layer and below that  there is the physical layer  slide time  20  21  21  05  802.1 gives you an overview ; 802.2 is the llc we will be talking about today 802.3 is the famous ethernet ; csma/cd is the kind of mac protocol that it uses 802.4 is the token bus  which we have already seen 802.5 is the token ring 802.6 is the distributed queue dual bus fddi is the fiber distributed data interface and there are others as new protocols come up  they keep adding to this list  slide time  21  06  21  53  llc  whatever it does  it requires some headers so when the packet is coming from the network layer  the llc header is added to the packet so it will reach the llc sublayer on the other side then it comes to the mac sublayer and mac sublayer will add its header and it may add some trailer also the mac  llc  and original packet may constitute one frame and it is pushed on to the physical layer in the network  slide time  22  01  22  18  the 802 lans offer the best effort data frame services error control and flow control are handled by llc llc runs on all the three 802 lans and hides the differences to the network layer  slide time  23  04  23  17  the different physical layer protocols are transparent to the network all that the data link network knows is that this network layer will provide a reliable service for sending the data from this node to the next llc adds its header to the network layer packet it contains sequence and acknowledgment numbers resulting structure goes into the payload of 802.x frame for transmission  slide time  23  18  23  46  llc operations are sometimes divided in this fashion type 1 operation supports un acknowledgement connectionless service type 2 operation supports connection mode service type 3 operation supports acknowledged connectionless service  slide time  23  47 ? 24  31  the llc has protocol data units or pdu  which carries user information the control field includes a 7-bit sequence number n  s   associated with this pdu it also includes a piggybacking acknowledgment sequence number n  r   unnumbered various protocol control pdus these five bit m fields indicates a what kind of pdu it is  slide time  24  32  24  52  there are some supervisory pdus used for flow and error control it includes an acknowledgment and sequence number and a 2-bit s field to distinguish three different pdus  receive ready  rr   receive not ready  rnr  and reject  rej    slide time  24  53  25  19  the type 1 operation supports the unacknowledged connectionless service the ui pdu is used to transfer user data there is not acknowledgement  flow control or error control the xid and test pdus support management functions associated with all the three types of operation  slide time  25  20  25  32  an llc entity may issue a command xid or test the receiving llc entity issues a corresponding xid or test in response  slide time  26  00  26  08  type 2 operations involve three phases  connection establishment  data transfer and connection termination  slide time  26  09  26  45  with type 3 operation  each pdu transmitted is acknowledged a new unnumbered pdu  the acknowledged connectionless  ac  information pdu  is defined user data are sent in ac command pdus and must be acknowledged using an ac response pdu  slide time  26  46  27  45  to guard against lost pdus a 1-bit sequence number is used the sender alternates the use of 0 and 1 in this 1 bit the receiver responds with an ac pdu with opposite number of the corresponding command only one pdu in each direction may be outstanding at any time  slide time  27  46  29  16  frame synchronization  two sides must be able to synchronize their movements this synchronization is of two types suppose you are sending data 1 byte at a time  or you are sending blocks  each block containing a number of bytes synchronization of frames is necessary for this when data are transferred from the transmitted to the receiver unless steps are taken to provide synchronization the receiver may start interpreting the data erroneously suppose you have taken the second byte as the first byte  you will never be able to know that it is not the first byte there are two common approaches  asynchronous transmission and synchronous transmission  slide time  29  17  30  45  in asynchronous transmission  data are transmitted one character at a time timing of synchronization must only be maintained within each character the receiver has the opportunity to resynchronize at the beginning of each new character if you use encoding  you can use the transition time for synchronization between the sending and receiving nodes  slide time  30  11  30  41  so when no character is being transmitted the line between transmitter and receiver is in idle state ; so there must be some start and some stop there is a start after which we can introduce some parity bits ? we will see later how parity bits are introduced ? and this is the stop  slide time  30  42  31  46  in synchronous transmission  a block of bits is transmitted in a steady stream without start and stop codes actually asynchronous transmission is not as efficient the block may be arbitrarily long to prevent timing drift between the transmitter and receiver  clock signal is embedded in the data signal  e.g manchester encoding   slide time  31  47  32  35  apart from this synchronization of clock for the bit  you require another level of synchronization  so as to allow the receiver to determine the beginning and end of a block of data every block begins with a preamble bit pattern  and generally ends with a postamble bit pattern the kind of preamble and postamble that are used is directly related to the kind of protocol that is used  slide time  32  36  33  55  there are many kinds of framing available you can observe that only the body is coming from the higher layer ; the rest of it is being added in this layer for example  decnet ? s ddcmp frame has syns  header  body and many other bits are there the atm cell has only the header  crc and the body ibms have a bisync frame  header  body and bits the arpanet ? s imp-imp frame has syn  header and body bits the iso ? s hdlc frame looks like this  header pattern  body and crc  and again some specific pattern  slide time  33  56  34  15  a typical synchronous frame format would have an 8-bit flag  which would be the preamble  control fields  data field and some more control fields and an 8-bit flag  post amble    slide time  34  16  34  42  for sizeable blocks of data  synchronous transmission is far more efficient than asynchronous mode asynchronous transmission requires 20 % or more of overhead the control information preamble and postamble in synchronous transmission are typically less than 100 bits the overhead is low here that is why the efficiency of synchronous transmission is very high so when you are sending large amount of data  you go for synchronous transmission  because it is efficient  slide time  34  54  35  34  framing translates the physical layer ? s raw bit stream into discrete units called frames the sender sends the message  which is transmitted in the form of frames n frames are on transit and they are going from the sender to the receiver now how can the receiver detect frame boundaries ? that is  how can the receiver recognize the start and end of a frame ? this is done by four methods  length count  bit stuffing  character or bit stuffing and pulse encoding we will look at some of these now  slide time  35  35  36  04  frames could be of fixed length  like atm when it is atm  you know that it is of 53-byte kind of regularity they could be of variable length also  in which case we use the byte count  byte stuffing  bit stuffing  generic framing procedure and manchester encoding atm is a kind of fixed length frame variable lengths are byte count  decnet   byte stuffing  sdlc   bit stuffing  hdlc   generic framing procedure  and manchester encoding  802.5    slide time  36  05  36  53  now in framing  we make the first field in the frame ? s header as the length of the frame that way the receiver knows how big the current frame is and can determine when the next frame ends from the above slide  we can see that frame 1 contains 5 characters  frame 2 contains 5 characters  frame 3 contains 8 characters and frame 4 contains 8 characters  slide time  36  54  37  55  here the disadvantage is that the receiver loses synchronization  when bits become garbled if the bits in the count become corrupted during transmission  the receiver will think that the frame contains fewer  or more  bits than it actually does  slide time  37  56  38  17  checksum will detect the incorrect frames ; the receiver will have difficulty resynchronizing to the start of a new frame this technique is not used anymore  since better techniques are available  slide time  38  18  39  04  one of the better techniques is known as bit stuffing use reserved bit patterns to indicate the start and end of a frame for instance  use the 4-bit sequence of 0111 to delimit consecutive frames a frame consists of everything between two delimiters so you have this one delimiter on one side  0111  and then the frame and then the 011 so as soon as you get 011  you know that the frame is starting and as soon as you get another 011  you know that the frame has ended so this way we can know the beginning or the end of the frame  slide time  39  05  41  53  the problem with this is as follows  what happens if the reserved delimiter happens to appear in the frame itself ? if we do not remove it from the data  the receiver will think that the incoming frame is actually two smaller frames suppose we have the 0111 as the delimiter and the delimiter may contain data that came from the user in any bit pattern you have to allow any bit pattern to the user it could be that a picture is being sent in several bits and the bit pattern may be arbitrary in that case  0111 may appear in the body of the data ; this is where the bit stuffing part comes we introduce a new set of pattern  say  0111  for each existing pattern so now  the solution is to use bit stuffing within the frame  after every occurrence of two consecutive 1s  insert a 0 for example  append a 0 bit after each pair of 1s in the data this prevents three consecutive 1s from ever appearing in the frame  slide time  41  54  43  25  similar to bit stuffing we may have byte stuffing for example  let us say a flag say some character is there so  say the flag  which is also a part of the regular header  just happens to appear in the body of the frame or body of the packet so what we do is that  we use this other character these are character introductions  it is called byte stuffing one byte is one character so we introduce the character  escape character  just before the flag  and what happens if escape itself appears in the body ? well  we put escape so if there are two escapes side by side we know that we have to interpret it as only one escape if there are two escapes in the original data packet  just by chance  then actually this will be center 4 escapes and just one after the other  and at the receiving side  for every 2 escapes  it will reduce it to one escape and know that this is the just a part of the data only at the end  we will get flag  etc  bytes if there is escape flag  we have escape escape escape flag escape escape and so on so this is known as byte stuffing  slide time  43  26  43  57  point to point protocol  slide time  43  58  44  40  we will now discuss point-to-point protocol there will be a flag field  address field  control field  protocol field  and payload field this payload is the one which is actually coming from the higher layers that means from the network layer  some of it will actually come from the user  from the application layer itself this is the payload so far as the data link layer is concerned ; it ends with checksum and then flag this is what the general things look like and we will come to discussing how they are used  slide time  44  41  46  09  in a point to point data link control  there is one sender  one receiver and one link  which is easier than broadcast link it has no media access control  no need for explicit mac addressing e.g dial-up link and isdn line the popular point to point dlc protocols are ppp  which is point to point protocol  and hdlc  which is high level data link control  slide time  46  16  49  13  in ppp design requirements are given in rfc 1551 rfc stands for request for comment and forms a very important part of networking ppp uses packet framing ; its requirements are encapsulation of network layer datagram in data link frame this carries network layer data of any network layer protocol at the same time it should have the ability to demultiplex upwards ppp uses bit transparency also  which means  it must carry any bit pattern in the data field  slide time  49  14  49  52  we only require error detection  but no correction at the receiving end the connection liveness  it should be able to detect  signal link failure to network layer network layer address negotiation means endpoint can learn/configure each other ? s network address  slide time  49  53  50  48  the ppp non-requirements are no error correction/recovery  no flow control  out of order delivery is acceptable ; and no need to support multipoint links ; e.g  polling error recovery  flow control and data ordering are all relegated to higher layers  slide time  50  49  52  36  the ppp data frame has flag  address  and control and protocol bits the flag is the delimiter the address does nothing the control also does nothing ; in the future possible multiple control fields the upper layer protocol is where frame is delivered the check is for detecting errors  slide time  52  37  52  58  in the data frame some info that is upper layer data being carried is required and the check is the cyclic redundancy check for error so info is the upper layer data so this is the main body or the payload which is being carried the check is for error detection  slide time  52  59  53  50  it uses byte stuffing the data transparency requirement data field must be allowed to include flag pattern < 01111110 >  now we can have the question  is the received < 01111110 > data or flag ? sender adds extra byte after each < 01111110 > data byte at the receiver side two 01111110 bytes in a row  discard first byte  continue data reception and single 01111110 is flag byte  slide time  53  51  54  18  so after ppp  instead of sending it will send first this b1 then b2 etc  and then instead of sending one of them 0 1110  it sends two of them and then b4 and b5 this is byte stuffing  which is used by ppp  slide time  54  19  54  38  there are a few control issues like before exchanging network layer data  data link peers must continue ppp link and learn/configure network  slide time  54  39  55  12  the first thing is the link may be dead then the carrier is detected so it will try to establish the link for that  they will require some authentication  which means the two sides  configurations  etc must agree if it fails to establish  then it goes back to dead if it gets successful authentication  then the network is open and then there is some transmission of data and then finally it will terminate so for all these  there is a data exchange  slide time  55  13  55  31  configure request  configure acknowledgement and configure not acknowledgement -that means your configured thing is not acknowledged some of the options are not accepted and some of the options are not negotiable so this way  the two sides communicate and establish the link we need not go into the details this is not really necessary this is a very simple protocol just use byte stuffing and use some data  some error detection and the framing this is a very simple  but very widely used protocol in the next lecture  we will see how the error control and error detection can be done by the data link layer thank you  slide time  56  02  56  07   slide time  56  08  56  11  error control  slide time  56  35  56  46   slide time  56  47  57  03  when data is transmitted over a cable or a channel  there is always a chance that some of the bits will be changed or corrupted due to noise signal distortion or attenuation for example  suppose you have a wireless channel and suddenly there is a burst of noise what will happen is that  some of the data will get garbled similarly the data may become very attenuated it may be due to some loose contact somewhere or something the one that was sent was not received that way or may be it was received as a one zero or something so whenever you are sending some data or something  there is some communication going on some transmission over some transmission line you always have to assume that  a data may not reach the other side in a perfect condition so that is why crc is preferred in many data link protocols  slide time  57  47  56  48  crc is cyclic redundancy code  slide time  57  58  58  05  in cyclic redundancy code  essentially the data is regarded as being one very long binary number after all  what you are sending is a string of ones and zeros so you can take a few of them and just look at it as a binary number although the original intention of the user place holder digits are added onto the end and it is divided by a generator polynomial using modulo 2 divisions the remainder at the end of this division is the crc 