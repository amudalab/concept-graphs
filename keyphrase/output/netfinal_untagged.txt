computer networks prof sujay ghosh department of computer science and engineering iit kharagpur lecture name # 17 stop & wait protocol  refer slide time  00  40  good day so in the last lecture we were discussing about stop and wait protocol it is really a simple kind of protocol  which is used both for error control as well as for flow control in some cases this is the simple protocol we will look at its performance now  refer slide time  01  06  01  08  so we will first finish our discussion on this stop and wait protocol  refer slide time  01  12 -02  01  and this we have already seen so each sender station sends one packet which are ack if it is comes with some error it may send negative acknowledgement it may not arrive at all in that case the sender will time out ; in either case  that is  when it is getting a negative acknowledgement or whether it is getting a time out it will retransmit that frame transmitted earlier the point to note is that there is only one frame  which is in transit in the channel at any point of time  whether it is the frame or the acknowledgment or the negative acknowledgement so this is the stop and wait arq  which we have automatic repeat request we have already discussed this  refer slide time  02  03  02  39  and we have seen that the main advantage of stop and wait arq is its simplicity and the disadvantage is that it is a highly inefficient use of communication links so we will see what its efficiency is this protocol is sometimes also known as alternate bit protocol it ? s called alternate bit because one person sends with a bit 0 ; the other person makes it 1 and sends it back ; so this way 1 and 0 alternate so you know that when you have sent an acknowledgement  which acknowledgement it is  refer slide time  02  42  03  39  now let us look at link utilization in stop and wait ? how much we are utilizing the link with the use of multiple frames for a single message  the stop and wait protocol does not perform well ; only one frame at a time can be in transit so let us illustrate this with an example suppose the transmission time  that is  the time it takes for a station to transmit a frame ? this is an important parameter ? let us normalize it for the time being to a value of 1 by transmission time  we mean the time the sender takes from the time it starts sending the first bit of the frame up to the time it takes to transmit the last bit of the frame so this depends on the rate at which the sender is pushing the frame into the channel so we will take it is a normalized value of 1 ; that is one component of the time  refer slide time  03  40-04  58  and the other component is the propagation delay  the time it takes for a bit to travel from the sender to the receiver there will be always be a finite propagation delay  because  depending on how long the channel is  depending may be on the distance  or the speed at which the signal travels  etc  there will be a propagation delay ? the time it takes for the first or any bit to move from the source to the destination let us call this a now if a < 1 ? remember we have normalized our transmission time to 1 ? which means that the first bit of the frame has already reached the receiver when some of the latter bits are being sent by the sender so the frame is sufficiently long such that the first bits of the frame arrive at the destination before the source has completed transmission of the frame and if a > 1  that means the sender completes transmission of the entire frame before leading bits of the frame arrive at the receiver of course  the sender now has to wait for the acknowledgement to arrive  refer slide time  04  59-05  40  out of this time  only tframe is actually is spent transmitting data and the other time is idle therefore  the efficiency of the utilization is tframe /td  which is the total time td has two components  one is tframe  time to send the frame or transmission time  plus twice the propagation time why twice ? because the signal or the message or the frame has to reach the destination and the destination has to send an acknowledgement back so 1 tprop this way and 1 tprop that way ; that is why twice t prop so that is the efficiency  refer slide time  05  41-06  13  now if we define a = tprop/ tframe  which means that if a = 1  we have the propagation time equal to the time frame ; so it just fits anyway  u = 1 + 2a ; if you look at the previous formula  if we divide the numerator and denominator by tframe  we get one from here one here and t prop /t frame that is our a so u = 1 + 2a so this is the efficiency  refer slide time  06  19  07  02  so well let us just see an example with some numbers a channel has a bit rate of 4 kbps and a propagation delay of 20 ms.for what range of frame size does the stop and wait protocol give an efficiency of 50 % ? my channel has a bit rate of 4 kbps  that means  this is the rate at which we are pumping the data into the channel this is the maximum rate the channel can carry and it has got a propagation delay of 20 ms so i want to find the optimum frame size for getting 50 % efficiency  refer slide time  07  03-07  11  so r the rate is 4 kbps tprop is 20 ms we want to find l that is the length of the frame  refer slide time  07  12-07  45  so u = tframe/  tframe + 2 * tprop   so we want u the efficiency to be 0.5 so 0.5 = tframe/  tframe + 2 * tprop   so t frame = 2 * t prop = 2 ? 20 ms  which is 40 ms so t frame better be 40 ms then we will get a value of 0.5 on this side  refer slide time  07  46  08  45  so length of the frame = r  rate at which we are pumping in  ? tframe which is 4 ? 103 ? 40 ? 10-3 and this 40 is in ms so all this 10-3 cancels so we get 160 thus for frame sizes l = 160 bits the stop and wait protocol gives an efficiency of 50 %  please note that if l = 160 bits then your tframe = 40 ms  which is 2  tprop    refer slide time  08  46 10  36  now we come to the topic of flow control if you remember  our data link layer had these several functionalities  chief functionalities  and one of them was framing  which we have discussed then there was an error control ; associated with error control or somewhat closely linked with error control  we have the flow control so the flow control is the other functionality ; we will see how flow control is achieved ? some schemes for that flow control is a technique for assuring that a transmitting station does not overwhelm the receiving station with data  which means that transmitting station is transmitting at a very fast rate and the receiving station can not receive it or can not process it ; its buffer over flows etc so the receiving station gets overwhelmed and some of the frames or some bits may get lost so this is what we want to avoid  which is the topic of flow control the receiver typically allocates a data buffer of some maximum length you can not store an arbitrary amount of data on the receiving side ; so there will be a finite  quite small buffer on the other side so if the receiver can not process ; it first goes into the buffer  but then since we have a small buffer or you may have limited sized buffer  eventually the buffer will overflow and this is what we want to avoid so after receiving data the receiver must do a certain amount of processing before passing the data onto the higher-level software higher-level software may be the network layer  refer slide time  10  37  10  57  now this is an example why flow control is necessary this data is torrentially coming from the above ; the receiving side has just got this much buffer buffer is full  and then what ever is coming  they are simply discarded there is no way to accommodate them  refer slide time  10  58  11  31  one way of seeing this is the same stop-and-wait flow control just as we use stop-and-wait for error control similarly the stop-and-wait can be used for flow control ; it is the same thing so this is the simplest form of flow control the source transmits a data frame after receiving the frame  the destination indicates its willingness to accept another frame by sending back an ack frame  acknowledging the frame it just received the source must wait until it receives the ack frame before sending the next data frame  refer slide time  11  32  12  24  it works fine when a message is sent in a few large frames as we have seen but if we have a large number of frames to send  then of course what happens is that its efficiency becomes a factor so this is not a very good situation for that case when we have to send a large amount of data or a large number of frames specifically often  the source splits a large message and transmits it in many frames buffer size of the receiver may be limited handling errors for smaller frames is cheaper  because if you have a very large frame your error correction and error detection will become a problem on a shared medium like lan  large frame sizes are not desirable  refer slide time  12  25  13  25  so we sort of make a more general case of this stop and wait protocol by giving a finite amount of buffer one way to look at stop and wait is that on the receiving side we have a buffer of size 1 if you have a larger buffer  then in this case  you have to have a buffer on both the sides ; you have to have a buffer on the transmitter side and the receiver side so in stop and wait flow control  if a > 1  serious inefficiencies result efficiency can be greatly improved by allowing multiple frames to be in transit at the same time so suppose two stations a and b are connected by a full duplex link the link has aroused on both sides  which means that we take them to a full duplex because the message has to flow from a to b the acks have to come from b to a  refer slide time  13  26 -16  16  station b allocates buffer space for n frames thus b can accept n frames  and a is allowed to send n frames without waiting for any acknowledgement this is alright because on the receiving side we have n buffer locations i am assuming that each location can contain one full frame so n frames can be pumped in even if the receiver does not process any of them but then at least they can be accommodated in the buffer ; so it will not overflow the transmitter can also transmit n frames but why does the transmitter require a buffer ? because if you remember  the frames which the transmitter has sent have to be stored in the transmitter side because they may have to be retransmitted retransmission may be due to the frame getting a lot of noise  which can not be corrected on the receiving end you may get a negative acknowledgement ; that is one thing secondly  the frame may get lost altogether thirdly  the acknowledgement ? this frame may have reached but the sender would know that the frame has reached only after it gets the acknowledgement and the acknowledgement  which the receiver might have sent  may have got lost so  till it gets an acknowledgement  the transmitter has to store the frame which has already been sent so on the transmitter side also we require a buffer if n frames are to be in transit then the transmitter has to store all of them because any of them might have to be retransmitted so a can send n frames without waiting for any acknowledgement each frame is labeled with a sequence number to keep track of the frames  which have been acknowledged because now since more than one frame may be in transit  may be the first frame is lost and the second frame has reached now the receiver somehow has to know that this is the second frame if the first frame has been lost otherwise it will send an acknowledgement and the transmitter would think that the first frame has been acknowledged so you have to identify what is it that you are acknowledging in this particular case so you have to have a sequence number the acknowledgement comes with this sequence number or some sort of small variation of it  so that the transmitter knows what is it that is being acknowledged  refer slide time  16  17-17  59  so b acknowledges a frame by sending an ack that includes the sequence number of the next frame expected this is what i mentioned as a slide variation instead of directly acknowledging a particular frame  let us say frame number 53  instead of sending ack 53  it sends ack 54 that means 54 is the next sequence number  which is expected in the next frame so it means that up to 53 everything has been received that is the small variation instead of the sequence number of the next frame expected this also explicitly announces that b is prepared to receive the next n frame let ? s say beginning with the number specified which means suppose n was 10 ? b is the receiver ? so when b gets the frame number 53  the next frame it is expecting is really 54 so it sends an ack 54  which also means that b must be having  let us say  this buffer size of 10 so from 54 to 63  it is ready for all these packets ; it is not ready for frame number 65 because the buffer size is only 10  refer slide time  18  00-19  16  this scheme can be used to acknowledge multiple frames b could receive frames 2  3  4 but withhold ack until frame 4 has arrived by returning an ack with sequence number 5  b acknowledges frames 2  3  4 at one time so in this protocol  when a particular frame is acknowledged ? say frame number 53 is acknowledged indirectly by sending ack 54 ? that means all frames up to 53 have been received so one particular ack may act for a number of frames ; this also has an advantage that if one of the ack frames  suppose 3  was acknowledged ; and 4 was acknowledged the acknowledgement for 3 had for some reason vanished ; that means it got killed on the way but say if the transmitter gets an ack 5  that is acknowledgement for up to frame number 4 that means 2  3  4 everything has been received  refer slide time  19  17-21  14  so now we come to the sliding of this window so the sender maintains a list of sequence numbers that it is allowed to send ; this is the sender window receiver also maintains a list of sequence numbers that it is prepared to receive ; that is the receiver window so the buffers on the two sides represent the two windows so on the transmitter side these are the frames  which the transmitter is allowed to send if transmitter has got all these frames from the higher layer but it can accommodate only that many frames now in its buffer so that is the window of transmission and the receiver also has a window in which there are the frames which it is now ready to receive now what the transmitter might do is that it might transmit some of these frames and they are in transit  the receiver window will still be the same because the receiver still has not got them now as it gets them one by one  the receiver windows slides and as these acks reach the sender  the transmitter ? s window slides so we have a sender window and a receiver window since the sequence number to be used occupies a field in the frame  it is clearly of bounden size so you can not have arbitrarily long sequence numbers so even if you are sending a very large number of frames  your sequence number will be bounded depending on how many bits you are using for this sequence number  refer slide time  21  15-21  43  so for a k bit field  the range of sequence numbers is 0 through 2k-1 and frames are numbered modulo 2k naturally so now the frame numbers are going to repeat because of this bounded size of k if k = 3  after sequence number 7 you have to go back to sequence number 0 the next slide shows a depiction of the sliding window for three bit sequence numbers  refer slide time  21  44-22  54  the actual window size need not be the maximum possible size for a given sequence number length ; it could be less actually so for a three-bit sequence number  a window size of 4 can be configured if two stations exchange data  each needs to maintain two windows to save communication capacity  a technique called piggybacking is used so this is the case we are talking about when both sides are trying to communicate ; previously also both sides were communicating in the sense the so-called receiver was sending an ack now let us say suppose two-way communication is going on we need a pair of buffer locations  that is  a pair of windows on both sides so we want two sets of buffers on this side for the two windows and two sets of buffers on the other side for the other two windows on each side  we will have one receiver window and one sender window and in this particular case  another thing we can do is that we can piggyback the acknowledgements so you need not send an acknowledgement frame by itself  refer slide time  22  55-24  39  so this is piggybacking each data frame includes a field that holds the sequence number of that frame plus a field that holds the sequence number used for acknowledgement if a station has an ack but no data to send  it sends a separate ack frame so if the communication is only one sided  that means one transmitter and one receiver  the receiver only sends an ack frame ; but if the communication is from both sides  what they can do is that for the communication that is messaged from here to here  its corresponding ack piggybacks on the messages or the actual frames  which are going from this side to this side so you need not send an acknowledgement frame by itself  which of course  saves a lot of time  because if you remember in stop and wait the acknowledgement was travelling all alone but for that  it took all its tprop  that is  the propagation time but all that is because you are using it for sending a real data  so that way piggybacking is nice of course  you must remember that if you are using piggybacking and if you are sending some packet and you do not have anything to acknowledge  still you will have to put in something in those bits otherwise  those bits will have some values ; anyways  it can not be blank ; each of the bit will be either a 0 or 1 so it may be misinterpreted on the other side so something will have to be sent  refer slide time  24  40-25  52  so this is what the picture looks like for sliding window these are the frames which are to be sent 0,1,2,3,4,5,6,7 assuming there are only 3 bits for the sequence number ; again the numbering starts with 0,1,2,3,4 this 0th frame and this 0th frame are really two different frames so these are the frames 7,0,1,2,3,4  etc  which have already been received if the frames have already been received  what happens is that up to 3  suppose this frame has been acknowledged so the first unacknowledged frame is here and suppose you have a window size of  let ? s say  4 or 5 it is 1,2,3,4,5 ? so up to this is your window size ; once he sends the acknowledgement this window will slide and once he gets the acknowledgement of 4 then this window will slide  refer slide time  25  54-26  40  there are some variations of these acknowledgements we can do ; we will discuss that these variations just try to make it a bit more efficient we will just look at a couple of variations now one is go-back-n arq this is once again based on the same basic sliding window protocol  which is mostly commonly used a station may send a series of frames sequentially numbered modulo some maximum value as usual the number of unacknowledged frames outstanding is determined by window size  using the sliding window flow control technique  refer slide time  26  41-27  56  while no error occurs  the destination will acknowledge incoming frames as usual using receive ready or rr frames if the destination detects a frame error  or it receives a frame out of order  it sends an nak or negative acknowledgement for that frame using reject or rej frame so it sends a negative acknowledgement for a particular frame if it is received badly previously we were only sending acks or not sending anything at all ; now if we have an erroneous frame  we send a negative acknowledgement for that and go-back-n means negative acknowledgement in sending the particular frame that may have come in as faulty now what the sender will have to do is that the sender will have to go back to this particular frame and retransmit from that frame onwards all the other frames  which it might already have transmitted so that is the go-back-n  refer slide time  27  57-28  48  the destination will discard the frame in error and all future frames until the frame in error is correctly received if it has got an erroneous frame and it might have got a couple of frames or later frames which may have come in  they are discarded because until and unless the erroneous frame is correctly received it will not move so the source station  on receiving an rej  that is a reject  must retransmit that particular frame  which went in an erroneous form  plus all succeeding frames that is the go-back-n  refer slide time  28  49-29  26  let us just quickly look at the window size limit for go-back-n arq for a k bit sequence number field  the maximum window size must be limited to 2k-1 why is it that the window size can not be greater than 2k-1 ? this is the reason suppose that data are being exchanged in both directions station b must send piggybacked acknowledgements to station a ? s frames in the data frames being transmitted by b this is required even if the ack has already been sent  since b must put some number in the ack field of its data frame  refer slide time  29  27-29  54  assuming a 3-bit sequence number suppose that a station sends frame 0 and gets back an rr1 that means from 1 onwards it has to send back all the frames so 1,2,3,4,5,6,7,0 it has to send all these and get another rr1  refer slide time  29  55-31  49  so this might either mean that rr1 is a cumulative ack for all 8 frames received correctly  or all 8 frames were damaged  and the receiver is repeating its previous rr1 a receiver might have to repeat the previous acknowledgement because it has to put something in that acknowledged field this problem can be solved if the maximum window size is kept at 7  so that they will not overflow into the next set of sequence numbers that is why the window size has to be kept smaller than this 2k-1 if you make a very large window size  there will be a number of packets here or frames here with the same number so if you get an acknowledgement or negative acknowledgement  you will not know which frame it is that is being talked about now people tried to improve on this because  if you remember  in go-back-n  when you get a negative acknowledgement the transmitter has to go back to that frame  send that frame again and send all the succeeding frames again although it might have transmitted them once and actually what might have happened is that the receiver might have received them also in correct order  but since the receiver is not moving the transmitter has to retransmit all that though the frames were received correctly earlier they are rejected in order to adjust this people then thought was to allow selective reject  that means  one particular frame is rejected ; and some subsequent frames are accepted  refer slide time  31  50-32  55  so here the only frames retransmitted are those that receive a negative acknowledgement  in this case called selective reject  that is  srej or time out of course if an acknowledgement does not come and times out  it has to be sent again because the frame might have been lost altogether but otherwise  only those which get a specific negative acknowledgement are sent again so this would naturally be more efficient than go-back-n receiver requires storage buffers to contain out-of-order frames until the frame in error is correctly received so if a particular frame is wrongly received and then some subsequent frames are correctly received now they have to be stored in the buffer so that when this wrongly received frame is retransmitted by the transmitter and it comes in a proper shape over here it has to be inserted in the middle of that list somewhere  refer slide time  32  56-34  17  if this inserting into this buffer management ; inserting into the buffer ; and taking out of the buffer  etc  are being done by hardware  then you have to have the logic circuit for putting things inside the list somewhere similarly for the transmission side it may have got all these frames lined up  which have already been transmitted out of that  one of them gets negative reject ; so instead of the one at the head of the queue  something from middle may have to be taken out and retransmitted so the transmitter must also have that capacity the receiver must also have the appropriate logic circuitry needed for reinserting the frames in the correct order and transmitter is more complex because it must be capable of sending frames out of sequence receiver is also slightly more complex another drawback is that the maximum window size can be no more than half the range of sequence numbers this is the small problem in selective reject previously remember it was up to 2k-1 ; now we can use only half of that and not the full thing ; we will see why  refer slide time  34  18-35  23  assume 3-bit sequence numbers as in the previous example and a window size of 7 consider the following scenario  station a sends frames 0 through 6 ? because we have a window size of 7 so we can send frames numbered from 0 through 6 ? to station b b receives all 7 frames and cumulatively acknowledges with rr7 so it has received and the next one it is expecting is the 7th one rr7 unfortunately gets lost in transit station a times out and retransmits frame 0 it has not received any of the acknowledgements because for 0 through 6 all the acknowledgements were clubbed together and one rr7 was sent  which unfortunately got lost in transit but station a has not got any acknowledgement so it is holding all these original 0 through 6 frames in its buffer so now it times out and retransmits frame 0  refer slide time  35  24-36  12  b has already advanced its received window to receive frames 7  0  1  2  3  4  5 now b wrongly assumes that frame 7 has been lost and that this is the new frame 0  and accepts it so this old frame 0 is interpreted as the new 0 number frame by b and it assumes that 7 has been lost in transit so may be later on a negative acknowledgement or selective reject for 7 would be sent but this 0 frame now has gone out of order so the problem arose due to overlap between sending and receiving windows for k bit sequence numbers  maximum window size therefore has to be smaller  refer slide time  36  18-38  25  go-back-n and selective reject  these are the diagrams for the two and we already know what these are then frame number 2  which is actually the 3rd frame  came in in an erroneous fashion ; an error was detected and the negative acknowledgement was sent once the negative acknowledgement is sent  although 3,4,5 had been sent and may be they have been reaching over here  this window over here has not moved beyond 1 so it sends 2 again and all these 3,4 are being sent again over here ? 2,3,4 these are discarded on the receiver side although they were correctly received  and this 0,1,2,3,4,5  etc  goes on this was the go-back-n scheme in the selective reject scheme  0  1 was received as usual ; the third frame  number 2  came in erroneous so a negative acknowledgement or nack 2 was sent so when it gets a nack 2  2 will be retransmitted but 3  4 have already been received correctly and acknowledgement of 3 and acknowledgement 4 have also reached the transmitter so the sender will now send frame number 5  6 and so on so please note the difference ? here it has to send this 2,3,4 again here this 3,4 need not be sent again  2 of course has to be sent again because it was specifically rejected but then you can go on with 5,6  etc so that is why this one is slightly more efficient than go-back-n  refer slide time  38  26-39  38  this is another picture of how the window slides so what happened is that this was the window 0,1,2 have been sent and as 0,1,2 have been sent  the receiver window has slid and then it has ack2 after 0,1 it sends an ack2 and then it gets 2 also suppose 3 were lost so although it might have received 4  5 after that  they are discarded in go-back-n and when there is a selective reject  the difference is that suppose any number 3 got lost on the way  4 and 5  which are coming over here are buffered  so that when you get back at 3  you can plug 3 in its proper position and the window can slide very quickly on the receiver side  refer slide time  39  39-39  48  maximum window size is going to be 2k-1 in case of go-back  refer slide time  39  49-40  56  we have discussed some of the major techniques  which are used in data link layer what we will do now is that we will look at just one more protocol this is a somewhat general version we have already discussed ppp  that is  point-to point protocol  which is used for just point-to-point communication but there could be a point-to-multi-point communication also ; for this we have this high level data link control this is the name of the protocol  or hdlc in short this is not considered so high level any longer ; but this is an important protocol so there are some variations of this which are used in various places  refer slide time  41  01-42  10  so this is an important data link protocol this hdlc or some variant of this is widely used it is also the basis for many other important data link control protocols its formulation has three types of stations  one could be primary stations these are responsible for the operation of the link that means primary station is something like a master ; for setting up of the link  and for all other control purposes  etc  the primary station holds the key responsibility so there is some kind of a master ; it may not be the only one master we will come to that later on but primary station is the one who will initiate the setting up of connections  etc frames issued by primary station are called commands  refer slide time  42  11-43  28  and then we have secondary station ; it operates under the control of primary station frames issued are called responses just as the frames issued by the primary station are called commands  the frames issued by the secondary stations are called responses primary maintains a separate logical link with each secondary this need not only be point-to-point  this could be a point-to-multi-point communication also that means there is one primary station  may be a number of secondary stations so the primary is communicating may be with each of them may be on the same medium if that is so  then actually the primary is maintaining a virtual link with each of the secondary so it will maintain its own data  etc  for each of this virtual connection this primary station has to do secondary station is of course under one primary  so this multipoint business does not come into picture on the secondary side and then  we can we have combined station ; it combines the features of primary and secondary in that case  it may issue both commands and responses and combined stations actually are very common and then there can be two types of link configurations unbalanced configuration consists of one primary and one or more secondary stations so if you have one primary and may be one secondary station  this is more like a point-to-point link if you have one primary and a number of secondary stations  then it is more like a point-to-multi-point link an example of a point-to-multi-point link would be suppose if you have a server and a number of terminals  which are all hanging on the same cable and the sever is holding in this case  the server would be the primary station and these terminals would be all secondary stations they are communicating only with the primary station  which is the server  and the server maintains a virtual link with each of them the terminals or the secondary stations  just maintain the link with the primary station so this is an unbalanced configuration in a balanced configuration  this consists of two combined stations combined station is the station  which can act both as a primary station as well as a secondary station so in a balanced link  on both the sides we have combined stations  both of them can act as primary as well as secondary  refer slide time  45  01-45  31  there are three data transfer modes one is normal response mode  which is in the unbalanced case ; it is used with unbalanced configuration primary may initiate data transfer to a secondary as i mentioned before  it is the responsibility of the primary station to initiate data transfers a secondary may only transmit data in response to a command from primary so this is the normal response mode used with unbalanced configuration  refer slide time  45  38-46  35  then we can have asynchronous balanced mode  abm   used with balanced configuration so either combined station may initiate transmission in this case  since it is on the balanced configuration  that means  on both sides of the link we have the two combined stations  both of them can act as primary and secondary and since both of them are combined stations  any of them can initiate the transmission and the transmission can start ? this is abm and the other is arm asynchronous response mode used with unbalanced configuration here the secondary may initiate transmission primary still retains responsibility for the line  initialization  error control etc  that is done by the primary arm this is not very common  refer slide time  46  36-47  27  the nrm is used on multi-drop lines for example  a number of terminals are connected to a host computer ; the computer polls each terminal for the input this is the example i talked about earlier this is used on multi-drop lines also it could also be used on point-to-point links the link connects a peripheral  let us say  terminal to the computer so it is a point-to-point link and what is happening is that the computer side is the primary station and the peripheral side is the secondary station in all these unbalanced cases  the nrm may be used  refer slide time  47  28-47  55  then abm this is the most widely used on both sides  we have combined stations it makes most efficient use of a full duplex point-to-point link  as there are no polling overheads you do not have to do any polling since this is point to point arm is rarely used ; it may be used in very special situations  whereas secondary may need to initiate transmission  refer slide time  47  56-48  52  now there are different types of hdlc frames one type of frame is called information frame  which contains user data then piggybacked acks  that means the next frame is expected so when you are piggybacking acknowledgement is also going on actual data and those acknowledgements are telling you about which is the next frame to expect poll or final is the command or response supervisory frames  flow and error control both go-back-n and selective reject are possible and then there is a frame  which we say is the final one  when there is no more data to send  refer slide time  48  53 49  14  then there can be some unnumbered frames  which are used for control purpose ; some mode setting commands and responses ; information transfer commands and responses ; recovery commands and responses ; miscellaneous commands and responses by the way  you do not have to remember all these because when you ? re trying to use it or design it for some particular situation  you can always look up the reference and see what exactly the different frames are  what are their formats  etc what i am trying to do is to give you a flavor of the kind of information a typical protocol will need to exchange and some typical ways in which these protocols work  refer slide time  49  54-51  36  so this is an example of hdlc operation for this line set-up from the primary station  you will send an sabm sabm stands for set asynchronous balanced mode it is the initiator and it wants to send an abm kind of a set abm on the other side it sets an abm may be what has happened is that after some time this sabm was not acknowledged so it times out and sends us an sabm again now it gets a response back  ua there are some unnumbered frames  if you remember  so this is an unnumbered acknowledgement after some time  possibly  there will be some transfer of data etc and then  there is a disconnect frame  which is a disc  which is going from here on the other hand  you may get frames like rr and rnr rr stands for receiver ready and rnr for receiver not ready if you look at the right-hand side  there are some rrs and rnrs ; these are going back and forth ; and in between  there may be a two-way data exchange actual data are being exchanged through these i frames ; i is for information  so this is information frame so a lot of link set-up and ack is traveling on both sides  refer slide time  51  37-52  27  from the reject there has to be a recovery suppose it is using a selective reject  so reject 4 is going on this side i,4,0 is coming from the other side ; that is  4 is now being retransmitted i,4,0 had been transmitted before it got lost on the way  so a reject 4 had come that same selective reject is working over here similarly  there is time out recovery ; that means  after some time  i  3,0 was sent and was never received so after sometime  it timed out ; so it says that some recovery frame is required this rr sends receiver ready  then i  3  0 is transmitted again these are the typical kinds of transactions  which are going on between the two stations once again  as i said  this gives you some idea about how this data link protocols etc  work and how they do error and flow control  etc  refer slide time  52  48-53  54  we will now take just a quick look at the various fields there are some flag fields each frame starts and ends with the special bit pattern of course  if you use a special pattern  in order to accommodate this pattern within the data itself  bit stuffing is used to unambiguously identify the flag fields bit stuffing this is not 100 % reliable you must remember when the same flag is used to mark both the beginning and the end  a 1-bit error may merge two frames into one a 1-bit error in the ending patterns will not be interpreted as an end of frame pattern by the receiving side ; so the two frames may get merged similarly  a 1-bit error inside the frame could split it into two this is not 100 % correct  but bit stuffing would work most of the time  refer slide time  53  55-54  27  then there is the address field it identifies the secondary station transmitted if you remember  it is not used for or needed for point-to-point links  but is included for the sake of uniformity for point-to-multi-point links  you need to have the address because when the primary station is sending something it is addressed to some particular secondary stations  out of all the secondary stations connected to it both single octet  that is  single-byte and multi-octet or multi-byte addressing are possible  refer slide time  54  28-54  39  then there are some control fields it defines three types of frames information frames carry the data flow and error control information are also piggybacked using arq  refer slide time  54  40-54  51  supervisory frames are also there some unnumbered frames provide supplemental link control functions so i and s frames use 3-bit sequence numbers  refer slide time  54  52-55  11  information field  it is present only in i frames and some u frames it can contain any sequence of bits  multiple of 8   but is usually limited in length from consideration of error control frames with empty i field are transmitted continuously on the idle point-to-point lines in order to keep the connection alive  refer slide time  55  14-55  17  finally  we have the frame check and sequence fields so with this example  we now come to the end of the general data link control we have seen some examples of data link control ; for example  we have seen some examples of mac like with token bus  token rings  etc we will see other examples of mac as we take up the other kinds of networks similarly  we have seen some kinds of error and data control a similar approach is used in some other higher layers also we will talk about it when we come to it and we will talk about some more specific and more widely used systems from the next class onwards so in the next class  what we will do is that we will look at another type of communication and how mac is done on that in satellite communication so  that will be the next topic thank you computer networks prof sujoy ghosh department of computer science and engineering iit  kharagpur lecture-18 satellite communication  refer slide 1  good day ! in this lecture we will be discussing one very important component of world wide communication  which is satellite communication  refer slide 1  slide 1 communication through satellite has been going on for quite sometime now satellite communication is fairly mature technology although some improvements are taking place satellite communication is an important component of world wide communication infrastructure we will also see how specifically mac  which is media access control  is handled in satellite communication this is important  since we obviously need mac because the communication medium is the electro magnetic field around us  which is common to everybody  refer slide 2  slide 2 we now talk about satellite communication satellite can be looked upon as a big microwave repeater repeater is something  which repeats the signal it takes in the incoming signal  amplifies it and then sends it back it contains several transponders transponders listen to some portion of the spectrum each transponder is listening to some portion of the spectrum so that several transponders together can listen to the wider band of the spectrum it amplifies the incoming signal and broadcasts in another frequency back to earth satellites are up in the space ; they take the incoming signal  amplify it and broadcast it back so satellite has to broadcast in a different frequency so as to avoid interference with the incoming signals  refer slide 2  slide3 this can relay signals over long distance ? this is one strength of satellite communication  because  if you send it all the way up and then when it is sending all the way down  and if it does so at an angle  the signal can reach a very long distance there are different kinds of satellites and the most commonly known ones are geostationary satellites because they are above the equator at a distance of 2300 miles approximately and are in the geosynchronous orbit they travel around the earth in exactly the time the earth takes to rotate  refer slide 3  slide 4 we have an uplink station from where some signal is going and then it is being listened to by one particular transponder in the satellite it amplifies signal and sends it back to earth where the downlink station  another dish  which is facing the satellite and tracking the satellite receives the signal over here this is the just reflected part which then gets on the horn this signal is taken down and amplified then we can use it  slide 4  earth stations communicate signals to satellite on an uplink they are called earth or base stations on the ground the satellite then repeats these signals back to the down link this feature is attractive for distribution of tv programmes it is known that many of our television channels  unless coming through cable  are coming from satellite  which is beaming back the signal over a very wider area and all the receivers around can receive the signal and then amplify it and use it so it is very popular for such kind of applications like distribution of television programming slide 5 there are other applications these signals are used to transmit signals and data over long distances for weather forecasting  television  internet communication and global positioning system these are the various applications of a satellite the space orbit allows more surface coverage  refer slide 5  slide 6 the spectrum is usually used by the satellite and is divided into sections ; each of these bands have names like c band  ku band or ku band and ka band or ka band the c band may have four downlinks and six uplinks ; c band is from 3.7 to 4.2 ghz this part of the spectrum is reserved for the c band communication through satellite ; that is  3,7 to 4.2 ghz for downlink and 5.925 to 6.425 ghz for uplink there is a 0.5 ghz bandwidth for downlink and another 0.5 ghz bandwidth for uplink since the uplink is at a higher frequency  you can have more channels over there the capacity is not very high by today ? s standard  especially  if you compare with fiber  this is really low but at the same time  at one point of time  when transoceanic fibers were not there  satellite was the chief medium of communication across continents the capacity is low but still it is useful ; however  terrestrial interference is a problem because when the weather is bad or when there are other kinds of extraneous sources of some electromagnetic noise  etc  these interfere with the signals but still it has got a lot of strong points ; that is why it is still an important component of communication these days  refer slide 6  slide 7 next set of transponders come in ku band they can accommodate greater number of transponders ? 12 on the downlink to 14 on uplink rain interference is the problem here ku band is from 11.7 to 12.2 ghz and 14.0 to 14.5 ghz in this band  rain is a problem though it has higher capacity and is less crowded than c band c band is very crowded  if you consider people with a sort of dish antenna for receiving satellite signal ? i am not talking about the base station ? those using 1-meter antenna are possibly using c band for ku band  the antenna size is smaller and pizza shaped at something like 18 to 20 inches they have a higher bandwidth ; however  rain and terrestrial interference are the problems faced in c band different parts of electromagnetic spectrum are most susceptible to interference and noise  etc  but ku band has higher capacity the ka band is at an even higher frequency ? 19 downlink and 29 uplink transponders are needed the equipment needed for this is quite expensive it is from 17.7 to 21.7 ghz and 27.5 to 30.5 it covers a greater bandwidth  but it is still not very widely used slide 8 satellite can be used for point-to-point transmission  to transfer large volume of data ; voice data and communication and for video conference satellite is not just for broadcast ; satellite can be used for point-to-point communication you may look it as point-to-multi-point communication so we can say that point-to-point and point-to-multi-point communication are supported also  standard broadcast is supported point-to-multi-point communication can be data communication  internet  and video conference broadcast services include television  refer slide 8  slide 9 the advantages are that you can reach a large geographical area and have a high bandwidth ; it is cheaper over long distances it is certainly cheaper than wiring it up  but if you are covering long distance  because of its inherent high capacity  the economy is in favor of the fiber optic cable and it is almost even in some cases but in many situations satellite retains its advantage it can transmit to places where the cable can not reach these are applications where satellites have an undoubted advantage over any wired kind of system it may be a remote area  which is not very easily reachable and road or other kind of communication is not well established to take cable over there but the satellite  since it is sitting high up in the sky  can cover any area without any difficulties hence this is a very strong point in favor of satellite it is especially useful for technology deployed at multiple sites regardless of location  like mobile technology nowadays the first thing people think about to be mobile is the cellular phone  which uses the nearest base station  which is usually wired but in some places where it can not be wired  it may go through the base station and may be connected to the backbone through a satellite that is one thing ; and if you want 100 % roaming all over the earth wherever you go  then you may not have a base station around the place where you are in that case  some satellite or the other would be visible to you and you can communicate through the satellite so mobility and accessibility to places which are difficult to reach otherwise are very strong points of satellite and of course standard communication is also a point slide 10 the disadvantage is the high initial cost you have to build the satellite and then to put it up in the space through some launch vehicle involves high investments but laying fibers all over is also costly so we have to work it out on a case by case basis and determine which one comes out to be better we can not do much at the physical level about susceptibility to noise and interference because the physical media is such that all kinds of noises are being generated all over the place and crowding this shared medium so we have to handle it in some other way at a higher layer then there is a propagation delay ; and this is a significant disadvantage compared to terrestrial communication for many satellites  especially the geostationary satellites we will come back to this point later on geostationary satellites are thousands of miles above earth so although your electromagnetic signal is travelling at the speed of light which is very high but even then to go all the way up to the satellite and then come all the way back down takes significant amount of time and this has lot of implications it has the implications on the mac and it has the other implications like delay and may be quality of service in some cases so this is an issue  a potential disadvantage and security can also be an issue since this medium is open to everybody whatever you are communicating  anybody else can listen on to it if you are trying to send some very sensitive data through satellite and you do not want other people to listen to what you are sending  then you have to take some other measure like encryption  etc we will talk about encryption much later in the course  refer slide 10  slide 11 there are different types of satellites and they have different types of orbits  circular or elliptical orbits the circular orbits will centre at the earth ? s centre there is the elliptical orbit with one foci at earth ? s centre there are some equatorial orbits above earth ? s equator this is quite common and necessary  especially for geostationary satellite it is necessary that they go around the equator but then you could also have a satellite pass over both the poles other orbits are referred to as inclined orbits  refer slide 11  slide 12 the altitude of the satellites and their distance from the earth have significant implication in terms of the time it takes for the signal to travel we have three different classes of satellites  geostationary orbit satellites  geos ; medium earth orbit satellites  meos ; and low earth orbits  leos out of these  geo is the most common one  refer slide 12  geos go around the equator and have a high bandwidth but they also require high power ? this is an important point ? and long latency these are the important issues when you are trying to communicate with some satellite  which is very far away  then your transmitter has to be strong enough so that the signal reaches the satellite if the transmitter power has to be large then you require lot of power in order to power this  it may be difficult to power it with a battery that kind of battery power may not be enough to reach a geostationary satellite the mobility becomes difficult from this power angle so this is an important issue  refer slide 13  slide 13 meo has a high bandwidth ; medium kind of power ; and medium kind of latency leo has low power and latency  but you require more number of satellites they have smaller footprint we have vsat  which means very small aperture when we talk about vsat  we are not actually referring to any satellite we are referring to the ground equipment that we use and vsats have small apertures  which private wans can use with smaller antenna but if they are using c band or ku band they use antenna which has a dimension of either 1 meter or 18 inches but for the main base station of the satellite  usually a much larger antenna is put in place we will first talk about geostationary satellite this is the most common type of satellite today and it is in a circular orbit we say it in miles about 23,000 to 22,000 odd ; and in kilometres it is 35,000 odd kilometres above the earth in the equatorial plane these satellites remain in the same position over the earth as it rotates  refer slide 14 and slide 15  slide14 and 15 slide 16 as the earth is moving  the satellite is moving along with that from some point on the earth  it would appear that the satellite is stationary over its head at all times that is why this is so sacrosanct about this geostationary satellite  this distance of 35,785 kilometres you can always calculate this distance by finding out about the centripetal force and the earth ? s gravitation etc you can put it in that equation and calculate that this is the exact distance at which  if you put a satellite with a particular angular velocity  which is the same angular velocity as that of the earth  what will happen is that to the people directly under it  it will appear as if the satellite is stationary so this is the good thing about this geostationary satellite and this is why this distance is so fixed  refer to 16  slide 17 from such a long distance  if you send a beam which has a reasonable solid angle over here  it will cover a large portion of the earth as a matter of fact  it has been calculated that with three or four satellites you can cover the entire surface of the earth ; but of course  three or four satellites would not be sufficient to handle the bandwidth that we require these days furthermore since this distance is so fixed  there is only one band in space where the satellites can be parked the other point is that if two such satellites are very close to each other  the signals will start interfering with each other so there has to be a minimum distance between two geostationary satellites the geostationary orbit and these parking slots are internationally decided  but these parking slots are quite crowded some nations may not put the satellite but would have reserved some parking slots these parking slots are quite crowded today with so many geostationary satellites up in the space  refer slide 17  slide 18 these have a coverage of about a fourth of the earth and have good tracking properties that means you can track it very easily but their signal weakens over great distance and the propagation delay can be large the propagation delay we are talking about is of the order of 0.24 seconds usually we talk in terms of milliseconds but here we are forced to talk in terms of seconds it may also be hard to get coverage at the polar regions because this geostationary satellite has to be over the equator ; it is difficult to get coverage at the far northern and southern hemispheres  refer slide 19  slide19 geo satellite provides universal connectivity in its footprint its footprint means the area of earth  which is covered by one particular transponder  let us say on one particular satellite so it covers all that area at the same time so now within its footprint it covers universal connectivity from any particular point  you can communicate with the satellite and possible satellite parking slots are quite crowded wide beams are circular  whereas spot beams  which are more focused  are elliptical apart from broadcasting  they may also be used with vsats for point-to-point communication we will come back to this point later  refer slide no.20   slide 20 so they are at this kind of distance that requires large transmitter power making them large and expensive there is considerable space delay and large cell size  which means smaller number of channels this is one particular point and we will come back to this point in greater detail when we discuss terrestrial wireless communication but the point is that a satellite has some amount of bandwidth which is assigned to it which it can handle ; now within that bandwidth for communication  namely  the voice channels require about 64 kbps rate one particular transponder can handle 800 such channels if the footprint of the satellite is very large  that means it is covering a large number of people but all these large number of people are constrained with those 800 channels a large cell size also necessarily means a smaller number of channel density on earth  refer slide 21  slide 21 a typical satellite has 12 to 20 transponders  each with a 30 to 50 mhz bandwidth ; a transponder can carry about 800 voice channels fdm  frequency division multiplexing  was used in early satellites nowadays tdm is also used ; as a matter of fact  a mixture of tdm and fdm is also used the cost of transmission is independent of distance sometimes this is an advantage when you are communicating via a communication satellite with somebody who is  say  10 kilometres away or with somebody who is 100 kilometres or 1000 kilometres away  the cost is constant over the entire footprint that may be an advantage in some cases  refer slide 22  slide 22 for some applications this may be useful security and privacy pose a problem as mentioned earlier so encryption is essential mobility is easily achievable and setup time is not required if the satellite is in space  then you do not require any setup time if the satellite is not there  you have to send it there gps is an interesting application we will see  refer slide 22  slide 23 we now come to the middle earth orbit satellites these are used for global wireless communication coverage they maintain orbit about 8000 miles from earth the moment you come out of the geostationary orbit  the satellite can not remain stationary over somebody ? s head any longer now the satellite will necessarily move over your head so in meos and leos what will happen is that you will find that the satellite is coming over your head just as other stars move so the satellite will move over in the sky and it will be there for sometime and then it will be out of your reach because it will go down below the horizon this is what is going to happen with meos as well as leos how soon will they come back depends on how far they are and what is the speed  etc so it orbits around earth once in about every 2 to 12 hours depending on its parameters so more satellites are needed and some handoffs are required as the satellites orbit now what is this handoff we are talking about ? you are communicating through the satellite to somebody else but the satellite has moved away so now the communication link will break in order that the communication link does not break what will have to happen is that another satellite will have to come and take its place and there has to be a handoff of communication from this satellite to this satellite before this satellite disappears altogether so that this communication between the two end points can continue so these handoffs are required as satellite ? s orbit and transmit data rate at 9.6 kbps to 38.4 kbps transmission delay is less than 0.1 seconds so this is considerably less than the 240 milliseconds we had earlier  refer slide 23  slide 24 taking it still further down  we have the low earth orbiting satellites  launched like a large flock of birds you require a lot of satellites because each of these satellites is visible to one particular point in earth only for a short duration of time so in order to give continuous coverage  you need a large number of satellites this cell size or the footprints will also become smaller so in order to cover the entire earth  you need a very large number of satellites orbiting at constant altitude of 400 to 1000 miles they must travel very fast to avoid gravity forces because in that case they will fall down to lower orbit  which allows for transmission of the 2.4 to 9.5 kbps it travels at 17000 miles per hour  circles earth approximately every 90 minutes so this goes around very fast it is used for mobile voice low and high-speed data ; internet access via mobile phones and pdas and gps  etc so the low earth orbiting satellites are what are used for the so-called sat phones it is dual linked due to some reason since this is low earth orbiting  the power that you require to reach the satellite is much less so now you have a handheld device  which may be a little bigger than your standard cell phone  but not very much bigger you can still carry it in your hand and with that now you can phone from anywhere from the earth because you are just communicating through the satellite  refer slide 24  slide 25 low earth orbiting satellites are individually cheaper they also give lower space delay  which is much less because we are that much nearer however a large number of satellites need to be deployed as the satellites keep moving  ground stations which are communicating  will have to switch from one satellite to another and quick handoffs will be required  refer slide 25  slide 26 one of the examples was the iridium set of satellites there were 66 satellites  which offered mobile telephony  paging and data communication unfortunately by 1990 they went out of service what happened was that  sat phone services became very costly by that time  other kinds of technology like fiber technology and the terrestrial wireless technology developed to such an extent that a major part of the market was captured by those  which were giving the same service to the end user at a much cheaper rate furthermore we require 66 of them  all of them moving very fast and you have to have this complicated handoff from satellite to satellite to make it low enough so that you can communicate from a handled device etc this could not be supported in the market since there are very few people going to such remote places where there can not be any other communication infrastructure majority of the users would have some base station for some terrestrial wireless nearby and that is why this price became very uncompetitive there were some efforts to revive this company  but finally it did not work out and they became bankrupt at present there is the ambitious ongoing project called teledesic in leo  which includes 288 leo satellites to provide low-cost high-speed internet access  networking and teleconferencing across the globe  refer slide 26  slide 27 here  as i mentioned  the space delay is lower and becomes comparable to terrestrial lines in the l band it is possible to communicate with it using battery powered handheld devices however cell sizes are still too large compared to terrestrial cells  refer slide 27  slide 28 iridium system had 66  so each satellite was to have 48 spot beams  giving a total of 1600 cells  each with 174 channels but 174 channels or total of 183,000 channels are not so many globally because terrestrial service providers give millions of channels over the area so finally  the cost turned out to be too high and the project went bankrupt  refer slide 28  slide 29 now we talk about vsats  which are small terminals with about 1-meter antenna and 1 watt transmitter power often the downlink capacity is more than the uplink speed for point-to-point communication usually goes through a hub if two persons want to communicate the communication will go from here to the satellite and from the satellite to a central hub  which will have a very big antenna and it can handle all the mac part of it we are not going into the details of this but anyway this will go to the hub and from the hub again it will go to the satellite and then go the point b let a be the sender and b be the receiver so it goes in two hubs ; so the space delay is doubled because we are going in two hubs  sometimes with the help of the satellite modem kind of thing  you can go in one hub so those channels are more costly otherwise  with the usual two hubs  there is considerable delay of the order of a half a second for this communication between a and b  but then there is no setup time so various combinations of tdm  tdma  fdm  and fdma are used for handling the mac and all this is controlled by that central hub  refer slide 29  slide 30 as i mentioned  one important application was the gps satellite constellation this is a global positioning system and this is operated by us air force another gps system is on the drawing board ; it will be deployed by some other consortium so there are 28 satellites in this and it has six orbital planes at a height of about 20,200 kilometres since this is not the geostationary orbit  they keep on moving and a minimum of five satellites are visible at all times so with this what you can do is that you can locate any position on the ground  if you have a gps terminal somewhere a very common application of gps is to put that antenna on a car so the car can be tracked anywhere on the earth  refer slide 30  slide 31 for gps we do a trilateration suppose there are a number of satellites which are visible to any of the ship  plane or a car as shown in the picture suppose we are measuring the car ? s distance from a number of satellites since for the satellites we know relevant parameters  from three different readings and three different distance measurements  if measured quite precisely and accurately  you can get the accurate position of the car there are so many different applications  which are possible for example  there is a central database  if you give information about where you want to go  then it can tell you the path to take or the alternative paths and which of them is crowded in many places in europe  you can get very precise information about where you are  which road you should take to reach the final destination  refer slide 31  slide 32 the advantages of avl  automatic vehicle location  are fast despatch ; customer service ; safety and security ; digital messaging ; dynamic route optimization and driver compliance slide 32 shows a mobile gps unit located on a truck with gps satellites  you can give faster dispatch of goods for example  some company has to deliver a lot of goods to a lot of warehouses so it may ship something and now the customer wants to know where it is you can immediately know where it is because you know into which truck you have put these goods and where it is exactly so  for courier service and similar services  you can give enhanced and sophisticated level of service through gps  refer slide 32  slide33 in conclusion  we can say that satellite communication will continue to serve where broadcasting is essential or where terrain is hostile or very sparsely populated it also has a niche where rapid deployment is extremely critical let us consider battlefield kind of situation where you want to rapidly set up some communication network if you have a satellite up in the sky already  you can take that transponder may be there is a disaster where you want to quickly set up disaster recovery and relief operations you can use this satellite because satellite communication will still go on whatever may happen even if there is a flood and everything is flooded  the satellite communication will still go on moving with your mobile units in other combination with terrestrial radio links fiber is likely to hold the advantage  refer slide 33  slide34 now we come to an interesting part of the satellite communication we see how this mac works for satellite communication this is another class of media access control technique  which we mentioned earlier this is the first example that we see it is random access protocol  refer slide 35  slide 35 we mentioned random access protocols earlier just as we talked about token based protocols  etc we also talked about random access protocols this is the first example of a random access protocol random access protocol is actually very simple when a node has a packet to transmit at full channel data rate  so just do not bother whether somebody else is transmitting or not transmitting or wants to transmit or it ? s going to transmit right away  you just do not bother about anything you just try to put in whatever you want to transmit on to the channel now what will happen if you are lucky since you are doing the random thing without any knowledge or consideration about what other people are doing  your transmission may get go through so there is no a priori coordination among the nodes but your transmission may still go through what will happen is that two or more stations may try to communicate at the same time or very nearly the same time what may happen is that the packet or the frame sent by one station a and the frame sent by the station b may collide and what will happen is that both the frames will be lost and will become garbled since you are talking about a medium  which is shared by everybody  these two transmitting stations a and b would also be able to listen to this and find out that both of their messages are garbled if they find that both are garbled  they will retransmit as a sort of backup for a random amount of time that is very important once again the second random is also very important this backing a random amount of time because if the protocol says no both of them backup for a fixed amount of time and after the lapse of that fixed amount of time both of them will start communicating again it is important that the backoff for a random amount of time and hopefully the random number generated by one station and the random number generated by the other station happen to be two different numbers so now they are going to stay communicating at two different points of time but they will not collide they may collide with other stations that is a different issue to ensure the random access protocol  if two or more transmitting nodes start transmitting at the same time we have a collision random access mac protocol specifies how to detect collisions and how to recover from collisions ; for example  via delayed retransmissions these are the two parts of any random access protocol  refer slide 36  slide 36 this satellite protocol  which is called aloha or slotted aloha is the simplest kind of random access protocol we will see other examples like csma csmacd csmaca etc later on so these are the examples of random access mac protocols aloha which was the original grandfather of all these protocols first came  then slotted aloha and then all these csma csmacd and csmaca etc were used  refer slide 36  slide 37 the aloha protocol was originally developed for packet radio in 1970s this was applicable to any system with uncoordinated users competing for a shared channel there was no carrier sensing carrier sensing means you do not try to find out whether or not somebody is already communicating that may sound a little strange at first ; because if you could find out that somebody is already communicating  then by trying to transmit at that point of time you are not only sure to fail because your own message will get garbled and somebody else ? s frame will also get garbled  but then you will also have a more crowded media for satellites there is a problem you can not always do this carrier sensing  due to space delay since we have a 240 milliseconds space delay  whatever you are listening to now was actually transmitted 240 milliseconds earlier so if you find that the channel is quiet now  there is no guarantee that after 240 milliseconds also it will also remain quiet that is why it is difficult to do carrier sensing in the case of a satellite that is why this latency  space delay  has a very significant impact on how we handle the mac here we do not do it ; 240 milliseconds is a lot of time in which a number of frames may be sent so we do not do any carrier sensing we simply send whenever we have to send something and then later on listen to the medium to find out whether or not there has been a collision this is the pure aloha protocol  refer slide 38  slide 38 users transmit whenever they have data if there is collision within a time frame  dictated by the space delay  it backs off for a random amount of time and sends it again if the first bit of a new frame collides with the last bit of a frame that is just finishing  both are taken as garbled so there is no such thing that the frame has gone through 95 %  either the frame has gone entirely  or even if one bit has collided  both the frames are taken as garbled and lost  refer slide 38  slide 39 collision detecting by listening to broadcast channel or by absence of acknowledgement  if collision occurs  each user waits random length of time as already mentioned various collision resolution algorithms are available station does not transmit new frame until old frame has been successfully transmitted the station is stuck with the frame until it can successfully send it  refer slide 39  slide 40 the slotted aloha has better performance all frames are of the same size time is divided into equal size slots and each slot is to transmit one frame with some distance if the transmitters and the receivers are synchronised they try to send frames only at the beginning of a slot so nodes start to transmit frames only at the beginning of slots nodes are synchronized ; if two or more nodes can still try to transmit in a slot  all nodes detect collision there may be collisions even after making the slots for example  suppose within the span of the fifth slot three different stations are ready to transmit something what will happen is that at the beginning of the sixth slot  all three will be communicating and all three will collide  refer slide 40  slide 41 when node obtains fresh frame it transmits the next slot as soon as it gets a frame to send  it sends it in the next slot no collision node can send new frame in the next slot if there is a collision  the node retransmits the frame in each subsequent slot with probability p until it attains success  refer slide 41  slide 42 this is a picture of a slotted aloha there is a collision over three nodes ? nodes 1  2  and 3 all three of them wanted to transmit they start transmitting and then collision occurred then all of them backed off it may so happen that the second slot went empty then in the third slot  what happened was that number 3 had backed off randomly for a long period of time but node 1 and 2 may have decided on the same number over here so 1 and 2 collide again what might happen is given as an example  may be in the fourth slot  2 has tried again and it has been successful so there is a success over there then next slot is empty node 1 and node 3 are trying and then they collide again then may be in the next slot  3 succeeds and so after 9 slots  the three have been able to communicate these three frames so you see because of this  collision affected efficiency  refer slide 42  slide 43 in slotted aloha pros a single active node can continuously transmit at full rate of channel if nobody else is transmitting one active node can go on transmitting this is highly decentralized only slots in nodes need to be in sync ; so that may be taken care of from the hub or through the satellite etc ; it is a very simple kind of protocol  refer slide 43  the cons are that there are idle slots and hence low efficiency  refer slide 44  slide 44 now what is the efficiency ? efficiency is the long run fraction of successful slots there are many nodes each with many frames to send suppose n nodes with many frames to send each transmitting slots with the probability p so probability that first node has success in a slot is equal to p  1  p *  n  1    so it is the probability p that that particular node sends and it is the p1  p that all the other n  1 do not send so only then you will have a success ; and probability that any node has a success is np  1-p  n-1  refer slide 44  slide45 so for maximum efficiency with n nodes  we have to find a p * that maximizes np  1  p  *  n  1  .hence this value for many nodes  we take the limit of np *  1  p *  n  1 as n goes to infinity and this gives a value of 1/e  which is 0.37 so this is the efficiency ? 37 % is the maximum theoretical efficiency that you can achieve in slotted aloha so at best  channels have useful transmissions ; 37 % of time  which may not look like a very high figure  but then you are absolutely uncoordinated ; but if you have low load then that may be alright  refer slide 45  slide 46 for pure or unslotted aloha  is simpler because there is no need for synchronization when a frame first arrives  it is transmitted immediately so collision probability actually increases a frame sent at t0 collides with other frames sent in t0  1 assuming that each frame takes one unit of time to send up to t0 + 1 ; so there is a big interval from t0  1 to t0 + 1  where things may collide  refer slide 45  slide 47 so this will overlap so this frame will overlap and now there is no question of any slots  so anybody can start transmitting at any point of time  refer slide 47  slide 48 what will the efficiency be like ? p of success by a given node is equal to p that the node transmits multiplied by the probability no other node transmits in  t0  1  t0  ? p  a probability that no other node transmits in t0  t0 + 1 so this is p  1  p  n  1 ?  1  p  n  1 so p  1  p  2  n  1   so choosing optimum p and then letting n tend to infinity gives as an efficiency of 1/  2e  or about 18 %  so this is a rather low efficiency for transmission  refer slide 48  slides 49 and 50 when a computer network developed there were a number of competing lan technologies but today ethernet has a come to dominate a lan almost totally excepting for the newly emerging wireless part which we will discuss later so this ethernet is not only a lan nowadays people are talking about ethernet in the man that is metropolitan network area also so ethernet  as you understand is very important so we will talk about ethernet it ? s a dominant data link layer technology  refer slides 49 and 50  slide51 the multiple access scheme of ethernet is csmacd now  refer slide 50  slide 52 so this minimum time is which may vary from system to system  that means a network to network so this is how it is calculated so far let us see how the minimum time would comes suppose this is the shared bus we put two nodes at the two extreme ends suppose now packet starts at over here at time t equal to zero packet is almost reached b at time t-e  at which point of time  it does not transmit suppose the propagating time of the packet for moving from one end to the other is t  at t e it has almost reached b at that point of time b starts transmitting  because we have been finding that the bus has been very quiet there is no signal at end so b can start .so b starts and if there is a collision and this collision is at one this end of the of the medium .so the collision bus starts transmitting back the jam signal .so it again take s almost tau to reach .soa so the total time is t noise so collision detection can take as long as 2 t  slide 52  computer networks prof sujay ghosh department of computer science and engineering iit kharagpur lecture name # 22 cellular networks  refer slide time  0  55  good day so  now we will start our discussion on terrestrial wireless networks we have already seen one kind of wireless communication  which is through satellites so it is microwave repeater and we know that but there are two very important and rapidly expanding field in networking  which is terrestrial wireless networking we will have two lectures on this in the first lecture  we will discuss cellular networks the cell phone  which has become ubiquitous nowadays and in the next lecture  we will talk about wireless lans  wireless lans are may be little bit of wireless mans also so  today we will discuss about cellular networks  refer slide time  01  49-04  29  so just right away  let us learn some jargons what is a cell ? the cellular network is organized in the form of some cells and it covers a geographical region it has base station analogous to 802.11 ap ap is for access point 802.11 is the wireless lan technology we will discuss about this in the next lecture anyway  the point is that there is a base station and it will have an antenna  some transmitters and receivers it will be connected to the backbone through a line may be this could also be a wireless line  but usually this could be a fibre optic line in a circluar geographical location around this base station  mobiles will communicate with this base station and through this base station to the rest of the network so mobile users attach to network through bs and air interface is the physical and link layer protocol between mobile and bs that is called air interface between the mobile and base station now all these base stations are connected to the mobile switching center  msc   the switching is essentially done over here the msc connects cells to wide area network the mobile switching center will be referred to as msc  base station as bs ,mobile switching center as msc  ms  by the way  is a mobile station msc connects cells to wide area network and manages call setup more about that later and these mscs will be connected to each other for a particular service provider they will also connect to public telephone network and the internet etc so one service provider  their network would be connected to another service provider ? s network so somebody from this network can call the other network and so on so we have the cells ; we have the base stations ; we have the mobile stations or mss we have the mobile switching center  msc  and of course the pstn at the back of it all this part is usually wired  refer slide time  04  30 06  20  the first hop ? we are now talking about the air interface between the mobile station and the base station there are two techniques for sharing mobile to bs radio spectrum there is certain radio spectrum  which is allocated to the base station and to the particular region that it has to be shared now  this is a question of multiple access and two techniques that we talked about earlier are fdma  if you remember this is frequency division multiple access  and tdma  time division multiple access in cellular technology  what we usually do is that we combine fdma and tdma so divide the spectrum in frequency channels and divide each channel into time slots if you say that these are the different frequency channels and each channel may be divided into number of time slots we will do fdma as well as tdma on this that is one kind of scheme ? the so-called gsm utilizes this we will be talking about how fdma and tdma are combined the other technology is cdma  which was designed by a company called volcom in usa  which uses code division multiple access we have already seen what code division multiple access is so we will not get into the details of cdma systems here cdma is another popular way of transporting data to the mobile devices both gsm and cdma are used in many countries for example  in our country also some service providers provide cdma services  and few offer gsm services  some provide both  and so on  refer slide time  06  24-07  19  we will now discuss cellular standards as they stand today historically  we had only the cellular system that came from some amps in usa previously  there was only one cell from the analog system from analog system  it came down to digital system in deamps and then we have these two systems of the 2g system ? one is the gsm system and the other is the cdma version 2g systems are voice channels  is-136 is tdma  combined with fdma  which is used in north america gsm  which is more popular of these schemes  is the global system for mobile communications it has combined fdma/tdma  which is most widely deployed is -95 is the code for cdma systems  which use code division multiple access so these are the 2g or second generation systems  refer slide time  07  20-08  23  there are 2.5g systems these were introduced because the 3g was promised quite some time back but the service providers really could not deliver it or crank it up to that extent but  there was lot of demand for it voice was alright with 2g  but then the demand for data and other kind of multimedia services etc  was increasing so people had to be given some data services instead of going all the way to 3g  people went to 2.5g 2.5g systems have both voice and data channels so  for those who can not wait for 3g services  there are 2g extensions one is gprs this is general packet radio services evolved from gsm and the data is sent on multiple channels if available it has an enhanced data rate for global evolution edge ; also evolved from gsm using enhanced modulation data rates up to 384k  refer slide time  08  24-09  11  cdma has its own version called cdma 2000  that was phase 1 ; then there was phase 2 also so data rates up to 144k evolved from is-95  which is the cdma system 3g system includes both voice and data  one service it provides is umts this is the name of the standard universal mobile telecommunications service  umts   gsm is the next step  but using cdma 2000 so  all these merge into the 3g systems how exactly this merging will take place and how it will actually be deployed and become popular remains to be seen ; but today you can get these data services on your cell phones  etc  refer slide time  09  12-09  46  the protocol layering for cells is a little different we will not go too much in to this one is of course  the physical layer  which has to do with the physical channels then there is mac  medium access control we will talk about it  at least for gsm so  there are these logical channels  transport channels  and then there is radio resource control layer that is the layer 3 particularly this you might say is a protocol  but this does not go all the way that the osi 7 layer this is just for the cellular systems  refer slide time  09  47-12  04  our idea is that we have some base stations and each base station will cover some geographical area like it has been shown here different bs would be connected through a backbone network or through mscs we are trying to get the basic idea of the cell the point is that  nowadays cell phones have become very popular its rate of penetration is much faster than the original telephones  and it is much faster than pcs also so  cellular phones have become very popular  which means a lot of people want to use it and lot of people have cell phones many of them would want to talk at the same time but how do you accommodate all these people talking at the same time ? we do multiple access but then  there is a limit to what you can do using same frequency spectrum the idea was to do some kind of space division multiple access in the sense that within one particular geographical area  we use a particular frequency band and then in another geographical area  which is far removed from there  so that these two do not interfere with each other  we use the same set of frequency band at the same time for a different set of users the point is that these powers have to be controlled because  if they are very powerful  they will start interfering with each other but if this power is controlled  then within that cell  that power is enough but  it is not enough to interfere with each other so  two different groups of users can use the same frequency band at the same time this is the basic idea of breaking up a region into cells so that you can increase the number of people  who would be using this system that is the basic concept of a cell  refer slide time  12  06-13  03  in practice  cells are may be of arbitrary shape but they will be close to a circle because usually the kind of antenna used in base stations is omni directional antenna  in the sense that it gives the same power on all sides it has the same sensitivity on all sides if that is so  the area of influence would be a circle but when many circles are put together they are pulling and they will intersect with each other to solve this problem  we can use a tessellation there are only three types of tessellations  which are possible ? equilateral triangles  squares or regular hexagons out of these three  the regular hexagon is the closest to a circle that is why usually the regular hexagons are used to represent a cellular structure a hexagonal cell  the closest approximation to a circle  is used traditionally for system design  refer slide time  13  04-14  27  this is how a big geographical area may have been divided into a large number of cells ? it looks like a beehive if you notice carefully some of the cells are dark and these cells are marked as a b c d e f g so  these are seven there are seven hexagons like this and these are actually different frequency ranges these frequencies are again reused for example  you have another a b c d e f g over here this b and this b ? although they use the same frequency ranges ? are far apart so  different groups of people can use it at the same once it gets into the base station  we usually take it to the fiber optic domain  where a large number of calls  simultaneous calls can be handled this really shows you the frequency reuse a  the set of frequency bands  which are associated with a  will also be reused here  here  and there and so on that is how a hexagonal cellular structure is constructed and we do this frequency reuse  refer slide time  14  28-14  54  co-channel reuse ratio is given by dl/rl = v3n  where dl is the distance between co-channel cells  that means those who share the same channel rl is cell radius ; n is the cluster size the number of cells in a cluster n determines the amount of co-channel interference and the number of frequency channels available per cell this really comes from geometry  refer slide time  14  55-16  29  when the number of subscribers in a given area increases  allocation of more channels covered by that cell is necessary what happens is that in one area  say a small town  one base station could satisfy people  who had these cellular phones or mobile phones now what happens is that  the number of people who wanted to use mobile phones kept on increasing and now we can not serve them any longer the number of requests  which are denied  keeps on increasing how can we increase ? may be break it up into two cells and then break it up into four cells and break it up into many more cells  depending on the clusters of users and the cells now  the same area has been divided into smaller cells may be in the bs  you decrease the transmitter power so that they do not interfere with each other so when the number of subscribers in a given area increases  allocation of more channels covered by that cell is necessary this is done by cell splitting a single small cell midway between two co-channel cells may be introduced  refer slide time  16  30-16  53  these are the small adhoc solutions to the problem for example over here  you had a large number of cells we created a small cell over here using a  which uses the same frequency bands as the already existing ones you can not use e  f  c  or b but you can use a with other cells so that is called cell splitting these are ad hoc solutions  when a particular area has more number of users  refer slide time  16  54-17  14  we now have a cellular hierarchy  the needs of which are  extending the coverage to the areas that are difficult to cover by a large cell ; increasing the capacity of the network for those areas that have a high density of users ; increasing the number of wireless devices and the communication between them  refer slide time  17  15 18  04  so  you have a large number of cellular hierarchies one set of them are called femto cells these are the smallest unit in the hierarchy so these cells need to cover only a few meters  where all devices are in the physical range of the users this is also called personal area networking so i have something in my left pocket  something in my right pocket and something in my hand these might communicate with each other so  that is personal area networking femtocells are small cells then we have picocells  the size of their network is in the range of a few tens of meters so  you can think of a small building as picocell for example  wlan  wireless lan    refer slide time  18  05-18  34  micro cells cover a range of hundreds of meters ; for example  in urban areas to support pcs or other technologies pcs is another kind of mobile technology macro cells cover areas in the order of several kilometers  for example  a metropolitan area  or may be a small town mega cells cover nationwide areas so  mega cells possibly are being serviced by a satellite  refer slide time  18  35-19  04  this is the picture of satellite  which may service a mega cell then  we have macro cell from this tower then we have pico cells  which have some access points etc inside a building and so on microcells for covering communication so these ways of different kinds of technologies may be deployed for these different ranges of cells  refer slide time  19  05-19  32  frequency reuse  we have already talked about this radio spectrum is one of the scarcest resources available ; because  there is so much demand for it for so many applications so  employ architectures that can support as many uses as possible  theoretically  with the available spectrum same spectrum can support multiple users separated by a distance and thus efficiently be using the spectrum  refer slide time  19  33-20  46  frequency reuse has its foundations in the attenuation of the signal strength of em waves with distance so  if two points are at a distance from each other  this signal gets attenuated and does not interfere significantly with this one  although they are using the same frequency band usually  what will happen is that the service provider will be given some band of frequencies now  he has to use that and can not stray from there  as that is the license agreement so  what he will do is that  is depending on where his users are  and what the distribution is  what the density is like  he has to develop or plan a cellular infrastructure in this fashion using and reusing this frequency  the same frequency band  here and there to give the maximum amount of service the distance separating the transmitters of this frequency reuse should be sufficiently large of course  this has to do with a transmitter ? s power transmit power should be reasonably small the cellular concept is an intelligent means of employing frequency reuse  refer slide time  20  41-21  21  so what we have been talking about is something like a fixed channel allocation that means for a particular cell  the channels  that means  the frequency band associated with the cell is fixed so  total number of channels is nc = w/b  where w is the bandwidth of the available for spectrum b is the bandwidth needed by each channel the total number of channels per cell is cc = nc/n  where n is the cluster size  refer slide time  21  22-21  53  adjacent radio frequency bands are assigned to different cells as shown in analog each channel corresponds to one user while in digital each rf channel carries several time slots or codes so  you are doing either tdma or cdma so  if you are doing this  the naturally fdma tdma combine or cdma uses spread spectrum technology so  it ? s simple to implement so  fixed channel allocation is simple to implement if traffic is uniform  refer slide time  21  54-23  24  but then  sometimes traffics are not uniform ? there may be two cells  which are side by side so  this has been given one band one has been given another band of frequencies they do not interfere with each other but  we find for each cell let us say  to start with  we are given with equal bandwidth to each of the cells now  i find that in one particular cell  the user density is much higher  whereas in adjacent cell  the user density is lower so  i could use some more bandwidth in this cell and i could do with a little less bandwidth here so  what could do is that  a part of this frequency band can borrow from the adjacent cell so  that is called channel borrowing technique high traffic cells borrows channel frequencies from low traffic cells temporary channel borrowing and static channel borrowing this could be a permanent feature or this could be the feature of a day for example  in the central business district  it might become very busy during the day time so  it may borrow channels from the side  whereas after the evening the use may fall drastically in that case  one cell can give out channels to others not only sort of giving channels to other people so  this could be static as well as it could be temporary  refer slide time  23  25-26  26  this is suitably complex picture of gsm  i.e the global system for mobile communications so  this just to show you how these tdma and fdma are combined so  you see there are 124 simplex channels in the gsm system now  each of the simplex channels actually carries a series of tdma frames and each of the frames is divided into 8 parts  that is how a large number of channels can be given there are two parts  one is the uplinking and another is the downlinking  that means  from bs to ms ? base station to the mobile station or from the mobile station to the base station so you have two different frequency bands for these ? one band for this bs to ms communication and another band for ms to bs communication in each band  there are a number of frequency channels and each frequency channel is again divided into so many slots  eight slots for simultaneous communication so this one and this one are same channels  but this and this are two different channels for a particular mobile station so from base station  it may be using this particular time slot in this particular channel  that is  from the base station to the mobile station the same one  from the mobile station to the base station  will be using another channel and actually another time slot  because there is some technical problem in giving the same time slot in this channel as well as the other channel so  you give it a different time slot over here so  in this particular time slot of this particular channel  the mobile station is communicating with its base station so  that is how it goes gsm uses 124 frequency channels  each of which uses an 8-slot tdm system and there is a frequency band at which it operates ; this is also fixed this is in the 959.8 mhz range you need not remember these figures  but this is the general scheme of the way tdma and fdma are combined together  refer slide time  26  27-27  15  suppose this is s1  t  and this is the signal which comes from source 1 and this is the signal from source n  sn  t   this is some other source what is happening is that in the tm slots  the first slot ? s1 ? gets the first slot and sn gets the nth slot so  they are pushed into this in the same frequency band  and as time progresses  they function just like in a tdma system so  this is the tdma part so  gsm = fdma 200 khz ; that is the gsm system  refer slide time  27  16 27  46  this is a portion of the gsm framing structure so  how they are framed ? actually  this is a somewhat complicated scheme some of these frames are used for control purpose and others for communication  one group for base to mobile and other from mobile to base  etc so  there is a scheme for this we will not go into the details of this  refer slide time  27  47-28  17  a gsm system has 124 pairs of simplex channels they are in pairs because one goes from bs to ms and the other from bs to ms each of these is 200 kilo hertz wide and supports 8 separate connections on it  using tdm so  each active station is assigned to one time slot on one channel pair 992 channels can be supported in each cell  but many of them are not available to avoid frequency conflicts with neighboring cells  refer slide time  28  18-30  16  transmitting and receiving does not happen in the same time slot because the gsm radios can not transmit and receive at the same time and it takes time to switch from one to another that is why different time slots are given a data frame is transmitted in 547 microseconds  but a transmitter is only allowed to send one data frame every 4.615 milliseconds  since it is sharing the channel with seven other stations the gross rate of each channel is about 270 or about 271 kbps divided among eight users this gives about 33 or 34 kbps gross cc i.e  control channels are used to manage the system if somebody is getting only 33 or 34 kbps previously  we have been talking about voice channel requiring 64 kbps now  the 64 kbps happens to be if you are doing a plain vanilla pcm that means we have explained  how it is encoded by sampling it at eight samples and eight levels for each sample ? that gives us 64 kbps the point is that  it is not the only coding scheme actually  there are more advanced coding schemes we did not find time to discuss those coding schemes using those coding schemes  good quality voice transmission can be achieved  using a much lower bandwidth this 33.854 kbps is actually enough  if you are doing your coding in a smart fashion  refer slide time  30  17-32  19  as i said  apart from the user channels  there are some control channels cc is used to manage the system the broadcast control channel  bcc  is a continuous stream of output from the base station containing the bs ? s identity and the channel status all mobile stations monitor their signal strength to see when they moved into a new cell the point is that the mobile station  when it gets these broadcasts from bs  by just sensing how much transmitter power it is getting  it can identify whether it is near this particular bcc  what this particular bs is  or what its identity is  or whether it is near some other bs in some systems like cdma  this power is very crucial even for decoding purposes that is one thing which is being broadcast and to listened by all the ms the dedicated control channel is used for location updating  registration  and call setup ; in particular  each bs maintains a database of mobile stations  which are in its area so  information needed to maintain this database is sent on the dedicated control channel so  the point is that these mobile stations are moving they move from one cell to another  from the vicinity of one base station to the vicinity of another base station so  the set of ms  which are now currently under this  that information in some schemes is collected on the side from time to time and there is a database  which is associated with the bs this is centrally communicated that is important for locating a person we come to that later on  refer slide time  32  20-33  33  and then there is a common control channel which has got three logical sub channels that is the paging sub channel  paging channel  in which the bs uses to announce incoming calls each ms monitors it continuously to watch for the call it should answer the point is that  if there is a call  and ms is in the area of some bs and then somebody wants to call to this ms  that one particular ms has to be alerted so  there is a paging for that ms from the bs and the ms is always listening to it so  whenever it hears the page for itself  it gets alerted so  the other is the random access channel this allows users to request a slot on the dedicated control channel if two requests collide  they are garbled and have to be retried later on so  this is the part of the call set-up so  it is the first part of call set-up it tries to put a request in the random access channel for a slot in the dedicated control channel when it gets a slot in the dedicated control channel  it can go away with the further steps of call set-up next is the access grant channel  refer slide time  33  34-33  51  in gsm the channel multiplexing is fdm + with eight tdm slots uplink is this much and channel bandwidth is200 khz so  dcs has certain frequency range etc  refer slide time  33  52-34  03  channels are broadcast and the channel rate is 13 kbps  refer slide time  34  04-34  42  we have already seen what cdma is ? it is based on ds spread spectrum  that is  the direct sequence spread spectrum it has two frequency bands  one for forward channel and one for reverse channel and one frequency band  a wide band actually that is shared that means it uses orthogonal codes by a number of handsets or number of mobile stations so  cdma allows use of same spectrum over all cells it also gives net capacity improvement although which system is better ? cdma or gsm ? is still not clear  refer slide time  34  43-35  40  there are certain issues in the cellular infrastructure  which have to be handled we will quickly discuss each of them the most important one is handoff because you may be talking on your mobile phone while moving  may be moving in a car so  what will happen is that  the car eventually will pass out of the range of one base station and move in to the range of another base station so  you have to hand off that means previously all communication from this mobile station was being handled by this particular base station  as it moves in to the area of another base station  this call has to be handed off from one bs to the other bs handoff changes of radio connection from one base station to another will happen but this not such a simple scheme and we will see why there are two types of handoff  hard handoff and soft handoff  refer slide time  35  41-36  33  this handoff has to be managed in order to manage the handoff  we have to detect that handoff requirement has arisen because the mobile station has moved and then you have to execute the handoff  in the sense that you have to do the channel assignment and you may have to do some path rerouting and there may be problems in this section also for example  when you move into a new cell  all the channels over there may be busy and so you may not have any extra channel  which has to be given to this ongoing call so  there are various schemes for handling ? may be you drop this that is the simplest thing to do  that you do not allow it or maybe you keep some guard channels specifically for these kinds of cases but this detection of handoff requirement is a troublesome affair  refer slide time  36  34-37  04  as i said  there are two types of handoff  hard handoff and soft handoff hard handoff is break before make this is used in gsm system ? that means you break this connection and set up the new connection with the bs in whose area you are moving ms connects to base station 2 after link with base station 1 breaks  and this is the region where the handoff will take place  refer slide time  37  05-37  57  the difficulties in handoff detection are the following the signal strength fluctuates this is a very challenging area of mobile system design ? the signal area fluctuates due to various reasons  scattering  reflection and diffraction results in fading there are fast fading and slow fading of the receiving signal there are false handoff requirements at the boundary ; there is a ping pong effect at the boundary that means what might happen is that it may hand off from bs 1 to bs 2  then again from bs 2 to bs 1  again from bs 1to bs 2 this kind of ping pong might be going on so  the number of unnecessary handoffs must be reduced because handoffs have a price paid  actually  keeping both channels busy on both sides there are other kinds of overheads to this  refer slide time  37  59-38  41  let us look at a very simple model actually the situation is much more complex because  there are number of base stations ? maybe three base stations and you may be equidistant from all the three at a particular point so  you may have an even more difficult problem but let us look at a simple problem suppose d is the distance between two base stations so  ideally we would like that the signal strength from bs1 is following like this and the signal strength from bs2 is going like this as you move from bs1 to bs2  as the ms is moving at the cell boundary  it just switches from bs1 to bs2 but the actual picture is something like this  refer slide time  38  42-39  44  this is the point is that the signal strength from bs1 is varying  very fast why does it vary ? i will just tell you i had just mentioned it  but i will tell it again this is varying like this the signal strength from bs2 is also varying like this so this has been plotted from  let us say  800 to 1200 region so  there is a solid region at least from 950 to 1050 there is a region of 100 m  where you really do not know who is stronger so the signal is varying all the time what might happen is that you might now decide to move from bs1 to bs2  and then you find that bs1 has become much stronger and bs2 has become much weaker so  it might switch from bs2 to bs1 and this might go on as a ping pong effect so  this is a very difficult problem  refer slide time  39  45 -41  03  and as i said  why is it that it varies in this fashion ? there are various reasons for this  one is that you are moving this mobile station is actually moving now whatever signal it gets  it may get some direct signal  it may get some reflected signal  it may get some scattered signal and all these signals may start interfering with each other so  actually what might happen is what is called multipath fading that means  the same signal may have arrived from source to destination through two different paths ? may be through two reflections ? and they may be out of phase because of the different distances  which may be allowed if they are precisely out of say  180 ? out of phase  then you are going to have distractive interference or they may be in phase ; they may strengthen each other so  in a very short span of time  as the mobile is moving  you may find a very largely fluctuating signal there are other reasons for this fading etc we will not go into the detail of this  refer slide time  41  04-42  21  so  there is a problem of handoff so  for the handoff decision there is various algorithms which have been proposed i will just mention them one is relative signal strength  which is the simplest first thing you will think that whichever is weaker  we leave that  and whichever is stronger it will chose that one so  choose bs2 if signal from bs2 is greater than the signal from bs 1 but as we saw  with just this  there may be lot of ping pong effect and lot of unnecessary handoffs you can use this same rss  that is  received signal strength  and some threshold base that means we choose bs2 if the signal from bs2 is greater than the signal from bs1 and the signal from bs1 is less than a threshold  which means that although bs2 is stronger  if bs1 is above the threshold  which is still working  then we do not do a handoff another thing is rss plus hysteresis  that is  received signal strength just being greater is not enough ; it has to be greater by a certain amount of hysteresis the hysteresis means base1 persists as the bs2 is becoming stronger in base 1 and then there are other kinds of other combinations people have tried for getting a good handoff decision  refer slide time  42  22-42  50  as i said  this hard handoff is used in gsm  whereas in cdma system  they use soft handoff this is ? make before break ? ? that means you make a connection to that coming in the next base station  before you release the connection with the previous base station so  ms connects to bs2 before connection to bs1 breaks this is called soft handoff  refer slide time  42  51-43  14  we will now discuss the merits and demerits of soft handoff merits are  mobile station does not loose contact during handoff ; the effects of ping pong are reduced ; and it is easy to implement for cdma systems the demerits are  it is a complex process so  hardware requirement is more and that means your hardware cost may also go up ; and it utilizes extra resource during handoff  refer slide time  43  16-44  22   43  16  now  we come to the question of mobility management how do you manage mobility in a local in a ms ? that is because  one of the very fascinating thing about mobile connection i have called somebody on the mobile  who i assumed is just local that is who is in the same area as i am it just so happens  that he is in a place far away he is visiting some place may be rajasthan or something ,as he is very far away now i will expect that the system would somehow locate him in rajasthan and then allow me to talk to him so  that is again a non trivial problem there are various approaches to this problem we will just once again touch on this so  this is called mobility management one is location management access point of a mobile station changes as it moves around the network coverage area and important for effective delivery of incoming cells and other is handoff management we have already talked about it  refer slide time  44  23-45  21  now  for location management  one approach through location updates that means messages are sent by ms that is a mobile station regarding its changing points of access to the fixed network so  that is to the fixed network  that is sort of time of time it tells that ok this is where some central database is updated each time the ms makes an update to its location a database in the fixed part of the network has to be updated to reflect the new location information so  that for a particular ms  if you go to the data base and find out what is the last point  where he said  that he was of course what he might have done is that he might have switched off his mobile and then moved to somewhere else and then put it on or something  so  put it on again so  that is not still solved all the problem 100 %  but this is one approach to solve it  refer slide time  45  22-46  26  the other this thing is the paging you know what is paging ? paging means that sort of broadcast it well broadcast means broadcast it everywhere we do not want to broadcast it everywhere so  you broadcast it only to certain places so what we do is that  we broadcast that there is a call for such so  that is what we page and if that paging is being done in a cell  where the ms is actually present and that the ms will respond  that is what will happen so  that is another scheme required to deliver an incoming message to the ms response from the paged terminal enables the network to locate the ms the other thing about location management is location information dissemination procedures to store and distribute the location information related to ms are serviced by the network that is the issues over that i am not going detail in any of these  as no time  refer slide time  46  27-48  03  and for the location update  you may do static location update that means initiation of location update is decided by the topology of the network and location area based location updates which is commonly used what a location area is and distance based  which performs location update after crossing certain number of cells or timer based  performs location update after a certain time has elapsed so  the question is that how frequently do you update this ? because  if collecting all the data all the time and just updating it all the time  that will consume an enormous amount of resources you have to optimize somehow that this is the point is that if we not doing frequently enough  your data in the database going to stay and then when you want to actually search for somebody  then you might have to search around a large area ideally what would you liked is that when a call is there for somebody  we know that exactly in that particular cell that mobile station is there so  we go and page over there he responds ok that is the idea but this idea will never work because  you can not keep it updated on all the time and you can not collect and keep all the information so  you have to do some kind of optimization over there  which means that you actually looking for one particular mobile you have to search not in just one cell  but may be in several cells so  that is where location area comes in that location area is collection of cells  we will come to that  refer slide time  48  04 49  02  the other is dynamic location update it uses mobility of the user and call pattern for location update so  if you know the mobility of the user and some call pattern etc  you may be able to predict that where this particular user may be it is more likely that he will be there so  it state-based  performs location update  based on the current state information such as distance travelled  the number of las crossed  etc or user profile based  which is more difficult  not exactly used at the moment maintains a list of las that is location areas that the ms located in at different points of that time usually so  usually during office hours i will be found in my office in that particular area so  that may be known and that may be a guess but then gathering this information and keeping this information for all users  this is not a mean task  refer slide time  49  03-49  58  so,this is the location area based location update so  as you see that a bunch of cells together form a location area so  this is the location area 1 containing 1 2 3 4 5 cells this location area 2 containing 7 cells and so on so  assign a location area identifier to a group of cells la 1  la2 bs broadcasts periodically la identifier so  it is enough to trying to fill a particular cell you are trying to fill it down to a location area so  bs broadcast it  whichever location it is in ms is required to listen for la identifier and make an update to the location if necessary drawback is once again  there may be ping pong effect this fellow is moving like this so  it going from location area 1 to 2,1 to 2 etc that is always the thing you can not eliminate this completely  refer slide time  49  59-50  22  location update in gsm la identity  that is it takes the location based approach identity is used for location updates la consists of a group of cells controlled by bsc and ms performs location update under 3  1  .circumstances upon power up  compares previous la identity with the one currently being broadcast if different  performs update  refer slide time  50  22-50  52   2  when ms crosses la boundary  performs update  3  after a predetermined period of time  performs update to ensure ms is available so that you do all the three things simultaneously so that would make sort of judgment about  what is this time interval  after which it will go automatically or of course  other two are simple  refer slide time  50  53-51  21   and then in for paging schemes  you can do blanket paging  that means when you know the location you just page everything all the cells paging in all cells within an la simultaneously if the la update is current  ms responds immediately advantage is minimum delay in getting paging response and disadvantage is it needs paging in all the cells within la equidistant from the current cells a timer is used to declare the ms is unreachable  refer slide time  51  22-51  39  all it could be that closest cells approach first page the cell where ms was last seen if not successful  page subsequent rings of cells that are so  this is all trying to reduce the overhead and give the maximum response time etc so,all these different schemes are there  refer slide time  51  40-52  52  and finally we will not go in to the details of these as i said that  now everybody want news on their handsets not only news they want to access  to the internet through the handsets  which means we will have to give some data service and that is why service providers also move from  noise  2g to 2.5g systems wherein from the gsm family it,the general packet radio system gprs and cdma to cdma2000 so  gprs is a really ? packet overlay ? network that means on the same network  there is a packet service  which is going on available frequency bands network on top of the existing gsm digital circuit switched voice based network so  it is tcp/ ip based the protocol based is same as the tcp ip which we will learn later it allows data packets to be conveyed across the mobile network using packet switching and it is ? always on ?  ? always connected ? type of thing and after initial ? log-on ?  user is permanently connected to the ip services  that is the gprs  refer slide time  52  54-53  22  instant access  no further log on and usually the rates also gives a flat rate user perceived performance  fluctuates  as gprs users defer to voice users   so  voice users have a preference so  because data may delay that is may be acceptable to a maximum of  noise  50kbps network resources only used when information ready to be exchanged bandwidth on demand so  more utilization of air time that is the gprs  refer slide time  53  23-53  52  so  this provides high speed frequency so  uplink is on the particular frequency band and downlink is on particular frequency band and these are all packet services which provide high speed packet data access this uses modified gsm hardware  different phones or cards  are required that is you have particular kind of set that handle gprs several time slots can be dynamically allocated to transmit a block of data so  if the packet is large  so several time slots may be used for that  refer slide time  53  53-54  25  the uplink channel is shared by a number of mobiles  and its use is allocated by a bsc  base station stream the downlink is of course fully controlled by the serving bsc and random access is not needed in the uplink of course multiple access will still because  so many people want to send the request for data the ms requests use of the channel in ? a packet random access message ?  the bsc allocates an unused channel to the mobile and sends a ? packet access grant message ? etc  refer slide time  54  26-54  49  cdma 2000 is once again is the cdma version of it increasing voice capacity once again this is always on peak packet data rate of 153 kbps which is quite high connectivity to ansi -41and gsm-map  which we need not to bother various bands and bandwidths of operation in support of different operator needs  refer slide time  54  50 55  58  it is expected that actually that  this cdma 2000 1x rtt is backward compatible with cdma1 system  which was the previous original cdma system improved service multiplexing and qos management and variable transmission rates and it is expected that in future what is going to happen is that  as data demand is definitely going to grow  so these will sort of move from these interim 2.5g system to the 3g systems i cdma is already being employed this is part of our big network architecture this converged network architecture  which is slowly emerging and in the next lecture  what we are going to do is that we are going to discuss wireless networking in the lan setup in the sense purely in this  we are talking about voice and voice added to data next  we are going to talk about data and may be data plus wires that is a separate issue thank you computer networks prof s ghosh dept of computer science and engineering i.i.t kharagpur lecturer # 30 udp and client server good day  today we will start our discussion about transport layer protocols there are two dominant protocols the udp and tcp we will take them up one by one let us look at udp in this lecture and tcp in the next one slide 1 udp stands for user datagram protocol slide 2 this is a transport layer protocol and has got the following responsibilities  first of all  it creates a process to process communication path till now we have talked about the network layer and the job of the network layer is to connect a distant machine to another distant machine so it is a machine to machine communication whereas now we are talking about process to process communication so in this particular source machine may be some application process is running which is trying to connect to the other distant machine for some job so this process has to connect to a corresponding process there which may be a particular application server on one side and application client on the other side whatever the applications may be this is a process to process communication path this also provides control mechanisms at the transport level the control mechanism in the case of udp is very minimal slide 3 udp is a connectionless unreliable transport protocol but why would we try to have an unreliable protocol ? this protocol is not exactly unreliable but it does not do anything extra for reliability making it a very light weight protocol so its overhead cost is very low in many cases it may be a very reasonable thing to have where you do not expect lot of errors or you do not really care if some error occurs from time to time in such cases you may use udp functions of udp   it only adds process to process communications to ip  performs very limited error checking  very simple protocol and has minimal overhead this is the main advantage it has very minimal overhead slide 4 when you are talking about the ip protocol you are talking about the connection from one machine to another but in this particular machine a number of application programs or processes may be running this udp protocol connects one process to another process  so does tcp and that is the job of the transport layer although udp is a connectionless protocol the job of the transport layer is to make some virtual connection or some virtual communication channel available to the corresponding processes slide 5 so to summarize   ip is responsible for host to host communication  message still needs to be handed to the correct process  udp is responsible for delivery of the message to the appropriate process actually  not only you need to understand that there is some kind of multiplexing and de-multiplexing going on in the same server a number of processes may be running and out of all those processes a good number of them may be using the same udp protocol so  when sending out a packet it is alright but when receiving a packet the udp protocol has to determine as to which process it will go to and that is one of its jobs and the other job is to make connections there is a point over here and this is a common task between tcp and the udp our computer network is mostly a packet switched network whereas as far as applications are concerned mostly they do not really bother about packets they may produce a chunk of data to be communicated to the other side they may even produce a stream of data to be communicated to the other side so it does not work with packets so somebody has to take this stream of data from the application layer and chop them into small packets and that is a job of the transport layer so  both the tcp and udp do that slide 6  udp is a transport layer protocol within the tcp/ip protocol suite  it is simpler than tcp tcp has higher overhead  it is more reliable than udp if you want to have reliability and still want to use udp then you have to take care of reliability in some other layer may be application layer or something  udp lies between the application layer and the ip layer and like tcp serves as the intermediary between the application programs and the network operations slide 7 if this is your ip datagram  the ip datagram will have an ip header and the payload for the ip would be the entire udp datagram the udp datagram would have the udp data which it derives from the application and the udp header slide 8 when a particular application wants to communicate to another application or when a process is trying to communicate to another process which is in a remote machine  in that case it will want to talk to some particular machine up to whatever we have seen  a particular machine means a particular ip address now this ip address is handled by the ip layer that means by the network layer on both the machines then how does the network layer get this ip address ? as such it is supposed to get the ip address  the destination source and destination ip address from the top but there is a transport layer between the ip layer and the application layer we are talking mostly about the tcp/ip protocol stack so we are not considering talking about osi protocol stack and presentation layer for the time being the destination ip address is known to the application but it has to be communicated to the network layer the transport layer has got nothing to do with the ip addresses therefore the application layer does communicate the source and destination ip addresses to the transport layer and the transport layer passes it on to the network layer and does not do anything with it except considering it for the check sum so this is known as ip pseudo header because this is not a real header for the udp protocol or tcp slide 9 this ip pseudo header contains the 32-bit source ip address  32-bit destination ip address and then this 16-bit udp length etc so this is the header which is passed on to the ip layer and this is in the same stack in the same machine these headers are actually meant for communication between peers that means the transport layer  the udp on this machine and the udp on that machine will communicate via this udp header so this is the proper header and the pseudo header just takes that information about ip addresses etc from above and passes it below what the real udp header uses to communicate with its peer on the other machine contains a 16-bit source port number and 16-bit destination port number remember  these were 32-bit source ip address and here these are 32-bit destination ip address there is also the port number here which we will see later we have 16-bit source port number  16-bit destination port number  16-bit udp length  optional 16-bit udp checksum which may be optional and data if any  possible odd bytes and a pad slide 10 so this is the length of the header and data therefore we have the source and destination port numbers  total length and checksum slide 11 let us go through this in detail the source port number has  16-bits  range from 0 to 65,535  port number used by the process running on the source host recall the multiplexing and de-multiplexing we discussed earlier in the same machine number of processes may be communicating and out of all these processes a good number of them may be using the same transport protocol namely udp while others could be using the transfer protocol tcp when a particular packet comes  you can see whether it is a tcp packet or udp packet once you make it out  you have to decide that out of all the processes using udp for which process is this packet meant for all these different processes are associated with different port numbers and looking at the port number the udp decides the process for which it is meant for and this is the de-multiplexing part but the multiplexing part comes with the source port number hence there is a source port number and the destination port number used by udp for multiplexing and de-multiplexing at its own level this is a number which is 16-bits long which will give you from 0 to 65,535 these are the port numbers and port number is used by the process running on the source host later on let us see in detail on how this port number is obtained slide 12 similarly  there is a destination port number   it has got 16-bits  port number used by the process running on the destination host  in most cases  it is a well known port number we will what is meant by well known port number slide 13  the length is 16-bits o it defines the total length of the user datagram  header plus data o note  maximum size of data is 65,507 after subtracting 20 bytes for ip header and 8 bytes for udp header as this is the overhead slide 14  checksum is 16 bits o used to detect errors over the entire user datagram slide 15  checksum includes three sections  o pseudoheader udp header and the data ? part of the header of the ip packet ? ensures that if the ip header is corrupted the user datagram is not delivered to the wrong host since the pseudoheader contains the destination ip address  even if the ip header gets corrupted this does not get delivered to the wrong host the pseudoheader  udp header and the data taken together forms the payload for the next layer that is the ip layer and the checksum is computed over this entire body so there is some amount of error checking and error detection done this is done by udp and this is the extent to which it will go for providing reliability beyond this if the entire packet is lost somewhere  udp can not do anything about it o udp header  there are the four fields in the header  source port number  destination port number  total length and the checksum slide 16 udp operation   it is a connectionless service  has very minimal flow and error control as given by the checksum  performs encapsulation and decapsulation and forming of packets  queuing  multiplexing and de-multiplexing let us look at these operations one by one slide 17 connectionless service   each user datagram sent is an independent datagram if an application sends one udp and is going to send another then they are handled independently in the layers below this application these two datagrams may be coming from the same source application process meant for the same destination application process  but they are going to be treated independently by the rest of the network layers first of all  it may so happen that these two packets may go in two different directions  may be routed differently because there is no connection this is completely a datagram oriented connectionless service therefore these two datagrams may travel in different paths one of them may get lost or they may get out of order which means the datagram that was sent earlier may reach the destination quite later udp is not going to take any responsibility for all these mishaps and it is taken for granted that whatever application takes place using this udp is resilient to such things  there is no relationship between different user datagrams  user datagrams are not numbered meaning that if the datagram which was sent later arrives much earlier and the vice versa then there is no way of knowing unless in the application layer itself we have taken some care to identify that slide 18  there is no connection establishment since this is completely a connectionless service there is no question of any connection establishment  and since there is no connection establishment there is no connection termination either  each user datagram can travel on a different path  only processes sending short messages should use udp usually udp is used in a case where you send one packet and that is the end of it when you are trying to the send a stream of packets or stream of bytes etc usually you do not use udp slide 19 as far as flow and error control is concerned which may be another job of the transport layer the udp does very little  it is very simple and an unreliable transport protocol  there is no flow control  the receiver may overflow with incoming messages  there is no error control except for the checksum what happens is that  suppose the receiver is getting a large number of udp packets  and if it wants to just stop or slow down to the senders it can not do that if it overflows some of the packets will get lost and then there is no error control except for the checksum slide 20  sender does not know if a message has been lost or if it has been duplicated  an error in the checksum causes a user datagram to be silently discarded this is a very simple protocol and this is very efficient and has a very low overhead slide 21 udp does encapsulation and de-capsulation which is a fundamental job of any protocol in the transport layer it has to form the packets  the packets form from the streams of data supplied by the application layer the data is chopped into pieces  a header is added to each piece and then is passed on to send a message from one process to another the udp protocol encapsulates and decapsulates messages slide 22 this is just a standard way as it goes down the stack  the message from the process  so this is the udp data  this is the udp header  then the ip header frame header etc and it is decapsulated in a similar fashion slide 23  queuing   each port has an associated incoming queue or incoming and outgoing queue depending on which way the communication is taking place a port is not just a number along with the particular number  inside the os there will be a queue of data being communicated in the machine there will be an incoming queue and an outgoing queue  udp removes message from the outgoing queue one by one  adds the udp header  delivers them to the ip slide 24 incoming queue   udp checks to see if an incoming queue exists the first thing udp does is to check whether the incoming queue exists  if there is  udp sends the user datagram to the end of the queue the particular application process is going to consume from this incoming queue the process will consume from this incoming queue which is being fed from the udp for the outgoing queue  the application process is going to put things in the queue and udp will take out the message to be communicated from the queue  if there is no such port then udp discards the user datagram and asks icmp to send a port unreachable message this means that a particular packet has come meant for a particular port and that port does not exist in this machine so it will send them an error message saying that the port is unreachable in order to generate this icmp message sometimes a packet is sent to an improvable port number so  when you get back you know that you have reached the destination but of course there is no application over there slide 25 it does multiplexing and demultiplexing  several processes may want to use the services of udp  udp multiplexes and demultiplexes to handle this slide 26 use of udp   this is suitable for processes that require simple request-response communication suppose there is a simple request which may be sent by udp and there is just one message as response to this request then that may also be sent back as an udp this also depends on the kind of network you have suppose you are communicating only inside the lan  in that case you may not like to have an overhead since this is not going over the wan therefore this is expected to be much more reliable and you may not like to incur any extra cost for providing reliability etc because you know that the underlying network is quite reliable and secondly if your process is such that there is a simple message coming and there is a simple response  in that case a simple udp protocol may be sufficient  this may also be suitable for processes which include internal flow and error control mechanisms that means  if the application process itself is handling some flow and error control  that means if it is handled at an upper layer then you do not want to duplicate it in the transport layer  in which case you use of simple protocol like udp which is more efficient because reliability is being handled by somebody else anyway so that is another case where udp is a very suitable protocol  udp may also be suitable for multicasting and broadcasting going to some specific examples  slide 27  this is used for management processes such as snmp snmp is a simple network management protocol used for managing network for managing network we have this central network management software which from time to time may probe different network boxes to see if their health is alright  collect all kinds of statistics etc so this is a simple message response kind of system it asks for queries  manages a particular device in the network by sending a message and that device responds with some statistics or some alarm or whatever it is so that is a case where udp protocol may be quite suitable  this is used for some route updating protocols such as rip we have already discussed rip for updating the routes the routers have to communicate with each other and that uses udp these are just two examples there are many other examples and user applications which may also use udp slide 28 now let us discuss about port numbers and then i will talk about client server port numbers   local host and remote host are defined by ip addresses here the host refers to the machine  a second identifier called port number is required to identify processes because many processes may be running on the same host so just identifying the host is not enough but we have to identify the process in this host or more specifically you have to talk about this process and this host so you have to have a port number as well as an ip address  in tcp/ip port numbers are integers between 0 and 65,535 slide 29  the server process requires a well known port number  the client process defines a port number chosen randomly by udp which is known as an ephemeral port number we will discuss this in more detail when we discuss more about client server this is one of the ways you write applications in a network environment by using the client server paradigm there will be different servers giving different services like you may have a web server giving you web services or mail server etc different clients could be using these services so they use different sets of port numbers this will be clear when we talk about the client server paradigm in more detail slide 30 once again  if you think about the ip address  this selects the host and then the port number selects the process when you give the destination ip address etc it reaches a particular host and in that host it looks at the port number and then selects that process using that particular port number slide 31  port numbers work as source and destination addresses for tcp/udp segments  ports ensure packets reach appropriate service on the server  the destination port field determines which service the source is requesting  tcp/ip associate ports at the transport layer with certain applications slide 32  software developers have agreed on well known ports  for example  o a packet bound for an ftp server would use port 21 just think of some network service  a web service when you are surfing the net you will use a browser and you may click on a particular url or network address and you immediately get the opening page of that particular site displayed by your browser if you think about how did this happen ? a particular site is hosted in some remote machine somewhere you may know only its ip address now  by knowing its ip address you have to make a request to that ip address  like requesting it to show the opening page now the ip address will help you through this mace of routers who may be running some routing protocol like rip  ospf so that your request reaches the destination machine but in the destination machine how does it know the port number ? you do not know about the destination machine  number of processes running etc suppose if it is a http request that means it is a request for a web page to a web server then this request has to reach the web server now there may be ten or fifty other processes running on that same machine  it should not go to any of these other servers so  for very standard applications like ftp  file transfer protocol   smtp  simple mail transfer protocol   http  hyper text transfer protocol  and so on are all applications so  for all these protocols the port numbers are fixed so  if i make an ftp request  as it says ftp server use a well known port 21 that means if i make an ftp request to any machine anywhere in the world i am going to use a port number 21 knowing that this is a well known port number and if it is reaches the destination machine port number 21 would mean the ftp server  conversations that do not involve applications with well known ports are assigned ports randomly selected from a specific range slide 33 there is an organization iana which handles these port numbers so port numbers have the following assigned ranges   below 255  0 to 255  are reserved for public applications like ftp  smtp  http etc  from 255 to 1023 these are assigned to companies for marketable applications  above 1023 these are unregulated which means that up to 1024 these are reserved this is again divided into two parts  one part for the public applications and the other for some vendor specific applications apart from well known port numbers you also need a whole lot of other port numbers take the previous example where we made an http request to a web server now the web server will send you back something  may be the contents of the first page of its website and that is going to be sent to the requester for this another port number is temporarily assigned and this is assigned from a number range from 1024 to 65,535 and the number is randomly chosen this is an ephemeral port  it is not a fixed port and it will be held constant for the duration of this communication and then it will be released for use by some other process slide 34  source port numbers are dynamically assigned by the originating host and are usually a number larger than 1023  port numbers in the range of 0 to 1023 are controlled by iana slide 35 these are some examples of well-known port numbers there are quite a good number of them but i have just mentioned some important protocols  ftp is a file transfer protocol uses port number 21  telnet  a terminal connection uses port number 23 i will be talking more about some of these application layer protocols in a later lecture there are hundreds of applications which have come up and we can not talk about all of them but we will talk about few of them towards the last part of our course  smtp is a simple mail transfer protocol that uses port number 25  tftp is a trivial file transfer  when you just have to send a short message it uses port number 69  http is the hyper text transfer protocol which is the one used for web services that uses well-known port number 80  pop3 is a post office protocol that uses the port number 110 what pop3 does is that  suppose you got mail in your mail box in the local mail server then on your desktop you can download all the mails from the local server to your machine through the post office protocol  snmp is used for network management that uses port 161 there are a whole lot of others but i have mentioned only a few which are important slide 36 now moving on to the full description of client server programming it uses what is known as a socket address socket address   socket address is a combination of an ip address and a port number  this uniquely defines each client and server process so  this process is in this machine therefore this process is given by the port number and this machine is given by the ip number slide 37 these are some of the references for the different rfcs and the udp is described in rfc 768 then there is rfc 1122 and iana port numbers can be seen in the websites mentioned here slide 38 let us see some more about client-server paradigm which is sort of universally used for network based application  server application is listener o waits for incoming message o performs service o returns results  client application establishes connection  o it sends the message to the server and then it waits for a return message in this client-server paradigm usually what happens is that  the client would initiate the request it initiates the request for some service it has to know the address of the service and if it is a well-known service then it will use the well-known port number so in that particular machine in that particular port number it will make the request and the server will accede to the request  in the sense that it will give the service and then return the result to the client and then it goes back to listening so  the server is always in the listening mode that means it is waiting for a particular request to come in slide 39  clients and servers exchange messages through the transport protocols e.g tcp or udp  both client and server must have the same protocol stack and interact with the transport layer so you may have a client server using both tcp and udp slide 40  protocols specify general operations and the api specifies exactly how it is done for using the socket there is a socket api api stands for application program interface  so the socket api is the de facto standard  origin is in the bsd unix from university of california at berkeley as part of one of the first versions of tcp/ip  slide 41 let us see a little bit about the sockets and socket libraries   this is a vendor supplied library of procedures  they have the same name and arguments as one of the socket functions  it promotes independent source code and it is usually easier to use than original sockets the vendors also provide socket libraries with some bells and whistles slide 42  socket software interface is designed to communicate between the user program and tcp/ip protocol stack internally that is the socket all tcp/ip stacks that we talked about right from the bottom one to right up to the transport layer is already in the system now you want to develop an application which should be run over the network in such a case you have to write your application program for any service you would like to give now this user program has to communicate with this tcp/ip protocol stack which is already in the machine and the intervening layer is the api for sockets so you go to this tcp/ip layer stack through the sockets  therefore socket is a data structure inside the program  both client and server programs communicate via pair of sockets slide 43 there are several significant socket domain families   internet domain sockets implemented via ip addresses and port numbers  unix domain sockets implemented via filenames  novell ipx apple talk etc all these other vendor specific socket domains are also there but the first two are the most important slide 44 there are three types of sockets   stream  it uses a tcp protocol stream socket is a connection oriented service so  naturally you can not use stream socket with udp hence the transport layer protocol to use with this stream socket is tcp  datagram  in the datagram socket there is sock datagram that uses udp protocol the type of socket determines the type of protocol it is going to use tcp or udp but this uses the udp protocol  there are the raw sockets which may be used for testing anything internally slide 45 for creating a socket you have to have a library and for accessing the functions in the library which is specifically that socket you have to include that < sys/types.h > and < sys/socket.h > assuming that you are writing in c language so you may have a function called something like this  int socket  int domain  int type  int protocol   when you give this socket call  you have to mention its domain  its type and its protocol  domain is one of the protocol families like pf_inet  pf_unix etc so these are the socket domain families we talked about slide 46  type defines the communication protocol semantics usually it defines either  o sock_stream that means connection oriented stream like tcp or o sock_dgram which is a connectionless unreliable udp  protocol specifies a particular protocol  just set this to 0 to accept the default slide 47 what happens in the client-server is  when the client is initiating a request for a standard kind of a service it knows the destination ip address and the well-known port number and this message has reached the destination machine and in the destination machine the server program always listens to that particular well-known port number so the server program is actually in a loop listening whether any request is coming in through that port number in the case of a udp server this may be simple it gets some request  it immediately gives a very short response and goes back to listening but in such a case when the interaction with the user may be prolonged  for example  the user makes an ftp request and then downloading the file is going to take quite a bit of time similarly  the user may have made an http request which means it may have asked for a particular webpage now  sending that webpage is also going to take some time of course it is always with respect to the kind of speed people are accustomed to if the communication is always through that well-known port then during the currency of this particular session between this particular client and the server that well-known port number is going to be blocked and others will not be able to get the service which is not acceptable so usually in the client-server there is a handshake so the request comes to the well-known port number and of course there is a port address which has been sent by the client from the server side the response goes back with another ephemeral port number which is not a standard port number now  on both sides you have two ephemeral port numbers that means the port number more than 1024 and they can then communicate through these two port numbers with source and destination respectively depending on from which side it is being sent so these two different port numbers are used this is happening on one side and on the other side the original server goes back to listening to that same well-known port number ready to service the next incoming request slide 48 although we have not discussed tcp as yet but so far as this client-server part is concerned both of them are very similar tcp server   sock_init    creates the socket  register port with the system  establish the client connection  accept the client connection  read/write data  close   is for shutting down when you establish the client connection and when you accept the client connection in this part all these two ephemeral port numbers are exchanged this is on the server side on the client side it creates the socket and tries to setup a connection usually in a client-server  the initiation of the connection is always from the client side then the write/read goes on and then there is a shut down slide 49 udp clients and servers are similar except that it uses sock_dgram instead of sock_stream  connectionless clients and servers create sockets using sock_dgram  connectionless servers do not call listen   or accept   and usually do not call connect    this means you may not require any specific handshake and you may not require a special ephemeral port for prolonged communication between the client and the server because in this case usually the service is to just send only one message and ending the service slide 50  since connectionless communications lack a sustained connection several methods are available that allow you to specify a destination address with every call  o sendto  sock  buffer  buflen  flags  to_addr  tolen  ; o recvfrom  sock  buffer  buflen  flags  from_addr  fromlen  ;  there is a way to specify a destination address with every call slide 51 for udp server the sequence of calls is the following   create a socket  register the port using the bind command  receive or send data  shutdown this is somewhat simpler than the tcp server and then there is the udp client that you create  send or receive and then you shutdown slide 52 there are two types of servers several clients can request service of the server in the same time in this case a server can   service one client at one time other client requests must wait this type of server is called non-concurrent the second type is   services all client requests are handled simultaneously this type of server is called concurrent this is what happens  the client ? s request for a connection has come to the server by the term server  we mean that software process which is running there and not the hardware box the hardware is also called a server but in a different sense in our context by server we mean the process which is giving the service and which is running in a particular machine if this server is non-concurrent all the user requests come and are sort of put in a queue then the server process will take one from the queue  process the service and then send the result and take the next one out of the queue so there is a queue where all the client requests are waiting and the server process takes one request at a time out of the queue this is called a non-concurrent server when you are using udp and when using sock_dgram that means you get a request  send a message and may be that is the end of the service in that case this non-concurrent server also called as iterative server is more efficient but it may also happen that  in a particular service the client server communication is for an extended period of time in this case  one particular request may block all other requests for an unnecessarily long time in that case concurrent server may be preferred in concurrent server  as soon as the server gets the request at the well-known port it immediately spawns a new process when you execute a fork  in say unique  what you get is an exactly similar piece of code to which you make some changes what you do is that you give them a new port number and let this new process communicate with this particular client ? s request and the original process goes back to listening to the well-known port another request may come from some other client somewhere else so it will again spawn another process and the original process will go back listening to the well-known port all these child server processes use different ephemeral port numbers to communicate with different clients in the strictest sense if you have only one particular processor in the server machine then only one program can run  things can not be concurrent but have to be sequential but then  that sequentiality is imposed by the way processors are scheduled by the scheduler inside the ?  so it will give some milliseconds for one process and then it gives few more milliseconds for some other process etc so it will look as if all the clients are getting the service simultaneously so that is what is meant when we say client requests are serviced simultaneously slide 53 these are the non-concurrent server sequence of calls the only thing to note is that  there is a while loop and this loop will service each request sequentially slide 54 the concurrent server uses the fork and in the fork it creates a child process which will now communicate with the client with this we come to the end of this lecture in the next lecture we will discuss the tcp protocol slide 55 slide 56 slide 57 our topic today is tcp  the second most important transport protocol it is very widely used in many applications this is a little more complex than udp but it also has some advantages we will see what they are and look into the transport layer responsibilities slide 58 if you remember the transport layer responsibilities  they  create packets from byte stream received from the application layer  in order to multiplex and demultiplex amongst various applications it uses port numbers to create process to process communications  uses a sliding window protocol to achieve flow control  uses acknowledgement packet  time-out and retransmission to achieve error control so unlike udp which is unreliable  tcp seeks to provide a reliable communication so that it is error free it is a connection oriented protocol and it also has some kind of congestion control mechanism and of course it does the basic thing of making connection between processors amongst two distant nodes possible full duplex communication  this means a is communicating to b and b is communicating to a at the same time even if predominantly only one side is sending data to the other side the acknowledgement is coming from the other side anyway slide 59  the connection can be terminated from both sides but then somebody has to initiate the termination  if connection is terminated in one direction data can continue to be sent in the other direction slide 60 four actions are required to close the connection in both directions let us assume a bi-directional connection that has to be closed  first host a sends a segment announcing connection termination which means it sends the segment contains fin you remember all the syn  fin etc  are the flag segments in the tcp segment header  host b sends a segment acknowledging the request from a after this the connection is closed in one direction slide 61  when host b has finished sending data it sends a segment indicating connection closure  host a acknowledges the request from b  second and third steps can not be combined together because although we are sort of allowing the termination of connection from one side but from the other side he may have acknowledgements or other things to send to this side so he will not terminate the connection so these two can not be combined together the third step can be taken only when host b has finished sending data from its side and it sends a segment indicating connection closure  called four-way handshaking computer networks prof.sujoy ghosh department of computer science and engineering iit  kharagpur lecture-35  refer start time 00  42-57  33  good day the topic for today is congestion control  refer slide time 00  48-02  00  slide 00  48-02  00 the performance of a computer network depends on a large extent on the kind of congestion that is there in the network once again this is a large topic we will just touch upon some aspects of them one thing we know by now is  in general network  may be data network or inter network in particular although multimedia and other contents are coming in  this is a packet based network and a large data network that is announced where we make only the best effort of delivering a packet now  what exactly do you mean by best effort ? most of these best efforts depend on how you handle congestion  refer slide time 02  01-02  38  slide 02  39-04  18 so  we know what congestion is when too many packets are pumped into the system  congestion occur leading into the degradation of the performance congestion tends to feed upon itself and backs up congestion shows lack of balance between various network components moreover it is a global issue because the congestion may happen in some intermediate router because of packets being pumped from various sources  so in that sense it is a global issue  refer slide time 02  39-04  18  slide 04  19-04  45 we have this intermediate node or channel etc and the demand is in the form of various sources pumping in packets at various rates namely ? 1 to ? n and this is being serviced by the channel capacity or the router capacity at the rate ? and going to the various destinations the problem is  the demand outstrips available capacity so this is basically the congestion problem and added dimension to this problem comes from the fact that although these ?  ? etc are coming from the general queuing theory and for simple queuing theory these are the arrival rate and service rates etc although queues are there  but in general the statistics which the data networks follow are rather complicated so traditionally telecom networks would follow some poisson distribution with exponential interval time but in data network it is seen that it follows something called as a self similar traffic or heavy tail distribution and that is a complex distribution one of its key features is bustiness that means data tends to come in busts and then there is comparatively long quotient period and again another burst comes so  that is the problem which has to be handled and when several bust arrives at a node at the same time that particular node may get overloaded  refer slide time 04  19-04  45  slide 04  46-05  43 so  if information about ? 1  ? ? etc is known in a central location where control of ? n and ? effected instantaneously with zero time delays then the congestion problem is solved unfortunately we can not do that because we have incomplete information and we require a distributed solution with time varying time delays this is what makes the problem a little difficult  refer slide time 04  46-05  43  slide 05  44-06  12 already we have seen this kind of throughput versus load curve we have seen already when we saw alocha networks  ccna cd etc but  in general this is what happens as the load increases the throughput also keeps on increasing at the same rate and then it starts sort of going down and it keeps going down because of the intermediate delays and other bottlenecks coming into the picture and then there is an area where the throughput does not increase any longer if you increase the load beyond that there is a catastrophic fall in the throughput so this part is known as the knee and this part is known as the cliff and this catastrophic fall is called congestion collapse  refer slide time 05  44-06  12  slide 06  13-06  42 so  knee is the point after which throughput increases very slowly and delay increases fast cliff  point after which throughput starts to decrease very fast to zero and this is congestion collapse and delay approaches infinity note in an m/m/1 queue delay = 1/  1 utilization   it does not follow this kind of a simple formulation  refer slide time 06  13-06  42  slide 06  43-07  03 if this was the previous curve and as you plot the delay  the delay is low in the beginning and starts increasing and in this area where there are lots of packet losses and there is a congestion collapse and there are throughput collapses the delay also becomes very high and it becomes a hyperbolic curve so obviously you have to take all precautions not to fall into this area  refer slide time 06  43-07  03  slide time 07  04-07  45 so  we talk about congestion control whose goal is to stay on the left of cliff that means not to go into the congestion collapse congestion avoidance  goal is to stay left of the knee and right of cliff is of course the congestion collapse region  refer slide time 07  04-07  45  slide time 07  46-09  15 so  the goal of congestion control is to guarantee stable operation of packet networks and a sub goal is to avoid congestion collapse to keep networks working in an efficient manner  for example  high throughput  low loss  low delay high utilization are the goals not always achievable especially because we have distributed systems with insufficient information about the global picture but anyway that is there  refer slide time 07  46-09  15   slide time 09  16-10  47 to provide fair allocation of network bandwidth among competing flows in steady state so  there has to be some kind of fairness  sometimes all are not taken as equal first of all you must see  if there is congestion at an intermediate node  what would happen is that there would be lot of packet loss over there so  various packets from various sources would be lost and the delay would become high many of them were running a tcp protocol therefore the question is who would again start retransmitting hence what would happen is that  more packets would be lost and more and more packets will keep on getting pumped this is just like a traffic jam  it starts at one place and then if the jam does not resolve soon then it becomes bigger and bigger and it starts getting pushed towards the source so the overall network throughput goes down and people tend to push more packets these are the kinds of scenario we would like to avoid  refer slide time 09  16-10  47  slide time 10  48-13  18 now  there are various policies at various levels that we can take for congestion control let us look at the data link layer  the open loop policies one is retransmission policy how would you retransmit ? one example of this re transmission policy is  suppose you have a ethernet network with csmacd going on and then you have detected a collision  the question is  are you becoming persistent or non persistent or you do a random back off or exponential back off or what is your retransmission policy hence you will try again similarly there are other things like out of order policy out of order policy is when you receive a packet when it is out of order acknowledgement policy is  do you acknowledge or do not acknowledge it for example  if you have an acknowledgement then the acknowledgement for each packet also takes up resources so  if you acknowledge every packet then there is going to be as many packets sent as many acknowledgements therefore this is a lot of acknowledgement for the network and there is a high overhead may be you take a policy of not acknowledging all the packets it could be some kind of a flow control policy therefore we have seen some kind of flow control in tcp we will look into more details and variations of it  refer slide time 10  48-13  18  slide time 13  19-14  25 in the network layer you can have the virtual circuit versus datagram this is an important issue and we will look at it in more detail when we discuss qos and multimedia communication suppose there is a very important communication going on between two hosts  mission critical or whatever it may be  now they will be exchanging a lot of packets let us say the packets are flowing in only one direction so lot of packets will be sent and we want some premium service for this if you want to give a premium service to this particular pair of nodes  may be they pay more or something then in that case you have to distinguish among the packets and assume that they form some kind of a flow so you need to have a kind of virtual circuit between these two points in order to distinguish them if all packets are on their own then that is a different kind of a situation where it will be more difficult to distinguish the flow between the two specific nodes virtual circuit versus datagram may be an important issue once again we will see more details of this when we look at rsvp  diffsservent in the qos when we discuss qos a little bit more in detail packet queuing and service policy means  in the router a number of packets may come and they are going to be serviced one by one and they are going to be put in a queue now the question is  do you put them in one queue or do you put them in several queues ? do you have the same priorities for all the queues or do different priorities for different queues and so on packet discard policy has to do with the buffer management of the router if the buffer becomes full  which packet do you drop ? routing algorithm  what kind of routing algorithm will you use ? packet lifetime management  this means the lifetime of the packet is over and you drop the packets these are important in the network layer so far we were discussing about open loop polices  refer slide time 13  19-14  25  slide time 14  26-15  26 now let us take a look at closed loop control this means monitoring the system to detect when and where congestion is occurring pass the information to places where actions can be taken adjust system operation to correct the problem this is more sophisticated and better the point is  if one router in between is congested and now if it can identify the chief sources of trouble where it can not handle a lot of packets  therefore if you could send a feedback back to the source so that he can control this behavior by sending less number of packets then the situation can be handled or you can adjust some system parameters  may be the window size in tcp etc these are the examples of the kind of thing you can do with close loop control  refer slide time 14  26-15  26  slide time 15  27-16  07 if you say that there is some congestion then we need to have some metrics for measuring congestion some examples are percentage of all packets discarded due to lack of buffer space this may be one measure average queue length in the buffer no of packets that time out and are retransmitted average and standard deviation of packet delay these may be metrics with which you measure congestion so  if these metrics go beyond a certain level then you might decide that some congestion is taking place and you need to take some action in order to prevent the performance degradation in a sharp manner  refer slide time 15  27-16  07  slide time 16  08-16  44 feedback mechanisms  it can be many as we have mentioned  router on sensing congestion sends a control packet to the source a bit in every packet can be reserved to announce congestion explicit probe packets can be sent to ask about congestion implicit algorithms make only local observations  refer slide time 16  08-16  44  slide time 16  45-17  56 then you can try adjusting system operations adjust time constants to a near optimal value decrease the load selectively if possible may be if one source somehow can decrease then all the others can be served very well because it goes below a threshold increase resources if possible  this is usually difficult   refer slide time 16  45-17  56  slide time 17  57-18  29 now  let us look at the one aspect of congestion control which is very important and which is done by tcp all the time tcp congestion control  if you remember uses a sliding window protocol we have a window and a sender can send right up to the window size to the other side and it will wait for acknowledgements and he will keep on acknowledging and once he gets the acknowledgement the window will slide this is about the basic tcp what we are going to see now is some variance of tcp since tcp is a very important protocol and application protocols like ftp  stp  etc use tcp  a lot of important traffic on the net is actually carried on tcp and that is why whatever we do at the tcp level is very much important and one of the chief tool for doing any congestion control by tcp is by adjusting the window size so  there are various variants  refer slide time 17  57-18  29  slide time 18  30-19  16 tcp has a mechanism for congestion control the mechanism is implemented at the sender the sender has two parameters  congestion window with a variable called cwnd and slow start threshold value with a variable called ssthresh so  initial value is the advertised window size so  with a tcp connection there is an advertisement of window size and this window size is taken as the initial ssthresh value  refer slide time 18  30-19  16  slide time 19  17-20  06 congestion control works in two modes one is slow start and the phase is slow at start when the cwnd value is less than ssthresh and congestion avoidance means that cwnd value is greater than equal to ssthresh so  basically we are trying to figure out whether we are on the left of knee or in the right of the knee so  if you are on the right of the knee but left of the cliff we are going to be careful if you are on the left of the knee and if things are going fine then we can try to increase the load stress to increase the overall throughput this is the basic idea  refer slide time 19  17-20  06  slide slide time 20  08-21  17 knowing initial values in a slow start i.e set cwnd = 1 naturally if the window size is small i.e one so one unit will go and the acknowledgement will come back and then only something else will go from this side that is why we are being very conservative and we are sending only a small bit of information note  the unit is a segment size i.e one of a second tcp is actually based on bytes and increments by 1 mss  maximum segment size   the receiver sends an acknowledgement  ack  for each packet so this is the slow start so  the receiver must acknowledge every packet  so the first packet it receives it can send an acknowledgement note  generally a tcp receiver sends an acknowledgement  ack  for every other segment  refer slide time 20  08-21  17  slide time 21  18-21  35 each time an ack is received by the sender  the congestion window is increased by 1 segment so what happens is that  the sender has sent one packet so it has got the acknowledgement  so actually the sender decides that things are fine and may do better that means it is the increase in congestion window size  cwnd   so we increase cwnd by 1 i.e cwnd = cwnd + 1 we make cwnd = 2 if an ack acknowledges two segments cwnd is still increased by only 1 segment that means for every ack it increases by 1 if it acknopwledges onlys one segment or two segments then cwnd is increased by one only actually the reason to acknowledge every other segment is to decrease the number of acknowledgements now  even if ack acknowledges a segment that is smaller than mss bytes long cwnd is still increased by one so  at anytime you get an ack you increase cwnd by one when you are in the slow start phase although it starts slowly does it increment slowly ? not really in fact  the increase of cwnd is exponential  refer slide time 21  18-21  35  slide time 21  36-22  24 the congestion window size grows very rapidly  cwnd rises very rapidly for every ack we increase cwnd by 1 irrespective of the number of segments ack ? ed the tcp slows down the increase of cwnd when cwnd > ssthresh   refer slide time 21  36-22  24  slide time 22  25-23  00 as you can see  suppose if it sends one segment it receives one acknowledgement  the cwnd is increased from one to two now you can send two segments  segment two and segment three it will get back the acknowledgement for segment two and acknowledgement for segment three now cwnd has become 4 it will send 4  5  6  etc  so three of them it has sent and the acknowledgement for 4  5  6 will come now cwnd has become 7 and it will send more you can see here  1  2  4  7 is increasing quiet fast because for each acknowledgement it is increased by one and when you are sending so many segments at a group you will get many acknowledgements therefore cwnd is increasing exponentially  refer slide time 22  25-23  00  slide time 23  01-23  21 congestion avoidance phase is started if cwnd has reached the slow start threshold value  ssthresh   if cwnd > = ssthresh then each time an ack is received  increment cwnd as follows  i.e cwnd = cwnd + 1/  cwnd  where  cwnd  is the minimum or the larger integer and is smaller than cwnd so this is only increased by a fraction while sending of course you will not send a fraction and whatever be the current cwnd value that is floured that many segments you can send  refer slide time 23  01-23  21  slide time 23  22-23  42 so  cwnd is increased by one only if all cwnd segments have been acknowledged that means  if all the cwnd have been sent or acknowledged  then cwnd increases only by one so we are very cautious while we move to the right of the knee  refer slide time 23  22-23  42  slide time 23  43-24  26 so  assume that ssthresh is 8 therefore what will happen is  round-trip time = 2  4  6  etc as time is going so cwnd is first increased exponentially it reaches the ssthresh value and then it increases slowly  refer slide time 23  43-24  26  slide time 24  27-25  02 tcp assumes there is congestion if it detects a packet loss now  what is the response to congestion ? tcp assumes that if congestion detects a packet loss a tcp sender can detect a lost packet via timeout of a retransmission timer or receipt of a duplicate ack duplicate ack has been received which means that previously may be some acknowledgement has been dropped and there is a duplicate ack so  when something is dropped it means that there may be congestion now there are different ways to respond to this congestion  refer slide time 24  27-25  02  slide slide time 25  03-25  20 one is  tcp interprets a time-out as a binary congestion signal which means there is congestion as soon as there is a timeout therefore when the sender performs cwnd is now reset to one i.e cwnd = 1 so once again it becomes very conservative ssthresh is set to half the current size of the congestion window ssthresh = cwnd/2 before sending it to one whatever be the cwnd value you divide it by two and make it the new threshold value and enter the slow start again  refer slide time 25  03-25  20  slide time 25  21-25  36 so initially  cwnd is equal to one i.e cwnd = 1 and ssthresh = advertised window size new acknowledgement  ack  is received  if  cwnd < ssthresh  / * slow start * / cwnd = cwnd + 1 ; else  refer slide time 25  21-25  36  slide time 25  37-25  58 congestion avoidance cwnd = 1/cwnd + 1/cwnd cwnd = cwnd + 1/cwnd if there is timeout it is multiplicative decrease i.e ssthresh = cwnd /2 and cwnd = 1  refer slide time 25  37-25  58  slide time 25  59-26  32 this is the typical plot of cwnd for a tcp connection  mss = 1500 bytes  with tcp tahoe  tcp tahoe is one flavor of tcp we have been discussing we will discuss about some other flavor also so  if cwnd goes on increasing  decreasing and then after sometime again increasing while things are good then this may be a typical plot  refer slide time 25  59-26  32  slide time 26  33-27  36 tcp tahoe uses one flavor  slowstart for every acknowledgement congestion avoidance that means only beyond the ssthresh it increases slowly fast retransmit in tcp reno there is also another version of tcp uses fast recovery and then there are some versions like new reno  sack,red  etc  refer slide time 26  33-27  36  slide time 27  38-28  42 acknowledgements in tcp  receiver sends acknowledgement  ack  to sender acknowledgement is used for flow control  error control and congestion control in error control if the acknowledgement is not received then you send a retransmit in congestion control we find that ack is used for controlling this ack number sent is the next sequence number expected delayed ack  tcp receiver normally delays transmissions of an ack for about 200 ms because it allows the packets to arrive thinking that it can send less number of acknowledgements this way  and acks are not delayed when packets are received out of sequence i.e a little out of ordinary  may be they came from two different paths  so you do not delay the ack but send it immediately  refer slide time 27  38-28  42  slide time 28  43-29  50 now fast retransmit  if you remember that the tcp reno uses fast retransmit if three or more duplicate acks are received in a row  the tcp sender believes that a segment has been lost this means acks have come meaning some earlier packets are gone this means  possibly the later packets or segments may be lost so what it does is  without waiting for the timeout to occur for this particular segment which has been sent it assumes that it has been lost and it sends one more again tcp performs a retransmission of what seems to be the missing segment without waiting for a timeout to happen and then it enters slow start that means it brings down the multiplicative decrease of ssthresh and sets the cwnd to one i.e ssthresh = cwnd/2 cwnd = 1 this is fast retransmit  refer slide time 28  43-29  50  slide time 29  51-30  18 in fast recovery the slow start is avoided after a fast retransmit that means after a fast retransmit intuition duplicate acks indicate that data is still getting through or at least the duplicate acks are through after three duplicate acks set retransmit lost packet  i.e decrease ssthresh to half so ssthresh = cwnd/2 but cwnd = cwnd + 3 and then you enter congestion avoidance so increment cwnd by one for each additional duplicate ack this is a fast recovery but then after this you enter the congestion avoidance that means  basically this is trying to tune the performance of tcp to get the maximum throughput without causing any congestion when ack arrives that acknowledges new data cwnd = ssthresh after that we enter the congestion avoidance so this is fast recovery  refer slide time 29  51-30  18  slide time 30  19-30  42 tcp reno  for duplicate acks it does fast retransmit and fast recovery fast recovery avoids slow start and if there is a time-out you retransmit and go to slow start tcp reno improves upon tcp tahoe when a single packet is dropped in a round-trip time but if multiple packets are dropped then of course the tcp reno can not handle that and for that we have a tcp new reno  refer slide time 30  19-30  42  slide time 30  43-30  58 when multiple packets are dropped reno has problems partial ack  occurs when multiple packets are lost a partial ack acknowledges some but not all packets that are outstanding at the start of a fast recovery  takes sender out of fast recovery the sender has to wait until time-out occurs  refer slide time 30  43-30  58  slide time 30  59-31  42 in new reno partial ack does not take sender out of fast recovery partial ack causes retransmission of the segment following the acknowledged segment new reno can deal with multiple lost segments without going to slow start  refer slide time 30  59-31  42  slide time 31  43-32  07 there is a selective acknowledgement  sack   here you can selectively acknowledge in an original tcp when you give an acknowledgement  that is the next segment you are expecting and all segments before that are acknowledged here you can give selective acknowledgement stating that you have got all these but not that particular one issue  reno and new reno retransmit at most one lost packet per round-trip time selective acknowledgement  the receiver can acknowledge non continuous blocks of data that means sack selective acknowledgement of 0 to 1023  1024-2047 and so on  refer slide time 31  43-32  07  ; slide time 32  08-33  12 multiple blocks can be sent in a single segment tcp sack enters fast recovery upon three duplicate acks sender keeps track of sacks and infers if segments are lost sender retransmits the next segment from the list of segment that is deemed to be lost like fast retransmit  refer slide time 32  08-33  12  slide time 33  13-33  43 to improve the performance of tcp  there are two competing demands here one is that we have to maximize the throughput and if you can maximize the throughput  naturally the overall delay  congestion etc will be small and at the same time you will get your job done faster but in order to push this maximum throughput we should not get into congestion  a collapse so we try to guard against that these are the versions or various flavors of tcp for doing that so  we have looked at tcp now we are going to look at some other topic once again associated with congestion control and the other one is traffic engineering that means  can you shape or can you handle your traffic in a particular way so that congestion is less likely to occur  refer slide time 33  13-33  43  slide time 33  44-34  00 all these build to give a quality of service in a network and at routers these may depend on packet classification and packet scheduling at network entrance it may depend on traffic conditioning at routers or somewhere in the network you may do admission control between hosts and routers you may do signaling so these are the different components of qos of a network  refer slide time 33  44-34  00  slide time 34  01-35  02 so  let us say you have a sender and receiver here  these are the intermediate routers then you can do the traffic conditioning at the edge of the network you can also do admission control here or somewhere else so  these are the different components  refer slide time 34  01-35  02  slide time 35  03-36  56 traffic conditioning mechanisms at the network boundary need to enforce that traffic from a flow does not exceed specification so  we will look later at what kind of specifications we are talking about  what kinds of things people may agree on  or negotiate about that what are the parameters but suppose from some source we had negotiated certain parameters and we find that the source is not sticking to that parameters and it is going out of that then we have to do some policing so  policing is a drop traffic that violates the specifications the specification as was agreed between the service provider and the sender shaping means the buffer traffic that violates specifications marking means mark packets with a lower priority or as best effort  if the traffic specification is violated  refer slide time 35  03-36  56  slide time 36  57-38  10 let us look at traffic shaping first regulating the average rate of data transmission allows control algorithms to work better so this is to be understood as i mentioned earlier  in computer network specifically data networks or internet traffic etc they are inherently very bursty in nature when it comes it comes in one big bunch and then for long periods there may be no traffic now the trouble is  if the burst peak to the average ratio may be as much as 1  1000  we have to accordingly design your buffer and other network provisioning so  we have to decide upon whether we are doing it for the peak or doing it for the average or may be doing something in between as designing for the peak if you design it for the peak everything works fine but that becomes very expensive and not practical in many cases you can not do it for the average also and that may be to lower so it may be somewhere in between therefore one inherent problem is the burstiness of the traffic now  if you could somehow make the burstiness smooth  then all your system will work much better one way of doing is to buffer it somewhere.the shape of the traffic is related to some statistics about data transfer rates as well as its sensitivity to error  delay jitter etc  refer slide time 36  57-38  10  slide time 38  11 one famous algorithm is the leaky bucket algorithm it is a single server queue with a constant service rate if you have a bucket which is leaking drop by drop that means water will come out at a constant rate therefore the same thing happens here if you have a single queue and then you service it at a constant rate this is the rate at which you are pumping the data into the network so  if there is a burst then it will get absorbed in your buffer at the edge so that in the core of the network the burst will not come and it will be more of a steady kind of a flow a steady average kind of flow is also something beyond the capacity of the intermediate nodes then of course the capacity of the intermediate nodes has to be increased that is the leaky bucket algorithm in short so the input buffer allows a bursty flow to be smoothed out to an even flow onto the network it may be implemented in hardware or the os operating system it may be implemented either in hardware or software  refer slide time 38  11  slide time 39  04-39  58 underutilized slots are written off by this what we mean is  the packets are being serviced by this network at a particular ray  let us say once every t unit of time now after another t unit of time it will try to service and finds that the buffer is empty so it will not send anything again after t unit of time and if something has arrived by that time it will send one packet the algorithm can work on the volume of the traffic rather than number of packets only problem here is  a somewhat slow response time for inherently bursty traffic which is quiet often in the node  refer slide time 39  04-39  58  slide time 39  59-41  19 one way to handle a little bit of burstiness is by a token bucket this again improves the throughput a little bit and it can accommodate burstiness to a certain degree we can not allow all kinds of burstiness because then the burstiness will flow into the core of the network where it will be more difficult to handle so this is the token bucket  it limits the input to specified burst size  b  and average rate  r   so traffic sent over any time t < = r * t + b  also know as linear bounded arrival process  lbap   so there is bound on an arrival process excess traffic may be queued  marked or simply dropped  refer slide time 39  59-41  19  slide time 41  20-41  44 so  tokens are generated for the buffer at a fixed rate which can be accumulated so this is the main point where is the token differs from the leaky bucket in the leaky bucket the underutilized slots were written off but here if your time comes you can get a token and you can collect and accumulate so many tokens and then when a burst comes up to that many tokens can be sent .the longer time average is helpless because there is a limit to the number of tokens you can really accumulate because after that you can not accumulate tokens anymore and at the same time a little bit of burstiness is allowed if your source is inherently bursty  and if you can allow some amount of burstiness that will improve the throughput so  for each token only one packet can be sent but tokens can be accumulated up to a certain maximum a variant is to allow k bytes per token essentially it allows bursts up to a regulated maximum length that is maximum number of tokens a leaky bucket may follow a token bucket also in order to make it absolutely smooth  refer slide time 41  20-41  44  slide 41  45-42  18 so this is the diagram  the bucket holds up to b tokens and there are so many tokens per second accumulating there and when a packet burst comes then it waits for the tokens if the tokens are not there then it can not send but if the tokens are there depending upon as many tokens that are available the tokens are removed and the packets are sent into the network  refer slide time 41  45-42  18  slide time 42  19-43  08 now having talked about this  let us just mention what are the kinds of traffic parameters that are important or that may be negotiated between the sender and the network service provider one could be maximum packet size that defines how big the packet is the token bucket rate  defines what the average rate is token bucket size defines how burst it will be maximum transmission rate tells us the exact maximum transmission rate  refer slide time 42  19-43  08  slide time 43  09-43  39 loss sensitivity  is this flow very sensitive to losses if you are just doing some file transfer it will be sensitive to losses  but if you are sending some voice it may not be that sensitive loss interval  at what interval it is a loss  if the loss is very bursty or if the loss has to be averaged out  etc burst loss sensitivity  packets   in terms of the number of packets minimum delay noticed  and maximum delay variation which are allowed these are again very important for multimedia traffic quality of the guarantee  is it just a best effort or better than the best effort is what it tells about these are the flow specifications of services  refer slide time 43  09-43  39  slide time 43  40-44  06 we will come to admission control and signaling in more detail when we discuss rsvp in the next lecture when we disscuss qos and multimedia traffic but just to mention it here  admission control is a function that decides if the network has enough resources admit new flow if enough resources are available reject the flow otherwise  refer slide time 43  40-44  06  slide time 44  07-44  20 you do some reservation of capacity through some protocol like rsvp which we will discuss later and if you find that you can reserve the capacity for this kind of flow that is the flow with these kinds of parameters then you admit it but otherwise you do not admit it this assumes that we have some kind of a virtual circuit  refer slide time 44  07-44  20  slide time 44  21-44  48 there may be distributed admission control instead of central admission control at the beginning for example  it may be end to end delay which must be less then than a delay bound d so calculate d1  d2  etc and you reserve resources  refer slide time 44  21-44  48  slide slide time 44  49-45  12 and what would you do is  the d is specified by the source and as it travels some reservation signal it calculates the delay d1  d2  d3 etc and if d < d1 + d2 + d3 then you reject the flow and if it is greater then you accept it send reject message to sender and release resources therefore if d > d1 + d2 + d3 accept flow  commit resource reservation and notify sender  refer slide time 44  49-45  12  slide time 45  13-45  39 some signaling protocol is used to reserve and release resources and to do admission control so you reserve one mbps that the request goes through  refer slide time 45  13-45  39  slide time 45  40-47  01 so  this is a congestion control in virtual circuits one approach is admission control  not allow new vc till congestion goes away or route new ones around problem areas other is  negotiate flow specification when new vcs are set up this requires resource like buffer space  bandwidth etc  and reservation along the way this may waste resources  refer slide time 45  40-47  01  slide time 47  02-47  59 one topic we mentioned earlier is the tcp ip source quench or sometimes called as choke packets this may be used as a crude mechanism for handling congestion each router monitors each output line and calculates the utilization as a weighted sum of current and past utilization above a certain threshold a choke packet with the destination is sent to the source and the original packet is tagged and sent along on receiving a source choke packet the source is supposed to reduce the traffic to that destination by some percentage if that happens and if it works then that is very fine when congestion is detected the source is sort of distributed and they are remote to each other so  if you could send this feedback instantaneously then you could control the congestion much better but that is not possible you have a distributed algorithm where you work only with some local information and something that might come along with some particular packet   refer slide time 47  02-47  59  slide time 48  00-48  16 the source waits for some time before acting again on the next choke packet because there may be multiple choke packets coming therefore for the same burst it has created ripples of congestion along the way and all the routers sending choke packets so multiple choke packets does not necessarily mean these are independent but they may have come because of the same source so it waits for sometime before acting on the next choke packet for high speed lines with a lot of hops  choke packets to the source is too slow so  choke packets may operate hop by hop thus by distributing the pressure on buffers these choke packets add to the network traffic and it operates hop by hop thus distributing the pressure on buffers  refer slide time 48  00-48  16  slide time 48  17-49  42 scheduling  this is another way to handle congestion  refer slide time 48  17-49  42  slide time 49  43-51  17 packet scheduling has to be done by deciding when and what packet to send on output link  usually implemented at the output interface suppose you have some switch or some router or network node and a number of packets are coming out so what you might want to do is to classify these packets in this context this could be the worst effort there are premium services and other kind of services etc and the rest are the best effort for with the rest what you may have is that you may have various classifications for these flows which may go into different queues and then there is a scheduler which schedules as to which queue to be serviced next a scheduler has a vital role to play on the kind of services on each of the packets at the micro level and each of the flows in general at a higher level they get  refer slide time 49  43-51  17  slide time 51  18-52  33 typical internet queuing  in internet queuing what we do is  we use fifo + drop tail what is fifo ? fifo is  first in first out it is a simplest choice and is used widely in internet this first in first out implies single class of traffic which is essentially means that we have a single queue so whoever comes in first  he is the one who would be attended first for servicing this fifo has to do with scheduling and there is a drop tail which means the arriving packets get dropped when queue is full regardless of which flow it belongs or regardless of its importance so  if the buffer is full whoever comes next will be dropped so fifo has to do with the scheduling discipline and drop tail that is the drop policy has to do with the buffer management this means how much of your buffer is kept empty or whether you allow the buffer to get full or whom you drop out when the buffer gets full etc are some of the buffer management policies now let us look at scheduling actually the scheduling policy and the buffer management policy always go hand with hand and the buffer management policy always come in pair  refer slide time 51  18-52  33  slide time 52  34-53  35 fifo issues  in a fifo discipline  the service seen by a flow is convoluted with the arrivals of packets from all other flows so there is no isolation between flows and no policing send more packets and get more services we have one single queue so whoever is pumping in more packets into it he is more likely to be serviced of course  you will lose some packets also but other people will also lose some packets but in some sense it favors somebody who is pumping data at a higher rate so he gets more service or may be he requires it or it is just some kind of a row node you do not differentiate between different flows at all there is no isolation between the flows if there is a flow which is very important but sends less number of packets he will get much lesser service compared to the one pumping lots of packets so that is the issue with fifo  refer slide time 52  34-53  35  slide time 53  36-54  02 drop-tail issues  routers are forced to have large queues to maintain high utilizations  that is a problem larger buffer implies larger steady state queues or delays so the delay is more synchronization  end hosts react to same events because packets tend to be lost in bursts so what happens is  when the buffer gets full  different packets coming from different sources would be dropped so  all the sources would know that the packets may be timed-out or something so they would act again in unition and this acting in unition is always bad  then you take another step which again is wrong in some way  this makes it become more bursty lock out  a side effect of burstiness and synchronization is that a few flows can monopolize the queue space so these are the drop-tail issues  refer slide time 53  36-54  02  slide time 54  03-54  11 priority queuing  classes have different priorities  and class may depend on explicit marking or other header info  for example ip source or destination  tcp port numbers  etc transmit a packet from the highest priority class with a non empty queue this has preemptive and non preemptive versions this is the kind of scheduling policies we have  refer slide time 54  03-54  11  slide time 54  12-54  27 so  routers must be able to classify arriving packets according to qos requirements this is known as packet classification and packets are transmitted in order to meet the qos requirements which are known as packet scheduling  refer slide time 54  12-54  27  slide time 54  28-54  41 you have class a service which is very premium class b services and class c services are also there you might attach different priorities to different queues and serve them that way  refer slide time 54  28-54  41  slide time 54  42-55  22 so  each router must implement some queuing discipline queuing allocates bandwidth and buffer space  so bandwidth tells which packet to serve next  scheduling  and buffer space tells which packet to drop next  buff management   queuing also affects latency  refer slide time 54  42-55  22  slide time 55  23-57  33 one thing which is very widely used is weighted fair queuing router maintains multiple queues for each output line one for each source the queues are serviced in a round robin fashion instead of packets the volume can also be examined and packets sent in order of their finishing some sources can be given a greater weight than others the point is  even if you do not give a greater weight  then the service which is premium  may be much less number of people might be there so  since the round robin is between the queues  automatically those which have the premium class get a better service since the population is low  refer slide time 55  23-57  33  slide time 57  43-57  51 use a few bits in header to indicate which queue  class  a packet goes into  also branded as cos lower delay and low likelihood of packet drop for high end users priority  round robin  classification  aggregation etc are the different mechanism which we use with this we come to a sort of the end of short handling of this congestion control issue  it is not a very easy issue because as we know this is a global problem but you have to take some local action so that it works fine in the next lecture we will take up quality of service  quality of service as we have already mentioned today  we have different kinds of quality requirements for different sets of people as i mentioned that if you are transferring a file  you do not want any bit to be lost because it may be a very vital bit so it may be a binary or a source or something that the whole thing may become junk if you lose one bit  it is very difficult and if it goes in a jerky fashion or takes longer time then you may not mind so that is one kind of quality you require another kind of quality you might require is  when you are doing some kind of multimedia transmission like audio  video  etc where i may sort of be insensitive to a few packets or a few bits being lost here and there but if the delay is too large or keeps on varying too much then i have a problem with the quality of reception so that is a different kind of quality so how to handle different kinds of quality and how multimedia transmission etc can take place in a network etc would be the content of our next lecture thank you refer start 57  34 good day  so our topic for today is qos and multimedia  that is  refer slide time 57  43-57  51  slide time 57  52-58  43 quality of service and multimedia  we will just look at these one by one  refer slide time 57  52-58  43  quality of service  what is quality of service ? qos refers to traffic control mechanisms that seek to either differentiate performance based on application or network operator requirements  or provide predictable or guaranteed performance to applications  sessions  or traffic aggregates it talks about a lot of things the basic notion is that there are some applications which require one kind of quality of service the quality of service may mean different things but the most important of them are the network delay and packet loss  so it is delay and various ways of delays computer networks prof sujoy ghosh iit kharagpur lecture no 1 emergence of networks & reference models  refer slide time  00  36  good day i am professor sujoy ghosh of iit kharagpur  i teach in the computer science and engineering department  i will be taking this course on computer networks we will be having about 40 lectures in the series today  we will start with an introductory lecture  which is about the emergence of computer networks  its brief history  and a little bit about the protocols and reference models  which is an abstract view of computer networks the text books for the course will be these three  computer networking  a top down approach featuring the internet by kurose data and communication by william stallings and computer networks by a s tanenbaum some of the material that we will be covering here verbally as well as in the slides  will be from these books the first question is  what is a computer network ? computer network is a number of computers  also know as nodes  connected by some communication lines we have these computers  which are connected by some communication lines two computers connected to the network can communicate with each other through other nodes if they are not directly connected  which means that computer does not have to be connected to all the other computers in the network in order to communicate with any of them it may be an indirect communication via some other computer and other point is that these nodes are computers but some of them are not computers ; some of them are network devices there are various kinds of network devices like switches  routers etc  so  they facilitate the communication and running of this entire network they are also taken as nodes in the network finally  we have some of the nodes  which may be either computers or they may be network devices like switches and routers and there is a communication between them this communication  refer slide time  1  28 -2  30  can be of various types ? we will come to that presently the computers can communicate with each other what do they communicate ? they exchange information between different computers  this information could be of any kind of information ? they could be data used by a program or they could be some program itself or it could be any kind of information this is one of the basic and major uses of computer networks there are other specialized uses of computer networks for example  interconnected  small computers can replace a large computer for example  you have a very large computation to perform and so for that either you need a very powerful and very large computer  which is very costly the other option could be that you break up this work into very small pieces and assign them to the small computers the small computers do the computation on that small chunk of the problem  and then they communicate with each other to form the final solution the other use of computer networks  which is coming into vogue very much these days  is that you can use this network as a communication tool for example  you can send emails to almost anybody these days  and that is really a very cheap and very fast mode of communication secondly  the computer networks could also be used for direct communication like you could communicate through voice over a computer network  you can communicate through video over a computer network all these different communication is converging into this computer network and nowadays when we talk about the network we do not look upon it just as a computer network it is the bedrock on which  all these computing communication are converging and then you have some applications  which are necessarily of distributed nature for example  railway reservation system ? now obviously if you had a large computer to handle all the railway reservations in the world in one place but we would not want all the people to go to one place and form a huge queue so  we want to distribute this functionality that means what that of booking tickets all over the country these are the examples of distributed systems so this is a distributed reservation system similarly  there could be other kinds of distributed systems  distributed databases and all kinds of applications  so that is the other application of networks  refer slide time  3  30-5  59  now  a quick look at the history of the computers first  then we will focus on computer networks in 1948  we have the first commercial computer installed ; it was a univac ? that was a big company once upon a time  and then in 1958  the first us communication satellite became operational the network always has these two component  one is that you have to have these computers and then you have to have these communication channels and satellite communication is one of the important medium of communication in 1964  we have an airline reservation system  which uses some kind of a packet switching network ; it was proposed by the rand corporation ; and in 1969  arpanet  the first packet switching network began its operation this was actually a water shed event as we will see this have been very far reaching impact on the way computer networks developed  refer slide time  6  51 -8  03  in 1971  we have the first computer chip  previous computers were made through very low level gates and all but the first four-bit small computer chip with 2300 transistors and they became available in 1971 in 1972  ethernet specification was formulated ? this ethernet is one protocol ? and ethernet remains one of the most important network protocols that we use so that was first formulated in 1972 in 1974  ibm introduced its own version of network in sna in 1975  altair 8800  the first commercial microcomputer  was sold as a kit  refer slide time  8  17-09  18  in 1975  we had paul alan and bill gates getting together who eventually formed microsoft in 1976  woznaik and jobs built apple1 so apple also has lot of contribution to make to computers in various aspects and windows system was basically started from apple computers in 1979  we had visicalc first commercial spreadsheet ; this is the popular application of computers these days  refer slide time  09  18  10  07  in 1981  ibm introduced ibm pc with one floppy drive ; later on they changed it with drive and hard drive ; and in 1983  tcp/ip is another network protocol that we are using we use both ethernet and tcp/ip protocol we have different protocols  which we are running on the network and how this different protocols are arranged and how they are used that i will cover today in second part of the lecture so  this tcp/ip is another important protocol that is still very much prevalent today ? that became the official protocol of the arpanet arpanet is the network  which was set up in usa under the drdo and which had a very far-reaching impact on the way the network developed in 1984  apple introduced gui with apple macintosh and 1986 we see the first laptop pcs  refer slide time  10  09 ? 11  07  in 1988  ibm gives a multitasking os for the pcs in 1989  microsoft releases windows  which is yet another multitasking system that is the microsoft version ; in 1989  nsf  national sound foundation of usa replaces arpanet as internet backbone and then www was invented by cern physicist tim burners lee in 1991 so this advent of www  world wide web  made the network very popular there was this kind of positive feedback going on  as it became more popular  more and more people jumped into it  as people showed their interest  so commercial companies also became interested because there would be a market for something in the networks that they do and when the commercial companies developed something  naturally it became more easier to use the network ; they had more functionalities ; so more people became interested  that was the positive loop actually the growth of network in the past decade ? in the 90s ? has been absolutely phenomenal the basic so called killerapp  application which attracted so many people to networks was this www which was invented in 1991  refer slide time  11  08 ? 12  48  in 1992  mosaic released first gui web browser  so that was the web browser ? then netscape became the popular web browser  microsoft had its own version of microsoft explorer  that was an another browser and then it all built up into some kind of a frenzy and in 2000  we had this .com  so-called .com meltdown that means people became absolutely frenzied about the growth of computers and such a frenzy can not go on forever so it has to come to an halt so  it did in 2000 but the development of networks and its utility and importance remains  refer slide time  12  48 ? 13  33  now  let us go to a brief history  more focused on the network itself we were in general talking about the computer scene in mid-1960s  usa ? s department of defense wanted a command and control network that could survive a nuclear attack if something had to survive a nuclear attack then you had to distribute it so that was the one strong reason that we wanted a distributed system and if you have a distributed system  these systems must be able to communicate so that was the seed of this project the subnet should consists of some honeywell 12 kw intermediate message processors so there are some kind of early network devices  which are connected by 64 kbps lines these imps ? intermediate message processors ? are connected to the various computers and the imps themselves were connected by telephone lines from telephone companies  refer slide time  13  34  14  36  later  the imp software was changed to terminal interface processor  which allowed the connection of terminals in the 1970s  nsf setup a machine connected to the arpanet to which other universities could dial up and connect now  this became very important in the sense that many people were interested in this so they upgraded their systems in various ways in mid-1980s nsf built a new backbone to connect with super computing centers to some regional networks its backbone  refer slide time  14  37  15  17  was upgraded to 448 kbps and then to 1.5 mbps fiber backbone  and once this fiber backbone was in place  communication became really fast so it allowed network connection to thousands of universities  research labs  libraries  museums  etc as the growth continued  commercial houses began to notice and to join  the decentralized model began to take hold  refer slide time  15  18 -15  45  as i described earlier  commercial people joined so there was a lot of innovation by a lot of people one of the major driving forces in the computing networks in the past decades or even now may be has been the role of so-called start up companies start-up companies means that some young engineers or some young people who had some very bright idea which they developed to a certain extent and when that was proven and then some big company would possibly buy their company or give them money to get access to this kind of technology there was so many success stories that a lot of people got interested in it and when a lot of people think about a problem  there is a lot of innovation so that is how computer networks had an explosive growth in the whole of 90s and even in the 21st century and the growth is going on although the frenzy in the stock exchanges  etc about these .com companies crashed in a 2000 but the growth in the field of networks and its use in various walks of life  is continuing with this brief historical background  now let us come to the networks and some kind of structure or some kind of an abstract view of this computer network i have already mentioned that computer networks will be a number of nodes and nodes could be computers or network devices  which are connected by some communication lines sometimes things are not so simple ; sometimes you have a line between two nodes  giving us point-to-point communication that means one node a is communicating directly to one another node b  where a and b are connected by a direct line  it could be physically a copper line or fiber line  etc this point-to-point connection could be the simplest case but actually it is dedicated and in the dedicated case also we have some different cases for example  you could have simplex communication ; it means that communication can go in only one direction in that line it could be half duplex  it means the communication could go both ways either way from a to b or from b to a  but only in one direction at a time  and full duplex  that a and b can communicate with each other simultaneously  in parallel  at the same time so that means there is communication from a to b and b to a at the same time .these are some different kinds of dedicated lines then if the nodes are not computers  some network devices  specifically  if they are multiplexers  we could share a point to point medium that means there is one line from a to b but a is connected to a lot of other nodes say  a1  a2  to an and b is connected again to a lot of other nodes say  b1  b2 to bn and they could all these ais and bis could communicate through this one single line  which is between a and b  this we will see later how such a thing can be done this business of sharing a link over time or whatever even parallely sometimes it is possible sharing this link by multiple people is called multiplexing these are the different kinds of point-to-point links but point-to-point links are not the only things we have for example we could have a broadcast kind of link ? if we have a satellite communication  satellite throws its signal all over the country or may be all over the region that is something  which is being broadcast so you can not really put it down as a point-to-point link between something  but you could use that shared medium and a broadcast in some way to make temporary point-to-point links or your application may be such that you want to broadcast something for example  we broadcast tv signals ; similarly there are things  which we want to broadcast all over this broadcast media can be dedicated to some users or it could be shared ; that means it is shared between multiple users there the term used is multiple access medium  to which different users are connected at different points and it is a broadcast kind of medium in a distributed fashion  they have some protocol of deciding how to share this because if it is in the same place  the business of sharing becomes somewhat easier so you can multiplex it if nodes themselves are physically distributed over the broadcast medium you will have some kind of protocol called multiple access so you can have a shared broadcast medium also ; that is quite common finally  we have something which is in between broadcasting and point-to-point  which is called multicasting  this means that if we have a group  i have  say  some friends and i want to send some things not to one particular friend but to my group of friends and to no others ? so multicasting is basically communicating to a specified group  refer slide time  15  46  22  21  using such communication link  we have this computer networks networks are divided into local area network  metropolitan area network  and wide area network local area network means that it is local  limited to maybe one building or small group of buildings so its size is small there are some other things about local area network  which make the issues of local area network somewhat different from a larger area network and the local area network usually could be privately owned now how does ownership come into picture ? ownership comes into picture because if you have the same owner for the entire network then you can have the same policy  which is not the case in wide area network in wide area network there may be various nodes which are connected to this wide area network the nodes may belong to very different people and they may have very different ideas about what should be done and all their policies that makes wide area networking somewhat different from local area networking metropolitan area network means a network which is spread over a community or may be even a city  their size is bigger than local area networks and one of the issues which is very important is the access issues  which means that how do you connect ? for example  you want to make the entire community networked ; so how do you connect each one of them because they are geographically more distributed then a local area network local area network may be sometimes we would use validers or sometimes we would just simply draw valve and the cost will not be very prohibitive but in local area how we connect the people becomes an issue that is the access issues we have talked about the wide area network wide area networks are costly they are communicating over may be hundreds or thousands of kilometers the communication is costly  the cost has come down and that is another thing  which has historically happened as more and more people got interested in network  technology developed that is one side of the issue the other side of the issue is that volumes went up ; which means that the number of people who used network so as the volumes went up the cost went down so the technology improved in one direction that was one input into bringing down the cost and the other issue was that more and more people started using it so the volume to a particular company developing something in the network area went up and they could make things cheaper and as the whole thing became cheaper and cheaper  more and more people wanted to join the network wide area network cost is still an issue wide area network  may connect various local area networks  so its a network of networks or internetwork or internet  refer slide time  22  26  26  17  let us look at the abstract idea about the networks in general in formal framework  we have what are known as protocols  why do we need protocols in network ? we need protocols in networks because networks by their very nature  might connect various different people as i said various different people may have very different ideas about how things have to be done if people have different ideas about how things have to be done then they have to agree on some common basis to communicate and this common basis is the protocol there are numbers of protocols  which are used in network and we will be getting into that you and i may have very different ideas about how some particular thing may be done i may be doing this in a certain way and you may be doing the same thing maybe in a completely different way but if we want to communicate we have to agree on some minimum protocol these protocols are the building blocks of this network architecture so each protocol object has two different interfaces ? one is the service interface that defines the operations on this protocol and peer to peer interface which defines messages exchanged with peer for example  any protocol  a protocol is between peers so if in this diagram there are the two lis are the peers and they communicate with each other through this peer interface ; that is the protocol this protocol is supposed to achieve something  supposed to do something for this it requires something maybe from some other called layer actually we have a layered architecture  i am coming to that in the next slide how this protocol is to be invade etc for this we have a service interface and between the peers we have a peer interface  refer slide time  26  18 to 28  50  we have all these different layers  we have this n + 1 th layer  n th layer and n  1 th layer how they are to be layered ? about that also there are some standards and we just look at two of them at least for example  this networking business is broken up into whatever the jobs you have to do for achieving for smooth functioning of computer networks we break them up into different functionalities and these functionalities are in different layers this is all in one place  that means in one node similarly  another node  which is connected to the network  will have its own layers and at the same level n and n here they are peers so there will be a protocol between this n and n  there will be a service interface between n + 1 th layer and n th layer similarly  there may be a service interface between n th layer and n  1 th layer and so on  refer slide time  28  51 -30  02  so let us see what they are like as i said most networks are organized as series of layers the task of each layer is to give some service to the upper layer and any layer maintains a virtual connection with the corresponding layer in a peer any layer maintains a virtual connection ; this virtual connection is used for running the peer-to-peer protocol  whereas this is the service interface the task of each layer ? each layer performs certain subtask of this whole networking business  so each layer performs some task ? is a service to the upper layer similarly for performing this task  it may break it up into some subtask and some subtask may be delegated to a lower layer this layer could have its own service interface to the lower layer whereas its own task  assuming that the subtask is done by the lower layer  is performed at the peer-to-peer level  using the corresponding protocol  refer slide time  30  03  31  15  there is peer-to-peer protocol running between any two corresponding and communicating layers the interface between the layers in the same node is well defined another point is that for this peer-to-peer protocol mostly they go through a virtual connection what is a virtual connection ? virtual connection means that physical connection ; we understand let us say two computers are connected by wire it is not necessary that two computers have to be directly connected in order to communicate ; it may be an indirect connection also that means it is going from one computer to another then  it is hopping from node to node then  it is finally reaching its destination  and so there is no direct physical communication when you are surfing the internet  you have been connected to some computer  which may be connected to opposite part of the globe so  to you it appears that you are directly connected to that computer so whenever you are clicking something over here  something happens so that clicking of the mouse somehow that gets communicated to that remote web server and may be the page changes or something there seems to be a direct communication but this communication is only virtual the physical communication is only at the lowest layer  where physically something is connected by a piece of wires or fiber optic links or by satellite links whatever it is  that is the physical connection for running all these protocols  these peers need to communicate and this communication is through virtual connection this is the main point of having this layer architecture  that the implementation of each layer  each node is transparent to the other two nodes as i said  i may want to do this one particular subtask in some particular way ? i means some company x ? and then some company y wants to do the same thing in a different way now you need not stop any of them so long as they agree on the protocol  so long as they agree on the service layers what is the service interface between the different layers ? because upper layer service may be given by some product of some company  whereas the lower layer may be developed by some other company once again if they can decide on the interface between these two layers  then they are very free to do it in their own way the same thing applies to the peers for example say two particular layers in two particular nodes may be peers  these nodes are computers themselves now  one may be an ibm machine another may be a sun machine and they will have different operating system  they will have different processors etc but so far as the peer to peer protocol is concerned  they agree so these are the messages i will send and then if i am expecting these kinds of answer  these kinds of messages  i will accept and these kind of answer will be given etc  so that is how a protocol goes so long as they agree on this protocol  these two companies are free to develop their product in their own way and when you allow that naturally  people can innovate  people can put in different things so long as you are conforming to the standards of the protocols and the interfaces  etc  you can develop your own thing in your own way and that is really good for the development of the entire network the other point is that this is one way of abstracting out all these unnecessary details for example any of this network operating system in a computer or a networking device  they may be very complex indeed some of the complexity is special to the implementer one implementer has decided to implement something in a particular way and that will have a whole lot of details we are not really interested in that one  we have to abstract out of that we concentrate on these protocols and the interfaces and the functionalities ; that gives us a fairly general picture about the entire networking  how networking is done and then if you go into the business of developing some of these modules yourself  then you have to go into some more nuts and bolts about how this service can be given the protocols between the peer layers can be changed if the peers all agree naturally if you are changing the protocol  all the peers have to agree ; otherwise the communication will breakdown however  it need not be referred to other layers ? so that is another good thing about layering ; that is whatever change i make it will not matter and the service definition says what the layer does and nothing else  means nothing about the specifics of implementation  which may vary from one vendor to another the interface tells the process about how to access it ; it specifies what the parameters are and what results can be expected  refer slide time  31  16 ? 37  57  we have mentioned the three layered models  the most famous is the osi reference model which we will look into in some detail and then tcp/ip reference model which is most widely used osi reference model mean some part of it is very somewhat theoretical because many people really do not do that and it is that they do not consider that part to be very important tcp/ip reference model is something which is almost ubiquitous and of course there is atm  it is one networking technology which is rather complex technology ; as i mentioned here just as an example ; so that is another kind of reference model there are all kinds of different reference models  sometimes these models are basically a description of the different layers that are there ; and naturally if you talk about the layers  what the layer is supposed to do and that is what you see and then how it is to be interfaced with the layer above and layer below since this is number of layers  one on top of other  they are also referred to as stacks we call about this as tcp/ip stacks  osi stacks  atm stacks and so on other protocol stacks exits and new ones are possible however the extent to which a particular model is universally accepted is the key to its success as i said a lot of thought went into osi reference model but in practice tcp/ip became much more prevalent  refer slide time  37  58-39  36  osi reference model has seven layers and these layers are ; application layer  the presentation layer  the session layer  the network layer  the data link layer and the physical layer  which means that in order that people can communicate over this network in a very seamless manner  all the jobs that are involved have been broken down into seven parts so they are different layers ? application layer is something and then presentation  session  network  data link and physical layer each layer has some kind of functionality and all these functionalities together give you the overall functionality in the network  refer slide time  39  37-40  24  little bit more about peer-level communication  messages sent from one application to another application on different host  travels down to the layers of the sending machine and each layer adds a header to be used by its corresponding peer level and the bottom layer  which is the physical layer  sends the message to the tcp machine ; this is the general scheme the point is that suppose we start something at the very top  in the case of osi  we call it the application layer some communication has been initiated at the application layer this application layer  mind you  has its peer in the destination machine in the destination machine also some application layer program is running for example let us say you are doing a telnet kind of thing  that means you are logging on to another machine  telnet to another machine so you will start a telnet program  which is your telnet client program and the destination machine will respond to a telnet client who will respond to telnet client ; only a telnet server can respond to a telnet client telnet server is under the remote machine these are the two modules which are in the application layer how telnet is an example of a protocol ? this is an application layer protocol and what this protocol does  how the telnet client will request and how the telnet server will respond etc are the internals of telnet protocol so far as the telnet client or any of these application program is concerned ? when it tries to communicate with another application program in another machine ? it just knows about this protocol and how things have to be done at that layer but how this communication be able to go from this machine to another machine ? for this  if you put the whole thing in the same program that becomes very complicated ; that was the idea of layering so give him a virtual connection  he will communicate to the target machine  he will have some data to send that will add up maybe to other kinds of data and then hand it over to the lower layer in the same node the lower layer may be running a protocol with the corresponding layer in the remote machine for that protocol it needs to do communication  for that communication what ever message has to be sent here that gets added to the original data  which was sent by the application layer as the message to be sent moves down the stack from the originating machine at each layer  each layer is running its own protocol with its peer and it has some message to add to give to his pair so  they will keep on adding it to this and this becomes fatter and fatter as it goes down as it goes down to the physical layer  there it can communicate to the remote machine and in the remote machine this is now again moved up the stack and at each layer that particular program or whatever that module in that layer  he will pick out the message which has been sent by its peer in the source this is how communication will go on for all these protocols  refer slide time  40  25-44  06  sending a message is received on the receiving side  then passed up through each layer and each layer reads the corresponding header that means the corresponding header which has been sent by its own peer on the source machine  refer slide time  44  11-44  32  for example  we have two machines  and one machine is a dos machine that means some dos is an old operating system which used to run on the pcs and this was microsoft dos  pc dos  ibm dos  etc and macintosh was a different company as i mentioned so  these two can still communicate  that means two different machines but this original data which was originated from the application layer there is the presentation layer and this presentation layer will add its own header to the original data this whole thing becomes data for the next layer  namely  the session layer session layer will add its own header so as i said  that the original data becomes fatter and fatter and fatter till it comes to the physical layer at the physical layer  data is actually sent in one hop  to the destination machine here  as this whole fat packet travels up  each layer will strip off its corresponding header which is coming from its peer in the source that is how the each of the peers can communicate and each of them has a virtual connection with the destination machine  although the actual connection is the physical connection  refer slide time  44  34-46  07  these are the seven protocol layers and now we are going bottom up first is the physical link  which is how to transmit the bits then we have the data link layer ? that is how to transmit frames now what is the difference between transmitting bits and transmitting frames ? we will see to that ; but a data link basically is a direct connection that is  how two computers which are directly connected or two nodes which are directly connected to each other how they will communicate is the matter of data link computers need not be directly connected to each other in order to communicate ; they have to be connected to the network if there are two machines a and b or two nodes a and b which wants to communicate and there is no direct link between a and b  so it may go as c d e and then b now  how do you know you have to go through c d and e and then to reach b ? somebody has to keep track of the route how to route the packets over the entire network ? that is the job of the network layer then there is the transport layer that is how to send packets to the application packet is some data which has been segregated and put into a packaged together but the original application layer need not have any concept of packet ; somebody has to packetize all these data and there are may be other functions in the transport layer that is they make packets out of the data given by the upper layer  this is a transport layer the session layer  which manages the virtual connection between in the application layer it manages the virtual connection the presentation layer that means how we encode and decode messages that means two different machines may have two different ways of encoding things so  that is the job of the presentation layer as well as the security comes here application  so whatever the actual job the human user is interested in comes in the application layer  refer slide time  46  08-48  42  the application layer contains a variety of protocols ; it depends on what you are trying to do the various users may want to do various things ; examples are ; ftp  telnet  smtp  http etc so these are names of some protocolsm by the ftp protocol  what u can do is you can download files from another machine  by http  you can look at web pages  surf etc and smtp is used for sending mails you may not have come across these protocols directly but the point is whenever you are sending a mail  let us say from a unix machine or something  you are using the smtp protocol  so smtp protocol has been built into that similarly  even if you are telneting that means the telnet sever  telnet client etc  they will be there in the machine as part of the os so  the application layer usually  request reliable and cheap connection to its peer that is what the application layer is concerned about  that it must be connected reliably and cheaply to its peer some examples of peers we have given some nodes given service etc  refer slide time  48  43-50  00  application layer hands this  whatever it has to send to the presentation layer which handles the format of the data  protocol conversion  data translation with its ascii or may be some other big or something and data compression  data encryption  these are handled in the presentation layer  refer slide time  50  00-50  22  in the session layer  it allows the application on different computers to share a connection we will see about this connection later on i go to the next layer we will see that i will packetize this data but then so far as the user is concerned  he wants a continuous connection this connection is handled in the session layer so it can provide check points ; that is if there is come disruption  you can come back to it and get the original state back and then you can retransmit if there is some distance ? dialogue control  who can transmit etc  refer slide time  50  22-51  01  the transport layer  the basic function of the transport layer is to accept data from the layer above  split it into smaller units if necessary now  why we need to split ? that we will come to later on so these are the packets pass these to the network layer and ensure that the pieces all arrive correctly and in the right order at the other end for example  you have chopped them into pieces ; they may have become out of order that is the business of the transport layer that should also be done in a cheap and efficient manner and etc and the same thing applies  refer slide time  51  01-51  33  there may be different types of transport services  there may be multiple protocols here one could be error-free  point-to-point channels or it could be a very cheap kind of channel or broadcasting of messages to multiple destinations so these are the different types of transport service  which are possible  refer slide time  51  33-51  56  network layer decides on what route to take locally  so that the intended message ultimately reaches the destination it controls the broadcasting by essentially segregating the different networks  etc it handles technological mismatches so we will get into the details of this later on  refer slide time  51  56-52  12  it does congestion control  it handles billing information etc  refer slide time  52  12-52  20  the data link layer makes the physical link layer appear like a channel that is free of transmission errors actually in the physical layer there may be error but the data link layer handles this error correction etc at the very lowest level  refer slide time  52  20-52  33  finally  at the lowest level we have the physical layer  where the data is actually transmitted as raw bits  etc  refer slide time  52  3-52  41  the other layer is tcp/ip reference model  where the session and presentation layer are not there we have the application layer  transport layer  network layer or maybe something like the data link or the physical layer  refer slide time  52  22-52  52  so the rough correspondence is something like this ; we have the tcp/ip model where we have just this few and we have the osi reference model with so many so more or less  they match the essential functions match there are other kinds of protocols  which are also used but the tcp/ip and osi  are the most common in the next class  we will be discussing the different structures of networks so  today we just had an abstract view of networks and in the next class we will handle different structures  refer slide time  52  52-53  25  preview computer networks prof  sujoy ghosh iit kharagpur lecture 2 network topology  refer slide time  53  57  good day in this lecture we will discuss the network topology now what do you mean by a network topology ?  refer slide time  54  00-55  20  we just have a quick recap of what we had learnt last time  basically a computer network  could be a number of nodes which are connected by some communication links there is some kind of graph  this graph has certain structure so when we talk about the structure  this structure has an implication about how will go about communicating as i said it is in general not feasible to have one to one communication between each pair of nodes that is not possible at all  so what kind of structure ? that is why the nodes connected in each manner is the subject matter of our discussion today a network may be represented as a graph  nodes representing computers or network devices like switches  routers etc and the links represent communication links modes of communication may be broadcast or point to point we have discussed this  refer slide time  55  25 ? 55  35  first let us talk about the lan topologies lan  the local area network and the local area network topologies are three they are very common ; star  ring and a bus refer slide time  55  49 ? 57  20  first of all  we first take up this bus topology and why do you take up a bus topology ? this a very simple kind of network which is based on a shared broadcast links we still want to look at point to point communication  that means there may be so many nodes a  b  c  d  etc  which are connected to the network and a wants to communicate to b so c  d  e are connected but a specifically wants to communicate to b each pair of communicating nodes used a link for the short time so  a uses the link for the short time to send his message to b then may be c might sends something to b or something like that other nodes ignore the communication since  this is shared broadcast link all the nodes get the communication  that is not private in that sense all the nodes get that communication but they usually ignore this communication whereas b will copy this for its own purpose now  they has to be a distributed protocol to decide who gets to use the link there has to be some protocol otherwise if a wants to communicate with b and b wants to communicate c  as c wants to communicate with d their communications will go and collide in that shared broadcast medium  so the communication of both the pairs of node will get garbled so by that i mean and sometimes actually that would happen that things will get garbled but that is not what we computer networks prof  sujoy ghosh lecture # 2 network topology  refer slide time  00  53  good day in this lecture we will discuss the network topology what do you mean by a network topology ?  slide reference time  01  04  01  14   refer slide time  01  15  02  33  we can just have a quick recap of what we have learnt last time basically a computer network could be a number of nodes  which are connected by some communication links there is some kind of what we usually call a graph representing the network this graph has a certain structure we talk about the structure this structure has an implication about how will we communicate i said it is in general not feasible to have one-to-one communication between each pair of node that is not possible at all so  we need a structure formed by the nodes connected in some manner that is the subject matter of discussion today so a network may be represented as a graph nodes may represent computer or network devices like switches  routers  etc and the links represent communication links modes of communication may be broadcast or point to point  refer slide time  02  34  02  49  first let us talk about the lan topologies lan is the local area network and local area network topologies are  star  ring and bus we will just look at all of them  refer slide time  02  59  04  30  we first take up this bus topology as this is a very simple kind of network this is based on a shared broadcast link we want to have point-to-point communication there may be so many nodes a  b  c  d etc  which are connected to the network a wants to communicate to b ; a specifically wants to communicate to b so each pair of communicating nodes uses the link for the short time so a uses the link for the short time to send his message to b after that is over may be c might send something to d or something like that so other nodes ignore the communication since this is shared broadcast link  all the links are shared by all the nodes for the communication hence that is not private in that sense so all the nodes get that communication but they usually ignore this communication whereas b will copy this for its own purpose there has to be a distributed protocol to decide who gets to use the link ; otherwise  communications will collide in that shared broadcast medium the communication of both the pairs of node will get garbled but we want a  b and c  d to get clear signal so there has to be some distributed protocol to decide who gets to use the link  refer slide time  05  12  05  59  now let us see bus topology what do we require ? the simplest thing is a single cable a single cable connects all the computers it is as if the computers are hanging from the single cable each computer is connected to this shared cable so computers must synchronize and allow only one computer to transmit at a time as per a protocol but as such  the network is very simple network with a single copper cable  refer slide time  06  00  06  26  so this is the picture of a bus we have this shared cable and computers are somehow connected to this so a will communicate to b b will simply broadcast over this medium b will capture it c  d  e  etc will all ignore this  refer slide time  06  27  08  25  the network is maintained by the single cable cable segment must end with a terminator otherwise  what will happen is that when some node  let us say a sends a signal on the cable not only c  d  etc will get it but it will get reflected from that other end if it is not properly terminated so it becomes a kind of unwanted noise in the medium which we do not want so the coaxial cable is used there are two types of coaxial cables traditionally used one is a thin coaxial cable called thin lan and the thick coaxial cable called thick lan and extra stations can be added in a daisy chain manner this technology is sort of getting outdated at the moment you still have maybe some thin and thick lans here and there but mostly people are moving out of this and the main reason why the people are moving out of this is because this connection is likely to become loose and as soon as you have a loose connection you will have a problem in communication there are some other reasons also why this technology has become obsolete these days but still if you have shared medium  i mean the technology of using a single cable with a single broadcast medium and some machines are sharing so this something like a bus topology  refer slide time  08  26  10  23  the standard which is used on this bus topology is ieee 802.3 actually what we do is to eliminate that cable and replace with something else we will discuss that later thin ethernet is the name of the technology when we use thin coaxial cable ? we call it 10base2 in this 10 stands for that it has a 10 mbps speed whereas 2 stands for the maximum range of segment length of 200 meters the maximum number of connections is about 30 devices four repeaters may be used to a total cable length of 1000 meters if you want to have a very long cable  what will happen is that  as the signal travels down the line  the signal will get weak and as the signal gets weak you have to regenerate the signal and one way to regenerate the signal is to use a repeater over there the repeater will simply take the incoming weak signal  amplify it and send the stronger signal down the line the maximum number of nodes that you can handle here is about 150  refer slide time  10  24  11  03  thick ethernet  which is the other version where you use a thick coaxial cable called 10base5  also has the same speed of 10 megabits per second but length up to 500 meters so they were used for backbones that are limited to 500 meters with a maximum of 100 nodes per segment that is somewhat more than a thin net and a total of four repeaters of 2500 meters that is also somewhat more than thin net  refer slide time  11  05  12  42  now the bus topology has both advantages and disadvantages it is very inexpensive as you have a simple cable it is easy to add stations you can have another punch on this cable and add new station that means a new computer the amount of cable it uses is also much less and may be  it works well for very small networks it is of course no longer recommended which means you will not get these parts any longer it is getting out of fashion because it is unreliable this is much less reliable than the technology that we have today the other disadvantage is that the limited number of devices that can be attached it is difficult to isolate the problems if there is a problem  then the whole network is down sharing the same cable slows the response rates  refer slide time  12  43  13  30  now we come to direct point-to-point communication that means this is not shared so this is some kind of a dedicated point-to-point communication so computers are connected by communication channels that each connect exactly two computers they are dedicated for this pair so this forms either a mesh or a point-to-point communication  and thus a complete graph we will come to that later this is some point-to-point network that means there is a dedicated link between some pairs of nodes it allows flexibility in communication  hardware  and packet formats and also provides security and privacy because communication channels are not shared  refer slide time  13  52  14  25  with point-to-point network  the network will look somewhat like this we have these two nodes or three nodes may be connected like this if we have four nodes and we want to interconnect everybody then we require six such cables as the number of nodes goes to n the number of cables you require is going to be nc2 which is n  n  1  /2 which is approximately equal to n2 which means the number of cables and the total length of cables that is involved are really increasing but the kind of cable which is usually used is not as expensive as the previous thin lan or the thick lan at the same time the amount of cable that you require becomes very high hence this kind of structure is not really recommended for a local area network suppose you have  say  10 nodes in a network and you are connecting everything to everything that means every node to every other node and length of the cable for some reason  let us say  is not an issue but then each node will be connected to 9 other nodes this means that in this particular computer you will require 9 ports to which these cables will be connected but that is not so easy to provide and this is another reason why  in a local area network  this kind of mesh topology is not recommended we have an alternative for that  refer slide time  15  55  16  02  we are coming to that alternative another reason why you can not connect everybody to everybody else can be illustrated thus  suppose there are two different buildings now the length of the cable will really become enormous because if you have n cables on one side and m cables  n nodes on one side and m nodes on the other side  you have a total of m ? n number of cables which are running between two different buildings it is lot of cables really so if we want to reduce the number of communication channels we have to  refer slide time  16  34  17  18  basically give up the idea of communicating directly in a lan it means that necessarily we share the connections among many computers there are ways of doing this by multiplexing here the computer takes turns in a very orderly fashion that is called time division multiplexing and it also must include some technique for synchronizing the use that means whoever wants to use that shared channel has to wait for his turn  refer slide time  16  34-17.18  we now come to this other topology  which is very common these days it is star topology a star topology looks like this there is a central hub  the centre of the wheel is called a hub  and a number of nodes are connected to this hub i may at this stage mention that there is a physical topology and a logical topology this is a star topology because it looks like a star its physical topology is that it looks like a star sometimes the hub is made in such a way that still this is a shared medium what is the advantage of converting to what was previously a bus ? it has some practical utility in the sense that  although the length of the cable is more in this case  the cable is a different kind of cable the cable connections are much better they do not get disconnected very often furthermore when you bring all the connections together centrally  you can handle the connections at one central point whereas  if you have a long running cable  it will be difficult to locate loose connections we will have to find out failures by going around so that becomes a bit difficult so the physical star topology still maintains a logical bus topology  which is an important thing otherwise this hub or the central node may not be a shared medium at all this is often the case these days  refer slide time  19  49  20  49  of course the previous star diagram is idealized usually you will have something like this you have this hub somewhere and then you have these different computers connected and there is a number which is written over here  rj-45 connector which is the kind of connection which has become almost ubiquitous these cables are something like the kind of cables which connect your telephones they are called utp cables or unshielded twisted pair cables they are basically easier to handle and are also cheaper these connections go on to the rj-45 connectors on both sides they are much more reliable than the previous thin lan or thick lan but the physical diagram may look something like this  refer slide time  20  50  21  36  you can have an extended star topology  which means different stars may be there  which are connected in some manner that means the hubs in those stars are connected and those hubs may be shared but may not be shared medium at all they may be what are known as switches these switches are connected if you look at this diagram  you have these different switches and from each switch we have a star connection to the different computers and the switches are connected in some fashion you can call this also as a star this is called extended star topology  refer slide time  20  50-21  36  you may have a hybrid topology some part of the network may be on a shared medium some part  maybe  is not shared and even in some part  you could also have a coaxial cable running  leaving a thin lan or thick lan although that is becoming less common these days  refer slide time  22  04  23  03  now we come to another topology  which is also very important topology  called as ring topology in ring topology  computers are connected in a closed loop this has a lot of advantage the way it works is that the first node passes the data to the second node ; the second one passes the data to the third and so on the data will go on hopping around the ring and what will happen is that  as it reaches the destination  if it will go around in a loop  it will surely reach the destination at some point of time the destination will copy the same in practice there is a short connected cable from the computer to the ring ring connections may run past offices with connector cables to sockets in the offices  refer slide time  23  04  25  45  this is an example of a ring topology actually  there are two rings in a ring the data will always go in only one direction if your destination is on the wrong side then the data has to come over the whole loop and then reach the destination so there is one ring for that what is the other ring for ? we put two rings or sometimes may be even three or four  two is quite common   one important reason for putting two rings is that if there is a failure in the network there is a possibility of the communication still going on look at the picture b let us say one particular node has come down that means  there is some problem in this thing if these nodes can sense that this has really gone down  they will sort of wrap the ring around now physically this still looks like a broken ring but if you look at it as a single ring  this is still a ring going through the nodes these nodes can still communicate although there is a breakage over here either this node may break or this link may fail so many things may happen so this fault tolerance is one good reason for using rings especially in the wide area network  we have a lot of things for example  let us say  these telephone exchanges are connected in some fashion using fiber optics cable we will be talking about all those things later on but they usually put them on a ring because if the cable is cut at some place they can still communicate by using the trick that i have just shown  refer slide time  25  46  28  24  this is the summary of the characteristics of the ring topology there is no beginning or end it is actually a ring all devices have equal access to media one good thing about it is that all of them should get data at some particular point of time so they have equal access to this media in a single ring  data travels in one direction only a double ring allows fault tolerance each device has to wait its turn to transmit that means you can not start transmitting as soon as you want to transmit you have to take your turn ; and most common type is the token ring token ring has got its ieee standard number  ieee 802.5   in a token ring what happens is that the token contains the data it reaches the destination data is extracted  acknowledgement of receipt sent back to transmitting device  removed  empty token passed for another device to use that is one way a ring can be used for example  you make a data packet with this token as well as whatever you want to send to the final user so this whole packet will go over to the next node in the ring this way  it keeps hopping from one node to another till the destination when the destination gets this packet  it knows that the destination had this or some kind of identification which will be there somehow in this whole bunch of data the destination node will know that this is meant for it it will extract the data it may be put in an acknowledgement if you are using the protocol which uses acknowledgement and send it along the ring it will go around the ring and come back to the original sender and the sender will know that this data has been received that will remove this acknowledgement also and the empty token is passed and this token keeps on circulating in the ring whoever wants to transmit has to wait till it gets the token .as soon as it gets the empty token it will put in the data that it wants to send and send it along in the same way  refer slide time  28  25  30  07  ring topology has its advantages and disadvantages the advantages are that  data packets travel at great speed now one reason why data packets can travel at great speed is that this is a very synchronous operation if you remember that in a shared medium where the nodes are not synchronizing their actions  what might happen is that two different nodes may start transmitting at the same time and then their data will collide in the broadcast medium  hence killing both the communications here such a thing can not happen because it has all been synchronized with the help of the token there are others ways of synchronization we will come to all that later on data packets can travel at great speeds there are no collisions it is easier to find faults and rectify faults and terminators are not required as in an ordinary cable the disadvantages are  it requires more cable than a bus and a couple of breakdowns may bring the entire ring down smaller rings exist nowadays but anyway they are not very common this is not as common as the bus so far as the local area network is concerned in a wide area network a ring is very common as a matter of fact the ring is the most common topology that wide area network could use  refer slide time  30  08  31  00  many lan technologies that use ring topology use token passing for synchronized access to the ring the ring itself is treated as a single shared communication medium bits pass from transmitter past other computers  and are copied by destination hardware should be designed to pass token even if attached computer is out of commission this is a small technicality if the interface of the computer to the ring can function independently of the computer  that will be nice  because even if the computer is shut down  other people ? s communications are not affected  refer slide time  31  01  31  38  this is a picture of the token ring  in which the sender holding token transmits bits of frames computer not holding the token passes the bits as they go around  circulate at a very high speed the destination passes the bits but it makes a copy and the sender receives the bits of a frame and it goes out this is one way the network could work  refer slide time  31  39  31  53  when a computer wants to transmit  it waits for the token after transmission computer transmits token on the ring to the next computer ready to transmit it receives token and then transmits this token ring was originally part of a lan technology  refer slide time  31  54  34  22  but then it fell into disuse first of all the token ring devices were less common they were more costly hence the token ring as a dominant lan technology went out with time but one version of it called fddi lived on and that lived on due to the very specific advantage that the ring topology has which is fault tolerance this technology is called fddi in a fddi  the ring is made of fiber optic cables multi mode fibers or even single mode fibers can be used they use fiber optic cables in which we can send data at a fairly high speed but the speed available is not comparable to the level possible nowadays fddi technology is also not that new it is aging and that way its speed may sound less today but when it was proposed it was taken as a very high speed the basic reason why somebody still would like to use fddi is its inherent fault tolerance capability that is the technology  which is used in lan  and it is fault tolerant ring technology  which is fault tolerant  is extensively used some other technology is extensively used in wan but in the lan we have this fddi technology whose full form is fiber distributed data interconnect this is another about ring technology which uses fiber optic between stations  which transmits data at 100 mbps when we were talking about the thin lan and the thick lan we were talking about 10 mbps speed ? 100 mbps was an order of magnitude high when it was proposed it uses pairs of fibers to form two concentric rings in order to get the fault tolerance we require with two fibers or two rings  refer slide time  34  23  35  48  as soon as a fault occurs somewhere  the fddi will automatically switch off and communication will not get disturbed furthermore you can have hybrid topology in the sense that you can have a ring  which emanates from the various nodes of the rings stars will form ; they will be the different hubs of the different stars and these different hubs can be put in a ring as a matter of fact  this is the very common way how fddi is configured some fddi switches form a ring and from each of these fddi switches  we can start other kind of technologies like ethernet etc  which form a tree-like structure the other reason why you could have hybrid topology is that older networks are updated and replaced  leaving some older segments you have replaced one part of network ; you will get a hybrid kind of topology thus it combines two or different more different types of topologies the common one is star bus or star ring star ring uses an mau  multi-station access unit   which is basically a part of fddi  refer slide time  35  54  38  48  next we take up the study of mesh topology by a mesh or a full mesh  it is meant a complete graph as shown here as discussed earlier  a complete mesh would take a lot of cable but at the same time with complete mesh we have lot of alternative paths from any node to any other node the diagram shows eight nodes and each one of them is connected to every other node now between any two nodes  you will have direct path and indirect paths as well we have many paths for going from the same source to the same destination this means that when one of the links breaks  all of them can still communicate without any problem as this arrangement takes lot of cables  we do not use this what we use is a partial mesh in a partial mesh some of these links would be dropped  taking care that none of the nodes becomes disconnected but all the links of the mesh need not be there even in the partial mesh we can still have some form of redundancy and thus have some level of fault tolerance but it may be not as much as one available in a full mesh for such a partial mesh the network topology is not well specified and it is difficult to evolve a protocol like token passing protocol so here you have to have some other method of sensing the faults and correcting them that becomes more complicated but the partial mesh topology is used in many places  refer slide time  38  49  39  55  mesh topology of course is not common on lans these are most often used in wans to interconnect lans because wan links usually are costly the users of a wan link naturally expect a certain grade of service that is why the wan service providers usually keep alternative paths if one of the paths becomes unavailable due to some node failure or due to some link failure then it can still send the traffic across the wan through some alternative paths  refer slide time  39  56  40  35  so the pros and cons of mesh topology are like this the advantage is of course it improves fault tolerance and it can carry more data the disadvantages of course are increased cost installation  difficulty in management and troubleshooting  slide reference time  40  41  41  20  now we have seen that each of these topologies has advantages as well as disadvantages rings ease synchronization  but it may be disabled if a cable breaks star is easier to manage and more robust but it requires more cable bus requires fewer cables  may be disabled if cable breaks and is not so reliable bus would not have fault tolerance really so as far as the lan is concerned  people are gravitating towards star topology that means some nodes or some computers may be connected to a switch and then some other computers may be connected to some other switch and then these switches will get connected in some fashion extended star topology is the most common topology as this is emerging in local area networks in wide area networks we have both ring as well as mesh topologies  refer slide time  41  21-46  12  the physical and the logical topologies may be different something will look like a physical star but it may actually be a ring let us look at the following examples suppose you have this as the hub of the star and we have these three stations a  b  and c ; we have say cable ducts running over there like this  through which a number of cables are passing at the central hub you might connect two cables like this and then more pairs of cables in a similar manner because this is one central place you can do this what you essentially have is a ring what you essentially have is a ring similarly  you can have any other kind of topology suppose you have a number of cables coming in like this now if we have a connection like this and similarly in all other places  then you can actually have a mesh although all this is within one physical duct and another physical duct going to nodes a  b  c  and d  it looks very much like a physical star but the actual connection is something like a mesh just as i could make a star  i could make it a mesh also the media is the physical topology whereas the way in which data access the medium and transmits packets is the logical topology a lan at a network is not always revealing cables emerging from a hub do not make it necessarily a star topology it may actually be a bus or a ring in a star topology  there is some piece of network box  which is called a hub this hub actually replaces the single cable this is again a shared medium if they are connected like a star it has got the star connection people use hubs these days but they do not use the single cable like thin lan and thick lan though it looks like a star  depending upon what kind of box it is  it could be actually a bus similarly as i have shown you  it could be a ring also  refer slide time  46  14  47  27  now the choice of logical topology is going to affect the physical topology and of course the other way around the kind of physical topology you will have will also dictate the kind of logical topology that you can have the kind of logical topology you can have will depend on two things ? one the actual physical topology  the number of cables you have etc  another is the type of network boxes like switches  hubs or whatever you have as the nodes we have to design carefully because it may be difficult to change the part way through the installation when you think about designing a network  you have to put the physical topology min place to get the correct logical topology your choice will determine cable installation network  network connections and protocols and spots where you will drill holes in the building  refer slide time  47  33  50  48  the different factors which you take into account while deciding on a particular topology are  the first thing that comes is what kind of technology you are going to use ? there are different kinds of lan technologies ? for example  if you are using fddi  then you have to have a logical ring somewhere if you are using the ethernet  you may have an extended star topology the kind of technology you are using is a factor and of course this technology will have some cost benefit as a matter of fact  in a lan  you will find that apart from the network boxes  in greenfield kind of situation   the cost of the cable is also significant then there is a question of scalability often what people will do is that  they will work with one kind of network and then  very soon  the network will get choked or people will want more bandwidth or more users will join this keeps on happening a network is never a stable thing in any organization ; but whenever you are putting some kind of topology or some kind of technology you have to think that 3 years to 5 years down the line  you will have to scale the network up you may have to change the number of your network boxes ; some of the boxes for example in old technology you may have had a bus by putting in a hub it was a physical star  but it is a bus now you put a switch over there and make it a star topology kind of thing and then later on people want more bandwidth when more people want to join  you have to design your physical topology that way for scalability  the bandwidth capacity and the ease of installation because how you take the cables around and how you scale up down and how you can install it are always problems ease of finding fault is another important factor we will talk more about it in the next class it is good to have a central cabling plan where all cables are coming you can manage all your cables in one central place .there are standards like structured cabling which are used for easy fault finding and maintenance thank you ! preview of next lecture good day ! today we will be talking about multiplexing  refer slide time  51  15  51  18   refer slide time  51  25  51  32  multiplexing is about sharing a medium different users share the same medium for communication at the same time  refer slide time  51  40  52  00  a medium can normally carry one signal at any moment because if there are two signals over there they are going to interfere and then the signals will get garbled .for multiple signals to share one medium  the medium must somehow be divided to give each signal a portion of total bandwidth a particular frequency range around one particular frequency is called bandwidth and this bandwidth is the most valuable resource as far as communication is concerned we try to use this bandwidth somehow to facilitate the communication between a number of pairs of senders and receivers.that is the idea of multiplexing there are various reasons why we want to use multiplexing and the chief one is that of transmission services which are  refer slide time  52  43  53  35  very expensive  in leased lines packet switched networks  for example  laying of line in itself fairly expensive and complex proposition and once you lay a line you really like to utilize it to the maximum the other thing is that  if you can use that for the maximum amount of communication multiplexing and compression techniques save a lot of money for the business when you can send a lot of data through the same line the data capacity of the line increases it becomes more cost effective for the company .most data devices individually require modest amount of data but with a number of users their aggregated requirements may occupy quite a substantial bandwidth  refer slide time  53  52  54  03  the current technique to accomplish this include frequency division multiplexing  wavelength division multiplexing  time division multiplexing and code division multiplexing  refer slide time  54  04  54  49  in the scheme of multiplexing  you have one multiplexer and then you have n inputs on one side .so these n inputs are coming to the same multiplexer they are getting mixed in some fashion and they are being sent over the same physical link .on the other side  depending on how you have put them together  they are separated into different lines these different lines can now go to different recipients on the left we have different senders and we have different receivers over here a number of sender receiver pairs are utilizing the same physical link in between  refer slide time  54  50  55  32  the alternative to multiplexing should be direct point to point connection this has number of problems .first problem is that you need those lines that we need for each device you thus need a large amount of wiring if they are on different floors  you need large number of io ports on the computer side  which really is not feasible you may have a few io ports  but you can not have hundreds of io ports it is really difficult to have hundreds of io ports .that is also another bottleneck   refer slide time  55  33  55  54  in a somewhat older approach  multi drop line   the host polls machine to see who wants to send and then uses the same lines total communications load is not greater than the rate of line  refer slide time  55  55  56  15  using a multiplexer approach all the device data ? s are multiplexed on one side  sent through one a line out link carries multiple channels of information  refer slide time  56  16  56  20  the signal will be restored depending on the quantum of noise present .if the noise is high then we will lose some information there will be some distortion and some loss of information would be there in case of digital signals it is more fault tolerant and more resilient compared to analog signals  refer slide time  57  01  57  17  we can correct errors in transmission using digital signals we add few bytes of error checking information and can ask for retransmission if an error is detected i will give you a simple example  suppose we are sending groups of eight bits called byte now what can we do is that associated with each byte we can add an extra byte and this extra byte would make the number of ones in whole nine bits to be odd  this is an example of odd parity now if at the receiver end we find that the number of ones have become even we know that  some bits must have flipped that means some bits must instead of zero have got a one and instead of one we got a zero it must have happened otherwise because the number of bits are supposed to be odd and of course by adding one bit we can always dictate that the number of bits in the original that means the sending station was odd .in that case the receiver may request the sender to retransmit the whole bunch once again hopefully there will not be error next time this is of course a very primitive kind of error checking there are more sophisticated error checking methods employed in networks and communications  refer slide time  58  40  58  48  computer networks prof .sujoy ghosh indian institute of technology i.i.t kharagpur lecture no # 3 physical medium  i good day in this third lecture we will be looking at physical medium in the last lecture we have seen two protocol stacks  we have seen osi protocol stack in detail and we had a look at its cpi pre reference stack but whatever be the model  at the bottom-most layer you have the physical medium because  after all  if two computers have to communicate  there has to be some physical medium between them so we will just look at some general characteristics of physical medium and how data can travel along them  today in the next lecture we are going to look at some specific media which are used in networks  refer slide time  01  36  2  26  as we talk about the physical medium  we have to talk about two different modes of communication  so to say one is analog and the other is digital  so you have before you that top one is the analog signal ; you can see that it can take any shape  and the digital signal is some kind of signal  which represents a series of ones and zeros ? stream of bits  but analog signals of course can take any value in them  refer slide time  2  27  3  20  and one important consideration for any medium is its bandwidth bandwidth is the capacity of a media to carry information now  the total capacity may be divided into channels ? i mean there is one total capacity you can sort of divide it into channels ? and give different channels to different users ; specific portion of the channel may not be used for direct communication but for control purpose and other specific purpose but whatever it is  any particular medium and technology will have a certain capacity and this is really important because  after all  your speed of communication will depend on the capacity of the medium  refer slide time  3  21  5  19  this inherent capacity of the medium is of course intermittently linked with the kind of signal one particular channel can carry for example  on the left-hand side  you see some digital signal and just on its right you have something that looks like a bargraph ? actually this is a representation of the same signal in a different way  what this right-hand side says is basically if you have a series of a sin x + b sin 2x + c sin 3x + d sin 4x and so on where a  b  c  d represent the values shown by the graph on the right-hand side  if you sum all that sin values up  you will get the signal on the left-hand side so the channel  if it has to carry the digital signal  has to be able to carry all these harmonics ? harmonics means the sin x constant  sin 2x constant  sin 3 etc so all these harmonics it should be able to carry ; whereas if you look at the second figure b  it is a pure sin wave so this just has one harmonic  a sin x or something like that this third figure has two harmonics  say a sin x + b sin 2 x ; so depending on the complexity of the wave form that you want to carry  you want more and more bandwidth for the channel  refer slide time  5  20  6  24  now for this we make a comparison of analog verses digital signals digital signals have some basic advantages the most basic advantages is that it is that less error prone that means if there is some kind of distortion in the signal between the source and destination that can be rectified very easily and to limited extent errors can be corrected whereas if you are talking about analog signal there is little control over signal distortion of course this also old technology and this has got some limitations in technology in the sense that how many people can use  etc there are some limitations over here so digital signals are of course in general preferred  although analog signal still rules in some niche areas  refer slide time  6  25  07  30  so let us see what we mean by the statement that digital signals are less error-prone in this figure we see in the left-hand side have some analog signal and then some noise has come ; that means  some distortion has come and the signal looks like the one below when noise affects an analog signal  it is hard to deduce the original signal from this whereas the same kind of noise or a similar kind of noise if it is gets superimposed on the digital signal as we see on the right  the signal gets distorted  but since we know that the original signal was sort of square shaped  we can deduce the original signal from the distorted signal so  despite the noise  noise can be eliminated easily in digital communication that is the greatest advantage of the digital communication  refer slide time  07  31 -8  51  and so far as the bandwidth of a channel is concerned  suppose we know the bandwidth  h  of the channel and the number of signal levels  v  being used  what is the maximum number of bits that we could transmit ? suppose we are trying to transmit bits in terms of digital signal ; so there is a nyquist limit it says that maximum bits per second = 2 * h * log2 v for example if the bandwidth is 3100 hz and we are using 16 level modulation then the maximum number of bits per second is log2  16  is four so 4 ? 2 ? 3100  that is 24800 bps 24.8 kbps so this is the maximum number of bits that we can send through the channel of this particular bandwidth so the higher the bandwidth of the channel  the higher the number of bits that we can send through it  but depending on the bandwidth  there is always a hard limit on how fast we can communicate  refer slide time  8  52-10  42  let us look at this regeneration of the digital signals once more we say that it is reliable because it can regenerate slightly damaged signals since there are only two states  for example  this is the original signal  which is a square  and it is grossly distorted as it is received this becomes weaker in strength and the shape has also been deformed but we can regenerate it since we know that the original shape of the signal must have been a square one so we regenerate it as a square one if there are two states of a voltage  let us say  + 10 volts  10 volts and the signal is + 8 volts  let us say  then it is quite possible that this that this + 8 volts is a result of noise  which is superimposed on + 10 volts rather than a result of noise superimposed on -10 volts so whenever you get + 8 volts  simply make it 10 volts with some electronics and the original signal will be restored of course i mean if the noise is very high  there is a limit to how much you can restore if the noise is very high then it will not be possible then we will know because  10 volts also becomes 8 volts in the case of a spike  and then whatever restoration we do will be a wrong one so we lose some information ; there will be some distortion and some loss of information will be there so there is always a limit but in the case of digital signals it is more fault-tolerant or resistant to noise  more resilient compared to analog signals  refer slide time  10  42  12  34  so we can correct errors in transmission ? that is another advantage of digital signals so what we do is that we add a few bytes of error-checking information and can ask for retransmission if an error is detected i will give you a simple example  suppose we are sending groups of 8 bits called bytes ; now what we can do is that associated with each byte  we can add an extra byte and this extra byte would make let us say the number of 1s in the whole 9 bits to be odd  this is an example of an odd parity now  if at the receiver ? s end  we find that the number of 1s have become even  we know that some bit must have flipped that means  some bit must have flipped ; instead of a 0  we got 1 and instead of a 1  we got a 0 it must have happened otherwise  because the number of bits was supposed to be odd ? and of course by adding 1  we can always dictate the number of bits in the original that the sending station was odd ? in that case the receiver may request the sender to retransmit that whole bunch once again ; hopefully there will not be an error next time this is of course a very primitive kind of error-checking ; there are more sophisticated error-checking methods employed in networks and communication so this error-checking and correction of error at the receiver ? s end is possible if you have adopted a very sophisticated coding technique so that is possible in case of digital transmission ; this is not possible in analog transmission  refer slide time  12  36-14  04  another advantage is that a digital signal can be encrypted  which makes it possible to carry sensitive information on the network for example  e-banking is coming in vogue ? that means  somebody does a bank transaction on the network similarly e-commerce ? that means you want to buy something online and then pay through your credit card  etc online now how does the transaction take place ? the point is that you are sending some information  may be your credit card number  may be some password  etc somebody can snoop on you in-between  so they will know your secrets and use the same set of numbers to may be buy something else  and the money will go from your bank account ; that is obviously not acceptable in this case when we send it down the network  we encrypt it in a way that even if somebody snoops and finds out the stream of bits that is going  he will not be able to make out the original numbers from this current stream so this is encryption and this is a very important application these days  refer slide time  14  05  15  54  so encryption is another advantage of digital transmission compression is another ; that means  we can compress a message before transmission and decompress it at the other end so the overall load on the circuit and the network is lighter ; since the load is lighter it is less expensive sometimes when you compress information there may be some loss of information ; there are lossy compression techniques and they are non-lossy compression techniques lossy compression technique is where you may lose some information  but it may not matter for example  let us say you want to send a digital photograph a digital photograph may have a very high resolution ; if you compress it and decompress on the other end  you may lose a few bits but the image that you get on the other end would still look almost as good as the original one of course  trained persons can look at it and find out there is something missing but it will almost serve the purpose sometimes loss compression is acceptable and of course there is loss-less compression also when you compress it and send it  it is a less expensive way of sending i mean you are sending the same information but only your are taking less amount of space ; of course you have to do the compression and decompression at the two ends  so that is some kind of overhead on the two sides  refer slide time  15  55  17  07  suppose we have some data ; how do we encode this digitally ? well  the simplest way  of course  is by the presence or absence of a signal let us say a positive voltage might represent a binary zero or a binary one or vice versa maybe if you have high voltage  you say that is i will interpret that is as one being sent and if i have a low voltage i interpret this as a zero being sent of course  when i am saying voltage  i am assuming that we are having some kind of electrical signal traveling ; that is not always the case for example  if you are using light for communication the presence of light may indicate one and the absence of light may indicate zero so whatever we code it  whatever be the medium  this is the simplest wave to encode data into a digital form the current state indicates the value of the data  refer slide time  17  08  18  31  if your signal is digital  sometimes you are forced to send some digital signal by analog transmission  but this is usually not preferred analog signal will transmit whatever signal comes regardless of whether it represents digital or analog data so it uses amplifiers other than the kind of regeneration that is possible in digital voice  the trouble with amplifiers is that it also boosts noise  whereas in the digital case we could take out the noise and regenerate the original shape of the signal here we can amplify it  so that if a signal becomes weak we can make it stronger ; but whatever noise is coming with the signal that also gets amplified this is okay for voice  but for digital data using analog transmission usually is not done because we have so little control over the correctness of whatever we are sending  refer slide time  18  32-19  58  digital transmission is concerned with the content of the signal ; it uses repeaters which recover the pattern of zeros and ones and then retransmits this can be used with analog signal if it carries digital data you know sometimes analog signal carries digital data ; it recovers the digital data from the analog signal  generates new clean analog signal this is becoming more standard ; for example  when you are connecting to the network  to the internet  from your home computer you may have use the modem and the telephone connection now what is happening over here is that the telephone line is essentially an analog medium ; so an analog signal will go over there on that  but whatever is coming out of your computer is digital so what you do is that you make this digital data ride on some analog signals to this modem pairs so that it reaches the telephone exchange at the telephone exchange it is converted back to digital data and the backbone and the core of the telephony system is purely digital  refer slide time  19  59  22  26  so there are various ways in which you can encode digital information in the analog domain one is the amplitude shift keying  which means the two binary numbers 0 and 1 are represented by two different amplitudes of carrier waves this is not very efficient ; uses up to 1.2 kbps on voice grade lines ; and is used to transmit digital data over optical fiber in the amplitude shift keying  although the signal is analog we know that there are only two levels  which this signal is supposed to take  i.e  two amplitudes  low amplitude and high amplitude it may be 0 and some amplitude if a 1 is to be transmitted may be we give this high amplitude and if a 0 is to be transmitted  we may use a low amplitude analog signal you may say this is the kind of thing which is done in the optical domain ; but in the electrical domain this is not very efficient more common is the so-called frequency shift keying in frequency shift keying  we use the two binaries ; that means we use two different frequencies for the two binary digits  0 and 1 so this is less susceptible to error than amplitude shift keying  and again  it sends up to 1.2 kbps on voice grade lines and is commonly used for high-frequency radio another way of encoding is the so-called phase shift keying two binary numbers may be represented by phase shift of carrier wave ; so this is more efficient and noise resistant than fsk ; this is psk it can be raised up to 9.6 kbps  kilo bits per second  on a voice grade line this is for a simple phase shift keying ; of course  we use more complex phase shift keying with other techniques in order to achieve even higher data rates nowadays  refer slide time  22  27  24  01  these techniques can be combined so it is common to combine phase shift and amplitude shift keying so we can get about 56 kbps on a voice grade line the modems that we buy usually are all 56 kbps  connected with some technique called multilevel signaling each signal represents more then one bit so this is also possible one is the signal  which indicates the level of the voltage or whatever it is  the phase or frequency  the level of the signal ; the other is the bit or bits that it may represent so  for example  if you have a simple technique  it will represent a 0 or a 1 by the current level of the signal  which is the simplest kind of technique  these two are the same one is the bit rate  that is  the number of bits of information that you are sending ; the other is the baud rate  that is  the number of times the signal will change per second ? the maximum number of times the signal will change per second so in the simplest case  baud rate and bit rate may be the same but that is not always the case  refer slide time  24  02  29  29  so we look at the other side of the coin  which is the digital encoding of analog information and a very common case is the telephones for example  as i just now told you  the heart of the telephone exchanges and the telephone switches and the trunk exchanges and the core network of the telephone system are nowadays entirely digital whereas our voice  of course  is analog by the way  the real world  in which we move around  is mostly analog now this digital is something that we adopt in-between in order to get these advantages of robustness  resiliency  error correction  etc our voice is analog  but the core telephone system is digital so at some point  our voice  an analog signal  has to be converted into a digital signal of course  our handsets also are mostly analog so they are going to be carried may be in this analog fashion right up to the nearest exchange ; but there  there will be a set of codecs  coders and decoders  which will convert this analog voice signal to a digital signal now  what kind of digital signal will a voice give ? the calculation is something like this  the voice data in a telephone system is limited to a maximum of 4 khz this telephone is a very good quality  the first so-called gold quality but this is not high fidelity kind of sound it is less than high fidelity  but very very clear  for all practical purposes for the telephone at least if i limit the bandwidth to 4 khz  we get some distortion  but nothing very noticeable so voice is still very clear we have to send this 4 khz of analog signal  whatever information is there  within 4 khz bandwidth we have to send this analog signal to the other side in a digital form ; that is  we have to digitize it there is a nyquist rate  which is like the nyquist limit that we have seen some time back nyquist rate  which says that if we sample any analog signal at double the maximum frequency that the particular analog signal has  then essentially we will have all the information that is needed to fully reconstruct the original analog signal from this sample so if you have 4 khz of signal  4 khz of bandwidth  we require 8000 samples per second let us say you have this analog voice ; so per second we will take 8000 samples  sample values at different points so  of course  at some points my voice may be low so i may have a small amplitude ; at some point my voice may be very high so i can have a large amplitude now that we break up each of these into a code of 8 bits  the point is that with the 8 bits  you can really distinguish between 256 levels and our assumption is that from the 0 level to the highest level that is admissible  we take it ; whatever it is  if you break it up in to 256 parts  that is good enough for capturing how high or low the volume is so a level of 256 is really quite a lot we require 8 bits for each of the sample and we require 8000 samples that makes it 8 ? 8  that is  64 kilo bits per second  64 kbps please remember this rate ? 64 kilo bits per second ? it is the fundamental unit on which a whole lot of all other technology  etc has been built and basically  it has come especially from telephony  because the telephone people had the first network and 64 kbps happened to be the rate which was set for a voice so naturally  of course  if you want to carry 1 voice channel  we will have a 64 kbps if you want to carry 1000 voice channels  you will require 64 kbps ? 1000  that is  64 mbps capacity so they planned their network depending on how many voice channels they want to carry where ; but 64 kbps is the basic unit in most places in telecommunications  refer slide time  29  31  32  53  now let us take a quick look at how data is encoded the simplest one is of course using the level of the voltage ; for example  over here this is the non return to zero level  the so-called nrz encoding it uses two different voltage levels to represent 0s and 1s ; typically negative voltage equals 1 and positive voltage equals 0 and the signal never returns to 0 voltage so it flip flops between a negative voltage and a positive voltage the value during bit time is a level voltage ; that means  during the duration of a bit 0 or 1 the voltage really remains the same so there is a transition at the boundaries of bit and of course  if there are two 1s then there will be no transition as we can see ; if there are two 0s consecutively  then there will be no transition so the number of transition is much less and it is a very simple kind of scheme this has some problem we will come to that later on ; but let us look at another variant of this non return to zero  which is nrzi that means non return to zero and invert on 1s that means once again we keep constant voltage during bit time ? no transition represents 0 and transition from low to high or from high to low is a 1 so the same bit pattern  0 0 1 1 0 1 is represented by a different voltage pattern over here there is no transition 0 0 and then there is a 1  so there is a transition ; there is another 1  there is a transition ; 0 no transition ; then again the 1  then another transition so this is another way of encoding now the trouble with these encodings is that suppose you have a large number of 0s  a large train of 0s  there is no transition really by the way  there is one point ? the reason they use the positive voltage and negative voltage rather than a positive voltage and zero voltage or zero voltage and negative voltage is that you want to distinguish between a 0 being sent and no signal being sent so that is one point and the other point is that as i was saying if there is a constant train of 0s in the original data then we will have a constant level signal in the system now if that be so  the synchronization of the clocks between the sender and the receiver tends to drift off and then the receiver  i mean in the worst case  the signal may go one off or it may interpret the signal in a very wrong fashion so this is the problem of this nrz and nrzi  which is taken care of  refer slide time  32  54  33  46  by some other kind of encoding ; we will come to that later on so this is a just a quick look at the disadvantages of nrz code ? hard to tell where one bit ends or starts ; with long string of 0s or 1s  any drift between timing of transmitter and receiver results in errors so there is a bit phase encoding  which uses the least transition per bit time so if you use at least one transition per bit time  what would happen is that the sender and the receiver clocks can remain in very close synchronization with each other ? that is a nice property ? and there is predictable bit transition during each bit time so an absence of a transition indicates an error so two examples are manchester and differential manchesters  refer slide time  33  47-34  29  so this is manchester encoding you see that at the middle of each bit 0 or 1  there is a transition now  low to high transition means 1 and high to low transition means 0 so the same pattern ? 0 0 1 1 0 1 ? is there for each bit ; you will see there is a transition in-between  and low to high transition is 1 and high to low transition is a 0 so this is the encoding  which is used in ethernets and many lans  refer slide time  30 35  42  there is another variant of this called differential manchester ; in this  the midbit transmission is really for clock synchronization purposes they do not represent either 0 or 1 so what it does is that transition at the beginning of a bit period is equal to 0 and the absence of a transition is bit period 1 so 0 0 ? when this 0 starts  there is a transition transition at the beginning of the bit period is a 0 ; but when the 1 starts  there is no transition there is a transition in the middle anyway ; that is for clocking purpose then at the next level  once again if there is no transition if there is a second one coming  there is no transition and so on this was used in token ring networks ; of course token ring networks are becoming less popular these days but anyway  this is another one there are other kinds of encoding techniques  but these are the common ones so you see that there are different ways of encoding the digital data into these different signal levels  refer slide time  35  43  38  29  signal levels and bit rates are different the rate at which the signals change is the baud rate  and the rate at which bits are sent is the bit rate the other thing we can consider is the analog encoding of analog information of course  this does not come too much in computer networks  but this is an important area in communications in general so of course  if you have an analog signal  it can directly be sent sometimes it is sent in the raw form ; sometimes that is not very practical  so we have to convert this to an analog signal maybe at higher frequency  and the most common example of this is the radio for example  a radio is carrying voice or may be some sound  etc the voice  as you know  is only 4 khz  but if you take a 4 khz signal and try to send it over the atmosphere  it will not reach any where  excepting in its close vicinity so  in order to reach out to all these different locations  you have to send your radio signal at a very high frequency ; but the information that is it carrying is still at that 4 khz bandwidth so this 4 khz bandwidth is sort of translated ; so there is a very high-frequency so-called carrier wave  which is carrying this 4 khz of signal if it is only voice of course if it is music  etc  you may like to have a somewhat higher bandwidth also ; but anyway  that is also analog signal and this is also analog signal so one analog signal is carrying the other analog signal and there are various ways of doing this so-called modulation the three most common ones are amplitude modulation  frequency modulation  and phase modulation so we will not talk much about this because in amplitude modulation as you can understand  the amplitude of the carrier wave is changed according to the signal ; similarly  in frequency modulation the frequency of the carrier wave is changed according to the signal ; and then in pm the phase is changed according to the signal  refer slide time  38  30 -39  58  so this is another picture of digital signaling so called current state ; that means zero represents the low voltage one is represented by the high voltage and digital signaling and state transition ; so if there is no transition that is zero if there is a transition that is the one so these are all different examples of encoding  refer slide time  38  59  39  35  as i was telling  the bit rate and the baud rate are different the maximum number of times a signal can change in a second is called the baud rate and the number of bits  1s and 0s transmitted in a second is called the bit rate in the examples we have seen so far  the bit rate and baud rate are the same ; this is not always the case the bit rate can be higher than the baud rate if we use more then two signal levels ; and the other one is also possible  the bit rate may be lower than the baud rate  refer slide time  39  36  41  15  now let us look at some of the inherent trouble with all these physical media that means  when we are throwing some signal  when we are trying to send some signal down some transmission medium ? it may be a piece of wire it may be this whole atmosphere or it may be a fiber optic cable ? there will be some kind of distortion  some kind of change in the original signal  that will inevitably come into play so we will look at some of these ; we have to really take care of all these these signals and these kinds of effects can not be eliminated i mean the world is not perfect and they are basic properties of the medium so we will have to design our systems in such a way that in spite of all these efforts the whole communication will still go on very correctly as a signal propagates  the signal changes as it travels ; so the receiver may not be able to recognize it as such for example  this shows an example of an original signal and the final signal this kind of change and distortion etc may be attributed to the following effects   refer slide time  41  16  42  51  the first one  the very first one  is attenuation a signal get weaker as it propagates ; attenuation becomes greater with distance naturally  and of course  finally  the signal will become too weak to recognize so the original signal strength is something but as the distance grows signals become weaker and weaker for example  let us say this kind of weakening is dependent on the property of the medium ; it also depends on the kind of frequency you are using for sending for example  let us say an am signal will not be received at a very large distance  whereas a short wave signal may travel some other way and come over here similarly  if you take a local area network or a cable  then if you make the cable very long ? there are other technical problems for making cable very long ? but even from the signal propagation point of view  the signal will get weaker and weaker because there will be leakage currents in the cable  current will leak out  etc finally  the signal that we will get will be very weak so this is a very fundamental property of any medium similarly  if you take an optical medium and if you send a light pulse through it  as it travels  the light pulse will get weaker ? that is one of the effects there are other effects  but this is one of the major effects  refer slide time  42  51  44  27  apart from attenuation  there is distortion that means  the signal changes shapes as it propagates now if it changes shapes in this way  the adjacent bits may overlap  may make recognition impossible for the receiver  so what might happen if the signal changes shape ? why does it change the shape ? if you remember in the very beginning i had shown you one slide of a square wave kind and we talked about some harmonics so the square wave may be looked upon as a sum of all these harmonics  a sum of all these sign waves now all the harmonics or sign waves are of different frequencies ? we had talked about the sin x sin 2 x and sin 3 x and so on ? so they are of different frequencies now signals of different frequencies change or get affected by the medium differently so a signal of a particular frequency may be attenuated less ; the signal at a much higher frequency may be attenuated much more or vice versa the point is that signals at different frequencies will get affected by the medium in different ways so finally  the relative strengths of the different frequencies will be different when you go to the far end ; that means  when you go to the receiving end  when you add that all up  you will get a different shape you will not get the old square shape or whatever shape you have sent ; you will not get that back so this is called distortion  refer slide time  44  27  45  31  then  of course  it is going to pick up noise there is thermal energy in wire  which is everywhere so this energy is some kind of inherent noise that will always come ; then there will be random signals so spikes may sometimes occur ; say  some car is starting somewhere so there will be some static discharge ; the lightning strikes somewhere  there is somebody running a motor  somebody is running a washing machine  all these things add to the general noise in our atmosphere and this medium  which is carrying a signal  will also catch some of this noise sometimes of course  the noise is so sharp that it may change the transmission in such a manner that you will not get the original signal back so sometimes such a thing may happen  refer slide time  45  31  46  47  what we want is a high signal-to-noise ratio in order to distinguish between the signal and the noise if the noise is very low and the signal is high  we can still distinguish at the receiving end between what is a signal and what is a noise and take the signal out  take out the noise but for this we want a high signal-to-noise ratio signal strength divided by the average noise strength is the snr and as snr falls  error will increase so in this figure  you can see that as the signal becomes weaker and weaker and touches the noise floor may be goes below it when it goes below it  the noise becomes more than the signal ; then no meaningful communication can be carried out so in general  we want a strong signal-to-noise ratio so one thing we might do quite often is that suppose we do have to send a signal to a very long distance  the signal will naturally get weak so in-between  we will put some amplifiers or repeaters or regenerators  which will take the signal  try to filter out the noises as much as possible  then amplify the signal and make it stronger  and then push it for the next span so after some distance  again another repeater will take it up and regenerate the signals we have to go on doing that so that i maintain an acceptable signal-to-noise ratio even at the receiving end  refer slide time  47  26  47  38  then of course  as i said that  there is interference that means energy from outside the wire adds to signal  like noise  which is often intermittent  and is very hard to control or diagnose  refer slide time  47  38  48  49  one important point is that a very strong interference can occur at cable termination so there are two things  first of all  if two cables are running in parallel  what might happen is the signal in one may affect the signal in the other so there is some kind of linkage between the two the so-called cross talk ? that is one thing this is more pronounced at the termination end ; at the termination end  if you do not terminate the thing properly  if you just leave it like this  the kind of distortion and the kind of noise that will be introduced will be much more so whenever we are putting some wired kind of network infrastructure  we have to be very careful about the termination  because that is where a lot of noise can come in so often there will be multiple wires in a bundle ; each radiates some of its signal  causes interference in nearby wires and this is especially bad at terminations where wires are unwound and are parallel  refer slide time  48  49  49  36  finally i just mentioned this  that when carrying digital data over analog lines  we require modems modem stands for modulation and demodulation this is used to connect a digital computer to an analog phone system usually  but modems can also be used elsewhere it can be installed internally or a card inserted into the motherboard or can be connected to the serial port  etc so now we understand why modems are required because essentially  digital data will have to be carried on the analog system the field of communication  as you know  is a very interesting field and we could not go too much into the details of communications but we have just talked about the very basics of communications used in computer networks  because remember computer network or some computers or some network nodes are connected via some communication lines so communication is absolutely important ; it is all-important in this ; so we have talked about this.in the next lecture  we will look at some of the medium that is actually used or deployed in common networks thank you preview of next lecture lecture no # 4 physical medium  ii today we will  have the second lecture on the physical media in the last lecture we have seen the different ways the digital signals and analog signals  etc how they can be used for communication how digital data or analog data can be encoded and some of the general impairments of physical medium in this lecture we are going to look at specific media which are used in networking  refer slide time  51  18  51  20   refer slide time  51  21 ? 52  30  so there are basically two types of mediawhich are used for communication one is cable i mean they are two different classes are together so one is a cable now this cable could be some copper cable they could be coaxial cable or twisted pair or shielded twisted pair so the twisted pair i mean we sometimes there actually unshielded twisted pair or utp sometimes we simply called them twisted pairs since they are more common there are shielded twisted pairs also and then of course the one of the most important cables these days is the fiber optic these are the different types of cables that we use in networks similarly we can also communicate without the use of any cables by simple electromagnetic radiation and these radiation could be in different ranges of the frequencies like they could be infrared or microwave or radio or satellite etc so we will look at all these one by one  refer slide time  52  31  55  25  first let us look at the kind of media that we use in a lan lan as you remember is a local area network and a local area network could vary from let us say one meter to one kilometer so its is local strictly by some means of size in some way so one meter means two computer connected siding on the same table connected side by side it could be all the computer in one building and all the computers in several buildings and so on so that is the kind of range that we have for lan  and the medium that we use for lan they could be coaxial cables  utp  fibers  wireless so you would note that basically most of the types of cables that we talk about find their way in some ways or other in local area networks and of course utp or unshielded twisted pairs are of different varieties or categories so that cat is for categories so we could have cat3 cable cat 5cable  cat 5e cable  cat 6 cable  cat 7 cable and so on .you must have seen cat 3 cable if you looked all your telephones that is the landline phones they are connected by unshielded twisted pair cables of categories three for computer networking i mean cat three cables could also be used for lan although we usually prefer cat five onwards the kind of things that are on the network that could be pbx  pbx is your local telephone exchange that could also have some digital ports etc ethernet is one technology which is used in lan atm is also used  fddi is sometimes used fddi if you remember is fiber distributed that is the fddi ring kind of structure so there are some networks even smaller than lan they have called personal area networks some networks so i may have be varying three or four computers and they or connected in a network on my body o we will come to pan later on but going on the other side of the spectrum that means from lan to a bigger network this is man that is a metropolitan area network typically one campus or one city may be several small towns which are closed together they would come under the preview of the man  so man by ballpark figure man would be extent of about ten kilometers  so it could be 5 kilometers or it could be twenty kilometers so something in that range  refer slide time  55  26 ? 57  48  and the kind of medium that we use for a metropolitan area networks coaxial cables both base band and broadband  we will come to this what they are sometime utp are used but that is not very preferred way of connecting although utp are used one way utp is definitely used are when you try to network to telephone lines that is i mean telephone linesi told you they use utp it could be a hybrid kind of system  some part of it could be coaxial some part of it could be utp and some part of it could be fiber fiber means  fiber optic cables and kind of things of course that kind of technology that goes into a man would be pbx different kinds of modems for example if you are using a broad band coaxial cable you might use something what is known as a cable modem  then you have this long ethernet that means on the ethernet on the over may be some lines cable tv dsl digital subscriber lines or it could be wireless one issue which is important in man is the issue of access alright that means how do you reach to each individual users.i mean think of a town or a city so you really have to in order to network the entire town you have to reach to each individual residence and reaching to each individual residence involves cost ok  if it is a small building like in a lan you can take very good say utp cable to his room  now there are problems of taking utp cable to each individual house i mean there could be i mean electromagnetic disturbance and things like that but apart from that there is a question of cost ok if you are trying to build so much copper into that is quite costly so how to access to users who are distributed over somewhat wide area in the sense of several kilometers that is an issue in metropolitan area networks  refer slide time  57  49  58  41  finally at the extreme of the spectrum we have wan that is wide area network so they may stretch from ten kilometers to may be 10000 kilometers  so 10000 kilometers almost to the other side of the globe so they can involve very very long distance  medium is usually fiber or satellite and the kind of technology that is used in wan are sonet or sdh that the almost similar technology atm ip that is the internet protocol  dwdm dense wavelength division multiplexing  geo and leo geo stands for geostationary satellite is a short form of geostationary satellite and leo is low art orbiting satellite computer networks prof .sujoy ghosh dept of computer science & engineering i.i.t  kharagpur lecture no # 4 physical medium  ii  refer start time  0  45  good day today we will have the second lecture on the physical medium ; in the last lecture we have seen the different ways these digital signals and analog signals  etc can be used for communication  and how digital data or analog data can be encoded well  we are mostly interested in the digital form of data  how they can be encoded etc  and some of the general impairments of physical medium in this lecture we are going to look at specific media  which are used in networking  refer slide time  01  33 ? 01  34  refer slide time  01  34 ? 02  43  there are basically two types of media  which are used for communication  one is cable they are actually two classes of cable now this cable could be copper cable or could be coaxial cable or twisted pair or shielded twisted pair the twisted pairs are actually unshielded twisted pairs or utp sometimes we simply called them twisted pairs since they are more common ; there are shielded twisted pairs also then  one of the most important cables these days is the fiber optic these are the different types of cables that we use in networks similarly  we can also communicate without the use of any cable  by simple electromagnetic radiation and this radiation could be in different ranges of frequencies  like infrared or microwave or radio or satellite  etc we will look at all these one by one  refer slide time  02  44 ? 05  09  first let us look at the kind of media that we use in a lan lan  as you remember  is a local area network that could vary from  let us say  1 m to 1 km so it is local strictly by its size ; 1 m means two computers connected on the same table or connected side by side ; it could be all the computers in one building and all the computers in several buildings ; and so on that is the kind of range that we have for lan the medium that we use for lan could be coaxial cables  utp  fibers  and wireless most of the types of cables that we talked about find their way in some niche or other in local area networks and  of course  utp or unshielded twisted pairs are of different varieties or categories we could have cat 3 cable  cat 5 cable  cat 5e cable  cat 6 cable  cat 7 cable and so on.you must have seen cat 3 cable ? if you have looked in your telephones that is the landline phones  they are connected by unshielded twisted pair cables of category 3 for computer networking  cat 3 cables could also be used for lan  although we usually prefer cat 5 onwards the kind of things that are on the network could be pbx ; pbx is local telephone exchange that could also have some digital ports  etc ethernet is one technology  which is used in lan ; atm is also used ; fddi is sometimes used fddi if you remember is fiber distributed  that is  the fddi ring kind of structure we have network boxes like hubs  switches  routers  etc so these are the terms you would come across of course we would talk about some of these in more detail later on  but these are some of the technologies that come into lan or local area networks  refer slide time  05  09 ? 07  22  then we come to slightly bigger networks  called man or metropolitan area networks there are some networks which are even smaller than a lan ; they are called personal area networks i may be wearing three or four computers and they are connected in network on my body so we will come to pan later on going on the other side of the spectrum  that means  from lan to bigger network  which is man  a metropolitan area network  typically one campus or one city may be several small towns  which are close together they would come under the purview of a man man is a ballpark figure ; it would extend may be about 10 kilometers ? so it could be 5 kilometers  or it could be 20 kilometers or something in that range the kind of medium that we use for metropolitan area networks is coaxial cables  both base band and broadband ; we will come to what they are sometimes utp are used but that is not a very preferred way of connecting one way where utp is definitely used is when you try to network through telephone lines utp could be a hybrid kind of system wherein some part of it could be coaxial and some part of it could be utp and some part of it could be fiber fiber means fiber optic cables the kind of technology that goes into a man would be pbx  different kinds of modems  for example if you are using a broadband coaxial cable you might use something that is known as a cable modem then you have this long-reach ethernet that means ethernet over may be some lines  cable tv dsl digital subscriber lines or it could be wireless one issue which is important in man is the issue of access that means how do you reach to each individual user ? think of it as a town or a city ; you really have to in order to network the entire town you have to reach to each individual residence and reaching to each individual residence involves cost if it is a small building like in a lan you can take utp cable to his room there are problems of taking utp cables to each individual house ; there could be electromagnetic disturbance and things like that but apart from that there is a question of cost so if you are trying to build so much copper into it that is quite costly so to access users who are distributed over a somewhat wide area of several kilometers that is an issue in metropolitan area networks  refer slide time  08  32 ? 10  08  finally  at the extreme of the spectrum  we have wan  wide area network so they may stretch from 10 kilometers to may be 10000 kilometers or almost to the other side of the globe they involve very very long distances the medium is usually fiber or satellite and the kind of technology used in wan is sonet or sdh it ? s almost similar technology atm  ip ? that is the internet protocol ? dwdm  dense wavelength division multiplexing  geo and leo geo stands for geostationary satellite and leo is low art orbiting satellite so these are the kind of technologies that go into wan one issue in man is of course always cost and bandwidth  wan bandwidth because as you can imagine that when you have to take some message across hundreds of thousands of kilometers away there is a lot of cost involved in it so wan bandwidth is usually costly and we try to make the maximum use of this bandwidth of course in recent times lot of fiber has been laid internationally so the bandwidth problem is becoming less and less  but even then wan bandwidth remains costly  refer slide time  10  08 ? 12  43  now let us see some of the cable specifications that we use  first we take up this utp cable of category 5 so cat 5 utp cables specification says about 100 mhz and these can stretch up to 100 meters these are the figures which are normal  you can stretch things little bit this way or that way at times depending on your operating circumstances  etc but this is normally the figure ; so you can have some kind of idea from these the cat 5 cable looks like your standard telephone cable ; the only thing is that they are made to a slightly better specification the connector at the end of a cat 5 cable has got a specific scientific number ; this is called rj 45 so we use rj 45 connectors for connecting cat 5 cables there is a standard ansi or tia or eia standard for how cat 5 cable is to be used what are the standard ways and how they are twisted  etc there are a number of wires inside the twisted pair of cables ; so which wire stands for what  etc i simply refer to the name of the standard here  which is eia 568 a and then a cable has to be tested according to some standards ; tsb 6795 is the standard for testing cables cat 5 cable is usually under these circumstances 100 mhz to say 100 meters if you are within the 100 meters  if you have done everything properly it is expected that it can work up to 100 mbps the point is that if the distance is much less than that then naturally the same cable can work at a much higher speed so inside the same room the cat 5 cable may be used for 1000 mbps connection between computers or network nodes  refer slide time  12  43 ? 13  26  there is some enhanced version of cat 5 cable ; i will not go into the details of this  which are given over here the specifications are almost the same ; only thing is that this is slightly better in some way and it can work for 1000 base tx for small distance i said within a room if you are using cat 5 e cable instead of simple cat 5  you may be able to operate at 1000 mbps without much of a difficulty  refer slide time  13  27 ? 15  24  then we have the cat 6 cables  which is again slightly higher than cat 5 cables here  the specification is 250 mhz this specification is much higher ; so naturally cat 6 cable would be somewhat costlier than cat 5 or cat 5 e cables the same kind of connector is actually the recommended cable for operating at 1000 mbps so here is a point when networking started  people thought that 10 mbps is a fairly high speed and soon people were using networks a lot and 10 mbps was not enough  so people went to 100 mbps now people are saying that 100 mbps is slow ; so we want to go to 1000 mbps you see that in a comparatively short period of time  may be 15 ? 20 years  our demand for bandwidth has grown a thousand-fold when you are planning for an infrastructure  say copper infrastructure  in any organization or somewhere  then you should keep this in mind that whatever specification people are giving you today  after some time people may want to upgrade what i mean to say is that if you put in cat 6 kind of cables and use it for only 800 mbps today  then 1 or 2 years later you can use the same cable for 1000 mbps saving a lot of cost at that time ; but of course  that would mean a higher upfront cost today so that is always there  refer slide time  15  25 -16  44  so for testing these kind of cables there are all kinds of testing parameters i will not go to the details of these at all this is a rather technical part return loss is a measure of the reflected energy caused by impedance mismatch in the cabling system when you put a cabling system you can test it and one of the things you might test for is return loss and another thing you might test is a cross talk as reflected from the other end elfext is defined as the measure of signal coupling from a transmitter at the near end into a neighboring pair measured at the far end  relative to the received signal level on the same pair these kinds of testing parameters are there for testing copper cables similarly if we have put fiber optic cable somewhere  then fiber optic cables would have some other testing parameters it ? s a good idea to test the passive networking infrastructure  meaning all these cables and connections etc  and how they perform  refer slide time  16  45 ? 18  23  now from unshielded twisted pair cables  we go to the base band coaxial cables we have already mentioned about the base band coaxial cables these are the cables we were talking about when we talked about the bus topology if you remember ; so it is basically a shielded cable there is a copper cord surrounded by an insulating material  which is surrounded by braided outer conductor  which is surrounded again by a protective outer covering so this is considerably thicker than a utp and then in the coaxial cables also there are two varieties  the so-called thick coaxial cable and thin coaxial cable this technology is becoming obsolete now  but just for our knowledge  a thick coaxial cable is also presented as 10base5 this 10 represents that it works at 10 mbps and 5 represents that it can go up to 500 hundred meters the thin coaxial cable is 10base2  so it works at 10 mbps and goes up to 200 meters as i told you  nowadays almost everybody wants a 100 mbps to their desktop  in which case this thick and thin coaxial cables  that is the base band coaxial cables  are no longer of much use today  refer slide time  18  23 ? 20  57  but another type of coaxial cable  which is very much in vogue and which is used even today  is the kind of cable that your cable operator puts many of you have seen that cable operator puts some kind of coaxial cable into your room  which goes into your tv now it is possible to use the same infrastructure for computer communications also  i.e  computer networking also remember  i told you while discussing man that one of the most important issues in metropolitan area network is the issue of access ; that is  how do you reach each individual subscriber at his or her home ? this cable operator has reached lot of homes anyway so naturally  people started thinking whether we can use these cables from the cable operators for network communication  and special kinds of modems were designed for that called cable modem so we have a broadband cable infrastructure rather than the base band that we were talking about this is quite often used and now they are being deployed in many cities for computer communication this is  as i said  analog signal carrying tv signals and has been used for carrying data traffic older cables carry up to 450 mhz and the newer cables that have been put can go to higher frequencies  that means  higher bandwidth  and these cables use amplifiers at regular intervals now these amplifiers in the old days were only one-way amplifiers because the way the cable operators wanted it is that they are broadcasting their signal from some central location and it just has to reach people ? s tv but when you want to use this for computer communication the communication has to be two-way so the amplifier also has to be a two-way amplifier so such small technicalities are there ; it requires an amplifier at regular intervals and is a shared medium usually this medium is shared  that means  you and your neighbors ? all your data is in the same medium  refer slide time  20  57 ? 22  27  as i said  for carrying data  two-way amplification is necessary dual cable systems are like two trees  both rooted at the head-end ; the head-end is where all the service providers ? equipments etc are placed so there are all kinds of split systems  they use 5 to 30 mhz for inbound traffic and the rest for outbound traffic ; mid-split system and there are all kinds of systems for using this for data communication by the way  there is also some asymmetry that people have found in the network traffic for an average user in a city one of the most popular uses of computer network nowadays is just going onto the internet  may be surfing it  may be getting some information  etc but the amount of traffic in terms of query etc  which flows from the user to the computer  wherever it may be  is relatively small whereas you may be downloading large files  images  may be even songs  movies etc your bandwidth requirement ? the upstream bandwidth requirement and the downstream bandwidth requirement are usually not the same ; there is an asymmetry  refer slide time  22  27 ? 24  03  now we come to another very important kind of cable  having looked at copper cable  namely  optical fibers optical fiber basically is made of glass  very pure and very transparent silica glass is used  which is very very transparent in the sense that it can go up to tens of kilometers without too much of attenuation on the way so think of a glass slab  which is several kilometers thick and you can see through it quiet easily  so that kind of transparency is required so  naturally  there have to be some very strict standards for making this glass but after all  it is simply a glass  which is drawn into fiber for giving us this optical fiber at moderate dimensions  light is restricted to the fiber because of total internal reflection for ordinary light ; this is called a multimode fiber at still smaller dimensions  say something like 8 to 10 nanometers  the fiber acts like a wave guide for lasers this is known as a single-mode fiber multimode fibers are used for local area networks whereas in all wide area networks and even in local area networks these days single-mode fibres are more preferred for carrying signals  refer slide time  24  03 ? 26  55  finally what is optical networking ? one thing is  naturally  optical transmission by the way  optical transmission could be fibers or free space free space means suppose you direct a laser from the source to the destination on the free space  light will travel straight or it is expected at least to travel straight and then reach the receiver so you do not need any fiber or anything at all but there is a problem the first obvious problem is that the sender and the receiver have to be on the same line of sight without any hindrance in-between  that is one point and then there are other complications  which might come ; in the sense that the intervening air may get hot and its refractive index may change so the light may actually bend  like they do in a mirage in a desert that kind of things may happen  so it might miss the receiver altogether so free space optic communication is not very much preferred people prefer to put fiber optic cables wherever they can these cables or free space we are talking about is for fiber optic transmission then there is the question of optical switching ; can we provide the network level functionalities in the optical domain itself ? this is a topic of research these days as this is quite promising so maybe we will just look at this later on finally  why optics ? the point is that optical fiber capacity is huge  very huge ? you see 50 terabits per second is mentioned over here the point is that this has got an absolutely fantastic bandwidth  so if you can put a fiber optic connection between two endpoints your present as well as foreseable future requirements will surely be met so that is one good thing about optics the other very good thing about optics is that it is immune to electromagnetic interference  if there is a lightning strike nearby  then it is not going to affect this very thin strand of glass that we have put  which is very good because if the same thing happened to a copper cable  there would be a surge and it could maybe burn some of your equipment so this is another reason people favor fiber optics a lot  refer slide time  26  55 ? 29  27  now the point is that this 50 terabits per second bandwidth that we were talking about is only theoretical actually sometimes  i have been asked what the bandwidth of this fiber optic cable is ? this really does not make much sense because the bandwidth of any fiber optic cable you would find would ultimately be dictated by the kind of boxes that you connect to it the limitations would be there ; the limitation is not inherent in the fiber fiber can take up a huge bandwidth as i just mentioned  but at the two ends you will have some optics and then you will have some electronics now electronics can not work at that kind of speed a single piece of electronics suddenly can not work at that kind of speed ; so the overall speed at the bandwidth that you can get out of this fiber would depend on the kind of electronics that you put at the two ends that is why there is a lot of interest these days in whether some of these electronics can be replaced by optics so that we can get much higher bandwidth now not content with just sending data through only one wavelength through this fiber  we have what is known as wavelength division multiplexing that means different wavelengths of light carry different signals through the same fiber optic channel ; that is called multiplexing we will come to wdm later on with this wdm  you can get higher kind of bandwidth lucent  for example  demonstrated 64 lambda ; that means  64 different wavelengths into 40 gbps that is each of them operating at 40 gigabits per second over a distance of 4000 kilometers  so i think that is really great there are two kinds of wavelength division multiplexing  namely  coarse wavelength division multiplexing  which is somewhat cheaper  and dense wavelength division multiplexing  which is used in wan but is much more costly sothe number of wavelengths that we can use today varies from may be 8 or 12 to may be 64 or so people are working on this ultra dense wavelength division multiplexing  which can carry us to may be 100 wavelengths in the same fiber  refer slide time  29  27 ? 31  02  for a quick history  in 1958 laser was discovered then in the mid-60s guided wave optics was demonstrated  in 1970  we saw the production of low loss fibers because we want this low loss  we will be talking about this loss presently after sometime so this made long-distance optical transmission possible there was the invention of semi conductor laser diode  which was important then in 70s to 80s we used fiber in telephony in the form of sonet or sdh do not bother about what they are right now ; we will be talking about them later on in mid-80s  lans and man were sort of being put in place and in late 80s  we had a breakthrough in optically amplifying optical signals so there is edfa and rbm  dot fiber amplifier ? we will be talking about that too in this lecture itself ; and then in mid to late 90s  this dense wavelength division multiplexing system started being put and in late 90s and in 21st century optical switching systems  different components of optical switching systems are been developed all the time the point is that fiber optics has such a tremendous potential that there was a lot of interest in this and there is a lot of work going on in this area at the moment  refer slide time  31  02 ? 32  17  so here is some kind of a picture of a cross-section of a fiber optic cable as you can see  when you see a fiber optic cable  you will see this fad jacket  which is just a productive jacket made of plastic  rubber ; then inside it  there will be glass fiber but what you see is actually not the fiber ; that is also actually a cladding but that is made of glass inside this cladding there is this very fine core  which actually carries the signal in one fiber optic cable like this  you will have several such individual fibers so these are all individual fibers what has been shown over here are the individual fibers and each of them will carry one ; i have shown only 3 over here but it is typical to have something like 4 cores  8 cores  24 cores  120 cores in one cable  refer slide time  32  17 ? 34  02  let us look at this diagram of how it is so if you take a cross section  there is cladding on two sides and core in-between if you sort of cut it side ways  this is the kind of picture you get and what happens is that once the light comes into the core it sort of refracts like this and it impinges on this wall at a very wide angle of incidence there is a difference in the refractive index between the core and the cladding that is always maintained so the point is that the core is at the higher refractive index and the cladding at lower refractive index there is total internal reflection over here  so even if the fiber bends a little bit ? although light usually would travel straight but through this total internal reflection it would follow this fiber ? it can take small bends and come out of the other side of the fiber but of course there are limitations to how much you can bend first of all  if you bend this core too sharply  this core will get damaged so there are limitations on what is your bending radius  radius of curvature  etc but in general to this total internal reflection the light will follow this core so this is another picture ? light is input from one end so this sort of follows the fiber and gets out of the other end  refer slide time  34  02 ? 35  02  well the light gets out  but how do you get it into something ? that means  how do you connect these fiber cables  which are actually glass fibers  how do you connect them to other things ? there are two ways of termination ; we can terminate a fiber by plugging it into a fiber socket and then sort of clamping them together we can splice them mechanically by putting the two cut ends into a sleeve and clamping them or we can fuse them to form a solid  which is a better method of connecting fibers even when you fuse them what will happen is there will be some kind of disturbance ? that glass material will not be totally homogenous at the junction so there will still be some loss but this loss is quite low if you are very careful in this splicing  referred slide time  35  02 ? 35  27  and what about light sources ? we have two different light sources ; they are called semiconductor lasers and light emitting diodes naturally  the first one gives out lasers whereas the other one  the simple leds  give non-coherent lights so they are simple leds both have their advantages and disadvantages  refer slide time  35  27 ? 37  19  when you are using the semi-conductor laser ? laser as you know is coherent light and simple led gives you non-coherent light ? so the data rate for lasers can be much higher with lasers and this is low fiber type you can use multimode fibers over here and you can use single mode fibers we prefer single mode fibres for lasers the distance that an led can cover is short whereas the distance that single mode fibers  that means lasers  can travel through a single mode fiber is really long so all our long-distance cables are actually single mode types and they carry laser since we are going to higher and higher speed all the time  we tend to prefer single mode fibers these days of course  led has a very long life so this is one area in which led is definitely better whereas laser ? s lifetime seems to be short  although not very short if proper care is taken  they will certainly run for several years the temperature sensitivity for led is minor so for semiconductor laser it is substantial  so its life source has to be maintained at a particular temperature led naturally is low cost and laser is more expensive these are the pros and cons of the two sources  refer slide time  37  19 ? 39  06  let us took take a closer look at the kind of losses that we have in fiber remember  when we were discussing about electrical transmission through some copper medium ? we were talking about it in the last class ? there are several kinds of distortion to the signal first of all  the signal strength tends to weaken as we go over a longer and longer distance ; that is called attenuation the same thing happens in the case of fiber also  in the sense that as we go further and further the signal will get weakened you can look at this way that if the signal did not weaken  then we can look through a glass of any thickness that is not true ; the transparency of the glass  although it is very highly transparent  is not 100 %  that is why as it travels down the fiber its strength will become lower and not only that  it will also get its wave shape and also get somewhat distorted due to certain phenomena for example  there is this phenomena of rayleigh scattering ; that means due to slight changes in the refractive index of the glass some of the light will get scattered then there are other kinds of scattering called mie scattering due to the imperfection of the cylindrical structure these losses are non uniform for different wavelengths that is why on the other end your signal will arrive first of all weakened  and secondly in a slightly distorted fashion  refer slide time  39  06 ? 40  09  this figure  this famous figure  is the plot of the loss that will happen to a light signal at different wavelengths as you can see  this loss in the fiber  given in db per kilometer  is not uniform you can see that it is not uniform across all the wavelengths so there are some wavelengths  namely here  where the loss is very low then there are other wavelengths where the loss is quiet high what we do is that we try to find some kind of windows  where the loss would be low and we can go to high distance because  remember that if the loss is low  refer slide time  40  09 ? 41  17  we can go much longer without any amplification or repeated kind of action and that is good i mean that would make the thing cheaper and of course we would be able to carry data for longer distance these are the three useful windows so to say  one is the 850 nanometer window  the other is the 1300 nanometer window  and another is the 1550 nanometer window around these wavelengths  if we send our signal  it will go a long way so these are the three windows  which are used for data transmission because of the very high frequencies involved ? you can look at the frequencies from these wavelengths  you can calculate and you will see that the frequencies are very high ? it can potentially have a very huge bandwidth so the theoretical capacity of the fiber is very high ; it is limited by the optoelectronic devices and boxes at the two ends  refer slide time  41  17 ? 43  23  now let us see if we want to take the fiber optic signal to a long distance ; naturally  i mean whatever window you use after some distance depending on the kind of source you are using  the kind of frequency you are using  the quality of fiber you are using  it may be 5 kilometers or it may be 50 kilometers but when you are going thousands of kilometers  at some point of time the signal will become very weak so you need some kind of repeater function what is the repeater ? the incoming signal may amplify or make the shape all right ; so there are all kinds of repeaters repeaters are different gates ; there are some repeaters  which simply amplify the signal there are other repeaters  which can also make corrections to the shape of the incoming signal  etc you need this repeater function in order to go to a very large distance so we will just take a look at this interesting phenomenon  how do you repeat optical signals ? optical signals traveling for long distances through fiber need to be strengthened this may be done through olts ; now what is an olt ? that is optical line transmitter  which takes the signal to the electronic domain and  of course  you can use a fresh source over there to make a nice and strong wave form and push it for the next leg of its journey the important thing is that this may also be done in the optical domain and the advantage of doing it in the optical domain is that you are no longer restricted by the bandwidth limitations of electronics so you can really operate at very high speed always in the optical domain and one way to do that is with  refer slide time  43  24 ? 43  58  erbium doped fiber amplifiers so erbium has a large number of excited states and from some of the excited states it gives out 1550 nanometer light  exactly the wavelength used in the third window in the glass so a few meters of optical fiber are doped ; that means a small quantity of this erbium is introduced in that ; the glass is doped with the few parts per million of erbium and is pumped with 1480 or 980 nanometer laser  to give amplification so what would happen is  refer slide time  43  58 ? 44  39  you look at this suppose this is the ordinary fiber  which is carrying the signal and there is some portion of it which is doped with erbium and a pump laser of certain frequency is fed into this so what will happen is that the erbium atoms in this region will be in an excited state  so erbium will be in a excited state when a signal photon comes  this sort of induces the erbium to come down to the ground state  giving an amplified signal so this is a very simplified version of how erbium doped amplification is used  refer slide time  44  39 ? 44  57  there are other kinds of this ; depending on what kind of pump laser you are using  you may go to this kind of excited state or this kind of excited state from which you can go to excited state one and so on but anyway  the basic idea remains the same  refer slide time  44  57 ? 45  38  because of dispersion  that is chromatic dispersion and polarization  mode dispersion wave shaping is necessary after some distance there are other kinds of combination of wave forms known as solitons ; these are waves shaped specially to match the dispersion characteristics of fiber so that a soliton would not be distorted for a long distance distortion can also be counteracted by reverse fiber so all kinds of technology are there ; we do not have the time to go into the details of these  but this is a very up-coming and growing field  refer slide time  45  38 ? 46  25  once again  why do we like fiber ? ? because repeaters are needed only every 50 to 100 kilometers as opposed may be 2 to 5 kilometers for copper ; not affected by power surges  electromagnetic interference  power failures  corrosive chemicals  etc ; communication in a fiber is usually simplex that means there is the source on one end  receiver on the other end  so in one fiber the data is really going in one direction so for two-way communication  we require a pair of fibers  but these two fibers have more capacity than 1000 strands of twisted pair  and that is really really great  refer slide time  46  27 ? 47  05  we will have just one quick look at where fibers are going ? people are putting fiber at a feverish pitch now one is the ultra long hall ? ultra long hall means we have fiber for a distance of may be thousands of kilometers then in the long hall we have this wdm or sonet  sgas etc  which is put by the telecom company or other communications companies then we have the wdm  atm  sonet  ethernet  etc in the metro  that means  within the same city  and now finally fiber is finding its way in the access side ? that means to individual users also  refer slide time  47  05 ? 47  41  these are the different ways fibers can reach your home  which is the ultimate goal of networking either you can take individual fibers to homes or we can take them to a switch  which is placed in the neighborhood and from there individual fibers go to every home there is also a concept of passive optical networking in that instead of keeping a switch out in the open  you put a passive sort of splitter  which splits the signal into so many parts so pon  passive optical network  is another possibility  refer slide time  47  41 ? 48  22  let us come to the other most important physical medium  namely  wireless one disadvantage of each of the data transmission methods that we have seen so far is that they are all wired connections moving from a wired connection to a wireless connection results in the ability to connect a network without having a physical connection what is the great advantage of that ? the greatest advantage of course is mobility that means if you are connected in a wireless fashion  you can move around but still remain connected  refer slide time  48  22 ? 49  24  this entire electromagnetic spectrum is used for communication this just shows a picture of that on the low end we have the radio  followed by microwave  which is of a higher frequency  followed by infrared  which is of still higher frequency then we have the visible light ; of course we talked about the fiber optics and this part has not been used for communication as yet  may be in future these are the kind of frequencies we have so the frequency range is tremendous ? from 104 or may be 1014 or 1015 or so we have these twisted pairs in this region  coaxial cables  maritime signaling  am radio  fm radio  tv  terrestrial microwave  satellite  fiber optics by the way  radio  and sometimes tv also  terrestrial microwave  satellite are all used for computer communication also  refer slide time  49  24 ? 49  40  these are the different names for the different ranges  we have lf for low frequency  medium frequency  high frequency  very high frequency  ultra high frequency  super high frequency  extremely high frequency  and so on  refer slide time  49  40 ? 50  08  transmitting data  data is transmitted through a wave just as with coax ; that means the higher the frequency  the more the data that can be encoded and transmitted narrow band is often used as the number of watts/hertz is high  and there are different pros and cons at different frequency bands we will just look at some of them  refer slide time  50  08 ? 50  35  sometimes a wide band is used ; using a wide band allows the transmitter to jump from one frequency to another in order to avoid communication jams and to hide detection that is just one example and this is nowadays used in ieee 802.11  which is a wireless lan standard we will look at this later on bluetooth is another wireless lan standard  refer slide time  50  35 ? 51  20  to start at the low end of the spectrum  at the radio transmission  this is very easy to generate  travels long distances and it is omni directional ; that means you have an omni directional antenna and you send your signal over there so it will travel in all directions and it will reach everybody around in a certain area that will not happen if you are using a very high frequency like microwave ; so at low frequencies  waves go to walls and power falls off sharply with distance from the source at high frequencies waves will bounce off of obstacles  refer slide time  51  20 ? 51  34  so there is a limit to the distance that a radio wave can cover vlf  lf  and mf bands are limited by distance on the ground high-frequency and very high-frequency waves can be bounced off the ionosphere  sending it back to earth  which is a very important thing  refer slide time  51  35 ? 52  01  this is a picture of what might happen in short-wave range ? you know the short wave radio ? you can listen to the radio transmission from usa what is happening is that it is getting repeatedly reflected off the ionosphere and reaching the other end of the earth  refer slide time  52  01 ? 52  23  there are problems with this wireless communication ; we will not go into all the details first of all there will be selective kind of attenuation  then there is a very irritating thing called multipath fading so what happens is   refer slide time  52  23 ? 52  47  for example  something like this  your signal may reach directly or your signal may reach through a path after getting reflected somewhere and these two may be out of phase so when they are out of phase  they will sort of cancel each other and you will have a very bad signal these are the problems we encounter in mobile phones  etc so you have to do something about these  refer slide time  52  47 ? 53  21  for microwave transmission  the transmission can be very narrowly focused so data can be moved from one tower to another you may have seen those microwave towers ; so they are sort of in line of sight with each other alignment is important because this is a focused beam if it is not aligned  your receiver will miss the signal altogether beams do not pass through buildings well these are the disadvantages of microwave if the waves are delayed  they may arrive out of sync  which is known as multipath fading  refer slide time  53  21 ? 54  13  finally  we have infrared and millimeter waves at the very high end of these ; of course  we have talked about optical fiber they are mainly used for short-range communication and they are strictly directional as we are going more towards the light  it is becoming more and more directed  as light is very directed so they are directional  cheap  and easy to use but they don ? t pass through solid objects you can not use them for a mobile phone  let us say  but you can use them for controlling your tv or for short-range connection to your computer from some handheld device  etc so this can be an advantage or disadvantage ? one way of looking at it is that since it does not go through walls  whatever you do in one room is going to not affect whatever you are doing in the other room so that may be an advantage also we tried to cover all the different ranges that we use in communication ; we have the satellites also as i mentioned  you have this geostationary satellites  which are nothing but repeaters on the sky  refer slide time  54  36 ? 54  50  so we can sort of send the signal from earth to the satellite  where it will be amplified and sent it back to earth these satellites could be geostationary or the satellites could be sort of low  earth orbiting satellites so they are also used for communication over long distances  refer slide time  55  00 ? 55  10  note  the rest is part of lec 5 faculty name prof sujoy ghosh lecture no # 5 multiplexing  shareing a medium  today we will talk about multiplexing  refer slide  55  27 55  34  multiplexing is about sharing a medium that means different users are sharing the same medium for communication at the same time  refer slide time  55  42 ? 59  54  another simplest condition a medium can carry one signal at any moment because if there are two signals over there they are going to interfere and then the signal will get garble but for multiple signals can share one medium the medium must somehow be divided giving each signal a portion of the total bandwidth if you remember that a particular frequency range around one particular frequency is called bandwidth and this band width is the most valuable resource so far as communication is concerned so what we tried to do is that we tried to use this bandwidth some how to to facilitate the communication between a number of pairs of senders and receivers so that is the idea of multiplexing  refer slide time  56  34 ? 56  43  these line increases it becomes more cost effective for the company and most data devices individually the require modest amount of data but when the when a number of users their requirement are aggregated together the sum total may be quite substantial band width  refer slide time  56  55 ? 57  10  the current technique accomplish this includes frequency division multiplexing wavelength division multiplexing time division multiplexing and code division multiplexing we will look at many of some of these at least  refer slide time  57  10 57  55  let us see so this is the scheme of multiplexing you have one multiplexer and then you have n inputs on one side so these n inputs are coming to the same multiplexer they are getting mixed up in some fashion and they are being sent over the same physical link and on the other side depending on in which fashion you have put them together they started separated in two different lines so these now these different lines in the right they can now go to different recipients so just as on the left we have different senders and we have different receivers over here so the so a number of sender receiver pair is utilizing the same physical link in  refer slide time  57  57 ? 58  12  now to for the types of multiplexer as i mentioned that we have fdm that is the frequency division multiplexing  tdm that is the time division multiplexing  stdm that is the statistical time division multiplexing so we will look at these  refer slide time  58  11 ? 58  36  just quickly before we go into get into the details of each of these time division multiplexing each user periodically gets the entire bandwidth that means the entire channel is dedicated to one user but only for a short period of time for a small burst of time after that it is somebody else so we will look at the details of this later  refer slide time  58  37 ? 58  38  computer networks prof  sujoy ghosh dept of computer science & engineering iit kharagpur lecture no # 6 telecom networks good day ! today we will talk about telecom networks that means the kind of network that is used by telephones and  of course nowadays  by a host of other things as we will discuss this telecom network  refer slide time  01  10  01  38  is very important in the sense that first of all it is one of the earliest networks that we had ; which means it is quite old secondly  the telecom network even today is mostly used for wide area communication we have much fewer entirely or exclusive data networks so we will look at the evolution of telecom networks  refer slide time  01  46  03  22  when alexander graham bell developed the first telephone  it was a couple of telephone instruments connected by a wire now if you are trying to connect more than one people  that means more than one subscribers  taking this principle forward  you will have to connect everybody to everybody else through wire  which of course becomes very unwieldy very soon it ? s because connecting the wires between every pair of telephones that might want to communicate was not a good long-term strategy at all very soon we could have a veritable jungle of wires and  of course  it means it is costly and very difficult to manage even at the subscriber end  you can not handle so many wires coming into your premise so a better idea was to connect all the telephones to a central switching office ; there an operator could connect one telephone to another via a switch board that is the next figure that you see ; that the number of wires have come down as a matter of fact  in the figure at the top  if you have n subscribers  naturally you have n  n  -1/2 links  which is approximately n2 kind of links ; whereas in the latter case  you have only n links so the number of links increases as n becomes large and you know today there are so many telephone subscribers ; so there is no question of connecting them individually you have to connect them to a central switching office and when some subscriber a wants to connect to subscriber b  it goes via the switching office and finally a connection is made  refer slide time 03  49-07  00  now in the switching office in this system  a telephone user could connect to any other telephone in the town by cranking a handle ; this was the old system you know in the old system ? if you have seen some of older movies or movies depicting an older time ? somebody would go to the telephone  lift it up  and go with the handle like this ? crank crank crank ? and what this would do is that basically this would ring some kind of a bell or give some indication in the central switching office the switch operator was of course a person  may be lady  who would know that this is the person who wants to talk to somebody then he would talk to that person and find out who it is or who the subscriber is to whom he wants to be connected when the subscriber tells connect me to such and such  through a wire  jumper wire  the telephone operator would connect this subscriber to the indented subscriber that is how it would operate in the beginning  which of course is a rather a difficult thing to do and it is unbelievable that with today ? s teledensity we can handle in that way so after this  this role of the person was replaced by some electromechanical gadget and those exchanges were called stowager exchanges there is an interesting story about the stowager exchange ? it seems that there was a person called mr stowager ; he was an undertaker you know who an undertaker is ; he sort of prepares coffins for a person who has passed away it just so happened that there was another undertaker in the same town  whose wife was actually the telephone operator so whenever somebody wanted to connect to an undertaker necessarily her husband would get the job so mr stowager thought that was not a good idea at all ; so he went ahead and designed some kind of electromechanical system so that there would be relays and mechanical switches would sort of rotate  depending on what you have dialed on the other side and connect this electromechanical exchange served us quite well and even may be 15 or 20 years back in this country you could see stowager exchanges were operating but of course nowadays  these electromechanical things have been replaced by electronic switches and the architecture also has become more complicated so this is how the switching office used to operate previously there would be an operator physically who would make a connection  who would make a physical copper connection through a wire from the caller to the callee  using jumper cable on a plug board and there would be a connection between the two telephones so that is how it used to operate  refer slide time  07  01  08  42  nowadays we have a picture which is something like this ; you can see that there is a local exchange building  where there is a local exchange switch  the kind of signal that is used for connecting this part ? the local exchange ? to the individual subscribers by the way this part is also called the local loop in telephone parlance so the telephones still use analog carrier systems mostly and you see there are two types of wires used over here  one is sort of connecting the premise of each individual subscriber to some kind of a housing  may be some kind of a hut over here  through a category 3 cable  which is a thick kind of black cable  which actually comes into your home so these cables  yellow colored  are much thicker  may be 50 pair or 100 pair kind of cables these category 3 cables in this hut are connected to this through this ; it goes to the local exchange where switching is done what is switching ? suppose this user wants to talk to this subscriber so there would be a switch over here because there are individual pairs of wires going from each subscriber to the local exchange and the switch would connect these two pairs of wires and they would have get connected this is the scheme  refer slide time  08  43  10  18  now when telephones developed more and more  naturally people found it very useful so it was soon apparent that callers did not just want to talk to people in the same town  but also to people in neighbouring towns now this was the next hurdle to be solved the first one was that the all pairs of telephones can not be connected together so every subscriber was only connected to the local exchange or the local switching office  where individual subscribers would be connected now if you have two different towns in two different locations  what would happen is that you can not connect all of them to the same local exchange this is a problem ; first of all from one town to another the distance would be quite large so irrespective of where you put your exchange  whether in this town or that town or somewhere in-between  there will be lot of wires involved and naturally this is not feasible so what is required is that there will be a local exchange for this town and there will be another local exchange for that town and these two exchanges have to be connected so this was the next step in telecom evolution ; so to connect every telephone in a number of towns to a single switching office was obviously impractical as the wires were too long  refer slide time  10  19  12  17  so we came to the so-called trunk exchanges ; now what are trunk exchanges ? well  there are local exchanges and if one local exchange wants to go through to another local exchange  it usually goes through a trunk exchange ; this is a two-tier hierarchy there will be some trunk exchanges and then each of the trunk exchanges would be connected to a number of local exchanges and the trunk exchanges would be connected between themselves in some fashion automatic switching office enables connections in a fraction of a second that means your connection request ? if it is local  then the connection request is just served by the local exchange that means if you just want to make a local call between two subscribers who are under the same exchange  it need not go anywhere else ; it can just simply be locally connected if the caller and callee are under two different local exchanges  it is possible that their local exchanges are connected but the general scenario is that they would go to the trunk exchange and the trunk exchange would connect to other local exchange and then that local exchange would make the connection available to the callee so this is how connections are set up as telecom grew bigger and bigger  you not only want to talk to the person in the next town  you want to talk to the person in next state and may be in the next county or a country around the world so in that case also more levels of hierarchy came into the picture as we will see here  refer slide time  12  17  12  47  and soon customers wanted to talk to people in different regions  states and other countries to cope with this  even more tiers were added to the hierarchy to make a call  we now dial a number this number is examined by the local exchange  which decides if it can connect you with local telephone or if it needs to connect you via a higher level switching office so this is the public switched telephone network that we have today or namely pstn  refer slide time  12  48  13  36  at the bottom of this figure we have these individual telephones  which are connected to the local exchanges and the local exchanges may be connected to some trunk exchanges these trunk exchanges may be connected to still other trunk exchanges and so on not only that  the picture is even messier than it is shown here for example  some of the local exchanges would connect between themselves straight away if there are lots of calls between two local exchanges  then the telephone company might like to connect fiber between these two exchanges for example  let us say in india  if you are making a local call  that is fine if you are making a call which is to an exchange that is just adjacent  then you would go through some connection between the exchanges if you want to make an std inside the same state then this trunk exchange would somehow go to the trunk exchange on the remote side if you are going out of a circle ? for example  west bengal may be a telecom circle and then bihar would be another telecom circle so the main trunk exchange of west bengal would be in kolkata and the main trunk exchange of bihar would be in patna ; so these two from kolkata to patna main trunk exchanges would be connected through very high speed lines and what would happen is that  it will go from the subscriber to the local exchange to the local trunk exchange to the main trunk exchange at kolkata and then to main trunk exchange in bihar  let us say in patna  and then to further trunk exchanges then further to local exchanges and then to the final callee of course  if you have international calls  if you are making isd calls  then you have to go through still other hierarchy ; that means  there are some particular gateways through which you will have to come before you can go out of the country  refer slide time  15  15  16  24  there is a question of routing a telephone call routing a telephone call means  how do you find this way ? that from one exchange to another exchange to trunk exchanges to other trunk exchanges and finally to the destination  you have to make a connection ; that means on each of the switch on the way  you will have to make some provision or some connection for this particular telephone connection so how do you find out ? for example a particular trunk exchange may be connected to a number of local exchanges and then number of other trunk exchanges also so how do you know which trunk exchange to go to next ? this is the problem of routing so you have to route a telephone call in older telephone systems  when you made a call the switching office set up a physical link called a copper path between your telephone and the callee ? s telephone the way that the copper path is set up is called routing in a telephone network  routing is usually straightforward and i will come to the reason  refer slide time  16  26 -20  12  a call is routed up through higher level switching offices until it reaches a switching office that can reach the destination telephone by connecting with lower level switching offices the switching offices examine the digits of the telephone number you dialed to make these connections so this is really in some sense fairly simple  in the sense that the way the telephone numbers are distributed in any country is in quite a systematic manner for example  let us say if you are making an std call in india  usually we start with the digit 0 now the digit 0 is not really a part of the number of the callee ; digit 0 is just indicating to the local exchange that we will have to be connected to some other exchange this is not the same local exchange so that is some kind of an escape from its local exchange to somewhere else but as i said  the telephone numbers are distributed in a fairly methodical manner for example  after 0 if it is 3  you immediately know that this will be somewhere let say near kolkata ; at least it will go through the kolkata trunk exchange similarly if it is 011  you immediately know ; you do not even have to look at the other digits and as a matter of fact for a remote caller or to the exchange to which the remote caller is connected  the other digits do not make any sense because they are really a number under an exchange which is far away  but it knows just by looking at the first few digits that that is the trunk exchange which i have to reach for example  somebody is making a connection from let us say kolkata to delhi now immediately you would know  suppose from kolkata so you start typing say 011 and then something  the local exchange would know that this is not only a trunk call  it is the so-called subscriber trunk dialing  std  call so this will have to go through the main tax exchange in kolkata in order to connect to that main tax exchange in delhi so it just makes the connection just by looking at those say first two digits and after that whatever digits follow  they will be looked at by the exchange at let us say delhi and then the next few digits may indicate a particular exchange in delhi so it will look at the next few numbers  maybe two or three digits and decide that that is the exchange to which it is connected so it is immediately routed to that exchange and that exchange will look at the last few digits may be and know that this is the subscriber  so the connection would be made so you do not have to really have to search around in the entire country to find out where this number belongs to ; just by looking at the numbers  looking at the digits one or two at a time  you can find out what the next step is that the connection has to take this makes the routing problem easy  unlike some other cases which we will get to later on but for telephone  the routing is fairly straightforward so it will look at the digits and make up the connection  refer slide time  20  12  23  17  and one point is that we are always talking about connections because essentially telephone service is a connection-oriented service what do we mean when we say that telephone service is a connection-oriented service ? it means that ? usually this is sort of changing somewhat a little bit ? the overwhelming majority of telephone connections are still connection-oriented in a connection-oriented service  what happens is that a dedicated connection between the end points is maintained throughout the session when you are actually calling  during the time by looking at the call number the path will be set up and at each point  at each switch  let us assume there is a physical connection  which may not be physical connection  but the connection may be some kind of virtual connection but for our purpose at the moment  let us assume that they are physical connections  so there is a physical connection at each switch so there is a continuous path from the source to the destination from the caller to the callee and this path is maintained  is held reserved  for this particular session during the entire session this is not shared with anybody else and this has number of advantages usually it means the quality of service can be reasonably guaranteed to the extent that the bandwidth for the channel that is established ? whatever bandwidth this channel might be having ? is exclusively for this particular call  for this particular session so there is no contention for bandwidth by multiple users usually we are talking about just landline phones for the time-being so first of all  the bandwidth is held constant  hence the quality of service is good second thing is that since the path  the actual path is held constant  the message bits arrive in the same order in which they are sent by the way  please note that this always need not be so for example if this path was not reserved and held constant for a particular session  that means if some part of your call is going through one path and some other part of your call is going through another path  then later bits may arrive earlier  depending on what these two paths are so such a thing would not happen in a telephone connection usually  so message bits arrive in the same order these are the advantages of having a connection-oriented service  refer slide time  23  18  23  50  so traditional telephone circuit is a circuit switched  that means actual physical connections are made with a connection-oriented system the downside of this is that it is less efficient use of the total available bandwidth the reason that this is less efficient use of the total available bandwidth is that whenever we speak there are ? for example  this is just one of the factors  there are many other factors ? considerable periods of time or epochs of time during which nobody is speaking at that time the channel is lying idle remember this particular channel that has been set up for one particular call is held constant during the duration  during the entire duration of the call so at that time nobody else can use it so this is one source why this is sort of inefficient use of bandwidth another problem  actually a very serious problem ? this happened due to historical reasons ? is that this traditional telephone equipment tends to be more costly now why is that so ? well  the reason is that this telephone system and the way the switches  etc  were designed at least the earlier ones had a long history  and naturally in this particular field  the rate of development of technology is very high and the next generation of technology would always have a tremendous cost benefit advantage compared to the previous generation of technology so it so happened that the computer technology started leading the technology base ; of course it does not mean that the traditional telecom technology was steady only at one point this was also evolving and the computer communication field was also evolving ; but it so happened that some competing technology  which is the so-called connectionless service  came about we have been talking about connection-oriented service in telephone  so in the connectionless service it always or it quite often has the advantage of using the next generation of technology  making it much cheaper and this proved to be a great hindrance to the traditional technology in telephones and that is why most of the traditional service providers are slowly now depending on how they are moving to this new technology  which essentially sort of sprang from another field and that is the so-called connectionless service  refer slide time  26  43  29  36  now  what is a connectionless service ? connectionless service is packet-by-packet ; this is not over the entire session ; one packet of data or that particular data may be containing first data so one particular packet is sort of thrown into the system and routed independently of all other packets so as we had seen earlier that this means that you have to have the destination address at each packet that is one thing ; so if you have the destination address in each packet  may be you can route it fast enough to reach the destination and the next packet from between the same caller and callee will come as another packet it will also have the same destination written on it and it may so happen that some router in-between is going to route it in a different path this connection is not held constant like the connection-oriented service this is a connectionless service ; it is packet-by-packet service this has some disadvantages also for example  one reason is that some of the lines may be good  some other lines may be bad and some of the packets may get dropped in-between secondly  what might happen is that a packet  which had been sent later  may  through a different path  arrive earlier at the destination so all these problems are there in a connectionless service ; but the major advantage of connectionless service  one major advantage is that it is cheaper it is cheaper firstly because it is somewhat more efficient than the traditional circuit switch systems  and secondly it is usually more efficient because it usually tends to use more recent technology in terms of silicon  in terms of ic  etc it has higher volume ; its pricing is lower that is attracting all these other telephone service people also into this technology and there is a definite shift towards this kind of technology by the way  you can take special care to guarantee that the packets are correctly received by the final recipient and in proper order but you have to put in some extra effort for that so we will look into this later  refer slide time  29  37  30  07  as mentioned earlier  each packet must contain the source and the destination address in order to be routed ip networks are based on packet switching technologies so this is what most computer systems use ; special techniques are employed to get some guarantee about the quality of service the technology being cheaper  it is beginning to dominate all networks  traditional networks as well as the current networks  refer slide time  30  08  31  57  by the way  i mentioned this earlier in the lecture that you must remember that it is not that we have a whole parallel network for data from computers  etc  all over the globe it is not there because the telecom network has been around for a long time ; it had a long and very excellent history so that is why even today most of the wide area networks traffic still rides on this telecom network originally it might have been a packet ; then it might be sort of made into some kind of a session for which some part of the connection is dedicated so all kinds of technology have come in  but even today most of the wide area networks are based on the telecom networks and telecom so that is one side of the story the other side of the story is that telecom networks  the telecom people  are actually in the process of routing some of the voice calls and may be some of the other kinds of calls into this packet kind of technology now about the transmission media in telephone systems  we have already talked little bit about it earlier  so i am not going into the details in traditional analog telephone systems the telephone is connected to the local exchange via category 3 utp cables  and the connection is called the local loop it is typically between 1 km and 10 km in length  refer slide time  31  58  35  01  higher up in the hierarchy  higher bandwidth cables are used to carry multiple telephone calls this is far cheaper than using separate cables for separate calls specifically digital lines on fiber are used analog systems use a technique called frequency division multiplexing to do this nowadays of course time division multiplexing is the most dominant standard so if you remember the earlier figure we had  we had this local exchange ; so your particular subscriber would be connected to the local connection hut maybe through a category 3 cable  from that hut a fat cable would usually run to the local exchange and this fat cable ? in most cases today are still basically a collection of pairs of cables ? is just in one sheath so that is why it is a fat cable  physically it is fat maybe there are 50 pairs of cables or 100 pairs of cables ; so if there are 50 subscribers coming into a hut  they can be connected through individual pairs in this bunch of pairs of cables that run from the hut to the local exchange so you may say that up to the local exchange we have these pairs of copper cables running but once you go to the exchange level and beyond  that means  higher up in the hierarchy  like  to the trunk exchanges and so on  there of course you need to carry lot of calls and usually this connection is through fiber so there are all kinds of multiplexing techniques but specifically time division multiplexing  which is the dominant one some specific version of time division multiplexing  which we will see later on  is used today a fiber may easily carry say 1000 voice calls or even 3000 voice calls just on a fiber ; so that is no problem at all for example  think of a connection between let us say two big cities a lot of subscriber pairs from both sides will want to talk to each other at the same time that is the great thing about these fibers  because they can accommodate a large number of channels so it has got a huge bandwidth so they are connected through fiber and all these calls are sort of multiplexed may be in time division multiplex fashion  which goes to the other end  gets the multiplex  and finally feeds to the local loops  which again are individual copper pairs  refer slide time  35  02  36  32  local loop  the subscriber handsets are powered by a battery bank in the exchange for example  i mean with at least the ordinary handsets  you do not need to connect it to any power ; it actually derives its power from the same cable which is coming and connecting your telephone set and with echo suppressors  the transmission is half duplex and with echo cancellors  it is possible to have full duplex communication so if you remember we talked about half duplex and full duplex communication half duplex communication means that the communication can go in either direction from this side to this side or from this side to this side  a to b or b to a ? but then  only in one direction at any one particular point of time so at some point of time a may be connecting to b or a may be transmitting to b and then a will become quiescent and b will be communicating to a through the same the line this is half duplex communication we require some kind of echo suppressors for this because otherwise we will be hearing our own voice  which is really irritating there is a way of echo cancellation and it is possible to have full duplex communication on the same line  refer slide time  36  32  39  07  since local loop is still analog we need modems for sending digital data that is  this local loop being analog has quite a bit of implications ; one of the implications is that when you try to communicate digital data over it ? and we are talking about this telecom network in the context of computer networks  but if you want to connect a computer network to a local loop ? your computer produces digital data so they have to be modulated and demodulated so modems always come in pairs for sending the digital data ; since one bit is used for control purpose we usually get 56 kbps speed on this local line you remember that the computer lines are designed to handle 64 kbps ; 64 kbps is the basic rate for communication purpose if you remember  we have this 4 k bandwidth  which has sampled at doubled the rate  which is the nyquist rate this 8 kilo samples  8 bits per sample is for indicating the level or the intensity of the signal ; so we have 64 kbps so this line is really designed for 64 kbps when you are sending a computer data over it  you are using a modem and these modem pairs  etc  they need to communicate with each other and there is one bit used for control purpose so finally we get a 56 kbps speed ; so that is why now almost everywhere you will see that the modem has 56 kbps speed people talk about 56 kbps modem ; that is where this particular figure comes from but of course although you may be having a 56 kbps modem you may not always get a 56 kbps speed because depending on the line condition  maybe some of the connections are weak  etc so however  it is noisy so it is picking up a lot of noise so depending on that  the two modems will automatically negotiate a lower speed and in actual practice you might find the lower speed for your computer communication  refer slide time  39  08  43  56  and just one another point before i go to signaling ? i want to mention that another implication of having fully analog technology in the local loop is that on an analog signal before you can use tdm or other kinds of multiplexing techniques higher up than all those in-between for connecting between exchanges  etc  you need to convert it to the digital signal over there so an exchange usually will have a bunch of codecs for coders and decoders and there are various coding and decoding standards but any way it will have a bunch of codecs  which will convert the analog signal which is coming through this local loop into a digital signal and now this digital signal is ready to be multiplexed with other digital signals to reach its final destination now let me tell you a little bit about signaling  this is a rather vast area ; we will just be touching upon it we will just mention some names and basically what signaling is signaling refers to the information exchange between terminal devices  exchanges  and routers for setting up circuits  termination  billing  advanced network services  etc so what it means is that when you are making a telephone call ? of course  suppose you are making a simple voice call  what you are finally interested in is that your voice should be audible to the callee at the other side and his voice should be audible to you so this voice should communicate ; that is the main communication which is going on through this channel  but in order to achieve this  all the intermediate nodes ? that could be a local exchange  that could be a trunk exchange  that could be sort of switches in-between  there could be routers and multiplexers ? have to get some information and then need to exchange some information for basic setting up of the line now apart from basic setting up of the line  you need other kinds of services of course from the service provider side  you need to bill a person if he is making a call  you want to bill him  and depending on whether he is making a local call or whether he is making an std call or an isd call  you may bill him at different rates similarly  for making the connections  we have to capture those digits and those digits have to be fed into the particular exchange ; it may be computers  routers  switches  etc so they have to be fed over there in order to make the connection all this is a part of signaling apart from the actual transfer of  let us say  voice or it could even be data but whenever you want to set up some call and take some service  some signaling will always be required so there are various types of signaling systems but it is sort of converging to some standards in common channel signaling there is in band ; by in band we mean the same bandwidth  which is used by the voice  is used by the signaling also why does it not interfere with voice ? well  what is done is that first of all usually this signaling would be suppressed even if they go on during the call but usually most of the signaling is done before the call is set up  so common channel signaling works very fine some of the bits in the frames are used for this purpose that means that finally  even your analog signal is converted to digital signals and you make a frame out of it  you could stuff this frame with some extra bits for this control purpose ss7  signaling system 7  is a widely accepted standard and this is slowly spreading ; this is a complex standard  refer slide time  43  57  46  39  but this is slowly spreading now whether in band or out of band  logically  the switch controllers may be considered to be in an overlay network in the control plane that means  you have all the switches through which the actual connection is taking place but then you have some switch controllers  which will actually give instructions to this switch  to switch in a particular fashion  or maybe do some billing  etc there is a network of switch controllers ; first of all  there is this network of subscribers that are connected through their voice set or may be through modem  etc  all over so that is the primary service-giving network but overlaid on this same network  you have these switch controllers at various points who are talking to each other for giving all these services and they are using the same network so this is some kind of an overlay network over the basic network that we have there are all kinds of extra services being given these days for example  you know that nowadays where ever ss7 or any other advanced signaling system is there  you can get the caller id that means if your local exchange supports it  who ever is the caller  his id  that means his telephone number  will appear in your hand set so that even before you answer  you know who it is that is calling and then you may choose not to answer his call anyway  you can make a note of it now how is that done ? the numbers that he dialed at his end ? circuit has been set up there and not only that  because the local exchange has to know the source number  the source number is also transmitted and finally fed to the receiver ? s end so that he gets the caller id number so all kinds of intelligent services are being given these days this is the signaling system 7 and there is an out of band signaling  which is different from in band signaling that means in out of band  for signaling purpose  a separate channel is always earmarked so they do not interfere with this regular channel at all so this is more flexible as it allows arbitrarily complex message transfer  refer slide time  46  39  48  43  so this is a state diagram ? a very rough diagram ? of the kind of states that the system goes through when a call is being made first of all  it is quiescent that means it is not doing anything then you take the receiver off the hook nowadays of course telephone services have improved tremendously ; otherwise  you would have noticed that the moment you take it off the hook and the moment you get the dialing tone there may be a gap actually these two are not the same thing  you pull it off the hook  which gives a signal to the local exchange that you want to make a call and the local exchange then finds some resource to serve you and when it finds the resource to serve you  it gives you a dial tone so when you get the dial tone  you know that the local exchange is ready to receive the numbers that you dial then you will dial some numbers and you have to wait for some time for the call to be set up if it is simply a local call  it may be a small fraction of a time ; if it is a long-distance call  you may have to wait for some time  for some appreciable time  when the call is being set up so  of course  the hand set on the other side starts ringing but that is not the ring that you hear when the local switch knows that the entire path has been set up  it sends the signal  which comes as the ringing noise to your phone so you know that the other side the line must have been set up and then they start talking the other side will also go off the hook and then they start talking and they will disconnect and at the time of disconnection  you want to know how much to bill this person  etc so we will quickly go through this control plane protocols of ss 7 i will just mention some names  for example  names of some elements ? you know that this is the very huge area   refer slide time  48  56  49  17  this software development for a telecom so these are some of the elements which are there in ss 7  application service element  that is application level functionality such as interpreting signaling messages  then the transaction capabilities  which allow systems to invoke procedure calls on remote machines   refer slide time  49  17  49  36  signaling connection control part sccp  connections  sequence numbering  segmentation  reassembly  flow control  etc some of these terms may not make any sense at the moment so we will discuss this later on in other context then there is a message transfer part3  part2   refer slide time  49  37 49  52  and part 1 one of the main applications of ss 7 is the telephone user part  which is responsible for setting up voice calls the tup interprets dialed digits  routes  reserves resources  and maintains accounts etc  refer slide time  49  53  50  19  now we will take a quick look at the digital technology in the telephone network as mentioned earlier  traditionally everything was analog then the exchanges started getting converted to digital technology  so a device called a codec is used to convert analog voice signals into digital information that can be handled by digital technology  refer slide time  50  19  50  47  the codec is also used to convert the digital signals back into analog on the other side  so that voice signals that can be handled by the older analog technology now most of the telephone network is digital ; only the local loop is still mostly analog there have been attempts to make this digital also and one of the items was this integrated service digital network  the so-called isdn let us take a quick look at isdn  refer slide time  50  48  52  07  isdn was envisaged as an end-to-end digital service ; that means it starts as a digital service from the user ? s premise and goes straight that way as a digital service right to the other end now home users would be connected by the same category 3 cables ; that was important because people are already connected by cat 3 cables and it is a very difficult and costly proposition to change all that cabling so the idea was to use the same category 3 cables for this new digital service there would be some kind of network termination on the end so there were two rates ; one was the basic rate  which was the 2b + d or 144 kbps ; 2 b means 2 voice channel of 64 kbps each  so that is 128 kbps ; and 1 d channel that is for the control purpose so you could do out-of-band signaling over here of 16 kbps  giving you a total of 144 kbps that is the basic rate for isdn for higher users  you have a primary rate equivalent to e 1  so there are 30 channels for this  maybe voice channels  and 1d channel  etc  for an e 1 line  there is some thing else in usa ; that we will see later  refer slide time  52  08  52  25  the system uses out-of-band signaling and uses the d channel for that nt1 is the network terminating device  which connects to the isdn exchange on one side and a local passive bus on the other  refer slide time  52  26  52  33  for larger users we have another kind of termination called nt 2 the isdn turned out to be very expensive  which was a problem isdn was originally envisaged as a very broadband service with voice data  etc on this same isdn  but unfortunately  because of historical and technological reasons  the isdn turned out to be quite expensive so  although it was deployed in some places ? it is also deployed some places in india and a lot of places in europe ? since it was so expensive  it did not become popular so that was the problem with isdn ; so people thought about an altogether new technology called atm and we will discuss atm later  refer slide time  53  12  53  34  another direction  in which this digitizing the local loop went  was the digital subscriber loop or dsl so it had two basic approaches  one was that for the large user  let us say  a particular office or company you can take a fiber to the premise of that company  which can be integrated like a sort of outlet and you can give all kinds of services ? that is one thing the other is to use the same category-3 cable ? maybe different bands of it using some advanced technology of multiplexing signals and then give both data and voice at the same time on the same line  refer slide time  54  01  54  07  so you have this remote subscriber terminal  which is connected to the individual users  refer slide time  54  08  54  19  the copper twisted pair remains the same  but the new equipment is integrated  enabling a service provider to deliver voice and high-speed data service at the same time  refer slide time  54  20  54  56  so this is the picture that shows subscribers who are connected through the analog and dsl lines now in the centre of the side  you have some kind of a splitter and in this splitter  one side is the data  one side the data goes through this d slam  which is digital service digital service access multiplexer so that goes maybe to the internet  the other part goes to the voice switch to the pstn  which is the other  plain old previous voice services  refer slide time  54  57  55  22  so dsl at subscriber ? s end has voice traffic that is transmitted as standard analog telephony signals ; data traffic is transmitted over the same line but via a dsl modem that transmits the data as high-frequency digital broadband signals on the same line so if you have dsl modem  you can have both your voice as well as data at the same time  unlike ordinary analog lines  refer slide time  55  23  55  35  so with dsl at the central office end  co end  the signals pass through a splitter as i have shown and a local loop management system  so the subscriber line access multiplexer is there  refer slide time  55  36  55  38   refer slide time  55  39  55  43  you can just have this figure where we have dslam and the loop management over there  refer slide time  55  44  55  56  the broadband digital signals are directed to a dslam that terminates and coordinates traffic from multiple local loop lines  from the dslam the traffic is sent to a router and then to the internet and finally we have the loop management system   refer slide time  56  03  which may be in front of the splitter or behind the splitter so this performs various functions as they are like giving the connections ; testing ; and all these services are done through the local loop management thank you preview of next lecture lecture name # 07 switches  i good day ! so today and in the next next lecture we will be talking about switches  switches are the most important part of computer networks and we will just look into some aspects of the different types of switches ; so first in this lecture we will start with the some kind of switches which are used in the telecom networks then there is special special version of these which we will cover in a later lecture and then in the next lecture we will be talking about packet switches which are closer to the heart of data networks so we talk about switches first thing is why do we need switches well ? ? ? ? ?  refer slide time  57  29  58  05  the problem is that each user can potentially call any other user as we have seen in telephone networks so and we can not have direct lines we can not have order in square kind of lines so every user is connected to a essentially a switch in the switching office and switches establish temporary circuits that is they establish a temporary connection between the caller and the collie at the switching station and switching system comes in two parts one is the switch and the other is the switch controller  refer slide time  58  06  you see this fellow say zero zero zero zero wants to talk to zero zero zero one so he will simply go like this and similarly another another line over here may wants to go straight down to somewhere over here so many calls can go through together but this is not always the case now always the case as there may be contention for the same switching element as we will see in this diagram you know because if if you produce something in very large number you can ammonites the cost of its development etc.over a large number of switches so this cost of this switch comes down so ethernet switches have become very cheap these days a switch which use to cost may be lack or so may be 10,15 years back cost only few 1000 rupees today so this is the most common type of switch which we see every where computer networks prof sujoy ghosh dept of computer science and engineering  iit kharagpur lecture # 07 switches-1  reference time  00  45  good day so today and in the next lecture we will be talking about switches switches are the  refer slide time  01  01  01  03  most important part of a computer networks and we will look into some aspects of the different types of switches in this lecture we will look at the kind of switches that are used in telecom networks there is a special version of these  which we will cover in a later lecture and then in the next lecture we will be talking about packet switches  which are closer to the heart of data networks first thing is why do we need switches ?  slide refer time  01  38 ? 02  15  the problem is that each user can potentially call any other user  as we have seen in telephone networks and we can not have direct lines we can not have an order n2 kind of lines so every user is connected to essentially a switch in the switching office switches establish temporary circuits ; that means they establish a temporary connection between the caller and the callee at the switching station switching systems come in two parts  one is the switch and the other is the switch controller  refer slide time 02  16 ? 03  41  as you remember from our discussion about telecom networks  people want to talk to other subscribers  who are in maybe a different location  under a different switching station the switching stations have to connect among themselves for making this connection through the signaling that we talked about  there is a control plane over here control planes are some kind of computers  which are capable of sending some kind of signals or instructions to the individual switches in the control plane  we set up the path and there is a corresponding signal from the controller to the corresponding switch for setting up a particular circuit or a particular connection  so that an end-to-end connection from one user to the other is set up this control plane is sort of an overlay network over the actual switch  and once the connection is set up naturally the call and all the signals  etc  flow in this plane  refer slide time 03  42 ? 04  10  there is a network device called a router and there is routing  which is very close to switching the only thing is that in routing  we decide about long-range paths if you remember from our discussion about the seven-layer osi protocols  you remember that there was a network layer and the router is a device in the network layer whose job it is to find out that in order to reach the ultimate destination station  what is the local link that i have to take here ? for a switch it is slightly simpler ; it is strictly a local decision but for the router there is a global implication ? what is the local link on the output side that i must take for a signal coming from input line to a particular destination  so that i will finally go through all these connections through various other routers to reach my destination  whereas for a switch the job is a little simpler in the sense that when the signal is coming from one incoming link and is going to go out to a particular outgoing link  which is known at the switch  how to set up the connection ? actually  a router is a switch with some added functionality  refer slide time 05  34 ? 06  22  many connections will need paths through more than one switch  so that is when we required routing static routing uses the same approach all the time ; that means same destination is routed through the same path all the time a dynamic routing may allow changes in routing depending on traffic ; that means some part of the network may be congested  so it might want to avoid that path and go to the same destination through some other path as we have seen at least in telephone networks  because of the way we distribute the telephone numbers to subscribers  it is easy to route you can look at those incoming digits and just decide on the route switching is the local connectivity between input and output lines now we will discuss some basic concepts and terminology  refer slide time  06  31 07  21  one is the transfer medium ? transfer medium in a switch  could be buses  electronic buses  through which you can send a stream of cells queues are memory locations that temporarily store cells switches often require some queues ; the queues may be on the input side or the queues may be on the output side ; queues may be in various places so we will look at all these different cases but these are temporary memory locations  where we temporarily store some cells till we know what to do with it or forward it to its destination a switching element is the building block for the switch a switch may be either on or off and if it is on that connection is there or if it is off the connection is not there sometimes the switch is like this ? at a particular point a switch may connect either to one point or to another point a switch is just a simple element and in a big switch  we have a lot of these switching elements these switching elements form the so-called  refer slide time  07  58 08  09  switching fabric ; that means the shape of the switch  like  how the switches are organized so that all the incoming calls can be handled there is a term called blocking and non-blocking  refer slide time  08  18  08  35  blocking means a network is unable to connect stations because all paths are in use a blocking network allows this this is used in voice systems and the main reason is that we have short-duration calls the point is that there are so many subscribers  may be thousands of subscribers ; if we want to provide the switching capability to the maximum possible extent  that means  if everybody is busy talking to somebody or the other  that means  if every subscriber is using this  then if we try to provision our equipment based on this assumption that everybody may be talking to everybody at the same time  then the switch will become very big and very expensive so what the telephone people have done is that they have made an extensive study of how many people are likely to talk during a particular time of the day  especially bell labs in usa they were the pioneers and a giant telephone company  which was the largest at one point of time  and later was broken up etc during the early part of may be 1940s and 1950s  they made a very extensive study about people ? s calling habits they found out that during the busy time or the peak hour when all the officers are open  how many people out of a subscriber base are likely to call that is one kind of statistic they collected ; and the other kind of statistic they collected is that if one person starts talking what is the distribution of the call duration ; for how long is this particular subscriber likely to hold on to that line they found the statistical distribution ; and based on that they decided that if i provision this much in terms of our switching elements and switching capacity  then almost all the time everybody will be able to get the service  but exceptions may occur this is based on some statistical study at some particular point of time it may so happen that the number of subscribers who wanted to speak is just larger than the overall switching capacity that you have in that case some of the calls will be blocked i am just talking in terms of switching capacity this kind of blocking may occur elsewhere in the network also we provision based on some statistical averages but at exceptional times  for short durations of time  we may have to block some of the calls because we do not have the capacity to handle so many calls at the same time so that is a situation where it is blocking and what people try to do is that they try to calculate the blocking probability  which may be 1 %  2 % or 5 % ? 5 % is quite high  as nowadays people do not even like that that is the blocking probability that we wish to achieve ? we are provisioning this much for these many subscribers  refer slide time  12  08 ? 12  38  non-blocking permits all stations to connect in pairs at once this may be used for some data connection where blocking is not allowed or blocking is not acceptable under any circumstances if you want to make it fully non-blocking  that solution would be more expensive than if you allow a limited amount of blocking of course a high degree of blocking will not be acceptable to the users at all  refer slide time  12  39 ? 13  21  there are various kinds of switches i am trying to present here a taxonomy of different types of switches ? not that all actual switches neatly fit into the boxes some of them take some portions of this and there is some kind of a hybrid or mixture but this is one way in which the different types of switches can be classified we have space division switching and time division switching like in multiplexing we have a time division multiplexing and frequency division multiplexing  here we have space division switching and time division switching time division switching is very close to time division multiplexing as we will see now space division switches  refer slide time  13  37 14  22  maybe single stage or multistage in single stage we have a switching matrix ; then we have a knockout network  shuffle exchange networks in multistage  it may be a single path or multipath like delta networks or benes networks  sorting networks  etc in time division switches we have shared memory and shared medium shared memory could be a central memory or shared medium could be a bus or a ring etc ; so these are different types of switches we will not have the time to look at all these in detail so we will just look at some of the very common types of switches that are used  refer slide time  14  23 ? 15  25  let us first talk about space division switching it was developed mainly for analog environment why do we call it is space division ? because the different calls go through separate physical paths that is why they are called space division switches  unlike time division  where different calls may be going through the same physical path at different time slots ; we will come to that when we discuss time division switching but in space division switching  different calls go through separate physical paths the simplest of space division switches is the cross bar switch the number of cross points grows as the square of number of stations ; loss of cross point prevents connection ; if a particular cross point becomes bad it is an inefficient use of cross points ; all stations are connected but only a few cross points are actually in use ; and this is fully non-blocking let us first have a quick look at a cross bar switch a cross bar switch is very simple  refer slide time 15  32 16  36  what do we have in a switch ? in a switch you have n input lines coming on from one side and n output lines ? you have to connect some of the line let us say i want to connect this particular line to let us say this particular output line  i.e  the fourth input line to be connected to the fifth output line i want this particular switch to be on and the other switch off if this particular switch is on  there is a connection between this line and this line so i have a direct physical path between the fourth input line and the fifth output line and each of these crosses that you see is a single switching element and as you can see  since there are n lines i.e  if there are n lines on the input side and n lines on the output side  we have n2 switching elements  which actually is quite a lot  refer slide time  16  37 16  38  so if you go back  refer slide time  16  38  17  49  the number of cross points grows as the square of the number of stations if a particular switch  which is at the crossing point between the fourth input line and the fifth output line  if that particular switching element  somehow has gone bad  then four and five can not talk to each other ever that is again another drawback of this kind of switches of course it is an inefficient use of cross point ? at every cross point we have a switch and all stations are connected but only a few cross points are actually in use at most n/2 cross points can actually be in use  whereas we are using n2 cross points  which is a really a poor utilization of the switches one good thing about this kind of switch is that it is totally non-blocking ; that means  all pairs of subscribers can talk to each other at the same time  refer slide time  17  50 ? 18  52  the cross bar switch is the simplest form of n input lines and n output lines that feed to n2electronic switches if all lines are full duplex  that means all lines allow communication in both the directions  then we require only half the number of switches we possibly do not require the diagonal switches  the switches which are in the diagonal i do not want to talk to myself ; the other thing is that only either the top half or the bottom half of the switches ? top half means top half of the principal diagonal or the bottom half of the principal diagonal ? only those switches are required  in general n2/ 2 switches would be required if you have full duplex lines the other problem about the cross bar switches is that apart from the number of switches  the number of i/o pins is also a problem if you want to a make let us say 1000/1000 line switches for 1000 subscribers  you may have 1000 incoming lines  1000 outgoing lines  but how do you put all these 2000 pins on the chip ? it also becomes a problem ? people have gone to more sophisticated design for switches they are classified in various ways  through input queuing  output queuing  refer slide time  19  32 ? 19  34  or central queuing we will look at these one by one later on  refer slide time  19  35 20  05  let us look at another kind of a space division switches known as knockout switches  which were introduced in 1987 by at&t bell labs essentially we require using output queuing over here we will look at output queuing and the issues in detail later on if the switch is trying to pump in more number of bits or more number of bits to a particular output line than that an output line can handle  you have to either drop them or you have to store them somewhere  maybe in a queue  and that queuing is associated with the output ports that is what we mean by output queuing so n inlets  refer slide time  20  26 ? 20  44  and n outlets operate at the same speed transfer medium consists of n broadcast buses  one for each inlet n bus interface units  one for each outlet  takes input from all the broadcast buses each delivers an output to its own outlet let us take a look at the figure  refer slide time  20  47 21  52  so we have the n input lines on one side a call may come from anywhere  let us say subscriber 1 is trying to call to subscriber 2 so what subscriber 1 will do is that it will broadcast the signal over this bus there are n buses over here and all these n bus interface units are connected to all the buses  each of the bus interface units ? 1  2  3 up to n ? will receive that signal from n but this bus interface unit 2 knows that this is supposed be meant for me so he will allow this signal to transfer to the output line  whereas others will simply ignore it this is again another fairly simple scheme we have  of course  reduced the number of switching elements that are required  refer slide time  21  53  22  01  it is not using a bus  and you will not get a very fast switching  but this works fairly well if you want to go beyond this  that means  you do not want so many lines  etc  as i said and even if you have 1000 subscribers you want to service from the same switch  even in knockout switch you have 1000 buses inside  which is not technically feasible so we go to the other kind of switches which i showed earlier ; namely  multistage switches and multistage switches have one of the most commonly used switching architecture even today  so far as space division is concerned in multistage switches we may actually provision less number of switching elements than are strictly required for the highest use  as we want to reduce the cost of the switch all the input lines can go to all the output lines and it is broken up into several stages as we will see  refer slide time  23  19 ? 24  04  the advantage of a multistage switch is that it has reduced number of cross points  more than one path through the network ; this increases reliability as you remember  in our simple cross bar switch  if one particular switch is bad that particular pair of users can not talk to each other ; that is not really desirable since there are more than one path through the network  even if one particular switching element becomes bad they are still able to communicate the control becomes more complex and it may be blocking so  as i said  in most of the cases it will not block  but in some cases  it may be blocking  refer slide time  24  05 ? 24  36  they have a large number of inlets and outlets which are  sort of  grouped into small groups so that these problems with pins and input lines are not there often they have identical switching building blocks  forming a fabric so there are many switching building blocks consisting of some number of switches and such modules are used all over the switch as you can guess  in a multistage switch  we will have different stages the input will come from one side and will go to one stage  then may be another stage  and a third stage  and then may be out so there are multiple stages and each stage is broken up into small modules these modules may or may not be identical  so it is sort of cheaper to manufacture and it also handles all the pins  etc  in this fashion so it often has  refer slide time  25  11 25  15  identical switching building blocks forming a fabric  and a fabric has multiple stages  refer slide time  25  16 ? 26  16  this is just one example of a small multistage interconnection network so as you see  this is one stage  this is another stage and this is the third stage there are three stages over here each stage is broken up into small blocks ; so this is an 8 ? 8 sort of switch if you remember to have 8 ? 8 switches in our cross bar switch  we require 64  or even if we take half of it  maybe 30 or above 30 switches here each is a 2 ? 2 switch ; so actually you can handle it with only one switch the number of switches has come down drastically but there are problems  as we will see  that it may be blocking kind of system  refer slide time  26  17-28  01  so how do you know that something  which is coming over from an input line  would reach the particular output line ? suppose the output lines are numbered and since there are eight output lines  we can code them using these three bits  from 000 to 111 in a binary fashion this particular line  which really is the input line number 011  wants to have a call to the output line number 101 if you know to which output line you want to go to  1  0  and 1 really become control signals for these switches on the way so 1 means go to the lower output line ; 0 means go to the upper output line and you can see that those that are starting with 0 come at the top  those that are starting with 1 come over here and that is the same binary number order that we are maintaining the switch is simply a rule that if it looks at bit  if it is 0 it connects to the upper line and if it is 1 it is connected to the lower line so 1 will connect to the lower line  0 it will connect it to the upper line 1 over in this stage will be connected to the lower line and we will reach 101 this is almost self routing through the switching fabric and because of this  routing is easy  refer slide time  28  02 ? 28  34  delta network is one kind of a multistage interconnection networks it is constructed of identical k ? k switching elements it has regular interconnection patterns suitable for a large-scale chip integration it is self routing as we have shown  requiring log_k n number of digits and a log-k n number of stages each  with n/k switching elements so  refer slide time  28  34  29  53  this is the picture that we had seen earlier ; this is the diagram of a bigger delta network  may be with 16 input lines and 16 output lines as you can see  this is a four-stage switch  because in order to code for 16 lines  it will require four bits from 0000 up to 1111 each bit decides whether that particular switch connects you to the upper output line or the lower output line and from any of these input lines there is a path to any of the other output line this is the 16 ? 16 banyan network as you can see  by doing it in this multistage fashion in a regular cross bar switch  while we require some thing like 125 switching elements here  you require only  say  32 switching elements so the number of switching elements is much less  refer slide time  29  54 ? 30  11  but there may be a problem of contention in a delta network cells can be simultaneously switched through the network however cells may have to contend for the same switching element let us go back to the earlier diagram  refer slide time  30  13 ? 30  39  you see this  say  0000 wants to talk to 0001  so he will simply go like this and similarly another line over here  may want to go straight down to somewhere over here so many calls can go through together but this is not always the case there may be a contention for the same switching element as we will see in this diagram  refer slide time  30  42-31  58  let us say 0 1 1 0  so 0  1  and then 1,0 ; 0 will come here  then 1 will go straight ; 0 1 1 0 ; and then 0 1 0 0 so 0  upper 1  1  and you see that we have potentially got a contention for the same switching element from two different points in the network ; it is sort of converging to the same switching element before it can proceed so there is going to be a contention over there if there is a contention  obviously both of them can not be handled at the same time ; either one of them has to wait you have to make it wait by putting it in some buffer  etc  or one of them will have to be blocked or dropped although we save on the number of switching elements  sometimes we get a contention some ways to reduce contention is  refer slide time  32  26 ? 32  37  to provide buffers in every basic switching element  increase the internal link speed relative to the external speed  and use a backward feedback these are different sort of techniques to reduce contention one is of course providing buffers as we have already discussed ; you could increase the internal link speed relative to the external speed that means if the internal link is much faster than the external speed at which you are pumping in  then it may be able to handle both of them so far as the input streams  refer slide time  33  04 ? 33  31  or the output streams are concerned  they will not notice the faster switching that is going on within the switch so that they will think that there is no contention you can use backward feedback ; that means  at some later point in the main if you find that there is a contention then give one of them feedback so that it sort of re-circulates  refer slide time  33  32 ? 34  07  the other ways are to use multiple networks in parallel ; provide multiple links internally between switching elements ; and shuffle cells first so that they do not collide later this is also another kind of switch that is quite common ; it is known as the batcher banyan switch we have seen the banyan switch part ; in batcher part there is some shuffling of the input cells so that in the banyan part they do not collide by contending for the same switching element  refer slide time  34  08 ? 34-57  in the space division switch  the big switch is broken into multistage smaller chunks i will show a three-stage switch suppose i want an n/n switch ; suppose it were a cross bar  then it would be an n/n switch this is replaced by n/n number of n ? k switches in the first stage  followed by k  n/n  ?  n/n  switches in the second stage  followed by n/n number of k ? n switches in the third stage so let us take a first look at a simple example  refer slide time  34  58-35  57  so this is a three-stage switch ; in the first stage  we have 10 of them so n is 10 ; and k is 2 so we have 5 ? 2 switches we have 1 2 3 4 5 at the input stage  so n/n  that is  two of them or 5 ? 2 switches and then two 2 ? 2 switches followed by 2 ? 5 switches let us say 5 wants to speak to 2  so 5 comes here ; gets switched in this fashion to 2 ; and 6 wants to talk to 1 so 6 goes to this switching fabric in this fashion in the third stage  refer slide time  35  58 ? 37  59  if you take the general case of n = 1000  n = 50  k = 10  this reduces the number of switches to 24,000 from about 500,000 because 1000 ? 1000/2 is 500,000 ; that is  the number of switching elements you would require for a simple cross bar kind of switch  whereas by breaking it up into three stages in this fashion taking this particular value of n = 50 and k = 10  you reduce the number of switches to 24,000 however  the switch can handle only n * k/n so if n = 1000 and k = 10 and n = 50  so n * k/n would be 200 so only 200 simultaneous calls  so only 400 users can use it at the same time as i mentioned  it may be fairly alright because you have a phone but you are not talking on that phone all the time ; most of the time actually it is just lying idle if the telephone company makes a good study and finds out that 400 is the maximum number that is sufficient for a very low blocking probability even during busy hour  then that is fine  refer slide time  37  34 -38  24  the general scheme of this is that you have n lines fitting into each of these n/n modules at the first stage so you have a total of n lines fitting into one module so you have n ? k kind of switches so that this switch can be directed to any of the switches on this side so there are k of them here there are n/n switch modules in this first stage  k modules in the second stage  and again n/n modules in the last stage  third stage so you have  n/n + k + n/n  modules  refer slide time  38  25 ? 39  28  in the multistage interconnect network  you may either have a connection based kind of system  that means  once a connection is made it is permanent till the call is held  as we have in a usual telephone network  or it may be a cell-by-cell  that means  although the user sort of goes on having the conversation  his stream of bits is divided into small cells and each cell is individually routed through the main many connections will need paths through more than one switch ? cell-based means routing tag versus network-based  which is routing tables so if you have tags it is faster ; if it is table it is slightly slower and as i said  the static routing uses the same approach all the time ; dynamic routing allows for change in routing depending on the traffic so what is a tag ?  refer slide time  39  32 ? 39  35  you remember that in a delta network we were putting 001 etc ; we were encoding the input or the output  specifically the output lines  and then using that address so that the cell can route itself through the network that is an example of a tag  which means that within a switch each of the lines has got some kind of code in it ; you might call it tag this tag will be used for routing now if it is self-routing  like the one shown in delta network  which is very simple  it will be very fast if it is some other kind of tag we are using where such a simple scheme does not hold  then maybe we have to look up to some table to find out where i want to go with tags  cells can be  refer slide time  40  27 ? 40  58  augmented to include extra header information when they enter a switch that means you look at which is the output line it wants to go to and then add the code for that output line on to this cell  which sort of becomes the tag for example  with the siemens atm chip set  each 53-byte octet or byte cell is augmented to a 64-byte cell as it enters the switch so these extra bytes are for putting in this tags  etc this extra information speeds up the routing process  refer slide time  40  59 ? 42  09  in a connection-based system ? we discussed this earlier  but once again ? the path is determined once for the duration of the connection that means  once the connection is made  for the entire duration of the connection the path remains the same all cells of the connection follow the same path now it may be a connection-based system with cells ; that means  once the connection is set up  a particular path is designated that this is the path all the cells  which are originating for this particular call  will take so  all cells of the connection follow the same path this guarantees proper sequencing of cells ; of course  they will now go in an order the connection  of course  may be refused  that means when you are trying to set up a connection you find that in an intermediate stage there is not enough resource there is too much contention for that  so the connection may be refused paths can be determined by a combination of random selection to distribute the load if you remember  in a multistage switch specially  there are various paths from the input to the output ; there are various possible paths  so that if one path is not alright because of some defect or one path is not very good because at that particular point of time that path is loaded  you may route your path through some other path of the switch  refer slide time 42  32 ? 42  49  you might do a random selection amongst the paths to distribute the load  do a careful selection to arrive at the correct destination ? if this and this selection can be done either centrally or in a step-by-step fashion as is done in a delta network  refer slide time  42  50 ? 43  49  we have different types of switching ? we have connections plus tags  you have connectionless  which are tags of course we will look at connectionless switches in more detail when we discuss packet switches so the same discussion that we have now  part of the discussion that we are having here  could also be useful in the next lecture we have connectionless plus tables  that means  if tags are not possible you have to do some table lookup because this table lookup will always be slightly costly in terms of time the kind of speed that you can achieve with a table lookup becomes limited because of that ; but any way if this is again a possibility that you can have connections-oriented system by using tables  you can have connectionless systems using tables ; this is also used in routers specially  refer slide time 43  50 ? 44  40  we will look into buffers in more detail when we discuss packet switches buffers may be complete sharing  which is the best utilization of memory and best for bursts of equal loads complete sharing means everybody can share all  so there is a central memory kind of thing  which is shared it may be a complete partitioning ; naturally complete partitioning would be faster and best for unbalanced load partial sharing means some of it may be centralized  some of it may be distributed  etc there may be various strategies regarding buffers  refer slide time 44  41 ? 44  43  next we come to time division switches ? time division switches follow almost the same principle as time division multiplexing  in which the same line was being used for communication by different channels ; what we did was that we kept a specific time slot for one channel and these time slots go in a round robin fashion so after a particular frame is over  that means  all the input lines have had their time slots then one particular channel will get back its second time slot  and so on so it will go on in a round robin fashion we use the same principle in time division switches ; in time division switches the bits or bit streams may follow the same path  that means  different calls are following the same path but they are using different time slots so a fixed  refer slide time  45  55 ? 46  17  the number of bits from each line is read into a ram in order ? this constitutes a single frame that means a fixed number of bits from each frame  each line a mapping table reads from the ram in a different order for switching from line j to line k  the j th location is read in the k th step  refer slide time 46  18 ? 47  27  this is shown here suppose these are the input lines 0 1 2 3 4 5 6 7 the output is read in a somewhat different fashion 4 7 6 3 0 5 2 1 that means actually whatever the 0  its line 0  puts in this slot would be read by line 4  because line 4 is reading in that time slot so line 0 is  in effect  connected to line 4 similarly  line 1 is connected to line 7  line 3 is not connected to anybody it ? s idle at the moment  so 3 3 ; similarly a 5 5 ; so it is idle similarly  just as we have 0 4 we 4 0 ; so this is a bidirectional communication  duplex communication going on so in the first slot or  let ? s say  the 0 th slot  the line number 4 reads it and in the 4 th time slot  line number 0 reads it so line 0 is switched to line 4  1 to 7  etc lines 3 and 5 are idle  refer slide time 47  28 ? 48  29  basic components of a tdm switch ? we will not have the time to go into the details of this it has a dedicated internal buffer memory  distinct from the ram memory used for program code and data and this buffer will sort of contain the bits which are to be written into and read often on a completely separate physical module  that means  printed writing card usually it has at least two dma bidirectional serial ports if you have studied operating system  that is direct memory access  which is used for fast communication without the intervention of cpu  that is dma of course we want this as fast as possible ; so dma bidirectional serial ports  input and output  are simultaneous on each port with dedicated hardware for each operation so our memories are very special ; that means  they have multiple port memories and serial i/o on each port this is a very simplified block diagram  refer slide time 48  32 ? 49  25  usually in your line  the bit stream will come serially but on the bus internally we want to put them together  maybe 1 byte at a time so we have a serial to parallel converter for getting 8 bits and converting it to a byte  which will be fed in parallel so database goes into the buffer ram memory ? there is a connection memory which is a mapping table that we have talked about so when you are setting up a connection  you will make entries into the connection memory we will just have a look at the connection memory  that is  what we have already seen and then it gets consecutive address generated here and then from the buffer memory once again it goes to the output side and then there is a parallel to serial converter for feeding into the individual lines so this is the data bus and this is the address bus  refer slide time  49  26 ? 49  47  connection memory contains a list or table for mapping input time slots to output time slots when a call is set up  you make an increase in this connection memory the pointer data values are set from the cpu on a per call basis the data output of this memory is used as an address to access the buffer ram ; decimal representation is shown  refer slide time 49  48 ? 50  02  this is another example so in address 0  we have pointer or content is 14 ; that means line number 0 may be connected into line number 14 in this example  refer slide time  50  03 ? 52  06  now just one more thing ? that assuming 1 byte is read from each line  each frame is to be processed in 125 micro seconds you remember how this 125 micro second comes about ? remember we talked about the voice channel  and each voice channel requires a capacity of 64 kbps as we mentioned so 64 kbps means that what is the gap between every bit in 1 second ? there are 64,000 of them so it would be 64 kbps if we handle 1 byte at a time  it will be 8 kbps and 1/8 kbps would be 125 micro seconds so this is the basic time for frame and in the entire time division hierarchy  as we will see in time division multiplexing  this 125 micro second is a very sacred figure ; this is what everybody sort of sticks to so that a voice call can smoothly fit into this of course if you want to have a higher speed channel then what you might do is in the same 125 micro seconds ? slot  you may pack in a large number of bits that is alright but we keep the frame size to 125 micro second if the memory cycle time is t micro second and there are n lines we have 2nt  because each of them has two operations  one read and one write so 2nt would be 125 so a 1000 line switch will require a cycle time of about 60 nanoseconds that is the kind of memory speed  and as we will see  as the number of lines goes up or as the speed of switches goes up  this memory speed becomes a constraint as with space to division switches  it is possible to device multistage switches  refer slide time  52  07 ? 53  15  now just one last point about capacity allocation ; i mentioned that the service providers actually want to provision less than the maximum possible but what would be the blocking probability if you provision it in a certain manner  let us say  in the c stage switch ? so i will just give you the formula if the average call arrival rate is  say  ? calls per second  which is an exponential distribution as people have seen for a voice network ? for data network it is different ; we will come to that in the next lecture ? the average holding time is m seconds per call  which is poisson distribution the call load in erlangs is a = ? m this is called the load and given a load a  we try to allocate a channel capacity n such that the call blocking probability b is at an acceptable level  typically around 1 % or less this is the typical figure that we try to achieve the difference is that within the busy hour  we get not more than 1 % call blocking probability and the formula for calculating this is this  refer slide time  53  16 ? 53  39  b is equal to a * * n / n ! *  ?  a * * i/i !   ? so you can use this formula or may be write a small program using this formula to calculate the call blocking probability giving values of a  n  i  etc  refer slide time  53  40 ? 54  19  so you can verify this this is one last this thing ? verify using erlang-b and stirlings approximation for handling the factorial  that for large n  say 100  even with 70 % average channel utilization  that is a/n  we get very small blocking probability but of course  if the channel utilization or a/n becomes 80 % and then 90 %  what will happen is that you will find that your channel probability is going up and then you can do the same thing for a small n and try to see what happens thank you  refer slide time  54  22  54  25  good day so in this lecture we will discuss about packet switches that means packet switches are switches which as specifically designed for handling packets we have seen the telecom switches like space division time division switches etc ok we have also discuss something about multistage switches which are used quit often in packet switches also but in this lecture we will specifically discuss about a packet switches  refer slide time  54  59  55  01  which is at the heart of all most all your computer networks ok so  refer slide time 55  11  55  26  first just to give you some motivation that why do we require switches the performance of a lan can be considerably enhanced by moving over to switched lans moving over from what if you remember that some of the earliest kinds of lans that we have just seen a brief glance of some of them used shared memory like a hub or a bus etc now in a if you are using a shared medium what is going to happen is that only two nodes connected to this lan can communicate with each other at a particular point of time where as if you have a switch multiple pairs of users or multiple pairs of nodes can communicate with each other at the same time so naturally you get a very good boost in performance of the over all lan so that is one reason why we require switches of course we require switches in other place also  refer slide time  56  18  56  23  multiple distinct source destination pairs are able to communicate at the same time thorough a switch so that is why we require a switch in  refer slide time ? 56  24 56  34  packet networks a packet switch needs to look at the header of each packet to find the destination address of the packet so you do not have to do a full scale sort of lookup of a very big table a refer slide time 56  43-57  52  so you have a you lookup only a very small table of v c i and v p i in the v c table replace but of course virtual connection just as their setup they may be taken down so replace old v c i v p i with new ones forward cell to outgoing interface transmit cell onto link so this is the this is how an a t m switch works so if you so you see that the basic concept of the cell remains the same that means we have we have some we have to find out the output port from the address and the here the address once it is setup after that the output the address is simply a small table of v c i v p i which makes this lookup process much faster so this together with the fact that the cells are of same size so you can develop your hardware in such a way so that this a t m switches will work very fast otherwise the rest of the switch and the switching principle remains the same as we have discussed already  refer slide time 57  53-58  08  next comes comes ethernet switch which is perhaps the common most common type of switch that you see almost every where as a matter of fact this number of ethernet switches which are being used and which hare being put to use the almost regularly is so high that the cost of this switches have also come down you know because if if you produce something in very large number you can amountize the cost of is development etc over a large number of switches so this cost of the switch comes down so ethernet switches have become very cheap these days ok switch which are used to cost may be a lack or so may be ten fifteen years back cause only a few thousand rupees today so this is the most common type of switch which we see every where computer networks prof sujoy ghosh department of computer science and engineering i.i.t  kharagpur lecture name # 8 packet switches  refer slide time  00  40  good day in this lecture  we will discuss about packet switches ; packet switches are switches  which are specifically designed for handling packets we have seen the telecom switches like space division  time division switches  etc we have also discussed something about multistage switches  which are used in packet switches in this lecture  we will specifically discuss about packet switches  which are at the heart of almost all your computer networks  refer slide time  01  22 ? 01  37  first  to give you some motivation  why do we require switches ? the performance of a lan can be considerably enhanced by moving over to switched lans if you remember  some of the earliest kinds of lans that we have just seen  a brief glance of some of them  used shared memory like hub or a bus if you are using a shared medium  what is going to happen is that only 2 nodes connected to this lan can communicate with each other at a particular point of time  whereas if you have a switch  multiple pairs of users or multiple pairs of nodes can communicate with each other at the same time naturally  you get a very good boost in performance of the overall lan ; that is one reason we require switches we require switches in other place also  refer slide time  02  28  02  48  multiple distinct source destination pairs are able to communicate at the same time through a switch that is why we require a switch in packet networks a packet switch needs to look at the header of each packet to find the destination address of the packet if you remember  when we discussed about connection-oriented and connectionless systems  telephone networks are predominantly connection-oriented  although connectionless technology is also getting there data networks are predominantly connectionless although some connection-oriented network technologies are also used in some parts of the network today when we are talking about packet switches  we are specifically talking about connectionless systems in a connectionless system  since there is no fixed connection between the source and destination which is held during a session etc  such concepts are not there so each packet is on its own and that packet is perishable and contains data from the source node  which is meant for the destination node it will contain lots of others things like headers  etc  which we talked about earlier but now we are specifically interested in the packets ? that means  the data stream has been broken up into packets so each packet must contain the destination address of where the packet will finally reach because since there is no space connection  each packet must carry  refer slide time  04  12 ? 04  38  the destination address and this destination address is sometimes also called the mac address ; mac is for media access control there are various types of mac address we will come to that later on depending on the address  the packet is forwarded to another port what happens in a packet switch is that through one port  some data has come in ; this data will contain a mac address  this mac address is the address of the node  the address of the destination where it is supposed to reach  the destination node this destination node ? the switch has to know that this destination is connected to this particular outgoing link there is a question of mapping from the mac address to a particular output line and if that output line has a tag as we had seen in the earlier lecture on some of the switches that they use tags if they have a tag  depending on this mac address  this tag could be sort of maybe looked up from table or something and added to the packet so that packet can make its way to the switch and reach the final  correct output line  and from then on to the destination station  refer slide time  05  42 ? 06  57  depending on the address  the packet is forwarded to another port since more than one packet may arrive at different ports destined for the same output port  they may have to be internally queued this was also discussed in the last lecture  that if we have more than one packet which is sort of destined for the same output port  obviously we can not take both of them together one of them has to wait in some memory or in some buffer or maybe it will be queued because there maybe other packets coming up for the same port so they will be all queued and this queue could be serviced by the output line 1/1  that means 1/1 will be popped out of the queue you may queue it right at the input  if you see that the output port is busy  you may queue it at output port or somewhere in-between not dropping packets and being fair to all input lines are desirable criteria for packet switch design that means we do not like to drop packets ; we want to buffer them as far as possible of course if a switch is of small capacity  which is swamped by a huge number of incoming streams  etc  maybe for the same output port or something the queue  the switch may be forced to drop some packets but usually we would not like to do that we would not like to drop any packet and at the same time we do not want to starve any particular input line in general  we like to serve all of them in a fair fashion these are the criteria we use for evaluating a design for a particular packet switch  refer slide time  07  37 ? 07  56  the first-generation packet switch went through several generations  we are in the 4th generation or something anyway  the 1st generation packet switch is here  it simply uses a cpu  stores packets received online cards in its main memory these packets are routed to output queues  the packets in the same queue are scheduled by software for access to the output line card let us look at this  the simple kind of a situation  refer slide time  07  56 ? 09  27  we have a cpu with some memory there are particular input and output queues ; these are the line cards what are the line cards ? this is a 6 port switch as you see ; there are 6 lines  and there are maybe so many ports these ports  some of the functionalities are collected together and they are implemented in a small dotter card kind of thing  which is called a line card a line card will handle just a few of the lines  and there will be several line cards on the same switch if you go back these packets are routed through the cpu  which does the lookup ? it looks at the mac address  the particular output port to which it must go cpu will have all that information the cpu looks up and then it directs that packet to the particular output port there maybe a queue and this queue is scheduled by software for access to the output line card this was the first-generation packet switch  which is fine ? excepting that because of this cpu and memory storage  looking up  tables  etc  it takes time these switches were  refer slide time  09  27 ? 10  56  comparatively slow next we came to the second-generation switches here some of the routing functions are involved do you remember what the routing function is ? the routing function in general means that we look at the destination address and decide which output line this packet must go to and this routing function  if you are doing centrally  naturally it will be slower you can distribute it somehow  like distributing some of the routing functions to the line cards themselves line cards which can switch locally if the destination is on the same line card ? there is another point you can do that ? and if a particular line cards sees that the output destination will go through the same line card through a particular line  then the line card need not send it to the cpu at all this can switch locally so that was one improvement over the first-generation switch secondly  there is contention for the shared bus ; that is of course a problem  a contention for the shared bus  and packet switch can not be routed and the same is handed over to a central processor this can not be the local line card  which does not have enough intelligence and knowledge to know how to route it in that case that is sent to the central processor  refer slide time  10  56 ? 11  32  in third-generation switches  the shared bus is replaced by a switch fabric  which is an interconnection of buses and switching elements the shared bus is replaced if you remember  we can use a bus for broadcast  etc  like we did in knockout switch that may become a problem because of the contention for this shared bus so we replace that by the switch fabric  which is the interconnection of buses and switching elements  refer slide time  11  32 -11  52  when a packet arrives in this third-generation switch  which we will discuss in detail  when a packet arrives at an input port it is tagged with the output port id by a control processor the switch elements automatically routes it to the correct output port  as we have seen  this routing takes place in a min the buffers in the switches can be associated  refer slide time  11  52 ? 12  21  with the input or the output or with individual switching elements the switch fabric may be cross bar  broadcast  banyan or other configuration we have seen some of these configurations ; remember the cross bar switches ? that means just a simple connection of switches ; then we have some broadcast like the knockout switch  maybe a banyan like a multistage switch or other kinds of configuration  refer slide time  12  23 ? 12  54  there are three types of switching fabrics  one is that we are using through the memory  other is one which you switch through a shared bus or you have a fabric of switching elements like cross bar ? it is the simplest kind of fabric of course you can have more complex fabric over here as we have seen  like multistage interconnect network these are the three different types of switching fabrics that we have  refer slide time  12  54 ? 13  48  switching via memory  this was the first-generation routers as we have discussed packets are copied by a system  a single cpu now  speed is limited by memory bandwidth at two bus crossings per datagram  what is happening is that from the input port  some packet is coming through the system ; the bus sent to the memory where the cpu is looking into it and then decides where it must go  then sends it back to the data bus in that output port  which catches it and throws it out this is the sort of part which gives a bottleneck to this entire scheme because this bus part tends to be slow  refer slide time  13  48 ? 14  04  in modern routers  as i mentioned input port processor performs lookup  copy into memory  etc an example is ? this is short of commercial system ? like cisco catalyst 8,500  which would take this kind of approach  refer slide time  14  04-14  40  switching via bus  datagram from input port memory to output port memory is via a shared bus bus contention  switching speed is limited by bus bandwidth you have very fast buses like 1 gbps for cisco 1900  which is low and cisco switch  which has now been discontinued it has sufficient speed for access and enterprise routers  not regional or backbone but this bus structure does not really do well for higher level switches and one example of bus structure is a knockout switch we have already discussed  just to recapitulate  we have n bus interface units  one for each outlet and each takes input from all the broadcast buses ; each delivers output to its own outlet this is  if you remember the diagram of the knockout switch  you have these buses on which the data is broadcast from the input side in the output side  particularly bus interface unit for which it is destined  it catches the particular packet ; others ignore that packet and so it is queued up over here ? like q1  q2  q3  q4  etc  and it is pumped out as per this queue  on a first come first serve basis ; this basis could be something else also if you want to have some other pair  also in particular packets  etc  it ? s possible but in the simplest case  this is a first come first serve kind of queue  refer slide time  15  47-16  16  switching via an interconnection network are just as in the other kind of switches we have seen it overcame bus bandwidth limitations  that is the basic implication as we want to go faster and faster  we have to migrate from buses to an interconnection network we have already seen banyan networks other interconnection was initially developed to connect processors and multiprocessors  etc it became useful in this class of packet switches  refer slide time  16  17 ? 16  29  advanced design may involve fragmenting datagram into fixed length cells  switch cells through the fabric ? this was the idea for example  this is done in  let us say atm switches in atm switches what they do is that whatever the packets may come in the form of packets  it may come in the form of streams originally ; it is finally broken into fixed length cells the good thing about a fixed length cell is that you can  if you know length in advance  then you can design hardware so that it can be handled in faster a possible way although the atm cell has 53 bytes inside the switch  it is something like 64 bytes  these 64-byte cells are fixed length cells and they are pumped as fast as possible it is for designing very fast interconnection network  in which we fragment them into fixed length cells cisco 12,000 switches gbps through the interconnection network  when you go to this gigabit kind of switches  you require an interconnection network or maybe something more as we will see  refer slide time  17  38  17  47  as was discussed earlier  we have three kinds of approaches to handling  contention and buffering  etc one is on the input side  another is on the output side ; the other one is somewhere in-between we will discuss these one by one ; first let us come to the input side but before we go forward  i will digress a little bit  i will just explain a little bit about what is involved in the input side  the input part of the switch if you remember in our discussion about the several osi models  in the bottom-most layer  we had the physical layer above that was the data link layer  above that we had the network work layer  above that we had transport and other layers  which do not occupy us at the moment we will look at these later but we are having the physical layer  the data link layer and then network layer or the routing layer  these three are sort of very closely linked to switches operation first is the physical layer  that means  physically the link is coming in some fashion that means there will be certain kind of connecters  certain number of lines are coming per input line when we are saying one input line  but the one input line may consist of a number of wires when you are connecting for example  if you are connecting through a cat -5 cable  there are a number of wires which will connect to that particular port ; that is  a single port similarly  in other cases  you have a physical layer  you have an optical connection coming in  and you must have an optical detector over there  etc this also means physical characteristics of the media have to be handled by the input port if you look at this picture again  we have just the input part shown over here  this side is the switch fabric  that means  getting inside the switch so here it is sort of the line card itself first there is a line termination  which takes it specification  etc  from the particular physical layer that is being used we have something like a data link layer functionality an example of a data link layer kind of protocol is the ethernet we will  of course  look at details of ethernet later on what does the data link layer contain ? the data link layer contains the address called the mac address  which we have talked about in the last lecture ? the mac address  the media access control address ? of the next machine to which it is destined please remember that these addresses are addresses of the machine  because the source node knows the destination  let us say it may not know it also directly anyway let us forget about the large network  let us now focus on a particular switch and some nodes connected to this switch this node a knows that i want to communicate with the node b of course node a  b  etc  do not have any meaning at this level so at this level  some particular address is given called the hardware address  which actually is the address of the networking card if it is a computer that you have as a node  then the networking card of the computer  the network interface card  the nic card  it will have some address built into it in the hardware similarly  the destination will also have another hardware address this hardware address is put in this data link layer part and that means the data link layer puts this hardware destination hardware address into the packet  refer slide time  21  53  22  22  this address has to be read and then somehow you have to make a mapping from this address this particular address is connected to this particular line for that you need some lookup  forwarding  and queuing ? if you are doing input queuing  you will do the input queuing also what kind of lookup ? this lookup will tell you that for this particular mac address that is the output line card nowadays  what the switches do is that they keep on sort of getting this information in a dynamic fashion when a switch is connected to a number of computers  the switch will listen to the network traffic and find out all the hardware addresses  which are connected to these different lines it will sort of slowly gather this information and store it inside ; it will know that whenever some particular node is sending  it will give it the source address  also called the source mac address it will now get the source or mac address and this particular mac address must be connected to this line this switch keeps on gathering kind of information  and storing inside ; and part of it maybe stored locally in the line card some part of it maybe stored centrally and there are thousands ? nowadays  a switch can remember thousands of such mac addresses  which are directly connected to the switch there is another level of problem  which is finding about the addresses of remote machines  machines that are not connected to this switch at all machines  which are connected through others switches  routes  etc  in a different country  maybe so that is a different problem ; that is a routing problem  but in the data link problem we are concerned with all the mac addresses of all the nodes which are connected to this particular network which is local so that is stored in this switch ; you will now look up the table  refer slide time  24  07 ? 24  21  and decide that that is the final destination output line  which is the forwarding line and then you do the queuing then you send it to the switching fabric for its final destination  refer slide time  24  22  26  04  we will now talk about decentralized switching  given datagram destination  there is lookup of output port using routing table in input port memory  the goal is complete input port processing at ? line speed ; ? so this is what i want to do we do not want to hold up this particular packet ; you get the maximum throughput at the maximum speed we do not want to hold up any packet in any buffer ? ideally that is what we would like to do so we want to look it up locally at the input port itself  if that is possible but please remember that even if you can do all this lookup business at the line speed at which the packet comes  even then you maybe forced to store the packet for some time because either the output port where this particular packet is headed is already occupied because it is sending some other packet through it at the moment to some intermediate switching element  there maybe a contention for intermediate switching elements  etc for all this contention  etc  we maybe forced to put this packet on hold even if we do the lookup at line speed so we have to queue this in the datagram and the other possibility is that if the datagram arrives faster  then forwarding it into switching fabric and forwarding maybe constrained by all this contention  etc then you have to put it in a queue so what you can do is that you can put it in the input  refer slide time  26  05 27  00  side ; you can buffer it at input called input buffering packets are buffered at the input they are released when they gain access to both the fabric and the output trunk that means both the internal switching elements as well as the output port must be free and then this packet maybe released from the buffer  which is held at the input all elements except the arbiter  which is combinational  needs to run only as fast as the lines so this is a good point about input buffering that elements do not need to be faster than the rate at which the lines operate in some other cases  we will see that at faster speed  this is a big problem  this input buffering  which is known as the head of line blocking let us look at head of line blocking  refer slide time  27  03 ? 28  33  look at this head of the line blocking ? you see what is happening is  here you see there are three input ports  and this is the switch fabric there are three input ports ; the destination is shown by the color  that means the following  red means it is destined for this particular port ; blue one is destined for this particular port ; green one is destined for this particular port see what is happening  the first packet  red  comes here and goes to the output port ; this one is also red  which means it is destined for the same output port although there is no contention in the switch fabric ; it has to wait that is accepted the trouble is  this green one  which was sort of destined for something in the middle  and which could have gone through this fabric at the same time as this red packet  is flowing at the top this has to wait because the queue is blocked by this particular red packet this is called head of line blocking at the head of the queue  there is somebody who is blocked and all the people who are behind  all the packets which are behind  have to wait  this is called head of line output port contention time t  when only one red packet can be transferred so the green packet experiences head of line blocking this is the head of line blocking  which is a problem with input buffering other reason you might require input port queuing is that the fabric is slower than input ports combined input ports combined means it is a special case when all the lines are trying to pump data at the same time what you require is a sum total of all the speed that you get over there  which is not always possible  because then surely there will be contention inside for the switching element so you will be forced to queue some of it at the input head of line blocking we have already discussed that queue datagram in front of a queue prevents others in queue from moving forward so there is queuing delay and loss due to input buffer overflow this is the other thing  which might happen ; what might happen is that this queue is given for each input port at each input port since this buffer is not shared  this one is only for that particular input port naturally the size of the queue is limited ; if it so happens that data is coming in at a fast rate and the fabric is very congested  it is not getting a chance to go through  this queue at the input port may overflow if they overflow  which means that some packets have been lost  it is a very undesirable situation ; but this may happen this is the head of line blocking so the other option is to buffer  refer slide time  30  33 -30  58  them at the output ; that means  you have a queuing buffer management  this part  then the output part is being fed from the switching fabric ; queuing buffer management ; data link processing  that means  protocol decapsulation for the next jump  etc  and finally the line termination once again you have to go to the physical layer over here this is the output port queuing  refer slide time  31  00 ? 31  13  what are the implications of output port ? queuing buffering required when datagrams arrive from fabric faster then the transmission rate  the fabric is pushing a datagram into a particular output line at a faster rate than the output line can pump it out naturally packets are getting accumulated near the output port  so packets are getting queued over there so you develop a queue  refer slide time  3  30 -32  11  there is a scheduling discipline  which we might choose among the queued datagrams for transmission ? which is the one that gets the higher priority  if you are putting some higher priority etc  and even if you are trying to give the same priority to everyone  it might so have happened that we might have kept one particular packet quite long in other places ; we may have sort of fed it back ; i did something with it as it was already late we might like to give higher priority than other packet  etc so there maybe a scheduling which is going on in this queued buffers are maintained for each output line  refer slide time  32  11 ? 32  25  this is a great advantage  because it does not suffer from head of line blocking naturally  because it is been buffering as soon as possible  but there  refer slide time  32  26 ? 3  42  are problems later stages of switch fabric and buffers have to be n times faster in the worst case to avoid dropping of packets within this space this rule makes the switches more expensive another thing is that suppose  in the worst case  all the n inputs  say n  1 input lines  are trying to feed data into the same output port what is going to happen is that these packets  which are coming at the line speed through n  1 lines  they sort of start converging to the nth port how can they converge ? obviously  if everything is operating at the same speed  then there is going to be contention in these switching elements or one way to avoid this contention is to make switching elements faster that means suppose two of them have to go to the same switching element but suppose that the switching element operates at double the speed ? ? i am just giving a simple example ? at double the speed but at the same rate at which it is coming  it can push it forward so as you go more towards output port  the speed requirement becomes higher and higher finally  near the output  at the very point of the output port  it has to be n times faster approximately  which is not done like n times faster that is not possible but the point is this is a difficulty which we have with output buffering ; although we do not have head of line blocking  they tend to be more expensive if you have a buffer fabric i mean there is always a sort of trade-off between how expensive a particular switch is and what its performance is naturally if you want to go for higher and higher performance where it is very important  then you need to sort of get switches that are more expensive  refer slide time  34  47 ? 35  31  we have the buffer at the input and buffer at the output the buffer maybe distributed in-between all over the fabric  the buffer is associated with each switching element  which is used when the next stage is not available it needs a lot of memory and quality of connection is difficult to control the point is that if  throughout switching fabric  if you have distributed our buffer  it is very difficult to have any kind of policy about priorities  etc the switches will handle it any way they can  so we can not have a policy which holds over all the buffer because we do not have processing capability over there ; it is just a buffer and a switch  refer slide time  35  32 ? 35  44  this is an example of a switching fabric element you look at this switch in the center we have the switch and then with two input lines coming in  you have a buffer over here if the next switching element is busy  then that particular thing can be put into the buffer  from the buffer it will come back to the switch and then get switched when the next element is available  refer slide time  36  10-37  04  buffers need to be only as fast as an element ? s fan-in ratio  and during overload  the resulting queue is distributed there is one good thing about distributing the buffer ? which is that instead of putting all the buffer either on input side or the output side as the output side gets more and more congested in one particular area  what will happen is that the previous switching element will also get congested they will buffer something and then the buffer will be pushed back what is happening is that there is a distribution of this buffer all over the fabric these later stages need not be all the way up to n times faster than the initial stages  which is not always possible so that is one good thing about buffer fabric  refer slide time  37  04 ? 37  35  we will look at some examples of packet switches  we will talk about three switches that is  ethernet switches  atm switches and ip routers ? these are all packet switches all of them hold very important positions in the world of networking ; we will just look at these one by one  refer slide time  37  35  37  51  let us take up an atm switch first if you remember  in the atm system  we have fixed sized cells ? in the atm world  there called cells  then in the ethernet world  etc  they are called cells packets  datagrams  etc anyway they are called cells ; these are of fixed size  like 53 bytes etc each cell will contain a so-called destination address and the destination address is in two parts  one is called virtual path identifier and the other is virtual connection identifier ? vci and vpi in the virtual connection table what happens is that atm is a set of virtual connections ; what is a virtual connection ? a virtual connection is somewhere in-between a physical connection on one side and completely connectionless  let ? s say ethernet packets  on other side in a completely connectionless ethernet packet  that packet contains the full destination and at each node in-between  this destination is interpreted  looked up into some table  etc  some algorithm is done  and then you decide what is the next step to go to in a connection-orientated system  physical connection through the switches is set up from the source to the destination in a virtual connection  virtual connection is also set up so there is initial set-up time just as there is for connection-oriented  purely physical connection-oriented systems similarly for virtual connection also  we need a set-up phase and then you can start communicating in the set-up phase  all the nodes in-between know that we are going to have a session  where the destination is going to be ; what would be its next address  and so on ? it is computed  let ? s say  as we do in ethernet  etc but once it is computed  it is coded in a very small vci/vpi the port one has to go to for this particular session is identified by the vci and vpi so this computation is done  recomputed at each of the intermediate nodes  and then the virtual connection is set up ; that is all there is no physical connection so as soon as there is some cell  which is for this virtual connection  an intermediate node will immediately know that this is the next step and that is where it will push it so you do not have to do a full-scale look-up  you have  refer slide time  40  29-41  40  a very big table so we look up a very small table of vci and vpi in the vc table but  of course  just as the virtual connections are set up  they maybe taken down so we replace the old vci/vpi with new ones ; forward cell to outgoing interface transmit cell onto link this is how an atm switch works you will see that the basic concept of the cell remains the same ; that means  we have to find out the output port from the address once the output  the addresses are set up  it is simply a small table of vci/vpi  which make this look-up process much faster with this  together with the fact that the cells are of same size  you can develop your hardware in such a way  so the atm switch will work very fast otherwise  the rest of the switch and switching principle remains the same as we have discussed already  refer slide time  41  40 41  55  next comes an ethernet switch  which is perhaps the most common type of switch that you see almost everywhere as a matter of fact  the number of ethernet switches which are being used almost regularly  is so high that the cost of switches has also come down it is because if you produce something in large numbers  you can amount the cost of its development  etc  over a large number of switches  so the cost of switches comes down ethernet switches have become very cheap these days  switches which used to cost maybe 1 lakh or so 10  15 years back  cost only few thousands of rupees today   this is the most common type of switches  which we see everywhere if it is an ethernet packet  then it has to handle the ethernet addresses which are in the packet the ethernet address is actually a 6-byte address  so we will have a 48-bit address usually we do not get to see it as users  because this is 6 byte ; it is very difficult to remember such a long address  and these addresses come in a very random fashion it is very difficult to remember ethernet addresses  but human beings need not remember ethernet addresses ethernet addresses are learnt by the system ; when a system is put in a network where the system maybe a computer or a node or the system maybe a switch or a router  they learn about the ethernet addresses  local ethernet addresses  which are there we will get into the details of ethernet  etc  later on but anyway this lookup is necessary the first step in ethernet switch is look up frame destination address in forwarding table ; if known  forward to correct port ; if unknown broadcast to all ports so this is what an ethernet switch does suppose a packet comes with a particular destination address  and if the destination address is known  the node having this particular address is connected to this particular port then the output port  for this packet ? s output port  is forwarded to the correct port if unknown  you broadcast it to all ports why is this ? if you remember as i mentioned earlier  these switches automatically learn from whatever is going on ; they automatically learn the mac addresses of the local machines but suppose it is put in a network  in the beginning it does not know anything what does it do ? what it does is that  as soon as it comes from some port  it broadcasts it to all the other ports it will listen and find out which is the one that really was successful and there are various protocols for finding these things out ; it will slowly learn it may so happen that this switch may get a packet for which the destination address is not known to the switch in that case  it broadcasts to all the ports then we have  learn source address of incoming frame ? one thing of course is learned from this frame  although the destination address is unknown  it knows the source address ; the source address is the particular incoming link it came in through this particular address must be the node having a particular address  must be connected to this port so that later on if this particular node comes as a destination  it knows where to send it to forward frame to outgoing interface ? that is the other thing  transmit frame onto a link these are the various functions of an ethernet switch  refer slide time  46  07-46  17  we have something called an ip router ; router as you know works at the network layer ; it is not in the data link layer that means a router has a different set of address called ip address ; so ip address is a global kind of addressing scheme there is some scheme for this ip address although not as good as the telephone numbering scheme  but anyway  there is some central control the job of the ip router is to find out this global address that i have got maybe this particular node is in some other country ; it has to understand that for going to that  reaching that final destination  i have to take this link locally then it will send it to the next level  that is  the data link level  for hopping that particular local layer once again  we have the same problem that we have got an address  some kind of destination address  which happens to be an ip address we have to do that  look up  we have to decide this is the port it must go to and then send it to the port so the same switch is used with some added processing capability for doing the process router ? usually it comes with all kind of other functionalities and also it needs some processor of its own and it needs some memory naturally for running programs  etc there is some kind of an operating system which is there in a router  so a router is more complex but the hardware part  the major part of an hardware  is still the switch and the input and output line ports usually a router can handle different types of ports ; for example  usually an ethernet switch will handle only ethernet port so the physical characteristics or the physical layer properties of the ports are constant for all the ports  but a router can cut different types of cards  which can handle different types of ports  maybe serial port  high-speed serial port  and all kinds of things  refer slide time  48  27 ? 49  13  but the basic thing remains the same look-up  the packet destination address in forwarding table ? if known  forward to correct port ; if unknown  well  the router can not broadcast it because if all routers start broadcasting then there will be broadcast all over the world through all the routers  which is not really acceptable at all you can broadcast something only locally by an ethernet switch ; so if the destination is unknown  and it has no way of finding where to send it  it simply drops the packet when it sends  it decrements the time to leave  update header  checksum ? so these are some of the side-effects which it has to go through ? let me not go into the details of this ? and finally forward the packet to outgoing interface  transmit packet on the link as usual  refer slide time  49  14 ? 49  26  this is a router ? once again we have a switching fabric  we have input port and we have output port  and we have a routing processor  refer slide time  49  27-50  55  let me quickly look at some of the issues in developing fast packet switches first thing you must know  understand  is that the demand for communication speed is growing much faster than that for computational speed you know that in computers there is this moore ? s law  which tells that every one-and-half years maybe  the speed doubles ; the memory capacity maybe doubled ; etc but if you look at the way growth has taken place in the communication field  especially with this speed of communication which is required  this is much faster than the similar developments in the computational area there are two reasons for this  one is  of course  people are trying to communicate more people previously were just satisfied with voice ; now they want to send data  they want to upload or download large files  they want to send movies  etc the individual demand for bandwidth is growing  that is one thing ; and the other thing is that more and more people are getting connected to the network as more and more people get connected to the network  the number of possible connections goes up as n2 ; if there are n people  as n goes up  it goes up in the squares so all this is going through the central backbone  etc at the backbone level  the speed requirement is very high  so we require very fast packet switches and we will look at  refer slide time  50  57 ? 51  08  just some issues over here the main bottleneck in an ultra fast switch is the speed of memory used in buffers this is the main bottleneck  refer slide time  51  09 ? 52  17  for example  if you have a 5-nanosecond sram  that is  static ram ? it is the faster kind of ram rather than dram and you have 64-byte wide bus ? you have 5 ns per memory operation  that is your memory speed  two memory operations per packet you have to write it there and you have to read it  so that makes it 10 ns and you have 64 bytes  which means 64 ? 8  that is  512 bits ? so you are handling 512 bits in 10 ns  which comes to 51.2 gb/s this looks like a very high figure but now  we get switches which have speeds of maybe 100 or even 200 gb/s they are very high speed  so the buffer memory is the maximum this is not as simple as that ; ultimately it comes to about 40 gb/s or so we use the fastest possible ram but even that is not enough so we can take some possibility   refer slide time  52  18-52  33  one is the ping pong buffering  which means the packet comes over here there are two buffer memories  one is that either you send it or you put it in a buffer like this  refer slide time  52  34 ? 52  59  for example  when it comes  maybe one of them is being sent while the other is being buffered then this one will be sent and the next one that comes  will be buffered so you are trying to double the speed at which it is operating you require two buffer memories for it that is one approach  refer slide time  53  00 ? 53  01   refer slide time  53  02 ? 53  27  the other approach is to use multiple parallel buffers ; instead of two  you have many of them and you put them in buffer in parallel  so you can go about it maybe in a round robin fashion  put in an multiple buffer and the other bottleneck is that  especially in a router  if that your processor  if that is centralized  then that becomes the bottleneck for speed  refer slide time  53  27-53  35  we have the fork  the so-called fork join router  where maybe you have put a number of routers in parallel these lines are coming at a particular rate ; they are distributed over all the routers so the routers individually do the look up  etc  at whatever speed they operate on then they keep on pumping this side as well as this side ? these are combinational so they can operate very fast ? the look up  etc  is paralyzed these do not have any buffers in them  this part has the buffer so this way  by going in for parallel operation  we try to make as fast switches and routers as possible this speed is going on increasing as they have to increase in order to cater to the growing demand of packet switches  speed of packet switches  and capacity of packet switches  all over the world thank you preview of next lecture lecture no # 09 sonet/sdh this lecture  we will discuss about sonet the word sonet stands for synchronous optical net work sonnet in the usa  canada and japan,synchronous digital hierarchy elsewhere for example in india  we will be calling sdh  this is a time division multiplexing system that transmits a constant stream of information  refer the slide time  55  14 ? 56  57  please look at this figure so we have some multiplexers as the figure shows  we have a multiplexer in this side another which is an output fits to another multiplexer  this multiplexer is going in this direction and then after some time  the signal becomes weak we want a repeater  that means what is a repeater ? a repeater is something which boosts the signal strength  so there is a repeater then it travels some more distance and then there is a repeater again and then it travels some more distance and the other side we have the corresponding demultiplexer and then it fits into the other demultiplexer from repeater to repeater  we call it as section so all from repeater to multiplexer this is also a section multiplexer to repeater  repeater to repeater  these are called sections and then from multiplexer to multiplexer we call it a line at the repeater nothing happens except the signal is cleaned up  signal maybe boosted or there maybe other cleaning operation synchronizing operation etc that maybe done at the repeater but as such the signals which are traveling here are the same set of signals are traveling here at a multiplexer some of the signals may go off in another direction  some signals may go in some other direction etc at the multiplexer there maybe convergence or divergence depending on which way the signals is flowing so that may happen at a multiplexer so from multiplexer to multiplexer  we call it a line and then from the end user part point to end user point  we called it a path  refer slide time  56  57 ? 57  09  the spe does not necessarily start in column 4 which mean that the spe that does not necessarily stay within 1 frame  these are 2 very important points in on it  the point is that all through you have 87 columns but actually the data may start getting transmitted as some arbitrary point inside that 87 columns what is the idea ? why do want to leave something and they only start from the middle ? the point is that if there are some kind of mismatches because of miss matches of rate etc  if everything in the world were absolutely synchronous  all activities an all equipments etc then would have started from the beginning but that is not the case this is where we absorbed this kind of variation and this gives a great flexibility to solve it which was not there earlier other interesting thing is that spe does not necessarily stay within 1 frame which means  that the spe start in 1 frame and then 1 in another  we will just look at a diagram of this let us have a diagram of this  you see the spe  this light green color that really starts from somewhere after leavening some of the root  starts hear in the path overheat is somewhere hear and there are 2 frame is here so the spe is really spent in both the frames computer networks prof sujoy ghosh dept of computer science& engineering iit kharagpur lecture 11 routing and wavelength assignment in wdm all optical networks  refer slide time  00  48 min  good day in this lecture we are going to continue our discussion on wavelength deviation multiplexing specifically we are going to talk about routing and wavelength assignment ?  refer slide time  01  02 -01  04  routing and wavelength assignment to what ? well  routing and wavelength assignment means that we have some stream of packets or whatever data or whatever communication is going from one source to one destination now these sources and destination  first of all  if there is point-to-point connection they directly send it through the fiber that is simple ; but in general  they will not be directly connected they will go through a network ; they go through some intermediate notes to reach the destination so for this stream we have to route this ; that is one problem and the other thing is that may be the stream rides on some particular wavelength for the time being let us assume that it is continued on the same wavelength ; we have to assign one wavelength  so we have this problem of routing and wavelength assignment  refer slide time  02  09-02  19 min  in wdm and all optical networks of course we can do routing etc very easily in the electronic domain ? that is known ? but we have not yet discussed routing in the electronic domain  how it is done etc we will discuss it later on in this series of lectures but in routing  we are talking about simple kinds of routing problem here so we will talk about routing and wavelength assignment  refer slide time  02  39 03  11 min  the optical wdm networks are future backbone for wide area networks the reason we want it is because the bandwidth demand from the users is going up at a very fast rate ; of course  we have to go for fiber  we have to go for higher speed and then we have to pack in a lot of these channels over the same fiber so we require an optical wdm network  refer slide time  03  18 ? 03  57 min  the speed of electronics compared to optics is a major constraint at the backbone so it is always preferable to handle the traffic at the optical layer  where we can achieve much higher speed and the whole thing is transferred the physical topology that we will consider at the optical wavelength routers is connected by some fiber links so these are the same kind of topology we had talked about ; that means there are some nodes  which are connected by some communication links in this particular case  the communication links happen to be optical fibers  refer slide time  03  58 05  10 min  most of the node pairs in the backbones are not physically connected so we have 30 or 40  let ? s say 40 nodes now for 40 nodes  there are 780 possible pairs  that is  40 c2  that is  40 ? 39/2  that is  780 pairs  which is a very large number of course  only few nodes are connected actually through physical fibers so they can reach each other only through other intermediate nodes a light path or connection  this is the concept that we will be talking about most in this part of the lecture this is the path between two end nodes and a wavelength on that path  so we want to route  that means  we want to find this path between two end nodes and we want to select the wavelength on which to send all our communication from the source node to the destination node  refer slide time  05  11-05  21 min  the intermediate nodes can cross connect that particular wavelength from the incoming fiber to the outgoing fiber do you remember our discussion on digital cross connect ? may be through mems  that means  a particular wavelength is coming through one particular fiber  we direct it through some mirror to another fiber on that same wavelength it is as simple as that thus with programmable optical switches  the traffic can be routed entirely in the optical plane  refer slide time  05  51-06  14 min  so no wavelength conversion for the present  and any light path uses the same wavelength on all the links its path spans so 16 or 32 wavelengths in each fiber are common these days and hundreds of ? s are being talked about a single fiber could theoretically accommodate as many light paths  refer slide time  06  13-06  39 min  what are the basic concepts of the light path ? end users use light paths to communicate  each light path passing along the same fiber occupies different wavelengths ; that means on the same fiber there may be different light paths going through the same fiber  each of them would be writing on a different wavelength or different lambda two ? s two light paths with the same wavelength can not share a fiber  that means two different light paths who are on the same wavelength they can not have any fiber in common because then their signals will get mixed up with each other of course  we can have  refer slide time  06  52-07  36 min  wdm with wavelength conversion also as i mentioned in the previous lecture that wave length conversions are possible although they are quiet costly so it is possible in different extents  for example none that means no wavelength conversion or we can have a partial wavelength conversion that means some of the nodes have wc capabilities while others do not have or it may be full if you have wavelength conversion we get some kind of flexibility in routing and wavelength assignment we will not concentrate on that but you can understand that if we could convert the wavelength midway that means  as the signal is going  we can convert the signal midway  then maybe we can have better possibility of accommodating many more light paths for our purpose  we will be concentrating only without wavelength conversion  refer slide time  08  00-08  21 min  so how to establish light paths ? two parameters to be decided  path from source to destination ? this is the routing part ? and wavelength along the path  which is the wavelength assignment part traffic types subjected to optical networks may be static or dynamic ; that means you know the specific source destination pairs  which have to be connected in advance and that is quiet stable so now you may run some centralized algorithm kind of things and find the best way to assign the light paths the other situation could be dynamic ; dynamically there is a request from some node for a connection to some other node and you want to set up the light path on the fly and take it down that is a slightly more complex situation  refer slide time  08  59 09  52 min  so two versions of rwa are realized depending on the characteristics of the traffic applied  static light path establishment or dynamic light path establishment now routing and wavelength assignment several  signals can share a single fiber all signals must have different wavelengths  so these are the constraints of course  technology sets the upper limit to the number of wavelengths you can not have unlimited number of wavelengths  you can have a large number these days but even then this is not unlimited so these are the constraints  which you will have to respect while doing the routing and wavelength assignment the problem is how to choose a route and a wavelength to each connection  so that signals won ? t block each other how can signals block each other ? well  the signals can block each other in this way for example  suppose you have routed two particular source destination pairs in a certain manner using a certain wavelength  let us say ? 1 another pair of source destinations was  let us say  n1n2 ; then we want to put a connection between n3 n4  for which the route happens to share some of the links in these links now you can not use ? 1 for this  because ? 1 on those links is already occupied by the link from n1 n2 so if n3 n4 share even one link  you can not use the same ? 1 ; you will have to use ? 2  but then ? 2 has to be blocked because of some other links and so on  refer slide time  10  52-11  23 min  so the objective of sle  that is  static light path establishment  is to minimize the total number of used wavelengths connecting the maximum number of nodes they are the same ; if you can connect some particular set of nodes using the minimum number of wavelengths  using the number of wavelengths  which are given to you  you may connect the maximum number of nodes other objective functions we may also consider are the load in the most loaded link  the total number of optical switches  etc  refer slide time  11  24-13  48 min  so this is an example of light path establishment suppose you have these a b c d e connected so in the first part the left half of the figure what we have is the physical connection from a to b there is a connection and b to d and so on in this  i show some rw routing and wavelength assignment has already been done and some of the wavelengths and some of the links have been used so here only two wavelengths are used let us say a to b are not connected ; say a light path has been established via b for a to c at b  there will be a switch  which will switch this dashed line  which is ? 1 so ? 1 coming through this fiber from a to b is switched to ? 1  using the same wavelength to the outgoing fiber from b to c so we have light path established between b to c similarly  from c to d there is a light path ; there is a light path from b to d ; there is a light path from d to e ; there is a light path from e to f ; there is a light path from d to f and so on  using the same ? 1 then i want to connect e to c now i can not go from e to c after say ? 1 has been assigned  i can not go from e by ? 1 to anywhere because all the outgoing fibers of the ? 1s have been used up this side for a  this side for b  and this side for f so  in order to connect from e to c  i use another wavelength  say ? 2  which connects me via d and the d cross connect will connect this particular ? from this fiber to this fiber so we will get a direct light path from e to c similarly  we will get a light path from b to f using ? 2  a to d using ? 2 and this way they are all connected as you can see  a large number of light paths have been established using just two ? s  refer slide time  13  49-14  35 min  dynamic light path establishment  on the other hand  is appropriate for network having dynamic traffic  where the traffic pattern changes very dynamically and a communication request may arrive at any time the goal is to maximize the number of the incoming communication requests accepted well  if it so happens that you have already made some kind of reservation and some kind of allocation to an earlier request and when a new request comes  you find that there are no paths on which a ? is consistently free throughout so in that case  you have to block that request or regret that request so we want to minimize such regrets and maximize the number of incoming communication requests that can be accepted that is the goal of dle  refer slide time  14  36-14  57 min  in order to solve this problem  let us see what the complexity of the problem is the rwa problem is difficult ; it can be divided into two sub-problems ? routing and wavelength assignment both of these sub-problems are np complete and tightly linked together if you remember  by np complete we mean that class of problems for which no polynomial time algorithm is known and so  if you can solve any one of them in polynomial time  all others can be solved in polynomial time it is not known whether any polynomial time algorithm exists  but since the number of such problems is so large and people have thought about these problems in so many different guises  it is very unlikely that you would suddenly come up with a polynomial time solution to any of these and of course  when an algorithm has an exponential complexity  it takes a lot of time so that is a difficult problem in that sense ; both its parts are np complete so there is no exact solution so we can not expect to get the so-called ideal solution or the optimal solution in all cases  but we can try good heuristics  refer slide time  16  00 16  31 min  now what we want from a good algorithm ? maximize the number of connections ; use the shortest routes ; and minimize the number of wavelengths if you can maximize the number of connections  this is of course our basic requirement if you use the shortest routes or the number of hops should be minimum  delays and all kinds of things should be minimum so that is another good thing to have  and if you minimize the number of wavelengths that have been used  future requests can also be possibly accommodated  refer slide time  16  32 17  06 min  so for routing  there are different techniques like fixed routing ; that means the path that is predefined is used ; that means the for all pairs we have some fixed paths and fixed alternate routing  meaning multiple predefined paths are there and one of them is selected so the criteria could be shortest path  least loaded path  least congested path  and so on  refer slide time  17  07-17  27 min  there could be adaptive routing techniques ; the path is found on the fly that means as the network is in operation dynamically  you find the least congested path or the most suitable path depending on the current situation in the network  and once again we may try to find the shortest path or least loaded path  refer slide time  17  28-18  03 min  now how do the wavelengths affect routing ? there can not be two signals with same wavelength per fiber for two different light paths ; that is not possible so the shortest route may be blocked by other signal and in the worst case all the routes are blocked then  of course  either you have to reassign the wavelengths of other earlier assignments or you have to block this request if the wavelength conversion is possible  the signal can use other free wavelengths but the conversion is not always supported  refer slide time  18  04-18  15 min  wavelength assignment problem arises under the wavelength continuity constraint ; that means the wavelength has to be continuously available in all the links down the line and there are various algorithms for that one of the most commonly used one is the first fit  which means  you have decided on the path by some means ; that is the routing path once you have decided on the path you have a list of these wavelengths  ? 1 to ? n  and you try them in order the first wavelength  which is free on all the links in the route is the one which is assigned to this particular light path request that is called first fit  and it has some good points in the sense that since you are always trying from the same end  you tend to use up these earlier ? s more and more  giving you very good utilization of the ? s so you may be having a lot of other ? s in the network you have them on reserve to accommodate the request so that is a first fit algorithm but then again you must remember this is just a heuristic  in the sense that there is no way you can prove ? as matter of fact you can disprove it in some cases  this would not give you an optimal algorithm in some cases it may give you an optimal algorithm in many of the cases  it has been found that this gives good results  but in some cases  it may give very bad results it may be random you may want to distribute the load all over  so it may be random or people have used the least used ; that means the least used ?  which is most free  is the one that is picked up when you try all the ? s one by one  you reach the ? that can fit this particular route so this will have the opposite effect  in the sense that this will try to distribute the load evenly across all the ? s or the most used ones ; it need not be the first fit or the least loaded  etc so these are the different algorithms or different heuristics  which you might use for assigning your ?  of course  what you could do also is that at some point you could go back and instead of asking about your routing path you can ask  give me the next alternative path so from the shortest path  which it might have given in the first instance  it might give you the second shortest path on which you may try the same kind of wavelength assignments using that so all kind of combinations of routing and the wavelengths  all these strategies are possible  refer the slide time  21  18-21  34 min  what are all the good points about wavelength routing ? setting up a light path is like setting up a circuit you remember we have talked about circuit switch network and packet switch networks ? so in circuit switch networks  specifically the telephone circuits  even today may be majority of their networks are circuit switches ; that means  a call from one node to another  one caller to one callee  a continuous circuit is set up all those things have become more complicated as we have seen because of the tdm and all kinds of packets and all these things are coming in between anyway  the essential circuit switching is that the circuit is switched just in the same manner  when we are assigning a particular light path to two nodes  which have to be connected  it is just like setting up a circuit and once the light path is set up  the route is fixed and the wavelength is assigned and the light path is set up then these two nodes can communicate  pumping as many packets as they like through this  of course limited by the technology constraints but this is quiet a high constraint so the inherent advantages of setting up this circuit switching is that in this particular approach to the problem specifically the quality of service is good what we mean by the quality of service is smooth traffic and qos guarantee can be given due to fixed bandwidth reservation and sle is easy to manage  that means static light path establishment is easy to manage that is the advantage of wavelength routing  refer slide time  23  22-23  39 min  the disadvantages are the following  long circuit set-up time this circuit time will be in the order of tens of milliseconds actually the circuits are set up in such a way that the source sends some request and the request goes down all the nodes on the way the local switches have to be set up in that particular fashion and then they will acknowledge and say that ok the light path has been set up so all this communication takes the order of tens of milliseconds now tens of milliseconds may be a lot of time depending on the situation when a very high-speed communication is going on  then tens of milliseconds is a lot of time but if you are going to set up a light path and then use it for one month or one year  then tens of milliseconds may not be much so it depends on the situation ; but if your traffic is changing dynamically then you want to adopt what light paths you want to assign etc  in a dynamic fashion  then tens of milliseconds may be a lot of time the other problem is that the huge capacity of 1 ? can carry how much traffic  let us say of the order of 2.5 gbps or something like that or may be even more these days its capacity is very huge the point is that for just two nodes communicating  it may be a gross underutilization if proper traffic grooming is not done at the edge what you mean by traffic grooming ? you remember that at the edge  first of all  when we are talking about the edge  we are talking about the backbone network  which is where usually all your wdm systems will be deployed so we have this backbone network and these backbone networks have been fed by all different networks  are routed from different networks etc  so number of streams are coming into this backbone network they are converging and then traveling to the backbone  and then going out on the other side so  the routers which communicate with this backbone are the edge routers and the light path you have got from n1 to n2  as we have seen is the granularity is quite coarse ; that means a quite high amount of traffic can be handled so if the edge router get together a number of streams from different sources and then uses it  it ? s good traffic roaming ; it loads it quite well then that is good so we are achieving high efficiency if it is two single users and the two end then it is a gross under utilization of this ?  unfortunately in this circuit inherently you can not have less than 1 ? for a circuit  if you are setting up a circuit you have that capacity but you are underutilizing it this is the same problem that we had seen in circuit switching versus packet switching  and as a matter of fact there is a development as we will see for the packet switching part also  which we will see in the next half of this lecture  refer slide time  27  03-27  13 min  so bandwidth is inefficient for bursty traffic this is another term that you should know  if you remember i told you while discussing about the telephone traffic that the bell telephones people had done a lot of study about what kind of traffic is there  and how long the people talk and how frequently they talk at different times of the day  etc we know that this is the some kind of poisson distribution with exponential inter arrival time etc  so those are very well-behaved kind of systems unfortunately  in recent years first of all the voice traffic has shrunk to may be less than 5 % of the overall traffic in the network  95 % of it is data traffic and this data traffic has seen to be very bursty they also follow some kind of statistics  but it is a complicated kind of statistics  the whole thing is that the data traffic seems to come in bunch when they come lot of packets are coming and then for a long time there is no traffic it is also self similar  and it is complex kinds of statistics but in anyway the point is  for long time for which when it is not sending anything  the circuit is remaining unutilized ; so this is a gross under utilization of the circuit the busy time versus the lean time may be of the ratio of 1  500 or something like that so that is why this becomes an inefficient way another disadvantage is wasted bandwidth during either off or low traffic periods for sle or too much overhead  that is  delay  due to frequent set up or release in dynamic light path establishment that means if you want to put it down and then set it up again  in that time frame this becomes too much of an overhead because  if you remember  for setting up a light path we require may be tens of milliseconds so you can not do it very fast  refer slide time  29  16-30  05 min  particular ? path specific pros and cons are that  they have very coarse granularity  as we have discussed i.e  oc 48 and above oc 48 if you remember is 2.5 gbps or above that they have limited number of wavelengths and number of light paths ; no aggregation  that is  merging of the light paths inside the core so inside the core  there can not be any aggregation etc traffic grooming can only be done at the edge so this may be complex or inflexible that oxc has a millisecond kind of switching time so these are the pros and cons of ? paths  refer slide time  30  06-30  10 min  so this takes us to the next half of our lecture  where we will have a look at the other way and other approach to this whole problem  namely  optical burst switching just as the previous one was circuit switching  where we were doing circuit switching ; we were setting up light paths here we will try to take the packet route ; that means we will send them packet by packet how that can be done ? originally  the packets may have originated from some say tcp/ip or ethernet or some computers as small kinds of packets doing it at that particular level becomes difficult at the optical level so we have some technology for that ; we will look at this now we will discuss the next topic  which is optical burst switching  refer slide time  31  13-32  19 min  first of all  let us do one quick comparison between electronic versus optical switching data is transmitted optically in wans  mans and even some lans electronic switch uses digital switching fabrics ; converts data from optical to electronic for switching and then from electrical to optical for transmission that means what we are doing is that  we are trying to do the switching in the electronic domain as mentioned a number of times before  the electronic switching always has problem ; at high speeds it is very costly and this is not very easily upgradeable  scalable  etc so that is a problem ; but if you have done the switching in the electronic domain  there will be no problem the kind of switching and kind of logic  kind of algorithm that we use in the other parts of the network could be put over there but we want to avoid electronic switching and do optical switching as much as possible so let us see how that can be done  refer slide time  32  20-32  33 min  the cost of electronic switching goes up steeply as the speed requirement increases and optical or photonic switching uses optical switching fabrics  keeps data in the optical domain  refer slide time  32  35-32  51 min  so  why not we keep the status quo ; that means that do the switching in the electronic domain only ? well  the trouble is that the data traffic growth is still doubling every year and this is different from what we have in the computing domain in the computing domain or moor ? s law  it doubles may be in one and a half years and this is doubling every year actually if you see over the long range  although the computational speed has increased many fold  the communication speed has grown even more  by an order of magnitude more maybe so the point is that electronics is unable to move and that is not possible for developing at that particular rate of development so pure electronic processing and switching can hardly keep up electronic mux  demux  space power consumption  heat dissipation  etc  are always a problem because heat dissipation is more  it requires most space etc there is no transparency  meaning  it depends on the kind of system and the kind of the modulation system  the kind of multiplexing system that you are using  which you have to use in the electronic components so when the technology moves on  these intermediate nodes will also have to be changed  whereas  the optical switching  since it is transparent  does not matter if you change what you are sending through that pipe  refer slide time  34  33-34  51 min  the cost factor  of course  weighs the heaviest though the cost of oeo at 0c-48 is going down  the overall cost including wdm system at 0c-48  is still a dominant factor oeo at 0c-192 and higher in the future will still be a dominant cost factor  refer slide time  34  52-35  18 min  so we want to go to optical switching  whose advantage is that  low cost and high capacity  transparency ; that means it is independent of bit rate  format  protocol  etc it is synergetic to optical transmission and future proof ; that means when we upgrade  all these things might change but my intermediate node will not change in the optical switch  refer slide time  35  19-35  41 min  opaque  that is oeo switches  are more mature and reliable  of course so still they need some electronic processing and control ; that means  when we are doing in the optical domain  we still require some electronic processing and control what we do is  we try to minimize this  and optical 3r and performance monitoring are hard you remember that we can amplify a signal quite easily but if you want to do all the 3rs that means regenerate  reshape and retime  then we prefer to take it to the electronic domain  refer slide time  35  58-36  30 min  packet switching  a packet contains a header ; that means addresses and the payload it is a variable or fixed length the advantage of packet switching is that it has some kind of statistical multiplexing ; it can be sent without circuit set-up delay ? if the line is there just simply send it it also enables statistical sharing of link bandwidth among packets with different sources and destinations so that makes it more efficient ; bandwidth usage is more efficient  refer slide time  36  31-37  04 min  so packet switching is done usually this way store and forward at each node  it buffers the packet  processes its header  and sends it to the next hop this is how usually it is done in the electronic domain ; we will look at the details of this later on but usually what would happen is that  when we are using a circuit switching  the circuit is set up from n to n and then we can send whatever we like but when it comes to packet switching  since it is coming packet by packet  each packet has to be processed independently we have to look at this packet  look at this header  see what the destination is  decide on which next link to take  etc  and send it so you have to store this packet in a buffer and then examine  do some processing and then forward it ? this is the store and forward paradigm this is usually done in packet switching  refer slide time  37  37 ? 37  43 min  we have some problems with that optical domain  as we will see it is statistical multiplexing and is inherently bandwidth efficient  refer slide time  37  43 ? 38  25 min  now if you have a packet core  well  we have the access or metro networks  optical buses  passive star couplers  etc sonet wdm rings or token rings are used we will talk about token rings later it uses switched networks or gigabit ethernet so these are the kind of technologies that are deployed in the lan/man side  whereas in the wan side  we have the ? routed virtual topology  i.e  circuits or leased lines we have dynamic ? provisioning ; that means circuits on demand and optical burst switching  which we are talking about now  refer slide time  38  27 ? 38  54 min  the technology drivers for this are the explosive traffic growth  as i already mentioned  bursty traffic pattern  and to increase bandwidth efficiency to make the core more flexible  naturally a packet ? s system would be more flexible than those fixed light path kind of system to simplify network control and management and making the core more intelligent  refer slide time  38  54 ? 40  05 min  how important is this bandwidth efficiency ? we are always talking about the bandwidth efficiency well there are two views to it ? one is the user ? s point of view well  user wants some bandwidth today and if the bandwidth becomes cheaper and as it becomes available  he immediately thinks of another application and his bandwidth demand will grow previously  people were very happy to send some simple text now  they are downloading  then they want to download songs  files  they want to download entire videos  then they will try to do video conferencing with each other so these are very bandwidth intensive applications and they require a lot of bandwidth so from the users ? point of view  the more the bandwidth you give  i will bring lot more applications and i will just use it up so with more available bandwidth  new bandwidth intensive applications will be introduced high bandwidth is like an addictive drug  can not have too much of bandwidth from the users ? point of view  refer slide time  40  05 ? 40  38 min  from the carriers ? and vendors ? point of view expenditure rate is higher than revenue growth sometimes ; so longer-term equipment investment can not keep up with the traffic explosion so  you have to see that whatever i invest today  how long in future i can take so that my investment is lower we need bandwidth efficient solutions on the infrastructure existing today that will be competitive so these are the different issues which  refer slide time  40  39 ? 42  07 min  brought us to optical packet switching or optical burst switching i will come to that later on but this is our goal ; there are two problems ; and one of them is the lack of optical buffer in the optical domain  if some packet is coming  means some light pulse is coming now  how do you store them in the optical domain ? there is no good buffer for optical domain ; there is a thing called fiber delay lines this is really a very bulky and not very good stuff  you can put it in the fiber delay line as it comes  it goes to that fiber delay line and comes out of the other  the whole thing would be delayed a little bit ; that is something akin to buffer in it but there are severe limitations on how much you can delay  that is one thing secondly  it is bulky  expensive and not very good so fiber delay lines are bulky and provide only limited and deterministic delays store and forward with feedback fdls lead to fixed packet length and synchronous switching so we can not use because of this simple store and forward  and the other thing is that tight coupling of header and payload requires stringent synchronization and fast processing and switching so these things are difficult  refer slide time  42  07 ? 43  49 min  so we go to this optical burst switching or obs ; a burst has a long and variable length payload so first of all  variable length payload means we want to keep it as flexible as possible ; that is one good aspect of it that means we want to keep it as flexible as possible the other thing that we want it to be is it is long  why is it long ? because we have to do some processing  some setting up  etc  for these burst of packets to travel so what we do is  we will do some grooming in the electronic domain we collect a number of packets together forming a burst  which has the same source ? destination pair and then we set up the path and send this burst along all in the optical domain so that is the essential approach to optical burst switching a burst has a long and variable length payload  if it is long and has low amortized overhead and no fragmentation a control packet is sent out of band  that means using some other ? control and reserves bandwidth ? that is ? data reserves a particular bandwidth along a particular path ? and configures the switches so it is like setting up a temporary light path from the source to the destination a burst is sent after an offset time ; it arrives at a switch after it has been configured so no buffering is needed our original problem is of not having optical buffer  so buffers in the optical domain are avoided in this fashion  refer slide time  43  49  44  51 min  we have to do a burst assembly and disassembly at the edge at the source side that means the client data may be the ip packets  which are the most dominant ones they are assembled together into bursts ; and burst switching or reservation protocol is done  that means  we send the control packet  an offset time t ahead of burst so within this offset time  all the switches down the line will do their programming that means they will set up all their mirrors or whatever it is their cross connects  etc so that later on  when the burst does arrive  we do not have to do any processing on that and if you are do not doing any processing on them we do not need to store them either they can go straight away in the optical domain there is a dedicated control channel  which is out of band signaling for the control packets  refer slide time  44  52 -45  25 min  the advantage is no fiber delay lines nor oeo conversions for burst at any intermediate nodes  photonic burst switching fabric inside the core that means it leverages best of optics for burst switching and electronics for control packet processing and fabric control so just for the control part  we do this oeo and for the bulk of it  the burst  we do not have to go to the electronic domain at all  refer slide time  45  25  45  55 min  this is a diagram  say assembly queues for different egress nodes ; these are going to different channels this is an atm cell ip packet or sonet  and we have an ip packet over here we have a sonet frame over there because if you are sending things in the purely optical plane  you do not really care what the payload contains it may be an ip packet  it may be a sonet frame  it may be some cell  it may be anything else we do not care intermediate optics is transparent to all that so what happens is that  refer slide time  45  16 ? 47  18 min  we use the atm cell for the control packet purpose so we make a control packet  which assembles a burst  and as it assembles a burst  it knows what the time or length threshold reached is the length of the burst may be variable  as we said the burst could be long and of variable length but when all these different ip packets frames  sonet frames etc  are put together  what happens is that a control packet is generated and sent out the control packet now knows the source  it knows the destination  it knows the length of the burst  so it sends through a separate control channel  so this control channel goes through the control plane as we will see  refer slid time  47  18 -47  44 min  so we have the assembly queues for different egress nodes ; that means the destinations  for different destinations  all these packet frames etc  are getting queued up and forming into bursts  refer slide time  47  44  48  04 min  now we see fiber delay line ? as i just mentioned it fiber delay line  feed forward or feed backward so there is no optical ram for store and forward ; every fdl provides only limited delay and can not perform most of useful buffer functions so fdl units are bulky  affect signal quality etc  refer slide time  48  04 ? 48  24 min  now going back to this obs  we have various schemes still involving in an active area of research i will just present a simple scheme called just enough time or jet there is an offset time between cp and burst so what is done is that the control packet is sent and after the control packet is sent  there is a delay we give a delay and then we send a burst ; this delay is to cover all the programming time on the intervening nodes  refer slide time  48  43 ? 49  05 min  so an offset time between cp and burst  no fiber delay line required to delay the burst  when cp is processed and switch fabric is configured cp carries the burst length info  facilitates delayed reservation for intelligent efficient allocation of bandwidth and fdl if any  including look ahead scheduling we need not go into the details  refer slide time  49  10-49  53 min  we have the control packet here  which is moving in the control plane  and we have a burst over here and there is offset time t and we have just enough offset  jet  which we require for programming these intervening optical nodes so cp arrives at oeo node at time  let us say  t1 but the control packet is being taken to the electronic domain for processing  because this will have to be processed etc so it is better done in the electronic domain  refer slide time  49  54 ? 50  05 min  then cp goes through the optical to electrical conversion and configure the switch fabric and then it will move on  refer slide time  50  06-50  12 min  cp goes through eo conversion and leaves the oeo node at time t1 + ?   refer slide time  50  13-50  53 min  so what will happen is that  this will now move towards the other end  to the next node  and here this will again go through the o to e and then do the switch configuration and then again e to o and go to the next hop and this delay is calculated in such a fashion that when the burst arrives  what happens is that at the intermediate node  the switch fabric is already configured so you do not have to store it ; you simply pass through in the optical domain  refer slide time  50  54-51  16 min  offset of course is now t  ? because it spent delta amount of time over here so without any delay  the burst goes through the optical switch fabric depending on how many intervening nodes are there  you have to have this original t so that finally when t is exhausted  offset is exhausted but you have also reached your destination  refer slide time  51  17-51  37 min  that is just enough time and finally to conclude  obs is a programming switching paradigm that offers many advantages over the existing technologies  but is not likely to be the end-all kind of solution obs has several variations and adopting obs will be an evolutionary process this is another problem ? when you have a new scheme and there are different researches  they will try to do research and come up with different suggestions and then at different places some different things may be adopted but then  in order for the entire network to work in a very smooth fashion  you have to come to some standard  so obs has not come to that standard yet  but it is a quite a promising approach now  we have talked about the two approaches in wdm  namely  this circuit switching path  that is the light path routing and wavelength assignment and setting up of light path  and we have talked about optical burst switching in the next lecture  we will talk about sonet infrastructure the sonet  which we have talked about  a lot of it is also in fiber optics then we have all these fiber optics ; that means packet oriented fiber optic infrastructures are also coming in that means large routers  etc  are coming into this picture  one thing we did not discuss although we mentioned it a while discussing about sonet was that this has an inherent capacity of fault recovery  recovering from fault so that is one thing that we would like to discuss in the next lecture ? not only in sonet  in optical network  but in general  how do you handle faults that is very important  because this optical network is at the core of the network and if the core of the network fails  its repercussion is tremendous  both economic and other repercussion may be tremendous so we like to put in lot of reliability into all this fiber infrastructure that we have  and how exactly that is done  we will discuss in the next lecture thank you preview computer networks prof  sujoy ghosh dept of computer science& engineering iit kharagpur lecture 12 protection and restoration  refer slide time  53  37-53  41  good day in this lecturer  we are going to discuss the various protection and restoration mechanisms  which are usually employed in optical networks  refer slide time  53  54-53  57 min  we will be talking about protection and restoration  now of course we have to discuss  what is protection and restoration why we need them ?  refer slide time  54  05-54  16 min  what is protection and restoration  comparison between the two and the different schemes of rotation ? this could be our general outline of presentation  refer slide time  54  19-54  25 min  network is unreliable somehow  so many failures can occur  node may fail a link  may get cut  some fiber optic line may cut in between because somebody cut it  while digging a whole or something or node might fail there may power failures at nodes and so many things so there are failures in the network but if you remember that one of the most important places where we deploy optical networks is in the core of the network and the core of the network connects so many people  to so many other people it is so very vital that we can not allow the services to be a severely desalted because that would have very grave consequences anyway the service provider attempts to give a very high level of service so although failures are unavoidable in real life  we have to find a some way of combating this  that means if there is a failure  we want to recover from it as soon or as fast as possible so that  is what protection and restoration is all about another thing is that when we want to give some reliability  protection  restoration etc we always in some form  always have to bring in some redundancy without any redundancy a system can not be protected  it can not be restored without any replacement etc  so there has to be some redundant capacity in some form in the network  in order to achieve protection and restoration how this is done that is what we will discuss  refer slide time  56  14-56  25 min  so first let us talk about path protection  it uses more than one path to guarantee that data is sent successfully so if you look at this graph  it will be having a six node graph  where 1 and 6 are communicating on the top through the dash line we show the primary path  which is the primary connection between 1 and 6 what might happen is that the link between 2 and 3 might snap due to some reason so we have already got a backup route which is calculated going through 1 4 5 & 6  we will channel our communication through the backup link and please note that this backup or secondary path from the source of the destination is link this channel does not share any link with the primary path  so that is the requirement if any link in the primary path fails  i am assuming only one failure which means that the backup link is all intact and you can switch to the backup path for this particular communication  refer slide time  57  24-57  47 min  dedicated link protection is not always practical  sometimes it may have it shared link protection is practical  it is quiet often and it is implemented and it may fail  when this link protection may cause failure here you are only provisioning for the failure of the link  but if a node fails  then it may lead to some complications as we will see  refer slide time  57  48-58  07 min  so to compare between path switching and line switching path  switching of course is a coarse scheme and line switching is a finer scheme and line switching is can again be span protection  span would may be a several links together and that may be a span or a line protection  refer slide time  58  08-58  37 min  in mesh networks  of course the restoration is possible only if the graph is 2 edge connected that is by connected which means that there are 2 edge connected disjoint paths between any pair of nodes so that no single edge failure can disconnect the network so this is a necessity and usually try to keep that way  unless it will be difficult or it is not a cost  effective etc   refer slide time  58  37-59  21 min  protection in a mesh networks of course more complicated  then a ring simple minded scheme would be 2 edge node  no disjoint paths for each connection 1 + 1 not as is mentioned here  this not very efficient there may be many paths and provisioning double the number of paths  which are pair wise mutually node are edge disjoint that may be very difficult provisioning in the network better approach would be line protection which of course have the problem of coordination i will show the later on are protection cycles in mesh net  again i will show this computer networks prof sujoy ghosh dept of computer science& engineering iit kharagpur lecture 12 protection and restoration  refer start time  00  43  good day in this lecture we are going to discuss the various protection and restoration mechanisms which are usually employed in optical networks  refer slide time  00  57-00  59  we have to discuss what is protection and what is restoration and why we need them  refer slide time  01  08-01  18  what is protection  what is restoration  comparison between the two and the different schemes of protection would be our general outline of presentation   refer slide time  01  19-01  26  network is unreliable ; and then so many failures can occur ? a node may fail  a link may fail or a link may get cut  some fiber optic line may cut in-between because somebody cut it while digging a hole or something a node might fail  there may be power failures at nodes and so there are failures in the network but if you remember  one of the most important places where we deploy optical networks is in the core of the network the core of the network connects so many people to so many other people and it is very vital that we can not allow the services to be severely disrupted because that would have very grave consequences and anyway the service provider attempts to give a high level of service although failures are unavoidable in real life  we have to find some way of combating this ; that means if there is a failure we want to recover from it as soon or as fast as possible that is what protection and restoration is all about another thing is that when we want to give some reliability  protection  restoration  etc  in some form or the other we always have to bring in some redundancy without any redundancy  a system can not be protected  or it can not be restored without any replacement  etc there has to be some redundant capacity in some form in the network in order to achieve protection and restoration so how this is done is what we will discuss  refer slide time  03  20-03  25  protection and restoration are the mechanism to recover from network failure  their difference will be discussed in the following parts  refer slide time  03  26-03  37  why we need protection and restoration is now clear  to recover from network failure  to prevent the lot of data loss now another point is what would we mean by prevent lot of data loss ? the point is that we will be talking about protection at the optical level  at the lower  transport level  that is  the low physical level above this physical level  there are a whole lot of other layers like data link layer  network layer  transport layer  etc they may have their own protection mechanism and they might be able to tolerate in some cases  if such a protection is sort of implemented at higher level  such protection usually would tolerate a small amount of data loss  which they will retransmit or do something in the protocol to take care of that we will be talking about this later on within that limit we do not have a 100 % tight case  but we have something to play with within that limit  if the physical layer can come back up  then that is nice ; then the end user who is sitting at the top of the application layer would not notice that a failure has actually occurred so this is our general goal and  of course  to prevent lot of data loss  refer slide time  05  13-05  18  to provide reliable communication service is a reason for having protection and restoration  refer slide time  05  19-05  39  protection is the primary mechanism ; this is fast and routes are usually preplanned ? we will come to this part later on ? whereas restoration is the secondary mechanism  used to provide more efficient routes or additional resilience  etc  over and above protection we will see both of these later on  refer slide time  05  40-06  11  techniques for protection  we could protect a path  which is called path protection ; we could protect a link ; that is called link protection there are various schemes of protection  like 1 + 1 protection  1  1 protection  1  n protection  m  n protection this depends on what kind of redundancy we have built into the network so we will look at some of these techniques one by one  refer slide time  06  12-06  26  so what are the considerations and tradeoffs that we have for protection ? for support for fast protection  time is dictated by the client layer this is what i was talking about earlier ? in the client layer  whatever the higher layer we are talking about  all of them are clubbed together  and we are calling them client layer  let us say in the client layer we may have some resilience ; that means  we can tolerate some small amount of data loss so depending on that  and beyond that  it will be taken that the service will fail this is dictated by the client layer and that is the constraint within which we try to do our protection or restoration at the bottom layer  that is  the physical layer we require some switching technologies  refer slide time  07  13-07  33  as we will see  and how to implement protection it could be through dedicated hardware or through software here we will only be talking about ? since we are talking about the physical layer ? hardware protection  where some hardware has been put in order to take care of this protection  refer start time  07  34-07  51  support for low priority traffic ? that is another consideration we might have so low priority traffic supported using the protection bandwidth ; traffic dropped in case of a failure as i mentioned earlier that in order to give some protection capability into the network we have to build in some kind of redundancy over there now when there is no failure  naturally the redundant link would be idle what you could do is that if you have some low priority traffic  which could be dropped whenever there is a problem  under normal circumstances you can use your provision in the network to carry the low priority traffic  and as soon as there is a failure  where naturally the provision is going to be used up for providing protection  restoration  etc  the low priority traffic would be discontinued so that is one thing we could do  refer slide time  08  46-09  03  support for mesh topologies ? mesh topologies are bandwidth efficient  fast signaling mechanism  flexibility in choice of routes by preplanned routes  etc if we have support for mesh topologies  it is also nice as a matter of fact  if you remember our discussion about different types of topologies ? we have star  tree  ring  mesh etc  so these are the different possible topologies out of all these  point-to-point connection  ring and mesh are the three topologies  which dominate most of the wan when you want to communicate between two points  you first set a point-to-point link now consider that link to be quite important then what you would like to do is that you would like to put in some kind of reliability over there  by making it into a ring for example  we discussed sonet a sonet gear quite often is put in the form of ring  rings that would touch  mutually touching rings for example  the telecom people put up all these sonet rings through fiber optic networks the rings are quite easy to handle and we will discuss the protection mechanism in ring quite a lot but if you go to a wider geographical area ring  it may not to be feasible due to various reasons what you have is a mesh a mesh  if you recall  is just a graph  where the nodes are connected in some fashion it has to be a connected graph and actually later on we will see that for giving proper protection  it has to be not only a connected graph  it has to be biconnected graph as well that means between the two nodes  which are communicating  there have to be two alternatives paths  which are linked somehow otherwise  you will not be able to give protection giving protection in mesh networks is also an important consideration  refer slide time  11  17-11  55  other important considerations are maintenance of large distributed routing tables  that is  precomputed routes or up to date topology maps so you have to maintain this dynamically  because a network is a very dynamic thing as links come up or go down or nodes come up or go down  this may have to be recomputed and stored in a distributed fashion we would like to have support for all failure modes  node failure for mesh networks and for ring networks  so or it may be of course ring failures  refer slide time  11  55-13  05  first  let us talk about path protection it uses more than one path to guarantee that data be sent successfully if you look at this graph  it will have a 6-node graph where 1 and 6 are communicating and on the top  through the dashed line  we show the primary path  which is the primary connection between 1 and 6 now what might happen is that the link between 2 and 3 might snap due to some reason we have already got a backup route  which is calculated going through 1  4  5 and 6 so we will channel our communication through the backup link please note that this backup or secondary path from the source to the destination does not share any link with the primary path that is the requirement  if any link in the primary path fails  assuming there is only one failure  which means that the backup link is all intact and you can switch to the backup path for this particular communication  refer slide time  13  06-13  16  now path protection  there are various ways to protect a path  that is  various ways of provisioning the extra bandwidth capacity in the network so that you can give protection you need to build in some kind of redundancy in the network so there are various ways you can build in the redundancy and the schemes may be divided as dedicated path protection   refer slide time  13  40-13  50  or shared path protection dedicated path protection may be shown as 1 + 1 protection and shared path is 1  1 protection or 1  n protection so we will look at this one by one  refer slide time  13  51-15  31  this is an example of 1 + 1 protection so you have the source on the left  and then  you have destination on the right so it is communicating what you can see is that from the source  the signal is coming to the splitter if you remember  the splitter is going to split it into two halves  may be of equal power or something  and then the same signal is been carried through two different links and over there  we a switch the switch determines which signal is better and may be switches to that and a communication is going on if that particular link  say  this top one fails  it automatically switches to the other protection link so this is some kind of hot redundancy we have that means there is redundant source of information in the destination side ; so if the primary one fails  the secondary one is already on so protection would be very fast the only trouble is that for each such path  you will have to give an alternate path  which is also being used at the same time this is a dedicate path protection ? for this particular path there is a dedicated alternative path ; although this is very good  it is costly  refer slide time  15  32-16  57  now we come to shared mode protection ; in the shared mode  the figure looks almost the same  expect if you note  this splitter on the left has been replaced by a switch so what we have is we have a working fiber and we have a protection fiber unlike the 1 + 1 protection  this is not a hot standby this is cold in the sense that the protection fiber  to start with  is not carrying any signal  let us say the source is just simply passing through the switch  the signal from the source is passing through the switch  then down the path through the destination switch to the final destination if the working fiber goes down  then this switch will flip and the protection fiber would be in place since this is not a hot standby  meaning that since it is not carrying any signal under normal circumstances  you could share this path with something else you can use this to send some other channel or some other information  etc so that is why this is a shared mode of protection  refer slide time  16  58-19  35  generalizing this  we get this 1  n protection  where n line is sharing 1 protection line we have the inputs from 1 to n lines  so these are the n sources  and let us say so many destinations so they may be going ? 1 to 2 and n to n and so on ; this is the normal mode of operation this part of the network is for normal mode of operation and each of them is connected to a switch over here another link from the switch comes to one bigger switch  so this is an n input port over here and then there is a single link from this switch to this switch  on the destination side  which again feeds to all the switches what would happen is that in case there is a failure in any one  let us say  ith link from 1,2 to n  out of that  the ith source to ith destination  which is going through the ith link and the ith link fails  what this ith switch could do is that the ith switch could switch the signal from the ith source to this particular switch at the bottom and now the protection fiber would be carrying the signal that was flowing down ith channel over there and then again it will feed it to the ith switch on that side of course these two switches have to communicate that the ith one has failed over here  so you switch it to your ith mode  or this switch may sense it that this line has gone down  so it will take signal from this line this one protection fiber is been shared by these n working fibers  and as i mentioned earlier  when everything is fine this protection fiber could be carrying some low priority data when everything is fine these n working fibers are actually carrying the most of the important traffic so some low priority data could be flowing down the protection fiber as soon as there is any failure anywhere  the low priority data would be stopped or it will be dropped and then this protection fiber would switch to give the services between the nodes that have experienced a link failure just as we have a path protection that means for a path you try to give an alternate path  similarly you could do it at the link level also in general  it may be more efficient or more proper to do that because if you have n nodes and if it is slightly large  potentially you have very large number of paths through the networks and for each path having an alternate path may not always be a very good idea so we concentrate at the link level and for each link level we may give a protection  refer slide time  20  21-20  43  so use an alternate path if the link has failed this is the primary where the link may have failed so i have an alternate path to that from 2 to 3  2 to 4  4 to 5  5 to 3 this alternative  please note  is for the link from 2 to 3 we will have another diagram for that  refer slide time  20  44-21  09  dedicated link protection is not always practical although sometimes we may have it ; shared link protection is practical and it is quite often implemented this link protection may fail because here you are only provisioning for the failure of a link  but if a node fails  then it may lead to some complication as we will see  refer slide time  21  10-21  28  to compare between path switching and line switching  path switching is a coarser scheme and line switching is finer scheme ; and line switching can again be a span protection span may be several links together ; that may be span or a line protection  refer slide time  21  29-21  57  in mesh networks of course restoration is possible only if the graph is two edge connected i.e  biconnected  which means that there are two edge disjoint paths between any pair of nodes so that no single edge failure can disconnect the network this is a necessity and we usually try to keep it that way unless its very difficult or very cost it ? s not cost effective  etc  refer slide time  21  58-22  42  protection in a mesh network is more complicated then a ring simple minded scheme would be two edge or node disjoint paths for each connection  1 + 1 as is mentioned  it is not very efficient there may be many paths and provisioning double the number of paths  which are pair wise mutually node or edge disjointed may be very difficult that may be a lot of extra provisioning in the network a better approach would be line protection  which of course has the problem of coordination i will show that and protection cycles in mesh net later on  refer slide time  22  43-23  24  in the path layer and mesh protection  there is protection of mesh networks to protect the mesh at the single unit pre-computed routes means all possible routes and alternative routes are pre-computed 1 + 1 protection is protection route per light path  protection route per failure we will discuss this later but  as i said  this is a costly alternative or what we might do is that we can do on-the-fly route computation ; that means it is not pre-computed as there is a failure  centralized route computation and coordination route computation and coordination are done at end nodes or distributed route computations ? all these are possibilities  refer slide time  23  25-24  03  this is an example of mesh network  where let us say this is the primary path and this is an alternate path this alternate path may be pre-computed or it may be computed on the fly when there is a failure similarly  from here to here this may be the primary path and this is an alternate path please note that this communication as well as this communication are going through the same fiber maybe they are going through different wavelengths or maybe they are combined together ; so there are various way of handling this  refer slide time  24  04-24  51  let us look at some diagrams  this is a mesh network naturally once again  it has the same 6-node network and this is the normal operation  that is  communication from this node  node 1 to node 6 now there is link failure over here ; what you might do is you might switch the entire path like this so this was the pre-computed path for this path you switch to that ? this is one possibility or this particular span  the span could be live from here to here or from here to here that may have an alternative path  to which you switch  refer slide time  24  52-25  50  or this particular line may have this alternative ; that means from this node to this node if this is the link  the alternative to this link is this section from here to here to here to here it is trying to go through the same path  but then it takes a diversion when there is a link failure through the alternative  which is provided for this particular link i have shown only one node coming into this but you can appreciate that this path may be very long so you do not have to re-compute the path over the entire length ; rather locally  you can re-compute that for this particular link as an alternative so the alternative may well be through some local nodes only so this path just gets a slight diversion ; that is line protection  refer slide time  25  51-25  59  we talked about protection cycles in a mesh network  now for protection cycles  what we do is that for each of the paths we try to form a cycle ? cycle of provisioning of light paths  let us say the point in the cycle is that suppose we are going through some arc of the cycle and if some link in-between breaks  you can always go in the other direction so you try to form these cycles in the mesh which you keep ready and pre-computed so whenever there is a failure you can switch you can see here  refer slide time  26  38-27  03  there are pairs of a fibers going in both the directions and there you can form cycles over there one of them would be protection edge  maybe the inner one ; and one of them would be the working edge if one of them fails  the other will automatically take over ; the other direction will automatically take over  refer slide time  27  04-27  25  so this is another example of a network with both working and protection fibers the working fibers have been shown in solid lines whereas protection fibers have been shown with dashed lines once again you must realize that you may not provide the same level of protection to all paths or to all parts of the network ; depending on which part you consider more sensitive or more important  you may put your protection there a mesh network may be partially protected some of the parts may be protected or some of the parts may not be protected  refer slide time  27  51-29  53  so some more cases  line protection in a mesh network what we have is a unidirectional light path from node a to node d ; so from node a to node d we have an unidirectional light path going may be like this through nodes b  c  and e we are talking about this path a to b to c and then to e now after the link bc fails  the light path is rerouted by nodes b and c along the route a b f e c e d the unidirectional light path was going from a b c e and then to d ; so this was the path a b c e d now bc has failed ; so a b f e c e d you can see what has happened is that there was no point in coming from e to c and then back from c to e what has happened was that we were doing line protection ; that means  for bc my protection was from b to f to e to c because i wanted to go from b to c so i am going from b to f to e to c and so now bc has failed so that is what i do and from that point i continue wherever i was going and actually i was going from c to e to d  so once again from c  i go back to e and then to d such a thing is possible because we are taking a local decision ; that means  for this particular link what to do in the case of failure that has already been pre computed ? we are not taking a global picture ; here i have shown you a very small graph so you can immediately see the entire global picture with your own eyes but for local nodes we may not have the global pictures where this node is coming from and where this path is finally going to so all the intermediate nodes may not have the global pictures because if all of them had the global pictures maybe they could have computed a better path but this is for line protection  refer slide time  30  41-31  57  now line protection in mesh network  here what might happen is that erroneous connection due to the failure of a node is being treated by its adjacent nodes as link failure this is one case of the so-called race condition what might happen is that node 1 has failed ; so what would 6 do is that it may assume that the link from 6 to 1 has failed  whereas 2 may assume that the link from 2 to 1 has failed so both of them perceive as two different failures  so they take some local decisions  and it might lead to a funny situation where you are going in a cycle maybe other kinds of things may happen after node 1 fails ? node 5 gets connected to node 4 after node 6 and 2 invoke line protection independently if they perceive the same failure  the actual failure was that of node 1 ; but if they perceived differently as failure of link 6 1 and failure of link 2 1 and they have independent actions  it may lead to race conditions  refer slide time  31  58-32  14  the advantages and disadvantages of protection  we will also be talking a little bit of restoration protection is simple ; it ? s quick ; does not require much extra process time ? and this is the important part  since this is quick as i mentioned earlier  there will not be a lot of data loss for example  a sonet ring would sort of come back up from a failure in a less than 15 milliseconds so that is a benchmark ; you are back in action in less than 15 milliseconds  so whatever little you might have lost during that time would be taken care of by the higher layer protocols  refer slide time  32  51-33  08  but usually they can only recover from single link faults if there are multiple link faults  all kinds of funny things may happen there is inefficient usage of resource  because protection needs a lot of resources  even if we are sharing them  refer slide time  33  08-33  19  dedicated protection needs even more resources ; we talk about path restoration and link restoration  refer slide time  33  20-33  30  what we do is that we compute the path after the failure and the resource is reserved and then used so in restoration what you try to do that is that you try to look at the current actual situation you try to have some protocol for keeping track of the present situation and then you compute some root and then you reserve the path and then restore the original service this has got some software parts  so some data has to be processed  etc this usually takes more time  so this has a hardware as well as software aspect to do it   refer slide time  34  00-34  25  the path is discovered at the end nodes of the failed link ; but this is more practical than path restoration we have both path restoration and link restoration path restoration means the path may be long and to find out an alternative  it may be more difficult  whereas links are between the adjacent nodes so they may quickly find an alternative  refer slide time  34  26-34  53  advantages and disadvantages of restoration are the following  usually it can recover from multiplex element faults because you are sort of having some protocol to exchange information and then find the current situation and form the alternatives  etc there is more efficient usage of resources ; it is more complex ; it is slower ; it requires extra process time to set up path or reserve resources  refer slide time  34  54-35  19  so for comparison between protection and restoration  in protection the resources are reserved before the failure ; they may not be used in restoration the resources are reserved and used after the failure so this is the main difference between the two route  in protection it is predetermined  in restoration it can be dynamically computed resource efficiency  in protection it is naturally low and the restoration is comparatively high  refer slide time  35  20-35  55  time used for protection is short ; for restoration it is longer reliability  protection is mainly for single fault  whereas restoration can survive under multiple faults well  it is not that it can always survive under multiple faults ; it depends on the where the faults are  but if it is survivable after multiple faults  it will take global view and say that ok  still i can give the services so restoration will take care of that  whereas in protection it may not be possible to handle multiple faults implementation  protection is simple and restoration is naturally more complex  refer slide time  35  56-36  21  for optical networks  we not only talk about physical links we talk about virtual wavelength paths so in light paths also routing can be centrally controlled or distributed ; resource reservation  forward reservation  as well as backward reservation are done as we do in optical networks we will talk more about this later  refer slide time  36  22-37  15  now let us come to this all-important topic of fault management in ring networks as i said  ring networks are very ubiquitous in wan all the telecom people will love these things because naturally it allows them to give very high level of service so we have so many rings ; these sonet rings are very common  and rings are a very common kind of topology one of the chief attractions of the ring topology is its capability to allow some kind of protection and restoration with some redundancy in-built  as we will see we will look at two different cases  unidirectional path switch rings and bidirectional line switch rings or upsr and blsr  refer slide time  37  16-39  22  this is a diagram of upsr we have ab  means a to b and ba  means b to a first of all you see that we have these two rings ? we have this working fiber as well as a protection fiber working fiber is going in only one direction and protection fiber is going in the other direction  in the counter clockwise direction so for connection from a to b and from b to a ? this is a  and this is b ? my working fiber is going in this direction a to b is really going in this direction ; b to a is coming in this direction so a to b  b to a  this is the protection fiber part  a to b the working fiber is going in the other direction a to b is going like this and b to a is coming all the way like this let us say the outer one is a working fiber  it is through the outer ring for a to b  this is the path ; and b to a  this is the path  whereas for protection purpose ? and please note that this is a 1 + 1 scheme ; that means for this the alternative is already provisioned and maybe it is something like a hot standby so a to b is through the protection fiber and now this path from a to b is going via d and c  so a d c b  that is a to b and b to a the protection path is from this through the protection fiber so if there is a failure anywhere  this can still continue  so this is a unidirectional path switched ring  refer slide time  39  23-40  29  there are some limitations of upsr it does not spatially reuse the fiber capacity ; so what is happening is that since this is unidirectional  what is happening is that even if two nodes are side by side  if they are in wrong direction then it has to come all the way through and naturally all those links ? even if we are talking about particular ? s i mean wdm systems ? in the ring are entirely sort of covered by this otherwise even if we are talking about a wdm system what is happening is that at least one ? around the whole ring is getting occupied because two side by side things want to communicate so it does not spatially reuse fiber capacity and if there is some  you could use it for some other purpose that is not possible in a unidirectional ring each bidirectional sonet sdh connection uses up capacity on every link that is the thing ; if you look at the previous picture  refer slide time  40  30-40  44  we are just talking about a connection from a to b and b to a ; that ? s all  so this entire ring now has been used up assuming only one wavelength the entire ring now has been used up ; these adms of course are the adms of sonet  refer slide time  40  45-40  50  so it is efficient for lower-speed access networks  one to multipoint only  refer slide time  40  51-41  27  and the other point  which may become a problem  is that delays are different for the two paths because one of them is small and the other one is quite large  all the way around the link the relays in the two paths are quite different a remedy could be bidirectional lines ; that means  bidirectional line switched rings or blsr so we were in upsr  now we will be talking about blsr  bidirectional line switch rings this provides spatial reuse capabilities and additional protection mechanisms and adopts span as well as line protection we will have a look at both of these  refer slide time  41  28-42  26  this is a four-fiber bidirectional line switched ring ; so once again we have two working fibers  say  the outer two ones and two protection fibers or the inner ones so we actually have four fibers this is a four-fiber system and it is going  so we are using two such working fibers one of them is going in one direction the other is going in the other direction  so this is bidirectional we can communicate both ways  so if a to b and b to a both can communicate on the working fiber in this part at all  the rest of the space can be used for other communication so spatial reuse is much better for bidirectional line switched rings  and the protection fibers are there because if one of them fails then the protection fiber may take up  refer slide time  42  27-43  10  this is a span protection so we are talking about bidirectional traffic supports  maybe 16 nodes or some distances  etc  from a to b you may pre-compute a span that if this span goes down what is the alternative span if this is the case of line protection  if this line fails what is the alternative line ? now the alternative line of course may go in the other direction  depending on what the failure is so there are many different possibilities with this blsr  refer slide time  43  11-44  24  there is also two-fiber version of blsr  namely blsr/2 here both the fibers are working as well as protection fibers that means if one of them fails the other one will give the protection in the other direction of the ring if you note  the rings are going in the opposite directions and there is a line failure in both of these working as well as protection fiber that means a to b is communicating in this direction  b to a is communicating in this direction but if one of them fails  the other one will give the protection by going in the other direction in that case we have to go all the way round  then you will have to reserve the resource and if there is something already going on here  you may be blocked or this may have to be dropped and so on so naturally you have two fibers  we have less flexibility but with two fibers we can get this bidirectional thing going on  refer slide time  44  25-46  19  comparison of different types  these are all self healing rings what we mean by self healing is that the nodes  these adms and the sonet  etc  are programmed in such a fashion that as soon as they sense a failure they know what local action to take and how to adjust the switch internally  so that it automatically switches from the working fiber or from the working span or working fiber or whatever through the protection side that is why these are self healing rings  so they heal automatically and as i said these sonet rings really do this in less than 15 milliseconds ; the entire thing will again be up so we can compare the three  upsr  blsr/4  and blsr /2 for example  fiber pairs 1  2 and transmission receiver pair 2 4 and 2 spatial reuse in upsr it is none  in blsr it is there  and in blsr/4 it is there production capacity is equal to the working capacity link failure is path protection in the case of upsr or span or line protection in the case of blsr/4 in case of blsr/2  it is only line protection because it will have to go in the other direction node failure  it is path protection  line protection and line protection restoration is faster in upsr ; somewhat slower in blsrs and restoration speed is this node complexity is low  high and high another thing we talked about is the dual homing  refer slide time  46  21-47  50  by dual homing we mean that suppose we want to deploy your network in such a way that it is very mission critical and no failure is acceptable and we want a hot standby so what you might to do is that you may get connected through two different hubs and what you want to do is that you want dual home to these two hubs and these two hubs take independent paths to your destination this shows a dual homing to handle hub on node failure ; so we have these four adms  once again four nodes  let ? s say a b c d so the end node is a and these are the two hubs  b and c what we want is that not only some link failure but even if one of the hubs fails  i should still be able to communicate so what you do is on this ring you communicate with hub 1  let us say you are communicating with hub 1 through this a d c b and you are communicating with hub 2 through a b c as we will note  even if one of the hubs fails  you can still communicate through other one so this is another kind of protection  refer slide time  47  51-48  14  and finally i have mentioned this point before ? just a reminder that a network consists of many layers and each layer may have its own protection mechanism built in  independent of other layers so there are both advantages and disadvantages to this we have already talked about the advantages  refer slide time  48  15-49  51  this is an example of a wdm link carrying sonet traffic so there is a wdm link  so there is a sonet adm this is a working fiber pair and protection fiber pair please note that the pair has been shown as one line over here because usually as you know that fiber optic line is a simplex line ; that means it goes in only one direction ; there is a source in one side and the detector on the other side usually these fibers always come in pairs the other side is for the communication in other direction so we have a working fiber pair over there and protection fiber pair through this wdm link look at this 1  2 protected scheme what is happening is that there is one protection fiber pair  there may be protection fiber pair and through the working fiber there may be multiple virtual links going through the working fiber using different wavelengths a is a normal operation and b link is cut and the traffic is restored by the optical layer that means you automatically assign new wavelengths and new paths through the fibers etc  to bring it up so this you may do at the optical layer rather than at the electronic layer  refer slide time  49  52-51  58  but the case we are talking about here is that the sonet is riding on the optical layer so we have the optical layer at the bottom then you have a sonet on top of it on top of sonet also there will be the data link layer and then so on all the other links what we are saying is that each layer may have its own protection mechanism so for example i mentioned that the sonet will also have a protection mechanism of its own so if a sonet lte  i.e  the sonet line terminal equipment  senses that it can not communicate to the next lte  this will automatically reroute the traffic and try to reroute the traffic in the other direction sometimes it is good to have multiple protections at multiple layers but what might also happen is that they might sort of cancel each other or they might go into a race condition so these are the disadvantages of having protection at various layers there could be some disadvantage also if they are not very well coordinated  which usually would not be because these layers are sort of independent of each other they talk only to their peers and go through their own protocol and give protection apart from these of course the other disadvantage is that you may redo some part of the protection unnecessarily you may be unnecessarily duplicating the work at various places so these are the disadvantages of having protection at multiple layers  refer slide time  51  59-52  34  what is the advantage of optical layer protection ? speed and efficiency limitation would be detection of all faults may not be possible ; protects traffic in units of light paths so this is another problem as i mentioned  in light path the granularity is very coarse it may be 2.5 gbps ; so you are really giving the protection at a level of granularity  which may be quite high as i just now mentioned ; it could lead to race conditions when optical and client layers both try to protect against the same failure  refer slide time  52  35-53  28  of course  on the optical layer you have one more dimension to play with  which is in the case of a wdm that means you have different wavelengths  so instead of 1 + 1 link  you can talk about 1 + 1 wavelength path selection you can sort of try to select two independent light paths and the signal is bridged on both protection and working fibers if you are doing 1 + 1 protection kind of thing ; the receiver chooses the better signal in case of a failure  the destination switches to the operational link that is operational light path ; there is revertive or non revertive switching ; that means  if the original link comes back  it may revert or it may not revert ; and no signaling is required  refer slide time  53  29-53  30  so that is the unidirectional light path i have just shown you some of the schemes which are used for protection and restoration and as i mentioned  the schemes may be partially deployed and some of the parts may be protected and some of the parts may not be protected and so on but the essential idea is the same ? that you build in some kind of redundancy and the redundancy may be in the form of entire fibers or the redundancy may be in the form of light paths or wavelengths it may be pre-computed and pre-reserved like 1 + 1 ; it may be pre-computed but not pre-reserved like in a shared one or it may be computed as and when the failure occurs ; that is  in the case of restoration so there are various approaches to it depending on how critical the problem is or how critical the application is  what is the cost and how much extra provisioning you can do  you can choose your own way of protection and restoration thank you preview of the next lecture lecture ? 13 multiple access good day so today we will talk about multiple access ok now what is multiple access  refer slide time  54  59-57  54  if you remember that we had seven layer in the so called osi stack the top on being application then we have presentation session transport network link and physical ok we had been mostly talking about the physical layer till now although for optical networks we sort of ventured into some of the hired layers but from this lecture onwards we want to concentrate on the link layer ok now what medium access does is it coordinates competing request request for what for medium that means that there is a medium which may be an object of contention meaning that i mean several nodes may want to use it and this medium access control protocol has to do with how to handle that so sharing of link and transport of data over the link that is an general the description of what the data link layer does so when we share a link there is a question of committing request and we have to have some way of reserving that and of course there is a also question of transport of data over a link link if you remember when we say a link i mean that two nodes which are connected the nodes may be or computers routers switches etc they are two networking nodes they are directly connected now the when i do like this it might mean cable copper cable or a fiber or it might mean a shared medium like the free space ok so there is a but there is some way of communicating directly between these two nodes that is what we mean by link that means that is just one hop in the network that is what we are talking about in the data link layer so there is a question of reliable transfer of data over these link and if this link like when you have a free space transmission with so many nodes in the network now so many people would like to transmit so there is a question of sharing this medium and there is a question of who would access it when and just as i said free space could be a shared medium similarly if you remember that if you have some kind of a bus if you remember our discussion about topology of networks when we have some kind of a bus from which the number of nodes are hanging and that bus may also be an object of contention so that bus is the medium through which communication is taking place and there is an there is some kind of competition or sharing between the of this shared medium between the nodes so we have to handle that that is the other thing so examples of contention based or aloha and slotted aloha  refer slide time  57  57-59  00  these refers to some protocols which we are used in satellite communication so we will discuss these and we talk about satellite communication we have csma it stands for carrier sense multiple access or csma cd which is carrier sense multiple access with collision detection there are other variance of these like carrier science multiple access with collision avoidance and things like that so these aloha slotted aloha for satellite csma csma cd or specific specifically csma cd is used by ethernet in many situations and then we have csma ca may be for cellular communication etc so these are contention based mac and round robin there are these are token based protocols and so two very common ones are token bus and token ring so actually we will discuss these in the next in this lecture as well as the next we will be discussing these computer networks prof sujoy ghosh dept of computer science & engineering iit kharagpur lecture  14 token-based mac  refer slide time  00  45  good day in the last lecture  we talked about various multiple access schemes and one of this set of schemes is token bus dqd etc we will see two other variants of it  namely  token ring and fddi  refer slide time  01  08-01  15  we are going to talk about token-based mac  refer slide time  01  15 ? 01  34  they are some kind of round robin macs that means the chance to transmit comes to each of the stations in a round robin fashion this can be done as i mentioned earlier through polling or token passing here we will be specifically talking about token passing  refer slide time  01  34 ? 02  07  the first system that we will talk about is the token ring as the name itself suggests  it has a ring topology a token ring mac works with a special pattern or token  which is 3 bytes long  called token  which moves from one computer to the next priority indicators are placed within the token we will see later how the priority indicators are used  refer slide time  02  07  02  42  data rate may be 14  16 or 100 mbps medium may be utp  stp or fiber signaling is usually differential manchester ; we mentioned this earlier differential manchester is how you represent your 0s and 1s by electrical signals or optical signals as the case may be ; and the maximum frame size would be 4550 bytes or right up to 18.2 kb  refer slide time  02  42 ? 03  11  in token ring  like a token bus  a token is passed around the ring  and within the token is an indicator that senses the ring as free or busy if the token is busy that means some frame is being communicated at that time  the token circles continuously around the ring are passing each station each station is required to examine the token  refer slide time  03  11 ? 03  38  if a station wishes to transmit data and the token is empty  it seizes or captures the ring by modifying the token to a start of user frame indicator  appending the data and control fields and sending the frame around the ring to the next station the next station will now get the token as well as the frame  which will pass on till we get  refer slide time  03  38 ? 05  41  to the node where the data is copied only if it is to be passed to the end user application attached to the node that means there is a destination address when the destination node sees that data  it knows that this is for him so he absorbs  that means  he copies it back he makes a copy of it and sends it to the application layer in that particular node through all the other layers ; we are not concerned about that at the moment but the token and the frame continue circulating in the ring till it comes back to the center when the token arrives back at the original site  the token is once again made free and placed onto the network you see in this scheme only one frame ? i mean if the ring busy at all then one frame ? is traveling along it it has left the source station  then it has been copied by the intermediate nodes on to the frame as well as the token with the busy indicator over there then it finally comes to the end station and at the destination station  it makes the copy of the data for its own use and keeps on circulating this frame and the token right up to it when it comes back to the original sender  the original sender will now strip all these data  make the token free  and put it on the ring now  some body else who ever wants to transmit next  will capture the token and send it in this fashion this shared medium  namely the ring  is shared by all these nodes attached to it  refer slide time  05  41 ? 06  05  when a station wants to transmit  it has to wait for the token  then it has to seizes it  and then it transmits the frame when the station seizes token and begins transmission  there is no token on the ring nobody else can transmit there is no contention or collision as such  because only the station that has got the token can transmit ; so all others do not transmit  refer slide time  06  05 ? 06  44  what is the expected performance of token passing ? first of all  it is fair because it is going in a round robin fashion so everybody will have his chance ; each computer is given in turn an opportunity to transmit even when the traffic is high however  even if only one computer needs to transmit a message  it has to wait till the time that it receives back the token until it receives the token  it can not start the transmission  so it has to wait again  long messages should not be allowed because otherwise one computer may hold the token for too long  refer slide time  06  44 ? 07  49  several tokens are there some variations of it use slotted rings  where several tokens or slots are used these may be more useful and make it more efficient because if it is a very long ring and only one frame is traveling down it  it is rather inefficient way of using the system so what we can do is that we may allow multiple frames  that means multiple slots  which are sort of distributed over the space for example  if the speed is 200 m/ ? s of the frame  the data rate is 10 mbps these ten bits will span over 200 m over the ring so a 2 km ring can hold 100 bits ; that is the kind of performance with a single frame  refer slide time  07  49 ? 08  42  let us look at how the priority works in the token ring ; because what we can do is that we can do differential priorities to the nodes in the network and this is how it works let us go through one example ; assume a token ring has five stations attached to a priority ring station a has priority access of 1 1 is  let us assume  the lowest priority ; stations b and d have priority of 2 ; and stations c and e have priorities of 3 so c and e have the highest priorities once again  assume that a had already seized the ring and is transmitting data frames the token has a bit set to indicate that the token is busy and that means because a has already put a frame in it  it is being sent from a  refer slide time  08  42 ? 09  36  station b receives the frame it has data to transmit let us say that all of them also transmit some data to station b  which receives the frame it has data to transmit but it can not transmit at the moment because the ring is busy but it places its priority of 2 in a reservation field within the token ; it puts 2 over there in that reservation field  and sends the token and the frame sent by a along to c it then passes the token to c station c also determines the ring is busy ; it has data to send  so it places 3 in the reservation field  thus displacing the 2  which was inserted by b ; 2 gets replaced by 3 in the reservation field  other thing remains as it is it is still a ? s frame  which is moving along  refer slide time  09  36   station c then passes the frame to d d must defer because  if you remember  we had the priority of 1 to a  2 to b and d  and 3 to c and e so it came from a to b  b put a reservation and its priority of 2  then c over wrote this with its priority of 3 now d sees that there is a priority 3 that is waiting and d has only has its priority of 2 ; so it has to defer it can not do anything so d must defer ; it can not place its priority of 2 into the field because the priority of 3 is already there consequently  it passes the frame to e  which examines the reservation field upon seeing the 3 in the field it does nothing because since its priority is also 3  e is also a priority of 3  so e can not do anything so e simply sends it along  refer slide time  10  39 ? 11  11  station a receives the frame back ; it makes the ring free by resetting the token and passing the token to b b is not allowed to use the token because the reservation field inside the token is equal to 3  one higher that the priority of b although b wants to transmit and the ring is free  b can not start really transmitting because somebody with a priority 3 is waiting  refer slide time  11  11 ? 12  07  c is allowed to seize the token because the priority field in the token says 3 and c has the priority of 3  which means that c is the first node with that level of priority  which has got the token so this sort of seizes the token ; it places the data on the ring and sends the transmission to d now d is allowed to place its priority of 2 although c is sending  c has already put its frame and d sees that naturally the reservation field is reset now d can place its priority of 2 into the reservation field it does so and passes the frame to e e also wants to send ; so e replaces d ? s priority of 2 with its priority of 3  and passes the frame to a  refer slide time  12  07 ? 12  25  a also wants to send again  but a must defer any reservation placement since its priority is 1 b must also forego any priority allocation since its priority is 2 c receives its transmission back ; it is required to make the ring free it does so and transmits the token to d  refer slide time  12  25 ? 12  42  d is not allowed to seize the ring  since its priority of 2 is less than the reserved priority  which has been put there by c this is the priority indicator of 3 ; so it passes the token to e e seizes the ring because its priority of 3 is equal to or greater than the reservation of 3 this is the way the priority ring works ? if you see  whoever put the reservation earlier at the same level  it come backs to him so he puts the frame out there  but if the higher priority nodes have finished reservation  transmission  etc  then the lower parity nodes can start transmitting and so on so you can set these priority levels in the token this is how not only you can have a pure simple round robin  where everybody has the same priority  but you can have priority based token ring also  refer slide time  13  28 ? 13  49  there is a variation of this dedicated token ring  which is called dedicated token ring there is a central hub ; there is a more centralized system  which acts like a switch and it ? s more like a full duplex  a point-to-point link and the concentrator acts as frame level repeater  and there is no token passing  refer slide time  13  49 ? 15  09  next we will take up another system called fddi this is still in use in some places where some specific applications are there  but then again fddi is also sort of going out because other new technology is taking its place fddi was originally conceived as a high-speed network and this network could be used in a lan  wan or backbone as high-speed data when it was conceived  at that time  100 mbps was considered very high speed ; of course technology has changed  but still it is instructive to look at these technologies first of all  we ? ll see how different mac schemes can work  and new mac schemes for new technology  etc are also coming up all the time we will  just as an instructive thing  will look into fddi in some detail  refer slide time  15  11 ? 16  04  so fddi was conceived as a high-speed backbone technology it has a dual ring topology as just like the sonet rings ; we talked about dual ring topologies in the optical networks by the way  this is based on fibers this is fiber distributed data interface that forms the acronym fddi it uses dual ring topology  using fiber optic cable used to transmit light pulses optical fiber channel operates at a rate of 100 mbps well  we can say 100 mbps only today  but at one point of time  it was the standard in 1980s  which was proposed to be very high speed it is frequently used in lans to connect buildings together  refer slide time  16  04 ? 16  27  so ring circumference can extend to 200 kms ; the distance between nodes can be up to 200 kms fddi network can host up to 1000 nodes on one optical fiber that is how it was conceived this optical fiber is not just continuous optical fiber this optical fiber goes from hub to hub  that is  from node to node  refer slide time  16  29 ? 17  54  this is an fddi topology ; we have two rings a is known as the primary ring  which is shown in black the primary ring is the one  which usually carries all the data  and then  there is a secondary ring  which is used for fault tolerance purpose as matter of fact  this is one reason fddi is still used in some places where the reliability of the network is of very high concern we can not allow it to remain down for any length of time fddi can quickly switch from the primary to the secondary ring this is a production kind of system as you can see  because there is one ring fully dedicated as a secondary ring  which is there in case of a fault either of a link or particular node  we can quickly have another ring in its place  refer slide time  17  54 ? 20  14  the fddi standard specification came up in the 1980s this has various parts  one is the media access control  mac part  which deals with how the medium is accessed  the frame format  token handling  addressing  and error recovery fddi has a somewhat more complex mac protocol because fddi allows both synchronous as well as asynchronous traffic if some traffic is synchronous  that means  if it is carrying some kind of voice or something  then you know that is 125 microsecond length ; it is very sacred and sacrosanct over there every 125 microseconds  some channel may have to send something  as well as we can have packets or data flowing in the network  may be with some kind of lower priority so this can handle a mixture of both synchronous and asynchronous traffic that is a peculiarity of fddi system  which makes its mac somewhat more complex than a plain vanilla token ring so we will see details of this mac later on the physical layer protocol defines the data encoding and decoding  how data is encoded and decoded we will see later the clocking requirements and framing under the physical layer  we will see medium characteristics of transmission medium  fiber optic link  power levels  bit error rates  optical components  connectors  etc that is also a part of the standard for the physical layer medium there is a standard for the station management  which defines station and ring configurations  initialization  scheduling  collection of statistics  fault isolation  and recovery from faults as i said  the recovery from faults was and still is a very strong point of fddi ? one reason fddi may be preferred for some applications  refer slide time  20  14 ? 20  36  so  as mentioned earlier  the topology of fddi network consists of two independent rings ? primary ring a is used for data transmission  while secondary ring b provides an alternative data path ; this has already been shown and secondary ring remains idle  unless primary ring fails  refer slide time  20  36 ? 22  37  optical fiber rings are counter rotating ; that means one is moving in one direction while the other is moving in the other direction two signal paths are provided  one in each direction why do you make the rings counter rotating ? well  we had seen this in our recovery lecture also ; the reason is that if there is a node failure what you can do is that suppose you are a station and there are two counter rotating rings passing through you that means in one  the signal will pass in this direction and in the other the signal will pass in this direction in optical fiber  this is quite fixed because you want to have proper transmitter on one side and the receiver on the other side so one ring is moving like this  the other ring is moving like this now what might happen is that suppose the next station has failed and this station understands that there is something wrong either with the link or with the next station so what it might do is that it might make a quick connection over here so that the ring coming in this direction may take this other path and still we can make one ring this ring will not have any fault tolerance ; there will be one ring by using part of the two rings a and b so we can get a recovery through that ; that is why we have two counter rotating rings with two signal paths provided  one in each direction a station is a computer  workstation  or node connected to fddi network there are some network nodes also ; we will talk about this or a station must be connected to both in order to use secondary ring as an alternate data path if it is connected to only one of them  it can not use the alternate path  refer slide time  22  37 ? 23  05  media is  as i said  1300 nanometer optical fibers  transmission method is base band ; that means  there is no modulation only the pulses in the raw form travel down the ring ; data rate is 100 mbps and topology is a physical ring of trees and a logical ring why is it a ring of trees where do the trees come from ? we will talk about that  refer slide time  23  05 ? 23  41  now let us talk about the type of network stations  which may be connected to an fddi ring one is a dual attached station  which is connected to both the rings that means  it is a station  which is connected to both the rings that is why it is called dual attached we have dual attached concentrator  dac  which is connected to both rings and provides connection for additional stations and concentrators it is actually the root of a tree this is where the tree comes from  refer slide time  23  41 ? 25  33  we have this picture of an fddi concentrator  so you can see that this is the main part of concentrator the two rings are there ; they are counter rotating ? this is the primary ring and this is the secondary ring so the primary ring is coming like this from a to b and secondary ring is going like this it has some additional ports from which other stations may hang and  actually  what might happen is that we may have a tree hanging from a concentrator we have a tree of nodes here ; so that is why this main fddi ring may be a ring of trees the way fddi is actually deployed is also interesting in the sense that you may have a large ring ; that is possible what is done is that we make a very small ring in the core of the system  like wherever your main server is we make a very small ring just within a room and what happens is that we have concentrators connected to this ring and from this concentrators  a tree spans out to all the other  may be near by buildings or whatever  so that all of them are connected to this fddi backbone  but the backbone has got two rings this backbone is fault tolerant so that is a good thing about fddi ; that is one way fddi may be deployed so we have a very small ring and tree is spanning out and going out of the building  may be to other building  and so on or alternatively  you can have a large ring also  refer slide time  25  33 ? 25  42  so we have this dual attached stations and dual attached concentrators ; concentrators could be the roots of trees  refer slide time  25  42 ? 26  15  dual attached stations and dual attached concentrators are more costly we have a cheaper variety you think that it is good enough which is a single attached station which is attached only to the primary ring we have single attached concentrators which is connected to only the primary ring through a tree  a double attached station or concentrator can reconfigure the dual ring as mentioned earlier into a single ring in the event of a failure  refer slide time  26  15 ? 27  03  what are the physical interfaces like ? as opposed to a basic token ring network  in which at any instant there is a single active ring monitor  which supplies the master clock for the ring  in fddi  this approach is not suitable because of the high data rates that is one thing ; and the other thing is that the ring could be very large so if the ring is quite large then having the central clock becomes difficult each interface has its own local clock and the outgoing data are transmitted using this clock  refer slide time  27  03 ? 27  43  all data to be transmitted are encoded  as i mentioned earlier  prior to transmission using a 4 of 5 group code  which means there are nearly 32 possibilities so  for 4 bits of data  we actually have 5 bits  which are going over there the additional capacity is used in some other way for control purpose ; that we will see later this means  for each 4 bits of data  a corresponding 5 bit code word or symbol is generated by the encoder some of these symbols or combinations are used for link control functions  refer slide time  27  43 ? 29  13  now let us go through the ring operation ? there are two aspects to it one aspect is similar to the token ring  which we have already discussed the sending station waits for a token ; sending station captures and strips token and then transmits frames ; sending station issues token at the end of transmission now this is one point where the fddi is different from a token ring in a token ring  if you remember  only when the transmitted frame with that busy ring etc  comes all the way back to the sender  the sender makes this token free and puts it back on the ring since fddi was perceived as a high-speed ring  what was proposed was that as soon as its transmission of its frame is over  it can put a new token on the ring multiple frames may be circulating in the ring at the same time bringing up the speed so sending station issues token at the end of transmission  destination station copies the transmitted frame and sets the a and c  which is the address recognized by the frame copied indicators that means it has already copied the frame like what we have in a token ring  refer slide time  29  13 ? 29  46  the sending station removes the data from the ring by stripping the sent and acknowledged frame  etc so it takes out the frame ; the first few bytes of the frame are not stripped ? this is for some technical reason  we need not go into the details here ? and continue to circulate on the ring as a fragment each repeating station strips 1 byte from the fragment and the transmitting station completely strips it so there are some fragments also apart from the frames ; some fragments are also moving around in the ring  refer slide time  29  46 ? 30  52  now we come to token passing scheme it uses token passing protocol to move data around ; the ring uses another protocol based on timers we will look at this protocol later on timing is very critical to token passing scheme  as it is designed for delay sensitive synchronous data as i mentioned earlier  the fddi ring carries a mixture of data it may carry lower priority packet data kind of thing  which we have been talking about  in the token ring it may also carry synchronous data  which is time sensitive and which has somewhat higher priority than this other one this is based on some timing protocol we will go into timing protocol now fddi allows for high data rates  where each ring interface has its own clock all outgoing data are transmitted using this clock  refer slide time  30  52 ? 31  15  a node will get packets within a specified amount of time we are discussing the timing part of it a node will get packets within a specified amount of time as a packet circles the ring with a token behind  each station retimes and regenerates the packets  refer slide time  31  15 ? 31  35  so this increases probability frame fragments  which will be propagated on the ring ? how fragments are eliminated early token release is required because of the high speed and extensive distance provided by fddi  refer slide time  31  35 ? 32  00  fddi rotation time  fddi uses time to ensure equal access to the ring ; measures rotation time by calculating distance of segments  processing time  and number of stations this is the time you expect a packet to move around the entire ring rotation time refers to how it takes a signal to propagate around the ring  refer slide time  32  00 ? 33  36  so rotation time is used to control the priority operation of fddi ring we have several timings  one is measured by the clock that times the period between the receipt of tokens called the token rotation time  that means  how long is it that the token takes to come around the ring the operation of mac layer is governed by a mac receiver and is calculated by target token rotation timer that means there is a target rotation time  which is prefixed and there is a trt  which is measured usually you would expect under the normal conditions  when the load is moderate  the token rotation time would be less than the ttrt when the node is moderately noted by comparing trt with ttrt  we can find out how loaded the system is if you have a synchronous link going through the synchronous traffic that is going through this fddi ring  the synchronous traffic will have to be given the first priority and the asynchronous traffic of some lower priority data traffic  will be put on the ring or will not be put on the ring  depending on how loaded it is and this is how it is calculated  refer slide time  33  36 ? 33  56  there is a pre-negotiated target time called ptt ptt is coordinated for the arrival of a transmission each node measures time it takes for the token to return to it ; that is the trt it compares time to a pre-negotiated target time ptt for its arrival  refer slide time  34  01 ? 34  36  a node is allowed to transmit as long as its full transmission stream does not exceed the ptt so there is a pre-negotiated target time  which is allowed  and the node is allowed to transmit as long as its full transmission stream does not exceed the ptt if the token comes back sooner than ptt threshold  it is deemed as a light network load if the token comes back later than ptt  it indicates the heavy traffic load low priority traffic must then be deferred until load on the network becomes lighter  refer slide time  34  36 ? 35  26  there is a token holding time  tht if you look at the last point tht is actually equal to ttrt minus trt it is used to calculate maximum length of time a station can hold the token to initiate asynchronous transmissions the point is that there is a target time and there is an actual measured time  by which the token has come back if the actual measured time is low  that means the network is lightly loaded  you can put some asynchronous traffic that is why tht is calculated it calculates the difference between the arrival of the token and the ttrt it keeps track of the amount of time a host can transmit this is the formula  and then you have the following rules  refer slide time  35  26 ? 36  21  if tht is less than zero that means traffic is heavy  the total rotation time is actually more than the expected time  which was expected earlier this means that all asynchronous traffic has to wait the synchronous traffic will go through so if the tht is less than zero  it is a heavily loaded station stations can only transmit synchronous traffic if tht is greater than zero stations can transmit both synchronous and asynchronous traffic during tht so it first sends the synchronous traffic and then sends the asynchronous traffic till tht falls to zero if tht is equal to zero  the host can not start any new packet tht increases and number of stations decreases  refer slide time  36  21 ? 39  59  the fddi frame format  fddi is a technology  which is not moving forward very much these days as the matter of fact  it may be slowly on its way out because we have other ways of achieving the main point of fddi  which is its fault tolerance the speed of fddi has become 100 mbps  which is rather not very fast as far as the backbone is concerned ; it is taken as a very low speed these days so fddi may be on its way out it is also expensive and the support to it is also dwindling the reason we are looking at how different issues are handled by a typical mac protocol is that this business about framing is common to all kinds of data link protocol so later on  when we talk about ethernet  which is the most common kind of network in the world today  we will see that it has some frame format and if you remember our first day ? s discussion  when we were talking about these different layers  we said that they are at the same level ? that means a network layer to network layer ; network layer in this node to network layer in this node ; similarly the transmission layer in this node to transmission layer in that node  etc ? and have some protocol running how do these protocols run ? these protocols run by adding some header and in some cases a trailer also to the main payload so whatever it gets from the upper layer is the payload to it for running its own protocol it adds some header ; that means  adds some information to the beginning of the frame and adds some information to the end of the frame to make a complete frame the corresponding layer in the other node strips this particular information  does whatever it has to do  because it is also running the same protocol so it knows what to do and then may be either it goes up or it goes down again to the next station and so on this is an example frame format of fddi fddi frame format has some preamble we will not going to the details of this because this is not very important any more  but we will just mention that such fields are common in many frames we have a start delimiter ; we have a frame control ; and we have a destination address this has to be there because otherwise the destination will not know that this particular packet is meant for him we have a source address field  so we have a da and then an sa field ; we have the data  frame check sequence for some error control by the way  error is not handled by fddi ; error allows other layers to handle the error if there is an error but we have to check the error ; so there is frame check sequence  end delimiter  and frame status  refer slide time  39  59 ? 40  30  fddi encodes all data prior to transmission  uses a 4 or 5 group code method  which was mentioned earlier the encoder generates a corresponding 5 bit word or symbol for every 4 bits transmitted  fddi creates a 5 bit code bits provide clocking for the signal itself the status of bit reflects a change of state of the light on the other side  refer slide time  40  30 ? 41  57  symbols are light ; taken with another symbol they form one byte so there are 16 data symbols issued with 5 bits you can have 32 different symbols ; out of it  16 data symbols are reserved for data this is for 0 to f so if you write your scheme of bytes in hex  that means in groups of 4 bits each  each of these 4 bits has got its corresponding code in the fddi symbol and then  we have 16 other symbols  which are left ; so 8 are used as control symbols and 8 as violation symbols the control symbols are called q  h  i  j  k  etc coding the symbols prevents the occurrence of 4 consecutive 0s in a row this is necessary to ensure each station ? s clock is in sync with other stations for the transition that takes place when you go from a 0 to 1  that transition ? s edge is used for synchronizing the clock this is the very common method of synchronization ; that is why we have the codes in such a manner  so that we do not have a long string of 0s because then the synchronization might drift  refer slide time  41  57 ? 42  16  token has the following fields  we have a preamble ; we have a start delimiter ; we have a frame control ; and we have an ending delimiter as i said  one of the main points of fddi is the  refer slide time  42  26 ? 44  14  fault tolerance that it provides there is a ring wrap i mentioned this earlier that in a dual attached concentrator  if it senses that on the other side the node has failed  it can make a connection between the primary and the secondary ring within itself  so that the ring  while coming like this  starts traveling like this and completes its round that is because if you have the node on the other side  the corresponding concentrator will also make a connection between the primary and the secondary ring the failed node is essentially isolated on both the sides there are connections within the concentrator  and instead of a single ring  you have two rings now the primary and secondary ring are fused together and then  suppose this was the primary ring coming  then it goes back to the secondary ring and then to the other concentrator on the other side and the connection is completed you have one ring ; that is why the physical diameter of an fddi ring is kept within 100 miles if there is a failure  the total ring diameter does not exceed 200 miles  which is the standard ring wrap technique is the technique that we mentioned earlier when we talked about protection and restoration ; the technique is used to manage failures when a station fails or a cable is damaged  dual ring is automatically wrapped two adjacent ports connecting to a broken link will be removed from the ring and both stations enter wrap state  refer slide time  44  14 ? 44  33  fddi concentrator switches to a wrap state and the ring is doubled back onto itself data continue to be transmitted on fddi single ring performance is not negatively impacted during wrap state so this is the good thing about fddi when you have very mission-critical situations  fddi is kept as a strength for very critical situations like  may be  stock exchange or may be some thing else  where even few seconds of network down time is not acceptable to anybody so there you could deploy this kind of technology with its inherent fault tolerance so this is the another picture of fddi ring wrap  refer slide time  45  13  45  33  as shown over here  you have one station 4  which has gone down so that 2 adjacent stations  namely  2 and 3 wrap around and we have a single ring now going around so this is clear  refer slide time  45  33 ? 47  40  we have discussed earlier how this is done we have optical bypass switches used for two or more failures to occur by the way  what would happen if more failures occur ? suppose there was a one single failure  one single node failure  and the two rings primary and secondary and the two adjacent concentrators were wrapped back and we had a single ring like this  what would happen if another node fails in-between ? what would happen is its adjacent concentrators once again wrap around but now  instead of only one single ring  which we had earlier in the case of a single failure  now with this double failure we may have two rings these two rings are not connected to each other so these two rings individually would still keep working there is a part of the protocol  which i have not covered it is that if there is a single token  which was on the other side  and now the token is lost ; there is no token there is a protocol for reclaiming and regenerating a token now what would happen is that  two individual rings will come into operation on the two sides  but they will not be able to do so the nodes  which are connecting to this sub-ring and the nodes  which are connected to the other sub-ring  will not be able to communicate with each other across  but within themselves  they will very well communicate as usual so rings are segmented back into two independent rings incapable of communicating with each other additional failures can cause further ring segmentation optical bypass switches can eliminate failed stations to prevent ring segmentation we have all seen how this is done ? actually this is all done with mirrors  refer slide time  47  45   so optical bypass switch has optional optical mirrors that pass light from ring directly to das station during normal operation das station experiences a power loss ; optical bypass switch will pass the light through itself it uses internal mirrors to maintain ring integrity  refer slide time  48  04 ? 48  54  the other technique of this protection  etc  which we had seen earlier is dual homing this dual homing is also used in an fddi context ; a router or a das ? das you remember is a dual attached station ? is connected to two concentrator ports on fddi concentrator one port provides a connection to active fiber link  while the other port is in hot standby mode actually there are two nodes  a and b ; usually the a node is in hot standby mode and b node is operating so the port is in hot standby or passive mode ; hot standby is constantly tested and will take over if the primary link fails  refer slide time  48  54 ? 49  08  a typical das configuration has a b port ; it is designated as active port ; and a port is configured as the hot standby when the primary link fails  passive link automatically activates and hot standby becomes operational so this is the same dual homing principle  which we had seen earlier when we were talking about recovery and protection with this  we come to an end of the discussion about token bus and token ring and fddi we have discussed the number of these token-based protocols  namely  token bus  dqdb  token ring  and fddi the fddi was quite good only thing was that fddi was also quite costly these technologies are actually going out in some sense if you remember  when we were talking about dqdb  we said it can handle 53 byte cells ; that came down to atm and atm is that sort of the technology that is still quite alive today we will have an extensive discussion about atm regarding the wan technology  two other technologies  which are once again on their way out  are x 25 and frame relay well  frame relay is still there in many parts ; x 25 is sort of going on but still we will just have a quick look at these then we have to consider these mac levels this is how the next set of lectures will go what will happen is that once we finish this  then we will talk about the data link layer and specifically about the mac sub-layer of the data link layer then we will have to talk about the llc  that is  the logical link control so we will discuss that and the other important functionality of this data link layer  which is the error and flow controls because whenever you have a transmission  somehow you have to assume that errors may occur depending on the medium and the technology  errors may be more or less frequent ; for example  in a fiber  the error may be very low  error probability may be very low when you are using wireless  the error probability is high but  anyway  you have to consider the possibility of some error and how errors are handled that means  we are talking about bit errors  which may come in due to noise and other things into the data in a particular link that is one thing and if there is a flow control to be done  that means  if there is a congestion or not because you are sending from one side whether the other side is receiving it or not  that you have to some how make out we will take up these things next thank you preview computer networks prof sujoy ghosh dept of computer science & engineering iit kharagpur lecture  15 data link protocols  refer slide time  52  17 ? 52  18   refer slide time  52  18 ? 52  20  good day so today we will start our discussion on data link layer as a matter of fact we have discussed a part of data link layer namely the mac sub layer  refer slide time  52  30 ? 53  16  we will see how that all fix in but to fit it into the broader picture if you remember when we were discussing the seven layer osi protocol starting from the application layer the bottom most layer was the physical layer so we have finished our discussion on physical layer and just above the physical layer we have the data link layer so we will look at the different components of data link layer and how they will be used different protocols etc so that is what we will do so our this main thing is data link protocols which are the protocols which are used in the data link layer  refer slide time  53  16 ? 54  03  now what are the main tasks of data link layer it transfers data from the network layer of one machine to the network layer of another machine so actually this is the part of the service it gives to the upper layer do you remember that above the data link layer we have the network layer so below the network layer we have the data link layer so the data link layer gives some service to the network layer and this service is the transfer of data from one network layer to another network layer so that is the service it gives it to the network layer and this in its turn uses the physical layer so it converts raw bit streams of the physical layer into groups of bits etc or frames  refer slide time  54  03 ? 55  07  so this is how we can look at it so this is one node and this is another node above this there may be other layers we are not concerned about this upper layers at the moment so this gets some data to be sent from the network layer and this data link layer sends it to the next data link layer remember once again that the network layer is concerned with transfer of data etc across the network that means it may take several such hubs but data link layer is just concerned with the single hub so this is how we simply the problem the problem of going multi hub so this multi hub part we leave it to the network layer for this single hub so multi hub will naturally constitute the number of such single hubs and data link layer would handle the transfer of data from one from one node to the next  refer slide time  55  08 ? 56  34  so what are the kinds of services types of services that the data link layer gives one is unacknowledged connectionless so no attempt to recover lost frame if some frame is lost due to noise error etc etc there is no attempt to recover this and because there is no acknowledgement from the other side it is a connectionless system suited for low error rate network or for fault tolerant applications such as voice what you mean that voice is a fault tolerant application we mean that even if some of the bits in a voice stream digitized voice stream that is even if some of bits drop obviously there will be some degradation on the other side if your are do not doing any kind of correction etc but to the human ear it may not be very perceptible for example i am talking even if there is a momentary glitch you will more or less make out what i am talking about so that is why in that sense it is more inherently fault tolerant so that is un acknowledgement unacknowledged connectionless service that is one kind of service acknowledged connectionless service this is another kind of service so each frame is acknowledged by the receiver so this is suited for unreliable channel so require this acknowledgement for the special reliability  refer slide time  56  36 ? 56  49  acknowledged connection oriented service ensures that all frames are received and each is received exactly once and these services are accomplished using as i said simplex not usual but half duplex or full duplex channels  refer slide time  56  49 ? 57  33  so this is some examples not very important sorry so is a reliable message stream it may be connection oriented service or it may connection less service and it may be a reliable message stream or reliable byte stream so reliable message stream sequence of page reliable byte stream they say remote login so they are coming byte by byte here it is coming page by page unreliable connection like digital voice unreliable datagram so these are but when you come to datagram this becomes connectionless service unreliable datagram acknowledged datagram request reply etc  refer slide time  57  32 ? 57  40  now let us look at just one thing that where does this all these data link layer exact exactly where does it exist physical medium we understand it is a cable or it is this electromagnetic field this free space etc or fiber so we can see it we can fell it but where does the data link layer resides so to say  refer slide time  58  00 ? 58  25  now frames could be fixed length like atm so atm cells are of fixed length so you know once you have synchronized you know that they are going to come with fifty three byte kind of regularity but frames could be variable length also in which case we use this byte count byte stuffing bit stuffing generic framing procedure manchester encoding etc computer networks prof sujoy ghosh dept of computer science and engineering i .i .t kharagpur lecturer name # 15 data link protocols  start time  00  45   slide time  00  53  00  54  good day today we will start our discussion on data link layer as a matter of fact  we have already discussed a part of the data link layer  namely  the mac sublink layer we will see how it all fits in to fit it into the broader picture  if you remember when we discussing the 7-layer osi protocol  starting from the application layer the bottom most layer was the physical layer just above the physical layer we have the data link layer we will see the different components of data link layer and how they are used  we will discuss different protocols  etc  slide time  01  33  01  38  these are protocols which are used in the data link layer  slide time  01  39  02  27  the main task of the data link layer is that it transfers data from the network layer of one machine to the network layer of another machine this is a part of the services it gives to the upper layer if you remember  above the data link layer  we have the network layer the data link layer gives a service to the network layer  and this service is the transfer of data from one network layer to the other  and this in turn uses the physical layer it converts the raw bit stream of the physical layer into groups of bits or frames  slide time  02  28  03  33  this is how we can look at it  this is one node and this is another node above this is there could be other layers ; we are not concerned with these at the moment this gets some data to be sent from the network layer and the data link layer sends it to the next data link layer remember that the network layer is concerned with transfer of data  etc  across the network that means it may take several such hops ; but data link layer is concerned with just a single hop this is how we simplify the problem of multi hop ; this we will leave to the network layer for the single hop so  multi-hop will constitute several such hops and data link layer will handle transfer of data from one hop to the next hop this is another way of looking at it  slide time  03  34  03  51  there is a virtual data path from layer three to layer three  but actually this goes through the data link layer and this is the actual data path  which goes through the physical layer and some physical transmission medium  slide time  03  52  06  06  now  why do we require any controls in the main data link ? these are the main functions of the data link layer actually  all the combinations are not used in all the situations  but these are the general categorizations of data link the frame synchronization  the beginning and end of a data block  that means  a frame  should be recognizable that means when you are sending number of bytes from one machine to other  they are formed into blocks at that time  the other machine should be able to recognize the beginning and end of the block so you have to organize these bytes into frames that is the first job of the data link layer second job of data link layer that it might or might not do is flow control the sender should not send frames at a rate faster than the receiver can receive and process them  because the sender may not know everything about the state of the receiver at that particular point of time if it goes on sending data  the receiver may be forced to drop some of the data in some cases  this is ignored but in some cases  it is relevant and the data link layer may do some floor control the third thing is error control  where any bit errors introduced by the transmission system should be corrected whenever you are sending something through a transmission medium there is always a chance of some error  and the data link layer has to take care of this error  slide time  06  24  08  00  addressing  on a multipoint link like lan the identity of sender and receiver must be specified in such a case  the identity of the receiver would be very important because in many such links  especially in broadcast links  what happens is that the data reaches everybody the receiving station must know whether or not one of these frames is meant for him the addressing of receiver is important for that reason for all the above points  we require some data link layer protocol to run between the two layers in order for this protocol to run  these two nodes need to have some kind of control or management information the control and management information will be transmitted on the same medium control and data flow on the same link the receiver must be able to distinguish control information from the data being transmitted we also require link management ? the procedures for the management of the initiation  maintenance and termination of a sustained data exchange  slide time  08  08  09  22  these are the different functions of the data link layer the link layer services are framing and link access it encapsulates datagram into frame  adding header or trailer what the header or trailer contains depends on the protocol that you are using on that link ; some do not have a trailer  some do not have header ; some have both header and trailer this is the part that is used for the protocol to run channel access is also there if it is a shared medium mac protocol is a part of it ; if it is a shared medium  the medium access control has to be used mac addresses are used in frame headers to identify source and destination ; it is different from another address we have over the entire network  called the ip address right now  we will be concentrating on mac addresses  slide time  09  23  10  58  link layer services offer reliable delivery between adjacent nodes if the medium is prone to noise or introduction to errors  the data link layer has to address the problem apart from this link  you may require resilience at a higher link because a particular node of the network link might fail so  whatever protocol you might have for the data link might not work  so the chain may break down this is for making individual links of the chain as good as possible this is one of its jobs ? reliable data delivery just as fiber may have low error bit  similarly  some links like wireless links have high error rates we have just discussed why it gives both link-level and end-end reliability  slide time  10  59  11  34  the flow control is pacing between the adjacent sending and receiving nodes they should always be in sync  whatever the sending station sends  the receiving station should be able to absorb that much for that  you may require some explicit controls sometimes we will look at floor control later on  in a later lecture the other service is error detection  which includes errors caused by signal attenuation and noise receiver detects presence of errors ; that is the error detection part once you detect that there has been some error  you may ask for some retransmission from the other side so that you may get the correct data  or you might be able to look at that faulty data and correct it locally the receiver identifies and corrects bit errors without resorting to retransmission all these would happen on the line  and the line could be simplex  half-duplex or full-duplex simplex is not very common  because simplex can go only in one direction  slide time  12  16 -12  46  in half-duplex nodes at both ends of link can transmit  but not at the same time  slide time  12  47  14  16  dll offers unacknowledged connectionless and acknowledged connectionless services in unacknowledged connectionless  there is no attempt to recover lost frame and there is no acknowledgement from the other side it is suited for low error rate networks or for fault tolerant applications such as voice by voice tolerant application  we mean that even if some of the bits in a digitized voice stream drop  there will be some degradation on the other side but to the human ear  it is imperceptible that is why it is fault-tolerant in acknowledged connectionless service  each frame is acknowledged by the receiver and it is suited for unreliable channels  where acknowledgement is required for special reliability  slide time  14  17  14  31  acknowledged connection-oriented service ensures that all frames are received and each is received exactly once and these services are accomplished using simplex not the usual  but half-duplex or full-duplex channels  slide time  14  32  14  36  these are some examples it is a reliable message stream it may be connection-oriented service or connectionless service it may be a reliable message stream  sequence of pages  or reliable byte stream  reliable login   in the latter it is coming byte by byte and in the former  it is page by page an example of unreliable connection is digitized voice ; unreliable datagram  electronic junk mail  is connectionless service  slide time  14  37  14  38  the data layer link exists in the network interface card if you have a pc that is connected to a network  it is probably connected through an ethernet card  or network interface card  nic  or something like that the card has a socket where the ethernet cable will be plugged in so  there is a network adaptor the adaptors implement most of these data link functions  so it is the adaptors that are communicating the datagram from a higher layer is made into a frame by the adaptor and it is then sent  following the link layer protocol  to the other node the adaptors communicating have two nodes  one sending node and one receiving node  slide time  14  39 -15  14   wrong slide ?  the link layer in adaptor is also called nic  examples of which are the ethernet card  pcmci card or the 802.11 card on the sending side  the adaptor encapsulates the datagram in a frame it adds error-checking bits  rdt  flow control  etc on the receiving side  it looks for errors  rdt  flow control  etc  extracts datagram and passes to the receiving node the adaptor is semi-autonomous and communicates directly with link and physical layers the adaptor has some hardware and some in-built software  slide time  15  15  16  48   wrong slide ?   slide time  16  49 -17  19   slide time  17  20 -17  45   slide time  17  59  18  42  the data link layer is divided into two parts one is the mac and the other is the llc so in any broadcast network  the stations must ensure that only one station transmits at a time on the shared communication channel that is the mac part of it the protocol that determines who can transmit on a broadcast channel is called medium access control  mac  protocol we have seen a number of mac protocols already  slide time  18  43  19  26  the data link layer is divided into two sublayers above the data link layer  you see two network layers and below it is the physical layer the data link layer itself is divided into two parts  the medium access control part  which is closer to the physical layer  and the logical link control the mac protocols are implemented in the mac sublayer  which is the lower sublayer of the data link layer the higher portion of the data link layer is often called logical link control or llc  slide time  19  27  20  20  this is the broad picture  we have been referring to some numbers like 802.1  2  3  4 etc so ieee 802 is a family of standards for lans  which define an llc and several mac sublayers so 802 encompass all these this 802.2 is the llc part and below the 802.2 there are various kinds of medium access controls there are 802.3  4  5  6 and then 10  11  12 etc  and now we have 15  16  etc above the data link layer  there is a higher layer and below that  there is the physical layer  slide time  20  21  21  05  802.1 gives you an overview ; 802.2 is the llc we will be talking about today 802.3 is the famous ethernet ; csma/cd is the kind of mac protocol that it uses 802.4 is the token bus  which we have already seen 802.5 is the token ring 802.6 is the distributed queue dual bus fddi is the fiber distributed data interface and there are others as new protocols come up  they keep adding to this list  slide time  21  06  21  53  llc  whatever it does  it requires some headers so when the packet is coming from the network layer  the llc header is added to the packet so it will reach the llc sublayer on the other side then it comes to the mac sublayer and mac sublayer will add its header and it may add some trailer also the mac  llc  and original packet may constitute one frame and it is pushed on to the physical layer in the network  slide time  22  01  22  18  the 802 lans offer the best effort data frame services error control and flow control are handled by llc llc runs on all the three 802 lans and hides the differences to the network layer  slide time  23  04  23  17  the different physical layer protocols are transparent to the network all that the data link network knows is that this network layer will provide a reliable service for sending the data from this node to the next llc adds its header to the network layer packet it contains sequence and acknowledgment numbers resulting structure goes into the payload of 802.x frame for transmission  slide time  23  18  23  46  llc operations are sometimes divided in this fashion type 1 operation supports un acknowledgement connectionless service type 2 operation supports connection mode service type 3 operation supports acknowledged connectionless service  slide time  23  47 ? 24  31  the llc has protocol data units or pdu  which carries user information the control field includes a 7-bit sequence number n  s   associated with this pdu it also includes a piggybacking acknowledgment sequence number n  r   unnumbered various protocol control pdus these five bit m fields indicates a what kind of pdu it is  slide time  24  32  24  52  there are some supervisory pdus used for flow and error control it includes an acknowledgment and sequence number and a 2-bit s field to distinguish three different pdus  receive ready  rr   receive not ready  rnr  and reject  rej    slide time  24  53  25  19  the type 1 operation supports the unacknowledged connectionless service the ui pdu is used to transfer user data there is not acknowledgement  flow control or error control the xid and test pdus support management functions associated with all the three types of operation  slide time  25  20  25  32  an llc entity may issue a command xid or test the receiving llc entity issues a corresponding xid or test in response  slide time  26  00  26  08  type 2 operations involve three phases  connection establishment  data transfer and connection termination  slide time  26  09  26  45  with type 3 operation  each pdu transmitted is acknowledged a new unnumbered pdu  the acknowledged connectionless  ac  information pdu  is defined user data are sent in ac command pdus and must be acknowledged using an ac response pdu  slide time  26  46  27  45  to guard against lost pdus a 1-bit sequence number is used the sender alternates the use of 0 and 1 in this 1 bit the receiver responds with an ac pdu with opposite number of the corresponding command only one pdu in each direction may be outstanding at any time  slide time  27  46  29  16  frame synchronization  two sides must be able to synchronize their movements this synchronization is of two types suppose you are sending data 1 byte at a time  or you are sending blocks  each block containing a number of bytes synchronization of frames is necessary for this when data are transferred from the transmitted to the receiver unless steps are taken to provide synchronization the receiver may start interpreting the data erroneously suppose you have taken the second byte as the first byte  you will never be able to know that it is not the first byte there are two common approaches  asynchronous transmission and synchronous transmission  slide time  29  17  30  45  in asynchronous transmission  data are transmitted one character at a time timing of synchronization must only be maintained within each character the receiver has the opportunity to resynchronize at the beginning of each new character if you use encoding  you can use the transition time for synchronization between the sending and receiving nodes  slide time  30  11  30  41  so when no character is being transmitted the line between transmitter and receiver is in idle state ; so there must be some start and some stop there is a start after which we can introduce some parity bits ? we will see later how parity bits are introduced ? and this is the stop  slide time  30  42  31  46  in synchronous transmission  a block of bits is transmitted in a steady stream without start and stop codes actually asynchronous transmission is not as efficient the block may be arbitrarily long to prevent timing drift between the transmitter and receiver  clock signal is embedded in the data signal  e.g manchester encoding   slide time  31  47  32  35  apart from this synchronization of clock for the bit  you require another level of synchronization  so as to allow the receiver to determine the beginning and end of a block of data every block begins with a preamble bit pattern  and generally ends with a postamble bit pattern the kind of preamble and postamble that are used is directly related to the kind of protocol that is used  slide time  32  36  33  55  there are many kinds of framing available you can observe that only the body is coming from the higher layer ; the rest of it is being added in this layer for example  decnet ? s ddcmp frame has syns  header  body and many other bits are there the atm cell has only the header  crc and the body ibms have a bisync frame  header  body and bits the arpanet ? s imp-imp frame has syn  header and body bits the iso ? s hdlc frame looks like this  header pattern  body and crc  and again some specific pattern  slide time  33  56  34  15  a typical synchronous frame format would have an 8-bit flag  which would be the preamble  control fields  data field and some more control fields and an 8-bit flag  post amble    slide time  34  16  34  42  for sizeable blocks of data  synchronous transmission is far more efficient than asynchronous mode asynchronous transmission requires 20 % or more of overhead the control information preamble and postamble in synchronous transmission are typically less than 100 bits the overhead is low here that is why the efficiency of synchronous transmission is very high so when you are sending large amount of data  you go for synchronous transmission  because it is efficient  slide time  34  54  35  34  framing translates the physical layer ? s raw bit stream into discrete units called frames the sender sends the message  which is transmitted in the form of frames n frames are on transit and they are going from the sender to the receiver now how can the receiver detect frame boundaries ? that is  how can the receiver recognize the start and end of a frame ? this is done by four methods  length count  bit stuffing  character or bit stuffing and pulse encoding we will look at some of these now  slide time  35  35  36  04  frames could be of fixed length  like atm when it is atm  you know that it is of 53-byte kind of regularity they could be of variable length also  in which case we use the byte count  byte stuffing  bit stuffing  generic framing procedure and manchester encoding atm is a kind of fixed length frame variable lengths are byte count  decnet   byte stuffing  sdlc   bit stuffing  hdlc   generic framing procedure  and manchester encoding  802.5    slide time  36  05  36  53  now in framing  we make the first field in the frame ? s header as the length of the frame that way the receiver knows how big the current frame is and can determine when the next frame ends from the above slide  we can see that frame 1 contains 5 characters  frame 2 contains 5 characters  frame 3 contains 8 characters and frame 4 contains 8 characters  slide time  36  54  37  55  here the disadvantage is that the receiver loses synchronization  when bits become garbled if the bits in the count become corrupted during transmission  the receiver will think that the frame contains fewer  or more  bits than it actually does  slide time  37  56  38  17  checksum will detect the incorrect frames ; the receiver will have difficulty resynchronizing to the start of a new frame this technique is not used anymore  since better techniques are available  slide time  38  18  39  04  one of the better techniques is known as bit stuffing use reserved bit patterns to indicate the start and end of a frame for instance  use the 4-bit sequence of 0111 to delimit consecutive frames a frame consists of everything between two delimiters so you have this one delimiter on one side  0111  and then the frame and then the 011 so as soon as you get 011  you know that the frame is starting and as soon as you get another 011  you know that the frame has ended so this way we can know the beginning or the end of the frame  slide time  39  05  41  53  the problem with this is as follows  what happens if the reserved delimiter happens to appear in the frame itself ? if we do not remove it from the data  the receiver will think that the incoming frame is actually two smaller frames suppose we have the 0111 as the delimiter and the delimiter may contain data that came from the user in any bit pattern you have to allow any bit pattern to the user it could be that a picture is being sent in several bits and the bit pattern may be arbitrary in that case  0111 may appear in the body of the data ; this is where the bit stuffing part comes we introduce a new set of pattern  say  0111  for each existing pattern so now  the solution is to use bit stuffing within the frame  after every occurrence of two consecutive 1s  insert a 0 for example  append a 0 bit after each pair of 1s in the data this prevents three consecutive 1s from ever appearing in the frame  slide time  41  54  43  25  similar to bit stuffing we may have byte stuffing for example  let us say a flag say some character is there so  say the flag  which is also a part of the regular header  just happens to appear in the body of the frame or body of the packet so what we do is that  we use this other character these are character introductions  it is called byte stuffing one byte is one character so we introduce the character  escape character  just before the flag  and what happens if escape itself appears in the body ? well  we put escape so if there are two escapes side by side we know that we have to interpret it as only one escape if there are two escapes in the original data packet  just by chance  then actually this will be center 4 escapes and just one after the other  and at the receiving side  for every 2 escapes  it will reduce it to one escape and know that this is the just a part of the data only at the end  we will get flag  etc  bytes if there is escape flag  we have escape escape escape flag escape escape and so on so this is known as byte stuffing  slide time  43  26  43  57  point to point protocol  slide time  43  58  44  40  we will now discuss point-to-point protocol there will be a flag field  address field  control field  protocol field  and payload field this payload is the one which is actually coming from the higher layers that means from the network layer  some of it will actually come from the user  from the application layer itself this is the payload so far as the data link layer is concerned ; it ends with checksum and then flag this is what the general things look like and we will come to discussing how they are used  slide time  44  41  46  09  in a point to point data link control  there is one sender  one receiver and one link  which is easier than broadcast link it has no media access control  no need for explicit mac addressing e.g dial-up link and isdn line the popular point to point dlc protocols are ppp  which is point to point protocol  and hdlc  which is high level data link control  slide time  46  16  49  13  in ppp design requirements are given in rfc 1551 rfc stands for request for comment and forms a very important part of networking ppp uses packet framing ; its requirements are encapsulation of network layer datagram in data link frame this carries network layer data of any network layer protocol at the same time it should have the ability to demultiplex upwards ppp uses bit transparency also  which means  it must carry any bit pattern in the data field  slide time  49  14  49  52  we only require error detection  but no correction at the receiving end the connection liveness  it should be able to detect  signal link failure to network layer network layer address negotiation means endpoint can learn/configure each other ? s network address  slide time  49  53  50  48  the ppp non-requirements are no error correction/recovery  no flow control  out of order delivery is acceptable ; and no need to support multipoint links ; e.g  polling error recovery  flow control and data ordering are all relegated to higher layers  slide time  50  49  52  36  the ppp data frame has flag  address  and control and protocol bits the flag is the delimiter the address does nothing the control also does nothing ; in the future possible multiple control fields the upper layer protocol is where frame is delivered the check is for detecting errors  slide time  52  37  52  58  in the data frame some info that is upper layer data being carried is required and the check is the cyclic redundancy check for error so info is the upper layer data so this is the main body or the payload which is being carried the check is for error detection  slide time  52  59  53  50  it uses byte stuffing the data transparency requirement data field must be allowed to include flag pattern < 01111110 >  now we can have the question  is the received < 01111110 > data or flag ? sender adds extra byte after each < 01111110 > data byte at the receiver side two 01111110 bytes in a row  discard first byte  continue data reception and single 01111110 is flag byte  slide time  53  51  54  18  so after ppp  instead of sending it will send first this b1 then b2 etc  and then instead of sending one of them 0 1110  it sends two of them and then b4 and b5 this is byte stuffing  which is used by ppp  slide time  54  19  54  38  there are a few control issues like before exchanging network layer data  data link peers must continue ppp link and learn/configure network  slide time  54  39  55  12  the first thing is the link may be dead then the carrier is detected so it will try to establish the link for that  they will require some authentication  which means the two sides  configurations  etc must agree if it fails to establish  then it goes back to dead if it gets successful authentication  then the network is open and then there is some transmission of data and then finally it will terminate so for all these  there is a data exchange  slide time  55  13  55  31  configure request  configure acknowledgement and configure not acknowledgement -that means your configured thing is not acknowledged some of the options are not accepted and some of the options are not negotiable so this way  the two sides communicate and establish the link we need not go into the details this is not really necessary this is a very simple protocol just use byte stuffing and use some data  some error detection and the framing this is a very simple  but very widely used protocol in the next lecture  we will see how the error control and error detection can be done by the data link layer thank you  slide time  56  02  56  07   slide time  56  08  56  11  error control  slide time  56  35  56  46   slide time  56  47  57  03  when data is transmitted over a cable or a channel  there is always a chance that some of the bits will be changed or corrupted due to noise signal distortion or attenuation for example  suppose you have a wireless channel and suddenly there is a burst of noise what will happen is that  some of the data will get garbled similarly the data may become very attenuated it may be due to some loose contact somewhere or something the one that was sent was not received that way or may be it was received as a one zero or something so whenever you are sending some data or something  there is some communication going on some transmission over some transmission line you always have to assume that  a data may not reach the other side in a perfect condition so that is why crc is preferred in many data link protocols  slide time  57  47  56  48  crc is cyclic redundancy code  slide time  57  58  58  05  in cyclic redundancy code  essentially the data is regarded as being one very long binary number after all  what you are sending is a string of ones and zeros so you can take a few of them and just look at it as a binary number although the original intention of the user place holder digits are added onto the end and it is divided by a generator polynomial using modulo 2 divisions the remainder at the end of this division is the crc computer networks prof dr sujoy ghosh department of computer science and engineering iit kharagpur lecture -16 error control good day in the last lecture  we have seen some functionalities of the data link layer namely framing etc and we have been talking off and on about the error control error control means error detection correction  etc we will be talking about error detection correction in this lecture we will be talking about error control now  refer slide time  01  14  03  35  now data errors  when data is transmitted over a cable or a channel there is always a chance that some of the bits will be changed or corrupted due to noise  signal distortion or attenuation etc so many things may happen ; for example  suppose you have a wireless channel and suddenly there is a burst of noise  so some of the data will get garbled similarly the data may have become very attenuated due to some loose contact somewhere or something and the one that was sent was not received or maybe it was received as a 0 or something so  whenever you are sending some data or something  there is some communication going on over some transmission line  you always have to assume that data may not reach the other side in a perfect condition and error control has to deal with how to handle that so if errors do occur then some of the transmitted bits will either change from 0 to 1 or from 1 to 0 now what do you mean by error ? some bits were transmitted from 1 and were changed to 0 or from 0 they was changed to 1 so this is the only kind of error that may occur and if you knew where the position of that error is  we can correct it because the correct one will be the reverse of the faulty one so if it is 0  then the correct one is 1 and if it is 1 then the correct one is 0 the whole trick is to find out whether any errors or any change has occurred and if such a change has occurred  where it has occurred and how to handle it there may be a lot of noise and a lot of data may get corrupted in this fashion so we will see how or what we can do about this this data error will also depend on the kind of transmission medium we are using so that is always there  refer slide time  03  37  04  20  so  random errors change bits unpredictably each bit transmitted has a probability of being changed these errors are often caused by thermal noise ; because this thermal noise is something very general and is always present in any kind of these things there is higher thermal noise or there may be low level of thermal noise but this thermal noise is always present so these cause some random errors there are some burst errors or a change in a number of bits in succession they are often caused by faults in electrical equipment or by interference on some neighboring things so  electrical interference is a very major cause of such burst errors  refer slide time  04  21  05  17  so  we take transmission errors as inevitable  resulting in the change of one or more bits in a transmitted frame the rate of error may be high or low  but there will always be some error ; that is what we assume let us just see what it means  if there is a finite probability of error for a particular bit let us just have a look at some notations let pb be the probability of a single bit error called bit error rate so the probability of a single bit error is the bit error rate or b e r as they are sometimes called p1 is probability that a frame arrives with no bit errors  that means there is no error and p2 is the probability that a frame arrives with one or more undetected bit errors so  p1 is no error and p2 is one or more errors  refer slide time  05  17  05  55  p3 is a probability that a frame arrives with one or more detected bit errors  but no undetected bit errors sometimes we can detect which bits are in error and sometime we can not so  we will come to this later let f be the number of bits in a frame  if no error detection scheme is used suppose we are not detecting it specifically so p3 = 0 ; we can not detect which bits are in error so p1 =  1  pb  f  refer slide time  05  55  06  01  if you remember  pb is a bit error rate since pb is a bit error rate probability of a single bit error  p1 would be 1 pb for one particular bit  refer slide time  06  02  06  04  in one particular bit  the probability of error is pb so  the probability for that particular bit has no error  that is  1 pb and we are assuming that these errors are sort of independent  which may not always be the case with burst errors but for thermal noise  we assume that there are bit errors we will see that the noise will introduce an error or some other error will creep in let us say they are independent so if there are f bits in a frame  the probability that a frame arrives with no error is  1  pb  f  refer slide time  06  47  06  58  and p2 arrives with one or more errors   1 p1   p2 = 1  p1 so  clearly longer frame and higher pb leads to lower p1 let us try to look at some numbers  refer slide time  06  59  07  11  so  this is an illustrative example a defined specification for isdn connections ? you remember isdn means integrated service data network which is the digital service given through the telephone lines so that is the isdn so in isdn connections  bit error rate on a 64-kbps channel should be less than 10-6 on at least 90 % of the observed 1-minute intervals suppose that looks quite low  rate of error is 1 in 1016 that means only in a million bits 1 one bit may come in error suppose we want that at most one frame with an undetected bit error should occur per day on a continuously used 64-kbps channel  with a frame length of 1000 bits so we want not more than one frame should come with undetected bit error so we are using this for a whole day on the 64-kbps channel and the length of the frame is 1000 bits  refer slide time  08  59  09  34  so number of frames transmitted per day =  64k/1000  ? 60 ? 60 ? 24 = 5.5 ? 106 so if one of them is desired frame error rate  p2 = 1/  5.5 ? 106  = 0.18 ? 10-6  but  if we assume pb = 10-6  then p1 =  0.999999  1000 = 0.999 so if p1 = 0.999  p2 = 10-3  which is about three orders of magnitude too large to meet our requirements that means it is thousand times more  although one bit in a million looks a fairly good error rate but we find that at the end of the day  we may have a thousand frames which are in error well  it does not work out that way that by multiplying with 1000  we will get so many frames in error but the point is that whatever probability we require for a faulty frame we have got a much higher probability than we were prepared we were prepared for say one faulty data frame per day but that is not the case at all so this necessitates the use of error detection ; that means  we have to do something to bring down this error rate the other point is that sometimes one will not have control over the environment or the transmission line directly it is quite difficult  because if you are having a wireless transmission now  some noise will certainly come from some other source may be somebody starting a car will also give out some kind of electrical noise and somebody starting a machine somewhere will give some kind of electrical noise  some mixer or grinder running in the house may give some kind of error all kinds of sources are there  and you do not have any control over it so the point is that  whatever the error that is coming  you have to do something at your end to get better error rates so  we want to detect such errors and if possible we want to correct them so this is what we are going to discuss now  refer slide time  11  11  12  49  error detection  one general principle of getting greater reliability or less error  as i said is always redundancy that means you put in some kind of redundancy in the system in order to get better reliability we have seen this when we were talking about the reliability of optical networks but in this case  the redundancy comes in the form of extra bits that we introduce into the data  which means that whatever data is being sent  we also send in some extra bits specifically for the purpose of error detection and correction so edc are the error detection and correction bits which are actually redundant that means they are not original part of the data  and they are extra bits  which have been introduced suppose d = data protected by error checking ; it may include header fields so the data which we are protecting may or may not include it ; it depends on the protocol it may just be on the payload and the header  all together  we may like to detect the error error detection is never 100 % reliable but the protocol may miss some errors but usually we can bring down the level of errors to a very low figure the larger edc fields yield better detection if you put larger redundancy you have better error detection and correction  refer slide time  12  50  13  42  so you have the datagram coming we add some extra bits edc from there we send it to the bit error prone link  which arrives at d ? and edc ?  now d may be the same as in d ? and has no error and it itself may have corrupted or both may have been corrupted but any way we run some algorithm or some method for finding out whether these are alright and if we think they are alright we say yes otherwise  we say that an error has been detected sometimes  the errors may be such that although we say everything is ok  it may not be so ; in that case  we say that the error has gone undetected  refer slide time  13  42  14  25  now for this error detection and correction  one concept  which is used  is the so-called hamming distance between the two bit patterns and then there are hamming codes also we will not go in to the details of hamming codes here  but let me just tell you what is hamming distance suppose we have two code words  like it has been shown here this one code word is 10101110 and the other one is 0100110  these are the code words by hamming distance  what we mean is that we have to see in how many bit positions the two code words are different  refer slide time  14  35  16  07  so  in order to find that  we simply xor the two so  if we xor these  we get this if you can go through 0 1 is 1  1 0 is 1 and so on so you get 1 1 1 0 0 0 1 1 now we count the number of 1s in this xor  which is 5 so we say that their hamming distance is 5 please note that if the two corresponding bits are different in the two code words 0 and 1  1 and 0  then we get a 1 in this xor if they are the same like 1 1 or 0 0  we get 0 this h hamming distance is the number of positions where the two code words differ if you have a set of code words  say between these two hamming distance is 4  between these two  the hamming distance is 3  between these two also the hamming distance is 3 let us see this differs in one position  two positions  these are the same in the third position this is again the same this differs in three positions similarly  this other h is equal to 3 for other peers in this set as a whole  the minimum hamming distance between two code words is actually 3 h of the code word is actually 3 we take the minimum of all these h values and this comes out to be 3 so we say that for this set of code words  the hamming distance is 3 now  if the hamming distance is 3  we have an interesting situation let us say these code words are what we are sending to the other side ; now if there is a single error ; that means if a single bit has flipped from 1  it has become 0 so what has happened is that this code word will move to another code word so this will appear as another code word in the receiving end ; and the one which is received and the one which was sent ? the hamming distance between the two will be only 1  because only one bit has flipped so  only one position  what was 0 has become a 1 there  or may be what was 1 here has become 0 there so it has changed 1 in one position assuming that there is a single bit error  the hamming distance between the transmitted and the received code word will be 1 now if the system is known  then this is the set of code words which is being used on both the sides ; and first of all you will immediately know that for this particular set of code words h = 3 was there that means  say  this is the set of keywords that i showed you ; those are the only code words  which had been sent so the hamming distance was 3 so for whichever value  this new transmuted or new changed code that was received is not going to be a valid code  because this is only at a hamming distance of 1 from the transmitted code so this is not going to be a member of the set so immediately  we will detect that there has been some error and not only that  if you assume that there is most likelihood that we have got only one error then it is the one which is at a hamming distance of 1 from this transmitted code it will be at a hamming distance of 1 or 2 from the code  whereas it is at a hamming distance of 1 from the code word which was already sent and if you know this and if you assume that there can be only one error then you know that that is the code word so you can not only detect that there has been an error  you can also correct the error by going to the nearest code word from which the hamming distance is minimum  namely  the one which was transmitted so this is the general principle so we will see practically how this is done there is a coding scheme  for which it goes as hamming code we will not discuss that  but there are other schemes  but all of them use this idea of a hamming distance  refer slide time  19  08  19  50  the simplest error detection scheme is the parity check it appends a parity bit to the end of a block of data what is a parity bit ? it is an extra bit  which is sort of added to some data there are two kinds of parity  odd parity and even parity odd number of bit errors can be detected why odd number of bit errors can be detected  i will explain that if an even number of bits is in inverted due to error an undetected error occurs the technique is not foolproof  as noise impulses are often long enough to destroy more than one bit  particularly at high data rates  refer slide time  19  08  23  09  but let us first of all see what a parity bit is suppose 1 0 1 1 0 1 1 1 was the original bit pattern in even parity  what we do is that we make the number of 1 ; we add a bit which is 0 or 1  depending on whether the number of 1s in the original pattern is even or odd if it is even parity  we want to make the number of 1s even  so the number of 1s were originally even over here so in 1 0 1 1 0 1 1 1  we have six 1s so we already have an even number of 1s here  in the added parity bit we just give it a value 0  whereas in the other one  that is  1 1 0 0 0 0 0 1  we have three 1s so this was odd  so the added parity bit was also made 1  so that overall the number of 1s in this data plus parity bit taken together is always even that is  the number of 1s is always even in even parity if everything is fine ; and the number of 1s is always odd similarly  the number of 1s is always odd in odd parity now if you just think about it a bit  if you are using even parity then all the valid code words have even number of 1s in them so what is the number of position and what is the minimum number of positions in which they have to differ ? these two different code words ? well  the minimum number is 2 ; that means  the hamming distance of this set of code words will be minimum 2 and if the hamming distance is 2 and if there is a single error  what is going to come is that we are going to get a code word in the receiving end  which has got an odd number of 1s and  if it has got an odd number of 1s  we immediately know that this could not be a valid code word so we know that there has been some error  although we can not say where that error is  or what the original intended transmitted code is  because if you think of two code words which are at a distance of 2 and the transmitted one ? let us say we had even parity  that is  even number of 1s ; their hamming distance minimum was 2 let us take the worst case  the minimum is 2 and then the transmitted one of this code word was this where one of the bits flipped  we get something in the middle  which is at the hamming distance of 1 from the two valid code words so we know that this has been transmitted as invalid in that sense  this is not a valid code word so an error has occurred but i do not know whether something from here came here or the original transmitted code was here and it came here  because we do not know where the error has occurred so in this particular case  we can nearly detect an error we can not correct it at the receiving end so the case of parity is a very simple kind of scheme  refer slide time  from 23  09 to 24  22  so once again  if you go back to the earlier slide  i mentioned that odd number of bit errors can be detected now as i said if there is a single bit error  it will be detected because now we have got an odd number of points well  if there are odd number of errors  that means if there are one error or three errors or five errors in that bit stream  then again  we will get an odd number of 1s on the receiving end so we can detect that there has been an error we do not know the number of errors  but in any case  we can detect it but if there are only two errors  then it will again become an even number of ones on other side which may be a valid code word so we will not know whether there has been any error or not so if there are an even number of errors  this parity check will go undetected by this single parity bit error checking running the parity check is very easy  refer slide time  24  22  24  37  you just run them through some xors and invert it if you want it in odd parity or if you want an even parity  you can get it and this is very simple  refer slide time  24  22  24  59  now parity testing  the receiving device can work out if a bit has been corrupted in a character by counting the number of 1s in the character and parity bit if even parity bit is being used but there are an odd number of 1s then an error must have occurred similarly  if odd parity is being used but there is an even number of 1s then an error must have occurred  refer slide time  24  59  25  37  one drawback with parity testing errors is that if two errors occur in the same character  they will not be detected this is because if there were an even number of 1s originally  if two bits are changed  then there will still be an even number of 1s because either two 1s will become 0 so the even number of 1s remain even or two 0s will become 1  also even number of 0s remain even or 1 1 has become 0 and 1 0 has become 1 so the number of 1s does not change and they still remain even so it remains undetected  refer slide time  25  37  26  12  there is some improvement over this and we can see how to make it more efficient this is an extension of parity bit  which is called block parity testing this is how it works suppose we have a long stream of 1s and 0s  1s and 0s  1 0 1 1  etc so what we do is  we break them up into blocks of bits let us say 8 bits ; we take the first 8 bits as the first pattern then the next 8 bits are the next pattern  and so on  refer slide time  26  12  27  11  so what we do is  for each group of 8 bits a parity can be added in this case let us say even parity  so the first 8 bits were 1 0 1 0 1 1 1 0 so for even parity if there are five 1s here so i have to add a 1  there are three 1s here  i have to add 1  there are four 1s here ; so i add a 0 in this way for each block of 8 bits  we add a parity bit then for every n blocks the parity is calculated as a new character  in this case 8 ? 8   so this is how it goes what we do is  if you look at this as some kind of a matrix so  we calculate the parity on this side we calculate the parity along the column also so five 1s  so we make it a 1 over here for this parity  refer slide time  27  12  27  40  then for every n blocks the parity is calculated as a new character i have mentioned that i have got parity on this side so for this block of  say  64 characters  i have got say 8 + 8 + 1 = 16 + 1 = 17 parity bits  refer slide time  27  42  28  43  now if there is a single error  which has occurred  what is going to happen is that where ever it may have occurred in that row the parity test will fail similarly in the column also the parity test will fail ; and since one column and one row intercept exactly at one cell  we know that that is the bit which has become corrupted so now if an error occurs  we will know which character and which column it has occurred in not only can we detect the error but we can also correct a single bit error by simply changing it so since we know that this is the bit which is in error  i can simply flip it at the receiving end itself without any referring back to the transmitter and we know that we have got the correct one we can not only detect errors but we can also correct single errors in block parity testing  refer slide time  28  43  29  46  so this is just a better diagram for this ; we have got this system this is using odd parity i mean there is no reason to use the same kind of parity in both the cases you can use odd parity for the transverse parity bits and you can use even parity for this and calculate this so if there is some error we can compute it if there are more than one error then you may get into some kind of trouble because you will not know which bit is in error if there are two rows and two columns which show parity error then you will not know which row and which column will match together to get that particular bit  which has been corrupted  refer slide time  29  45  30  09  so we not only have error detecting codes but we have some error correcting codes also by comparing error detection and error correcting codes  error correcting codes require more number of bits because we want to correct it so we require more number of bits  which is a problem  refer slide time  30  09  30  43  in error correcting codes  rather than just detecting an error  sometimes it is useful to be able to correct an error as well for example  cds use error correcting codes to ensure high-quality sound reproduction even if the cd is slightly damaged so we are talking about some music cd so even if a few bits are in error still it will use error correcting code to handle that we have already seen that we can correct a single error in a block parity check there are other techniques that can correct more number of errors  refer slide time  30  44  32  06  so what happens is that your one scheme could be error detection so suppose some alphabet a was sent  this was a valid code word  and there was a noisy channel so some error got introduced so  1 0 1 1 0 1 became 1 0 0 1 0 1 that means the third one from the left has become a 0 so this is an invalid code word we know that the original one was using odd parity kind of thing  so even number and odd number of 1s were there but in the even number there was even parity and hence even number of 1s were there but i have got an odd number of 1s  i do not know where the error is  so what we do is  we request for retransmission ; that could be one approach but if i can correct a single error on the other side  then i do not need to ask for retransmission overall my efficiency may improve but of course for error correction  i have to send more bits so that is the one area where i am sort of losing something so it all depends on how you do your engineering and how you come to your particular point of say optimal amount of error correction  refer slide time  32  06 ? 32  41  so another way of checking for errors was to use a checksum this checksum is also used in other fields so this has been borrowed not just from communication from other fields for accounting also  sometimes checksum is used this is just used for this sum just for control purpose so in some arbitrary order you sum it and then with all the data you also check with the sum  refer slide time  32  41 ? 33  06  this is a number calculated from the data and sent along with the data if any errors occur during transmission then checksum for the received data will differ from the transmitted checksum of course  the data may arrive alright  but the checksum may become faulty but even then in that case the checksum and the data will not match so checksum can only detect errors ; it will not be possible to correct it  refer slide time  33  06 ? 33  46  a simple checksum can be calculated by adding all the data together for example if the data is 121  17  29 and 47  then the checksum  add all the data  will be 214 we could transmit 121  17  29  47 and 214 we know that the last number is the checksum  which should be the sum of all the numbers which have been sent a checksum is usually restricted to a certain number of bits  typically 16 bits if the checksum is longer than this  then only the lower 16 bits will be transmitted but checksum is not very efficient and not widely used  refer slide time  33  46 ? 34  38  one scheme  which is widely used  is the so-called cyclic redundancy code what is a cyclic redundancy code ? a cyclic redundancy code  crc  is a more sophisticated type of checksum if a crc is used  it is extremely unlikely that any errors will go undetected a lot of different types of errors are caught by the crc although the technique may sound a little complicated  in practice calculating a crc is easy and can be implemented in hardware using linear shift registers which is a very simple kind of circuit ; through that  we can compute it very easily and quite fast so  the crc is preferred in many data link protocols  refer slide time  34  38  34  49  so what is crc ? let us just look at the details of it  refer slide time  34  49 ? 35  21  essentially the data is regarded as being one very long binary number after all what you are sending is a string of 1s and 0s  and you can take a few of them and just look at it as a binary number if you are adding the header also  then it got even more mixed up i mean it was not to be interpreted as a number but for crc purpose  we interpret it as a binary number  refer slide time  35  21 ? 35  44  so to this we add some place holder digits at the end and it is divided by a generator polynomial using modulo 2 division so for modulo 2 division  you do the same kind of division only thing is that if they match then we get a 0  if they do not match we get 1 the remainder at the end of this division is the crc so let us just look at this  refer slide time  35  44 ? 36  48  so given a k bit block of bits  the transmitter generates an n bit sequence  known as a frame check sequence  fcs   so that the resulting frame  consisting of k + n bits  is exactly divisible by some predetermined number the receiver divides the incoming frame by that number and if there is no remainder  assumes there was no error you look at it as a number ; find the crc ; add it to the end ; so what will happen is that you will get a longer number this longer number is supposed to be divisible by the polynomial  which the receiver side knows so the receiver side will do its own division and if the division is ok  then it will assume that there is no error if it is not ok  then obviously there is some error  refer slide time  36  48 ? 37  02  so we have d data bits and r  crc bits so how are the crc bits computed ? d * 2r xor r so this is done by some division so we will see how it is done  refer slide time  37  02 ? 38  52  this is the formula  d ? 2r/g this is the generated polynomial why it is a polynomial ? that we will see actually the bit pattern is represented as a polynomial ; ultimately  this so-called polynomial will be a binary number like this suppose the g is 1 0 0 1 and what you are trying to send is 1 0 1 0 1 1 so this is what we are trying to send ; and this is the generated polynomial what we are going to do is that we are going to add some extra bits so this d ? 2r means  adding so many 0s at the end so in this case  say  r = 3 ; so we have added three 0s to the end and i do a division as it is done so 1 0 0 1 only thing is we do a modulo 2 kind of operation so 1 1 becomes 0 1 0 as it gives 1  you got a 1 0 1 and so you got a 0 and so on so in this way the division goes on till we sort of exhaust this and we get 0 1 1 as the remainder and what will happen is that if you add this 0 1 1 over here  instead of sending 1 0 1 0 1 1  what we do is  we add 1 0 1 any way  if you add it what will happen is that this will become exactly divisible modulo 2 the modulo 2 divisions will come out exactly  refer slide time  38  53 ? 40  22  so the crc process can be very easily implemented in hardware using  lfsr  linear feedback shift register the lfsr divides a message polynomial by a suitably chosen divisor polynomial ; the remainder constitutes the fcs  which is added to the data bits commonly used divisor polynomials are  crc 16 = x16 + x 15 + x 2 + 1 so actually it is a 16 bit binary number as i said the g is called as generator polynomial so g will have one in the sixteenth position  one in the fifteen position  one in the second position  and one in the first  that is  0th position  which means that there are going to be four 1s in this g and all the rest are going to be 0 so how it is generated polynomial ? so we are not going into that  how this particular polynomial  why was this particular polynomial chosen rather then some other polynomial but as we have seen  they cover a lot of different types of errors previously if you remember  in our parity bit we were just getting odd numbers of errors if there are an odd number of errors then we can detect it here and we can detect a lot of different cases of error so it is extremely unlikely that if the crc is alright  then there has been some error so there are different protocols and different systems with different generator polynomial  refer slide time  40  57 ? 41  02  so crc ccitt = x16 + x12 + x5 + 1 and so on  refer slide time  41  03 ? 41  35  from the above slide we can see crc 32 and crc 8 so crc 8 means this is an 8-bit thing this is the eighth position  second position  first position  and zeroth position are all 1s  rest are 0s so this is used in atm crc 10  this may also be used ; and crc 12 so these are the different crcs actually not all polynomials will give you the same kind of error coverage ; that is known  and people have found out some properties which are good properties to have in a generator polynomial and then people have found out some good polynomials which will cover a lot of errors so hdlc uses some kind of errors  refer slide time  41  59 ? 42  09  so csma/cd  fddi  atm ? they use crc 32 and so on i am just showing you  but you need not remember any of these  refer slide time  41  59 ? 42  25  now  we come to a slightly higher level  data link protocols we are still talking about errors and error control  but the point is that  we have been talking about this parity and crc that is error control at a lower levels we say a lower level because it is a small amount of error we can possibly handle it using such error detection or error correction kind of schemes but what might happen is  because of a very vast noise or something it may garble the data so badly  that it is entirely unrecognizable on the other side even if you have an error correction scheme  because none of the error correction and error detection schemes are 100 % infallible so there is still a possibility that there will be some undetected errors and then there will be some data which becomes so bad that there is no question of any error detection or correction we require some higher-level schemes also in addition to whatever we have talked about this parity crc etc so we will now see higher layer data link protocols  refer slide time  43  34 ? 44  07  once again  data link protocols could be of different types ; for example  unrestricted simplex protocol  this does not do much as we will see ; stop and wait protocol ; stop and wait arq for a noisy channel means that arq stands for acknowledgement request that means an acknowledgement is expected one bit sliding window protocol  this is similar to stop and wait  sliding window with go back n arq  sliding window with selective reject arq  and so on  refer slide time  44  07 ? 44  57 the first is unrestricted simplex protocol well  it simply sends  it does not do any kind of error control  and so this is the simplest situation we have a sender to fetch a packet from a network layer  construct a frame ; and send the frame to the physical layer so the sender is just going on sending without bothering about what is happening on the receiver end so if things are alright  the receiver waits for an event  receives a frame from physical layer and passes the packet to network layer the faulty things  which have gone in  may be it is the responsibility of higher layer systems to take care of that but the higher layer application does not bother  if a few bits are bad say in the case of a voice channel  refer slide time  44  58 ? 45  02   refer slide time  45  03 ? 45  04   refer slide time  45  05 ? 45  46  when data is sent as a sequence of frames  two types of errors can occur  one is lost frame  the frame has been lost entirely and the frame fails to arrive at the receiver this may be due to a noise burst destroying the frame beyond recognition it may have a recognizable frame arriving at the receiver but some bits are in error a frame may be damaged or a frame may be entirely lost see sender and the receiver the sender is sending a number of frames one  two  to frame n frame one is going first so the point is that some of the frames in between may get lost all together we have to make the worst case assumptions  refer slide time  45  58 ? 46  11  error control is concerned with insuring that all frames are eventually delivered  possibly in order  to a destination so  how ? three items required are acknowledgment  timer and sequence number  refer slide time  46  12 ? 46  57  acknowledgment ? what do we do with acknowledgment ? typically reliable delivery is achieved using the ? acknowledgments with retransmission ? paradigm  whereby the receiver returns a special acknowledgment  ack  frame to the sender indicating the correct receipt of a frame ; that means the receiver  after receiving the same will send an acknowledgment in some systems  the receiver also returns a negative acknowledgment for incorrectly received frame so this is a hint to the sender  so that it can retransmit a frame right away without waiting for a timer to expire we will come to this timer to expire the point is that there is a two way communication the sender is sending the frames  and the receiver is sending the acknowledgments if it gets a damaged frame  then it will send a negative acknowledgment of course  if it does not get any frame  then it will not know whether anything was sent at all in that case  it may not send any acknowledgment or negative acknowledgment anything at all  refer slide time  47  20 ? 48  05  the situation is something like this  suppose 0 was sent by the sender and it arrived the receiver sent an acknowledgment 0 then a 1 was sent suppose i am just taking this bit by bit  just to make it simpler suppose 1 was sent it came with some error  we do not know about what kind of error it is so the frame number 0 was acknowledged  frame number 1 was received  but it was damaged  so a negative acknowledgment was sent that means  frame number 1 was not rightly received  so frame number 1 is going to be retransmitted by the sender this is the argument  refer slide time  47  20 ? 48  50  the other thing we require is a timer one problem simple acknowledgment  negative acknowledgment schemes fail to address is recovering from a frame that is totally lost  and as a result  fails to solicit an acknowledgment or a negative acknowledgment what happens if an acknowledgment or negative acknowledgment becomes lost ? retransmission timers are used to resend frames that do not produce an acknowledgement when sending a frame  schedule a timer to expire at some time after the acknowledgment should have been returned if the timer goes off  retransmit the frame  refer slide time  48  09 ? 50  51  so this is the scheme  you see a frame which was sent was lost so the receiver of course did not know anything what happens is that as soon as the frame was sent  at the same time a clock was started in the sender ? s end i have to assume that the system has transmission time  and this is the time it might require for the receiver to process it and send an acknowledgment then the acknowledgment will take some time to reach the sender so  all that is taken into the account with some amount of time thrown in  and that is set in the timer so if the timer goes out that means  if there is a time out  now the sender knows that the frame must have been lost  otherwise an acknowledgment would have come so he sends the frame again the other thing that might happen is that suppose the frame was sent the 0 th frame was sent it was received and then an acknowledgment was sent  then the acknowledgment was lost he would not know whether reached at all or the acknowledgement was lost so after a time out  he will send this frame again so this is a case where the frame has been duplicated depending on what kind of protocol we are using the receiver may or may not understand that this frame is actually a duplicate of this maybe two such exactly similar frames were supposed to come one after the other because it is after all coming from some application  which is absolutely unknown to the data link layer so the frame may get duplicated but then there are some protocols which take care of that where if the receiving side will know that this is actually a duplicated frame we will come to that protocol later on  refer slide time  50  51 ? 51  39  and the third technique that we use is the so-called sequence number so retransmission introduces the possibility of duplicate frames to suppress duplicates  add sequence number to each frame  so that a receiver can distinguish between new frames and old copies so that if the frames are numbered sequentially like say 0  1  2 etc as i was showing you the case where the receiver gets two frames which have the same number 0  it knows that acknowledgment must have got lost or something like that happened the sender sends the same frame twice  so he will discard just one of them  refer slide time  51  40 ? 52  01  so collectively  the mechanisms stated are referred to as automatic repeat request  arq   the objective is to turn an unreliable data link into a reliable one three versions of arq have been standardized  stop and wait arq  go back n arq  and selective reject arq  refer slide time  52  02 ? 52  39  so we have the stop and wait arq  which is based on the stop and wait flow control technique the source station transmits a single frame and then waits for an acknowledgment to arrive no other data frames can be sent until the destination stations reply arrives at the source station so it waits for the acknowledgment ; if the acknowledgment does not come it will resend after a automatic repeat request so it will automatically repeat the frame  refer slide time  52  40 ? 53  39  so this is the scheme  we have the sender which fetches a packet from network layer  construct a frame  send the frame to physical layer  wait for an event so if it gets an acknowledgment then it is fine then it is going to send a second frame if it does not get an acknowledgment it will send the same frame again so until it gets an acknowledgment or the timer runs out  the frame which was already sent that has to be stored locally in some buffer in whichever system is handling this data link control and the receiver side also waits for an event  receive a frame from the physical layer  pass a packet to the network layer  send an acknowledgment to the physical layer so this is the stop and wait protocol this is a very simple protocol unfortunately  this is not very efficient as we will see that later  refer slide time  53  30 ? 53  35  and so we will continue our discussion on this error control and then we will move on to flow control in the next lecture so this is a simple kind of protocol but this has got efficiency problem  in the sense that this is not very efficient so we will continue this discussion in the next lecture thank you preview of next lecture lecture # 17 stop and wait protocol good day  so in the last lecture we were discussing about stop and wait protocol .we have seen what it is it is really a simple kind of protocol which is used both for error control as well as for flow control in some cases but since this is a simple protocol we will look at its performance now  refer slide time  54  34 ? 54  38  so we will first finish our discussion on this stop and wait protocol  refer slide time  54  39 -55  21  and this we have already seen  so each sender station sends one packet which are ack ? ed if it is comes with some error it may send a negative acknowledgement  it may not arrive at all  in that case the sender will time out in either case that means  it is getting a negative acknowledgement or whether it is getting a time out it will retransmit that frame retransmit whichever frame was just transmitted earlier and the point to note is that there is only one frame  which is in transit in the channel at any point of time whether it is the frame or the acknowledgment  now we have discussed some of the major techniques which are used in the data link layer  so what we will do now is that we will look at just one more protocol this is somewhat general version that we have discussed ppp that is the point to point protocol which is used for point to point communication but there could be a point to multi point communication also for this we have this high level data link control  this is the name of the protocol so this is the name of the protocol or hdlc in short i mean this is not so high level any longer this is not considered  so high level any longer but even then this is an important protocol so there are some variations of this  which are used in various places so we will just look at some generic the way how this hdlc is important  refer slide time  56  32  56  59  now this is an important data link protocol this hdlc or some variant say this is widely used  it also is the basis for many other important data link control protocols so we suggest three types of stations one could be primary station this is responsible for the operation of the link by the way you do not have to remember all these because when you are trying to use it or design it for some particular situation you can always look up the reference and see what exactly the different frames are what are their formats etc  i am trying to give you a flavor of the kind of information about which a typical protocol would need to exchange so with this example we come to the end of this general data link control  but still we have seen some examples of data link control  for example we have seen some examples of mac like with token bus  token ring  etc we will see other examples of mac as we take up other kinds of networks similarly we have seen some kind of error and data control by the way the similar approach is used in some other higher layers also we will talk about it when we come to it and we will talk about more specific and more widely used systems in the next class onwards so in the next class what we will do is  we will look at another type of communication and how mac is done on that in satellite communication .so that will be the next topic thank you computer networks prof.sujoy ghosh lecturer name # 19 ethernet ? csma/cd  refer slide time  00  41  good day today  we will talk about ethernet this is possibly the most ubiquitous lan technology today as a matter of fact  when computer network developed  there were a number of competing lan technologies but today ethernet has come to dominate lan almost totally  excepting for the newly emerging world spot also  which we will discuss later not only lan  nowadays people are talking about ethernet in the man  i.e  metropolitan area network also ethernet as you understand is very important so we will talk about ethernet  refer slide time  01  37  01  59  it is a dominating data link layer technology and the multiple access scheme of ethernet is csma/cd we will talk about ethernet and csma/cd ; this will be our first lecture on this we will continue on this topic in the next lecture also  refer slide time  02  00  02  54  what is the broad outline of the ethernet ? first of all  it was conceived as a broadcast network  so single communication channel that is shared by all the machines on the network this would be the kind of medium we will have we have a shared medium where everybody broadcasts it is supposedly one of the common broadcasts in the early days  one of the common physical organizations of ethernet where some machines were connected to a coaxial cable this is a lan technology unlike the satellite technology that we have talked about ? remember that in satellite technology  which is also a shared medium  we of send data and then detect collision this is further advancement the multiple access technique of ethernet is just some refinement over that but this is essential in a lan environment  meaning it is for a small geographical area we have packets ; that means packets are sent over this  we will see later on how it frames them so short messages sent by any machine are received by all others since this is a broadcast network  a message which is sent by any machine is received by all networks and so naturally you have to give the destination address there are various fields in the ethernet header and we will look at that later on one of them has to be the destination address so that we understand because otherwise the recipients will not know for whom this frame is meant  refer slide time  04  05  04  57  since it is a shared medium  all these machines are supposed to be in the so-called same collision domain ; because if two machines are sending simultaneously  their packets will collide suppose you have the sender over here and sender has a packet to send  it puts it on this common bus the packet travels both ways and then it is received by all the recipients all of them copy the frame into their nic they would compare the destination address with their own address  if it is not for them  they will simply ignore it if it is meant for this node  it will absorb it and then send it to the higher layer  refer slide time  04  58  05  58  all machines receive the packets but only one would process it ; i.e the mode of operation is broadcasting it is also possible to address a packet to a subset of machines ; this is called multicasting this mode of operation is called multicasting  meaning we have two ends of the spectrum  one is a point-to-point communication  one sender and one receiver on the other end of spectrum is a broadcast where one sender and everybody else is a receiver somewhere in between is a multicast ; meaning there is one sender and several receivers in order that several receivers can receive it  we have to do something with the address so we have to give a special kind of address ; that is also possible it is possible to multicast since it is possible to broadcast  refer slide time  05  59  07  22  just to remind you about our discussion on satellite communication  if you remember  the satellite communication used a mac protocol called aloha there were two versions of aloha and one was the pure aloha  whereby if anybody has any data to send he simply sends it if there is a collision  he would back off and maybe send it again that is a pure aloha scheme and we saw that this is the form of s = ge-2g where s is the throughput  that means how much you are actually able to communicate successfully  and g is the number of attempts per packet time this is the s versus gee of pure aloha  which gives about 18 % of efficiency at the maximum slotted aloha is where you can send only from the beginning of a slot time ; that has considerably better performance then it comes to about 37 %  the formula is s = ge ? s refer slide time  07  23  09  39  ethernet is something similar that means we broadcast and then we detect collision  so it should be the same as some kind of aloha the only thing is that since this is a local area network  a small network  what we can do is that we can sense the carrier ; that means we can sense whether somebody is sending if somebody is sending  we refrain from sending anything ; so that is called carrier sensing we discussed this earlier that it is not possible to do carrier sensing in satellites because the space delay is so high  whatever you are listening to now must have happened may be 250 milliseconds earlier ; that is a long time back but that is not the case in a small lan the timeframes are much smaller  so you can actually listen to the medium and find out whether somebody is actually broadcasting something at that particular point of time in that case  even if you have something to send  you do not do so that reduces the collision considerably and that naturally leads to an improvement in the efficiency so this stream is called carrier sense multiple access and we find that even if you are doing carrier sensing  there can be some collisions although there will be reduced number of collisions compared to pure aloha  slotted aloha we have to detect the collision and this cd part the full mac protocol that is used by ethernet is the csma cd ; this is the dynamic channel allocation technology or the random access mac for this  used in old ethernet nowadays we have moved to fast ethernet  where we have reduced collision and switched ethernet  which we will discuss these in the next lecture  refer slide time  09  40 ? 09  55  so we have carrier sense multiple access we improve the performance of our simple network greatly if we introduce carrier sensing ; with carrier sensing each hosts listens to the data being transmitted over the cable  refer slide time  09  56 ? 10  25  a host will only transmit its own frames when it can not hear any data being transmitted by the other hosts when a frame finishes an inter frame gap of about 9.6 ? s is allowed to pass before another host starts transmitting its frame so he listens to somebody sending and then he naturally waits and then after that frame is over  he gives a gap of about 9.6 ? s and then starts transmitting  refer slide time  10  27 ? 13  03  collisions can still occur mainly because of the propagation delay propagation delay means two nodes may not hear each other ? s transmission as before  if there is a collision  the entire packet transmission time is wasted ; and naturally the distance and propagation delay has a strong role to play in the collision probability let us look at this suppose this node b starts transmission at time t0 naturally  the transmission goes both towards a as well as towards c and d so there is a cone like this ? if you plot it against time and distance ? over which b ? s transmission is going what happens is that c was listening and at this particular point of time  t0 or even later than that  c did not have any carrier to sense  because b ? s transmission  although it had started in terms of absolute time  had still not reached c so it will reach c only at this particular point of time during this period  the transmission from b will reach d at a much later time  let us say t2 or something if d starts its transmission t1  what will happen is that somewhere in-between they are going to collide ; and these garbled bits will now start propagating on both sides  which is shown in this hashed figure what happens is that  naturally b ? s transmission is lost and d ? s transmission is also lost so there will be a finite probability of collision and this probability will depend on the time it takes for the frame to reach all the nodes because if it had reached some other node  that particular node would not start transmitting ; but it takes a finite amount of time  and within that finite amount of time  if somebody else starts transmitting  we have a collision so we can still have collision ; that is why csma is not enough ; we have to do cd also  refer slide time  13  04 ? 14  53  so csma  as we mentioned  means listen before transmit if a channel is sensed busy  defer transmission ; and persistent csma means retry immediately when channel becomes idle ? this may cause instability this is called persistent csma that means retry immediately when channel becomes idle ; because what might happen is that during the time when the frame is being sent ? that may be a considerable amount of time ? more than one node may become ready to transmit if more than one node is ready to transmit  naturally all of them will pounce on it after giving a 9.6 ? s gap and start transmitting  and naturally they are going to collide if they collide they know that is bad  so they allow that collision to subside and then they start again by this time  quite a lot of time has elapsed somebody else may become ready and somebody else may again start persisting ; so this may grow to some kind of instability being totally persistent is not very good  as we will see the performance of each of this ; but that is persistent csma we call a strategy as pure persistent ; that means  we retry in the next immediate available time with the probability of p  which means  with the probability of 1  p  we do not persist that means  we defer still more  refer slide time  14  54 ? 15  34  there is a non-persistent csma ; that is  somebody is ready to send something ; finds that it is busy then he will retry only after the random interval he generates some random numbers and decides by himself to wait for this random amount of time collisions may still exist  since two stations may sense the channel idle at the same time or within a vulnerable window  which is equal to the round-trip delay in case of collision  the entire packet transmission time is wasted ; so we have pure aloha this is the group of protocols  we have pure aloha  then we have slotted aloha  persistent csma  p persistent csma  non-persistent csma ; and here is how they behave  refer slide time  15  53  17  54  we have already seen these two curves  pure aloha and slotted aloha they are used in satellite communication because we can not do area sensing over there because of the significant space delay if you do carrier sensing and if it is persistent  the performance improves somewhat ; so it may go slightly above 50 % and then comes down you can have different values of p  remember p is the probability that the node will try immediately when it senses that the channel is available ; that probability will be 0.5 at probability 0.5  it will not try at all at 0.5  persistent csma is good  0.1 persistent csma is even better ; that means what it will do is with 0.1 probability it will try and with 0.9 probability it will differ if it is non-persistent  this is the 0.01 persistent csma and non-persistent csma non-persistent means it will always go back if you draw the throughput versus load curve  this is the kind of curve you get but the exact throughput will depend on how many nodes are there and what their distances are  etc these are somewhat idealized figures but you get something like this as you can see  with non-persistent or very low persistent csma  we get very high throughput even when the load is going up so when the load is going up  it is not falling down steeply like aloha or slotted aloha this is the channel utilization by the various mac protocols  refer slide time  17  55 ? 18  08  so csma/cd is carrier sensing  deferral as in csma ; collision is detected within a short time ; colliding transmissions are aborted  reducing channel wastage  refer slide time  18  09 ? 18  39  collision detection is easy in wired lan ; it measures signal strengths and compares transmitted and received signals this is how you detect a collision it is somewhat more complicated in wireless lans we will discuss wireless lans later on as we move on  but the receiver is usually shut off while transmitting this is a problem with the wireless lans  where collision detection is difficult we go for some other kind of scheme over there  which is called collision avoidance  we will discuss it later  refer slide time  18  54 ? 19  49  as i mentioned  ethernet is the dominant lan technology  and since this is dominant  people who followed the ethernet line had the great advantage of having a huge market that really drove down the cost and today ethernet is cheap ethernet network interface card costs in the order of some $ 20 or something of that order for a 100 mbps card  which is quite fast  it is very cheap it is the first widely used lan technology ; it is simpler and cheaper than token lans and atm ? so that is a great advantage and it kept up with speed rates of 10,100  or 1000 mbps ethernet started with 10 mbps  then went on to 100 mbps  which is a standard today people are talking about 1000 mbps or 1 giga bit ethernet  which is also making inroads into the backbones of lans etc maybe in a couple of years ? time  it will go into the desktop also  if it has not already reached some desktop so ethernet is a very widely used technology this is  refer slide time  20  26 ? 20  54  a diagram to show you how the original ethernet looks you have a cable  which would be terminated on two sides ; it would be tapped and then a transceiver will tap into it  to connect it there will be an interface cable from the transceiver to the interface of the controller this is basically the nic  and this is how it will be connected to various machines  which should be tapped into the cable at various points of time  so this is the so-called ethernet  refer slide time  20  55 ? 21  34  now  we go into the details of how exactly this is done we have discussed the basic technology already ethernet uses a bus topology ; it assumes a bus topology  carrier sense multiple access in csma/cd  each station has equal access to the network but it can broadcast only when the network is idle before transmitting  a station   1  listens to the network to sense if another workstation is transmitting  which is carrier sense if the network is still idle after a certain period   2  the station will transmit  refer slide time 21  35 ? 21  42  it is possible that two stations will listen and sense an idle network at the same time each will then transmit a message  which will collide  refer slide time 21  43 ? 22  05  while transmitting  a station must perform collision detection to detect if its message was destroyed if a collision is detected  the detecting station broadcasts a collision or jam signal to alert other stations that a collision has occurred each transmission station then waits a random amount of time ranging from 10 to 90 ? s before attempting the transmission again  refer slide time  22  06  22  36  so this is the same algorithm step by step ; adapter gets datagram from the network layer and creates a frame that means it adds a header to create a frame if the adapter senses that the channel is idle  it starts to transmit the frame ; if it senses that the channel is busy  it waits until the channel is idle and then transmits if the adapter transmits the entire frame without detecting another transmission  the adapter is done with the frame if the adapter  refer slide time  22  39 ? 25  50  detects another transmission while transmitting  it aborts the transmission and sends a jam signal this is an interesting point ? it needs to detect collision only while it is transmitting after the transmission is over  there is no detection within that frame transmission time ; you can forget about collision that means just some time after that  you may still detect the collision that collision would be presumed to be due to another station  not your frame ? because if you detect a collision after sending a frame  you have to understand whether it was your frame which collided or your frame went through and somebody nearby started transmitting and they collided so the idea is that while you are transmitting  that time only should be enough for any collision  any inadvertent collision to happen ; we will come back to this point so if there is a collision  it aborts ; after aborting  the adapter enters an exponential back-off algorithm what is an exponential back-off algorithm ? what might happen is that the frame sent might have collided and then it might have backed off for sometime ; it may have tried again and it may have collided again ; maybe the network is busy what is the remedy if the network is very busy ? obviously if the network is very busy  what is going to happen is that more and more people will try to send ; they will fail and then they will try again this may bring down the overall throughput of the system to a large degree so what is done is that if the network is busy  everybody tries to make the network less loaded  which means that they wait for longer before they try to send it what they do is that they generate this random number over an exponentially increasing period so that the probability of a higher random number becomes more and more if the network is more loaded  which means that you are backing off for a larger amount of time that is exponential back-off  so after the mth collision  the adapter chooses a k at random from 0,1,2-1 if m is 10  it chooses a random number between 0 to 1023 the adapter waits k = 512 bit times and then returns to step 2  which means  suppose k is 100  it would be 100 ? 512 bit times it waits 512 bit times and tries again  refer slide time  25  51  26  36  so jam signal makes sure that all other transmitters are aware of the collision we send a jam when it detects a collision and backs off we calculate the amount it backs off as follows  let us say bit time is 0.1 ? s for 10 mbps ethernet for k = 1023 if you remember 512 into 0.1  512 bit time should be about 51.2 ? s and 51.2 ? s into 1023 will be approximately 50 msec  i.e it waits for 50 msec  if k has to come out as 1023  refer slide time  26  37  28  16  the idea of this exponential back off is to adapt retransmission attempts to estimated current load if it is heavy  the random wait will be longer once again  we do this because if the load is heavy at some particular point of time  then people in general should refrain from sending so that the load comes down if the load is kept high and everybody starts to transmit  there will be even more collision and even less throughput than what you would achieve by a number of people backing off this backing off is done exponentially  so first collision  choose k from 01  and delay is k ? 512 bit transmission time  which means that with 50 % probability  we try to transmit immediately  and with 50 % probability  we would back off for this k ? 512  i.e  51.2 ? s before listening and trying to send again after the second collision  we choose k from 0123 the aim is increasing ; the number of collisions is increasing after 10 collisions  it is not allowed to increase more than that this range of k becomes fixed and you always choose from this 0 to 1023 this is the exponential back-off algorithm ; for heavier load presumably a node will choose a larger k and wait for longer  reducing the load on the system and increasing the throughput this csma/cd system can be in  refer slide time  28  23 ? 28  40  one of the three states there may be contention  there maybe successful transmission  or it may be idle there may be contention slots or frames or idle period  refer slide time  28  41 ? 29  50  ieee 802.3 defines this ethernet protocol if you remember 802.2 was llc and 802.3 was for csma/cd and 802.45 etc  like token bus token ring etc there are a couple of variants of ethernet  one is ieee 802.3 and the other is dixie ethernet we will maybe mention it later on  but they are more or less the same  excepting for minor differences 802.3 is the more dominant one these days ; besides  this is the standard 802.3 is the number of the standard and it describes the format of the frames and the type of encoding used for transmitting frames it also describes what the frame format is and what kind of encoding is used for transmitting the frame the minimum  refer slide time  29  59 ? 31  01  length of frames can be varied from network to network this is important because  depending on the size of the network  the frames must be of a suitable minimum length remember that a node has to detect collision only during the transmission time if transmission is over and there has been no collision detected  it assumes that its own frame has reached whatever destination it was supposed to reach after that  if there is a collision  it is supposed to be between two other nodes because once there is a collision only the sender would know whether his own frame has collided because you can not really decipher the address field of the collided frame the collided frames are gone  they are garbled the standard also makes some suggestions about the type of cabling that should be used for csma/cd  bus lans  etc  refer slide time  31  02 ? 32  41  this minimum time may vary from system to system ; that means  network to network this is how it is calculated first of all  let ? s see how the minimum time would come suppose this is the shared bus we put two nodes at the two extreme ends  the packet starts over here at time t = 0  it almost reached b at time  t ? ?   suppose this propagation time of the packet  from one end to the other  is t  at  t ? ?   it has almost reached b at that point of time b starts transmitting because while b has been finding that  the bus has been very quiet ; there is no signal on it b can start transmitting and it starts sending there is a collision at one end of the medium the collision bursts  starts traveling back and the jam signal is sent that starts travelling back  it again takes time t to reach a the total time is 2 t  the collision detection can take as long as 2 t the point is that your transmission time has to be greater than this 2 t there are a few other issues ; we will discuss them later  refer slide time  32  42 ? 35  19  this is what we were discussing  minimum frame length to ensure that no node may completely receive a frame before the transmitting node has finished sending it ethernet defines a minimum frame size  i.e no frame may have less than 46 bytes of payload remember payload is the packet  which the data link layer receives from the upper layer what happens if the packet is much smaller ? the application itself is such that you have to send maybe 1 character or 2 characters ; what happens to it ? ethernet does not allow less than 46 bytes  so you have to pad it up ; we will come to that later the minimum frame size is related to the distance which the network spans  the type of media being used ? because of the time it takes for the signal to travel ? and the number of repeaters which the signal may have to pass through to reach the furthest part of the lan repeater if you remember is something  which enhances the signal as a signal travels down the transmission line  it tends to get weaker and weaker because of attenuation at some particular point of time the signal may have to be amplified a repeater does just that  it takes some incoming signal and amplifies it  maybe some wave shipping or something there may be a number of repeaters each of these repeaters might introduce some delay because the repeater will not go through instantaneously there will be some delay in this repeater and if there are a number of repeaters  this delay would get added remember what we are trying to find out when the packet being sent from one end of the network  reaches the other end and almost at the other end  there is a collision and that collision comes back what is this total time ? during this whole time  this packet must be transmitting because it will detect the collision only during the packet transmission time the number of repeaters also is important as are the type of media and distance to the furthest part of the lan together these define a value known as the ethernet slot time  corresponding to 512 bit times at 10 mbps  refer slide time  35  20 ? 35  56  the longest time between starting to transmit a frame and receiving the first bit of a jam sequence is twice the propagation delay from one end of the cable to the other this means that a frame must have enough bits to last twice the propagation delay the 802.3 csma/cd bus lan transmits data at the standard rate of r = 10 mbps this was the earlier standard of 10 mbps the speed of signal propagation is about v = 2 ? 108 ? s in this coaxial cable  refer slide time  35  57 ? 36  28  the cable maybe of 400 m length  transmission speed = 10 mbps  so propagation speed is 2 * 10 * * 8 ? s let us see what the delay is and what the minimum frame size comes out to be propagation delay time is tprop ; the round-trip propagation delay is twice this number of bits we can fit into a round-trip propagation delay  the minimum frame length nb  refer slide time  36  29 -37  04  tprop = d/v = 2 ? 108 and distance is 400 m  which makes it 2 ? 10-6 sec or rather 2 ? s  2 ? tprop ; that means  for the signal to travel all these 400 m and come back  it takes 4 ? s for the 4 ? s  the transmitting station must go on transmitting and the transmitting station is pumping data at the rate of r = 10 mbps  refer slide time  37  05 ? 37  52  a bit time  the time to transmit 1 bit is 1/r ; it is 1/10 megabits  which is 10 ? 106 which is 0.1 ? s the minimum number of bits the frame must have is 2 ? tp/tb tp is the propagation delay ; 2 ? tp for the round trip propagation delay divided by tb = 4/0.1 = 40 bits this calculation brings us to 40 bits as i said the minimum size is much bigger than 40 bits  and we will see why  refer slide time  37  53 ? 38  07  the minimum frame length is thus 40 bits or 5 bytes a margin of error is usually added to this  often to make it a power of two  so we might use 64 bits or 8 bytes  refer slide time  38  08 ? 38  53  let us see another example  calculating something else but it is closely related two nodes are communicating using csma/cd protocol  and the speed transmission is 100 mbps this is a fast ethernet and frame size is 1500 bytes the propagation speed is 3 ? 108 meters per second ? that is the speed of the light calculate the distance between the nodes such that the time to transmit the frame equal the time to recognize that the collision has occurred we want to calculate the distance  refer slide time  38  54 ? 39  12  since frame time is given we calculate the propagation delay from this so tround trip = tframe = 2 ? tprop so tprop = tframe/2  and what is the tframe ?  refer slide time  39  12  39  22  we have 1500 bytes  which is being pumped at the rate of 100 mbps  refer slide time  39  23    if you multiply 1500 bytes into eight  that means how many bits will get 12000 bits which is 1.2 ? 10-4  i.e  6 ? 10-5  refer slide time  39  53 ? 40  17  the maximum distance is calculated using the propagation velocity  tprop = d/v = tprop ? v =  6 ? 10 -5  ?  3 ? 108  = 18 ? 103 = 18 km with this kind of minimum frame length  you can go up to 18 km remember  the minimum frame size has become 1,500 bytes this standard  refer slide time  40  29 ? 40  48  frame length is at least 512 bits or 64 bytes long  which is much longer than our minimum requirement of 64 bits which is 8 bytes we only have to start worrying when the lan reaches lengths of more 2.5 km  refer slide time  40  49 ? 41  41  802.3 csma/cd bus lans longer than 500 m are usually composed of multiple segments joined by in-line passive repeaters as a signal travels down transmission line  what would happen is that it will become weaker  so we will have to put a repeater  and one kind of repeater maybe called a hub in-line passive repeaters output on one cable the signals received on another cable or we may simply have an amplifier over there when we work out the minimum frame length for these longer lans  we also have to take the delays caused by the passive repeater ; each passive repeater introduces a delay of about 2.5 ? s each  so we have to take this into account as well  refer slide time  41  42 ? 43  23  let us say we have 500 m on each segment  we have 4 repeaters  so 5 segments that is about the maximum you should go nowadays we do not use such coaxial cables what happens is that 64 bytes sent at 10 mbps would take 64 ? 8 = 512 bits ; 512 bits at 10 mbps is 51.2 ? s and 500 m per segment four repeaters between the nodes means there are 5 segments ; 2500 m in all this gives rise to 25 ? s propagation delay  because remember our propagation velocity is about 2 ? 108 if you calculate  it comes to about 12.5 ? s from one end to the other  twice that is about 25 ? s the frame should be long enough for the sender to detect the collision in 2 ? 25  this is 125 and the other 25 is these 4 repeaters together  about 50 ? s ; 64 bytes sent at 10 mbps is 51.2 ? s if you have a frame length of 64 bytes  that is quite good  refer slide time  43  24 ? 45  27  let us look at the details of the ethernet frame all information on an ethernet network is organized into frames also called packets or may be packet is what the upper layer gives and then this is formed into a frame contents of an ethernet frame  sending adapter encapsulates ip datagram or other network layer protocol packet in ethernet frame this is what the ethernet frame looks like  we have a preamble of 7 bytes  we have a start of frame of 1 byte  we have a destination address of 6 bytes  we have a source address of 6 bytes  we have frame length of 2 bytes and then data may vary from 46 to 1500 bytes and then followed by crc of 4 bytes if you remember crc is the cyclic redundancy code which ethernet uses for error detection on the other side so you have actually about 72 bytes  which is even larger than the 64 bytes we require 46 bytes the minimum and 1500 bytes is the maximum length of the payload  this is the payload part ; to this we have to add this header and trailer part in the trailer you have the crc in the header the source address destination address  etc this frame length is required because you might have padding over here in some other version of ethernet  there is a type field over here  which gives the network layer protocol type let us look at the  refer slide time  45  28 ? 46  08  details quickly sending adapter encapsulates ip datagram ethernet frame ; preamble has 7 bytes with the pattern 10101010 please note that 1s and 0s are alternating ? and there is a reason for that ? followed by 1 byte with pattern 10101011 ; so these 7 bytes are called the preamble this 10101011 is the start of frame delimiter  7 bytes of pattern this 1 0 is required ; it is used to synchronize receiver and sender clock rates that is why we alternate 1 and 0 etc  refer slide time  46  09 ? 47  47  we have an address of 6 bytes if the adapter receives a frame with matching destination address or with broadcast address  for example an arp packet  it may be broadcast  it may be multicast or it may be unicast if actually a frame would be broadcast  only 1 would come up arp is the address resolution protocol ; we will discuss this in the next lecture it passes data in the frame to the net layer protocol ; otherwise the adapter discards the frame so this address has to be there the destination address and source address are also put over there type  as i said  in some form the type indicates the higher layer protocol  mostly ip  but others are supported  such as novell ipx and apple talk what type of network layer protocol is it talking to ? the same ethernet ? as i mentioned before ? the same data link layer protocol may be supporting a number of network layer protocols in that case  there has to be multiplexing and de-multiplexing in the receiver side when a packet comes  maybe this data link layer knows that this is for this particular machine because its address is there so it will absorb it but then send it if there are two different network layer protocols  which are running at the same time  whom will it send it to ? that type is mentioned in the field so that it can do a de-multiplexing properly crc or cyclic redundancy code is checked at the receiver if an error is detected  the frame is simply dropped  refer slide time  47  48 ? 49  53  the other thing to understand is that this ? ethernet gives you an unreliable connectionless service it ? s connectionless  and there is no handshaking between sending and receiving adapters ; so it is connectionless the sender simply sends some packet and there is no handshaking between the two the actual reliability  whether there will be error or not  will depend on the quality of the cable  the quality of connections  whether all standards have been followed very meticulously  and the quality of distance and the ambient noise and these kinds of things that is not what we are talking about  it is unreliable in the sense that whatever physical layer parameters are there  they are given to the data link layer  that is  the ethernet layer but the ethernet does not really try to take any special care to see that the communication is reliable it has a crc for sure  so on the other side if the receiver sees that the crc shows some error  it may drop the packet but the receiver does not send any acknowledgement to the sender the sender does not know about it if that packet is dropped that frame is dropped if that has to be handled  it can only be handled at a higher layer so it is unreliable in that sense  receiving adapter does not send acks or negative acknowledgements to the sending adapter the stream of datagrams passed to network layer can have gaps ; that means some of the frames may have been dropped gaps will be filled if the application is using tcp this is one kind of transmission protocol  which we will discuss later  which tries to take care of such errors otherwise  the application will have to handle these gaps  refer slide time  49  54 ? 52  20  just a couple of words about the addresses ? remember there are 6 byte addresses every network card in the world has a unique 46-bit serial number  called a mac address we are talking about the ethernet  there is 46 bit ; 246 is about 64 trillion  which is a very large number and these numbers or these addresses are distributed by ieee a manufacturer who manufactures ethernet nic ? that means ethernet network interface cards ? will apply to ieee and get a whole chunk of addresses  whole block of addresses and will put these addresses one by one into the network cards that are produced and then sell in the market what happens is that one of the network cards may have gone to india and the next network card may be used in beijing it may so happen that the network cards we have and not the network addresses in the lan will have very contiguous addresses they may not ; anyway  what is guaranteed is that since this is distributed centrally from ieee  no two addresses  i.e no two mac addresses of two network interface cards or two ethernet cards are going to be the same they are all going to be distinct  because we have this pool of 64 trillion addresses being distributed by ieee ieee allocates these numbers to network card manufacturers  who encode them into the firmware on their cards it is almost in the hardware  encoded in the firmware in the card  the destination and source address fields of the mac frame have 48 bits set aside remember 6 bytes is 48 bits there is a 2-bit discrepancy these 2 bits are used for something  the standard also allows for a 16-bit address but they are rarely used  refer slide time  52  21 ? 53  47  in these 2 bits  the most significant bit is set to 0 to indicate an ordinary address  and 1 is to indicate a group address this is for multicasting  which means that frames are sent to several hosts remember  in the beginning of the lecture we said that although the medium is broadcast  usually there will be 1 sender and 1 receiver  i.e  it is a unicast ; that means 1 sender 1 receiver sometimes you may have a broadcast ; that means it is meant for everybody  and sometimes you may have a multicast ; that means it is meant for a few of the hosts in the network  not for all how do you indicate the address ? you indicate a very special address starting with a 1 for multicasting if all 48 bits are set to 1  frames are broadcast so for the destination field if all bits are 1  there is a very special address  not the address of any particular machine  which is meant to match with any ethernet address on that particular lan if 2 most significant bits are both 0  the 46 least significant bits contain the mac addresses of the source and destination hosts this is how you make out  refer slide time  53  53 ? 54  49  also this is connectionless and unreliable in the sense that it does not take any special care for reliability this is also non-deterministic network ; this means that no host is guaranteed to be able to send its frame within a reasonable time  just a good probability of doing so theoretically what might happen is that you may try to go and find it busy again you come back and then go ; it might collide next time you come back and this might happen an indefinite number of times although the probability of its happening in a large number of times becomes lower and lower  with a very good probability  we will be able to send it but there is no guarantee that within this time you will definitely be able to send your frame when the network is busy  the number of collisions rises dramatically and it may become very difficult for any host to transmit its frames  refer slide time  54  50 ? 55  19  this makes it not suitable for a real-time computing application at least this bus type network may not be suitable for a real-time computing application such as an assembly line  which will demand that data be transmitted within a specified time period since the 802.3 bus lan can not guarantee this  its use for real-time applications may not only be undesirable but sometimes potentially dangerous there are other ways of very high-speed network when this is low ; then the chance of not being able to send at all becomes very low indeed just one  refer slide time  55  36 ? 56  42  last word about the csma/cd efficiency we will not go to the details of this discussion suppose each station transmits during a contention slot with probability p the probability a that some station acquires the channel in that slot is a = kp  1  p  k-1 so p is the probability that a particular contention slot is taken by one node and 1  p is the probability that all the other k  1 nodes have not taken and that a particular slot is being used  i.e kp  1  p  k-1 so a is maximized when p = 1/k with a tending to 1/ ? ? as k tends to 8 the probability that the contention interval has j slots in it is a  1  a  j-1  refer slide time  56  43 ? 57  02  the calculation of channel efficiency would be p  where p is the time that a node needs to transmit mean frame and 2 t is slot duration so p/p + 2t/a means that if p is large  that means if we are sending a large frame  the channel efficiency increases  refer slide time  57  03 -57  15  as you will see in this slide  with 1024-byte frames  the channel efficiency is very high if you send in small frames  the channel efficiency tends to be smaller this plot is with a number of stations trying to send with this  we come to the end of this lecture in the next lecture  we will look at the modern versions of ethernet like switched ethernet and how different networks are connected together thank you computer networks lecture name # 20 prof sujoy ghosh dept of computer science and engineering i.i.t kharagpur modern internet  reference time  00  46  good day ! in this lecture we will continue our discussion about ethernet in the previous lectures  we have seen the basic data link protocol used in ethernet ethernet is a very popular and nowadays it is almost ubiquitous in the lan area it is a very widely used system and it has evolved from whatever was the approach to ethernet in the earlier days and the basic ethernet protocol that we had discussed people are sort of shifting away from it because as the technology develops and as things like switches etc  become cheaper as the speed of network goes up  there is a slight shift in emphasis in modern ethernet in this lecture  what we are going to do is that first  we are going to have a look at the physical layer of the ethernet there is not much to discuss about that  and then we will see how we are shifting from a shared medium to a switched ethernet kind of concept  and how speed is increasing then  we will discuss a little bit about ethernet  lan as a concept is so  we discuss the modern ethernet that is how the ethernet is evolved  refer slide time  02  15  02  20  before we go into that   refer slide time  02  21 ? 02  47  we will look at the topology and some of the limitations of the earlier versions of ethernet the topology of a network refers to the pattern of workstations  cables and repeaters in an ethernet  there are two primary limitations to the topology  transmission accuracy and end-to-end transmission time transmission accuracy means that ethernet really under a data link layer is an unreliable protocol in sense that it does not do a lot of acknowledgement or negative acknowledgement and things like that therefore  essentially the transmission accuracy should be fairly tolerable what happens is that the maximum distance for accurate transmission is determined by signal attenuation along the cable  and it would depend on the on the quality of the cable  the kind of cable we used and the data rate the other important point is the end-to-end transmission time as we have seen  because of this collision and other things this end-to-end transmission time is important it ? s not just for the data rate or things to move faster but for other reasons  also this end-to-end transmission time is a factor  refer slide time  03  48  04  56  these are the ethernet physical layer standards that we have ? some of them  they are actually more so 10base5  that is  10 mbps base band transmission and 500 m ; this 5 here stands for 500 m cable length  this is called thick ethernet or has thick coaxial cables and this has become obsolete then 10base2 is 10 mbps base band transmission ; once again all of these are base band transmissions ; that means we do not modulate them to a higher channel or frequency channel so  10 mbps and 2 for above 200 m cable line  or lines of 180 to 200 m length then  10baset ; this again is for 10 mbps base band transmission  which uses utp cable there are various versions of utp cable like categories 3  4  5  etc 100base-tx is 100 mbps base band transmission  also uses utp cable  refer slide time  04  58  06  28  so  these are the of maximum segment length as we can see  10base5 is 500 m ; 10base2 is 185 m ; 10base-t is 100 m fibre optic cable 10base-fl goes up to 2 km actually  10base-f is not in much use these days  because fibre optic components became cheap and available  and people have moved from this 10 mbps rate to the 100 mbps rate the point is that  the fibre optic cable goes much longer than copper cables and it is best between buildings ; that means when it goes through some open space  etc  we avoid copper cable most times because of electric interference and other problems  not to mention the distance the nodes per segment in 10base-f could also be more ; we will come back to this topic of nodes per segment later as we have seen previously  10base5 and 10base2 have many limitations ; for example  in 10base2  you see the figure of 30 and a network segment having only 30 nodes is a constraint these days because all kinds of things are being networked for completeness sake  i will make a mention of 10base2 and other kinds of  refer slide time  06  51  07  18  technologies  although they have become obsolete now ? 10base2 has 10 mbps  200 m maximum cable length  is a thin coaxial cable in a bus topology ; this is a classical bus topology repeaters are used to connect up to multiple segments repeater repeats bits ; it hears on one interface to the other interface  so this is a physical layer device just for amplification  strengthening the signal  refer slide time  07  19  07  53  this is a figure showing how they are connected we have this thin cable  which has terminated on both the ends and these nodes would be connected using some t connectors over here  and this is the network adapter when a network adapter pushes some signal on to the cable  the transmitted packet travels in both the directions  refer slide time  07  55  08  32  this is just a mention about 10base5  because connecting a 10base5 is more cumbersome and in 10base2  connection would get loose quite often in the earlier days anyway  this is a 10base5 ; it has a thick coaxial cable  the transceiver  and transceiver  drop cable and there would be a network interface card here with this mac unit and protocol control firmware etc as i said  this has become obsolete now  refer slide time  08  33  09  21  let us talk a little about repeaters repeater is a physical layer kind of device  which regenerates the signal  and provides more flexibility in network design because it depends on where we want to extend your lan so if you want to extend your lan in some direction  make running into this distance limitation 200 m for 10base2 etc you may sort of increase that by just putting another segment on the other side of repeater so that you can go another 200 m therefore you can extend the distance over which a signal may travel down a cable ; an example of a repeater is ethernet hub a hub has two purposes  one is to provide a collision domain and replace the cable the other function of the hub is the repeater function ; that means it regenerates the signal this connects  refer slide time  09  48  10  02  together or a repeater or a hub it connects together one or more ethernet cable segments of any media type if an internet segment were allowed to exceed the maximum length or the maximum number of attached systems to the segment  the signal quality would deteriorate  refer slide time  10  03  10  36  you can see that you have one cable segment here this goes up to its maximum distance there is a cable segment too again going up to the maximum distance but we put this repeater in between so that  we can increase the total distance that may be covered these are the different computers connected to the cable it is used between a pair of segments ; this is a simple repeater to provide signal amplification and regeneration to restore a good signal level before sending it from one cable segment to another  refer slide time  10  37  13  02  hubs are essentially physical layer repeaters ; bits come in one link and go out all other links there is no frame buffering or csma/cd at the hub adapters detect the collisions and provide net management functionality  which means that this hub  although it is an active device  in the sense that this has some electronics in it  in its action it is more passive its active component is restricted to the fact that it regenerates the signal ; it amplifies and regenerates it so far as the other intelligence is concerned  like detecting collisions  it does nothing like that if two signals coming at two different ports of the hub come to the hub at the same point of time  they will collide so  a hub is a whole co-axial cable  which has been collapsed into one collision domain inside the hub ; we could look at that way but it does provide some net management functionality that means  if you have a managed hub  there are two kinds of devices the point is that a network is usually a geographically distributed  dispersed kind of entity ; but this has to be managed therefore if there is a problem somewhere  may be some user has put in a complaint  what we will do is that there are so many things which connect from the user to the central network there are cables  may be switches  hubs  and other things  so it is important that you should be able to remotely tell whether some active device is functioning we can not do this on passive things like a cable but there are managed switches and managed hubs etc  whom a central network station may interrogate and find out whether its health is alright or not so if you have a managed hub  you have net management functionality ; of course  the managed hubs are costlier than unmanaged hubs  refer slide time  13  03  13  24  so this is the picture of hub this is a co-axial cable coming in here and this is a t joint ; the t joint is feeding into the hub there may be a number of ports and a number of segments may be connected together  refer slide time  13  25  14  40  now  we come to 10baset ; so far as the physical part is concerned  this 10baset can go on to become 100baset ; that means  from 10 mbps it can go to 100mbps but for this utp  unshielded twisted pair cable of various categories like 3  4  5  etc  are the dominant physical medium and the varying technology today for local area networks we can have category 5 cable data transmission up to 100 mbps and we can go a little bit more on this depending on the distance the impedance of a utp cable is about 100 ohm  give or take another 15 ohm over the useful frequency range of the cable the transmission speed is 0.6 to 0.65 ? c  which is about 2108 m/s time delay is about 5 nanoseconds /m  refer slide time  14  42  15  40  here  you can see there are some 10baset repeaters and then 10base-fl segments this is just to give you an idea about the various delays which are involved the first segment delay is about 0.57 ? s for this 100-m segment  middle segment delay is about 10 ? s and last segment delay of about 0.57 ? s the transceiver delay is about 7 ? s  fl repeater delay is about 1.7 ? s  10baset delay is about 21 ? s and so on all these delays really add up and you have some limit on this in order for your csma/cd to work properly  refer slide time  15  41  15  57  so this is the same data in tabular form it has various types of cables and these are all fibre optic kind of cables  which go up to 2 km or 1 km these are obsolete now ? these are the maximum lengths and these are the delays  the receiver delay and the delay at the repeater and so on now  what happened was that the people moved as the demand for bandwidth grew ; so at least in the lan it moved much faster when lan bandwidth became quite cheap and everybody wanted to move from 10 mbps to the next speed  which is 100 mbps  and this was called fast ethernet one thing was that  when we come to fast ethernet  this co-axial cable really was out so the thing preferred was the unshielded twisted pair or utp category 5 is preferred for 100 mbps operation  although category 4 would also work it is possible to transmit it over category 4 cables also ; but category 5 cables are preferred now one thing about this utp cables is that because they are used for connection from end to end unlike the coaxial cables ? in coaxial cables  we have one cable and many nodes may be connected at intermediate points ? you put a connector  usually an rj45 kind of connector on the two ends and then go into two nodes it is as simple as that so if there are no nodes in between  just two end point connections  where this part of the medium is not shared  at one end may be the computer  and the other end might go into another machine straight away these two machines network together usually the other end would go to a network device let us say  to start with  it might go into a 100 mbps hub so  all the nodes which are connecting  that means which are part of the network  all of them are connected by this utp cable to the central hub so the central hub is a shared medium at the collision domain but so far as the utp part is concerned  there is no collision just as we had the 10base-t  which supported 10 mbps  may be with the same kind of cable with this utp cable  we could support fast ethernet  that is  100base-t there was 100base-tx  but there are some problems with this  one is to increase to 100 mbps  we have got one order of magnitude jump in the speed that is not a mean achievement on the same medium depending on the quality of the medium  as the speed goes up  its performance tends to decrease so depending on what kind of medium it is  there is only a certain amount of bandwidth in a certain range that you can support on that medium so to increase to 100 mbps  different encoding is used to reduce the bandwidth of the transmission encoding data at 100 mbps using manchester encoding would create a bit stream of 200 mbps so  we can not straight away use manchester encoding here  because this is for supporting 200 mbps  we requires at least 100 mhz of analog bandwidth  which is too much category 5 utp cable is rated up to 100 mhz but for keeping some margin etc  transmitting a signal of 100 mhz bandwidth would be unreliable so what we do is that instead of manchester encoding  we use a different kind encoding  which is called multiple or multilevel encoding to reduce the bandwidth  a different encoding scheme is required 100base-tx uses a multiple level encoding scheme  that is mlt3  multiple level transition 3 the bandwidth required in this case has come down quite sharply to 31.25 mhz the encoding is somewhat like this ? 0  there is no transition and 1  there is a transition and this transition could be of various types from low to 0  high to 0  0 to low or 0 to high  depending on the context for example  this is a 10110001110 that is being encoded suppose with the 1 there is a transition from 0 to low  that is  0 to low level  then for 0 there is no transition  after 0 there is 1 now there is a transition ; since we go to low now  and the only place to go to is high  we go to a high and then there is another 1 and since we are going high  we go high some more  that is  another 1 should this go from 0 to high  then three 0s  that is  no transition at all then from 0 to 1  now from high since 1 has come  you will have to come to low and again another one has come ; we are going in the downward direction so we continue from 0 to low and then  another 1 from low to high and then 0 ; there is no transition so  this is the way an mlt encodes using different levels or multiple levels of signals this reduces the net analog bandwidth requirement for the cable so this is how  the ten-fold increase in the speed was achieved on the same physical infrastructure so bandwidth required for mlt is half the bandwidth required for a two-level scheme half is a rough figure long stream of zeros will cause the line to hold a constant voltage and lose clocking  synchronization is necessary to read the signal this is one problem  which is handled in various ways one way is to encode each 4-bit sequence as a 5-bit pattern 4b5b encoding in this 4b5b encoding what is done is that instead of a 4-bit sequence we introduce a 5-bit sequence so we get some transition and we can hold on to synchronization this pushes up the bit rate to 125mbps for100base-tx  where data is only 125mbps/4 = 31.25 mhz category 3 or 4 cable is used for a rate of 100 mbps by using all four twisted pairs in the utp cable ; so this is also possible three pairs will transmit data while the fourth pair is used by each station for collisions as in 10base-tx  a three-level signal is transmitted in 100base-t4 t4 is when we are using category 4 cable but the data rate must be minimised further therefore the signal is broken into 8-bit sequence and each 8-bit sequence is represented as 6 three level signals  or 8/6t if we are trying to put in a new network today we are never going to use category 4 utp  we are always use category 5 or better you know about the increasing requirement of speed in the lan  but these techniques were developed so that ethernet could move into some existing physical infrastructure like wiring  where category 4 cable is used for moving from 10 to 100 mbps ; that is why these were developed fast ethernet is done with cabling of the following types ? 100base-t4 with category 5 100base-tx ; and 100base-fx is quite common as i said  10base-fl has become outdated but 100base-fx is still there  which uses fibre optics and goes up to 2 km category 5 utp goes only up to 100 m or may be some people are conservative and limit it to 75 m at full duplex at 100mbps  fibre is again full duplex at 100 mbps ; these are the advantages the advantage of t4 is that  it uses existing category 3 utp these are the repeater delays 10base-t and 100base-tx wiring goes like this ? from the end station a maximum distance of 100 m to the hub we can use multiple hubs  a maximum of four  to increase the distance between any two stations ; a hub may go to another hub ; that may go to a station again now  there are three segments we can use a maximum of four hubs and five segments with 100 m from the node to the hub for upgrading from 10base-t to 100base-tx  we need new hubs or switches you may have some 10 mbps ports to handle 10base-t ; nics may have auto sensing 10/100 ports that handle either auto sensing ports are quite common as a matter of fact  most of the network interface cards you get today are 10/100 ; that means they are auto sensing ports an nic senses the network device at the other end if the other end supports a rate of 100 mbps  this nic will operate at 100 mbps if it senses that the opposite end can handle only 10 mbps  it will use only 10 mbps by the way  if there are problems with the varying connection  etc  it may send 100 mbps port as 10 mbps so  if you want to upgrade from 10base-t to 100base-tx  you may need new nics  and only for stations that need more speed and no need to rewire ? that may be a big advantage in some cases we may have 100 multiple hubs  one connecting to the other ; you can have multiple hubs for connecting etc in 100base-tx there is a limitation that you can have only maximum two hubs and they must be within a few meters of each other so  the maximum span using these hubs is only 200 m  which is shorter than 10base-t it could be a big problem and that is why 100 mbps hubs are also becoming obsolete people have migrated from hubs to switches  and that is what we will be talking about so if you had used hubs  this would have been a limitation ; but nowadays people do not usually use hubs we will come back to the topic about hubs and switches later on what happened is that this development went on and now we are moving into the era of gigabit ethernet the gigabit ethernet in the desktop is still not very common  but it is coming and for servers etc  nowadays we routinely get gigabit ports and  may be  soon your desktop computer may also be connected with gigabit ports so  this is a depiction of a two-station ethernet ? two computers connected straight away  this is a switch or a hub which operates at gigabit speed so  these allow point-to-point links and shared broadcast channels through some hubs if they are there in shared mode  csma/cd is used for the short distance between the nodes to be efficient ; but this is not very common it uses standard ethernet frame format 802.3z ; the normal mode is full duplex mode with a central switch this is the most common one connected to computers in this configuration all lines are buffered on the right-hand side  you see one switch and the nodes are connected straight to the switch so this is a switch rather than a hub  where each of the ports has a buffering since each of the port is buffered  contention is impossible ; because data can always and gets it on the buffer so  it makes no sense to the channel to see if it is idle or not because if there is no contention  csma/cd protocol is not used at all and this is the mode  in which gigabit is usually used  although there are buffered distributors also now people are talking about moving to 10 gbps  at least in the metropolitan area network they use copper and fibre with 850 nm or 1300 nm lasers and some kind of encoding the ethernet is moving really fast  because it is upgrading quite fast ? it went from 10 mbps to 100 mbps ; from 100 mbps we are moving to 1gbps ; and from 1gbps  we can see the possibility of moving to 10 gbps  and 10 gbps is already in operation today from 10 mbps to 10 gbps is a 1000-fold increase in a very short span of time  which is really amazing for gigabit  refer slide time  32  16  32  56  ethernet  we have 1000base-sx ; this sx shows the multimode fibre for 1000base  so the maximum segment size would be about 550 m 1000base-lx uses single or multimode  so this goes upto 5000 m shielded twisted pair would only take to 25 m and 1000baset can go up to 100 m using category 5  category 5b or  for gigabit ethernet  category 6 is preferred we will talk more in detail about the switching  which is very important so  ethernet is  refer slide time  33  17  33  38  usually considered as a shared media lan only one station can be transmitted at a time even when you have multiple hubs  these hubs are all shared domain  which means that only one can transmit all other stations must wait while one station sends so this is the big limitation of latency and congestion with hubs  refer slide time  33  39  33  45  to improve this  people moved over from hubs to switches packet switches are very useful they give you improved security users are less able to tap into other users ? data in a shared medium  we know everything is being broadcast so all packets are going to every other node that is poor security ; this gives you much better security ; better management ? we can control who receives what information that means  even using a switch  even within a lan  we can create a work group and make users members of different virtual lans these virtual lans may be packet filtering between the virtual lans  etc  to give a better management and limit the impact of network problems this switch will also give you full duplex communication  rather than half duplex one side effect of having a shared medium is that only one sends  and every body else is in the receiving mode obviously that channel can not work as a full duplex mode because two of them can not send simultaneously at the same time  only one may be sending and the other may send at most  this works as a half duplex channel  whereas over here this can work as full duplex channel a hub simulates a single  refer slide time  35  20  36  07  shared medium  whereas switch simulates a bridged lan with one computer per segment for example  we have only one computer and many segments  and there is only one computer for each segment so it does not have any collision and from two different computers you can send data at the same time to the switch the switch will buffer it and there will be no collision so collision detection may be eliminated some of these may connect to a hub instead of going to a computer so a switch may be connected to another switch  that switch may connect to hub  and that hub may connect to so many computers so there are many possibilities  refer slide time  36  08  36  01  ethernet switches are highly scalable we had 10base originally ; we went from 10baset hubs to 10baset switches 10baset switches are increasingly being replaced by 100base-tx switches with auto sensing codes 100base-tx switches are very common these days  they have higher performance and their costs have come down these days we get 100base-tx switch at the cost of what a 10baset hub would cost a few years ago we can see how the technology and the economy have improved gigabit ethernet switches are still expensive ; it will take some more time in order for them to move to the desktop  refer slide time  37  02  37  16  other advantages of switches are that there are no limits on the number of ethernet switches between the farthest stations and no distance limit on size of switched networks you remember when we were talking about 100base-tx and when we were using 100 base tx hubs you can only have a maximum of two hubs and these two hubs have to be close together ; they can not go far long so  the maximum span of a local area network could almost be 200 m  which was really a limitation  but then people moved to100base-tx they also moved from hubs to switches with these switches  now there is no problem because the distance limitation had to do with the round-trip propagation delay and things like that since there is no contention and the switches have buffers  there is no distance limitation at all you can have any number of switches connected to each other ; there is no distance limit on size of switched networks so often individual hosts  are connected to switches and may be different switches are also connected this is ethernet without collisions or csma/cd  refer slide time  38  17  38  55  here  we have a  b  c  and so on suppose a wants to communicate with a ' and b wants to communicate with b '  both the communications may take place simultaneously this is a switch if this had been a hub that would not be possible but since this is a switch  b can communicate to b ' and a can communicate to a '  just as in a telephone switch  two pairs or distinct pairs of people can communicate at the same time similarly  two distinct pairs of machines  through this packet switch  can communicate at the same time  refer slide time  38  56  39  22  this is essentially a multi-interface bridge ; it has a layer 2 frame forwarding  filtering using lan addresses ; lan addresses mean mac addresses we will talk more about mac addresses presently it allows switching a to a ' and b to b ' simultaneously  but there are no collisions this can have a large number of interfaces a modern switch may have hundreds of ports  so hundreds of machines can be connected to the same switch similarly  a number of such switches can connect to each other ethernet switches  refer slide time  39  34  40  04  must be arranged in a hierarchy or daisy chain with only one possible path between any two stations suppose  from 4 to 3 there is only a single path that is 4  2  1  3 ; you do not make a loop connecting two ports of a switch because that would really create a lot of problem therefore  ethernet switches must be arranged in a hierarchy or daisy chain there is only one possible path between any two stations or switches  refer slide time  40  05  42  27  a station is an ethernet frame switch plug-in card it checks to see if it is destined to the same card if so  the frame is copied there we mentioned that in a packet switch  usually the ports would be grouped into small groups and each of these groups will go into a particular line card this line card is similar to the ethernet a switch is nothing but a packet switch ; there will be line cards over there and may be 4 lines coming to one particular line card and may be there are 8 line cards for a 32-port switch now  for those that are coming into the line card  there are variations of how they are handled by the line card it could be that a frame which has arrived in a switch plug in card is destined to the same card ; that means it is destined to some other line in the same card if so  the frame is simply copied there ; if not  the frame is sent now these line cards should get connected to each other through the backplane if the frame is sent over from the high-speed backbone to the destinations card  it will travel to the other distinct destination through the switching fabric this backplane may be active or passive ; they are of various types anyway  the backbone typically runs at many gigabits per second as a matter of fact  nowadays it is possible to have a high-end switch with something of the order of 100 gbps backplane switch it is a very high-speed switch that can support a lot of machines at the same time if two machines attached to the same plug in card transmit frames at the same time  what would happen ? there are two machines attached to the same plug in a card and they transmit frames at the same time ? what would happen would really depend on the way the card handles it ; here there are some variations for example  let us say  there are 4 line cards ? 1  2  3  4 ? coming into this one particular line card line 1 and line 2 frames arrived simultaneously and both of them are destined to line 3 ; what is going to happen ? it depends on how it is handled one possibility  refer slide time  42  54  43  41  could be that all the ports on the card are wired together to form a local  on-card lan this lan card itself is a local on-card lan  and on this on-card lan  there will be a csma/cd network csma/cd may operate on that particular card itself ; in that case  there will be a collision that will be detected only one transmission per card is possible at any instant of time  so if you are doing that  you have made that line card to be a shared medium all the cards can be transmitting in parallel ; the different cards may be transmitting in parallel each card forms its own csma/cd network independent of the others ; that is one possibility  refer slide time  43  42  44  04  the other possibility is that the plug-in card of each input port is buffered ; so incoming frames are stored in the cards on board this allows all input ports to receive or transmit frames at the same time for a parallel  full duplex operation this is not possible with csma/cd on a single channel previously we had talked about buffers in packet switches we mentioned how buffers could be on input side  how buffers could be on output side and distributed through out the switch fabric that was from the point of view of handling head of line  blocking  switching  speed etc here  it is slightly different in the sense that if there is some small buffer at each of the ports and on input side  full duplex transmission at the same time is possible on all the lines instead of making a local csma/cd and allowing some kind of collision  this naturally is a better kind of switch once a frame has been completely received  the card will then check to see the frame is destined for another port on the same card  or for a distant port in the a case  it can be directed to the destination ; in the b case it must be transmitted over the backbone to the proper card  refer slide time  45  12  45  21  each port has a separate csma/cd so collisions do not occur there is now no question of any csma/cd because each port has only one machine  refer slide time  45  23 45  51  then there is another term called cut through switching  frame forwarded from input to output port without waiting for assembly of the entire frame that means even when the frame has not fully come in  the bits are transmitted and there is a slight reduction in latency so  combinations of shared dedicated 10/100/1000 mbps interfaces are possible on the same switch you might get some 10 mbps ports  some 100 mbps ports  also some 1000 mbps or giga bit ports for uplinking to the main backbone  refer slide time  46  03  48  04  this is a typical lan of an ip network let us look at this figure ? some hubs are remaining  but these hubs will give way to switches from 10baset to 100baset very soon  but let us say  there is a legacy system  through which some 10baset hubs and some computers are connected to this these hubs may be connected to a switch this switch could be connected to another switch and that switch might connect to some other nodes  etc this constitutes the lan ? may be there is a 100 mbps connection from this switch to the mail server  because mail server may be something which everybody is using this is a server  and you might want to have a higher speed of this one also ? these are 10 mbps ports you might want to make it 100 mbps there is a www server  that is  a web server  which is also connected through a 100 mbps port so from the same switch  you may connect to some hubs  you may connect to some servers  you may connect to some individual desktops  pcs or machines so this is what the lan part looks like and of course  nowadays nobody would want a lan which is standing by itself people want to connect their lans to the internet  which is the great network of networks there are probably lot of networks  may be millions of networks  in other places ; we want to connect to other networks also so we have to go through what is known as a router we go through a router to the external internet we will be talking about this part when we talk about the network layer in more detail ; so this is a typical picture of a lan  refer slide time  48  05  48  34  if we abstract this a little bit  we have a lan  and different nodes or the different machines are connected to this lan and then there is a router  which connects you to the internet this internet may be a connection between a lot of different networks  may be a lot of different lans to their own routers etc this is a slightly more abstract view  refer slide time  46  35  48  39  and then looking into it in detail in the lan part of it  if we go to the previous picture   refer slide time  48  40  48  44  this is the lan part of it and these nodes are connected these nodes are usually connected  refer slide time  48  45  51  34  through adapters that means the network interface card  nic  or the adapter these nodes may communicate with each other in the lan if it is connected to the internet naturally it may communicate with the other machines in the outside world also ; but let us for the time being just focus our attention on the nodes which are in the lan  and they are sort of trying to talk to each other if they want to talk to each other using either a hub or a switch  or in this case  the ethernet frame format  what is going to happen is that the frame format has certain fields and those fields have to be filled up that means the destination address has to be there  and the destination address is the lan address or the mac address or the hardware address sometimes this is also called an ethernet address and this ethernet address is distributed by ieee ; the manufacturers of these adapters buy blocks of addresses from ieee and these are all 6-byte addresses  something like this  1a23f9  each of then is 1 byte and if you look at this figure  say 1a23f9cd069b and 88b22a do not have any relationship with each other they are just 6 bytes  may be 6 arbitrary bytes this card may have come from some manufacturer and got entirely different blocks from ieee  the other may have an entirely different address  which has no relationship with the other ; but they are all sharing this lan there is a small problem ? how does the source node get to know the destination address ? one thing is sure ? since one central agency  namely ieee  gives this ethernet addresses  each adapter on lan has a unique lan address ; no two adapters will ever have the same address sometimes  there may be some nodes with a number of lan addresses  with a number of adapters etc  but one particular adapter will have one unique address  two addresses will never be the same the point is that  how do get to know this is the source ? this is a destination ? how does the source know the destination  lan address or the mac address ?  refer slide time  51  35  51  46  there are at least two kinds of addresses  which are used in networks one is the ip address  which is used by the network layer to decide on the total route from the source to the destination what will happen is that it will know where it will have to go ; in order to reach its destination address  it must have some kind of relationship with geography and then  there are these hardware or mac addresses  which are at a lower level and are just as unique ; they do not have any relationship with each other so we have this 32-bit ip addresses   refer slide time  52  32  52  50  network layer addresses used to get datagram to the destination ip we have lan  mac  physical  ethernet or hardware address used to get datagram from one interface to another physically connected interface in the same network so this is a 48-bit mac address for most lans burned in the adapter rom  refer slide time  52  51  53  01  analogy of mac address is like a social security number ; ip address is like postal address the question is how do you get to know the  refer slide time  53  02  53  16  other person ? s address ? address translation  how does a host know the mac address of the other host in its local area network ? and secondly  how does a router determine the mac address from the ip address of a host ? this are two interrelated questions  refer slide time  53  17  53  36  we need some kind of a translator for ip addresses from mac addresses address translation can be static or dynamic ; static translation means you keep some static table static translation requires a lot of book-keeping work from system administration and this is not feasible  refer slide time  53  37  54  39  we have this address resolution protocol or automatic resolution protocol  the so-called arp protocol  which is a dynamic address translation scheme if the destination ip address is not in the local arp cache ? arp cache is a table  which is stored in the local machine and which gives this ip address to mac address mapping  the broadcast query for that address  ? at the most one host will reply because the ip address will match with only one of the host addresses so  the arp table entries are cached for up to 15 minutes  unless if refreshed it is firmly at 15 minutes so that a machine can go from one lan and can also be shifted to another lan what will happen is that these old entries must automatically wash out and if the new entries communicate to their communicating machine  their mac addresses are going to come into the cache so this is how it is always kept fresh arp uses layer 2 broadcasting  refer slide time  54  40  54  59  each ip node on lan has an arp table arp table is ip  mac address mapping for some lan nodes and there is a time to leave  something like 15 minutes or so  it depends on the time after which the address mapping will be forgotten ? it is typically around 15  20 or 25 minutes  refer slide time  55  00  55  36  so starting at a  we want to send a datagram addressed to b we look up the net address of b or link layer what will happen is that we want we do not need b ? s mac address that means this 2 23.1.1.1 is an ip address ? we know it is b ? s ip address  but we want to know its mac address so a ? s ip address  b ? s ip address and some ip pay load form a frame like this  which is broadcast  refer slide time  55  37  56  08  a wants to send datagram to b and a knows b ? s ip address suppose b ? s mac address is not in the arp table  a broadcasts an arp query packet containing b ? s ip address all machines on lan receive the arp query b receives the arp packet ; replies to a with b ? s mac address ; the frame is sent to a ? s mac address  which is unicast it is now specifically given as mac address is known  because a sent the query with a source address  refer slide time  56  09  56  34  a cache saves ip to mac address pair in its arp table until information becomes old  that is  it times out but if it is being used  then it will not become older so in a soft state  information that times out  goes away unless refreshed arp is plug and play  otherwise it will get washed out and new entries will come in automatically nodes create their arp table without intervention from the node administrator  refer slide time  56  35  56  53  all hosts receive the request but only b responds with the ip address ; however  other nodes may update their own cache from the transaction the cache is required since broadcast is a very expensive proposition and more than one packet transfer is very likely between any two stations  refer slide time  56  54  57  12  this is an important question  what is a network ? we always talk about networks ; it is the interconnected nodes in the same broadcast domain we are doing the broadcast ? this broadcast is limited to that domain networks are connected through routers  refer slide time  57  13  57  30  when we want to route to another lan  it is more involved we will talk about going through a router and then we will specifically discuss bridges thank you  refer slide time  57  45  57  47  today we will be talking about local internetworking  refer slide time  57  56  58  18  our topic of today is local internetworking  what is internetworking ? internetworking is connection of different networks  everybody is aware of the term internet today why are comes to this term internetworking and by internetworking we mean connecting different networks just to remind you   refer slide time  58  20  58  40  what is a network ? we discussed this in the last lecture that the interconnected nodes in the same broadcast domains and networks are usually connected through routers but as we will see for local internetworking we may not need a router we may need something called the bridge we will come to that this is the set of nodes which are in the same broadcast domain  this broadcast may be a good thing to have for some applications but for the operation of the network there is one very crucial reason  why we require the broadcast that is to discover the mac addresses of the different computers computer networks faculty name prof sujoy ghosh dept of computer science & engineering i.i.t  kharagpur lecture name # 23 wireless network  refer slide time  00  39  good day in the last lecture we had discussed about the cellular network and that end of wireless networking ; today we will talk more specifically about data networking and wireless lan  and may be wireless man and things like that actually there has been an explosive interest in wireless technology in just the last few years  and a number of different systems have come up it is not known at this moment what will finally stabilize  but the number of systems have come up and some of them of are on drawing board  some of them are on actual deployment so we will talk about just a few of them  the more important ones today  refer slide time  01  29  today we will talk about wireless networks   refer slide time  01  29  03  36  and specifically if i may say  wireless lan a lan means a local area network that works without wires  which means you do not have to wire up the whole place ; you do not have to have a wire coming into your system ; you can walk into a room with a laptop and you are already on the network but this has some peculiar problems ; we will discuss them this is not as easy since signals are of limited range unlike wired lan  if a can hear b and b can hear c  it is not necessarily true that a can hear c so this is a problem which we have to handle ; secondly in many of the cases  these wireless lans use unlicensed frequencies and low power low power is important because you want to have a small-sized cell so that in the another part of the building there may be another cell just giving services to another group of users as we know that this way  by doing space division multiplexing  we can increase the number of users who are on the network one of the most important lan standards today  wireless lan standard  is 802.11 and there are various versions of 802.11 the speed varies from 2 mbps to 54 mbps we will also talk a little bit about bluetooth  which is a personal area network we will talk a little bit about wireless man  which is 802.16 and just mention of few other emerging technologies  refer slide time  03  07  04  28  there are two modes of operation in a lan ? in the presence of a control module or a cm often called a base station ; just as we have a base station in case of a mobile  similarly here we can have a base station which  in 802.11 parlance  is called an access point or ap so we can have a base station access point or ap ; so we can have a base station or a control module and a number of users that is one mode of operation the other mode of operation is a rather ad hoc network ; that means  we just have some peers there is a peer to peer connectivity and there is no central module so applications could be lan extensions  cross building interconnect  or nomadic access ; that means some body just moves in and gets immediate access to ad hoc networking  refer slide time  04  30  04  42  these are the two modes of operation ? in one we have a base station  which is controlling them this is slightly easier to handle than complete peer to peer ad hoc network  refer slide time  04  43  05  23  what happens is this control module or this access point in the case of 802.11 could be connected to a wired network so that all those stations  which are connected to the control module via wireless link  get connected to the entire network so they may connect straightaway to individual pcs or they may connect to some network hub or switch they may connect to a server and a number of lans so this is the picture of a single cell  wireless lan single cell ? w lan ? and we can have multiple cells of w lan  refer slide time  05  25  05  50  in each of the cells we will have a control module  which will serve some of the user modules you may note that there may be a region where it is possible to connect to either of the cms also that is something the user module will have to handle  refer slide time  05  51  07  33  now we will look at w lan requirement this is some kind of a wish list actually ? what all we would want from wireless lan good use of bandwidth is we want ? high throughput ? every body uses a number of nodes ; it should be large  may be in the hundreds a good connection to lan backbone is required because nowadays just a local network by itself is of limited utility since every body is getting use to be connected to the entire network meaning the internet even all the time so the backbone connectivity is also important ; good service coverage ; ok i mean wherever i am i would like to be connected so this to be a good service coverage or range ; minimal battery power consumption this an important issue in any kind of mobile system because if the battery consumption becomes high  either you have to carry heavier batteries or you have to charge them often so that is not good so we want minimal battery power consumption ; transmission security and robustness ? this may be an issue in many cases ? because you know so in a wireless system the medium is of course open to every body alright including snoopers if any so but you would like your communication to remain somewhat private or protected and in some cases that may even become crucial so we want security and robustness ok and some colocated network operation  refer slide time  07  35  09  15  license free operation  this is another important issue for example  the ism band consists of industrial  scientific and medical bands of frequencies which are free ; there is no license on it that means operation with the unlicensed band is important because then whoever can develop a good system can go ahead and compete in it  and that way the world technology improves fast then people also get cheaper and better quality service that is why ism band is generally preferred ; but it is not that in a wireless network  we always stick to ism band cell hand-off and network roaming  this is another thing we would like to have this is some kind of a wish list ; that is  not all of them are achieved 100 % today  but these are the kinds of things we would like to have  like cell hand-off and network roaming just as in voice network we can roam from one cell to another and our call remains online  similarly in network connection  we would like them to remain online when we move from one cell to another so we require dynamic management  adaptive mac address management  dynamic and automated addition  deletion  relocation of end systems without disruption and then we require a choice of physical solutions ; for example infrared spread spectrum  narrow band microwave  etc  refer slide time  09  16  10  22  as i said there are a number of standards that came up ; here i am just showing some standards in the 802.11 family then there is an 802.15 family ; 802.16 ; and so on this is just one of them 802.11 originally was a 2.4 ghz ism band and used fhss  which is frequency hopping spread spectrum  with 1 ? 2 mbps speed or direct sequence spread spectrum  dsss had 1 or 2 mbps  and then slowly it graduated and then it fell over to three standards  802.11b  which is the most earliest and the most common one ; it was followed by 802.11a ; and 802.11g these two are in the 2.4 ghz ism band  whereas this one is in the 5 ghz ism band  refer slide time  10  23  11  14  we will not go in to the details of all these and what exactly are their differences  etc today what we are trying to do is that we are just trying to get a general idea  because there are too many standards 802.11 lan architecture  by now we know that we will have an access point  which is connected to a hub or a switch or a router this is in one cell ; this is another cell so cells may be called a basic service set  also known as cell in infrastructural mode  it contains wireless hosts ? so these are the wireless hosts it contains an access point in an ad hoc mode  there will not be any access station  so they will all be connecting to each other in a peer-to-peer module  refer slide time  11  15  11  46  and in the physical layer in 802.11 family itself you see that there are so many techniques that are used ? fhss  which is frequency hopping spread spectrum ; direct sequence spread spectrum ; orthogonal frequency division multiplexing  ofdm  ; hrdsss is another one ; ofdm and so on above this we have the data link layer  that is  the llc and the mac sub-layer  and above that we have the upper layers  refer slide time  11  47  12  59  so we do not have the time to go into the details of the physical layer technologies  like  how exactly the multiplexing and multiple access is done  but this is just a very broad and high level view of the system we have the input data  which is encoded so that is a channel encoder ; it uses either fsk  that is  frequency shift keying  or phase shift keying  fsk or psk there are other variations of this we will just get a feel of this this feeds into a modulator and then there is a pseudo random pattern generator on the receiver side this is on the sender side  similarly there is a pseudo random pattern generator on the receiver side and these two are synchronized so this modifies the main carrier  and it then goes into the air or whatever the medium ; then it arises at the other end  plus some noise is also added to it  where it is demodulated and it is decoded and then we get the output data  refer slide time  13  00  14  58  now how do we ? glossing over the physical layer ? how do we handle the multiple access of an 802.11 ? it avoids collisions ; that means  we know that when two or more nodes are transmitting at the same time  their signals will collide  and we will have a collision so 802.11 tries to avoid collision it does csma ? if you remember csma is carrier sense multiple access so it does some carrier sensing ; it senses the channel before transmitting of course it does not collide with the ongoing transmissions by other node  but it does not do any collision detection and the reason it does not do any collision detection is that if it has to do collision detection  first of all what would happen is that not all traffic is apparent to all the nodes in the network due to various reasons it could happen so that is one reason that even if there is a collision and if you are doing collision detection  you may not be able to detect it at all so that is why the stress here is not to do collision detection like you do in a wired lan like ethernet  but to avoid the collision alright so it is difficult to receive sense collision when transmitting due to weak received signal and fading etc and it can not sense all collisions in any case ? hidden terminal fading so goal is to avoid collisions so this is called csma ca instead of csma cd we have csma ca that is csma with collision avoidance  refer slide time  15  00  15  58  so this is a diagram which shows you this problem about hidden terminal for example  we have a  b and c now b can listen to c ; a can listen to b  that means  a b can communicate with each other ; b c can communicate with each other ; but between a and c there is some kind of an obstacle so a and c can not communicate with each other even if there is no obstacle like this  the situation could be something like this suppose this is a ; this is b ; and this is c now at the point b  a and b have fairly high signal  whereas at c  a signal strength is very low ; similarly at a  c signal strength is very low some of the terminals may be hidden from some other terminals this is a problem ; that is why our mac protocol is designed to handle  refer slide time  16  00 ? 18  29  situations like these this is a mac overview ; we have a number of boxes here i will not go in to all the details like radio management ; power management ; management information base ; this is for network management ; there is an addressing ; there is a security part  like shared key and association management ; similarly there is a fragmentation of large frames and so on we will not look into all this ; we will just mention that for addressing we use the similar 48-bit mac address  which is ethernet compliant you remember that the ethernet address or the hardware address or the mac address that we talked about when we discussed ethernet  is a 6-byte or 48-bit address and 48 is of course a very large address space ; that means 248 is 256 trillion  which is a very large number so there is no shortage of addresses so a bunch of addresses may be given to these the same kind of 48-bit addresses are used for this also making it ethernet compliant has its advantage because ethernet is just another ubiquitous kind of network another point is that we have an acknowledgement request kind of a system  where some frames and some fragments  etc are acknowledged so if the acknowledgement does not come we have retransmission we also have some error correction ; and radio link security ; data authentication ; data encryption ; simple scrambling ; or peer-to-peer  etc we will not be discussing these as do not have the time in the radio link  there is a question of quality of service there is this csma ca ? we will look into this channel access mechanism in some more detail dedicated real time support systems are also there ; they are with pcf so there are actually two mechanisms  which may be simultaneously present in the same system ? dcf and pcf ? we will be talking about these the standard provides two modes of  refer slide time  18  36  19  33  operation  dcf  which is mandatory that means every 802.11 system has to be following dcf at least so it is a best effort service that uses csma ca ; that is  csma with collision avoidance and there is another mode  which may optional  which is pcf this is a base station this is a distributed control function and this is a point control function this base station controls access to the medium and uses a polling mechanism with higher priority access to the medium so actually  if pcf is there  what pcf can do is that actually pcf can take precision so for dcf  it can give some guaranteed kind of service or quality of service to some users there are three different types of frames  data frames  control frames  and management frames  refer slide time  19  35  20  09  so one is the point coordination function which is pcf the other is the distributed coordination function which is the dcf ok so and how i mean which one you are using may be you are not using pcf at all so that would be a network administrator ? s choice so the if you are using pcf that would give you some contention free service whereas if you are using dcf you are using a service where there may be contention of course you can use pcf and dcf at the same time alright  refer slide time  20  11  22  10  so how does the protocol work ? from the sender ? s side it senses if the channel is idle for difs difs is the period of time which can be configured ; it then transmits the entire frame so it just can not send some thing as soon as the channel is idle ; it has to wait for at least difs amount of time and it does not do any collision detection how does it know that there will not be any collision ? just because you have waited for difs amount of time does not mean that there will not be any collision ; there may still be collision because somebody else may also be listening to the channel waiting for difs amount of time and start transmitting  and you are not doing any collision detection the point is that you will not get an acknowledgement unlike the ethernet system  where there is no acknowledgement  this is an acknowledgement based system so you will get an acknowledgement ; if you get the acknowledgement you know that there is a collision and if you do not get an acknowledgement you know that there is a problem  so you retransmit if  on the other hand  you sense the channel to be busy  then you start some random back-off time  similar to ethernet where you do binary exponential back-off  etc we start random back-off time the timer counts down while the channel is idle  transmits when timer expires if there is no acknowledgement  we increase random back-off interval and repeat step 2 this is the way system works  if there is no acknowledgement  it means that it has not succeeded so you increase the back-off time and repeat another reason why collision detection is not done in wireless network is that for many of the radio systems  it is difficult to do transmission and reception at the same time so collision detection means you keep on doing collision detection while you are transmitting you just keep on listening whether it is going through or there is some garbled message in the medium but that is difficult to do in many systems ; so that is another reason why cd is not done in the receiver it is simple ; if it gets the frame then it returns the acknowledgement  refer slide time  22  51  23  23  sifs is another time interval  which is defined so after some time  it will send the acknowledgement acknowledgement is needed for the hidden terminal problem so there is the sender ; there is the receiver ; and suppose after difs amount of time the sender has sent some data  the receiver has received it after sifs amount of time  it sends back the acknowledgement  refer slide time  23  26  24  48  there is another scheme which uses this rts cts exchange suppose a wants to communicate ? this is the ap and this is b ? so a wants to communicate and let say b also wants to communicate so a sends a request for transmission ? it is just a reservation request b also sends the reservation request at the same time  and there is a collision since there is a collision  none of them will get it actually they will get it by some signal from ap as we will see after some time a may be sending the request again and may be it is has gone through ; so once it goes through ap will issue a cts that now cts a can be sent and please note that cts a not only reaches a it also reaches b and since now b knows that it has been reserved by a  b will back off or defer for a considerable period of time b will defer for quite a bit of time and a will send its data  then a will get its acknowledgement this is an rts cts based scheme  refer slide time  24  49  25  53  this is another example a wants to send data ; so it sends an rts and gets a cts from b a can now send the data by the way  this rts and cts have been detected by c and d also  so what they do is that now they know that somebody is communicating so this nav or network allocation vector it automatically puts itself off this is a very polite kind of system so it automatically puts itself off till it gets the acknowledgement a wants to talk to b  c is in range of a  but d is in the range of b that is why the nav of c starts here  whereas when b sends a cts meant for a  then d catches it and starts it own nav that means it starts its own blocking time ; this is called virtual channel sensing  refer slide time  25  55  27  17  now just to mention how this point coordination function and distributed coordination function work at the same time ? the pfc and dfc ? and why we use difs and sifs ? these two periods of time in difs there are actually three time intervals  which are configured this is difs ; this is pifs for point control function ; and this is sifs please note that when the medium is busy  after that if somebody wants to send  he can not send immediately he has to wait for difs amount of time if pcf is also operating at the same time and pcf wants to send something  pcf has to start doing that within this pifs amount of time so somebody wanted to send and is waiting for difs ; when he gets this  when the pcf grabs the channel  then this other node will defer for a longer time and there is an sifs  after which acknowledgements are sent and after this difs  there is a contention window where there may be a random back-off and the next frame is sent  refer slide time  27  19  28  17  suppose this was the previous frame within sifs  the acknowledgement and the control frame and next fragment may be sent here ; so either acknowledgement or control frame or next fragment is sent here pcf  frames may be sent here that means after pifs amount of time  the pcf or point coordination function will grab the channel if pcf has not done that  then after difs amount of time  it can be distributed ? that means anybody can try to send anything there is another time which is called eifs  for bad frame recovery so sifs is for short inter frame spacing ; pifs is for pcf inter frame spacing ; difs is for dcf inter frame spacing ; and eifs for extended inter frame spacing these are the different kinds of spacing this way this pcf and dcf can work at the same time another point is that if you have a very large frame  there may be a problem in the sense that  refer slide time  28  38  29  45  if a large frame becomes garbled  a large frame has a larger window  where it puts off every body so for better throughput  it may be a good thing to break up a large frame into smaller fragments after an rts cts  it may send as one small fragment ; then acknowledgement fragment to an acknowledgement ; and so on the other thing is that a large frame is more likely to beget errors and if you just do the calculation  you will find that if you break it up  there may be orders of magnitude difference between the error probability of a large frame and a small frame so overall  your throughput may be much better and in an especially noisy situation  your throughput may be much better if you send smaller fragments for smaller fragments  first of all you can do some error handling locally  and you can handle it ? that is one thing secondly  for a large frame  the probability of error is much higher  refer slide time  29  46  32  09  we will discuss just a little bit about the 802.11 frame addressing if you remember  in an ethernet  we had two addresses  the source address and the destination address here  actually very surprisingly  we have four addresses and just to show you why  address 1 is the mac address of wireless host or ap to receive this frame so this is the destination  immediate wireless destination  that is  wherever you want to land up on this wireless link address 2 is the mac address or wireless host or ap transmitting this frame this is the source address  so to say now the point is that  after all  quite often what you want to do is that you are not always interested in the technology used for this wireless transmission you are trying to connect to a network  which is in the outside world so this is what will happen ? this access point will connect to a router  or it may connect to a lan and that lan may be connected to a router so basically what you have to do for going out of this network altogether ? that means not only this wireless part of the lan or the wire part of the lan ? you will have to know the mac address of that particular port of the router  which you want to reach as a next stop then the router will decide to go next so the mac address of that router must also come from the source itself so address 3 is for that mac address of router interface  to which ap is attached and ap may be attached to a lan and it may have multiple addresses address 4 is used only in ad hoc mode ; we will not discuss it there these are the four addresses ; yet another thing is the payload the payload is from 0 to 2 kb these are all in bytes  all mac addresses are in 6 bytes ; mac addresses are 18 bytes just for 3 addresses ; and for 4 addresses it is 24 bytes  refer slide time  32  10  32  33  so this is the picture ? originally we had a just the routers  mac address and ap mac address these two ? destination and source address ? when you are sending from a wireless host the ap mac address  the host mac address  the router mac address are address 1  address 2 and address 3  refer slide time  32  36  33  25  let us now talk about the other fields ? there is a duration of reserved transmission time in the rts cts system that we were talking about  and that we showed you there is a duration of reserved time then there is a sequence control ? this is the frame sequence number for reliable arq since you are doing acknowledgement with retransmission request  you require a 6-sum sequence number for that window we have discussed this and now we have a sequence control number over here then of course  there are other fields it could be frame type ; it could be rts type ; cts type ; or the acknowledgement data subtype we need not go into all of these  refer slide time  33  27  34  23  and then we talk a little bit about the mobility within this  because whenever we are in wireless we want to be mobile if we are going from one from under one ap to under another ap  that means from one bss to another bss there is the basic service set that is from one cell to another  so what the mobile host we will do is that it will sense whoever is stronger and he will connect there so there is some chance of confusion in this but since he handles it  as he moves he will connect from ap 1 to ap 2 but this is assuming that these two aps are in the same network if these two aps are in different networks  then the situation is a little more difficult and we can not handle it at this layer  refer slide time  34  25  37  00  directly we have quickly covered 802.11  which is the most common kind of wireless lan that we see today in many places  we have 802.11 ; actually in some places they are also called hot spots that means this is under some ap  so that if a person is in that hot spot he can connect to the network and there are some campuses  at least some places  where a large number of aps have been deployed so that you are continuously ? wherever you are in that whole campus ? always in the network that is one kind of system  that is  802.11 next we come to another kind of wireless systems  namely wireless man ; that means wireless metropolitan area network what we want to do is that we want to connect an entire metropolis with this ; obviously this 802.11 is no longer sufficient first of all  the power is low actually in 802.11  in order to handle more number of users  we keep the power low so that we have smaller sized cells  etc  but in this metropolitan area network there will be many users in the same cell ; working in that 2.4 ghz ism band will not be sufficient any more so we have to go for a much wider range of frequencies  and for this  we need to go to a higher frequency in the so-called millimeter wave region millimeter wave means when the wavelength is at the millimeter order there is a standard for this wireless man ; this is called 802.16 what we might do is that we might have a large tower because these millimeter waves usually travel in straight lines so what we have to do is that we have to have a line of sight to the base station we have to have a large tower so that everybody can be on the line of sight  and these different base stations may be connected through a wired network  or this base station would be connected to the general network through may be a fiber optic line or something  refer slide time  37  02  37  44  this is the 802.16 protocol stack ; this is orthogonal phase shift keying or quadrature amplitude modulation qm 16 or qm 64 we are not going into these or the different kinds of modulation techniques  which are used there is a transmission convergence sub-layer ; that means how to handle it from here ? once again we do not bother about this we will just talk a little bit about the mac sub-layer common part and the service specific convergence layer we will just talk a little bit about it as i said  so many systems are coming up these days that it will not be possible to handle all of them this is  refer slide time  37  46  39  03  just the frame format there may be a data frame and the control frame the control frame is the bandwidth request frame there is a connection id ; this binds the end points to the system there is a connection id  through which any particular system would get a chance to communicate the first bit defines if it is a data or a control frame ; if it is a data frame  the first bit is 0  if it is the control frame  the first bit is 1 then it says whether the payload is encrypted or not ; 1 or 0 type is the type of the frame there are management frames and things like that ; so c1 is the check sum there is a check sum indication key that is used once again  we need not go in to all the details but it uses crc error correction so header is the header portion ; for the header portion there is a crc and the data connection id etc basically the access to the medium is controlled through this connection id  refer slide time  39  04  39  00  there are different service classes  which are defined in this  one is the constant bit rate service for voice real time ; variable bit rate service  this is a vbr  ; rtvbr or a non-real time variable bit rate service  that means  nrtvbr  for high quality data ; and for ordinary data  email  http  etc  this is the best efforts service there are different service classes in 802.16  and all these are possible because here the mac is simply controlled by the base station the key architectural principle  refer slide time  39  53  41  09  is traffic control by the base station the base station controls the traffic totally it creates frames of time slots and allocates timeslots to connection ids so time slots are allocated by service class this means that if there is a constant bit rate service  what the base station would do is that in every frame it is going to allot one or more slots to this constant bit rate service  so that it gets constant rate updates so whoever reserves or requests that constant bit rate service  if he is not using it at any particular point of time  then it is going empty that is why he has to pay higher for this constant bit rate service similarly there are variable bit rate services  and finally  with just a slightly higher priority than the non-real time one and just the available bit rate service  whatever else is left may be given to those connection ids  which are only getting available bit rate service these are just  refer slide time  41  11  42  07  pictures showing frames and each of the frames will have some slot there are some guard times between the frames some of the slots are reserved for upstream traffic  whereas some of the other slots are for the downstream traffic quite often  what happens is that in this metropolitan area networks or in many networks  the downstream traffic turns out to be much higher than the upstream traffic we all know  for example  if you are surfing the net  which is a very popular activity  you just send one request  which is a very small thing  and in response to your http request  a large page with a lot of graphics  etc  may be downloaded so the downstream traffic turns to be much larger there is a lot of asymmetry here ; that is why there are a few upstream slots and a lot of downstream slots  refer slide time  42  08  42  55  so frames and time slots are for time division multiplexing or duplexing actually it is for time division duplexing  because both upstream and downstream traffics are given some slots duplexing means it is going in both directions base station allocates time slots in frames to connections there are some connection ids  and to a particular connection id  the base station may allocate time slots cbr as i said  constant bit rate services  are of the highest priority rtvbr  that is  real time variable bit rate has the next highest priority ; nrtvbr has the third highest priority this can be delayed and anything remaining is the best efforts contention based access of unallocated timeslots to other kinds of traffic this is how it is done next we move on to  refer slide time  42  56  44  55  another end of the spectrum first we talked about wireless lans ; that means 802.11  and as i mentioned  it has a lot of variations like 802.11 a  b  g  etc so 802.11 is the lan side then we talked about man  metropolitan area network  and now we are going to the other end of the scale  which means very small networks  let us say  personal area networks that means a small area is covered under a network ? between whatever i have in this pocket and this pocket  and my in my hand we will talk about one thing  which is quite popular  namely bluetooth  which is 802.15 so 802.15 is for the personal area network group ; 802.11 is for local area network ; .16 is for metropolitan area network ; and .15 is for personal area network this is less than 10 m in diameter ; so you see this is very small it has a replacement for cables  mouse  keyboard  headphones  etc so whatever i am using may be replaced by wireless links ? that was the idea this is ad hoc ; that means there no infrastructure is necessary this works with the idea of master and slaves ; that means slaves request permission to send to master  and master grants the request so in any such cell or radius of coverage  there will be a master and then there will be some slaves m is the master device  s are the slave devices  and p are the parked devices that means these are inactive at the moment  so they are called parked devices in bluetooth  refer slide time  44  57  46  52  so bluetooth and 802.15 are almost the same there are some small differences  but this not very important it operates in the 2.4 ghz industrial scientific  that is  ism band  and is unlicensed  packet switched  and 1 milliwatt this is a very important issue ? that this uses a very small amount of power as opposed to  let ? s say  500 milliwatt for a cell phone this is low cost ; that means up to 10 m to 100 m range and uses frequency hop spread spectrum ; so fhss is used we will see what kind of an fhss  which divides a frequency band into a number of hop channels  is used during connection  devices hop from one channel to another 1600 times per second ; so you see it is hopping the frequencies very fast so that is one good thing because if some part of the frequency band has noise  it has got better noise immunity because it is hopping such a large number of times there are a large number of channels ? why a large number of channels ? we are talking about a personal area network ; but nowadays i may be using so many different gadgets  etc  when i am using my pc  i may be having a cell phone ; i may be having a laptop ; i may also have a desktop in front of me each of them will have a mouse and all these peripherals ? let ? s say it has a monitor and all these peripherals may be connected in some way through wireless so there may be so many things ; altogether about 79 channels are possible in bluetooth and so they go on hopping in the frequency  refer slide time  46  53  47  28  bandwidth is 1 ? 2 mbps ; we are not looking for a very large bandwidth over here  but this is just more for control and function rather than downloading files it supports up to eight devices in a piconet what is a piconet ? two or more bluetooth units sharing a channel is called a piconet it has some built-in security line of sight transmission through walls and briefcases because of the frequency band which it uses it uses integration of tcp/ip for networking  refer slide time  47  30  47  54  so piconet is a small area network it is ad hoc  which means that a network with no predefined structure there is no predefined structure ; it is based on available nodes and their locations ; it is formed and changed in real time as you can see  these networks are being formed and being changed in real time ; so they may be changing all the time  refer slide time  47  56  48  38  the basic connectivity is point-to-point ; that means from the master to the slave piconet is point-to-multipoint master multiple slaves ; two or more piconets can be connected to form a scatternet by the way  how does a piconet start ? anybody can start it and claim himself to be a master  and the other devices  which are coming in later  will become the slaves so anybody can start and become a master this is one piconet ; this is another piconet ; and they may be connected the two piconets may be connected to a scatternet if you want to have a scatternet  then we have to have a bridge from this piconet to this other piconet so we have a bridge slave  refer slide time  48  39  49  26  so 802.15 version of the bluetooth protocol architecture ? these two are slightly different  but we will not bother about it we have the application profiles ; then we have the physical radio base band and the link manager link manager means the radio link manager  and then there is a middle layer  which is the service discovery  telephony  rf communication  and so on once again  we do not have the time to go into the details of this the idea is that you can switch from one kind of service to another kind of service  depending on the context and situation  refer slide time  49  27  49  38  this is a more detailed picture of the different kinds of protocol let us skip this also  refer slide time  49  39  50  29  in the physical layer  it has 79 channels  each 1 mhz  using frequency shift keying with 1 bit per symbol so it comes out to about 1 mbps per channel of course  this is 1 mbps the individual devices finally do not get a 1 mbps throughput for the payload part  because the efficiency is quite low much of the 1 mbps is taken up with protocol overheads caused by the frequency hopping so this takes about 250 to 260 micro seconds needed to stabilize the radio after the hop so this leaves about 366 bits for actual data  of which 126 bits are headers  leaving only 240 bits for data per slot so what was supposed to be 1000 bits has become 240 bits but for small devices  which are getting locally connected to each other  even 240 bits per second kind of speed may be more than enough but so many different channels are possible ; 79 channels are possible this is just a little bit about the bluetooth frame structure ; we have the access code  and then the header  and then the data  refer slide time  50  49  51  16  and the header will contain the address type  etc  and some flags and some checksum ; also it is an 18-bit header it is repeated three times for a total of 54 bits the access code identifies the master to its slaves ; one master and upto seven active slaves some slaves are in parked mode  refer slide time  51  17  51  28  so these are the system blocks  we have a bluetooth radio ; a bluetooth link controller ; and a bluetooth link manager  refer slide time  51  29  52  00  so two physical link types have been defined  one is synchronous connection oriented link ? between the master and a single slave for audio and data ? and the asynchronous connectionless acl link  point-to-multipoint between the master and all those slaves on the piconet for data only this is for data and this is used for others if some voice channel is there  you can get a synchronous connection oriented link there so that you get acceptable quality of service  refer slide time  52  08  52  24  multiple access scheme is based on fh cdma  that is  frequency hopping cdma high speed of hops and code division multiple access offers the best properties for ad hoc radio systems as i said  79 hop carriers have been defined at a 1 mhz spacing  refer slide time  52  26  52  58  the bluetooth has been designed to allow a large number of independent channels  each channel having only a limited number of participants theoretically  the spectrum with 79 carriers can support 79 mbps  but as we have seen  the efficiency may be something of the order of 25 %  so it will be much less than that different channels have different masters and therefore  they also have different hopping sequences and phases  refer slide time  52  59  53  38  by definition  the unit that establishes the piconet becomes the master as i said  anybody can start a piconet and become his master in bluetooth  the master implements centralized control ; once again we do not try to do any distributed control it is a small system so we do a centralized control by the master communication is possible only between the master and one or more slaves  which means that the slaves do not communicate with each other directly it has to go through by the master the master unit schedules the traffic in both the uplink and the downlink  refer slide time  53  39  54  08  there are various types of error corrections  which are possible this includes both fec and packet retransmission schemes at the base band level bluetooth makes use of three types of error correction schemes  one-third rate fec  sending three copies of each bit with a majority logic ; two-third rate fec  a form of some kind of hamming code ; or automatic repeat request or arq so this is the error correction scheme that is used  refer slide time  54  10  55  54  just now we have talked about three different ends of the spectrum i will just mention one or two more  just to show that there are all kinds of other possibilities for example  after this bluetooth became somewhat popular  there was a group who wondered why not make the radius of operation of this even smaller but here the main emphasis would be on long battery life  so that you put a small battery in a small device and it will just work till the battery ? s shelf life is over it will have a very low power we have the 802.15.4 similarly  there is an 802.15.2 and 802.15.3 we are not covering any of them ; this is just to give you a feeling of the kinds of things  which are going on 802.15.4 is a simple packet data protocol for low rate ; it has no quality of service ; has wireless personal area network ; is a low power  low cost  device so low power and low cost are the most important things naturally you will get low rate also  but for many applications  this may be quite fine the channel access is via carrier sense multiple access with collision avoidance  and optional time slotting it has message acknowledgement and an optional beacon structure ? beacon means the signal  which may be sent centrally to synchronize other systems so three bands and 27 channels are specified  2.4 ghz and 16 channels ; 868.3 mhz and so on  refer slide time  55  56  56  37  it works well for long battery life ; it has selectable latency for controllers  sensors  remote monitoring  and portable electronics for example  a sensor just stays there ; it is supposed to do its work  which is sensing  and may be send little bits of data from time to time so it has a low rate  no quality of service guaranty  etc is required  but low power and low cost are very important that is the focus of this particular group it is configured for maximum battery life ; has the potential to last as long as the shelf life of most batteries  refer slide time  56  40  56  59  so mac uses 64-bit ieee or 16-bit short addresses  using local addressing that means  if it is just locally  you can have your own 16-bit or you can use the full 64-bit ieee address ; it has a simple frame structure  reliable delivery of data  etc  refer slide time  57  01  57  29  so as i said  there are two channel access mechanisms  one is the non-beacon type  where it uses a standard aloha with csma ca  that is collision avoidance  and positive acknowledgement ; or we can have a beacon enabled network  where it is synchronized it has a super frame structure for dedicated bandwidth and low latency setup by network coordinator to transmit beacons at predetermined intervals  refer slide time  57  30  58  14  let us now compare quickly between 802.15.4  which is the low rate and low power one  and 15.1  which is the standard bluetooth  it transmits smaller packets over large network and larger packets over small network they are mostly static networks with many infrequently used devices this is an ad hoc network  which is more dynamic you can do things like file transfer here  which you do not look forward to doing here this may be used for home automation  toys  remote control sensing  etc this may be used for screen graphics  pictures  hands-free  etc so this is a somewhat different niche of application  which is the two groups  but both use wireless with different emphases  refer slide time  58  15  58  55  as i said  there are many standards ? i just listed some of them there are many more  which i have not put over here  802.11 b  which gives 11 mbps ; a  which gives 54 mbps ; g  which gives 54 mbps  but this is backward compatible with b  because b was the one which was most widely deployed in the beginning 802.16 is for a man ; bluetooth has about 30-feet radius ; we have talked about gsm gprs when we talked about cell phones ; it is going to 3g people also talk about of 4g  but nobody knows when even 3g will actually get widely deployed we have just seen uwb  and there are so many others  refer slide time  58  59  59  06  the one last point is that if you have a wireless lan  you would want to have a bridge for connecting the tcp/ip stack  etc we will talk about tcp/ip later on to transmit from one to another  we require a bridge in-between this wlan may be a plain wireless lan extension and the application will sit on top of this we require a seamless support for this bridge ; that is very important there are a large number of such protocols  because there is a lot of interest over there some of these protocols  etc  will tie up some of them and naturally become very widely used and this is one of the most important areas of networking today thank you computer networks prof sujoy ghosh dept of computer science & engineering department iit kharagpur lecture no 24 atm  asynchronous transfer mode  refer slide time  00  44  in this lecture we will start our discussion on another very important technology  namely  asynchronous transfer mode or atm  refer slide time  00  57  00  59  slide time  02  25  03  35 the atm was originally envisioned as a technology  which will solve all problems it is present in the lan  wan and it gives very good quality of service when introduced  it was considered a very ambitious plan unfortunately  it did not work out that way because the standardisation took a lot of time when people from computer world and people from communication world start discussing things and come up with a standard  it becomes very complex and also the cost becomes quite high although the atm made its debut in some local area networks  slowly it has been replaced in most of the local area networks but still it is a very strong and important technology in the wide area network so atm remains in operation in a lot of places today and we will look into this atm  asynchronous transfer mode  now  refer slide time  02  25  03  35  slide time  03  04  03  35 why atm networks ? it is driven by the integration of services  i.e  wires  data  and everything else are integrated into the same kind of network this is the vision of the performance requirements of both telephony and data networking this was called broadband integrated service vision or b isdn telephone networks support a single quality of service and are expensive to boot internet supports no quality of service ; but it is flexible and cheap the atm was developed to utilize the best of both  refer slide time  03  04  03  35  slide time  03  37  04  45 atm networks were meant to support a range of service qualities at a reasonable cost and hence intended to subsume both telephone network and the internet but the cost and complexity turned out to be high and now ip-based technology is going to fill the above role but as we have seen  in many service providers  atm is still present and people are deploying atm networks even today so atm will remain in existence for quite some time  refer slide time  03  37  04  45  slide time  04  47  05  15 let us see in brief the history of atm in the 1980s  a packet research began and in 1986  it adopted the b isdn approach in 1989  a 53-byte cell was permitted  which was a rather small value the communication experts wanted a small value  but computer experts wanted a large value and there was a dispute in 1991  the atm forum was set up in 1992  the atm forum issued its first spec and added user committees in 1996  it approved the anchorage that occurred from then on  death of atm in the enterprise and rollouts in the carrier networks occurred but it is still important today  refer slide time  04  47  05  15  slide time  06  27-06  45 the basic points of atm are that it transmits all information in small  fixed-size packets called cells since they are of fixed size  the switch design becomes easier cells are transmitted asynchronously at high speeds this is basically statistical multiplexing in tdm we saw that one of the advantages of packet networks is that it was more efficient in terms of bandwidth utilization the circuit switch network was less efficient because when there is no communication  the circuit is remaining idle and bandwidth is wasted so the atm tried to address that using statistical multiplexing that means  the size of cell is fixed and these cells can be pushed in any order by the end stations  but the network will be connection-oriented this was necessary in order to accommodate the quality of service that everybody wanted this is asynchronous unlike sdh  which is a synchronous system nevertheless  each cell is 53 bytes long with 5 bytes of header and 48 bytes of payload  refer slide time  06  27-06  45  slide time  07  49  08  05 to make an atm call  a message is to be sent first to set up a connection subsequently all cells follow the same path to the destination so this is just like circuit switching first of all  you have to set up a connection where the connection is not physical but they are virtual circuits that means the path should be found first and then along the path all the atm switches  etc  would reserve some resources for the connection this reservation of the resources in all the nodes along the way constitutes the virtual circuit all the cells would flow through this same path this is a connection-oriented system  but cells are switched for better efficiency it can handle both constant rate traffic and variable rate traffic thus it can carry multiple types of traffic with end-to-end quality of service  refer slide time  07  49  08  05  slide time  09  14  10  01 atm is independent of transmission medium ; we will see later about the different transmission media that are possible it does not prescribe any particular rule for transmission medium they may be sent on a wire or fibre by themselves or they may also be packaged inside the payload of other carrier systems this is a very interesting situation for example  when you are carrying just atm traffic and in-between you have a wan segment which has sdh  the atm cells can be pushed into some sdh container and sent along correctly reversal of this process is also possible suppose there is some sdh traffic and in-between there is an atm link  the vcs can take some constant bit rate service on an atm link so atm transmitted on sdh is possible and sdh transmitted on atm is also possible atm by itself can be used as a transport network so the carriers or the service providers have employed a lot of atm in their backbone so atm is still prevalent  although it is not present in lan or enterprise network  refer slide time  09  14  10  01  the delivery of packets is not guaranteed but the order is as this is circuit-oriented or is a set of virtual circuits  the order of the cells will remain the same  so that the higher layer cells need not be changed for example  ibm suggested 25 mbps for atm nics for taking it to the desktop  but it did not survive one of the reasons for this was the cost the atm nics were more costly the atm switches are costlier than the ordinary  ethernet  switches there were few or no software for atm as most of the software developed was based on ip people were also not ready to move all the software into atm  which would involve high cost and since the market did not expand as expected  the cost remained high for quite some time so this was the difficulty of this approach much of the atm devices operated at 155 mbps  oc 3  or  even higher  622 mbps  oc 12  speeds the standardization process took too long and the resulting technology was too complex  costly  to remain in the cutting edge the basic atm concepts are  virtual circuits  fixed-size packets  cells   which allow fast hardware switching  small packet size  statistical multiplexing and integrated services that means different qualities of services can coexist at the same time with good management and traffic engineering features scalability in speed and network sizes is possible we will look at a few of these in the next lecture  refer slide time  11  03 ? 11  35  slide time  11  03 ? 11  35 atm applications could be atm deployments in frame relay backbones frame relay is one kind of wide area network connectivity  which is now slowly going out  but atms give connectivity to backbones it is also deployed in internet backbones and aggregating residential broadband networks  cable  dsl  isdn  etc   they can feed into an atm switch and then get transported carrier infrastructure for the telephone and private line networks deploys atm  and this is one area where it is still going strong  refer slide time  10  36  12  23  slide time  10  36  12  23 the failed market tests of atm were the atm workgroup and campus networks  atm enterprise network consolidation  and end-to-end atm these did not happen because of software and these did not take off because of cost  refer slide time  12  25  13  36  slide time  12  25  13  36 now we will compare the synchronous  i.e  telephone networks and atm telephone networks are synchronous and we know it because 125 ? s is the frame rate  which is very sacrosanct in this world atm is asynchronous transfer mode phone networks use circuit switching  whereas atm networks use packet or cell switching with virtual circuits in a telephone network  cells from a particular source or information or payload from a particular source will come periodically as shown  whereas in atm they can come any time if the line is free  refer slide time  12  48  13  26  slide time  12  48  13  26 in telephone networks all rates are in multiples of 64 kbps  but with atm service you can get any rate and you can vary the rate with time by programming for the required rate if you require a constant bit rate service of 10 kbps in a data service  it is possible to have a virtual circuit where the reservation of resources would be in that fashion this kind of service is used with current phone networks and all high speed circuits are manually set up atm allows dialling at any speed and rapid provisioning since this is done through software and signalling ; atm allows this as far as telephone networks are concerned  there are lots of advantages of using atm  refer slide time  14  09  14  33  slide time  14  09  14  33 now let us compare atm with data networks atm is ? virtual circuit ? based the path  and optionally resources on the path  is reserved before transmission ip on the other hand is connectionless and end-to-end resource reservation is not possible directly indirectly people are still trying to do that because quality of service remains an important issue rsvp is a new signalling protocol in this ip domain in the internet  which tries to reserve resources there are other ways to do this and one way which has become quite popular is mpls ; and we will talk about mpls in a different lecture  refer slide time  14  39  15  14  slide time  14  39  15  14 atm cells are fixed and are small in size and there is a trade-off between voice and data but ip packets are in variable sizes atm provides qos routing coupled to signalling called pnni internet provides ? best-effort ? service  aiming only for connectivity  refer slide time  15  15-15  41  slide time  15  15-15  41 for addressing  atm uses a 20-byte global nsap addresses for signalling and 32-bit locally assigned labels in cells actually when we are talking about atm  there are two kinds of addresses that are referred one is the atm address  which is 20-byte  160 bits  long it is a huge address and it requires a large address space ; this address space is divided in a particular way  which will be discussed later there are different schemes of addresses  which people tried to subsume in this atm addressing ; this is one kind of atm addressing for setting of a path  this 20-byte address is required but once a path has been set up this address is not required any longer because the path has been set up the only thing is that since this is a virtual path in-between when a node gets a cell  it must know to which particular virtual circuit this belongs so some kind of virtual circuit identifier is required and it is a much smaller address this is another kind of addressing but ip uses 32-bit global address in all packets atm offers sophisticated traffic management and this is one of the strong points of atm and still remains strong in it but in tcp/ip  congestion control is packet-loss based whether the packet is lost or not  atm gives much more sophisticated qos  refer slide time  15  43  17  26  slide time  15  43  17  26 let us see the pros and cons of fixed-size packets pros are that it uses simpler buffer hardware  i.e packet arrival and departure requires us to manage fixed buffer sizes  simpler line scheduling  i.e each cell takes a constant chunk of bandwidth to transmit  and it is easier to build large parallel packet switches  refer slide time  17  29  17  55  slide time  17  29  17  55 the disadvantage is the overhead  i.e for sending small amounts of data at the same time for each cell you have to have this 5-byte header on only 48 bytes so 10 % is already gone on the header and if a large amount of data  may be several megabytes  is to be sent  you need a lot of cells hence overhead becomes important large frames  which are to be sent  have to be broken up into small cells all these cells are to be put together to form the original large frame this segmentation is on one side and the reassembly is on the other side the overhead and the cost will also come in and the last unfilled cells  after segmentation  waste the bandwidth this is not very important  refer slide time  17  56  18  56  slide time  17  56  18  56 when the cell is smaller  an endpoint has to wait for lesser time to fill it so there is low packetization delay when the packet is smaller  the header overhead is larger standard body balances the two to prescribe 48 bytes + 5 bytes  which is equal to 53 bytes therefore the maximal efficiency could be about 90 % only  refer slide time  18  58  19  25  slide time  18  58  19  25 now we will discuss atm layers it was done by a committee in which there was a dispute and the ultimate result was that the atm protocol and its layers  etc were framed these are quite complex atm is the three-dimensional figure and now we will talk about some of the important sub-layers in it on the control and management side of it  there are number of layers and on data side there are number of them  refer slide time  19  26  21  18  slide time  21  19  22  23 the layers are  cs  the convergence sub-layer  sar  the segmentation and reassembly sub-layer these two layers put together is the atm adaptation layer  which is called aal there are different kinds of aals aal 1,2,3,4,5  etc but they all have these two sub-layers then we have the atm layer and this is somewhat in-between the data link layer and the network layer the transmission convergence sub-layer  in which the transmission will come and will be put back  and the physical medium dependent sub-layer  pmd  together form the physical layer  refer slide time  21  19  22  23  slide time  22  23  23  03 in the above slide  there is an atm adaptation layer  an atm layer and a physical layer in the end system this is a very simplistic view of the atm layers there are other layers for control and management function  which will be dealt with later there are two end systems communicating from the atm adaptation layer the atm adaptation layer will readily communicate with other higher layers of the software it will come through this aal  physical layer  then go only up to the atm layer and then go to the other side this is a simple view of a stack  refer slide time  22  23  23  03  slide time  23  03  23  27 atm layer ? s adaptation is mapping of application  e.g  voice  data  etc  to atm cells the physical layer could be sonet or it could simply be a dwdm system atm layer handles transmission/switching/reception  congestion control  cell header processing  sequential delivery  etc  refer slide time  23  03  23  27  slide time  24  40  25  03 now let us discuss about the layers in detail the top one is the top sub-layer of the aal  atm adaptation layer   the convergence sub-layer it offers different kinds of services to different applications here the different types of services are supposed to converge and all of them are supposed to do atm so for convergence this atm adaptation layer is used for example  for a voice channel  constant bit rate traffic is required ; and similarly for data  some other kind of traffic is required so different classes of services were defined depending on the kind of aal  aal 1,2,3,4,5  etc  and the convergence sub-layer negotiated that and came to a bandwidth contract so the different services that are offered are the cbr  which is constant bit rate or bandwidth guarantee  and which is suitable for real time traffic abr is for available bit rate  suitable for bursty traffic and feedback  bout congestion ubr  which is unspecified bit rate  is the cheapest of all and suitable for bursty traffic  may be data traffic it provides a specific aal service at an aal network service access point  nsap    refer slide time  24  40  25  03  slide time  25  34  26  16 nsap refers to network service access point the other sub-layer of aal is the segmentation and reassembly sub-layer it segments higher level user data into 48-byte cells at the sending node and reassembles cells at the receiving node this sub-layer is usually implemented with asic one of the reasons atm was envisioned as a system  which will really scale to very high speed  is that cell segmentation and reassembly is to be done very fast usually it is done with the help of asic asic is an application specific ic for doing the segmentation and reassembling it tears down messages passed from the upper layer and converts them to cells some padding may be necessary to make it a multiple of 48 bytes at the destination the stream of cells are reassembled  refer slide time  25  34  26  16  slide time  26  30  26  50 the different types of aal are aal 1,2,3,4  and 5  which give different classes of service  class a  class b  class c and class d class a is connection-oriented cbr  e.g voice  and it is supported by aal1 class b is connection-oriented vbr  e.g packet based video  supported by aal2 class c/d may be connection-oriented vbr  e.g file transfer   connectionless vbr  e.g lan data  supported by aal 3/4  i.e aal 3/4 may be connection oriented vbr or connectionless vbr aal 5 is a simple and efficient adaptation layer  seal  supporting class c/d for bursty error control at higher-layer protocol these aals are complex since atm got into the service providers ? backbone but many of these aals  etc were never widely deployed  refer slide time  26  30  26  50  slide time  27  03  27  53 the convergence sub-layer  cs  interprets the type and format of incoming information based on 1 to 4 classes of service assigned by the application class a is constant bit rate  cbr   it is connection-oriented and there is strict timing relationship between source and destination  i.e voice if such a very sensitive quality of service like voice is required  class a service can be used but class a service is more costly  refer slide time  27  03  27  53  slide time  27  54  28  15 class b is variable bit rate  vbr  service and connection oriented it has strict timing  e.g packet mode video for video conferencing class c is connection oriented vbr but without a strict timing service so there is a slight difference between class b and class c ; e.g lan data transfer applications class d is connectionless vbr with no strict timing ; e.g lan data transfer applications such as ip for example if it is frame relay  then the person who had taken this frame relay service should have some original negotiation about the speed so class c is a little better than class d  but not better than class a or b  refer slide time  27  54  28  15  slide time  28  17  2  32 aal 5 was introduced for data services it supports both message mode and stream mode in the message mode  a packet of length up to 65 kb may be passed to the aal layer to have it delivered to the destination either on a guaranteed or ? best-effort ? basis  refer slide time  28  17  2  32  slide time  29  53  30  20 the service categories available are abr  ubr  cbr and vbr abr is available bit rate in this source bit rate  source follows network feedback and there is maximum throughput with minimum loss hence the network gives some feedback this is just to give you an idea about how quality of service is handled in atm because a lot of things which were learned in atm are also employed today in some other guise in mpls or some kind of very new ip technology how quality of service can be guaranteed still remains a very important issue in networking today as people are talking about convergence of voice  data  video  etc  into the same network  we require some guarantee about quality of service whatever happens in the pure data network like delay or jitter etc may not be acceptable for this kind of service so for convergence  quality of service is important and atm offered a good quality of service ubr  unspecified bit rate  is of course the cheapest of all the user sends anything with no feedback and no guarantee cells are dropped during congestion between ubr cells  refer slide time  29  53  30  20  slide time  30  20  31  00 cbr  constant bit rate  is one in which the user declares the required rate for this  throughput delay and delay variation are guaranteed in vbr the average and maximum rates are declared it has two different types one is real time vbr for voice  conferencing  etc with maximum delay guaranteed and the other is non-real time vbr for stored video  refer slide time  30  20  31  00  slide time  31  01  31  35 let ? s compare abr and ubr in abr  the queue is in the source because the source takes the feedback from the network and adjusts the rate in ubr  the queue is in the network in abr  if the queue gets filled it gets dropped and pushes congestion to the edges in ubr  there is no backpressure because if there is pressure  the ubr will be dropped abr is good if the network is end-to-end atm ubr is the same whether it is end-to-end atm or backbone to atm abr is very fair and good for the provider and ubr is simple for the user but ubr is generally unfair even though it is simple for the user  refer slide time  31  01  31  35  slide time  31  38  31  45 there is also a concept of guaranteed frame rate  gfr   it is a ubr with a minimum cell rate  mcr   it will try to guarantee this minimum cell rate but beyond that  it is ubr so gfr is a frame-based service or guaranteed frame rate service in this  complete frames are accepted or discarded in the switch  and traffic shaping is frame-based all cells of the frame have the same cell loss priority  clp   whether they are inside the mcr or not  refer slide time  31  38  31  45  slide time  31  47  33  10 all frames below mcr are given clp = 0 service  and all frames above mcr are given best effort clp  i.e clp = 1 service  refer slide time  31  47  33  10  slide time  33  10  34  01 having talked about the different types of quality of service that are available in atm  now let us look at the atm layer and then we will look at the data link layer of atm atm layer is akin to the network layer of osi  although it has data link layer characteristics as seen already  this is somewhere in-between network layer and data link layer atm uses globally unique addresses using the nsap format of iso this is used for setting up connections path and circuit identifiers are used once a connection is established  refer slide time  33  10  34  01  slide time  34  05  34  15 atm interfaces are different types of interfaces designated in the standards one is a computer connecting to a private switch there is a hierarchy of switches like private switches and public switches here computer in the lan may be connecting to a private atm switch for this there is a private uni or private user network interface similarly when a private switch is connected to public switch there is a public uni  that is  a public user network interface public switches talk to each other using the interface called nni  network node interface    refer slide time  34  05  34  15  slide time  34  40  35  08 uni is the user network interface  public and private   nni is the network node interface  private and public   pnni is public nni b ici is broadband inter carrier interface between two carriers so if there are two different carriers  there is an isi defined for that dxi is data exchange interface with a router  etc different interfaces were defined but some were not fully defined because they were not very widely deployed  refer slide time  34  40  35  08  slide time  35  33  35  55 there is a hierarchy of switches in the carrier  there are the carrier backbone switches and carrier edge switches in the service provider frame or central office enterprise switches  which stopped at the carrier edge switches  lan or campus backbone switches and the workgroup switches are in the customer frame actually the hierarchy of switches means they are all basically atm switches with different interfaces ; different software and different protocols are given and these links differ depending on where that switch is  refer slide time  35  33  35  55  slide time  35  56  36  29 let ? s see the physical layer functions of atm it transports atm cells on communication channels and defines mechanical specs like connectors  etc there are two sub-layers one is the pmd or physical medium dependent sub-layer it has medium dependent functions like bit transfer  bit alignment  optically electrical optical  oeo  functions  etc  refer slide time  35  56  36  29  slide time  36  48  37  08 the other sub-layer is the transmission convergence sub-layer it maps cells into the physical layer frame format like ds 1 or sts 3 on transmit and delineates atm cells in the received bit stream it is a wavelength  which generates hec  i.e header of cells for transmission it generates idle cells for cell rate decoupling or speed matching based on the kind of transport it is using  all these speed matching  etc  have to be done and hence  this sub-layer is called transmission convergence sub-layer  refer slide time  36  48  37  08  slide time  37  12  37  20 let ? s see the physical layers of atm in atm no particular medium was specified and so many media are possible starting from multimode fibre  100 mbps using 4b/5b   155 mbps sonet sts-3c  155 mbps using 8 b/10 b  single mode fibre using 155 mbps sts-3 c  622 mbps  plastic optical fibre using 155 mbps  shielded twisted pair using 155 mbps 8 b/10 b to coaxial using 45 mbps  ds3  155 mbps  refer slide time  37  12  37  20  slide time  37  23  37  40 other media starting from unshielded twisted pair  utp 3  phone wire  at 25.6  51.84  155 mbps  utp 5  data grade utp  at 155 mbps to ds1  ds3  etc  are also possible  refer slide time  37  23  37  40  slide time  37  41  38  43 actually a serious attempt was made to inter-operate with several l1  l2 and l3 technologies however  since atm survived only in the service provider ? s backbone and at the edge fibre  the single-mode fibre remains the most important medium today  refer slide time  37  41  38  43  slide time  38  45  38  56 how is atm sonet mapping done ? atm sonet mapping is done because atm may finally get carried by a sonet transport at some point in the wan in a good and easy manner in a sonet there is a pointer pointing to the beginning of the payload and this payload can actually be anywhere in the frame these cells are packed in the frame so cells are mapped row-wise into the frame cells could contain data or be empty some empty cells might have been put over there for late matching  refer slide time  38  45  38  56  slide time  41  08  41  45 since atm is coming at a particular rate  depending on what rate it is  the atm is connected to the next using an sdh transport at the user end atm has to give some guarantee about bandwidth  etc it has to do some provisioning and for that it carries the provisioning across this sdh link sdh is not very difficult because  depending on what speed or what rate is required  the next higher-sized container is chosen sdh  as you know  can accommodate various types of containers like vc 1  vc 2  etc so it can have various types of containers  various rates  etc  and tributaries you take the kind of container that gives guarantee about the rate this is how the service provider provides the virtual link the container may be in the infrastructure of the same service provider or it may be in the infrastructure of some other service provider then we can negotiate and configure the sdh switch so that the atm stream will get the kind of bandwidth across the sdh part of the backbone so this link is a virtual one the atm contains a number of virtual paths and each virtual path contains a number of virtual circuits one particular pair of users is using one particular virtual circuit so that virtual circuit would be identified with a vc number known as a virtual circuit identifier and a vp number or the virtual path identifier for good management function  atm is divided into virtual paths and virtual circuits  refer slide time  41  08  41  45  slide time  42  07  42  54 atm cell structure has 48 bytes of payload and 5 bytes of header the header contains so many fields there are 16 bits or 2 bytes for the virtual circuit identifier  vci  and 8 bits or 1 byte for the virtual path identifier  vpi   the virtual path and the virtual circuit together will define a particular stream  a particular atm stream coming from a particular virtual circuit which is originating from some particular user somewhere then there is an 8-bit hec  refer slide time  42  07  42  54  slide time  42  55  43  35 this structure of the cell header shown is not constant across all interfaces gfc is present in uni  but in nni this gfc has been dropped and vpi is increased vpi is only 8 bits in uni but is 12 bits in nni when you are doing network node interface  a lot of paths  etc are coming ; you require more bits for identifying the path and so there is 12 bit of path identifier in uni there is 12 bit of vci identifier  but only 8 bit of path identifier is present in nni  refer slide time  42  55  43  35  slide time  43  35  43  56 now let us discuss about atm cell format the first one is generic flow control  gfc   once again this was put there with some idea but it was not used much this has 4 bits and is used for local flow control between the network access point  typically a switch belonging to the network provider   and one or more end stations this is used for multiple access for more than one station and for reducing the transmission rate for single nodes  etc this is used to do some local flow control at the lan end between the switch and the users but this is usually ignored  refer slide time  43  35  43  56  slide time  45  45  46  06 vpi  the virtual path identifier  has 8 bits ; but since gfc is irrelevant within the network  12 bits are used these may be thought of as the high order bits for the virtual channel identifiers a virtual path contains a number of virtual channels the switches store per path parameters so that individual channels do not need any signalling so  one pair of users is using one channel  one virtual circuit this virtual circuit has to be identified and then given some kind of bandwidth contract some kind of class of service will be negotiated for this in a big atm network  thousands or even millions of circuits may be set up and toned down at a very high rate as many people are using millions of switched circuits under a service provider these virtual circuits may be set up and toned down in a very short time theoretically with each of these virtual circuits  some kinds of quality of service parameters have been negotiated but these are grouped together for the similar kind of services and these virtual channels are put together so that only paths are to be stored to avoid implications in finding and routing  some of these virtual circuits are put together to form virtual paths we have the vpi identifier for this this vpi has the higher order bits specifying the channel  and the lower order bit specifying the vci  refer slide time  45  45  46  06  slide time  46  12  46  42 however  if a virtual path is already set up and is scantily used  then resources are wasted so  dynamic renegotiation of vp capacity can be used vci  the virtual channel identifier  is 16 bits vc 0 to 15 are reserved for special purpose  and others are used for actual communication  refer slide time  46  12  46  42  slide time  47  05  47  10 pt is the payload type  which is of 3 bits if high order bit is 0  the second bit indicates congestion and third bit indicates end of aal 5 frame 100 and 101 are reserved for link management clp  cell loss priority  bit is used by the source for making priority intermediate switches may mark it for violating agreements depending on whether clp = 0 or clp = 1  the cells may be dropped or not dropped in an intermediate switch hec is an 8-bit header checksum this is very important in checking whether the header has an error this has some other function  which will be dealt with in data link functions in atm  refer slide time  47  05  47  10  slide time  47  18  47  38 the next sub-topic is data link layer in atm this consists of the transmission control layer  refer slide time  47  18  47  38  slide time  47  40  48  06 each atm cell has a 5-byte header  in which the last field  hec  is a checksum for just the header the tc takes the cells from the atm layer  adds an hec to them and sends them as bit streams to the pmd on the transmission side the bit streams may or may not have a separate transport  refer slide time  47  40  48  06  slide time  49  17  49  44 on the receiving side  the incoming bit streams are formed into cells and passed on to the atm layer here the cell boundaries are to be detected it also discards cells with invalid headers and processes oam cells for administration management and control one problem which came up was the atm forum wanted the atm to be deployed everywhere from the backbone  provide a switch right down to the user so nothing much was specified about the physical layer since they wanted neutral to the kind of physical medium through which the atm will pass  another problem came up with receiving the bit streams cell starting and cell ending couldn ? t be identified on the receiving side  refer slide time  49  17  49  44  slide time  51  00  51  12 in some cases  the underlying physical layer helps for example  when atm cells are carried over sonet or sdh  the spe pointer in the sonet header points to the first full cell so we immediately know where it starts in other cases every 40-bit sequence is tested for being a valid header the 8 bits at the extreme right will be valid hec for the remaining 32 bits hec has two functions one is that it gives you some checking mechanism on whether the header is correct or not and the other is for synchronization function when a bit stream is coming and if it is 40-bit long  it is taken now if these 40 bits happen to be the header  the last 8 bits will be the checksum  assuming that the entire header has come correctly so the last 8 bits would be a checksum for the other 32 bits in the header if it is a header with an error  it is neglected then  the next 40 bits are taken and tested again  assuming that a header has come correctly  refer slide time  51  00  51  12  slide time  52  40  53  27 the tc goes through a hunt ; this is the hunting phase and once it gets a header it gets into the presynch stage it has one header but  out of 40 bits  8 bits are the checksum of the other 32 bits so the probability is that this was not a header but a user payload and was wrongly interpreted as a header because these 8 bits matched the checksum for the other 32 bits so  now it goes into the presynch stage if this is indeed the header  then the first 5 bytes would be the header  the next 48 bytes would be data and the next 5 bytes would again be a header and you continue checking this for some time this is a presynch stage when this synchronization is done for some time and you are reasonably sure that this can not be a coincidence in the data given by the user  then we are indeed locked on to the header and now tc is synchronized the tc goes through the hunt  presynch and synch stages to detect the cell boundaries if the number of hecs is found to be incorrect then tc is said to have lost synchronization then it has to be resynchronized this heuristic defies the layered architecture  refer slide time  52  40  53  27  in this simple state diagram  the signal is in the hunting stage at this stage the signal looks at every 40 bits and tries to figure out whether it could be a possible header or not when correct hec is detected it goes to the presynch stage if correct hec is not detected  the signal goes back to the hunting stage if a few consecutive correct hecs are found  then it is synchronized if a few consecutive incorrect hecs are found  then the tc will determine that it has lost synchronization and it will go back to the hunting phase in the next lecture we will talk first about atm addresses  atm routing  etc preview of the next lecture lecture no 25 atm signalling routing and lan emulation in the last lecture we discussed atm technology we saw  how it handles cells  how it make cells  etc now  in the first half of this lecture we will discuss atm signalling and routing ethernet networks and other kinds of networks are ubiquitous in the second part  we will discuss about how an ip network and an atm network will interoperate when we use atm as the backbone  refer slide time  55  03  55  09  slide time  55  11 ? 55  36 next we will discuss atm signalling  routing and lan emulation  refer slide time  55  11 ? 55  36  slide time  55  38  55  42 atm connections are of various types  the most predominant being the switched virtual circuit  in which a path is set up and taken to the destination the other one is permanent virtual circuit which is pre-coded there are also other connection types like simple point-to-point connection  symmetric or asymmetric bandwidth connection  uni or bi-directional   point-to-multi point connection  uni-directional  and data replicated by the network  refer slide time  55  38  55  42  slide time  55  43  56  53 this is an example of a point-to-multi point network  refer slide time  55  43  56  53  slide time  56  54  57  28 in an atm connection set up  a signal is set up where the source and the destination are shown there are intermediate switches in between from the source there is a set up signal which goes to the intermediate switch the switch sends back some kind of an acknowledgement saying that the call is proceeding and sends the set up signal to the next hop and so on each of them will immediately send back some kind of acknowledgement and then when the call is accepted a connect signal will start flowing in the opposite direction when it reaches the source then a connect acknowledgement will flow and for this connect signal the circuit is set up alternatively the destination may reject the signal and then it will send a region release signal back  refer slide time  56  54  57  28  slide time  57  29  57  31 on the other hand  when the circuit is as shown above  for taking it down the source will send a release when it finishes sending it will send a release till it reaches the destination the destination will then send a release all the way back the release could be initiated by the sender or the release could be initiated by the destination  refer slide time  57  29  57  31  slide time  57  33 ? 58  13 then connection gets terminated and the release is completed  refer slide time  57  33 ? 58  13  slide time  58  15 -51  20 min there is another approach to this not using lan but using classical ip over atm the definitions for implementations of classical ip over atm are described in rfc 177 this rfc considers only the application of atm as a direct replacement of the ? wires ?  lan segments connecting ip end-stations  members  and routers operating in the classical lan-based paradigm issues raised by mac level bridging and lan emulation are not covered here  refer slide time  58  15 -51  20 min  when we look at classical ip over atm  address resolution and encapsulation are the two issues which are to be considered encapsulation consists of putting appropriate atm header/trailer to a packet  converting it to a number of cells and then sending it this means that when you have an atm packet and a classical ip is running over atm and you have got a big packet  you have to break the cells up and put a proper header on each of them and then send them atm features are not utilized and inter network traffic handling is clunky computer networks prof sujoy ghosh department of computer science and engineering iit  kharagpur lecture-25 atm signaling  routing and lan emulation  refer slide time  00  35  we have looked at atm technology in the box  in the sense that how it handles cells  how it makes cells today  in the first half of this lecture or first part of this lecture  we will discuss atm signaling and routing since ethernet networks and other kinds of networks are ubiquitous  everywhere  if atm is used in a backbone  how they would interoperate between an ip network and an atm network we will talk about that in the second part of this lecture  refer slide time  01  23  01  30min  so today we talk about atm signaling  routing  and lan emulations  refer slide time  01  31  04  43 min  the first concept is that atm uses virtual circuits ; that means there are two ways to use packets  carry entire destination address in header  or carry only an identifier  also known as label labels have local significance  addresses have global significance signaling protocol fundamentally maps global addresses or paths or sequence of addresses to local labels we will discuss this in much more detail when we discuss routing of ip packets  which we will take up after this lecture usually when you have a packet switching network  then each packet is considered in one extreme  that is  in the ip end each packet is considered on its own that means each packet must contain the destination address at the very least it also contains the source address that is different ; so it must contain the destination address  so that looking at each packet  an intermediate router would know where it should go that is one end of the spectrum  whereas in the connection-oriented system we know that the physical connection is set up in atm we set virtual circuits or virtual paths in virtual circuits or virtual paths  what happens is that these atm cells are very small  only 53 bytes long each of the cells will contain some local label ; so a path is set up now setting up a path in atm means that each of the intermediate switches would know that a flow of cells is going to go through them ? from one source to some destination they make provision to accommodate this flow ; they make provision for the virtual circuit  and then  once they do that  they set up this virtual circuit in the starting phase after that  each of the cells need not contain any specific identifier or specific address for the destination it just needs a small address  which tells the intermediate switches which virtual circuit to use it contains a virtual circuit identifier actually it is divided into two parts as we have seen in the cell header  we have the vpi part and the vci part simply looking at that label  the intermediate switch would know which virtual circuit to use  refer slide time  04  44  05  10 min  before this virtual circuit  we see that we have the samples suppose we have the data in the atm cell  the data would be preceded by simply the virtual circuit identifier and this might have two parts  vpi and vci  whereas in a regular datagram the entire address may have to be there in each packet  refer slide time  05  11  06  57 min  in vpi/vci assignment used in this case  all packets must follow the same path unlike a datagram  because this virtual circuit is set up before any actual flow of packets begins there is a time for the circuit set up and this circuit is not a physical circuit we have in a telephone network ; but this is a virtual circuit  that means each of the intermediate nodes simply knows that a flow is about to begin so this has to be set up once this is set up  all packets would flow through the same path switches store per vci state  e.g qos  quality of service  information about this particular vci signaling implies separation of data and control when we do atm signaling  we are talking about setting up the entire path we will come to that ; small ids can be looked up exactly much quickly in hardware ? that is one good thing if you have a small vci  that means  virtual circuit identifier  it can be looked up very quickly in a hardware ? this is a bottle neck in a router this can be handled very fast  it is harder to do this with ip address that means this longest prefix match ? we will come to that later on the setup must precede data transfer this is the other disadvantage of this ? the vpi and vci must be set up  which means it delays short messages there are two types of virtual circuits  switched and permanent virtual circuits  refer slide time  06  58  07  43 min  this is an example  the switch knows in the input ports say 1 and 2  1/37 if these are the vpi or vci identifiers  out will be through port 3  1/35 similarly port 1 for 34 will go to 4  2/56 and so on there is a table which simply quickly matches the vpi/vci values and puts it on another vci/vpi pair on the other side this is how vpi/vcis are assigned and used  refer slide time  07  44 10  16 min  we now come to atm addresses this address is different from the vpi/vci ; that is  the virtual circuit identifier/virtual path identifier  which is simply local but for setting up the path  initially you require an address  and you can not do with a local address you have to do with a globally consistent address this global address of atm is 20 bytes long there is a 20-byte long atm address  which you use for setting up a circuit i mentioned previously that there are two types of circuits  switched virtual circuits and permanent virtual circuits in permanent virtual circuits  a path is set up initially manually the path remains a permanent virtual circuit whenever there are two end points between which a lot of traffic will flow  you may skip this overhead of path set up and set up a permanent virtual circuit ; this is like a leased line whenever there is something to go from this source to that destination  it will simply use the pre-existing permanent virtual circuit or otherwise  we may have a switched virtual circuit that means this virtual circuit is set up on the fly  as the network is being used in an atm switch  hundreds of thousands or may be millions of virtual circuits may be set up or taken down every second this is a very fast process for setting up this virtual circuit  we require an atm format and this is 20-byte long address unlike an ip address  which is only 4 bytes  this is 20 bytes this is a very long address  left to right hierarchical in this  there are level 1  level 2 level 3 and level 4 the first two levels have a 13-byte prefix  this are the levels of hierarchy this part is usually used for the actual network addressing inside since it is such a long address   refer slide time  10  17 11  56 min  it can accommodate various schemes atm was conceived as a technology  which will subsume and absorb all pre-existing technologies the people who designed atm tried to accommodate different kinds of addressing schemes in one super addressing scheme  which they say is atm addressing scheme as you see here  there are different types of addresses possible since there are 20 bytes  it is possible to have more number of schemes these are the schemes 1 byte + 2 byte 3 + 10  13 ? this is supplied by the network these 6 bytes are end-system supplied and not used in routing this may be used inside the host ; 1 byte for maybe de-multiplexing inside these network supplied parts are 1 byte  which indicates the scheme the three nsap  network service access point address  formats are dcc  icd  and e.164 or icd number or dcc number this is a data country code  which uses 2 bytes and 10 are used for the other part of the network  refer slide time  11  57  13  07 min  actually here  authority and format identifier is the first thing so 39 is iso dcc ; 47 is british standards institute icd ; and 45 is itu isdn  which means that this e.164 is actually an isdn number isdn uses 15 characters  i.e 15 binary coded decimals  that is  7 ? bytes this entire isdn number  which again can subsume telephone numbers  can be put over here isdn uses e.164 numbers atm forum extended e.164 addresses to nsap format and e.164 number is filled with leading 0s to make 15 digits  that is  af16 is padded to make 8 bytes instead of 7 ? bytes end system identifier is the other part this is the end system identifier part  and these 6 bytes could be various things  specifically  refer slide time  13  08  13  42 min  this 6 byte could be 48-bit ieee mac address remember the mac address that we used in the data link layer is 6 bytes  supplied by ieee the entire 6 bytes can straightaway be incorporated in the low order bits of the address selector is for use inside the host ; all atm addresses are thus 20 bytes long there are various ways you can route this atm ; given an atm address there are various schemes possible  refer slide time  13  43  14  03 min  since various schemes are possible  atm addresses could be of variable lengths and have an initial domain part and a domain specific part the initial domain part consists of two fields as we have already mentioned  afi  that is  the authority and format indicator   refer slide time  14  04  14  15 min  and idi  that is  initial domain identifier this identifies the domain within the purview of a given addressing authority  refer slide time  14  16  16  18 min  in a particular format  say icd  international code designator   all addresses have a unique fixed length prefix the high order dsp or the high order bits of domain specific parts roughly correspond to the low order part of network number in ip ; esi is the second this particular scheme can subsume a lot of other schemes  which were possible the reason for showing this in this fashion is that a similar thing was tried later on in ip version 6 we have a very large address field where a lot of previous schemes could be subsumed in this one of the difficulties with this ip addressing scheme was that it was done in a very haphazard manner  unlike the telephone number for example  the telephone numbers are geographically distributed that means  you put particular first few digits and that will immediately indicate which country and region you are calling it is easy for the router to just look at the first few digits and send it to the trunk but that is not possible in the ip version 4 which is used  because it has no geographic correlation you have to take keep a very long table and look into the table once again when people developed this atm addresses or the ip version 6  they tried to bring back some order into this addressing scheme  refer slide time  16  19  16  36 min  for setting up connections  ip atm supports both permanent virtual circuits and switched virtual circuits pvcs are pre-coded in each switch along the way and are always present they are like leased lines  which do not need any connection setup  refer slide time  16  37  17  06 min  for connection setup there is a user network interface or uni  and the network interface  which is the nni there is a part called q.2931  which is an itu protocol for setting up paths and this sscop means service specific connection oriented protocol you have the aal and atm these layers have already been talked about earlier  refer slide time  17  07  17  49 min  unfortunately this whole scheme turned out to be quite a complex one we will not go into all the details we have already seen the atm layer and the aal layer  which is in the user plane today we are going to talk a little bit on this control plane  which has one service aal and three parts  sscf  sscop and aalcp or aal common part for setting up the circuits  etc  we have q.2931  bisup and pnni or public network-to-network interface  refer slide time  17  50  18  30 min  uni is the user interface of the atm networks and consists of signaling protocol for setting up circuits of a certain quality and the format of the cells the nni deals with the issue of signaling and data transfer as well as routing  data transfer  operations and management remember there is also a slight difference between the cells which go through in the uni part and this nni part in the nni part  the gfc is dropped and we use the whole thing to accommodate more number of virtual circuits ; but that is a small technical point  refer slide time  18  31  19  01 min  if you look at the control stack  that is  control plane stack  we have this q.2931 sitting on this sscf  this saal  that is  service atm adaptation layer  which sits on the atm layer  which again is on some physical layer  there is a virtual link between two atms  aalcps and so on between a stack from the source to the destination or from one hop to the other  refer slide time  19  02  21  14 min  let us see what q.2931 is we will not go into this  once again the protocol is quite complex we will just touch upon some aspects of it this is an itu protocol for setting up a connection first it sends a request in the meta signaling channel 0 to negotiate a quality of service for a signaling channel what is done is that  for setting up the circuit  you have to do some communication this communication again will be through atm actually for that  it will require some kind of virtual path and virtual circuit atm is quite strong on quality of service there is a question of quality of service of the service channel also although the service channel would be used for a very short time  once the circuit is set up  that service channel may be released there is a meta signaling channel called 0  where you can negotiate the quality of service for the weak signal channel with the quality of service otherwise  there is a default which is vp0  vc5  that means  virtual path number 0 in virtual path number 0  which is a bundle of circuits  take the vc 5  which is a standard channel  where you put your request for signal  for setting up the path now if this is successful  then a new vc is assigned for connection setup requests and replies then you first make the request in this channel then a new vc would be assigned for this particular connection setup q.2931  if you remember  is at the top of the control plane protocol stack  which initiates at the setting up of the circuit and handles setting up of circuits  refer slide time  21  15  21  59 min  below the q.2931 we have the signaling aal ; that means  signaling atm adaptation layer  which again contains three parts  service specific coordination function  which provides interface q.2931 ; interface between q.2931 and the atm stack ; service specific connection-oriented protocol  which is the sscop ? this handles error  loss and recovery all these are communications for setting up circuit for communication for the control purpose and the aal common part  which handles error detection this is roughly the stack  refer slide time  22  00  23  59 min  there are various kinds of parameters in the forward direction and in the backward direction there are various parameters that you can specify for the quality of service with atm  when it was introduced  a serious attempt to handle the issue of quality of service was made it has now become so important that in the ip domain also  which is turning out to be the dominant technology  quality of service has become important people have thought of various schemes for handling quality of service many of the schemes that people had already thought about with atm have been adopted in various ways we will talk in detail about quality of service later on today  we will just touch upon it ; there are various parameters like peak cell rate ? that means the peak rate at which you will be pumping inside ; sustainable cell rate ; maximum burst size ; etc all these different parameters can be negotiated for one particular virtual circuit when a path is set up along the way  each of the atm switches on the way makes some provision for supporting that particular new virtual circuit with that kind of service if it can not handle that  may be some negotiation about it can be handled leaky bucket is some kind of congestion control algorithm we will discuss it later  refer slide time  24  00  24  29 min  atm connection types are of various types ; the most pre-dominant ones are the switched virtual circuits  where you set up a path and take it down ; or permanent virtual circuit  which is pre-coded there are other connection types  e.g simple point-to-point connection  symmetric or asymmetric bandwidth connection  point-to-multipoint connection  data flow in one direction only  or data is replicated by the network  refer slide time  24  30  24  35 min  so this is an example of a point-to-multipoint network  refer slide time  24  36  25  45 min  when you do an atm connection setup  you set up signal and maybe this is the source and this is the destination these are the intermediate switches from the source  there is a set up signal  which goes through the intermediate switch  which sends back an acknowledgement saying that the call is proceeding and sends a set up signal to the next hop the set up signal is then sent to the next hop and each of them immediately will send back an acknowledgement when the call is accepted  a connect signal will start flowing in the other direction and when it reaches the source  a connect acknowledgement will flow and each of them will give this connect acknowledgement for this connect signal the circuit has now been set up or alternatively  the destination may reject it ; then it simply sends a region release kind of a signal  refer slide time  25  46  26  23 min  for circuit setting up and for taking down a circuit  the source will send a release ; that means he has finished sending release and release complete will go on then finally the destination will send a release all the way back a release could be initiated by the sender or the release could be initiated by the destination also  refer slide time  26  24  26  28 min  the connection gets terminated and release is completed  refer slide time  26  29  28  14 min  pnni is the private network-to-network interface ; that means between the end system and the switch  we have the uni and we have the nni pnni is a private network-to-network interface and this could be between two switches or two entire networks pnni uses link state routing protocol for atm networks we will look into the details of link state routing when we deal with ospf in the ip worlds since ip is the more prevalent technology  we will discuss it in detail when we do it here each node will periodically broadcast the state of the link to which it is connected to all parts of the network this way all the switches get some global picture about the status of the various links  so that they can run some algorithm locally in a centralized fashion and find out all the possible paths they use this for setting up the path later on  refer slide time  28  15 30  17 min  actually the situation is a little more complex than what i have just said  because there is a hierarchy mechanism that ensures that this protocol scales well for large  world wide atm networks a key feature of the pnni hierarchy mechanism is its ability to automatically configure itself in networks in which the address structure reflects the topology there are two things here  one is this hierarchy we are talking about  and the same kind of thing is used in ospf in the ip domain when we discuss ospf  we will go into the details of this ; but there is a hierarchy over there imagine what would happen if all were atm switches  which they are not  but suppose they all were that was the vision ; and if the atm switches were communicating with everybody else with their link states  the database and everything would become huge in order to scale to a very large network  it goes through in a hierarchical fashion  meaning you can have a hierarchy of networks and at each hierarchy  the peers run some kind of pnni for routing within that level of hierarchy and at a lower level  they will again run pnni for that level and various hierarchy levels are possible you have seen that the atm address is given in such a way that we have only shown the broad boundaries but within that boundaries  it can be further divided into a number of hierarchies and again different designated authorities can break it up in a different way all these flexibilities are possible ; pnni allows that in some plane  in some hierarchy  one kind of addressing scheme is used and in another  a different kind of addressing scheme is used  refer slide time  30  18 31  36min  the substance is that it scales to very large networks  supports hierarchical routing  supports quality of service  supports multiple routing metrics and attributes  because when you broadcast the link state  i.e  the state of the link  you may also broadcast all different kinds of parameters about the links that can be handled in that link or how much can be handled by the switches  etc can be propagated throughout the network if you have a fair idea about what is possible and what is not possible  then you can plan your route in the source in a particular fashion use of source routed connection setup  since the source has the global picture  it will use that global picture to compute the route and set up the connection once it decides on the route  it used the q.2931 to give all the connection setup that set up request  acknowledgement and release etc will be used it operates in the presence of partitioned areas  refer slide time  31  37  32  16min  pnni features provide dynamic routing ; that means  the link states may change from time to time each of the switches are going to broadcast their link states ; it is responsive to changes in resource availability ; separates the routing protocol used within a peer group from that used among peer groups various hierarchies are possible  interoperates with external routing domains  which are not necessarily using pnni and supports both physical links and tunneling over virtual circuits  refer slide time  32  17  33  44min  this is an example of hierarchy this big network  which is again a network of networks  is represented by one node in the top level of the hierarchy similarly  you use pnni to plan a route like this within the network you might have to again do a planning and each node may again be corresponding to another network at a lower level at each higher level of the hierarchy  you can use pnni to plan the route if there is a.1.1 its view of a.1.1 is something below a.1.1  a.1.2  a.1.3 are explicit these have abstracted notions of a.1.2 and then you come to b ; these are b and c although when the call setup is passing through b  it may come all the way down and do the actual path setup that is how the hierarchy works  refer slide time  33  45  34  10min  at any level of the hierarchy  a.1.1 will make a source route  which goes through a.1.2  then b and c so the source specifies the route as a list of all intermediate systems in the route this was the original idea also in the token ring  refer slide time  34  11  34  30min  for this  it uses a designated transit list  dtl   which is in the form of a stack  as i will show you source route is across each level of hierarchy ; there is an entry switch for each peer group ; it specifies complete route through that group ; and set of dtl manipulations is implemented as a stack  refer slide time  34  32 34  45min  a and b may be at the bottom of the stack ; a.1 is at the top level of the hierarchy and this is how it is put in a stack and the path is completed  refer slide time  34  46 35  32min  we now discuss the quality of service parameters i will just mention some of the metrics  etc we will not go again very deep into this because we do not have that much time but it will give you some idea about what we mean when we say quality of service one such parameter metric is maximum cell transfer delay ; that means  the delay from the beginning of the first bit of the first cell to the last bit of the cell others include maximum cell delay variation ; the variation of this time ; maximum cell loss ratio ; whether the cells could be lost  and if so  what is the maximum cell loss ratio ; administrative weight  etc  refer slide time  35  33  35  55min  the attributes of the parameters are available cell rate or its capacity  whether it is available ; cell rate margin is allocated minus actual ; variation factor ; branching flag ; restricted transit flag these are all different parameters and their attributes ? qos parameters and their attributes  refer slide time  35  56  37  27min  one way this is handled is the generic call admission control  which happens when you are on the source side  i.e  when you are deciding on the route and you are doing a source routing  at that point whether you can admit a request  which has finally come from the user  from the uni  etc but at that particular point of time before making the request  there is an admission control  which is a generic cell admission control run by a switch for choosing a source route it determines which path can probably support the call ; that way it will try to route the call setup actual call admission control is run by each switch in the beginning we will run a gcac as well as acac and the intermediate switch simply runs an acac or the actual call admission control to check whether that request has come to this switch  whether it can handle this request or not ; this is the protocol which is running  refer slide time  37  28 38  06min  there are traffic management functions ; the call admission control is a kind of traffic management traffic shaping means limit burst length  space out cells  etc for getting a maximum throughput ; usage parameter control is to monitor and control traffic at the network entrance of various traffic management systems both quality of service management and traffic management are possible in atm  and there are extensive protocols for negotiating these various parameters and for setting it up  refer slide time  38  07 38  39 min  the functions of traffic management are as follows  there is selective cell discard with clp or cell loss priority if clp is 1  the cells may be dropped if the situation warrants it is something like an unspecified bit rate and it may have a very low priority cells from non-compliant connections may be dropped there is also frame discarding one example of feed back control is an abr scheme  refer slide time  38  40 38  46 min  we will just quickly look at the peak cell rate i am not going into the details of these  cell transfer delay  cell delay variation  cell delay variation tolerance  cell loss ratio  etc are the parameters  refer slide time  38  47 39  21min  explicit forward congestion indicator  we will just have a quick look at this abr system  which is a binary rate system  which sends an efci this is explicit forward congestion indicator  which is set to 0 at source and congested switch is set to 1 every nth cell destination sends a resource management cell to the source  refer slide time  39  22 39  43 min  what happens is that somewhere in-between if an intermediate source  or efci  is congested  this may set it to 1 and then that information may flow back finally to the source and the source may try to restrict its requests  refer slide time  39  44  40  16 min  sources send 1 rm cell every nth cells  the rm cells contain the explicit rate that has been asked for ; the destination returns the rm cell to the source the switches adjust the rate down ; that means if it is congested  it may adjust the rate down and the source adjusts to the specified rate whatever rate comes through this  going up and coming down through this negotiation  is what the source finally has to accept  refer slide time  40  17  41  38 min  we will talk a little bit about lan emulation  which is emulating a local area network when the backbone is of an atm or when you use an atm but still want to use the ethernet and ip  specifically ip  in the nodes and one very specific reason this is required is as follows one of the reasons atm was not successful in the lan segment  although it was put as a lan solution also in enterprise lan solutions  was that there was hardly any software which was developed on atm whereas a huge amount of software has been developed using ip and so much of software has been developed in ip  you can not throw it up nor can you translate it to an atm software overnight ; that is very difficult people took a more pragmatic approach and thought the backbone network technology be that of atm or have an atm let us emulate the lan so that your software ip based software can still run  refer slide time  41  39  42  02 min  problem  it needs new networking software for atm solution let atm network appear as a virtual lan how can an atm network appear as a virtual lan ? lan emulation is implemented as a device driver below the network layer these are lan emulation bridges actually ; if there is an atm  this will look like a lan  refer slide time  42  03 42  41 min  for this  1 atm lan can be n virtual lans many virtual lans can be there in the same atm lan only one of them may be sufficient  this is a logical subnet interconnected via routers this is the abstraction  this is the picture that we want to give to the world it needs drivers in hosts to support each lan ; so in actual practice  only ieee 802.3 and 802.5 were supported  although fddi could also be done  refer slide time  42  42  43  21 min  this is the picture  we have an atm switch  we have some lane servers  we have multiple lans on this  we have a lane server a and a lane server b the logical view would be as if a router is also connected to the atm switch the logical view looks like an ip network we have a1  a2 connected via this network a and b1  b2 and there is a network b  which is connected these two ip networks are connected via routers this is the logical view  although the actual view is emulated here  refer slide time  43  22  45  55 min  it requires several components ; one component is that we require a lan emulation client in each host each host must have lec or lan emulation client  which is a small software  which can be loaded in each host lan emulation configuration server or lecs will be in one central server  it will be taken as the lan emulation configuration server whenever somebody wants to join the lan or leave the lan  the lan emulation client will first ask for the parameters from the lecs it has to know the address of the lecs and here is a lan emulation server itself  the les  and a broadcast and unknown server if there is something  like the broadcasting in a network  which is done  we know that it is in a particular network for an arp we want to do an address resolution protocol what we do is that we broadcast a request  i.e  the ip address ; what is the data link address ? remember that this atm works on point to point  mostly  as a point-to-point connection although point-to-multipoint is possible  but it is not in both directions instead of trying to do the broadcast from the host itself  what it does is that if each host in this lan emulation client has to broadcast anything  it will send it to another server called bus ; there is a virtual connection between every host and the bus  and the bus will send the broadcast to each of the hosts that way in an indirect fashion  the broadcast takes place similarly there is an unknown server ; that means i do not know the address of the server like arp once again  you send the request to this bus and the bus will find out and finally give you the address these are the main components of lane  namely lec  lecs  les and bus  refer slide time  46  00  46  51 min  what does the les do ? the basic function of the le server is to provide directory  multicast  and address resolution services to the le layers in the work stations that is what the lan emulation server does it also provides a connectionless data transfer service to the le layers in the workstation if needed the parameters for setting up a server  etc  will be known to the lecs  which will communicate to the lec as the lec joins the network  refer slide time  46  52  47  44 min  initialization  the client gets the address of lecs from its switch  uses well-known lecs address  or well-known lecs pvc there has to be a particular pvc  which it starts using automatically the client gets server ? s address from lecs it also discovers its own atm address if required for direct vcs that means if it wants to do some direct communication between two nodes  it has to get the atm address of the other side if it wants to set up a direct vc instead of going via the servers in that case it will require its own atm address also  refer slide time  47  45  48  00 min  it does a registration ; client sends a list of its mac addresses to the server ; declares whether it wants arp requests these have to be known to the server so that the server can give the service to the other nodes connected to that network client sends arp request to server  refer slide time  48  01  48  19 min  address resolution  client sends arp request to server ; unresolved requests are sent to clients  bridges  servers and the arp ; client sets up a direct connection this is how a connection is set up  refer slide time  48  20  48  40 min  broadcast to unknown server or bus  as i said  it forwards multicast traffic to all members clients can also send unicast frames for unknown addresses there suppose some address is not known  you send it to bus and then bus will try to find out  refer slide time  48  41  49  54 min  there is a flush protocol that means clients can send unicast packets via bus while trying to resolve the address what might happen is that client may try to get the address  then get some address  maybe send it directly what might happen is that something which was not sent directly here  the packets may come out of order remember i mentioned that in atm  one guarantee is that cells will not come out of order cells may get lost  but cells will not come out of order  unlike pure datagram services but in this particular case this may happen because we are not talking about one particular vc in one particular virtual circuit  the packets will indeed not go out of order but in this particular case  they might when direct vcc is set up  client sends a flush message to the destination  destination returns it to source  can then send packets on vc this is a flush message that this problem is solved  refer slide time  49  55 ? 50  38 min  there is another approach to this  which does not use lan but uses classical ip over atm what is classical ip of our atm ? the definitions for implementations of classical ip over atm are described in rfc 1577 all the details are here ; once again  we will just simply mention it very quickly this rfc considers only the application of atm as a direct replacement of the wires ; local lan segments connecting ip end stations which are the members ; and routers operating in the classical lan based paradigm ; issues raised by mac level bridging and lan emulation are not covered  refer slide time  50  39 -51  20 min  if you want to look at classical ip over atm  you have to do address resolution and encapsulation these are the two issues to be considered here encapsulation consists of putting appropriate atm header trailer to a packet  converting it to a number of cells and then sending them this is encapsulation  which means that you have an atm packet this is classical ip running over atm when you have a big packet you know that cells have to break it up  and put a proper header on each one and then send them atm features are not utilized and inter network traffic handling is clunky  refer slide time  51  21  52  21 min  each of the ip sub-networks is a logical ip sub-network all members of a logical ip sub-network are able to communicate via atm with all other members in the same lis  which means that if two nodes are in the same logical ip sub-network  i.e  same lis  you would set up a vc on there is a vc between every pair within or amongst all nodes in a particular logical ip sub-network there is a vc mesh ; everybody can communicate to everybody else communication to hosts outside the lis  local lis  is provided via an ip router this router is an atm endpoint attached to the atm network that is configured as a member of one or more lis  refer slide time  52  22  52  49 min  naturally  a router may be a member of more than one network similarly  the network is configured as a member of one or more lis you have to do an address resolution the valid question is that  if the ip address is this  what is the atm address ? you have to do an atm arp  ip address to atm address translation  address resolution protocol is used inverse atm arp means vc to ip address ; solution  use atm arp servers there are atm arp servers there  refer slide time  52  50  53  49 min  this is a diagram  suppose this is a logical ip sub-network number 1 and this is logical ip sub network number 2  each of them has its own atm arp server for doing arp  that means  ip to atm address translation and vice versa nodes are connected ; if a1 wants to communicate to b2  naturally at the top level  you give the ip address previously we were breaking it up into data link address finally what is the route to take if it is in some other list ? if it is in the same list  you have a direct vc to it and you have a direct virtual circuit ; you take that each lis has an atm arp server for resolution ; clients are configured with the server ? s atm address and clients register at start up periodically  refer slide time  53  50  55  08 min  in atm  arp protocol is used to resolve a host ip address for a known hardware address it is the inverse atm arp as you can understand  this atm is a rather complex technology and this is one of the reasons it was not so successful as you will find later on  many of the ideas which were used in atm  namely  about this quality of service  about setting up flows and setting up virtual circuits with vci vpi labels  these ideas were later on adopted in ip and we will discuss it a lecture called mpls  that is  multi protocol label switching  where the similar ideas have been used to give this kind of services later on also  atm is used quite extensively in big backbone networks because of the various facilities although it has moved out of the lan segment  these days the gigabit ethernet has replaced it simply because of the host thank you preview of the next lecture  refer slide time  55  11-55  12  so today we will start our discussion on routing actually we have already talked about routing a little bit in different context specifically in the context of atm how the atm virtual path are set up today  we will talk about the major area we will start our discussion on the major area of routing which is how and specially with reference to the tcp ip stack that is how packets are routed in a ip network  refer slide time  55  54 -56  04  we will talk about today  we start the introduction and to routing  we will take up the discussion about different routing protocols in next set of lectures  refer slide time  56  09  56  48  let us just recollect what the job of the network layer or what is routing this is to carry data end to end  i.e from source to destination perhaps through a number of intermediate subnets depending on whether connection oriented or connectionless services are used other functionalities may be incorporated at this layer  we will talk about this later on we are talking about ip routing of ip packets and how you can have a virtually connection oriented system on that we will discuss it later on  the point is unlike data link layer remembering the next hop just the link which is immediately adjacent that has some advantages in the sense that whatever information you require about it are locally available here routing is the major problem  we are talking about routing over multiple networks and towards a very remote system the packet might have to take many hops maybe 10  20 even 30 hops to reach the end point and when you take naturally let say 20 hops  the area you are sort of serving becomes so large with so many machines connected to it how to keep track and naturally switch so many machines with so many links is the problem some of the link may go down some of the machines  may come up and when i say machines it may refer to actual either pcs servers etc they may also refer to the network boxes like other routers  refer slide time  58  03-58  29  calculate the check sum which is for your connection as we know can transmit to the next hop and send an icmp packet if necessary icmp is for internet control message protocol if the routers may use icmp packets for sort of talking to each other and sending various messages if necessary we will see 1 example  computer networks prof sujoy ghosh department of computer science and engineering iit  kharagpur lecture-26 introduction to routing  refer slide time  00  39  today we will start our discussion on routing we have already talked about routing a little bit in different context  specifically in the context of atm of how the atm virtual path etc are set up today we will start our discussion on the major area of routing and specially with reference to the tcp/ip stack that is how packets are routed in an ip network  refer slide time  01  22  01  33 min  today we will start the introduction with routing and then we will take up the discussion about different routing protocols in the next set of lectures  refer slide time  01  34  03  46 min  let us just recollect  what is the job of the network layer or what is routing ? the job of the network layer is to carry data from end-to-end that is  from the source to destination perhaps through a number of intermediate subnets now depending on whether connection-oriented or connectionless services are used other functionalities may be incorporated at this layer we will talk about this later on right now we are talking about routing of ip packets and later on we will discuss on how you can have a virtually connection oriented system on that unlike data link layer  if you remember  is just the next hop  just the link which is immediately adjacent so that has some advantages in the sense that whatever information you require about it are locally available unlike the data link layer  the major problem with routing is that it happens over multiple networks and towards a very remote system and the packet might have to take many hops  may be 10  20 or even 30 hops to reach the end point when you take 20 hops the area you are serving becomes so large with so many machines connected to it and then how do you keep track and then switch so many machines with so many links ? the problem is some of the links may go down  some of the machines may go down  some of the machines may come up and when i may refer it actually says pcs  servers  etc  they may also refer to network boxes like other routers so the job of the router is to know which link it should take so that globally the packet will arrive nearer to its destination  refer slide time  03  47  04  12 min  this is the basic routing problem at a particular subnet node given a packet with a particular final destination determine the next subnet node or the outgoing link which is appropriate in the datagram network this is determined for individual packets but in vc networks this is determined only for setup packet for each session now we will concentrate on the datagram network  refer slide time  04  13  08  20 min  consider a router x x may not know the topology of the entire internetwork these days everybody wants to be connected to the internet so we have a giant network of networks so there is this big network of networks spanning the entire globe and then a particular network once again may be divided into so many sub networks there are billions of machines connected to this network so some user somewhere wants to connect to another user on the other part of the globe this is a huge problem that must be solved in a systematic manner but this is the objective of routing or the network layer so x needs to determine the next ? hop router for every other network in the internet we are trying to reach some particular machine  some particular server if you want to keep track of all the machines in the world it becomes really impractical we somewhat reduce the problem where all these different machines are grouped into different networks or even sub networks they are grouped into different networks so that a remote router needs to keep track of only the remote network rather than a particular server in that network of course  the idea is that  once you reach your destination network finding a particular server within that network will be very easy either through arp or some such protocol you can reach the particular server once you have reached the correct destination network the entire information that is required is structured as a routing table of router x to keep track of all the other networks what is a routing table ? given the address of a particular network in a remote location we should be able to find from the routing table that which local hop i must take next even that is not easy even if you reduce the scope of the problem from servers or pcs to networks because there are millions of networks in the world so theoretically if you do it in a very naive fashion you have to keep millions of entries so that you can match and know that this is what the mistake is of course  even this is not possible because at the same time you want to go to the correct destination for this particular packet and at the same time you want to process the packets as fast as possible people want more and more speed so the network traffic and the number of packets are increasing day by day so you have to process the packets very fast if you have a very large table then it demands time even just to look up to it and you require a lot of memory additionally it consumes lot of processing power which will thereby drive up the cost of the router so  even keeping millions of entries for most routers this is not a feasible option therefore we have to do something about it  refer slide time  08  21  10  04 min   the other issues in routing are  one is  the topology changes affect convergence  delay and stability topology of the network changes all the time because the links may go down or come up  nodes may go down or come up so the topology is changing therefore this may the change the path that a particular packet takes and the path the next packet takes in the same stream this may affect the delay and the stability the other problem is scalability to a large number of interconnected networks or routers or links and even when you come down from nodes to networks this is still a very large problem then there are other issues like what is the best path from x to y it may be that five different routes are possible from x to y now all these five routes are not equal first of all they may not be equal in the number of hops  they may not be equal in length  they may not be equal in cost  they may not be equal in the quality  some of the routes may be very unreliable that the packet has a larger probability of getting dropped and so on and so forth so we would like to have the minimum number of hops or the minimum delay or the maximum capacity therefore if possible we would also like to incorporate the quality of the path when deciding on a route for a particular packet from x to y  refer slide time  10  05 11  30 min   so routing consists of deciding the route for each packet and in order to do that the router has to have knowledge of the entire network and this knowledge has to be dynamic because the network topology keeps on changing so we have to update the knowledge of the network from time to time suppose you have a host or lans connected to some routers say a  b  c  d  e and then through the links 1  2  3  4  5 and 6 respectively then for example when the router a gets a packet from a local network which is connected to it which may be destined for the lan which is connected to router c so it has to decide whether to take link 1 or link 3 obviously it does not take this link because this is where it is coming from and obviously it is destined to some other sort of remote so it has to decide although in this particular example you may theoretically reach c both by taking link 1 and link 3 but then these links may be of different quality  may be something like a  d  b,c  e is a bit of choice  refer slide time  11  31 12  12 min  as mentioned earlier these are the routing tables we have the routing tables in routers they look somewhat like this for example  let us look at the routing from a and this may be just one form of it it may not be exactly used in this form but let us look at it suppose you want to route to the router a which is again local because we are sitting on router a  for b you take link 1  for router c link 1  for router d link 3 and for router e link 1  refer slide time  12  13 12  24 min   from a to b is link 1  may be c is also link 1 and d is link 3 and e is again link 1 and so on   refer slide time  12  25  12  59   similarly  b will have a routing table and c will have a routing table and so on suppose you take any destination a   refer slide time  13  00  15  41   now for a let us consider a tree with a root at a now b connects to a through link 1 and c connects to a through link 2 obviously link 2 is not taking c directly to a but link 2 is only taking c to b but that is the preferred path for connection from c to a if you think about it this way  for each destination we have got some kind of a tree if the network was very bigger here the network is very small so the tree is only two levels deep but the tree could be very deep may be 10 or 15 levels deep so for each destination we actually have a tree which is implicit in these routing tables which are distributed at each node we try to see the local link to be taken for that particular destination as i said  the local link may not take you directly to the ultimate destination but the local link will take you somewhere and that particular node will again have a link for the same destination this way  if everything is working fine  after some hops you will reach the final destination this means that some of the other nodes may be directly connected  some may be 2 hops away  some may be 3 hops away etc but overall there is an implicit tree for each destination and for one movable link of this tree is in one particular link of this routing table just according to the destination in other words  if there are n nodes and there are n implicit trees and these n implicit trees are distributed over n nodes so it is one link from each tree in the routing table of a particular node in that way you have a routing table of size n including the root which is the local link and somehow you need to maintain this tree and that is the job of a routing protocol later on we will see different routing protocols and also see how these implicit trees may be maintained or rather how these routing tables have to be maintained  refer slide time  15  42 16  44 min   when there is a routing table there is a question of forwarding routing is the process of building routing tables at each router forwarding is the process of looking at the destination address of a packet and sending it to appropriate next hop interface of a router this means  once through a routing protocol you have a routing table then a packet actually arrives and you have to forward it to the correct interface of that router so  you look up to this table and the interface to which the packet must be sent and forward it so this routing or forwarding are two different and distinct parts of the router actually sometimes these two are diverged even more for the time being we assume that routing and forwarding happen at the same place and the routing table itself is being used for forwarding although that may not always be the case forwarding requires access to local routing table sometimes forwarding table is structured in a different manner than routing tables  refer slide time  16  45  18  05 min   so forwarding table is optimized for packet look ups routing table is optimized for routing changes  topology changes etc a routing table may look like this  say  for net number 10 the next hop would be this ip number because the routing table is working in the ip address this ip address is version four addresses and it contains four numbers all less than 256 so it is 171.69.245.10 the link cost may be there in forwarding  we really do not care what the ip address or the next hop is we do not even care about the link cost because all these are a part of setting up the routing table in the forwarding table we just wanted to know the interface as to what is the local interface to which this packet has to be sent and what is the mac address at the next hop this is what we are more interested in basically you can just add your data-link headers and just send it over to the physical layer this is a slightly higher level and the abstract view of processing an ip datagram  refer slide time  18  06 21  09 min   in this ip module there is a routing table which is the central thing there is a routing protocol which makes this table sometimes we also use static routing  for the time being let us consider that it has been manually configured some of the entries may have come through a routing protocol while some of the entries may have been manually configured now  when a packet comes from an upper layer it will come from some transmission layer protocol two of the most common transmission layer protocols are tcp and udp we will see what they are later on but let us assume that some packet has come through udp with some destination ip address in it you look up at the routing table  the next hop and send the datagram or the same thing must have come through tcp also when we are discussing the processing of the ip datagram in the ip layer the ip layer is present in two different places in one place it is the regular host the pc and in the other place it is a router the jobs of the two places are a little different if a packet comes from outside to a pc  and is not meant for the pc  the pc is simply going to drop that packet in the case of a router  if a packet comes from outside  it looks up the destination and then actually forward it so in a pc the forwarding table may be disabled whereas in a router the forwarding table will be enabled if the packet originates from machine pc itself then it has to go out on its way it will send the packet to the router the ip datagram it is sent to the network layer this is a high level view of what is happening in the ip datagram processing  refer slide time  21  10  21  21 min  the processing of ip datagrams is very similar on an ip router and a host the main difference is ip forwarding is enabled on router and disabled on host  refer slide time  21  22  21  45 min  now when the ip forwarding is enabled  if a datagram is received but it is not for the local system  the datagram will be sent to a different system when ip forwarding is disabled  if a datagram is received it is not for the local system and the datagram will usually be ignored  refer slide time  21  46  22  03 min  the view at the data link layer is somewhat different internetwork is a collection of lans or point-to-point links or switched networks that are connected by routers so this is the data link layer view of the ip datagram  refer slide time  22  04  23  02 min  in this diagram there may be some point-to-point links or some lans  etc and they are all connected by some routers r1  r2  r3  r4 etc a particular host places an ip datagram on the local ethernet that is destined for outside it will eventually reach the local router and the router will decide whether to give it to another network such as the network of ethernet switches  token ring etc through different networks the packet proceeds through the routers to this when you look at it from a data link layer point of view all these switches become visible whereas at the ip layer only the routers and the networks will be of main concern  refer slide time  23  03 -23  26min  a view att the ip layer  an ip network is a logical entity with a network number we represent an ip network as a cloud the ip delivery service takes the view of clouds and ignores the data link layer view that means the details of these actual switches etc are in the data link layer view whereas in the ip layer view it will simply be a cloud  refer slide time  23  27  23  26 min  in this picture there are routers r1  r2  r3  r4  etc and the connecting networks are shown as clouds each network has some number  refer slide time  23  47 -27  13min  the following conditions must hold so that an ip datagram can be successfully delivered the network prefix of an ip destination address must correspond to a unique data link layer network which is equal to lan or point-to-point link or switched network the reverse need not be true this is quite fundamental you have already seen examples of ip addresses they are basically four numbers each less than 255 that is something like 144.16.192.53 this may be the ip address of a particular machine in the network layer it is not possible to handle all the machines individually because that will make the problem really big so as our first step in our reduction or scaling it  actually in the remote routers we do not usually keep track of the specific ip addresses of specific machines we just keep track of how to go to that network which contains this ip address so the ip address usually has two parts  the leading part that is the first few bits or bytes is a address of the network whereas the last few bits or bytes may be reserved for a particular machine within that network this is how a global ip addressing scheme is this is not as neat as in telephone numbering which exactly tells you the particular state  area  leca and the particular exchange finally so it is not that neat but at least the first few bits or bytes will be associated with all the ip addresses in a particular network if you just take that prefix part you know that it precisely means that particular network and no other network will have the same exact prefix the network addresses have to be globally unique because now-a-days our network is really span the entire globe therefore this is called as the network prefix of an ip destination address and this must correspond to a unique data link layer network but the reverse need not be true which means one data link layer network may have two different network prefixes  refer slide time  27  14  27  37 min  so routers and hosts that have a common network prefix must be able to exchange ip datagrams using a data link layer protocol such as ethernet  ppp etc every data link layer network must be connected to at least one other data link layer network via a router  refer slide time  27  38 -28  08 min  each router and host keeps a routing table which tells the router how to process an outgoing packet the main columns as we have already seen are  1  the destination addresses  i.e where is the ip data gram going to   2  next hop  or how to send the ip datagram and  3  interface or what is the output port next hop and interface columns can often be summarized as one column and routing tables are set so that the datagram gets closer to it is destination  refer slide time  28  09 -29  39 min  this is another example of a routing table ip datagrams can be directly delivered which means these are in the local network therefore they go through the interface called ethernet zero whereas these addresses are outside so this one had to go through a router or to a point-to-point link or this can be some other network altogether now the prefix has distinctly changed for example  10.1.0.0/24 means any number from 0 to 24 can be there so  for all these ip addresses  you just deliver the datagrams directly similarly 10.1.0.2 is also connected directly which means they are all in the same network and then there is a point-to-point connection through a serial link on this router which is also may be very closely connected to the same set of networks there may be other networks out in the wan which really starts from 20 so  for those networks you again have to go to the router and go out through some port of that router  refer slide time  29  40 -30  22 min  if you take a more global view these different routers will be having routing tables we know the details of these routing tables and what they contain and this is how one particular ip packet which originates here will go to a router then to a next router and then to another router and so on  refer slide time  30  23 -33  41 min  processing of an ip datagram at the router  first we have to receive an ip datagram then ip header validation the ip protocol is a network layer protocol previously we discussed about a lot of data link layer protocols but now we are talking about ip protocols and for these ip protocols once again you require some information to be exchanged between peers this information will be in the header called the ip header because in the network layer we are mainly concerned with ip so it is the ip header in any case the ip header has to be validated if there are some options in the ip header they have to be processed the destination ip address is parsed from this header then we do a routing table look up and we decrement ttl i.e we decrement time to leave here is a common example in this distributed fashion we are trying to capture a good and consistent and correct picture of the entire global connectivity which gives you the best connection but in practice this may not always be possible because the global picture may change from time to time so  to get the entire global picture in a very correct fashion is not possible sometimes you may have inconsistent routing table entries and that may lead to various things such that it may lead to a loop in the routing table the loop may not be in one routing table but if you take several routing tables together then you can see that the packet will go in a loop once a packet starts going in a loop it will continue in that loop because each time it comes to the router the router will see its own routing table locally and send it to the next one which was hopefully in a correct path but actually now it is in the vicious ring so this packet will just go on circulating ad infinitum to stop this we put some kind of restriction on the number of hops a packet will take may be 30 each time an intermediate router forwards a packet it will decrement this time to leave that is from 30 to 29 and from 29 to 28 and so on after 30 hops whichever router finds a packet with a ttl zero will simply drop the packet either that packet is going in a loop or the packets have gone very astray because of mistaken entries in the routing table and so on  refer slide time  33  42 -35  18 min  then perform fragmentation if necessary we will see the details of fragmentation later on fragmentation here is  what you are doing is that you are going from one network to another network to another network and so on all these different networks are on different administrative controls and different domains and they may even have different data link layer technologies some token ring may be connected to some ethernet and there can be all different kinds of networks in between now suppose the source had sent an ip packet which was quite large but inside one particular network it is not possible to handle such a large packet it would be unfortunate if you drop the packet all the time because it will never go through therefore what is done is that this big packet is broken up into small fragments and the fragments are sent later on when you are in a sort of wider area the fragments are again reassembled into a big packet and sent along when it reaches the destination then you calculate the check sum which is of error in connection as we note and transmit to the next hop and send an icmp packet if necessary icmp stands for internet control message protocol the routers may use icmp packets for communicating between each other and sending various messages if necessary we will see one example list now and the rest later  refer slide time  35  19 -35  41 min  when a router or host needs to transmit an ip datagram it performs a routing table lookup so  use the ip destination address as a key to search the routing table the result of the lookup is the ip address of the next hop of the router and/or the name of the network interface  refer slide time  35  42  37  09 min  so we have seen that therefore either you take the network prefix or host ip address or loopback address or the default route loopback address means this is meant for local consumption so it will go back to the same machine so it is coming down from a machine and it contains a loopback address then it goes back to the same machine why would somebody want to send the packet like this ? one process of the packet of the host is sending some packet to another process in the same host and it is using this network operating system part for sending that message default route is very important because you can not keep the network prefix for all possible networks in the world in this table then this table will then become very large so you will have fewer entries for the network prefixes and if your network is something else may be there is a bigger router somewhere that knows about all these networks so there is a router which is likely to know about this particular network prefix which has come so you send it to a default route and on this side you have the ip address or the name of the network interface  refer slide time  37  10  37  26 min  so the destination address is a network address  most entries are network routes for the host route the destination address is an interface address which is used to specify a separate route for certain hosts  refer slide time  37  27  38  09 min  the default route is used when no network or host route matches the router that is listed as the next hop of the default route is the default gateway we are calling it gateway because this is not a packet for a network which is close by this is a packet for some arbitrary distant destination  this is a smaller router that is connected which will send it to the gateway and the gateway will in turn send it to a bigger router to find its final destination  refer slide time  38  10  38  27 min  loopback address  routing table for the loopback address is the particular loopback address which is used in ip which is 127.0.0.1 and this is meant for local consumption the next hop lists and loopback interface as outgoing interface  refer slide time  38  28  40  04 min  to minimize the size of the routing table we use the longest prefix match  i.e we search for the routing table entry that has the longest match with the prefix of the destination ip address it means search for a match on all 32 bits the ip address contains four integers less than 256 i.e four bytes which is actually 32 bits so an ip address in ipv4 address is 32 bit long so first you try to match all the 32 bits with some entry in the table if the 32 bit does not match then you take only 31 bits and check whether they match and you keep on doing it and keep on reducing till you get a match so you have identified the first entry that matches with the longest prefix where such a match is possible the host route loopback entry is a 32 bit prefix match the default route is represented as all zeros which is a zero bit prefix match that means there is a zero entry which will give you the next hop as the gateway because now it has not matched with anything finally this is a zero bit prefix match  refer slide time  40  05  41  14 min  suppose the destination address that has come in is 128.143.71.21 then of course the 128 and 143 parts have matched with this but then here this is zero and this is 71 so this is a much better match here with the one shown in red similarly 128.143.71 is also matching here but the next number is 21 which will match better with this rather than with this range this is where the match will take place and you will send to router r4 the default router at the gateway is shown as r5 so the longest prefix match for this is for 24 bits with entry you can find this out if you actually break up 21 into its binary form and see how many bits are matching but this is matching with the 24 bits etc  so data gram will be sent to r4  refer slide time  41  15  41  32 min  the longest prefix match algorithm permits to aggregate prefixes with identical next hop address to a single entry this contributes to significantly reducing the size of the routing tables for internet routers  refer slide time  41  33  42  31 min  suppose for 20.2.0.0 to 16 i would have gone to router r2 and for 30.1.1.0 to 28 i would have gone to r2 once again now we see that the next hop is the same and what we can do is  instead of 20 and 30 if we make the entry as 20.0.0.0/8 and put it as r2 then because of longest prefix match then whenever something also comes in this range it will have a longest prefix match with this rather than with this because this is taken over here and 30 is naturally closer to 20 so instead of two entries we keep only one entry in the routing table which helps in reducing the size of the routing table  refer slide time  42  32  42  56 min  how do routing tables get updated ? one way is to add an interface and then configure the same so it adds a routing table entry this is manual configuration we can also add a default gateway that means for the destination that is the default route we can add a gateway this is once again a manual updating  refer slide time  42  57  43  32 min  so it is the static configuration of network routes or host routes if some particular route is forced then i might put in a static configuration of what they are routing tables also get updated through routing protocols there may be icmp messages from some router which may update the routing tables so these are the different ways in which a routing table may get updated  refer slide time  43  33  44  31 min  for example  for this icmp when a router detects that an ip datagram should have gone to a different router the router  here r2  forwards the ip datagram to the correct router and sends an icmp redirect message to the host the host uses the icmp message to update its routing table what is happening is that one particular host had sent the ip datagram to one router now this router sees that it need not get it from this host and that host should have sent it to that router this router will now send it to the that router anyway and send an icmp message to this host saying that from next time onwards when you have got this destination please send it to that particular router rather than sending it to this destination this is one example of how icmp may be used these are the different kinds of icmp messages  refer slide time  44  32  45  46 min  the other thing is  icmp router solicitation and icmp router advertisement when a router is switched on for the first time how will other routers know that this router has come up ? since the other routers do not know about the existence of the new router which has come up it is was not sending any message to it so  after bootstrapping a router broadcasts an icmp router solicitation it sends an icmp and advertises itself and solicits icmp messages from the neighboring routers in response the router sends an icmp router advertisement message also  routers periodically broadcast icmp router advertisement this is sometimes called router discovery protocol this has to be done periodically because some router may have gone dead in the meanwhile therefore by doing things periodically you try to keep it as current as possible  refer slide time  45  47  46  28 min  we can look at routing as some kind of a graph theory problem where  a  the nodes are the routers of a single administrative domain or different networks   b  the edges are interconnection links   c  link costs are related to physical distance  capacity  delay  etc and  d  the objective is to determine minimum cost path you can formulate it as a graph theory problem and this particular graph theory problem can be handled in different ways we will see two different ways later on  refer slide time  46  29  46  41 min  the problem has some constraints  one is to solve the minimum cost path problem in a distributed manner rather than centralized manner and constraint two is to react quickly and robustly to topology changes  refer slide time  46  42  47  26 min  there are routing protocol requirements one is to minimize routing table space  i.e with all these millions of networks working at the same time minimizing the routing table space is always very important this makes the routers smaller or cheaper or faster  minimizing or controlling messages is also important routers should be robust and not misroute packets loops and oscillations must also be avoided finally optimal paths must be used all these are different routing requirements it is not that we can get 100 % of the requirements all the time but we try to do it as best as we can  refer slide time  47  27  48  40 min  now we will quickly go through the different approaches to routing one is the centralized versus distributed approach in centralized routing one central processor collects information about the status of each link  computes the routing table for each node and distributes it this is possible only in a small number of cases and not all the time and obviously it is not possible over the entire internet because there is no such centralized routing that would handle the scale in distributed routing  routers cooperate to run a distributed protocol to create mutually consistent routing tables in distributed routing also there may be two approaches one is that you distribute the local information only and then globally try to come to a solution the other is that you distribute the information globally and then locally you simply route some kind of a centralized algorithm to know because you have now got the global picture in each of the places  refer slide time  48  41  49  53 min  routing may be source based or versus hop by hop in source based routing the packet header contains the entire route if a link or a router along the path goes down a source routed packet will not reach the destination because the route has been fixed by the source the intermediate routers do not do anything if the next hop is available it will send the packet otherwise it will drop it in hop by hop routing the packet contains only the destination address and each router will consult its own routing table and find out what is the next hop and then choose that next hop but in the source routing the route is fixed from the beginning loose source route is something in between  it is an intermediate solution in loose source route what is done is that instead of specifying the entire path you specify some sort of islands in between that means you go from one router to the next through several hops then again several hops and so on so this is something intermediate between strict source routing and pure hop by hop routing  refer slide time  49  54  52  47 min  routing may be stochastic or deterministic in stochastic routing each router maintains more than one next hop for each possible destination one of these is randomly chosen so the idea is to distribute the load evenly along the links on the other hand packets may get out of order because of this it is because the packets from the same source travels to the same destination and the first packet may be stochastically chosen to go through this path and another may be stochastically chosen to go through this path the probability of choosing either this path or that path can be based on some metric like the delay but in the end the packets may reach out of order please remember  the service the network layer is providing is just to send the packet from one end to the other part of the network here this part has been said explicitly but it is also important to understand what has not been said it has not been said that this service is going to be very reliable which means that in the interim some router may drop a packet so your packet may not reach the destination at all so reliability is not guaranteed another thing that has not been said is that all the packets you sent from destination a to b will reach the other end in the same order in which they were sent the first packet may reach later than the second packet because may be it came through two different paths or may be due to some other reason once again there is no explicit guarantee regarding the ordering of the packets obviously towards the end application this may not work at all in many cases so in such cases where this is very important you have to take precaution against this or you have to put in some corrections for this at some other layer and the network layer is not doing this this was the idea for breaking it up into layers in the first place in the physical layer it is the physical sending and in the data link layer sending is from one to one hop only and makes it as reliable as possible through checksum etc in the network layer it is just reaching the other end of the network layer through several hops now if you want to do it reliably you have to go up one level more and then try to do something there we will see how it is done  refer slide time  52  48  53  16 min  single versus multiple paths  each router maintains one primary and some alternate paths single path routing is used in internet to reduce routing table size multiple paths such as stochastic etc are not usually used in these routers in the internet because the routing table size is at a premium multiple paths are used by telephone networks as routes can easily be deciphered from the address such as telephone numbers  refer slide time  53  17  53  33 min  next is state dependent versus state independent routing state independent or static routing pre-computes the routes ignoring the network state and state dependent or dynamic routing uses the current measured network state  like loading or health of a link  to determine the current route which may change as the packet is proceeding it requires more overhead but can usually find better routes  refer slide time  53  34  53  42 min  in static routing  the next state entry does not change in response to changes in network traffic or topology in dynamic routing it does change  refer slide time  53  43  54  08 min  routing in the telephone exchange of course is very simple as we have already seen under the same exchange there is no routing and under the same short distance charging area  sdca  a central switch sets up the connection with the destination exchange for trunk calls the central switch forwards the setup request to the trunk exchange  tax  and maintains a primary and alternate path to a long distance charging area  ldca    refer slide time  54  09  54  20 min  the possible goals of routing algorithm may be to minimize average end-to-end packet delay  which is desirable from the viewpoint of network user   to maximize throughput  which is desirable from viewpoint of network operator  and to minimize average number of hops  which tends to give both low delay and high throughput  refer slide time  54  21  55  49 min  another way we do routing route is by flooding this is some kind of broadcast  so if a router wants to flood something it will send the same message to all the routers which are connected that may be a very nice and fast way of reaching somewhere because when you are flooding very soon this message will get replicated at each node and everything is running perfectly and in a synchronous manner it will reach the destination using the shortest possible route the only problem is that not one copy will reach but multiple copies will reach using different paths and then other copies will never get anywhere but they will sort of choke other parts of the networks so these overheads are there still flooding is used in some special cases this is one reason we use flooding and the other reason is that when we actually want to broadcast this to everybody then one good thing to do is to flood it every incoming packet is sent out through every outgoing line except the one it arrived on a hop count or keeping track of previously flooded packets may be used to avoid generating infinite number of packets flooding gives the shortest route and is very robust but hardly practical otherwise but in many situations they are also practical  refer slide time  55  50  56  06 min  flow based routing is a static algorithm that uses both topology and load for routing the traffic matrix and the line capacity matrix and a routing algorithm is assumed to be given the mean delay time for the entire network is calculated from this different routes from different algorithms  or all possible routes  can be evaluated  refer slide time  56  07  56  20 min  we will come to that later on when we do mpls given a particular set of routing entries  the net average traffic in each link is calculated so you can try to do some traffic optimization through this  refer slide time  56  21  56  33 min  then we have multi path routing at the router  for a given packet with particular final destination several choices for next router are enumerated  and then the actual path is chosen in some fashion  refer slide time  56  34  56  42 min  multi path routing may yield more stable traffic  refer slide time  56  43  56  46 min  alternative routes are also similarly determined  refer slide time  56  47  56  53 min  we have already talked about dynamic routing versus centralized routing  refer slide time  56  54  56  58 min  it has its own disadvantages meaning it lacks some fault tolerance if routing computer goes down  refer slide time  56  59  57  23 min  distributed routing is the most usually used it may use some distributed algorithm like distributed bellman-ford or it may use some centralized algorithm with distributed global data we will look at distributed routing in more detail in the next couple of lectures computer networks prof sujoy ghosh department of computer science and engineering iit  kharagpur lecture-27 rip distance vector routing we have seen basic routing now we will go to some important and specific routing protocols the first routing protocol we will be discussing today is distance vector routing or rip routing information protocol  refer time slide from 01  08 to 01  25min  rip is one of the oldest routing protocol actually used in the internet and is still used in many places which is based on distance vector  refer time slide from 01  25 to 03  40min  the distance vector of node x is the minimum distance from x to every other node in the network for example  the distance vector for a in the following graph is 1  2  2  1  1 that means for b it is the distance one  for c it is 2  for d it is the distance 2  for e and f it is the distance 1 so from a these are the distance vectors if you recall from the last lecture  the routing problem can be reduced to a graph theoretic problem so these nodes are the routers but there could be some hosts also but for our purpose of rip we will consider these to be routers when we are not talking about delay  congestion  link  capacity etc in the simplest case this is the shortest path problem so the distance here is just the number of hops these links are also not weighted so we just count the number of links to reach from the source to destination and that is given as the distance vector for the destination node from the source node we will use these distance vectors to compute the shortest path we have to run a standard shortest path algorithm and here in this particular case we will be using bellman ford algorithm we have to run them in a distributed fashion this bellman ford algorithm should be running at each node  refer time slide from 03  40 to 04  25min  as per the bellman ford algorithm given directed graph with length djk which means this is the distance vector from j to k assigned to each directed link j ? k assume every cycle has positive total length this of course is trivial  if all the links are positive and since we are taking the link weight to be 1 this will always be valid if  j,k  is not included then include it with length d_jk set = 8 the goal is to determine the shortest path from each node to node 1 which is the destination  refer time slide from 04  24 to 04  27 min  so this is the graph and  refer time slide from 04  27 to 04  51min  what is this 8 ? well  the point is  when you are starting the algorithm j may not know that it is actually connected to k through multiple hops so to start with j will just set it equal to infinity  refer time slide from 04  51 to 07  35 min  let dih be the length of shortest directed path with at most h arcs from node i to destination dih is generated by the iteration dih + 1 = minj  dij + djh  and di0 = 8 so you can put all of them as infinity or the direct links you can take note of them and in one iteration that will be taken care of the d is telling us that this is the best path i know at the moment from myself to this particular node at this iteration  now  in another iteration when these distance vectors are interchanged we may find that my neighbor knows something which is of a better cost so i can go to my neighbor using dij over all j and then djh if there are n nodes i need to do this iteration where at most there will be n ? 1 arcs this is the worst case in which all the nodes are connected in a chain so  after n ? 1 iterations i will get to know about a node which is at a distance n ? 1 from me because at each iteration this information will filter through and then reach me this node might have thought that node is not connected at all so di0 is 8 but after n ? 2 iterations its neighbor would know that it is connected to that with a distance of n ? 2 and then this information will reach this node and this will know that it can go to its neighbor in one hop and take n ? 2 hops to destination so it can reach that node in n ? 1 hops since every cycle has positive length no optimal path contains a cycle hence it has at most n ? 1 arcs where n is the total number of nodes thus it is at most n iterations including the first one  refer time slide from 07  35 to 09  26 min  what we do in this distance vector routing is that at regular intervals router j sends packet to each neighbor giving new estimation for djk the current distance to destination k that means the router j is giving the djk value and not only djk value for all k so that is why this is not just one distance value but this is called a distance vector that is sent to all its neighbors so the neighbors tell each other about the distances they know to a particular node k and update the shortest one in its table if node j finds that sp for the node 1 from the neighbor is shorter than it own  it will update the new path we do some local exchange of information between any router and its neighbors as the algorithm is of course running globally and in a distributed fashion router i updates its table via decentralized bellman ford iteration so d  j,k  = minimum  dij + d  j,k   which gives the minimum distance to a particular destination k  refer time slide from 09  27 to 10  55min  for ip routing  a routing table has to be created and which has to be kept updated there may be icmp redirect messages from other routers make changes to this routing table there is the routing daemon what the routing daemon will do is that from time to time it will run and send packets to the neighboring routers or run some iterations of this bellman ford algorithm and keep the routing table up to date so  from this routing table we get the ip output and calculate the next hop router and if it is source routing we get it otherwise we get it from the routing table when a particular packet arrives it sees whether it is for the router and if yes of course it goes up  if it is no then it calculates the next hop  refer time slide 10  56 to 13  47min  autonomous systems are not directly used in rip but it is used in the other algorithm this is very important for scaling the network we know that whatever routing protocol we are following this has to scale to the global level for millions of routers which are connected to each other the router may be connected to a network the number of routers together may form an autonomous system here we are introducing another level of hierarchy autonomous system is a region of the internet that is administered by a single entity  therefore this is not just one network but a collection of networks some examples of autonomous regions are service providers  mci ? s with its own backbone system or regional internet service providers the regional internet service providers are giving the services to so many customers and each customer has their own router connecting to this backbone each of the customers will have his own network so it is a collection of networks in a way but this is one autonomous system the idea is to run the same kind of protocol inside this autonomous system there are two questions here ; one is that  what is the routing protocol you are running inside the autonomous system  and what are the routing protocols you are running between the autonomous systems thisis because finally your packet may go to a router to a network to the backbone of the same autonomous system still then it might have to hop across some autonomous systems and then finally enter into another autonomous system and go all the way down to a particular network and then to the intended host so  autonomous systems introduce another level of hierarchy routing is done differently within an autonomous system that is the intra domain routing and between autonomous systems which is the interdomain routing rip is suitable for intradomain routing for the time being we are talking about intradomain routing but will look at interdomain routing later on  refer time slide from 13  47 to 14  23 min  the characteristics of distance vector routing  one thing is  it uses periodic updates updates of the routing tables are sent at the end of certain time period  a typically value is 90 seconds this means every 1 ? minutes you send your updates which are the distance vectors to your neighbors there may be triggered updates if a metric changes on a link a router immediately sends out an update without waiting for the end of the outdated period because if some link has gone down or some thing has become really congested or some parameter has changed then at that point a router may not wait for the lapse of that 1 ? minutes but send immediate updates triggered by some kind of an event  refer time slide from 14  55 to 15  35min  there may also be full routing table updates most distance vector routing protocol send their neighbors the entire routing table not only entries we change in some cases of a triggered update you may send only that data which has changed and then from time to time you send the full which is your distance vector route invalidation timers  routing table entries are invalid if they are not refreshed a typical value is to invalidate an entry if no update is received after 3  6 update periods what might happen is that instead of a link going down a router itself may go down and then that router is not sending anymore updates to anybody but after 3 ? 6 update periods its neighbors find that they are not getting any thing then it will set that link to infinity that route or any route through that particular router which has gone dead will become invalid and this information will slowly percolate through the entire network so this  refer time slide from 16  25 to 18  05 min  change is a problem in routing because this change has to traverse globally everybody finally have to know but it takes time we have seen distance vector routing and now we shall look at the actual protocol which is called rip or routing information protocol this is a simple intradomain protocol that means it is in the same autonomous system straightforward implementation of distance vector routing is the distributed bellman ford algorithm each router advertises its distance vector every 30 seconds or whenever its routing table changes to all its neighbors rip always uses 1 as link metric therefore negative cycles are not present the maximum hop count is 15 with 16 = 8 which means it is rather a low value for infinity and the reason we need to keep the hop count is that a packet which has been misdirected may have to be dropped and secondly what we are talking about here is this 15 that means it is giving you the length of the maximum number of hops within this autonomous system  within this domain it is not that from the source to the ultimate destination it has to be 16 but within the domain there can not be more than 15 hops routes time out is set to 16 after 3 minutes if they are not updated  refer time slide from 18  05 to 18  26 min  a brief history  in the late 1960 ? sdistance vectors protocols were used in the arpanet which is the beginning of this internet era mid 1970s  xns xerox network system routing protocol is the precursor of rip in ip and there were some other versions also  refer time slide 18  27 to 19  33 min  then this was sort of integrated in bsd distribution of unix rip version one was formalized using this rfc request for comment this is the standard way of formalizing things in the internet world through rfc ? s so  for any topic in this network you can possibly try to find rfc which will give you the most authentic source of information about that so  version one was described in rfc 1058 and after encountering certain issues with rip version one people came out with rip version 2 in 1993 that was rfc1388 so it adds subnet masks with ip address with each route entry that allows classless routing the original version is classful routing then classless routing was also possible with current version of rip 2 is in rfc 22453 which came out in 98  refer time slide 19  33 to 21  20 min  so what is the packet format of ripv1 ? a command would be either request or response so you may either request some information from some other router or you may be giving information in response to some request the command would therefore be one or two and the version would be rip version one and then you have an address family and this is 2 for ip  from 0 to 0 this is request full routing table if you put it this way it means that you are requesting the full routing table and then you have the address of the destination where you are sending this message and then these parts are unused so this is 20 bytes  this is one route entry there may be many such route entries up to 24 more routes each of 20 bytes so this is actually 32 bits of the total so  32 bits means 4 bytes so it is 4 + 4 = 8  12  16  20 so one rip message can have up to 25 routing then the cost measured in hops is also mentioned  refer time slide from 21  21 to 26  27 min  rip version 2 is an extension of rip version one subnet masks are carried in the route information now what is a subnet mask ? in your full ip address which is 4 bytes for the time being in the ip version 4 you have a 4 byte address  so 4 bytes is 32 bits out of which the first part would be the network prefix and the last part is the particular host in the network prefix now the question is  which part of it or how many bits is the first prefix which shows the network and how many bits are there to show the host ? now there were some standards here these are the so called classful days but there were class a  class b  class c etc these are classful where it is mentioned that for class a address the first byte would be the network prefix and the last three bytes are for the host which means you can have a very large network with a large number of hosts on the other side of the scale you have a class c where 3 bytes would be the network prefix and one byte would be a small network or limited to less than 255 hosts but a larger number of such networks are possible but even then what happened was that originally no one realized that the network world will grow into such a manner so only 4 bytes were kept as this address and this address space really became small suppose in an organization there are only 30 machines you will network them and then you want to connect them to the internet and for that you have to get some ip addresses now  if this network is to be specified completely then it has to be given a unique ip address for the network prefix part so at best what you can do is that give it a class c address which is say 3 bytes long so  that 1 byte is left over for up to 255 machines in your organization but then you are using only 20 of them so a part of the address space is not used now  in order to do that people wanted more flexibility in saying that how many bytes contain the network prefix and how many bytes contain the number of hosts and that would be host part of the address so you have to specify that how many bits are present so now we are going from classful routing to classless routing this classless routing has to carry that information called as the subnet mask so subnet masks are carried in the route information so that we can do classless interdomain routing authentication of routing messages was there because routing version one had no security and if it has no security what could happen is that a router might send all kinds of arbitrary distance vector messages to its neighbors creating problem everywhere when things become very big then you start thinking of different kinds of possibilities so you try to change so some authentication was included in rip version 2 although the authentication is not very full proof route information carries next hop address and exploits ip multicasting what is multicasting ? right now we are talking about unique casting this means there is one source with one message meant for one destination sometimes you want a message to be destined to a group of destinations you do not want to broadcast it  you do not want to send it to everybody may be there is a special interest group so you all only want to send to members of this group which is called multicasting so ip multicasting exploits in some sense so extensions of rip version two are carried in unused fields of rip version one messages  refer time slide from 26  27 to 26  55 min  in the ripv2 packet format as usual the command contains one or two whether it is a request or a response and then in ripv2 there is the address family  address of destination and then the cost measured in hops  refer time slide 27  11 to 27  56 min  what happens here is  this field is used for the subnet mask for ip address so you have an ip address over here  you see the how it is changed and the subnet mask has come here so that now you can do classless routing next hop ip address identifies the better next hop address on the same subnet than the advertising router if one exists  so that may come here and these are the changes and used to carry information from other routing protocols  for example autonomous system  number  etc comes in this part  refer time slide from 27  56 to 29  51min  now a little bit about rip messages  this is the operation of rip in routed so this routed is actually a command a dedicated port for rip is udp port 520 if you remember we had come across tcp and udp earlier these are the transmission level protocols which are at a higher level protocol than these network layers so udp is one such which has got very low overhead so we will talk both about udp and tcp later on but this is a higher level protocol and they use ports ports means for any message transferred between two nodes so many different transmissions may be going on from the same node to different processes in different hosts in order to de-multiplex them  unscramble them  when there is an incoming message and you want to know for which machine it is sent to  then with the help of the ip address you can find out that this particular process is for this particular machine designated by a port number this is a number which you get from the operating system if you ask for it so  for rip there is a particular port which is specified which is 520 for standard protocol there are standard ports which are assigned there are two types of messages  one is a request message used to ask neighboring nodes for an update and response message which contains an update  refer time slide 29  55 to 03  28min  rip packets are sent using udp hence may be lost actually udp is one transmission protocol which has a low overhead and the other side of the coin is that it is less reliable than its sister tcp which is more reliable so updates may be lost updates are done asynchronously after receipt of new distance vector from any neighbor if arriving distance vector includes a new destination network routing table is augmented to include this that means routing table now increases in size  refer time slide 30  29 to 31  20 min  and that is very important because when you power up your routing table may not contain anything as you get more and more information from your neighbor your routing table grows every router normally sends update to each neighbor every 30 seconds if the current route from node k to network i has a router n as next hop and if k has not received update from n in for 180 seconds which is 3 minutes it assumes failure that means 6 such update periods then it assumes failure of n or the network connecting k and n this does not matter because either ways it is the same for k and it marks the route invalid invalid routes should be replaced as soon as a valid one is found now  refer time slide from 31  20 to 32  20 min  how does it initialize ? send a request packet command equal to 1  address family is equal to 0 to 0 that means you are looking for the ip addresses and all interfaces that means you flood a request at all interfaces ripv1 uses broadcast if possible  ripv2 uses multicast address if possible the point is that when it is initializing it is asking for information from all possible sources of course its sources must come through one of the interfaces so it sends out the request through all the interfaces may be one by one or by some means requesting routing tables from neighboring routers means we are trying to get full routing tables from the neighboring routers  that is the initialization phase  refer time slide from 32  20 to 32  35 min  request received  when routers that receive the above request send their entire routing table and response received update the routing table naturally you update the routing table using your distributed bellman ford and then after some time when things are more stable the regular routing updates every 30 seconds send all or part of the routing tables to every neighbor in a response message and then there are triggered updates whenever the metric for a route change something becomes invalid then send the entire routing table  refer time slide from 32  59 to 33  12 min  issue  one is the security issue  sending bogus routing updates to a router ripv1 has no protection ripv2 uses simple authentication scheme we have mentioned about this authentication earlier  refer time slide from 33  13 to 33  35 min  what you may have is a few passwords unfortunately these passwords are of course plaintext passwords so it does not give you too much of security but at least it is better than ripv1 which had no security whatever  refer time slide from 33  36 to 34  13 min  there are some problems with rip  rip takes a long time to stabilize even for a small network it takes several minutes until the routing tables are settled after a change so that is one problem with rip and rip has all the problems of distance vector algorithm  for example  count-to-infinity we will come to this specific problem later on rip uses split horizon that means with reverse poison as it is usually said to avoid count-to-infinity  refer time slide form 34  13 to 34  36 min  so this is the count-to-infinity problem the problem is routers react to good news quickly the min operator brings down the value in one go in a sub net with n hops every router knows about it in n exchanges however it reacts slowly to bad news as other neighbors mislead the routers gradually all the routers count their way up to infinity so this  refer time slide from 34  37 to 37  17 min  is the problem suppose these are the 3 routers a  b and c with this one  c can go to a via b and the cost will be 2 and a can go to c via b and the cost is 2  b can go to c straight away with a cost one now suppose the link c goes down then b immediately finds out about it or after some period may be 180 seconds from then and it does not have any way to go to c so b may set c to infinity but look at what a does a had cb 2 so basically its routing table says that it can go to c with 2 because a still does not know about this mishap so it will have this c2 in its routing table which may be sent so c infinity is being sent from here to here  c2 is being sent from here to here now b sees that a can to go c with 2 so for going to c the b will now set a as the next hop and keep a cost of 3 a of course will realize that it can not take that b next because b is advertising c as infinity so it will make it to infinity now we have c infinity here and c3 here  exchange again and now this one becomes c4 and this one becomes c infinity so this way both of them start counting to infinity what was the problem ? the problem was a was sending c to  that means a was going to c via b but it was telling to b that it can go there at a distance 2 without realizing that this might mislead b so one heuristic which was said is that if a is really going to c through b then to b instead of saying c2 it should say c infinity so this is the  refer time slide from 37  18 to 37  38 min  hack so to say which was used the reason to the count-to-infinity problem is that each node has only next hop view for example  in the first step a did not realize that its route with cost 2 to c went through node b how can count-to-infinity problem be solved ?  refer time slide from 37  38 to 38  12 min  there is a one solution this is a proper solution but this is not used in rip always advertise the entire path in an update message that means you give the entire path if the entire path was given then this would not have happened but that is not done so  if routing tables are large the routing messages require substantial bandwidth there is a interdomain routing protocol called bgp which uses this solution  refer time slide from 38  12 to 38  46 min  this split horizon hack is that a router never advertises the cost of a destination to its neighbor n if n is the next hop to that destination so a never advertises c to b or in split horizon with poisonous reverse it advertises a cost of infinity this does not prevent three way count-to-infinity but this is a hack this is not a solution because this takes care of some of the cases but this may not take care of all the cases  refer time slide form 38  46 to 40  39 min  these are the details suppose you have this network a b c d e with this kind of cost associated it with it  now consider the router e so e distance tables from neighbors  from a it may get this  0,7,8,8,1  that means a to a is 0  a to b is 7  a to c is 8 to start with and a to b is 8 so distance table e sends to its neighbors so to a it sends a8 because it has to go to a itself  actually again it goes directly so to b also it sends 8  what it sends to d you just look at this value it tells that its cost to c is 8 although to b it says that its cost to c is 4 because to b it says that i can go with a distance 4 because it can take this route from e to c whereas it advertises a cost of 8 to d because the path that e thinks it can take with a cost of 4 passes through d so to d it says c 8 rather than c4 which is advertised to a and b so this is the split horizon with reverse poison  refer time slide from 40  40 to 41  05 min  but look at this case suppose you have a network structure like this abc and d so these are all routers which are very fine in order to simplify things let us say all the links have a cost of 1 now  refer time slide from 41  05 to 42  42 min  when the link between c and d fails which is this link then c will set its distance to d as 8 however a will then use b to go to d and b will use a to go to d because there is no reverse poison between them what is happening is that previously  b knows that it can go to d through c with a distance 2 a knows that it can go from a to d with a distance 2 now c is saying d is 8 but b is saying d is 2 now b then sends to a and a sends to b and mutually they start counting to 8 not realizing that both of them were actually going through c but there is no reverse poison between a and b  there is reverse poison between b and c  there is reverse poison between a and c but between a and b there is not reverse poison so they will mutually start counting to 8 after such updates a and b will then report new path to c for d and c will use the path now a will tell c that it has got a path to d through b of course and c will not know and now c will also take that so for any thing from d it will send it to a  a will send it to b and things like this will go on without any packet getting anywhere we thus have the count-to-infinity problem again  refer time slide from 42  43 to 44  07 min  other limitations of rip  the simple metric of hop count does not permit traffic-caused delays to be taken into account in routing so  when we are just talking about the hop count this is a limited kind of metric so basically we are seeing whether we can reach there at all but there are other kinds of metrics which may be important that means some of the links may be very weak or of low capacity then again some links may be very expensive  somewhere the reliability may be poor etc and all these metrics which may be important in today ? s world where the network communication is very important then you can not handle it in rip so that is one problem limitation of rip another limitation is if i6 hops are regarded as 8 then rip can not be used for networks for which there are distances exceeding 15 if there are distances exceeding 15 then rip can not be used so  by today ? s standard that may be a small value if infinity is regarded as corresponding to a larger number of hops then protocol will be very slow to converge upon initialization or on topology changes the point is that  if you see a value of 16 or if something has gone up to a value of 16 you know that that is infinity and you can forget about it whereas if you simply change that infinity from 16 to 16,000 then you will have to count right up to 16,000 so the thing would be very slow to converge convergence rate after topology change or after crash etc becomes an issue in rip we will now just look at an example  refer time slide from 44  43 to 45  40 min  suppose this is the situation and then in the initialization phase a sets itself to 0  d sets itself to 0  e sets itself to 0 and so on then they solicit router advertisements then what will happen is that when they get the distance vector d will respond and b will also respond so a would know that these 2 routers b and d are just neighbors so it can put a distance 1 in b and d and the same thing goes for all the routers so to get their next step so  direct neighbors come in after one exchange if there are values over here like 10  2  2 as distances etc these values get transmitted there so we get a0  b10  d1 for a similarly for d it gets e2 c2 and a1 therefore the routing table starts getting filled up this way then of course after the second step you get neighbors of neighbors and so on so this routing table has now become 0  10  3 etc so this is on going  refer time slide from 46  20 to 46  49 min  then neighbors of neighbors of neighbors so those are basically 3 hops away and slowly these values are converging to the correct values from a to d you can go to 1 and a to e you can go with a step of 3  a to c is 3 and a to b is 10 and a to a is 0 so now after three iterations it has stabilized so this is a stable convergence  refer time slide from 46  50 to 48  36 min  and no value changes any longer the ones in red were showing the values which change but now there is no change any longer now a new link has come up between b and c with a distance of 1 now this message will start getting transmitted through the network like this as soon as there is a communication between b and c both of them know that c has b as neighbor with distance 1 and b has c as neighbor with distance 1 so these are the direct endpoints then in the next step the neighbor of e will know the neighbor of c which is namely d will also know that they can reach b very quickly previously if you remember they had values like 11 and 13 so e had to go to b through 13 when it did not know because it took the route b to d to a to b so that is 2 + 1 + 10 = 13 but now since it can go to reach c and 2 and c can reach b with distance 1 so now it has updated the distance to b as 3 and distance to b as 3 so from 11 and 13 these values have come down in 1 hop and a of course still does not know now a knows that from going to b it need not take this route which is a very high cost path but it can go via c with a distance of 4 so now neighbors know  refer time slide from 48  37 to 48  55 min  once again we have a very happy and stable network the point was that this good news traveled as fast as the number of hops because in one go in the main function will bring down the value to anything but now suppose there is a bad news that  refer time slide from 48  59 to 49  08 min  means this link has crashed then what happens ?  refer time slide from 49  08 to 49  34 min  direct endpoints will know that it can no longer go in between b and c previously b for example thought that it can go to a through 4  there should be another entry that it can go through a through c similarly it can go to d through c once again  through e to e through c once again now when the link from b to c fails all these entries now become invalid because this link has crashed so  direct endpoints would know that some of their entries will vanish in the next step it will now set to a as 10 and when it gets the entire thing then it will set to something else  it will get help from neighbors so go to a to 10 and a says that it can go to c with a distance 3  d with a distance 1 and e with a distance 3 etc so it adds 10 to that so b gets all these values unfortunately there is a routing loop now  refer time slide from 50  35 to 51  12 min  due to inconsistent state information because now c knows that in order to go to b it can take a path of cost 5  how ? it is because there is no way it can reach b through 5 the point is  it has been misled by its neighbors  the same thing that was happening in count-to-infinity  refer time slide from 51  15 to 51  37 min  so they now mutually start counting to infinity for going to b until they reach a value which will force them to go through this link once again so this count-to-infinity will continue till we will reach the limit and come back to stability once again these kinds of limitations and problems were there in rip so one good thing about rip was that rip is a simple scheme  simple algorithm and actually it was conceived in days when networks were smaller but as networks grew bigger and bigger it had problems this count-to-infinity problem is actually a small problem but other major problems why rip could not be used when the network really scaled up for very big networks was this problem of having a low value of infinity and making the value larger makes the problem of convergence worse and then secondly it is that you are really doing this one domain whereas in today ? s world with millions of networks you require a hierarchy of domains you require these autonomous systems and other hierarchy etc the other limitation you was that we were unable to talk about the quality of the links since we were unable to talk about the quality of the links some of the routes which rip might set up may be much less than optical one thing that is very sure is because there is a lot of difference between the capacity of the links  you get capacities like 64 kbps on one end of the spectrum  you get capacities like 155 megabits per second may be in another side of the spectrum but the point is that these two values are several orders of magnitude away from each other but rip has no way of taking all this into account so this was also important so what happened was that people moved from this to another algorithm which is sometimes called link state algorithm just as rip is sometimes called distance vector algorithm because it exchanges distance vectors similarly there is an algorithm which exchanges the state of links globally since it exchanges the state of links globally then do some local processing and that algorithm is called open shortest path first ospf so this has got some advantages over rip  refer slide time  54  43  54  45  good day  so today we will talk about ip version 4 that is the internet protocol version 4 this internet protocol is really the network protocol of the entire stack and actually is at the heart of data communication and as it turned out that it became so successful that also other kinds of communication like voice  video etc are also coming over to ip in a big way in many segments so  today  refer time slide 55  23 to 55  26 min  we will talk about the ip version 4 and  refer time slide from 55  26 to 56  50 min  just a quick review of the stack that ip or the so called internet protocol is designed to connect networks that are possibly managed by multiple organizations or people the internet that we see today is a connection of network of networks so various networks are naturally owned by different organizations of people and also managed by different people but if they have to communicate they somehow have to come together namely to one central network layer protocol and ip is that protocol it may have different physical connections naturally if there are different networks having different connections it may have different physical connections and it may be connected via sequence of arbitrary intermediaries arbitrary intermediaries in the sense that when you are communicating from one computer to another computer these two networks also may not be directly connected and they may go through other intermediate networks so there may be a number of hops before your communication reaches its destination in the very beginning we discussed about layered approach which is used to simplify the application  refer time slide from 56  50 to 57  35 min  this is just an example let us say we have http which is the protocol used in the application layer so this http protocol may use a tcp connection this is another layer called the transport layer so we will talk about this later which communicates with the ip and which then may communicate with ethernet but you please note that below the ip there may be a multiplicity of different data link layer protocols like the ethernet is one  token ring is another so they can communicate because of this integrating protocol ip which is common to both  refer time slide from 57  35 to 57  44 min  so it is a single protocol at network level that insures packets will get from source to destination while allowing for flexibility  refer time slide from 57  44 to 58  18 min  so we have the so called hourglass design we have ftp  http  tftp etc and all these different application layer protocols are at the top then we have the transport layer and their two common protocols are tcp and udp but all of them integrate to one single network layer protocol namely ip and this ip may connect to different networks running different data link layer protocols  refer time slide from 58  18 to 59  30 min  just to look at how the encapsulation goes  we had discussed this earlier may be in the first or second lecture so  suppose we have the user data being fed to some application then that particular application will have its own header computer networks prof s ghosh dept of computer science and engineering i.i.t  kharagpur lecture number ? 28 ip version 4  refer slide time  00  46  good day  so today we will talk about ip version four 4 that is the internet protocol version four 4 tthis internet protocol is really the network protocol of the entire stack and actually is at the heart of data communication and aas it turned out that it became so successful that also other kinds of communication like voice  video  etc they are were also coming over to ip in a big way in many segments sso today  refer slide time  01  23  01  26  we will talk about the ip version four 4 and  refer time slide  01  26  02  50  just a quick review of the stack that ip  or the so called iinternet pprotocol is designed to connect networks that are possibly managed by multiple organizations or people tthe internet that we see today that is a connection of network of networks soso it is a of various networks sso and various networks nnatnataturally are naturally owned by various different organizations of people  managed by different people they are so managed by different people bbut they if they have to communicate  they somehow have to come together and agreed to one1 central protocol  one1one central network layer protocol and ip is that protocol  iiit may have different physical  noise  connections natnnnataturally if there are different networks having different connections so it may have different physical connections and it may be connected via sequence of arbitrary intermediaries aarbitrary intermediaries in the sensemean that when you are communicating from one1one say computer to another computer theise two networks also may not be directly connected  they may go through other intermediate networks sso there may be  noise  number of hops before your  noise  communication reaches its destinatnatnation aas we have discussed earlier in the beginning we discussed because with this we have discussed in the very beginning aboutt that layered approach   noise  which is a  noise  which is used to simplify the application   refer slide time  02  50  03  35 min  we just quickly have a lookok at the layered approach it tthis is just an example  letlet us say we have http which is the protocol used in the application layer  for  noise  well  noise  so this it http protocol this may use a tcp connection alright so tcp this is another layer this that is called the transport layer so we will talk about this later which tcp communicates with the ip and which then may communicate with ethernet bbut you please note that beyond  noise  below the ip there may be a multipiplicity of different data  noise  link layer protocols like ethernet and is onetoken1 token ring is another so they can whichthat communicates because of this iintegrating  noise  pprotocol ip which is common to both  refer slide time  03  35  03  44  sso it is a single protocol at network level that insures packets will get from source to destinatnatnation while allowing for flexibility  refer slide time  03  44  04  18  so wwe have this so called the hourglass design  noise  so we have the like ftp  http   noise  tftp etc  are all these different application layer protocols are at the top  thenthen we have the transport layer so and their two common protocols are namely tcp and udp over here but all of them both integrate to one1one single network layer protocol namely ip and this ip may connect to natnnataturally different networks running different  noise  data link layer protocols  refer slide time  04  18  06  30   noise  jjust to lookok at the how the encapsulation goes once again  we had discussed this earlier smay be in the first or second lecture  noise  so suppose we have the user data  which is being fed to may be maybe some application  then so there is an  noise  that particular application will have its own header  tthis header information is what is used for  noise  protocol between peers at the same layers so tthe application layer of this host will communicate with the application layer of the other host through this application header information  thenand this is passed to the transport layer where the tcp  noise  tcp is the transport layertcp the transport layer protocol which is being used here the then tcp header gets added and then it is passed to the network layer when it is coming down and when  so this wwhile coming down  while some thing something is being sent where so this the and the ip header gets added at the network layer so so as far as this ip protocol is concerned  this entire thing containing the tcp header  application header  user data etc etc is the payload ssimilarly  for tcp the application header and user data together is the payload so so  whatever is inside the tcp does is not really consider thiscerned with that ssimilarly ip considers the this entire thing as the payload and then it sends to the next layer which may be ethernet as an example ethernet adds a header as well as the trailer we can see and some some of the overhead that maywe incur  noise  in this  for example  this tcp header is twenty 20 bytes  ip header is twenty 20 bytes  ethernet header is fourteen 14 bytes and it has got a four 4 byte trailer ,ok and then this entire thing is payload for the ethernet which which i mean has a minimum this thing of forty six46 bytes to  fifteen hundred1500 bytes etc so tthis is how it comes when it ? s data is being sent  and when data is being received it is in the other way  that  the first layer will take out the first  noise  these two headers and trailers  then the ip layer will take out the ip header  lookok at it and pass it up the tcp header that and that will get stripped and finally the user data  noise  finally it will reach the application layer  refer slide time  06  31  07  38  so i meanby lookoking at it the other way  that means suppose we have the ethernet driver  this whichthis is really the lowest level  so herein the tree that has been shown  noise  upwards so in thesuch that when when something comes to ethernet well it may it has so many network  noise  protocols in the next layer but these arp you know is the address resolution protocol which is that given an ip address then  .askingfinding the what is the mac address  here this is the reverse of that as given the mac address  finding the asking ip address.of that that given a mac addressip address what is the ip addresses any way so these are used for communication within a same network but otherwise most of the traffic comes to ip and then  noise  above above the ip layer this thisere is tcp  udp  igmp this which isused for multicasting  we will talk a little bit about this latter on with and icmp internet control protocol we will talk about this little bit later on so this  noise  but mmostly the these applications really i mean these are for control and multi casting functions but the major part of the communication comes to this through this tcp and udp and they connect to the various applications which may be running at the application layer so and this how it is demultiplexedde-multiplexed  refer slide time  07  38  09  51  jjust to summarize this ipv  noise  v four 4 protocol  we have ip is a as theis the best effort connectionless protocol it is a best effort okand that means  noise  that the intermediate nodes will try to  noise  i mean get your packet to the proper destinatnatnation as best as possible but if it is not possible  it will drop the packet ok soand thisthis does not give you any guarantee about the delivery of the packet at onat the other end  but it is understood that all the  noise  nodes in between will make its best effort  noise  what does that mean ok it maythis means that supposesuppose you consider a router which is somewhere  noise  in the network now  now it is receiving packets from so many sources and they are destined to many other different networks iit may so so happen that because of the pattern of communication  the router may get congested so so and if it is congested as  there are so many packets coming in then it can not hold so so many packets are coming in it them just can not hold them in its buffer any longer  ss so it willis be force to drop some packets alright so it aalthough it will make the best effort but then it is this is not this is not a guarantee and and then secondly  this is connectionless you andyou remember  noise  about connection oriented and connectionless protocols ?  ffor example  our telephoneone1 network was a connection oriented protocol but here  this is a connectionless and thatthat means from the source to the destinatnatnation  there is no  noise  guaranteed physical or virtual connection between the two alright soandand what would happen is that if you are if you are sending a stream of packets from one1one source to the other what might happen is that some of the packets may take one1one route and then some of the some of the other packets may take another route where  they may reach the all of them may reach the all of them will reach their destinatnatnation but they may get out of order  and so on but so this is the all the partisthese are all part of the connectionless protocol it iswith a datagram or packet oriented protocol  you can get an ip packet from anyone1one without any setup or connection establishment packets packets are normally routed using destinatnatnation routing that means the destinatnatnation is known and how to get to the destinatnatnation  that is what is stored in the routing tables  youyou specify where the packet is to go now  and not how it gets there  refer slide time  09  51  10  46  now tthere are some more parts youyou can optionally specify source routing that means at the source itself there is a provision inin iinternet pprotocol there is a provision that in is the source itself  you specify that this is the route through which it will it should reach the destinatnatnation  it is possible to do that  noise  ffor example  if if you remember our bgp uses source routing bbut any way in general for internet packets it is possible to do the source routing but this is some whatsomewhathow limited because  the  noise  number of hops you can specify becomes restricted because of some limitations of ip v four ip version four 4r protocol structure we will come to that later on and eeach packet is routed independently and tthat means they can be delivered out of order or might not be delivered at all  refer slide time  10  46  11  19  now wwe nownow we come to this important topic of ip addresses the ok the ip address is a thirty two32 bit address that is four 4 bytes ok thirty two bit means four bytes itwhich identifies the network and the host on a given network  noise  it is divided into two parts  first part identifies the network and the second part identifies the host in the network tthe form is not the same for if the format is not the same for each address ok sso this is an important point to understand that when you are given an ip address  it is a thirty two32 bit address  theise thirty two32 bits areis actually divided into four 4 bytes ok and each byte is usually read out  noise  or in decimal separately ok so you can get a  noise  anyou can get a ip address like one1 forty four dot sixteen dot nineteen dot twenty three144.16.19.23 ok so this where this one1 forty four144  is the decimal equivalent of the binary string which is in the first byte of the address then we have 145.16 where  then one1 forty four dot sixteen144.16 dot is just separates the two bytes so sixteen 16 is the next byte andso next byte contains the decimal  noise  binary equivalent of sixteen 16 sso  if you convert this one1 forty four sixteen ninety two and three144161923 separately into binary  noise  into bytes which are the that means binary strings and put them together that gives you the thirty two32 bit address sso or or or in other words the thirty two32 bit address is usually read out this way now now in this  noise  in this four 4 bytes ok there is some part in the more significant part of it  then there is some part which specifies which network you are in and there is there is some part which specifies that which is the host in that particular network ok  noise  this this is the same concept as if when you think about anof a postal systemm  ok so wherein the postal system you give the name of the town and then you give the name of the street or the house bbut alright so the people outside we will not really know about the streets in a distant town ok sso tthey will just lookok at the  noise  at the town name or the so called pin code and just simply send it there tthen those people will figure out as to where is it that this that particular house or this street is in that particular town ok soso we have a network part which is usually mostly seen by people which is important for people who are outside who are trying to route into this network  and then there is a host part which is important within the network sso once it has the packet has reached this particular network  then it has to reach a particular host  so that this is where the host part comes in ok  refer slide time  13  42  14  26  tthere are three types of  noise  addresses in one1one sense ok tthere are other classifications alsowe will come to that later on  butbut one1one is that  it is for unicast communication uunicast means it is destined for a single host  sso  it is originatnatnating somewhere and this destined for a particular host ootherwise  there is broadcast communication  itwhich is destined for all hosts on a network sso inin a particular network if you want to send some message to everybody then you can use this broadcast communication oor  there may be multicast communication whichthis is destined for a set of hosts ok tthis is a subset of hosts all the hosts which are there in that particular network that which belong to a particular multicast group  sso  that is called multi for multicast for multicast communication  refer slide time  14  26  15  18  aas we have  noise  i have already seenexplained  the thirty two32 bit number is represented in the following format it is actually that means there are some something dot something dot something dot something where ? ? ? triple xxxx is the decimal representation of the binary bit string  forfor example  say one1 forty four dot sixteen dot seven dot four 144.16.7.4   so soone1 forty four144 if you see the first byte so so there are there are these byte so this is these it has got a place value of one1 twenty eight one1 twenty eight plus sixteen128 + 16 for these two one1 so that itwhich makes it to one1 forty four144 this is so tthis is the binary equivalent of one1 forty four144 or one1 forty four144 is the decimal equivalent of this sso this is the ip address four 4 bytes of it  and the corresponding decimal equivalent of each of the bytes is given one1 forty four dot sixteen dot seven dot four144.16.7.4 soso this lookoks like a valid ip address  refer slide time  15  19 to 20  51  aas for another classification of ip addresses  ok so there are they are divided into five classes this five classes  noise  we are by the way we are talking about ip version four 4 ok so in ip version four there are thesehas five classes a b c d e where a  all class a addresses start with zero0 0  so it has a prefix of zero0 0  class b has a prefix of one10 zero01 0  class c has a prefix of one1 one1 zero0 1 1 0  class d has a prefix of triple one1 zero01 1 1 ,0  and class e has a prefix of four one1s1 1 1 1 sso you can see  noise  that they all have unique prefixes and by lookoking at it  you can make out what it is irrespectiveirrespective of what values are here  you can make out which class it is now as i said that the  noise  aan ip address contains two parts  one1  noise  the first part is the network id and the rest of the of it is the host id nnow just consider the class a address  class a address  so the first byte  noise  is given to the network id and of course of  noise  of of the first byte  the first bit is zero0 0 indicating that this is a class a address and then so you have seven 7 bits left for network id sso you can have at most  noise  one1 twenty seven127 or one1 twenty six126  noise  networks as as a class a because that is the because we thathave only hasveonly have seven 7 bits to represent it andand in each of this network  the host id has a this thing of  noise  has a has twenty four24 bits for specifying the address of the host in that network sso for twenty four24 you have actually 2two to24 the power twenty four which is about sixteen 16 million so particular class a address  noise  i mean if you have a iif your organization has a class a a address  which is very unlikely but anyway if your organization does have a class a address  then this is one1one big network of that one1 twenty seven127  noise  networks that could be there world wide big networks which h  real big how big w well as as many hosts as are there in the network and how many hosts can be there ? ffor the host address  part we have kept twenty four24 bits which means that there can be a possibility of 2two24 to the power twenty four or about sixteen 16 million hosts  so there could be a network with sixteen 16 million computers in it ok this is very very  noise  i mean unlikely nno body has such a big network anywayand this is very unlikely to happen  we will come to that part later on but thisthis is how a class a address is specified so nnext we go to class b which is in the same way but here instead of one1 1 byte  noise  for specifying the network  we have two 2 bytes for specifying the network oout of theise two 2 bytes the first two 2 bits areis one1 zero00  so that is already gone1gone and the rest fourteen 14 bits  noise  are for the network id sso two to the power fourteen214 is about sixteen thousand16,000  so you can have sixteen thousand16,000 different class b networks andand in each network can contain two to the power sixteen216 hosts which is about  noise  sixty four thousand64,000 hosts  so these are also big networks fairly big networks  noise  but i mean tthere are networks which are of that order  noise  but you have only two to the power fourteen214 or sixteen thousand16,000 such networks but you can not have more ffor class c three 3 bytes are given for the  noise  network part and only one1 1 byte  sso a class c network can have only two to the power 4eight28 that is is two fifty six256 hosts  so that is a real small network ok but we you can have a large number of them namely you can have about two 2 million such networks 2two21 to the power twenty one1 cclass d is for multicast group and class e is really experimental  so they start with triple one1  zero01110 so aaso after triple one11110 zero0 the  noise  entire twenty eight28 bits is for specifying which group  butbut this does not work very well  so we will come to that later on sso if you see since you see that if class a ranges as dotted quad so a is zero0 point zero0 point zero0.0.0.0 of course all zero0ss 0 is not a valid particular address but anyway  so we are giving the outer limits of it to  noise  to one1 twenty seven dot two fifty five127.255 etc so  noise  so the sso by lookoking at the first decimal number which is corresponds to the first byte  we can immediately make out  noise  that whether this is a class a  class b  class c or class d etc  address because  noise  class a address can not be more than > = more than one1 twenty seven127 and if the first digit or the first decimal number is less than < = less than one1 twenty seven127 = less than or equal one1 twenty seven127 then  you know there are = less than one1 twenty seven127 actually then you know that this must be a class a address iif it is from one1 twenty eight to one1 ninety one1 128 to -191 then you know that this is a class b address and so on sso  by lookoking at the first  noise  decimal number which is the equivalent for the first which is the equivalent for the first because you see the first byte is being dictated this way depending on the class of the address that is how asso that is how then they come to a particular range of numbers so  by looking at the first number  lookoking at the first number we can know that which class of address it is  refer slide time  20  52  21  21  ok sso this class a a now that is obviously used for very small number of networks and large number of hosts  very small number of networks hereactually firstfirst byte represents the network address this we have this thing,and the last three bytes represent the host address cclass a address have a first bit of zero0 0 and class a network addresses range from zero0 to one1 twenty six one1 twenty seven0 to -126 and  127 is actually reserved for something else  refer slide time  21  21  21  49  cclass b it provides an equal number of networks and hosts ffirst two 2 bytes are network address and last two bytes are host addresses ffirst two 2 bits of a class b addresses are  noise  one1 and zero0  so you can only have you can only have sixteen thousand16,000 such classes b  noise  networks and network addresses range from one1 twenty eight to one1 ninety one1128 to -191  that is the first decimal number for the first byte  refer slide time  21  29  22  03  cclass c  noise  is a greater number of network addresses  fewer host addresses ff the first three 3 bits are one1 one1 zero0110 soso network addresses range from one1 ninety two to two twenty three192  223  refer slide time  22  04  22  11  cclass d is used for special multicast addresses ffthe first four 4 bits of class d are is triple one1 zero01110  we will talk about multicasting later on  refer slide time  22  12  22  21  in some more detail cclass e is used for experimental purposes ffthe first four 4 bits of class e areis one1 one1 one1 one1 1111.ok  refer slide time  22  21  25  42  now tthere are some special source addresses so special source addresses as part of an initialization procedure for example bootp tthiseis host on this network  theis is net part is zero0 0 and host id part is zero0 0 tthat means well when i say the net part is zero0 0  now depending on which class of address  it is the entire  noise  network sssuppose it is and suppose it is the class c address thenso the first three 3 bytes are really the  noise  network part  so it will be zero0 dot zero0 dot zero0.0.0 and the host part is zero0 .0 so so if you say zero0 dot zero0 dot zero0 dot zero00.0.0.0 it means that if you say that that it means yourself that means whoever is saying zero0 dot zero0 dot zero0 dot zero00.0.0.0 is meaning himselfit is itself alright sso this is sometimes required f  noise  ffor example in bootp protocol  you require to  noise  referreferring to yourself  specified specified host on this particular network   so so you keep the network part zero0 0 and the host id for this particular host that you want to specify  suppose this this is a class c address  so the in a class c address  noise  the host part is given only by the last byte ssuppose the last byte has a decimal value of whatever lets say maybe one1 thirty130 or something ok so so if you say zero0 dot zero0 dot zero0 dot one1 thirty0.0.0.130 that means whatever the network i may be in  in in this particular network get me the host  noise  number one1 thirty130 so that is the meaning so this host so iit is a specified host on this particular network wherever it is looploop back address  the loop back address loop back addresswhich allows applications on the same host to communicate using tcp ip nnow hhere the net id is given as one1 twenty seven127 and host id could be anything which means that the if the net id is one1 twenty seven127 that means the first byte is all one1s 1 ok that is the loop back that means thiswhich is referring to this particular host why do you require this ? why do you require this ssuppose two different applications are running on the same host and these two  noise  applications they want to communicate with each other using tcp ip now  but wwwhy do they require tcp ip if they are on the sitting on the same host and aswhen they could communicate directly ?  well yes but the point is that tthethe point is that these two applications could have been hosted in two different  noise  hosts also if this was the case if that were so then they would have to use tcp ip so iso instead of so iinstead of writing two different versions  one one1 for the case where both of them are in the same  noise  host and the other for the when are in two different hosts  you write the same program andyou use the same tcp ip stack the ooonly thing is that you want to refer to the same host you want to refer to the same host as you are this thing so iif you are trying to refer to the same host  noise  using the same tcp ip how would you know but how do you know where to which is the network address etc etc  noise  i mean you would not in general like to make changes to the  noise  i mean hardware a particular number into the application so there is a way to refer to the  noise  same host which isthe network address and so you would not be interested to include a hardware into that particular application therefore there is a way to refer to the same host which is by using one1 twenty seven127 that is all one1s in the first  noise  byte  refer slide time  25  43  28  41  tthen we were talking about you remember that we said there are  noise  three different types of addresses for unicast  broadcast and multicast  wwe have seen about unicast communication that is the network part and the host part  both you indicate and then you are really talking about to that particular host wwe haveafter seen about multicast ing class d and class c addresses and mostly in  class d smostly class d addresses sso that is it was a multicast group andand then now you talk about broadcast  butbut here there is a caveat iin the sense that you can not broadcast you are not allowed to broadcast to the whole wide world  why is that ? so well because if everybody or even a very limited fraction of people start broadcasting some message to every body in the world then the entire network will be swarmed with broadcast bb because now in this age of internet millions and may be billions of people are connect getting connected to the internet so so if  noise  only a small fraction of them want to broadcast things to everybody that is not that can not be allowed because then the entire network will go down sso there is  noise  you can not broadcast to everybody in the world so broadcasts are always limited and how they are limited and how the broadcast addresses are specified tthis is what i will bewe will discussed now  llimited broadcast typically used for initialization only appears on local cable or collision domain with net id is minus one1 ? 1 that is all one1s and host id is all one1s ok sso whichthis means that if you put give if you give an address which is all one1s it ok which means that you want something to be broadcast in the local network wherever you are in and the net directed broadcast that means you want to broadcast to a particular network sso this is forwarded via router now that particular net id  so now that and particular network has to be mentione1oned so so tt the net id then the network address part has is to be specified giving the net id  the host id is all one1s so you can see that all one1s mean that to everybody ss so that is the broadcast this thing so all one1s means to every body butbut if you put all one1s in network part as well as all one1s in  noise  the host part  it can not mean that all networks and all hosts in all networks  that is not allowed  as i said so aall one1s in the network part as well as all one1s in the host part meanss that to it is for all the hosts in this particular network andand then there could be subnet directed broadcast wwe have not talked about subnet as yet which we will do so this will give the so the net id will be  noise  particular net id ttherey will be a subnet id which is really carved out of the host part of the address we will come to this that gives the subnet id and then host id part will be all one1s  refer slide time  28  41  29  14  sso this is just another look at it so all zero0s 0all 0s means this host hasand all zero0s 0s in the network part and the host part is something specific which is like a a particular host on this particular network aall one1s means broadcast on the local networks ifif the networks part is specified and ifso  noise  host part is all one1s that it means that broadcast is on a distant network  ifif it is one1 twenty seven127 that meansthen it is all one1s on the first byte and anything in the rest of it that is a loop back  refer slide time  29  15  34  10  nnow we come to a problem  ok first is specifically aa few companies got class a ok like xeroxxerox and some other companies they got a class a address when they were actually very closely involved with designing internet iin the  noise  beginning of the this thing  when the in in the arpanet days so so they where there are from the beginning so at that time people really did not know the people who designed this network andthey had no idea that their project is finally going to blossom so wildly and become so greatly successful so tthey had no idea that they had to be careful with all these addresses that they were doling out  so so the companies which came in they had got some class a addresses these class a addresses can you remember the class a addressthat can have sixteen 16 million hosts which is really much bigger than anything that particular a company might want that is only one1 part of this mmany institutions got class b networks such as 12 institutions how many well as i said that ffor fourteen 14 bits so you can have only sixteen thousand16,000 so it is sso sixteen thousand16,000 which is not such a big number when you are talking about in the global scale  so so sixteen thousand16,000 institutions and may be one1 twenty six126 companies over there that is really a small number but but now-a-days everybody ok there are millions of companies now  noise  and ripped many thousands at least hundreds of thousands of companies who want to have their own network etc now tthey are now reduced to take a accepting only class c address  now classclass a c address is too big because you do can not have sixteen 16 million hosts but a class c address can accommodate only only two fifty six256 hosts but two fifty six256 is a very small number ok  noise  aany institution or many many institutions now a days have got many thousands of computers in their network  so this too small for them ok ffirst  noise  we will i mean how to handle this part we will come to that later on but  noise  for the ffor the first one irst one1 just let us think of another problem that supposesuppose you have a class or even a class b network suppose in a even in a class b network where you have sixty four64 you can have sixty four thousand64,000 nodes suppose  noise  even if you do not have sixty four thousand64,000 nodes ssuppose say you have ten thousand10,000 nodes now  if all these ten thousand10,00 nodes isand are one1one networknow if all these 10,000 nodes is one network  the  noise  remember that what is our buthere network in our in our parlance at this particular moment is well that is one1one particular broadcast domain  so you can always broadcast in this network if you want to communicate to some other host iif you are sitting in particular one1one particular network and you communicate to some other  noise  node in that particular network  then you need to know his mac address which you do not know but you know his ip address so what you will do is so what you will do ? is that yyyou will broadcast the mac address that is the arp protocol asking for the broadcast the ip address  asking for the mac address nnow whichever machine has got that particular ip address you will catch get it and answer with his own mac address and  ok and that is how the arp protocol works now if ten thousand10,000  noise  sso whenever you try to communicate if you do not know the mac address of the other side natnnataturally you will send a broadcast to the entire network nnow if all these ten thousand10,000  noise  hosts start sending broadcast messages from time to time then even that is too much for them ok the broadcast traffic would be too much ok so what you have what we have to do is that in since the network is so big we have to break it up into smaller parts  so that broadcasts are limited to smaller what we call sub networks for so we have to break up this network into sub networks  noise  which so that broadcast can be contained in order to do that you need some more bits to so now in the same principle ppreviously we were talking about the two parts of the address  one1one is saying this network and then we are saying this host in this network nnow we have actually we have to sayet three things ; it is  this network  this particular sub network in that network and then this particular host in that sub network it is just like instead of a town let us say if you have a city then in a city  there will be a large number of post offices in the same city ok so  noise  i mean ffrom outside may be from another country they will send it to that particular city and in the city  you will decide ok this is that particular post office in that city and that particular post office would know that it is for ok this particular house on this street and in this region ok sso that is how it is so we have a network  we have a sub network which is a part which is of the breaking of a big network into smaller sub networks and then we have a host in that particular sub network ok sso  as we have said that for broadcast would go to an entireenter a network obviously  noise  it is impractical for a class a networks and even for class b networks it is the impractical  refer slide time  34  10  34  29  sso sub nets are used to divide a large network into smaller networkss eacheach address allows for one1one network address and many hosts that is  all hosts are on the same network ssubnet masks are used to create many subnets within the same network address  refer slide time  34  30  35  32  so we will lookok at subnet masks so tthis is a bit string applied to an address  ifif the bit is one1one1 the corresponding bit in the address is considered to be a network bit and thethe network mask is known only locally alright so what we do is basically this supposeif we have one1one part which is the network part and the  noise  next part which is the host part  what we do is thatthen we take  noise  some bits from the host part we take some bits from the host part and  noise  use them for specifying the sub network  noise  so  noise  and this sub network so so how many the number of bits of the network which you take for the sub network that is  noise  given by the subnet mask by placing those particular bits to be one1one1 and this subnet mask is known only locally  refer slide time  35  32  36  55  so so this is an example  supposesuppose we have a class b network in a class b network  in a class b network you know that the first two bytes is the network part and  the other two bytes is the  noise  host part now now in this host part  let us say we take it that the firstthese one1 to 2,4,5,6,two four five six  noise  say these six 6 bits will  noise  show my sub network address so so you make the corresponding bits in the network mask  noise  to be one1 ok  and the rest are all zero0s the the host part all the host parts are all zero0s  ok  nnow  lookoking at the address we will know that ok  noise  since we will know that this is the whether it is a class a  b  c just by loookking at the first number and  so we know how much is the  noise  network part if if we know the subnet mask we know how much is the  noise  network and sub network part  so ifif we take out the network part from that  we get the subnet address here so so so these are actually  tactually tthis not the address  the masks only gives tells you that these are the bits which are used for the subnet address and the rest of it is for the host address we we will see examples of this  refer slide time  36  55  39  07  let let us say we have an ip address 144.97.16.132one1 forty four dot ninety seven dot sixteen dot one1 thirty two  that is the ip address of a particular host  andand we are also told that we have a subnet mask of 2550.255.255.192,two fifty five dot two fifty five dot two fifty five dot one1 ninety two well 255.250two fifty five dot two fifty five etc this thiese areis all for only human communication but of course  these are all individual bytes which are to be converted to the corresponding bit strings the  255two fifty five are all one1s in the byte  so all one1s all one1s and 192one1 ninety two is 128 + 64one which means1 twenty eight plus sixty four that is the first two two2 bits are one1 1 and the rest areis zero0 0.so so we know that we have tt so this is is the subnet mask and ssince this is the class b address  we know that this part of it if you convert that 144.97.16.132,one1 forty four dot  noise  ninety seven dot sixteen dot one1 then thirty two this is the string you get so so 144one1 forty four is 120 and etc.one1 twenty etc .so so  noise  so the first two 2two bytes is for the network part now now we also know that the 8 + 210 bitseight plus two ten bits are for the sub network part  soso this is the sub network address that ii am talking about so zero0 zero0 zero0 one0001000010 .1 1 zero0 zero0 zero0 zero0 and one1 1zero0 this this is the sub network and the which host host is this  one100 1zero0 zero0 part  soso the network part is the first part  two  noise  first two  and then the sub network part 000100zero0 zero0 zero0 one1 1zero0 zero0 so s so this is the entire network part  wherever ever we have a one1 and  1 beyond thatthat the point where we have a 1e point where we have a one1 1 we put all zero0s for the network address  sso network address is 1440.97.16.128one1 forty four dot ninety seven dot sixteen dot one1 twenty eight  this is the 144.97one1 forty four dot ninety seven is telling me which particular  noise  network it is and 16.128 sixteen dot one1 twenty eight is telling me which particular sub network is within that network aand the host is finally finally this is simply this one100 zero0 zero0  so the host is four 4 llet us just see another example  refer slide time  39  08  39  57   noise  so so we have this ip address which is one144.97.17.132  forty four dot ninety seven dot seventeen dot one thirty two andsubnet mask is this suppose s the subnet mask is this supposeso we see that the first seven this is my  if is this is the subnet mask that takes first 7 bits  so we see that the first seven 7 bits  so tt so the network has been brokoken down into one1 127twenty seven different networks  noise  and then we have the host  nine 9 bits for hosts s  noise  so so we can have may be 512five hundred and twelve hosts in each network andso so the thisthis is the network part up to this one so up  to this up ,to this one1  so wwe take all the one1s upto this and then which are there we take all the 1s there and the rest arewe put toasit as zero0 sso network is one144.97.16 forty four dot ninety seven dot sixteen and host is one1.1.132 dot one thirty two ok that is the host  refer slide time  39  58  40  53  so so how does packets get to the other end ?  sselect router  noise  based on the ip address thatthat is  for class b  use the upper sixteen 16 bits as a network specification  and for class c  use the upper twenty four24 bits as network specification  and so on natnand nataturally for class a  just lookok at the first eight 8 bits routeroute to that network using the routing tables as we have seen as as we have seen sso depending on whether it is a class a  class bb  or class cc  you use  noise  one1 bit  one 1 byte  two 2 bytes  or three 3 bytes as the network address routeroute to that network  using routing tables so so using this routing table  and i if your routers  andare working alright  if your rip or ospf or whateveretc is working properly  alright  then your it will reach  noise  that particular network  noise  the the point is  what happens after that ?  refer slide time  40  53  41  36  then that isthen the router uses the pre specified subnet mask to select a subnet  because lookoking at the sub net mask and lookoking at the ip address it  oneit knows that how many  noise  bits are there for specifying the subnet so so it finds the subnet  noise  mask  so and it just takes out the subnet part of the sub net part of the address which is lookoked up in a subnet routing table  aa subnet routing table is consulted and traffic is directed to that particular subnet so so this gives you a more hierarchical structure and arp broadcasts are contained within the subnet  so that is the this thing and of course iif you reach that particular subnet  then the host number is given  andthen you can  noise  go to that particular host  refer slide time  41  37  46  14  now now   noise  there are we come to the other part of the problem as i mentioned  noise  as i mentionedmentioned that this class a is of course huge  class b  is also very large  so we have to break them up in to the subnet and all that the the other side of the problem is that  this class c networks  the class c address is very small the other thing to note is that al right  class c address very small  andthat is one1 thing ,and the other thing is that the network has grown so much there there is a tremendous demand for ip addresses one1 thing you must remember that tthis ip addresses have to a global standard  ok ok  noise  yyou can not have your local standard because other people would be lookoking at your address may be at a different corner of the globe and try to route packets to you so so theise addresses have to have follow a global knob ok  and that was used to be controlled by internet one one1 central body so so you have to have  noise  now now  if you have to give the address the number of addresses aren if you haveare to be given it to somebody,n  noise  gives that the address to somebody  then you have to give one1 inter network address for his particular network usually.y alright  andand now this  noise  this creates a problem in the sense that when the demand for networkthese   noise  this addresses becomes too high you y you run out of addresses ok ok,actually aas a matter of fact we have come to a stage today where we actually for all practical purposes  we have run out of addresses  it is very scarce now now you only have a some a few class c addresses left now now iif we had been much more careful  if we could have envisaged how the networks would grow  and if we had been much more careful earlier in assigning addresses and not waste big addresses like that  may be we could have stretched this for by a few more years but but any way this  noise  this can not be helped now now nowso so people are trying working on various types of workaroundssolutions arounds for this particular problems  thisto overcome the shortage of ip addresses that is one1 side  aand the other side was that  quite a number of years back people worked on a new protocol if if  you must have noticed that this lecture is titled ip version four 4  ok possibly implying that there are other versions available and actually there is there is ip version six 6 which was finalized which was finalized quite a few years back and i will talk about ip version six 6 later on in the next lecture anyway anyway ,soin the ip version four 4 we have this problem  what are the various kinds of  so  noise  of various wwork arounds ? one thing  what kind of work arounds one1 thing ? could cocould be  if you take a big address chunk  let us say class b address  ok and give it to different  noise  organizations  may be some parts of it   ok  tthethe one one1 one1 problem is that  first of all you are breaking down these classes class a  b   c ,nice at the byte boundary you had it  noise  so so the point was that do not have them at the byte boundary  alright so they are no longer belong to oneaone1 particular class.  sso they are called classless aand classless inter domain routing  that is the cidr  that is the protocol which is there  noise  where what you do  is that you specify the your starting address and then specify somehow that how many hosts you have in your particular network so so  so this is an example suppose suppose some say  british uuniversities like cambridge  suppose the first address is this  and the last address is this  that means how many  noise  nodes they they can have ? you you can have from zero0 to seven 7 so that is eight 8 over here and of course 256two fifty six on the last byte so 8eight ? to 256two fifty six that is about 2000,two thousand 2048,4,two zero four eight hosts so so it gives the starting address one194240.0/21 ninety four twenty four zero dot zero then slash twenty one .this this twenty one 21 is a code  which really shows that there are really 20two zero0 48 four eight hosts ok  noise  now hosts now there are various such numbers are possible  22,twenty two means one1024 zero0 2two 4four hosts  20 twenty means 4096four zero0 nine 9 six hosts this this way it goes down on one1one side and on the other side you can even have less than one10240 ,24thousand twenty four etc hosts so so so there is a various numbers are there and there is a table  here we need not bother about that right now so this really represents how many are there so so there is a table that 21twenty one means 2048  00,two thousand 482four eight twenty two22 means one102400  thousand 2420twenty four twenty  20 means 4096four zero nine six and so on ok similarly similarly19nineteensimilarly 19 would mean eight thousand 8000 hosts and so on  refer slide time  46  15  50  57  there there is another workarounder on which people have donedone is  noise  and actually  many organizations are now doing it   noise  which is the  noise  which isand in common parlance it i it is called natnating nating  ,natnat nat is for n a tnat that is network network address address translation translation  so what you do is that as i said earlier  noise  and nnow i am going to sort of contradicted a little in the sense that as as i said earlier that this address  your ip address has to be known globally  alright  becauseit has to be has to be a global standard   noise  globally assigned ok now now  if we make an observation whichthatthat this is true  only when we are communicating  only when i am trying to communicate with somebody or when only when somebody else is trying to  noise  communicate with me   noise  that is when it needs to be global so so what you do is that yyso you have an entirely so called private address  you use a private address and if it is a private  why not it be a class a address ? ok so so whatever be the size of your organization may be you use a class a address inside ok  thisthis class a address that we you have just we have just  noise  decided to use it without anybody ? s permission or without anybody ? s leave  which means that this address is not recognized globally al right so you use that so so do you all your internal communication  i mean aassuming that you are in a big organization  so you do all your internal communication using this private address  tthe point is that only when you are going out to communicate with somebody  you will mask your private address  keep a table where there is will be a temporary table that th and tat table will be a dynamic one  one1 ok  for the time being there will be suppose you want to communicate  so dynamically there will be your  noise  local address  which is actually a private address  which and is not really a legala globally legally legal private address  so th and you willat you will put it and then you will have a pool of legal addresses oand ne,one1 of them whichever is free that you will use one of them whichever is free and then  noise  take out and then start communicating so tto the outside world it i it will be as if you are communicating with this particular  noise  legal address which you have assumed for a temporary point of time while you are communicating so so that is called network network address address translationtranslation suppose suppose we have this company lan that is the company router etc  and then a packet arrives and suppose this has an address 10.0.0.1ten dot zero dot zero dot one well  noise  then  the first number is ten 10 which immediately tellstell you that this is a class a address  which is notbut really this company does not have a class a let us say a class a address  he but is using it aand  noise  there is a convention that when we use private address some how we use ten 10 ok  there is no great reason for that bbut  noise  whenever somebody lookoks at an address which that starts with ten 10  he knows that this is a private ip address  so this is a private address that he is using therefore this is a private address he is using this tand this is going through may be let us say a natnat nat box or firewall ok  nownow this natnating could be  noise  donedone at a  noise  can done at a firewall  tthe natnating can be donedeone1 in the router also  so they you could do this natnating in various  and so all these boxes usually come with that capability so so  in the this natnat nat box over here or this firewall that maintains a table of this ip address it is trying to communicate  so it assigns so this is assign the pool of ip addresses  oo and out of thoseat ip addresses  may be this particular ip address one198604212 ninety eight sixty forty two  noise  twelve that is free at the moment so  so he  noise  he will give that he will  i i mean  he will take out this particular address  put in this particular address  and send it to the outside world  sso the outside world will know the source to be be this particular address so so wwhen the outside world  noise  replies back  it will come back here to this particular address  it will go through the same box  the box will know this is really an address which is temporarily assigned to him  so he will now take this out  put 10.0.0.1ten dot zero dot one and send the packet to the particular host in that particular network  sso the outside world will know that he is communicating with this fellow   noise  whereas this is not really a fellow this is just a one1 one of a pool of address which is heard shared by a large number of hosts and the translation is donedone here ok so so that is an example of how natnating is done.done  refer slide time  50  57  52  13  this this is not entirely satisfactory but this is used quite often   noise  for example in my organization iit  we use natnating  as we have a we have got 10,000,ten thousand more than 10,000ten thousand machines and we do not have a  noise  class b address you you can not be help  so we just have a bunch of class c addresses soso we assign these class c addresses to all these boxes   noise  we do the natnating and then that is how we communicate one1theone problem is that if the natnat box fails all the connections are lost that is one1 problem,and itit violates the osi layer independency  because this is a workaround after all  becauseand we do not have so many addresses that people demand ssome applications insert ip addresses as a part of the message  ,then of course that application will fail  because if the ip address is some how hard coated inside the application message somewhere  some where that is not going to work  andand natnat changes the content of the ip datagram  this  whichthis is incompatible with secured data communication if if you want to do the entire thing secured including your ip addresses where you are communicating this natnat will not work or  wherever you are doing natnating you can not encrypt that part   refer slide time  52  14  52  30  just one1a small point that ip data is laid out in big endian order that that means byte transmission order is zero0  1  2  3 one two three you you know big endian or little endian that or which way you go zero0  1  2  3 one1 two three or 3  2  1  0three two one zero  so so  in networks this is the network byte transition  refer slide time  52  31  53  23  now now we want to lookok at the ip header  noise  in this tthis ip header we have  noise  version  header length etc etc and i will just tell you just note thatthe ip header is twenty 20 bytes or more  it is minimum twenty20 bytes  so this is four 4 bytes each  so that is thirty two32 bits each the the source ip address is is given so that ias four 4 bytes  the destination destination ip address is given so that is another four 4 bytes  so that is eight 8 bytes gone.g one1 these these  noise  these three 3 bytes   noise  this what it isthesethree 3three batches of four 4 bytes each that means theis these twelve which amounts to 12 bytes are used for these various things which i will just describe and laterlater on there may be some options  refer slide time  53  23  54  36  version number well well this is four 4 right now  tthis is version four 4  if a if a then version six 6 version six would be there  bit  filled specifying the ip version  currently 4.four headerheader length specified in thirty two32 bit words and range is from five 5 to fifteen 15 words or 20twenty to sixty 60 bytes  sso what is the length of the header ?  wwhy do we need the length of the header ?  if if you lookok at the previous oneone1  previously that  there could be options  so how do you know whether just after destination destinatnation ip address the data starts or the  noise  header goes ? ssomesome more more aand moresome options arehave been exercised ?  so thethe header length has to be  noise  given  andso that is the header length and thenthe type of service  some kind of   noise  this is this was meant as that i mean what is some kind of quality of in service that was expected but this did not work out very well  andso this mostly is mostly ignored now now now then the message length is in bytes  ok  what is the length of thethe message datagram identification field that must be unique so so there is a datagram identification field  sixteen 16 bit packet identification  so this is important why important  wwe will talk about it when we talk about fragmentation fragmentation  refer slide time  54  37  56  49  time time to live livelive field   uupper limit on the number of hops that a message can go before being dropped although although this is called time time to live llive  actually this is given by the number of hops  and why do why do you require that  well you require that ? sometimes because the point is  suppose the routers  you know theywhich work in a distributed fashion  as we have seen in this rip and other protocols that they work in a distributed fashion  and there may be some problem somewhere because bnow because of that problem you may get a routing loop tthat means the packet will go on  noise  i mean virtually andthat since this this loop is since this loop is distributed stored in a stored in a distributed fashion such that no body really detects that there is a loop but actually one1 one particular packet finds that this is this has gone1onegone in a loop now now this packet if it does not die out naturally  naturally what will happen is that it will keep on circulating at infinitum  and such packets will get accumulated and it will bring down the whole network so so there is a mechanism and there were are other reasons for this of course  butbut there is a mechanism that if a packet has gonegone1 very much astray  or if it is just circulating after some number of hops the   noise  router will see that it has already crossed so many hops  tt and this is the its time to live and the time to live has come down to zero0  so drop it  otherwiseotherwise you just reduce the time to live by one1one1 and send it to the next hop now now there is a protocol which identifies tcp  udp or icmp  youyou remember that this is on the network layer now now above the network layer there is a transport layer  ip is a hhour glass design which sort of concentrates in on the ip from the various different types of networks like ethernet  tokenoken ring  etc it it also comes to ip  from ip it goes to various different protocols like tcp  udp  and so on if if it is going   noise  how does it decide  noise  in the network layer how does it decide where to gonow in the network layer how does it decide where to go to  ?  w wwhether to send it to tcp in transport layer or whether to send it to udp in the transport layer  ? there so sso that must also be mentioned.mentioned so so this protocol identifier is there whether it is tcp  udp  icmp  igmp  etc header header checksum checksum  checksum of just the tcp  ip header  that is this ip header and source address  which is four 4 bytes  thirty two32 bits destinationdestination address  another ip address this is again thirty two32 bits and options  refer slide time  56  48  57  45  datadata starts at total length  that is the header length etc and a and so maximum ip datagram size is sixty four64 kilo bytes hhosts are not required to receive packets greater than 576 five seventy six bytes  noise  that that means at  noise  least 576five seventy six bytes arethey to bthey have toe accepted ethernet mtu remember is only fifteen 1540forty bytesbits  noise  bytes sso most implementation allowed isfor about eight thousand8000 bytes for ip datagrams the the point is that when a particular packet has come to a network   noise  the packet may be too large for that particular network to handle  so so then something has to be done.done1 one thing is of course to drop it butone thing of course iiif you drop it  but if you drop it  noise  then every time he wants to send the packet  the packet will get dropped  noise  so so what is donedone ? is  t is tthis packet is brokoken down into smaller parts called fragments and these fragments are then sent through the network thank thank you  iin the next lecture we will talking about the ip version 6six and mobile ip thank you proof computer networks prof sujay ghosh department of computer science & engineering i.i.t kharagpur lecture no  29 ip version 6 & mobile ip  refer slide time  00  00  00  40  good day  in the last lecture we discussed about ip version  4  ipv4   that is the version of internet protocol that is now ubiquitous in the sense almost everywhere it is used but as this particular version became more popular than its originated thought then some problems about ipv4 came into focus and people started discussing about what is the next generation of internet protocol that would be there and after a lot of discussion etc people came up with this ip version 6  ipv6    refer slide time  01  30 ? 01  37  we will be doing a little discussion on ipv6 today in the later part of the lecture we will be talking about mobile ip  refer slide time  01  38 ? 01  37  what was the design goal ? as i mentioned  ipv4 was very successful  but the limited addresses posed problems this was discussed earlier as how people are trying to fight with this problem using natingnetting etc because so many machines are coming into the network these days and not only machines but in certain cases people are actually deploying all kinds of gadgets which should be connected to the network if something is connected to the network and accessed from anywhere on the internet then it has to have an ip address the pool of ip addresses we have in ipv4 is very limited and this is one of the major problems  refer slide time  02  34 ? 02  47  and the second problem is  as mentioned earlier  the routing information were not inherent in addresses for example  in a postal address  we have the pin code and in the pin code if the first digit is 7 then immediately we know that it is towards the east if the first digit is 1 immediately we know that it is towards the north so just by looking at that you can simply send the material to that direction but that has not been so because these ip addresses although they were based on networks which are larger chunks than hosts they were distributed but then this could not be maintained at that time if you could have some means of geographical information inbuilt into it then routing becomes easier and the routing table becomes smaller therefore  if the routing table is smaller routing speed becomes faster and so there are many advantages  refer slide time  03  43 ? 04  07  thirdly  experience had shown that some aspects of ipv4 were problematic like option headers and fragments etc were problematic then some type of service  tos  which people never never used  options also have a very limited utility because of its limited size and fragments was a problem these were the basic issues  refer slide time  04  08 ? 04  21  the simplification for ipv6 as mentioned was that to move to a 128-bit address from 32-bits if you remember that ipv4 has as an address size of 32-bits whereas this is 128-bits so in ipv4 in a theoretical maximum it is 232  of course it is less than that but anyway the theoretical maximum is 232  addresses whereas here it is 2128 addresses which is a very huge number even  if all the devices and computers you can think of are connected and given individual address space then also you will have a huge number of addresses to spare this was done with the idea that we are not going to run into this problem of limited address space ever the other point is  if you have so many bits  as i said that even after assigning numbers to all the devices and computers you will be left with some to spare so that can be used more intelligently  refer slide time  05  15  05  25  second point was to assign a fixed format to all headers in ipv4 also  the essential part of it  the initial part of it  the compulsory part of it is fixed but there are options and these options could be of various sizes so that is also removed  refer slide time 05  37 ? 06  01  remove the header checksum which was not doing much anyway use extension header rather than options options were removed and we came to the concept of extension header that means headers followed by other headers  we will come to this later on remove hop-by-hop segmentation procedure that means you do not segment it somewhere in between a packet that is traveling and then somewhere in between you try to fragment it however  that was not a good idea  and because of this fragmentation you have to keep the fragmentation number  the packet identification etc so all these are removed although fragmentation can be handled in some way we will talk about that later  refer slide time  06  23 ? 06  44  this was the original ipv4 header which we have already discussed like version header  length  type of service etc this type of service  tos  was not very useful fragments etc came in because we allowed fragmentation which is not done here header checksum may go out but the source and destination ip addresses would be there let us come to the ipv6 header  refer slide time  06  45 ? 07  09  ipv6 header is actually much simpler than the ipv4 headers we have a few fields and then the source address assuming that this is 32  previously ipv4 address was only one line but now you have four lines i.e 128-bits for source address and 128-bits for destination address let us look at the fields  refer slide time 07  10 ? 07  27  one is the version number previously it was 4 but now it is 6 class  this is used to assign service class for real time networking if you are doing some real time networking that can be indicated here then  there is a field called flow  if you quickly look at it we have version  class  flow level  refer slide time  07  28 ? 07  32  flow  flow means given one particular source and another destination then for this particular source and destination pair there is a flow level flow means these two are likely to send large number of packets and all of them would belong to the same flow this is not a virtual circuit identifier like atm because in atm the virtual circuit identifier and intermediate switch would just look at the virtual circuit identifier and switch it that way this is not for that purpose at all rather this is for treating the packets with a particular flow level from a particular source and destination in the same way where all packets belonging to the same flow level in the intermediate router for example  there may be class of service or all kinds of quality of service requirements for one particular flow that may require bandwidth reservation in between therefore such things can be handled using the flow level  refer slide time  08  45 ? 09  31  payload length  only include the payload and not the 20-byte header this is 16-bits for that so packets are once again less than or equal to 64 k next header ; this gives rise to the possibility that there may be more than one header if there are not any more ipv6 headers then  at least the higher layer headers like tcp or udp headers could be there there is a field called hop limit this is really the ttl  time to live  which was present earlier in ipv4 but was used to just keep the count of the hop and this is just renamed as hop limit  refer slide time  09  32 ? 10  12  fragments  one of the lessons we learnt in ipv4 was that the unit of transmission should be the unit of control so no fragments created en-route in ipv6 if message is greater than mtu the maximum transferable unit then you get icmp message which is an internet control message protocol we will talk a little bit more about icmp later on but this is some kind of control message which may be sent by a router to host etc so  an icmp message should use the path mtu let us see what is meant by this mtu and path mtu and how do you avoid transmission  suppose you are the source and you want to transmit a particular packet it so happens that en route it encountered a link where such a big packet can not be accommodated in ipv6 what this router will do is that it will drop the packet and send back an icmp message saying that this mtu is so much which is for the next link now you will reduce your packet size at the source itself and try to send it again but now it will definitely cross that particular link  it may get struck again in another link so again an icmp message will come back but finally you will come to size of packet which will go through all the links now this is your path mtu now you can go on sending all your communication using this particular packet length and it will not be fragmented in between  refer slide time  11  17 ? 11  36  this is a way to fragment a datagram but it is done in an end-to-end fashion it may so happen that for some particular application all these smaller packets we have made should actually be made into bigger packets so this is fragmentation in some sense so far as the application layer is concerned so there is a way to indicate that  there is a header for that  refer slide time  11  46 ? 12  29  finally we have removed the options from the ipv4 header and we have come to this extension header that means there may be more than one header we could have this situation that ipv6 header and next header is said to be tcp the payload is the tcp header and payload itself it could be that ipv6 header  the next header is a routing header  which again is an extension header for ipv6 routing header and the next header is tcp so the tcp header and payload comes here so there may be more than one ipv6 headers and headers are of different types  refer slide time  12  29 ? 13  01  intermediate routers do not need to look at the headers unless we tell them to specifically it has to look at some headers but can ignore few other headers it does not need to process all the information it should be fast extension headers and protocols  for example  tcp shares the same 256-entry name space i.e 256-entry name space for the headers hence there are limited number of extensions but this number is a big enough  refer slide time  13  02 ? 13  33  there is a certain order suggested that these headers should occur in one particular order one is  ipv6 header the main header we talked about  an and the extension header called hop-by-hop header  destination options header  routing header  fragment header  authentication header  destination options header  upper-layer headers if any that means tcp or udp let us quickly discuss a few of them  refer slide time  13  34 ? 14  21  payload may be encapsulated,payload followed by the transport layer header then there is a tcp  then a routing header  authentication header  another two routing headers  then ip header and so on what you do is that you peel them one by one so that one routing header is peeled of because the routing header gives you information about how to route the packet something like source routing so that is peeled of may be in the next hop and this goes out the ip header remains and the routing header authentication header etc remains you peel out one header after another and finally you get to the tcp and the payload  refer slide time  14  22 ? 14  38  naming  a large part of the address space is unassigned this means  at this point of time people thought it prudent to keep provision for some future requirement which we can not envisage at this moment so a large part of the name space is simply been kept unassigned  refer slide time  14  55 -15  08  there is a way now to move away from provider based routing  based id ? s the two routing based id ? s although both are possible previously what would happen is that the service provider would take a chunk of ip addresses and it is for his network now this could be distributed in various places so  provider wise this loses the destination information whereas if you had done it geographically the routing would have been much easier  the routing table will also be smaller ipv6 keeps the option of both so you can have provider based addresses and also geographic based addresses there are various levels of aggregation like top-level aggregation which is essentially a hierarchical organization reflecting the current internet architecture  refer slide time  15  56 ? 16  09  then the next level aggregator  then site level aggregator allocated to a link or a link level or site level aggregator that is local this means  at the link of the site level the rest of it may be common it does not matter because it is strictly for local use that is something similar to a private ip and not for communication with others  refer slide time  16  15  16  20  the interface id is based on eui id  the extension of the ethernet mac address and even that can be embedded  refer slide time  16  29 16  59  there are some unspecified addresses we need not bother about all this because ipv6 as of yet is not been deployed much only thing i would like to mention is about any cast we have talked about unicast  broadcast and multicast any cast is a concept something similar to multicast but in multicast there is a group where you can send some message to all the members of the group in any cast you can send any message to any member of the group  refer slide time  17  15 ? 17  41  let us look at some of the routing extension headers it has the next header a header length  a routing type etc now we have some address 1 to address n there are some ip addresses  ipv6 addresses may be listed over here  refer slide time  17  42 ? 17  55  it plays the same role as source routing header you remember that  in ipv4 options there is a way to give the routing from the source that means you determine the routing from the source itself such a facility is very important for protocols like bgp because bgp wants to dictate the route through which the packet should be routed but the problem with ipv4 was that the header length was very limited so you can go only up to a dozen or so may be 12 to 15 hops in the source routing if it is beyond 12 to 15 hops you would run out of space in the header so you would not be able to specify that here you can have a routing header then you can have more than one routing header and this particular difficulty is obviated  refer slide time  18  42 ? 18  54  basic idea is  when a datagram reaches a destination  the destination checks for a routing header if there is at least one segment left  that address is copied from the routing header and the packet is forwarded to that address  refer slide time  18  55 ? 19  17  otherwise  the routing header is removed and the next routing header is processed you can have multiple routing headers if the 8-bit header length causes a problem there is a header length of 8-bits so you can go up to a length of 256 but then you can have multiple routing headers you can specify other source routing nodes using type  refer slide time  19  18 ? 19  46  fragment header  each fragment routed independently identification identifies the original packet that was fragmented the offset is the offset within the fragment the m field is a more fragments bit and is set to one for all but last fragment this is exactly similar to the way fragmentation was handled in ipv4 the difference over here is that the source sends it using the path mtu that means in the in between it is not fragmented and whatever fragmentation is done is done at the source and that information is carried in one header called fragment header and those would need not fragment anything they will not use this header so  all these extension headers are optional you have to have the first ipv6 header but all the extension headers are optional therefore  if you are not fragmenting then you will not use this header  refer slide time  20  23 ? 20  39  there is a destination options header  when a packet reaches its final destination  or at least when all prior routing extensions have been processed   the destination options header is processed so as an option the unknown options are discarded  refer slide time  20  40 ? 21  23  hop-by-hop options header  this is another one the destination extension header is looked at just at the end at the destination in the hop-by-hop all these at intermediate hops you need to look at this hop-by-hop options header they are processed at each hop  for example  the jumbo payload header the ip header length is 0 and the jumbo option encodes the true length as a 32-bit value this is an option that you can have a very big packet traveling down it is also used to mark spanning trees for multicast and real time protocols etc there may be things that you need to do at every hop  refer slide time  21  25 -21  56  security is another area that was in focus security association  we will talk about network security etc at length later on there is a way to put authentication and encryption requires that senders and receivers agree on a key for encryption and decryption and authentication or encryption algorithm  and set of ancillary parameters such as the lifetime etc this is called security association  refer slide time  21  57 ? 22  17  now  you have an authentication header where the security parameters may be mentioned namely the sequence number field  next header  length and reserved the spi is selected by the receiver and is used to describe the security association where everything is normally negotiated during the key exchange  refer slide time  22  18 ? 22  53  there is encrypted security payload headers entirely can not be encrypted because then the intermediate routers will not be able to handle it the last unencrypted header in the chain  this is an encrypted security so there would be encrypted data and authentication data  also the esp  encrypted security payload  header esp header will be there esp header also includes authentication to prevent tampering with encrypted data we will talk in details about security in a later lecture  refer slide time  22  54 ? 22  58  to conclude this discussion about ipv6 this is really one scheme where people will not be running out of ip addresses then a funny thing happened in the sense that many of the hardware vendors like routers etc rather modified their design in order handle ipv6 however  actually what happened was that everybody is waiting for all others to switch from ipv4 to ipv6 when you switch you may have problems with some of your software or a lot of your software if you only switch over to the other version that would not do because the rest of the world will still go with ipv4 you can still operate it through some bridge  through an ipv4  ipv6 etc but then nobody wants to do it unless other people are doing it that is how everybody is held back for quite a few years but one thing is that if there are ubiquitous kind of networking  in the sense that  not only your computers but all your devices like refrigerator  tv and air conditioner and everything in the house is networked then we will require a huge number of network addresses then people will not have any option but to actually make the move right now everybody is sort of waiting for other people to make the move next  we will come to the topic of mobile ip what is mobile ip ? mobile ip means  now there are many network attachable devices it is not only the laptop computers people are carrying everywhere even apart from laptop computers there can be all kinds of devices including hand held devices which can be connected to a network now what is the problem if all these mobile devices are connected to the network ? there is no problem as such  whenever you go there have to be some way in which a physical connection is made that connection may be wireless in the case of mobile the wireless connection is very attractive but otherwise you may go to some other place and actually connect a wire over there  it may be wired also  although wireless is more dominant but the trouble is what happens to the ip address ?  your device has a particular ip address and that would have worked fine when you were at your home base but you have moved from your home base to some other place now  if somebody wants to talk to you he will be using your ip address and that is what he is familiar with for example  all the name servers etc will have the ip address corresponding to the url if you have a url and that is not going to change they are going to try to use your old ip address but by using your old ip address they will land in your home network where you are no longer available this is the problem of mobile ip when a particular network attached device moves from one network or one sub network to another network then how would you keep communicating ? that is the problem of mobile ip  refer slide time  25  36 ? 26  59  these are the problems as i just now discussed nodes in the internet are identified by specified ip address routing is performed using that same ip address when a node ? s location or attachment changes then routing will not work with the same ip address that is a simple point  refer slide time  27  00 ? 27  18  what are the alternatives ? one is that  the node must change its ip address whenever it changes its point of attachment it requires upper level protocols to handle address changes  that is one problem this means  if it is to be made automatic then it has to be automated by a higher-level protocol which really sort of violates this layered architecture  that is one point more importantly  what would happen is that the others who want to communicate with you know your ip address they do not know that it has changed in the meanwhile so they would still try to communicate with the old ip address  refer slide time  27  43 ? 28  54  the other thing was that  host specific routes must be propagated through the network this is another possibility because from your ip address if somebody is trying to contact you from outside he first looks at the network part of the address and allows them into your network  then within the network  you have this arp and other protocols to help you to get the mac address and reach you directly so the routing table essentially keeps track of all the networks as many as they can depending on what size the router is the big routers keep track of many networks  the small routers keep track of only a few network addresses if these entries were against host then the routers might dynamically change their entry etc and route it directly to that host however  even handling so many millions of networks is becoming a problem so handling billions of hosts in the routers is simply out of question the solution to this is to use another level of indirection  that is what we do in mobile ip as i have just now shown  refer slide time  28  55 ? 29  00  mobile ip design goals  a mobile node must be able to communicate with other nodes after changing its link layer attachment changing its link layer attachment is changing the attachment to the network or sub network to which it was originally attached yet without changing its ip address where its ip address remains the same this is the problem a mobile node must be able to communicate with other nodes that do not implement mobile ip this is the other requirement it means  you may do something very sophisticated and special in your hand held device but the point is that still it should be able to communicate with millions of other hosts who do not have any special arrangement for communicating with mobile ip therefore  you can not do anything on the other end  refer slide time  29  49  31  39  another point is that  this is a sort of security concerned that mobile ip must use authentication to offer security against redirectment attacks the point is  when you are in your own network you can try to authenticate it apart from any other security arrangement that is present like your password may be at a higher layer but the point is that it is also possible that you allow communication with that particular host which is in that network  so you will set up your firewall or router policy in such a way that  that particular communication will be allowed  may be communication from others will not be allowed but the point is  if this fellow has moved to another network then you will not be able to do it using the network address  that is one aspect the other point is  other people may fake from other places for example  suppose i want to communicate with mr x  then mr y from some other place may rather try to spoof ; in the sense  they may try to show that he is actually mr x so i will think that i am communicating with mr x but actually i am communicating with mr y therefore  anything might happen and security concern is also an issue the number of administrative messages should be small to save bandwidth and power you can not have a huge overhead for doing this  mobile ip must impose no additional constraints on the assignment of ip addresses  this is another important issue  refer slide time  29  49  32  09  before describing how this mobile ip is implemented  let us discuss about some terminology one is the mobile node that is a host or router that changes its point of attachment from one network or sub network to another a mobile node may change its location without changing its ip address it may continue to communicate with other internet nodes at any location using its own constant ip address  refer slide time  32  09  32  42  home agent  this is required in order to support mobile ip home agent is a router on a mobile nodes home network that tunnels datagrams to the mobile node when it is away from home you can immediately get the idea of how it is done the point is that  this particular mobile device has a home network and that home network has a router and that supports mobile ip what that home network router would do is  whatever communication is supposed to be received by this particular mobile device will come to its home network the router will accept that communication on behalf of this mobile host that may now be away somewhere else then it would be the job of the router to send that communication back to that particular mobile host not only you require a home agent  that means  some router helping you and your home network  then you require a foreign agent a router on a mobile nodes visited network means the network to which it is currently physically connected provides routing services to the mobile node while it is registered for getting this service you must register with this foreign agent  refer slide time  32  43  34  13  the mobile node is assigned a care of address this is a new address one is the mobile nodes own ip address which is remaining constant that actually belongs to the network in its home base it also has a care of address on the foreign network this address is used to deliver the datagrams for the mobile node this address can either be the foreign agent where the foreign agents address may be this care of address or it can be co-located with the mobile node  refer slide time  34  13 to 34  50  this is the idea you have  this is the home network of the device of a now a has moved to another network so this is the visited network of a in the home network a has a home agent which will help you in this mobile communication in the visited network it looks for and finds a foreign agent that will help you for this communication this foreign agent will give that care of address and then both of them will be connected to the internet  refer slide time  34  51  35  00  suppose some source wants to send something to a  naturally it will use a ? s original ip address so it will be routed to the home network of a  refer slide time  35  01  35  15  what will happen is that then the home network will send it to the home agent the home agent knows that a is no longer here but it is somewhere else and the home agent also knows the care of address given by the foreign agent  refer slide time  35  16  35  25  he tunnels the communication to the foreign agent using the care of address  refer slide time  35  26  35  33  then the foreign agent will deliver the message to a because foreign agent knows the a ? s current location  mac address etc where it can communicate  refer slide time  35  34  35  52  now a replies to c but this can go straight this need not go in the circuitous manner because he is using the ip address of the source of the original communication so a can send this reply directly back to the source hence  this need not go through the entire process  refer slide time  35  52  36  05  this is the solution in a nutshell  from the source  it goes to the home agent  to the foreign agent  to the node and from the node it directly goes back to the source for the return communication  refer slide time  36  05  37  06  a small overview of the protocol  you have advertisement that means the mobile agents the so-called foreign agents and home agents should advertise their services that means the mobile node comes to know that this foreign agent or home agent is available  that this service is available otherwise  a mobile node can also solicit for mobility agents and that is possible registration  when a mobile node is away from home it must register its care of address with its home agent so  not only it must set up some arrangement with the foreign agent to give it an address but also that address has to be sent to the home agent so that  whatever the home agent tunnels it will tunnel it straight to that care of address  refer slide time  37  06  37  23  delivering datagrams  datagrams must be forwarded by the home agent to the foreign agent for delivery to the care-of address the delivery mechanism must handle all packets including broadcast and multicast a tunnel is used for this analogy in a little while  let us see what a tunnel means  refer slide time  37  23  38  05  advertisement and solicitation  the router discovery icmp protocol was adapted for advertisement and solicitation so not much of a change was required we will look at the details of icmp protocol later the routers broadcast or multicast every few seconds so it uses limited broadcast or all systems on this link  multicast kind of an address for giving this because they can not use the ip address directly because it is an advertisement mobile nodes also send out solicitation messages that will cause a router to broadcast or multicast their advertisement  refer slide time  38  05  38  39  registration  request forwarding services when visiting a foreign network this allocates a local foreign node address that means a care of address is required inform home agent of their current care of address this creates a binding of the foreign node address to the home address in the home agent if anything comes destined for the original home address then this can be tunneled to the care of address  refer slide time  38  05  39  16  this is one small but important point that this binding has to be renewed from time to time bindings have lifetimes this is important because mobile node may be rude and just go away without informing anybody and that registration will rather last forever  it can not last forever it is best that it dies down after sometime if the mobile agent continues in the same location for more time  it is going to renew this binding from time to time and of course you have to deregister when they return home  refer slide time  39  16  39  26  tunneling  there are various methods of tunneling we will just discuss this ip-in-ip encapsulation and minimal encapsulation  refer slide time  39  16  39  26  this is ip-in-ip  this was the original message sent from the source and this is what landed in the home network of the destination if you remember  in the diagram the destination was marked as a this ip header will contain the actual address of a and this is the datagram what it does is  when it lands into the home agent the home agent knows that this has to be sent somewhere else it keeps the inner ip header and datagram intact this whole thing is considered now as a payload and then you add another ip header with some options if necessary this ip header will have as its destination the tunnel endpoints  the tunnel destinations which is supposed to be the care of address in the packet the original packet is still there  this inner ip header and the datagram etc and this whole thing is encapsulated as if this is a payload and sent to the foreign network in the care of address it will reach the foreign agent and the foreign agent will then send this part to the mobile node who is currently connected and its mac address is known to the foreign agent the mobile agent or the mobile node will receive a whole packet including this inner ip header so you do not require any kind of change in the software which handles it just like a normal packet it is as if he was in the home network and got this is original packet  refer slide time  41  15  41  50  the outer ip header source and destination address identify the tunnel endpoints the source would be the home agent and the destination would be the foreign agent the outer protocol is 4 that is the ip protocol the inner ip header  the source address and destination address identify the original sender and recipient  this is not changed by the encapsulator except to change the time to live so for time to live you have to look at the ttl and then make the necessary changes this whole thing is put in the payload  refer slide time  41  51  42  16  other headers for authentication might be added to the outer header in order to handle all these security concerns some outer ip header fields are copied from the inner ip fields for example  type of service etc most are recomputed like checksum length etc may change based on the new datagram  refer slide time  42  17  43  09  the other option is the minimal encapsulation minimal encapsulation means that you do not keep the entire ip header intact here so  what you want to do is that  you want to retain the minimal information in the minimal header and then construct an outer ip header for the outer ip header the tunnel endpoints as the source and destination address would still be there and some of the stuff from the ip header will also come here the destination address will be there in the minimal header you have to make some deconstruction and reconstruction at both places the size is a bit smaller so the overhead may be a bit smaller but it may not be such a big deal  refer slide time  43  10  43  30  in minimal encapsulation  we copy inner header modify protocol field to be 55 for the minimal encapsulation protocol because on the other side it must know which protocol it is following if it is following minimal encapsulation then it has to do something destination address is replaced by the tunnel exit  refer slide time  43  31  43  50  if encapsulator is not the originator of message  replace source address with address of encapsulator then increment total length by the size of the additional header by 12 or 8 octets and then re-compute the checksum this is called mobile ip in one way in which mobility can be handled and your ip address can be recomputed there are other possibilities and other ways of handling mobility for example  this has an overhead that any communication from the source to the intended host that has moved  now has to go through this triangular path will it continue to do so or whether after first communication there would be some protocol to exchange their new ip addresses etc ? then  they can communicate directly  that would avoid this triangular path the other problems with triangular path may be apart from higher overhead it may exceed the hop limit  as networks are growing it may increase the hop limit and you may never reach whereas if it had gone directly then it would have reached other options could be just like you do handoffs in cellular from one base station to another in the case of cellular networks what is happening is that  you are always in connection with some base station  may be even more than one base station if you are moving away from one base station when the signal strength drops then it goes to the realm of another base station  and the other base station automatically picks up and does some kind of registration when this is done  the communication remains direct but  if you want to change the ip address in such a dynamic fashion then there has to be an integrated system running everywhere which is using this protocol mobile ip is a way of handling mobility with minimal change to others and the problem is that this has a significant overhead in the next class we will be moving into the next higher layer which is the transport layer the tcp and udp  thank you lecture 30 udp and client server goodgood day  today we will start our discussion on transport layer protocols and there are actually two dominant protocols udp and tcp we will take them up one by one let us look at udp in this lecture and tcp in the next one  refer slide time  46  56 ? 47  02  udp stands for user datagram protocol   refer slide time  47  03  47  15  this is a transport layer protocol and this has got the following responsibilities first of all it creates a process-to-process communication path till now we have talked about the network layer and the job of the network layer is to connect a distant machine to another distant machine it ? s a machine to machine communication whereas now we are talking about  process to process communication in this particular source machine  some application process is running which is trying to connect the other distant machine for some job this process has to connect to the corresponding process there which may be a particular application server on one side and the application client on the other side  whatever that application may be so this is a process to process communication path  refer slide time  47  56  48  06  this also has to provide control mechanisms at the transport level this control mechanism in the case of udp is very minimal  as we will presently see  refer slide time  48  07  48  19  udp is a connectionless  unreliable transport protocol immediately  the question that would come in your mind is that  why would we try to have an unreliable protocol ? this is not unreliable per say  the point is  it does not do anything extra for reliability making it a very lightweight protocol  the overhead cost is very low in many cases  this may be a very reasonable thing to have where you do not expect lot of errors or you do not really care if some error occurs from time to time and in such cases  you may use a udp  refer slide time  48  58  49  12  this is a connectionless protocol it only adds process-to-process communications to ip it performs very limited error checking as we have mentioned it is a very simple protocol having minimal overhead this is the main point it forms the payload for the next layer that is the ip layer and the checksum is computed over this entire body so there is some amount of error checking and error detection done by udp and that is the extent to which it will go for providing reliability beyond this if the entire packet is lost somewhere the udp can not do anything about it  refer slide time  49  43  49  50  these are the four fields of the header  source port number  destination port number  total length and the checksum  refer slide time  49  53  50  16  and regarding the udp operation this is a connectionless service this has minimal flow and error control as given by the checksum it does the encapsulation and decapsulation  forming of packets  it uses some queuing and does the multiplexing and demultiplexing let us look at the operations one by one  refer slide time  50  17  52  12  this is a connectionless service that means each user datagram sent is an independent datagram it means that  suppose some particular application has sent one udp and is going to send another one  now the layers below this application may be coming from the same source application process destined for the same destination application process which are the two datagrams they are going to be treated independently by the rest of the network layers this means a number of things first of all it may so happen that these two packets may go in two different directions  may be route differently because there is no connection this is a completely a datagram oriented service  connectionless service so these two datagrams may travel in different paths secondly  one of them may get lost thirdly  what might happen is  they may go out of order  the datagram that was sent earlier may reach later the point is that  for all mishaps udp is not going to take any responsibility it is taken for granted that whatever application takes place using this udp is resilient to such events there is no relationship between different user datagrams the user datagrams are not numbered  meaning that  the datagram which was sent later if it arises earlier and vice versa then there is no way of knowing unless you have taken some care to identify that in the application layer itself  refer slide time  52  13  52  46  no connection establishment  since it is completely a connectionless service there is no question of any connection establishment and since there is no connection establishment there is no connection termination either these are unregulated which means that up to port number1023 these are reserved and that is also again divided into two parts one part is for public applications and the other for some vendor specific applications but they are all well-known port numbers now  think of the other direction  apart from well-known port numbers you also need a whole lot of other port numbers take the previous example that we have made an http request to a web server  now the web server will send you back something may be it will send you with the content of the first page of its website this is going to be sent to the requester but to which port ? for this  another port number is temporarily assigned this is assigned from a number range from 1024-65,000 the number is randomly chosen so this is an ephemeral port and not a fixed port for the duration of this communication this port number is going to be held constant and then it will be released for use by some other process  refer slide time  53  58  54  12  source port numbers are dynamically assigned by the originating host  and are usually a number larger than 1023 port numbers in the range of 0 -1023 are controlled by iana  refer slide time  54  13  55  46  these are some examples of some well known port numbers there are a quite a good number of them but i have just mentioned some important protocols for example  ftp  a file transfer protocol uses port number 21 telnet  a terminal connection uses port number 23 there are hundreds of applications that has come up we can not talk about all of them but we will talk about a few of them towards the last part of our course .for the time being  let me just mention them telnet is the terminal connection which uses the well known port number 23 smtp is a simple mail transfer protocol that uses port number 25 tftp trivial file transfer is used when you just have to send a short message that uses 69 http is the hyper text transfer protocol used for web services that uses the well-known port number 80 pop 3 is a post office protocol that uses a port number 110 what pop 3 does is that  suppose you got some mail in your mailbox in the local mail server then on your desktop you can download all the mails from the local server to your machine through the post service protocol this is the pop3 protocol this type of server is called concurrent just to elaborate on the server part a little bit more then what i have already discussed  the client request for a connection has come to the server now what is the server in this case ? when i mention the term server i mean that software process which is running there and not the hardware box a hardware box is also called a server in a different context in our context by server i mean the process which is giving the service  so this is some kind of process which is running in a particular machine now  in the non-concurrent case what will happen is that all the user requests will come and they are sort of put in a queue and now what the server process will do is that  it will take up one from the queue  process the service  then give it back and send the result then it will take the next one out of the queue so there is a queue where all the client requests are waiting and the server  that means the service process which is giving the service is taking one request at a time out of the queue this is called a non-concurrent server non-concurrent in the sense that when you are using sock d ? gram that is a udp kind of service  it is one of its kind where you get a request  send a message and may be that is the end of the service in that case this non-concurrent servers  also called iterative servers are more efficient but it may also happen that  in a particular service the client server communication is for an extended period of time in which case one particular request may block all other requests for an unnecessarily long time in that case the concurrent server may be preferred in concurrent server what happens is  as soon as the server gets a request at the well-known port it immediately spawns or forks note  regarding video content in this video after 45 minit the next lecture is stated after that there is a switching of some other topics which is not related to each other computer networks prof s ghosh dept of computer science & engineering iit kharagpur lecture no # 32 ip multicasting good day today ? s topic is ip multicasting  refer slide time  00  56 01  08  slide time  00  56 01  08 till now  we have seen the three modes of operation  one is unicast where one sender is sending to one receiver one is broadcast where one sender is sending to all the receivers that means all the nodes in the network and multicasting is when you want to send it to a group of hosts but not all the hosts so  ip multicasting is the topic for today  refer slide time  01  31 01  53  slide time  01  31 01  53 multicast communications refers to one-to-many and many-to-many communications for example  this is unicast when the source is one and the destination is one  broadcast is when source is one and destination is all and multicast is when destination are a few  refer slide time  01  53 02  14  slide time  01  53 02  14  ip multicasting refers to the implementation of multicast communication in the internet  individual hosts are configured as members of different multicast groups  multicasting is not connection-oriented  an ip multicast group is identified by class d address these are the general parameters one particular user may be member of different multicast groups but for one particular multicast group there will be few members in the network and it has to reach those and not others other thing to understand is that multicasting is not connection-oriented that means all the packets are sent it is packet by packet it is not that from the source multiple channels are prairie setup or anything like that  refer slide time  02  46 03  15  slide time  02  46 03  15 they are identified by class d address which is for multicast the class d address is seen in the fashion that the beginning four bits are 1110 so the initial value is 224 something and these 28 bits this is how by looking at an address you can see that this is the multicast address  refer slide time  03  15 03  26  slide time  03  15 03  26 there are many applications like news  sports  stock and weather updates let us take the example of stock updates now  not everybody would be interested in stock updates  only some group of people would be interested in stock updates again  it may be such that one group of stock is of interest to one group of people  another group of stock to another group of people and so these would be different multicast groups and the news feed should reach these people then multicasting may be applied in distance learning  refer slide time  03  49  04  17  slide time  03  49  04  17 when some learning material is distributed to distance learners and just specific group of learners  configuration  routing updates  service location may be the areas where multicast may be applied pointcast-type push applications where push means when the actual source of information finally on its own sends it to the group of people for example  stock quotes may be  refer slide time  04  28  04  52  slide time  04  28  04  52 pushed teleconferencing  audio  video  shared whiteboard  text editor etc is an interesting and important application of multicasting that means you may like to have a video conferencing amongst a group of people so this same video stream should reach the entire group of people  refer slide time  04  52 ? 05  18  slide time  04  52 ? 05  18  distributed interactive gaming or simulations  some people are participating in some game in a distributed fashion  email distribution lists  content distribution ; software distribution  web cache updates  database replication multicasting has very large number of applications but the trouble is  multicasting is a little complex the technology is not so simple and the fact is there are most of the routers which are in operation today are not configured for multicasting in a proper manner because it takes a toll on the routers capabilities so we will come to see what a multicast routing is all about  refer slide time  05  42  05  59  slide time  05  42  05  59 there are three essential components of ip multicast service   ip multicast addressing is  how you address  ip group management  multicast routing  refer slide time ? 06  00 07  13  slide time ? 06  00 07  13 if you look at this diagram  suppose you have these three routers and three networks connected to these three routers respectively suppose  you take any of these routers and that is connected to its own group of machines and some of these machines would be the members of a multicast group of course  new machines can come in and new machine can actually decide to join the multicast group and some of the old group members may choose to leave a particular multicast group so there is a group membership protocol which goes on between the router and the different machines connected to the network then  amongst the routers there is question of multicast routing so this internet group management protocol  igmp  runs between host and their immediately neighboring multicast routers and within the routers we have the multicast routing protocol running  refer slide time  07  13  07  41  slide time  07  13  07  41 this is another picture showing the same thing this is the service model  suppose  these are the hosts and host to router protocol which is known as the internet group management protocol  igmp   and then amongst the routers there is multicast routing protocol and there are various types of multicast routing protocol  we will just discuss a few  refer slide time  07  41 ? 08  07  slide time  07  41 ? 08  07  ip multicasting only supports udp as higher layer  there is no multicast tcp udp is a connectionless datagram oriented protocol and tcp is connection-oriented since  ip multicasting is essentially connectionless that is why it chooses udp as the transport layer protocol  refer slide time  08  07  09  13  slide time  08  07  09  13 if you look at the details of this part of the protocol stack here we have the network interface  ip and ip multicast layers the ip part of this network layer takes part in the normal routing protocol whereas ip multicast part takes care of the multicasting routing protocol then above this in the tcp ip stack we have the tcp protocol and the udp protocol so  for tcp we use the stream sockets whereas for udp we use the datagram sockets as well as multicast sockets so  multicast sockets also use udp this is the socket layer and above this we have the user layer so that is the application layer which uses these multicast sockets and uses udp to send multicast messages which are routed by the multicast supporting routers  refer slide time  09  13 ? 09  51  slide time  09  13 ? 09  51 ip multicast works as follows   multicast groups are identified by ip addresses in the range 224.0.0.0 to 239.255.255.255 these are the class d addresses  every host  more precisely every network interface card  can join or leave multicast group dynamically  at present the way it has been done has no access control so  if there is a multicast group which requires access control then this has to be implemented in the application layer as the protocol stands today this has not been included one of the reasons is that ip multicasting in actual practice constitutes a very small amount of traffic compared to its potential true multicasting later on let us see what is true multicasting and simulated multicasting but actual true multicasting traffic is really small compared to its potential mainly because most of the routers may not support  they are not more precisely configured to support multicasting because of the cost involved  refer slide time  10  46 ? 11  06  slide time  10  46 ? 11  06 since there is no access control every ip datagram sent to a multicast group is transmitted to all members of the group there is no security  no floor control moreover since it uses udp  ip multicast service is essentially unreliable  refer slide time  11  06 ? 11  46  slide time  11  06 ? 11  46 more detail about the multicast addresses   the range of addresses between 224.0.0.0 and 224.0.0.255 means the last byte for the first range inclusive is reserved for the use of routing protocols and other low level topology discovery or maintenance protocols  multicast routers should not forward any multicast datagram with destination address in this range so they are reserved addresses and other addresses can be distributed to different multicast routes  refer slide time  11  46  12  21  slide time  11  46  12  21 examples of special reserved class d address   224.0.0.1 really means all systems on this subnet  224.0.0.2 means all routers on this subnet  224.0.1.1 is for ntp  network time protocol  used for synchronizing machines  224.0.0.9 is for rip-2  a routing protocol   so these are some special addresses and there are others  refer slide time  12  21  12  28  slide time  12  21  12  28 now there is a question of multicast address translation you remember what happens in the case of unicast is  from the ip address  for transmitting packets in the local network we need to go down to the data link layer and we need to find out the hardware address let us say if we are using ethernet then we need to find out the ethernet or mac address and then data is actually sent as an ethernet frame so the ethernet address is put over there now  that is the case when we are handling unicast now  what happens in multicast ? for this particular ip address it is actually representing a particular multicast group and there will be a number of machines in that group how do you handle it in the ethernet level ?  refer slide time  13  23  14  19  slide time  13  23  14  19  in ethernet mac addresses a multicast address is identified by setting the lowest bit of the most left byte that is this byte suppose you want 1  2  3  4  5  6  if you remember  ethernet address is 6 bytes long  now  of the first byte the most significant byte if you want and the last bit of that is set to 1 in ethernet mac addresses to indicate that this is the multicast address  unfortunately not all ethernet cards can filter multicast addresses in hardware so  if it can not be done in hardware then filtering is to be done in software by the device driver so  you accept the packet and then do the filtering if it is multicast and if you are a member of the group and then accept it  refer slide time  14  19 ? 15  49  slide time  14  19 ? 15  49 this is how the mapping is done suppose in this 1110  the first 4 bits and suppose this is the class d address and we are looking at the first byte of that address and the first four bits 1110 identifies that this is a class d address then this bit is actually ignored and then we have a 23 bit address this 23 bit address comes straight to the ethernet address so these 7 bits  these 8 bits and these 8 bits are matched straight to the last 3 bytes of the ethernet address for the first three bytes of the ethernet address we have a one here showing that this is multicast actually the ethernet address with 01  00  5e in the first 3 bytes are reserved for ip multicast so 01  00 and this is 101 is 5e and 1110 is e so  this is 01  00  5e and this is first 3 bytes  this is reserved for multicast and this part comes straight away  refer slide time  15  49 ? 16  12  slide time  15  49 ? 16  12  now let us move on to igmp which is the internet group management protocol this is a very simple protocol for the support of ip multicast  igmp is defined in rfc 1112  igmp operates on a physical network that is the single ethernet segment  refer slide time  16  12 ? 17  08  slide time  16  12 ? 17  08 if you remember  in the previous diagram we saw that one particular router is connected to one ethernet segment so igmp is between this router and the host which are there so igmp is used by multicast router to keep track of the membership now  who all amongst these members  who has ceased to be a member  who is the new person who wants to join as a member  so this has to be kept track by the local multicasting router and that is what igmp supports so  it supports joining a multicast group  query membership and send membership reports so the multicasting router will send queries from time to time and the host will respond or not respond depending on whether or not they are members of the group  refer slide time  17  08 ? 17  27  slide time  17  08 ? 17  27 so  we have this multicasting router over here and one single ethernet segment and number of machines connected there so igmp query comes from this multicasting router and igmp report goes to the router from the host  refer slide time  17  27  18  30  slide time  17  27  18  30 there may be an igmp general query that igmp group address is set to be equal to 0 it means that this query is for all the hosts  for all the groups and destination ip address is broadcast in this subnet you remember that 224.0.0.1 is broadcast in this subnet and source ip address is the routers ip address there may also be groups specific query in which case the igmp group address is the group address  destination ip address is again the group address because now i want to give this query only to the members of one particular group and source address is the routers ip address and this individual host sends the reports so it is the igmp membership report therefore igmp group address is the group address  destination ip address is also the group address and source ip address is equal to host ? s ip address  refer slide time  18  30  19  02  slide time  18  30  19  02 in the igmp message format there is a version and type type may be 1 or 2  version is usually 1 and then a 16-bit checksum and 32-bit group address type  1 for the query sent by multicast router and 2 is a response sent by a host group address is a class d ip address on query it is 0 and on response it is the group address being reported  refer slide time  19  02  20  27  slide time  19  02  20  27  a host sends an igmp report when it joins a multicast group  note  multiple processes on a host can join a report is sent only for the first process   this means that when a host wants to join one particular multicast group then it sends an igmp report to the router that it wants to join  on the other side when a particular host wants to leave a group  it does not want this multicast traffic any longer so when it wants to leave that group it does not do anything at all only thing is that when the next query comes for this particular group  for which it was a member then it will not respond so this means that there is some kind of aging in the group membership list that the router would maintain so  no report is sent when a process leaves a group  a multicast router regularly multicasts an igmp query to all the hosts  group address is set to 0    a host responds to an igmp query with an igmp report if somebody fails to respond then it is taken that he has left the group  refer slide time  20  27  20  51  slide time  20  27  20  51 what does the igmp host reports look like ?  host sends a report when it joins a group  it does not report when it leaves the group but does not respond to the next query so this is the igmp report  the time to leave is 1  the igmp group address is group address  destination ip address is group address and source ip address is host ip address  refer slide time  20  51 ? 21  17  slide time  20  51 ? 21  17 for general query  group address is 0  destination ip address is naturally broadcast and source is the routers ip address  so routers sends query at regular intervals to see if anyone still belongs to any group queries send out each interface  host responds by sending one response for each group to which it belongs  refer slide time  21  17  21  36  slide time  21  17  21  36 igmp messages are only 8 bytes long we have ethernet header  ip header and the igmp message which is version  type and some part is unused and the checksum and a 32-bit class d address  refer slide time  21  36 ? 22  04  slide time  21  36 ? 22  04 suppose you have a network with multiple multicast routers that means the same network but it has got multiple multicast routers only one router responds to igmp queries so this is the query so the router with the smallest ip address becomes the querier on a network one router forwards multicast packets to the network  so it is the forwarder if a network happens to be so constituted that there are two routers connected to it and both of them support multicasting in that case  only one router will actually do the querying so out of these two routers whichever has the smaller ip address will be the one which does the querying  refer slide time  22  27 ? 22  38  slide time  22  27 ? 22  38 now we come to the topic of multicast routing so  what is special in multicast routing ?  refer slide time  22  38 ? 22  52  slide time  22  38 ? 22  52 let us see this diagram suppose there is no support for multicast at the network layer which is the case in many practical situations  even then you could sort of simulate multicasting by doing repeated unicast so your original source has the list of all the members meaning all their ip addresses so it sends the message to all of them one by one  one by one  one after the other so this is just a successive unicast done therefore this is as if a multicast obviously you are more packets are packed into hops if you take some measure like that and of course you are doing much more work than what is strictly necessary but this is all you can do this has an advantage that the source can closely control that who could be a member of the group and who would not be a member of the group therefore you can impose some kind of access control by having an access list  refer slide time  24  05 ? 26  37  slide time  24  05 ? 26  37 now  if there is support for multicasting then what would happen is that  let us say there is one packet being sent to all three members of the group and say this is the source therefore the source will send only one packet to the next router this router is going to duplicate the packet as to one on this link and the other on this link this packet is ultimately destined for this host whereas this packet again gets multiplied and now this packet goes to this host and this packet goes to this host so  the number of packets traveling down is minimized a lot  of course the final number of packets is the number of users but if you just consider how much each packet travels  that means if you take the number of packets into the hop count kind of a weighted measure then that could be much lower overhead in some sense for packets that are traveling so it is much lower overhead on the links but may be more overhead on the routers now  if you have to have this multicasting capability for the routers this specifically requires two things one is  packet forwarding that can send multiple copies of the same packet for example  consider this router  this router is receiving only one packet but it has in its list that there are two sort of users for which the packet is supposed to go through this router so it has to duplicate the packet one for this link and other for this link so it forwards multiple copies of the packet this capability has to be there in the router secondly  multicast routing algorithm builds a spanning tree dynamically but how you found this tree ? this looks somewhat similar to forming a routing tree for unicast cases but there are some differences this tree has to be built up dynamically and in a distributed fashion by the routers for that they have to run ip multicasting protocol between themselves that is what we mean when we say routers are supporting multicasting  refer slide time  26  37  26  52  slide time  26  37  26  52 goal  the main goal of multicast routing protocol is to build a spanning tree between all members of a multicast group so these are the members of the multicast group and we have to somehow get this tree  refer slide time  26  52  27  57  slide time  26  52  27  57 this can be looked upon as a graph theoretical problem in whatever graph you have you have to embed the tree such that all multicast group members are connected by the tree suppose these are the three members of the multicast group seen in the previous graph and you want to form a tree like this then the only solution is to have a shortest path tree or source-based tree that is  build a tree that minimizes the path cost from the source to each receiver so this is the so called source-based tree and you can form this hence this is one kind of a solution  refer slide time  27  57 ? 30  24  slide time  27  57 ? 30  24 this is called a source-based tree  this is a good tree if there is single sender so sometimes multicast group is such that there is a single sender take the previous example we were talking about  a central news service or some kind of financial advisory service has some members and these are the members of this multicast group and there are some stock codes so this particular group may be interested in the quotation of a particular group of stocks and for this particular group of stocks this company collects all the information  the stock value  etc in a regular fashion and keeps on pushing it to the members of this group now  this is multicasting where there is a single sender and in such cases making a source-based tree makes quite lot of sense but of course  if there are multiple senders you need one tree per sender now that becomes really difficult where it becomes more democratic where all the group members are interacting and any of them can send messages to any member in the group therefore you have to have a tree for each sender having a single sender is easy to compute for this multicasting router we will always assume that whatever unicast routing is happening through osp etc is always present here but this multicast is sitting as an additional service by the router which essentially means that the unicast routing table is available for building up your source-based tree so in such a case this is easy to compute the tree is built from receiver to the sender this is called reverse shortest path or reverse path forwarding  rpf    refer slide time  30  24 ? 31  20  slide time  30  24 ? 31  20 a second solution to the same problem is that  if you remember the other graph  this graph looks different because this is the graph where it minimizes the total cost of the edges if you do not know who your sender is going to be  that means if any member of the group can be a sender then it makes sense to make the tree in such a manner  suppose  if you assume that all of them send packets frequently then in that case having the tree with the minimum total cost of edges would be the optimum solution so this is the second kind of solution  refer slide time  31  20 ? 32  18  slide time  31  20 ? 32  18 this is very difficult to compute  this is called the core-based tree  this is a good solution if there are multiple senders instead of keeping one source-based tree for each potential source we keep one core-based tree  very expensive to compute  not practical for more than 30 nodes for a very good solution  selects one router as core  also called ? rendezvous point ?    all receivers build a shortest path to the core using the reverse shortest path or reverse path forwarding but who would be the core of the rendezvous point depends on how good your core based tree is thereby depending on how you choose the core if you have chosen the core towards the center of the potential graph then that is good  refer slide time  32  19-34  26  slide time  32  19-34  26 let us see the details of reverse path forwarding  rpf   this is the way to build the tree  rpf builds a shortest path tree in a distributed fashion by taking advantage of unicast routing tables  main idea  given the address of the root of the tree  you know the source this tree is being formed from the sources each of the destinations  that means each of these potential recipients are trying to reach to the source and for that they use the unicast routing table which is already there in the router so given the address of the root of the tree  a router selects its upstream neighbor in the tree  the router which is the next-hop neighbor for forwarding unicast packets to the root so  what you do is  for each of the potential recipient you are trying to minimize the path cost from this recipient to the one single source right now for the source-based tree you have one single source whatever you do for unicasting  while sending a message from this node to that node is what you have to follow what the routers have to do is that  on the way suppose two different potential routes from two different recipients go through the same router then from this point onwards it is expected that this router to the final destination is actually the source of multicast communication and there is only one path and the tree would be automatically formed this is the basic idea of reverse path forwarding  refer slide time  34  27-34  48   slide time  34  27-34  48  how can this be used to build a tree ?  rpf forwarding  forward a packet only if it is received from an rpf neighbor  set up multicast routing table in accordance from receiver to sender along the reverse shortest path tree  refer slide time  34  49-35  51  slide time  34  49  35  51 this is an example suppose h1 is the source and rpf neighbor of r3  this is r3 and this is r1  r4 and r5 from these when they try to reach h1 they go from r3 to r2 to some path to h1 so r2 is the rpf neighbor of r3 the destination is h1 and the next hop is r2 this is the unicast routing table so r3 knows that r2 is the rpf neighbor of itself  refer slide time  35  52  36  09  slide time  35  52  36  09  routing table entries for source-based trees and for core-based trees are different  source-based tree  for source-based tree it is  source  group  or  s  g  entry  core-based tree  naturally anybody can be communicating so it is  *  g  entry  refer slide time  36  10  36  49  slide time  36  10  36  49 the source ip address  multicast group  incoming interface  rpf interface  and outgoing interface are the l2  l3 etc  this is a list and finally when a packet arrives the router has to forward one copy of the packet along each of these outgoing links which eventually reach some members of this particular multicast group  refer slide time  36  50  37  08  slide time  36  50  37  08 for building a source-based tree in a network like this set routing tables according to rpf forwarding and then use flood-and-prune  refer slide time  37  09  39  43  slide time  37  09  39  43  set routing tables according to rpf as we have already discussed  flood-and-prune what is flood ? forward packets that arrive on rpf interface on all non-rpf interfaces receiver drops packets not received on rpf interfaces these routers require the capability of forwarding multiple copies of the same packet so  if a packet has come from its rpf neighbor   rpf neighbor is with respect to a particular group  bearing this address means that it is actually coming from the source now it has to be forwarded to each of the outgoing interfaces of course it is a non-rpf this means  when i say rpf interface it means that the rpf neighbor is coming from the source side to all others which lead to different members of this multicast group what happens if you happened to get a packet from a link for this particular group who is not your rpf member ? first of all  how did it happen ? you must remember that we are doing this in a distributed and dynamic system so things can come up and go down so that way a packet can come in but obviously so far as this particular router is concerned if a packet comes from non-rpf link for this group then this is not coming from the source so that packet is dropped and naturally it also does pruning pruning is sending a prune message when a packet is received on a non rpf interface this is one case when you prune or when there are no group members in its local network and no connection to other routers suppose  it so happens that this particular router  you remember that this router is also connected to its local network and with the host in the local network it is running igmp always finding out who are the members of group etc it could happen that this local member has retired it no longer wants to remain in the group that means it is no longer sending your igmp reports so it has nobody to send it to nor is it connected to neither any router nor a part of a link from a distant source to a distant destination  nor a transit link like that so it is not connected in that case also now as the local contributor member of the prune has retired then this of course may not be known to others so it may still get a packet but then what it will do is that  it will send a prune message stating not to send anymore packets to it any longer so it will send the prune message along the route because the neighboring router has sent in a packet and it has nobody to distribute it to nor is it a transit router so  naturally it drops this packet because it has no use for this packet and along this link whoever has sent this packet to it the local member sends a prune message it means do not send the local member any further packets because it has nothing to do with this group anymore so that is one case   refer slide time  41  23  42  24  slide time  41  23  42  24 or  has received a prune message on all non rpf interfaces that means  it was a member earlier with all the non rpf interfaces and just like the group member may have retired similarly this may also have been a transit router on a link from some distant source to distant destination this may be an intermediate router on the way but then it has got a prune message on all its non rpf interfaces that means it was a member of a transit link earlier but now it is no longer a member so once again whoever had sent it a packet  it will send back a prune message to that destination that prunes this link as well so this is no longer interested  refer slide time  42  25  42  51  slide time  42  25  42  51  prune message temporarily disables a routing table entry  effect  removes a link from the multicast tree  no multicast messages are sent on a pruned link  prune messages is sent in response to a multicast packet  which has come and which satisfies any of these conditions  refer slide time  42  52  43  07  slide time  42  52  43  07 once again that it has received on the non-rpf interface or when there are no group members in its local network and no connection to other routers or it has received a prune message on all non rpf interfaces so in such cases the prune message is sent  refer slide time  43  08-43  19  slide time  43  08-43  19 the prune message has the effect of temporarily disabling a routing table entry the question is  why temporary ?  refer slide time  43  20  44  16  slide time  43  20  44  16  why the routing table is only temporarily disabled ?  what happens is that  you may have a receiver who may again like to join so one needs to reactivate a pruned routing table entry in that case so what happens is that  this group member may have gone away somewhere and now has come back and wants to be a member of the group once again so  it gets the igmp report saying that it is a member of this group now  it is aware of who knows the source  this multicasting router so what it will do is that it will try to reactivate this link and then the rest of it will work  so this is called grafting  sending a graft message disables prune and reactivates the routing table entry so this pruning and grafting are complimentary to each other you prune to disable and you graft to enable again  refer slide time  44  17  45  50  slide time  44  17  45  50 next is the core-based tree this was a source-based tree when you have one source and many receivers now you have many to many kind of situation that was one to many communications  not one to all  not broadcast   but now we have many to many communications that means there are many members of the group who might like to communicate with other members of that group in this case we would like to have what is known as a core-based tree  one router is the core  receiver sends a join message to rpf neighbor with respect to core now every receiver actually wants to join to the core  join messages creates a  *  g  routing table entry  source sends data to the core  core forwards data according to routing table entry now  since there is no source or that anybody could be a source we put a star in place of s for a particular router all the links get messages like this so a message may come in through any such link and it has to be forwarded to the other links  refer slide time  45  59  46  47  slide time  45  59  46  47 we just mentioned about multicast routing protocols which is actually implemented in most of the routers and many of the level 3 switches this is called dvmrp so you find them actually but unfortunately i have seen it very rarely being used but this is there in most of the routers of today as well as in many of the level 3 switches dvmrp is there  dvmrp is a distance vector multicast routing protocol  this is the first multicasting routing protocol  it implements flood and prune distance vector routing  if you remember  the distance vector routing uses the distributed bellman ford algorithm which is implemented by rip the centralized diesters algorithm  the link state algorithm is implemented in the routing protocol called ospf  refer slide time  46  48  47  58  slide time  46  48  47  58 open shortest path first  recall our discussion about routing protocols and this ospf is currently the most acceptable routing protocol there is a multicast extension of ospf which is known as mospf  multicast open shortest path first    multicast extensions to ospf  each router calculates a shortest path tree based on link state database  it is not very widely used  pim-sm builds core-based trees but they are not widely used  refer slide time  47  59  48  18  slide time  47  59  48  18  distance-vector multicasting routing  dvmrp  consists of two major components   a conventional distance-vector routing protocol  like rip    a protocol for determining how to forward multicast packets based on the unicast routing table  refer slide time  48  20  49  27  slide time  48  20  49  27  dvmrp  distance-vector multicasting routing  routers forward a packet if   the packet arrived from the link used to reach the source packet this is the reverse path forwarding that means if from this router i want to reach the source then i have to go to that next hop and that is my rpf neighbor so  if the packet arrives from this link from my rpf neighbor link  arrived from the link used to reach the source of the packet then this is the rpf chain  packet forwarded only to the child links not in the direction from which it came but other child links  if provided the downstream links have not sent a prune message  refer slide time  49  28  52  45  slide time  49  28  52  45 but dvmrp has limitations   like distance vector protocols  affected by count-to-infinity and transient looping in the count-to-infinity problem some link has failed but nobody could make out that the link has actually failed so it is going round and round known as the count-to-infinity problem where exactly the counting of potential distance to that link comes to infinity since we are using the same distance vector routing transient looping means sometimes a routing loop may form and the packet goes round and round  multicast trees are more vulnerable than unicast for these problems  this shares the scaling limitations of rip and this scaling limitation essentially comes from what i have written in the last  no hierarchy  flat routing domain one of the advantages of ospf over rip was that in ospf we break up the network into a hierarchy there are these autonomous regions or autonomous domains and then further down it can be broken up so that the routing problem remains simpler and you can scale to bigger and bigger networks since dvmrp is based on rip or essentially on the ideas of rip it is again a problem in dvmrp also here you can not scale and then you have further problem because of multicasting  you may have  s  g  state in routers  even in pruned parts  broadcast-and-prune has an initial broadcast when i say flood-and-prune  actually you are flooding the network so there is some kind of broadcast going on if the network size is small  this broadcast may be acceptable but when the network grows bigger and bigger broadcast becomes unacceptable so that is again another problem in scaling  this is limited to few senders many small groups also undesired since this essentially forms a source-based tree you can have only a few of them  just a few senders many small groups are also undesired if you have large number of groups  once again you have the same problem of maintaining so many trees and that also becomes a limitation for scaling  refer slide time  52  46  53  29  slide time  52  46  53  29 let us discuss about an effort to implement multicasting as i told you  most of the routers are not configured to use the multicast in every manner but still some people want to use multicasting so they built up this multicast backbone  mbone  which is essentially an overlay network of ip multicast-capable routers using dvmrp so it uses dvmrp and it is an overlay network of ip multicast-capable routers what does that mean ?  refer slide time  53  30 ? 55  05  slide time  53  30 ? 55  05 that means  some of the routers in the network in some places are multicast-capable and what happens is that they are going to support multicasting in its own locality that means it will support multicasting amongst the network to which they are directly connected these routers are going to run a multicasting protocol between themselves but then in between there are whole lot of other routers in between there is a cloud of routers which are not supporting multicasting so what it will do is that it will tunnel through this cloud to the next multicast supporting router so this is the picture of the mbone you have r which is the host or the router and this r and this h are the mbone routers they support and the part of the mbone is shown in light blue where the multicasting is directly supported whereas when they try to communicate to another multicast supporting node over a cloud which does not support multicasting they tunnel through it  refer slide time  55  08  55  18  slide time  55  08  55  18  mbone tunnel is a method for sending multicast packets through multicast-ignorant routers  ip multicast packet is encapsulated in a unicast ip packet  ip-in-ip  addressed to far end of the tunnel  refer slide time  55  21  56  07  slide time  55  21  56  07 you have the ip header destination which is unicast and then you have another ip header destination that is multicast and then the transport header what happens is that  the intervening routers which are not multicast-enabled are going to see this destination and this destination would then actually the next multicast router and here this part will be the pay load so the network nodes would not look into this when it reaches the next multicast supporting router it will get this and then discard this and then look at this multicasting header so this is the ip-in-ip encapsulation and tunneling  refer slide time  56  07  57  23  slide time  56  07  57  23  tunnels act like virtual point-to-point link  intermediate routers see only router header that means the unicast routing header  tunnel endpoint recognizes ip-in-ip  protocol type = 4  and de-capsulate the datagram for processing  each end of the tunnel is manually configured with unicast address of the other end so  this is what you have to do this was done to implement multicasting in an environment and try it out if there are problems about the one which is actually implemented in most of the routers namely dmrp that does not scale well and if there are many groups  in today ? s world when everybody in sort of networked and people have all their special interest etc it is quite considerable that the number of groups will explode if it could really do multicasting in a very easy fashion and that is very difficult for routers to handle that is why most of them do not use it at the moment but potentially this is a very useful kind of technology thank you  refer slide time  57  27 ? 57  28  slide time  57  27 ? 57  28 good day today we will talk about some protocols which are useful for controlling the network and making the machines connected to the network specifically  under the broadcast we will talk about dhcp and icmp there are some protocols associated with this and we will talk about this  refer slide time  57  59  58  02  slide time  57  59  58  02  refer slide time  58  03  58  20  slide time  58  03  58  20 dhcp is the dynamic host configuration protocol it is about configuring a host  configuring a machine  configuring a may be a pc or some computer which is connected to the network  refer slide time  58  20  58  44  slide time  58  20  58  44 its chief utility  there are other utility are dhcp we will be discussing later the chief motivation came from dynamic assignment of ip addresses now  dynamic assignment of ip addresses is desirable for several reasons computer networks prof.sujoy ghosh department of computer science and engineering iit  kharagpur lecture  36  refer slide time  00  47  our topic for today is qosqos and multimedia  that is quality of service and multimedia  refer slide time  00  57  00  58  we will just look at these one by one  refer slide time  01  07  01  37  quality of service  what is quality of service ? qos refers to traffic control mechanisms that seek to either differentiate performance based on application or network operator requirements or provide predictable or guaranteed performance to applications  sessions or traffic aggregates it talks about lot of things  the basic notion is that there are some applications which require one kind of quality of service by the way the quality of service may mean so many different things but the most important of them are the network delay and the packet loss these 2 parameters may sort of come in various ways  they affect differently when you talk about different applications and by multimedia we mean audio  video  etc going through the net which has got a different kind of qos characteristics  a different set of requirements than a file transfer we will see how we can handle qos and how multimedia traffic is handled in the network sometimes it may so happen that some applications are more important than others  so they need a better guarantee of performance such things also come under quality of service  refer slide time  02  46  04  24  take examples  video and audio conference requires bounded delay and loss rate that means the delay has to be bounded and also the variability of the delay should also be within the bounds and the loss rate of packets should again be bounded as you can see  this is quiet different from a file transfer where the loss of some packets can not be tolerated at all it is somewhat tolerant of losses  but more sensitive about delays when you are downloading a file  they are usually not that sensitive to trace video and audio streaming means maybe from video server or some internet radio  etc ; audio or video is being streamed to different clients so this again requires a bounded packet loss rate it may not be so sensitive to delay there might be some time critical applications like real time control here again  bounded delay is important there are some valuable called premium applications maybe those who run these premium applications are ready to pay more for this and they expect better guaranteed service than a low premium or less valuable applications  refer slide time  04  25  04  47  qos requirements can be specified as delay  delay variation  jitter   throughput which is the rate at which you can send data and error rate error rate is something where some packets get lost  refer slide time  04  48  08  10  there are two approaches to this  stateless and stateful qos solutions stateless solution  router maintains no fine grained state about traffic this has got a positive point that this is very scalable actually the kind of thing we have talked about till now is that routers do not maintain any states it is simply the raw packet forwarding capacity that comes to this in this way it is very scalable  this is also quite robust but it has weak services because there is no guarantee about the kind of delay or performance a particular application you will have to encounter on the other hand  we have stateful solutions routers maintain per-flow state this flow is very important while guaranteeing quality of service suppose there is some audio conferencing going on between some people  the audio signal nature is digitized and packetized and then these packets are going on this is a packet switched network  essentially at the heart of it this is a packet switched network but at the same time we not only talk about a single packet in entity in itself which is how we have dealt with packets so far but the end users are interested in the flow  that means the flow of packet all these streams of packets that are flowing which contain these audio signals constitute a flow and the users are actually interested in the flow suppose somebody wants some guarantee on this service  he wants a guarantee on this service of this flow merely looking at packets is not enough ; you have to go from a purely stateless situation to a stateful situation actually you have to make out that this is a part of particular flow naturally if you are stateful  if you go into the packet and look at what kind of packet it is and maintain a state about it in the router then you can give powerful services like guaranteed services plus high resource utilization  fine grain differentiation between different flows  protection where here there is a problem that this is much less scalable that means when the number of flows through a router starts increasing  and that is what will happen in any of the core routers  then the core router will not be able to handle this so it is much less scalable and much less robust  refer slide time  08  11  10  25  let us look at the integrated services this is a fully stateful system and is also known as intserv this is an intserv architecture or isa it is the architecture for providing qos guarantees in ip networks for individual application sessions we are talking about an entire session and the flow that has gone on during that session of flow consisting of so many packets it relies on resource reservation and routers need to maintain state information of allocated resources  for example g  and respond to new call setup requests the point is  in this situation how will you guarantee that this particular flow which is starting will get the requested kind of guarantee of service that means its delay would be bounded etc ? for this we have to specially reserve resources like buffers  resources like cpu time and so on at the intermediate points so  you have to reserve these resources for this particular flow so long as this flow continues that is how you give better service to this particular flow than to any other ordinary packet it will have to maintain the state in the form of these reservations and respond to new call setup request for example  as soon as you take out some resources  then naturally it goes out of the available resource pool and if a new call setup request comes for another session some intermediate router may not be able to handle that so it will not be admitted network decides whether to admit or deny a new call setup request  refer slide time  10  26  10  55  this is the basic idea of intserv therefore in this case since you have to reserve resources there is a call setup phase this is almost like a virtual circuit which is being setup there is a call setup request which goes from the source to the destination and back and on the way it reserves resources at each of the intermediate nodes and if each of the intermediate nodes  that is  each of the intermediate routers are ready to provide these resources then the call will be admitted  refer slide time  10  54  12  20  for resource reservation there is a particular protocol called reservation protocol or rsvp rsvp constitutes of call setup and signaling then there is a traffic qos declaration and per element admission control which means whether the call could be admitted or not then there will be qos sensitive scheduling that means  when a packet arrives first it may go into the buffer of a router and there maybe various buffers each of these packets will have to be scheduled for processing and then forwarding this processing may not be done in a uniform manner but it may be done in a qos sensitive manner similarly routing algorithm may also be qos sensitive  packet discard strategies etc come under the intserv qos components we have talked about scheduling and some of the other things now let us discuss about rsvp  refer slide time  12  21  13  44  rsvp is internet signaling it creates and maintains distributed reservation state this is decoupled from routing one thing is to use routing for setting up paths but then this has to reserved resources therefore it is decoupled from routing it uses multiple trees setup by routing protocols  not rsvp multicast tree is setup by routing protocols rsvp is for reserving protocols there unlike atm or telephony signaling while doing the call setup you actually assign the virtual setup this is initiated by the receiver  this scales for a multicast and it may use soft state that means reservation times out unless refreshed so you have to refresh reservation from time to time  otherwise one particular flow may be reserved and never be used so that part will go away that is why reservation will be timed-out and latest paths discovered through path messages  forward direction  and used by reservation messages in the reverse direction  refer slide time  13  45  14  08  signaling semantics  in signaling semantics you have a setup acknowledgement  setup response  admission control  tentative resource reservation and confirmation this can be done from both directions  simplex and duplex setup and with no multicast support these are the signaling semantics in brief  refer slide time  14  09  15  02  suppose this is the source  the source would initiate the setup it will send a setup call to the first switch controller  router to another one and finally to the destination each of the intermediate nodes send a setup ack so that the source knows that this is the way it is going to go and the path is being setup and then a setup response will come and the acknowledgement will go to the destination and another setup response and acknowledgement will keep coming in what we will have to see is that  in this fashion  after this  the resource has to be reserved at each of the node for whatever service that is being asked for  refer slide time  15  03  16  19  session must first declare its qos requirements and characterize the traffic it will send through the network there are two specifications r spec and t spec  the r spec defines the qos being requested  what kind of bound we want on the delay  what kind of bound we want on the jitter  what kind of packet loss is acceptable to me and depending on this the resource is going to be reserved that means maybe a special queue or buffer will be setup just for this flow or something will be done with scheduling there will be some weight given to it for processor time and so on in the intermediate nodes and then there is a t spec that is  traffic characteristics like what kind of traffic  what is the burstiness of the traffic etc ? such traffic characteristic will also have to be sent therefore depending on the t spec and the r spec the intermediate nodes will compute what kind of resource is visibly required so signaling protocol is needed to carry the r spec and t spec to the routers where reservation is required rsvp is a leading candidate for such signaling protocol  refer slide time  16  20  17  00  as far as call admission is concerned  routers will admit calls based on their r spec and t spec that whether they can handle or they can manage to give so much resources for this there is the financial side also  that whoever has initiated whether he has an agreement to pay for such premium service and based on current resources allocated at the routers to other calls if other senders have already reserved most of the resources in the intermediate routers then a new call may not be admitted  refer slide time  17  01  17  30  this is the router  the request specifies the traffic the t spec and the guarantees of service which is required which is the r spec now this reply to the element considers unreserved resources and the required resources for this new request if it can handle that then it replies whether or not request can be satisfied  refer slide time  17  31  17  46  this achieves per-flow bandwidth and delay guarantees for example  suppose we want a guarantee 1 mb/sec and < 100 ms delay to a flow and if we have a network like this   refer slide time  17  47  18  06  first the receiver will just allocate resources  that means perform per-flow admission control first the path has to be setup  that has not been shown and this is in the response path  so perform per-flow admission control  refer slide time  18  07  18  14  install per-flow state  so this flow has to be recognized  for that the router has to have a per-flow state  refer slide time  18  15  18  25  challenge  maintain per-flow state in a consistent manner right up to the sender if all the routers agree then only you can give it  refer slide time  18  26  18  36  when sender starts sending first of all it has to be classified that this is the integral part of this flow  so per-flow classification is necessary  refer slide time  18  37  18  48  depending on how it has been classified  it will be put in the appropriate buffer and the corresponding buffer has to be managed  so per-flow buffer management is also necessary  refer slide time  18  49  19  03  and this way it will go through all the routers  and per flow scheduling is necessary for cpu resources and the flow will go through  refer slide time  19  04  19  56  in the data path  we have per-flow classification  per-flow buffer management  per-flow scheduling whereas in the control path we have the installed and maintained per-flow state for data and control paths for each of the flow the router has to do a lot of work so this does not scale unfortunately this is very good at giving services but if you are trying to maintain a per-flow kind of classification and management at each of the nodes  this would not scale because if the number of flows goes beyond a certain level then it will be very difficult to maintain it will be very difficult to properly give it buffers and queues etc in the intermediate nodes so that is why it does not scale so well  refer slide time  19  57  21  00  stateless solutions are more scalable and they are more robust stateful solutions provide more powerful and flexible services it gives guaranteed services plus high resource utilization it can make fine grained differentiation between different flows and it also receives protection on the way since we are short of demarcating each of the flows demarcating the flow is somewhat similar  either to setting up atm virtual circuits  when you do that  you also reserve request but that is done while call setup itself  that is not done by a separate reservation protocol hence it is similar to that or it maybe similar to mpls where a particular flow can be differentiated from other flows and it maybe treated specially  refer slide time  21  01  22  56  then on one hand you have  the raw internet just takes a packet by itself and tries to route it and if it can not route  it is the best effort and it goes off that means it is discarded  that is one end of the spectrum the other end of the spectrum is that you have a full power flow classification and management for each of the flows where you can have a very good control etc but it does not scale so there is a question  can we do something in between and that is well the next model comes which is known as a diff-serv  differentiated service this is also stateful but here each distinct flow does not necessarily mean a distinct state these are sort of soft states which can accommodate a number of flows together so that the pressure on the routers in the intermediate nodes or in the backbone of the network becomes less scalability  maintaining states by routers in high speed networks is difficult due to a very large number of flows so diffserv provides reduced state services  that is maintain state only for large granular flows rather than end to end flows  tries to achieve best of both worlds so diffserv intends to address the following difficulties with intserv and rsvp flexible service models  intserv has only two classes  wants to provide more qualitative service classes  wants to provide relative service distinction like platinum  gold  silver etc and simpler signaling than rsvp many applications and users may only want to specify a more qualitative notion of service rather than a quantitative notion of service  refer slide time  22  57  24  00  this is a diffserv model  you have an ingress edge router and you have the interior routers  it goes to the egress edge router edge routers  traffic conditioning that means  policing  marking  dropping etc are done at the edge the reason we want to do them at the edge of the network is that  there the number of flows etc is much lower and you can handle it over there and when you come to the core the core routers are very busy so we do not want to do that over there therefore set values in ds-byte in ip header based on negotiated services and observed traffic interior routers  traffic classification looking at this byte and forwarding near stateless core this is almost like mpls or atm use ds-byte as index into a forwarding table  refer slide time  24  01  24  45  edge router  it does per-flow traffic management  marks packets as in profile and out profile core router  it does per class tm  buffering and scheduling based on marking at edge preference is given to in-profile packets in-profile means some traffic shape has been negotiated or is expected and then something comes which is out of the shape that means somebody is sending more packets per unit time than that was negotiated  so those are out of profile packets assured forwarding  this is what the core router does  refer slide time  24  46  25  34  marking and power flow classification etc is done at the edge but in between the scheduling is done the packet is marked in the type of service in ipv4 and traffic class in ipv6 renamed as ds then 6 bits used for differentiated service code point dscp and determine the phb or per hop behavior that the packet will receive  2 bits are currently unused and this service code will dictate how this particular packet will be treated  refer slide time  25  35  26  47  for forwarding per hop behavior or phb carried out in the interior routers is simplified process based on class and resources specified when sla was created phb has been defined in a certain rfc for example for premium service  it should have low loss  low delay  low jitter  assigned bandwidth is equivalent to point to point leased line etc is the kind of service we want  although this is not leased  this is the plain packet switch network it is guaranteed through policing and shaping in order to stay within the departure rate of leaky bucket and wfq since all the intermediate nodes guarantee that it will get premium service traffic conditioning  it maybe desirable to limit traffic injection rate of some class  users declare traffic profile  example rate and burst size  traffic is metered and shaped if non-conformed we have seen this already when we discussed congestion control  refer slide time  26  48  30  34  the packets are classified and then they are marked when they are classified and marked naturally for the session  some kind of t spec that is traffic spec has been already negotiated so it meters to see whether it conforms or not and then the traffic maybe shaped if by chance some burst comes and if the system can handle it then it will keep it for some time and then forward it only at an appropriate rate but if it goes too much then it drops it here itself this qoi is absolutely important especially for multimedia traffic as was explained for ordinary data traffic like web traffic or ftp  file download etc  those usually are not very sensitive to delay and variation in the delay that means you may get a lot of packets in one bunch then packets maybe slowing and coming extra and these things really do not matter much if it is within some bounds but in multimedia  these things are very important for example  when we talk  if the delay is beyond a certain level then we feel very odd for example  few years back if you had made an international call which is routed in a very peculiar way  you would find a lot of delay if you are speaking to somebody in usa  which is quiet annoying additionally what is annoying is that if the delay remains constant  some other people can manage it but if the delay keeps varying a lot  that is  if there is a lot of jitter then that is very irritating for people on the other hand unlike data  maybe a few bits are dropped here and there ; it will not matter too much maybe if you analyze it using machines you will find some difference in quality but as such to human perception most of the time it does not matter too much the multimedia traffic is quite different from ordinary data traffic and as network is spreading and the way it is going  people find it cheaper and most convenient to use this internet or use this computer network for what was traditionally telecoms domain in the sense for audio or video conferencing we have discussed about inserv  diffserv  rsvp etc  but the trouble is  many of the routers on the way are not going to support this because you need a consistent support throughout the path so people still try to use the raw internet which is just handling it at the packet level not really taking note of the flows and still try to handle multimedia and for that a set of protocols has evolved let us just look at those protocols now  refer slide time  30  35  31  17  principles  classify multimedia applications ; identify the network services that the applications need making the best of best effort service  you already have a best effort service and how can you make the best of it is what we will see in rtp  etc and there are some mechanisms for providing qos these are specific protocols for best effort and architecture for qos at the network level if you have supported qos these would have gone through much better  refer slide time  31  18  33  24  there are various classes of mm applications and not all are the same there is streaming of stored audio and video  that is one kind of application  for example  you download a song  movie that is a streaming  the stored audio and video is being streamed then there is streaming of live audio and video  then there are real time interactive audio and video and by this way you can generally classify by multimedia application you mostly need audio and video so by this way they can be classified fundamental characteristics  they are typically delay sensitive they are also sensitive to delay jitter which is a variation in delay loss tolerant  infrequent losses cause minor glitches  so this is the antithesis of data which are loss intolerant but delay tolerant sometimes we like vcr like functionality suppose we are seeing a video  so we try to equate it with the kind of functionality like in a vcr so client can pause  rewind  fast forward  push slider bar etc and at the same time when a multimedia session starts maybe an initial delay of 5  10 seconds is acceptable  1 to 10 seconds until command effect is also acceptable but we need a separate control protocol because we really have no other way of getting any kind of control  feedback  etc on these streams as we will see timing constraint for still ? to-be transmitted data  in time for play out  refer slide time  33  25  34  42  suppose we have  streaming of stored multimedia suppose this is the recorded video which is being sent  this is the cumulative data that has been sent  this is like a staircase because they have been sent as packets so chunks of data is going together so they are being sent first of all you record the video and the video is sent and in the third position the video is received and played at the client this is streaming of stored multimedia there is a network delay in between when the video is sent and the video is received as soon as you send it  you can not start seeing it  streaming  at this time the client is playing a part of the video while the server is still sending the later part of the video maybe in this particular diagram the client has already started seeing something although some of the data has still not been sent  refer slide time  34  43  38  05  therefore the streaming of stored multimedia is different from streaming of live multimedia for example  internet radio talk show is a live multimedia  a live sporting event which is being web cast streaming has a playback buffer  so playback can lag 10 ? s of seconds after transmission but it still has some timing constraint the interactivity is limited  for example  obviously if it is live you can not fast forward it but rewind and pause maybe possible it solely depends on how you handle it so this is unlike a stored multimedia where fast forward would also be possible interactive real time multimedia  is one of the most important applications like ip telephony  video conference of the web  distributed interactive worlds etc are the applications of interactive real time multimedia which has the most stringent qos requirements end-to-end delay requirements  different applications have different kinds of requirements for example if it is audio  if the end-to-end delay is less than 150ms it is good and less than 400ms is acceptable but beyond that people seem to be bothered a lot it includes application level that is packetization and the application level delay and the network delays higher delays are noticeable and they impair the interactivity session initialization  how does callee advertise its ip address port number  encoding algorithms etc because like in an ip telephony call all these issues are there if you are using a standard tcp or udp ip this is what you would have to do actually but there are no guarantees on delay or loss but multimedia application requires some qos and level of performance to be effective today ? s internet multimedia applications use application level techniques to mitigate as best as possible this is what we mean by best efforts  this means we can not do anything  maybe at the network layer etc it would implement an inserv or diffserv  but in most of the places that is not practical at the moment so we try to do something at the end points i.e at the application level the application level necessarily means the end point because it is the intermediate  it will not go right up to the application layer but maybe it will penetrate a little deeper this is mostly done from end to end  refer slide time  38  06  40  18  in this pseudo protocol  the number of protocols  first we look at real time protocols rtp that is rfc 1889 rtp specifies a packet for packets carrying audio and video data so rtp packet provides payload type identification such as what type of payload it is carrying  packet sequence numbering  time stamping that is important for giving some feedback rtp runs in the end systems rtp packets are encapsulated in udp segments interoperability  if two internet phone applications run rtp then they maybe able to work together and may communicate to each other through the network rtp runs on top of udp we have seen in both tcp and udp  the udp is a very lightweight protocol so it is also expected to be much more efficient than tcp tcp is a heavy weight protocol so it has a lot of overhead and all these acks keep on flowing rtp libraries provide some kind of support over an above the transport layer library  that is how a rtp runs on udp so this is a provider transport layer interface that extend a udp so port numbers  ip addresses are there in udp itself and then payload type identification  packet sequence numbering and time stamping is what rtp adds to udp and then  the application is here  it moves a little bit into the application domain maybe just look at the rtp header to do some what better service  refer slide time  40  19  41  43  rtp by itself does not provide any mechanism to ensure timely delivery of data or provide other quality of service guarantees  because that really depends upon what is happening on the way an rtp is running just between the two end points so rtp encapsulation is only seen at the end system which is not seen by intermediate routers so routers providing best effort service do not make any special effort to ensure that rtp packets arrive at the destination in a timely manner the services in between is still a best effort since we look at it at the end points there we can effect on some kind of control if you have noted  this rtp header goes in front of the payload for the data for example  it is the voice which is traveling then the voice signal is digitized and packetized before each packet produced by your application layer  the rtp header will come which is available in the data there is a separate protocol control called real time control protocol or rtcp  refer slide time  41  44  43  25  this is used in conjunction with rtp for multicast transmissions each participants in rtp session periodically transmits rtcp control packets to all the other participants each rtcp packet contains sender and receiver reports so reports statistics etc are useful to applications and this is what you might use to improve the performance of your session inside the network  inside the backbone nobody really knows about your session so it is only the end points but they exchange this kind of a statistics through the rtcp packets and then the application can control the rate at which things can be done  etc therefore some kind of feedback mechanism is present the statistics include number of packets sent  number of packets lost  inter arrival jitter etc feedback can be used to control performance  sender may modify its transmissions based on feedback this is the main point  you get some kind of feed back as this is running on udp there is no acks  packets coming on which you can send these statistics therefore what is done is that  this rtcp is actually in band control so a part of the bandwidth is kept for rtcp and through this bandwidth they exchange this kind of information and the time stamp  so you know that how much delay is being experienced at the other end and after having all these statistics you may do what you can at the application layer to modify the way you are transmitting in order to get better service  refer slide time  43  26  44  14  there are receiver reports  fraction of packets lost  last sequence number  average inter arrival jitter  etc are a part of the receiver report sender report  ssrc of the rtp stream  the current time  the number of packets sent  and the number of bytes sent source description  e-mail address of sender  sender ? s name  ssrc of associated rtp stream etc provide mapping between ssrc and the user or host name  refer slide time  44  15  45  46  another use of rtcp is for synchronization rtcp can synchronize different media streams within a rtp session so consider video conferencing applications for which each sender generates one rtp stream for video and one for audio the point is  you have got two streams of packets for the video streams and then the audio has to be synchronized with it the lips are moving in some other way and sound is coming in some other way so that will not help in anyway hence they have to be synchronized in order to synchronize this  rtcp uses the time stamp which i referred to earlier and tries to synchronize the two different streams this is another important use of rtcp so time stamps in the rtcp packets are tied to the video and audio sampling clocks they are not tied to the wall clock time the wall clock times are also exchanged and this is to get an idea about the delay each rtcp sender report packet contains for the most recently generated packet in the associated rtp stream  timestamp of the rtp packet and wall clock time for when packet was created this gives you an idea about the delay receivers can use this association to synchronize the play out of audio and video  refer slide time  45  47  48  02  rtcp bandwidth scaling  rtcp attempts to limit its traffic to 5 % of the session bandwidth remember  that this is in band control that means whatever bandwidth is given for the session it is within that only so whatever the rtp actual data packets are using  maybe 5 % of that  the rtcp tries to use and in this 5 % it is kind of divided  like 25 % for the sender  and 75 % for the receiver because there may be many receivers and this 75 % will again be distributed amongst the receivers suppose one sender sending video at a rate of 2 mbps then rtcp attempts to limit its traffic that means to the rtcp traffic to 100 kbps rtcp gives 75 % percent of this rate to the receivers  remaining 25 % to the sender we come to another protocol called rtsp known as the real time streaming protocol earlier we were talking about interactive live audio or video conferencing  but now let us talk about streaming user interactive control is provided  for example  the real time streaming protocol where a helper application displays content which is typically requested via a web browser  for example a real player  then we have the typical functions namely decompression if it is compressed in audio or video  jitter removal which means you play them back at a constant rate  error correction  use redundant packets to be used for reconstruction of original stream  some kind of graphical user interface for user controls like rewind  fast forward  etc are given by rtsp what it does not do is  it does not define how audio and video is encapsulated for streaming over network  it does not restrict how streamed media is transported  whether tcp or udp does not specify how the media player buffers audio and video so these are more at the application layer  refer slide time  48  03  49  08  this is the simple approach for steaming audio or video audio or video is stored in file files are transferred as http object that is received in entirety at client then pass to player so audio or video are not streamed and so no pipelining  long delays until play out here the problem is that if it is some kind of a movie and if it is downloaded then the entire file is downloaded  so downloading that entire file will take a lot of time  this is a very simple approach and then there is no problem  you can download the entire file and then play it use options like fast forward or reverse or speed up etc but streaming in the media means  as it starts streaming the audio or video file then after some delay the play back also starts  refer slide time  49  09  50  43  simple situation is  we have a web browser  web server with audio files and a media player and that is how we do it the actp request  so browser gets a meta file then the browser launches a player passing the metafile to the player and the player contacts the server and the meta file contain all the necessary information  this is called progressive download let us look at the streaming multimedia client buffering suppose as before this is the constant bit rate video that is being transmitted and now because of the network delay and the availability of the network delay this is what the profile looks like of how it is received but if you do this after some sufficient delay and you buffer it  the main point is  these two lines are never crossing so now you can play it at a constant rate so all these delay variation etc that will sort of go and you would get a nice streaming audio or video this is the basic idea of streaming multimedia in this part  the difference between these two where this is the buffered part  so the client side buffering play out delay compensate for network added delay or delay jitter etc  refer slide time  50  44  51  29  streaming multimedia  is where udp is usually preferred we will also look at how tcp is done the server sends at rate appropriate for client oblivious to network congestion so  often sent rate is equal to encoding rate that is constant rate  then there is a fill rate for constant rate minus packet loss short play out delay 2-5 seconds compensate for the network delay jitter somebody does not really mind so much  that if the play back starts after 5 seconds but in this 5 seconds the entire thing will be buffered and that will take care of the jitter error recovery takes place if time permits  refer slide time  51  30  52  07  tcp  it sends at maximum possible rate under tcp and fill rate fluctuates due to tcp congestion control because in tcp congestion control the windows size can keep on varying so larger play out delay is smooth tcp delivery rate if you start playing it after quite some time so that you can handle this tcp variation in rates etc then you can get a smooth rating then http tcp passes more easily through firewalls rather than udp  refer slide time  52  08  52  24  rtsp example  meta file is created and communicated to the web browser browser launches player as we have seen and player sets up an rtsp control connection data connection to streaming server  refer slide time  52  25  52  47  web browser gets an http get and web server presentation description then the media player is setup a connection with the media server and it starts getting it  buffers it and starts playing the media stream comes  then you may pause  you may teardown  etc  refer slide time  52  48  53  09  finally i will just mention about two protocols namely  h.323 which is an itu standard which is the old protocol for setting up telephone calls h.323 is aging a little bit and there is a  refer slide time  53  10  53  28  newer protocol namely session initiation protocol all telephone calls and video conferencing calls take place over the internet that is the vision  you can reach the callee no matter where the callee roams  no matter what ip devices the callee is currently using therefore  refer slide time  53  29  53  58  for setting up calls there is a large protocol setting up a call  provides mechanisms for caller to let callee know she wants to establish a call and provides mechanism so that caller and callee can agree on media type and encoding because that has to agree and it provides a mechanism to end the call the first one is called an invite and there are all kinds of  refer slide time  53  59  54  29  commands for this it also has the facility to determine the current ip address of callee  maps mnemonic identifier to current ip address there are other components of chip like  chip register and so on then it has something for call management  that means add new media streams during call  change encoding during calls  invite others for a conference  transfer and hold calls etc  refer slide time  54  30  54  38  there are all kinds of details about codec negotiation etc  refer slide time  54  39  56  15  and then you may reject a call also the audio  video and multimedia over the internet is going very strongly at one point of time network performance was so poor that there was no question of accommodating this but as the network performance has increased exponentially over the past years now it is becoming much possible to handle lot of multimedia traffic through network this is getting more popular we talked about inserv  gifserv but the actual strategy that people actually deploy is when they feel this is not sufficient then they put in more bandwidth so put another fiber and take up your multiplexer weight etc so that you solve the problem because the demand for multimedia is so great good day  today we will talk about network management as the network becomes very large we need support for managing these networks  we need support for keeping track of these networks and so  we are going to discuss on how that is done  refer slide time  56.16  56.18  today ? s topic is network management  refer slide time  56.19  56.42  network management is the process of controlling a complex data network to maximize its efficiency and productivity the overall goal of network management is to help with the complexity of a data network and to ensure that data can go across it with maximum efficiency and transparency to the users  refer slide time  56.43  57.18  the iso  that is the international organization for standards in network management forum divided network management into five functional areas  fault management  configuration management  security management  performance management and accounting management out of this  actually it is quite often you find that there are two systems which was deployed  refer slide time  57.19  57.41  in that case the trap will never come the only thing is that when the network management station polls that particular device so it will fail to respond that way you will find out that something is wrong so you should use a mixture of trap and polling to do your management  refer slide time  57.42  58  30  let us quickly go through the types of snmp packets  one is the get request  it retrieves the value of a variable or a set of variables  and get next request used to retrieve values of entries in a table  so the next entry get bulk request retrieves a large amount of data used instead of multiple get request and get next request so that in one go you can get a lot of information as far as the bandwidth is concerned set request  set or store a value in a variable response  response to get request or get next request contains values and or variables requested trap  sent from agent to manager to report an event  refer slide time  58  31  58  48  inform request  sent from one manager to another remote manager to get a value of some value from agents under the control of the remote manager report  designed to report some types of errors between managers but not very widely used  refer slide time  58  49  58.58  now we come to the snmp data types computer networks prof s.ghosh dept of computer science & engineering iit kharagpur lecture 33 dhcp and icmp  refer slide time  00  47  good day today we shall talk about some protocols which are useful for controlling the network and also in keeping machines connected to the network specifically under the broadcast we will talk about dhcp and icmp there are some protocols associated with this so we shall discuss about it  refer slide time  1  14-1  16   refer slide time  1  18-1  38  dhcp is dynamic host configuration protocol it is about configuring a host  configuring a machine may be a pc or some computers connected to the network  refer slide time  1  35-3  29  the chief motivation came from the dynamic assignment of ip addresses the dynamic assignment of ip addresses is desirable for several reasons  ip addresses can be assigned on demand for example  when you have a scarcity for real ip addresses then you keep a central pool of ip addresses and then as some computer comes on line it assigns an ip address from the pool and when it goes out those ip addresses are withdrawn and are given to some other machines another place where it may be required is  suppose you have some kind of a ras or remote access server to which a number of machines should be connected via dial up connections then in that case you give them a temporary ip address for the connection now if somebody wants to visit some network with a laptop then they have to get a network address of that particular network therefore that network address has to be dynamically assigned ip addresses are assigned on demand it avoids manual ip configuration which is prone to errors it also supports mobility of laptops  refer slide time  3  30-3  59  dynamic assignment of ip addresses is done using three different protocols 1 rarp  it was widely used up to 1985 and even beyond this period people kept using it 2 bootp  bootstrap protocol was used until 1993 3 dhcp  is used after 1993 and currently this is in wide usage a bootp client can also use dhcp server  refer slide time  4  08-5  33  rarp is actually the reverse arp address resolution protocol the problem is  given an ip address what is the mac address this is for mapping between the ip addresses and the mac addresses finding the mac address for the ip address is useful when you want to communicate over a lan rarp is the reverse of this given a mac address  rarp finds ip address this would be necessary in case you have something like disclosed work station which boosts the signal over the network a disclosed work station has its own mac address and it wants to get an ip address assigned this is where rarp is typically used rarp is used to broadcast a request for ip address associated with a given mac address rap server responds with an ip address it only assigns ip address and not the default router  subnet masks etc that are required and they are not a part of this server refer slide time  5  34-5  46   refer slide time  5  34-5  46  so ip address to mac address is the arp and ethernet mac address to ip address is the rrap  refer slide time  5  45-6  39  let us see the improved version of rarp i.e bootp bootp not only assigns ip addresses dynamically but also has some more functions host can configure ip parameters at boot time basically there are three services  ip address assignment detection of the ip address for a serving machine the name of the file to be loaded and executed by the client machine i.e the boot file name this is the source from which it gets the name bootstrap protocol i.e when the machine is booting up it not only gets an ip address but also gets the name of the file which can be loaded and executed this is the bootstrap protocol or bootp  refer slide time  6  40-7  37  bootp not only assigns ip address but also default router  network mask  etc therefore whatever that particular machine requires for communication namely the addresses such as network  subnet mask  gateway etc are given by the bootp protocol this is sent as an udp message so udp port 67 is for server and udp port 68 is for the host port 68 for host is required when you may want to find out a machine from bootstrap protocol which is already available on the network and use limited broadcast address that is 255 255 255 255 if you recall from our discussion about addresses this is a broadcast address where the broadcast is limited to this particular subnet or network  refer slide time  7  51-8  14  bootp can be used for downloading memory image for diskless workstations so whatever was the motivation for rarp the same thing can be done through bootp also but assignment of ip address to hosts is static this is one sort of drawback of bootp  refer slide time  8  16-8  52  to make it dynamic we go to the dynamic host configuration protocol which is standard now and more versatile than rarp and bootp it can do a lot of things apart from just giving the ip address this was designed in 1993 as an extension of bootp with many similarities to bootp and same port numbers as bootp that is why dhcp server can handle a few bootp clients  refer slide time  8  52-10  05  extensions  there are lots of extensions especially with options but these extensions support temporary allocation or leases of ip addresses leasing of ip address  suppose when we have a remote access server and when people are dialing what would happen is that  it would be given a particular ip address for a fixed amount of time when its lease expires then that ip address may be withdrawn and half way down the lease period if there is no great demand for ip address then the lease may be automatically extended or if there is a great demand the lease may be withdrawn also this is for a temporary period of time and that is how it is dynamic dhcp client can acquire all ip configuration parameters not only subnet mask and gateway addresses which are there in bootp but also other kinds of parameters can be downloaded from a dhcp server  refer slide time  10  16-10  23  so dhcp is the preferred mechanism for dynamic assignment of ip addresses and dhcp can interoperate with bootp clients  refer slide time  10  24-12  17  dhcp has a number of options it is not possible to mention all the available options here other dhcp information is sent as an option so the number of options is actually greater than 100 which include things like subnet mask  name server  host name  domain name  forward on/off  default ip time to leave  broadcast address  static route  ethernet encapsulation  x window manager  x window font  dhcp message type  dhcp renewal time  dhcp rebinding  time server smtp server  client fqdn  printer name etc as the number of services given over a network grew it became important to give more information to the machines originally the machine was used just for communicating between two computers suppose there may be a centralized print service in the network and whenever you want to print something it can be done in the network similarly all other kinds of services became available in the local network as well as over wider networks so all these would require some kind of configuration on the host end therefore such information can be transferred via this dhcp  refer slide time  12  18-12  50   slide time  12  18-12  50  there are a number of dhcp operations let us discuss a few of them dhcp discover  at this time the dhcp client can start to use the ip address renewing a lease  it is sent when 50 % of the lease has expired if dhcp server sends dhcpnack then the address is released then you know your lease is not going to be renewed  slide time  12  49-12  55  dhcp release  at this time the dhcp client has released the ip address  so the client has given it up  refer slide time  12  56-13  40   slide time  12  56-13  40  dhcp message header fields  in some fields there is an opcode it may be a dhcp request from the client or it may be dhcp reply from the server the dhcp message type is sent as an option the hardware type of message is 1 for ethernet and hardware address length is 6 for ethernet hop count is set to 0 by client and transaction id is an integer used to match reply to response if there is more then one request  refer slide time  13  38-14  30   refer slide time  13  38-14  30  seconds  it is the number of seconds since the client started to boot client ip address  your ip address  server ip address  gateway ip address  client hardware address  server host name  boot file name  etc all these fields are available so when the client sends the request it would fill in whatever is known to it  maybe the mac address is known to it so it puts in the mac address and all other fields are left blank dhcp server will pick up the message that we broadcast and then fill up all the other necessary fields and then broadcast it back  refer slide time  14  29-14  50  the following are the dhcp message types sent as an option  dhcpdiscover dhcpoffer dhcprequest dhcpdecline dhcp acknowledge dhcp not acknowledge dhcprelease dhcpinform and so on  refer slide time  14  48-14  58 our next topic is icmp internet control message protocol  refer slide time  15  05-15  30  let us see ip protocol and its deficiencies before that  slide time  15  05-15  30  the internet is of course based on the internet protocol ip protocol has some drawbacks though it is a best effort delivery service it lacks error control and lack of assistance mechanisms since ip is a best effort delivery at some point of time the effort may not be enough and routers ore other nodes on the network may have to drop packets and packets may not reach its destination on time and in proper order first of all there is no error control and secondly if such errors do occur there is no message to the sources secondly  if you want to control the network for some reason  for example  may be the network is getting congested and so you want to do something about it  but ip does not have the mechanism so  for all these purposes icmp was brought in  slide time  16  36-16  55  therefore what happens if a router must discard a datagram because it can not find a route to the final destination ? what if the time to live field has zero value ? what if it has to discard all the fragments because not all were received in a predetermined time limit ? in all these cases ip has to discard a packet  slide time  17  05-17  24  and similarly there are other situations for example  may be it has reached the destination but the port is not available so ip protocol also lacks a mechanism for host and management queries so icmp was designed to compensate for these deficiencies  slide time  17  25-18  01  icmp is a type field that indicates the type of icmp message being sent and the type may be queries or errors code field gives further information specific to the icmp message for example  when an error occurs it tells what kind of error it is checksum field is used to verify the integrity of the icmp data so once again the checksum is included to control the error  refer slide time  18  00-18  24  there are two types of icmp messages one is error reporting and the other is query response if there is some error then the error reporting type of icmp message would be generated and if there is a query another type of icmp message would be generated  refer slide time  18  23-18  29  there is no effort in icmp to correct the errors this is the job of some other layer so it does not really try to correct the errors but nearly reports the errors the error messages are sent to the source suppose the datagram has been sent and something has happened to it and due to that there is an error  and now whoever drops that packet send an icmp message back to the source it may be a router on the way or may even be the final destination  refer slide time  19  23-19  50  these are the various types of errors in error reporting there may be a destination unreachable  there may be a source quench sending to first some of the important ones may be time exceeding  some may be parameters problem or redirection  etc  refer slide time  19  51-21  29  please note that  no icmp error message would be generated in response to a datagram carrying an icmp error message that means  somebody has generated an icmp error message and it is traveling back to the source  and that error message itself gets an error and may have to be dropped on the way  then in such cases we do not generate another icmp message a little bit of problem happens due to congestion of networks so if the network is very congested many packets may get dropped and then if in response to dropping many packets you generate more packets then the congestion is not going to go away so  icmp error messages do not trigger other icmp error messages for a fragment datagram that is not the first set of fragment for example  the datagram may have been fragmented into a number of parts  may be fifty parts  now for each of them you generate an icmp message then the icmp message would be too many so it is only generated for the first fragment for a datagram having a multicast address  once again we can not send an icmp messages to all members of the group and for a datagram with a special address such as 127 0000 or with some address like 0.0.0.0.0 also no icmp error messages are generated for these  refer slide time  21  30-23  15  all error messages contain a data section that includes the ip header of the original datagram plus the first 8 bytes of data in that datagram this information is required so that the source can inform the protocols about the error from the original packet that was dropped the ip header of that original packet is sent back first of all you need to know the source and know where you want to send back this icmp message secondly  even after this icmp message gets back to the specific machine from which the original packet was generated at this point it may have some error messages due to network intervening or this may have to do something with some process or application which is running on the source machine so  after getting the message the host must know to which process it relates to after the ip header what comes is the transport layer header so  a part of the transport layer header also goes back along with the icmp message .this information is required so that the source can inform the protocols about the error  refer slide time  23  16-23  50  destination unreachable  this is one type of an error message when a router can not route a datagram or a host can not deliver a datagram  then in that case the destination is unreachable a router can not detect all problems that are preventing the delivery of a packet so it is not always possible to exactly know why the destination is unreachable but at least this information that the destination is unreachable  goes back to the source  refer slide time  23  51-25  30  source quench  this is a crude attempt to implement some kind of flow control ip protocol has got no flow control routers and hosts have limited size queues so what happens is that  may be in an intermediate router and a number of packets have come up and certainly there is a flood of packets into one intermediate router from various directions so what would happen is that its buffer is going to overflow and it will not be able to process because there is a limit depending on the speed of the router etc  there is a limit as to how fast packets can be processed and forwarded by an intermediate router and if other packets keep coming in  within that time they are going to be stored in the buffer where in the buffer might overflow in that case the router can not do anything else but to drop those packets this router desperately wants to tell other people in the network to slow down on sending packets and that it can not handle it because of overload basically it tries to slow down the flow of packets into itself so it sends the source quench icmp message towards the sources if datagram is received faster than they can be processed the queue may overflow and in that case it asks the network to slow down  refer slide time  25  32-25  43  if a router or host discards a datagram due to congestion it sends a source quench message to the sender the source must slow down the sending of datagram until the congestion is relieved  refer slide time  25  44-26  03  this may be used when bottlenecks occur for example  on a wan link with too much congestion it is used to reduce the amount of data lost but a warning is  source quench message will in turn generate network congestion there were already too many packets in the network but you have sent a source quench packet towards the source which is just one hop towards the source was already getting packets from the source but will also get an icmp message from the router just one hop down so it is having more packets now so by this way congestion might travel towards the source but anyway finally it reaches the source and the source will hopefully slow down and all these will die  refer slide time  26  48-27  18  time exceeded  whenever a router receives a datagram with a time-to-live value of zero that means it has been going round the network it discards the datagram and sends a time exceeded message to the source when the final destination does not receive all of the fragments in a set time it discards the received fragments and sends a time exceeded message to the source these are two different cases  one is that  in the destination all the fragments did not reach so there was a specified time after which it has to drop all the fragments and send a time exceeded message to the original source the other thing is that  when a router receives a datagram with the time-to-leave field which is zero if you remember  keeping a time-to-leave field and decrementing it at every hop is quite important because suppose there were some packets which were floating around in the network and due to some trouble with the routing tables a loop has been formed  so  if you do not have this time-to-leave field it will go round and round at infinite term where they slowly burden the network so  the solution to that was  after a certain number of hops the packet is dropped and when a packet is dropped a time exceeded message is sent to the source there may be parameter problems  refer slide time  28  35-28  48  if an ambiguity is found in the header of a datagram the datagram is discarded and a parameter problem message is sent back to the source  refer slide time  28  47-28  59  redirection  a host usually starts with a small routing table that is gradually augmented and updated one of the tools to accomplish this is the redirection message  so  actually this helps in routing  refer slide time  29  00-29  18  now let us come to queries icmp can also diagnose some network problems for example  echo request and reply  time stamp  address mask  router solicitation and advertisements  these are example of queries we will just see a few of these also  refer slide time  29  22-30  01  echo request and reply  is used very often when you want to find out whether the network is up and running or not an echo request message can be sent by a host or router an echo reply message is sent by the host or router which receives an echo request message the echo request and echo reply message can be used by network managers to check the operation of the ip protocol echo request and echo reply message can test the reachability of a host this is usually done by invoking the ping command later on we will get into more details of ping because that is one kind of command which even users quite often require for example  if you are logged on and you find that you can not reach your destination anywhere in the network then you have to find where the problem lies  is it in your local network or in the local subnet therefore in the local subnet you might ping that gateway to see whether you can reach up to the gateway if your ping message goes up to the gateway and you get an echo reply then you know that up to that much the network is ok and if you are ok up to the router you may want to ping the router in the entire network now the problem may be somewhere in the link outside the problem may even be in the destination which you are trying to reach so one way is to go probing the network  even by users is to use ping  refer slide time  31  16-31  47   refer slide time  31  16-31  47  timestamp request and reply  timestamp request and timestamp reply messages can be used to calculate the round-trip time between a source and a destination machine even if their clocks are not synchronized so  sending time is equal to the value of receiving time stamp minus value of original time stamp so this way you can get some idea about the round-trip time there are other ways also  refer slide time  31  49-32  12  so receiving time = time the packet returned ? value of transmit timestamp round-trip time = sending time + receiving time so the timestamp request and timestamp reply message can be used to synchronize two clocks in two machines if the exact one-way time duration is known  refer slide time  32  14-32  21  address-mask request and reply  enables a host to request and receive the network or subnetwork mask it is useful for diskless stations at start up but we have seen the dhcp is another way of handling this  refer slide time  32  23-32  43  router solicitation and advertisement  allows request of routing information and the reply of this information routers can periodically send router advertisements without being solicited suppose a router has just been connected to the network  anyway the routers have to run the routing protocol like the rip or bgp  osp etc  this means it needs to communicate to the neighboring routers  but how do the other routers know there is a new router in the group so  one way is  as soon as the router gets connected it does some router solicitation and it advertises itself so that other routers get to know that and slowly the entire network becomes aware of this new router which is connected similarly  a link may go down and all kinds of other things may happen so  the exchange of router information has to happen through some mechanism  refer slide time  33  44-34  15  router discovery message  host can learn about available gateways to other networks host send the router solicitation message to begin the process using the multicast address of 224.0.0.2 as the destination it can also be a broadcast message in case a router does not accept multicast messages when a router receives the message it will advertise its available gateway  refer slide time  34  16-34  28   refer slide time  34  16-34  28  the checksum of the icmp message  in icmp the checksum is calculated over the entire message  that is the header and data combined this is just to keep some control over errors  refer slide time  34  26-34  48  clock synchronization  software may require time synchronization so icmp time stamp message combats this problem it allows local host to ask for the current time from a remote host using icmp timestamp request so it is type 13  refer slide time  34  47-35  04  remote host uses icmp timestamp reply which is type 14 so  the better way of synchronizing the clocks is to use the network time protocol the time is the ut universal time  refer slide time  35  05-35  08  ping and traceroute   refer side time  35  15-35  55  this is an overview this is part of the icmp messages ping sends an icmp message to a remote host and lets you determine if that host is responding actually ping uses echo and echo reply for the icmp message traceroute uses ttl fields to query all hosts enroute to a specific destination you can use traceroute to map a network that means  if you want to know which is the route you are tracing then this helps you  refer slide time  35  58-36  46  ping is named after sonar in sonar if you want to probe some place you send an ultra sound signal just like you do in radar and if it bounces of something you get a ping  so that is where the name comes from if you want to send an echo request you expect an echo reply and that is your ping so server normally implemented in kernel uses icmp echo and echo reply messages on unix the identifier field is set to unix pid or sending process sequence numbers starts at 0 incremented every time a new echo message is sent actually  when you ping a machine not just one request is sent the machine you are trying to ping or the channel may be noisy and if that happen then your echo request or the reply may get dropped in between so  sending one request is not sufficient and may be three times or five times etc you can configure it  it sends echo request and it expects all the three or all the five replies and if it receives none of them  then in that case it will say that hundred percent of packet loss or it may get two out of five so it will say sixty percent of packet loss or forty percent  refer slide time  36  37-39  46   refer slide time  36  37-39  46  let us see one example of ping suppose we ping a machine 144 16.182.1  we have pinged this machine and then give the ip address over here by the way if you have a name server on the network you could also put the name over there ping 144 16.182.1  56 data bytes is your data plus it will have some thing so you may get a result like this  64 bytes  this is what you are getting from the echo reply  64 bytes from 144 16 182 1 icmp sequence = 0 time-to-leave is 240 and time = 37 milliseconds so it gives you some idea about how much time it takes then another packet has came back as an echo reply 64 bytes from the same machine  sequence number 1 and time is so much for each packet it receives back as reply it is going to print a line like this and then finally it will give you a statistics as something like this  13 packets transmitted  11 packets received which means that it had originally sent 13 packets and it got only 11 packets back so 2 packets must have got lost therefore it is a 15 % packet loss and the round-trip time you may calculate the mean  average  max so  from the ping you can get an idea about the round-trip time  refer slide time  39  51-40  12  some details on the output sequence number are shown for each message in our example message returned in order but we lost some packets they may be returned due to out of order also ttl field of return message is displayed and round-trip time is calculated at the host based on the sequence number  refer slide time  40  14-41  45  we can estimate not only the round-trip time but also the bandwidth using ping but this works only for few hops if it is beyond a number of hops your ping will not work the ping packet can estimate the bandwidth in this way  20 byte ip header  8 byte icmp header  56 byte message this can be set by the user  so the total datagram size is that + 76 + 8 = 84 bytes so 84 bytes were sent now  if it was sent through ppp it will add about 8 bytes so the total size will be 92 bytes so this connection looks like 92/.180/2 that is about 1069 bytes per second what is this .180 ? it is 92 bytes so this is time this gives you some idea about what kind of bandwidth you have in this particular case the bandwidth is not that much but it is only about 1069 bytes per second this is a very crude estimate but you can get some kind of feel about your immediate locality  refer slide time  41  56-42  23  record route option  most ping implementations provide record route which is ? r option on linux  ? r option on windows each router stores its address in the ip options field  only 9 addresses are possible thus round-trip is only possible for 4 routing hops so you can take only 4 hops and within those 4 hops you can find out that how your message went and how it came back that is  may be it came back through different paths or it could have returned in the same path etc you can actually trace the route and because of the limitation on the size that is on the number of addresses you can store you can only route or map the network in your immediate locality but if you want to go beyond this then you have to use something else called traceroute  refer slide time  43  12-46  16  traceroute uses a sequence of icmp messages to determine the current route to a particular destination this is actually done in an iterative fashion suppose i want to traceroute to a distant machine whose ip address is known then i will send a message to that machine but with a very small number for the time-to ? live therefore what will happen is that my message will take so many hops but then it has not reached the destination so may be it must have just started and it will be somewhere in the beginning so its time-to-leave is going to become 0 as soon as the time-to-live becomes 0 the intermediate node may be that router will have to drop the packet and it sends an icmp message back to the source now my program gets this icmp message and now it sends the same dummy message to the destination after increasing the time-to-live by one unit now it is going to pass that router that had dropped the packet in the previous instant and so it will go one more hop and then the packet will get dropped so that router is now going to send an icmp message back to the source now we will know which router is on the way therefore by this way iteratively you keep on increasing the time-to-leave one by one and you trace the entire route  that is  you map it out but let us see what happens when it reaches the destination ? when it reaches the destination what happens is that this message is sent to a very unlikely port  a randomly selected port most probably the destination machine will not know about this port so it will say that the port is unreachable and then that icmp message will come back now we know that we have reached the destination hence this way we have traced the entire route one by one from the source to the destination traceroute uses a sequence of icmp messages to determine the current route to a particular destination the ttl specifies the number of hops a message can travel trace route sends udp datagrams while varying the ttl the router that drops the udp packet now replies with a time exceeded icmp message  refer slide time  46  20-46  40  the end point will not reply with that icmp message because it has already reached there so traceroute sends to an unlikely udp port eventually get a no such port icmp message it knows that it has reached the end  refer slide time  46  41-46  46  so this is the reference about icmp messages actually these are not the only internet control message protocols but there are a number of others which we did not discuss we just discussed a few of them there are other protocols like dhcp  bootp  rarp  arp for example  they help in running the network in a better fashion arp protocol is a low level protocol then we have this rarp  bootp and dhcp for assigning a network this icmp helps in controlling the network operation and giving error messages then there is another side protocol which we will discuss in the next class namely igmp which is internet group management protocol so  that is another part of routing that we have not discussed as yet preview of the next lecture lecture ? 34 dns & directory good day  so today we will take up two topics and they are dns and directory first let us talk about dns  refer slide time  48  29-48  33   refer slide time  48  35-50  00  the dns is a short form for domain name system until now we have seen two kinds of addresses one is mac address or the so called hardware address and in case of ethernet they are also called ethernet addresses which is used in the data link layer for direct communication then we have seen ip addresses which are used for communication between two end points and these two end points may be anywhere in the network so ip address includes information used for routing and there is a network part and post part etc but unfortunately these ip addresses are tough for humans to remember you can remember only a small part of address which you basically require for your own configuration like your own ip address  address of your gateway  address of your mail server etc but beyond that if you have to remember ip addresses of other people it becomes very difficult for human beings to remember and of course they are impossible to guess humans find it much easier to remember and use the domain names domain names are what people use in surfing the web and for a www site sometimes you do not know the name exactly but you make out some guesses by some combination of .com or .net etc we not only can guess but it is much easier to remember we remember so many site names but now  what is the name ? it is used to map some particular machine or site therefore this is also some kind of an address so we have a third layer which are the domain names today we will see how we use these domain names and of course just as in the local area network you require mapping from ip addresses to mac addresses which is done by the arp protocol and in the reverse mac address to ip address done by rarp here you need a mechanism for mapping the domain names to ip address  refer slide time  51  51-52  36  we have discussed this  why not centralized dns > ? single point of failure  traffic volume  distant centralized database would not work  maintenance would be a problem  does not scale so it is distributed so  no server has the entire name to ip address mapping local name servers  each isp company has local name or the default name server and host query first goes to the local name server authoritative name server  for a host  towards that hosts ip address names can perform name address translation for that host name  refer side time  52  37-53  10  there are some root name servers which are   ? .centric   and some of the biggest name servers are in usa but of course it depends on what root it is and they could be distributed also  refer slide time  53  10-53  36  nslookup is an interactive resolver that allows the user to communicate directly with a dns server so  from the os you can use this nslookup and give a name query this is actually a name server look up and that is how the term nslookup comes nslookup is usually available on unix workstations   refer slide time  53  38-53  55  servers handle requests for their domain directly servers handle request for other domains by contacting remote dns servers servers cache external mappings  refer slide time  53  56-54  21  if a server has no clue about where to find the address for a hostname it asks the root server the root server will tell you what name server to contact a request may get forwarded a few times for example  if the iitkgp has a name server now the iitkgp has a name server and request for a particular domain name translation has come to it and it does not know to whom to connect the name server so it can always transfer it to the next higher level namely ernet and if the ernet also does not know where this ernet is there then it can contact the in in will definitely know all the sub domains under it in has to know because it is administering that domain similarly if it is for some address which is from outside you can send it directly to the root of that particular domain  suppose from india you are trying to contact something for japan then you can send it to the jp root name server and then jp root name server would know which name sever to contact so that will come back so this way the dns queries will go back and forth few times and finally the name will be resolved  refer slide time  55  30-56  39  now we come to ldap which is the lightweight directory access protocol since this was designed by the same people who has designed osi this x.500 actually tends to be a little complex it is heavy and it uses the all the seven osi layer for the internet purpose actually it uses the tcp ip stack rather than the seven layer osi layer stack there was a lightweight directory access protocol which can interoperate at least on one side so the ldap can use that x.500 directory service but this is much simpler than x.500 and ldap is used in many places these are lightweight directory access protocol it supports x.500 interface  it does not require the osi protocol it uses the tcp ip protocol so this is x.500 for the internet crowd it is useful as a generic addressing interface like netscape  address book and so on  refer slide time  56  41-56  57  the ldap or lightweight directory access protocol is a networking protocol for querying and modifying directory services running over tcp ip an ldap directory usually follows the same x.500 model which we have discussed  refer slide time  56  58-57  24  now it is a tree of entries  each of which consists of a set of named attributes with values an ldap directory often reflects various political geographic and or organizational boundaries depending on the model chosen when you do that you can also define your security policies based on this directory and based on these boundaries these are especially authentication services  refer slide time  57  33-57  40  so directory is a tree of directory entries an entry consists of a set of attributes an attribute values the attributes are defined in the schema  refer slide time  57  43-59  00  so this is the protocol stack for ldap suppose you have a directory based application or some authorization service or may be access to some information which may be there for the organization which uses ldap may use tls this tls is transport level security you can also use ssl here we are talking a lot about security in future we will give one lecture to security because this has become so important now  in an organizational context a directory may be an important component of the entire security arrangement security is a complex issue but anyway for this ldap we need to communicate securely in many cases and many ldap implementations support this tls the transport level security or you can use ssl or sasl also computers networks prof sujoy ghosh indtan institute of technology iit kharagpur lecture  34 dns & directory  refer slide time  00  42  good day today we will take up two topics  dns and directory first let us talk about dns  refer slide time  00  54-00  56  slide time  00  54-00  56 dns is the short form for domain name system  refer slide time  00  57-4  19  slide time  00  57-4  19 we have seen two kinds of addresses one kind is mac address or the so called hardware address in the case of ethernet it is also called as ethernet addressed which is used in the data link layer for direct communication then we have seen ip addresses used for communication between two end points the end points can be anywhere in the network so  ip address includes information used for routing ip is used for routing where there is a network part and post part etc but unfortunately  this ip address is tough for humans to remember we can remember only a few addresses that we really require for our own configuration  like our own ip address  address of gateway  address of mail server etc beyond that it is very difficult for human beings to remember ip addresses of other people they are impossible to guess what human beings find is  it much easier to remember and use the domain names domain names are used most of time by the people for surfing the web  www site name used for surfing   while surfing the web for a www site  sometimes you may not know the name exactly but you can make it out in 3 or 4 guesses  may be make some combination of .com  .net etc the most important thing here is that it is much easier for humans to remember site names the name is used to some particular machine  site etc this is also some kind of an address and we have the third layer namely the domain names we will see how we use these domain names just as in the local area network  you require a mapping from ip addresses to mac addresses done by the arp protocol and the reverse mac addresses to ip addresses using rarp you need a mechanism for mapping the domain names to ip addresses that is what this whole scheme of dns is all about may be sometimes we will look into the reverse query also  refer slide time  4  20-5  58  slide time  4  20-5  58  the domain name system is usually used to translate a host name into an ip address  domain names comprise a hierarchy so that names are unique  yet easy to remember it is important to remember that  if it is an address it needs to be unique in ip v4 we ran out of ip addresses because we had limited length here  we can go easily with the length because these are not to be used in high speed computations but may be used just once or twice in a session this means you can allow longer names  that is  rather than 4 bytes you can use many bytes but then this also has to be unique what people thought was  if we make a hierarchy of names which is a logical hierarchy which corresponds with the external world then not only they will be remembered easily but can be easily administered and we can make them unique so  domain names comprise a hierarchy so that names are unique yet easy to remember  refer slide time  5  59-6  48  slide time  5  59-6  48 this is what the hierarchy looks like there is a root and from the root we have the top level domain here we have edu  com  org and so on and finally these are for some nations under edu  we have mit  albany and all other kinds of organizations under in  there may be ernet and all that under mit  also there may be cs or something so there is a tree and a hierarchy this is sort of a global hierarchy and is the dns hierarchy  refer slide time  6  49-8  34  slide time  6  49-8  34  each host name is made up of a sequence of labels separated by periods o each label can be up to 63 characters long o the total name can be at most 255 characters so  you have up to 255 bytes to code these names so you can go easy on the length  examples  whitehouse.gov  .gov is for government and since it started in usa  it is us government and whitehouse.gov is a domain similarly let us say csc.iitkgp.ernet.in  .in is a top level domain standing for india and ernet is an organization which comes in the next level in in under ernet  there is iitkgp which comes in the next level and under iitkgp there is csc which again comes in the next layer so  starting from here you can go from the leaf of the tree right up to the root of the tree that is the dns hierarchy tree and  after giving a label at each level we put a dot and then go up to the next level this is how we name hosts  refer slide time  8  35-9  04  slide time  8  35-9  04  the domain name for a host is the sequence of labels that lead from the host to the top of the worldwide naming tree  a domain is a subtree of the worldwide naming tree so  mit is a domain  ernet is a domain and so on there is a subtree under ernet and there will be many sub domains so any domain is a subtree of the worldwide naming tree  refer slide time  9  05-9  25  slide time  9  05-9  25  a host has a domain name specified using a sequence of names  each of which may be up to 63 characters long  separated by periods  names are case sensitive  a domain is an absolute domain name or a fully qualified domain name  fqdn   if it ends with a period  refer slide time  9  26-10  41  slide time  9  26-10  41  most generic domains  .com  .edu  etc  are international  but there are some like .gov for government and .mil for military are us-specifications so when you say .gov  it actually means us government and .mil is for us military if you remember  the history of internet started in usa from the arpa net and it evolved at that time  it was very us centric but now the whole world has embraced it  new top level domains recently been proposed  though they are not very popular yet  countries each have a top level domain  2 letter domain name   for example  in for india  jp for japan  uk for uk and so on  a system is required to map the domain names to ip addresses just like we have arp for ip address to mac or rarp for mac to ip address  we need a system to map domain name to ip address that is the chief one and may be the reverse also  refer slide time  10  42 12  45  slide time  10  42 12  45 implementing dns   distributed database implemented in hierarchy of many name servers this is distributed because this is widely used and you can not have a centralized database centralized database will be much more difficult to administer  contribute to a single point of failure and the network traffic at that node will be tremendous you will not be able to handle the network traffic if everybody tries to login to the same central name server that will not scale and it needs to be distributed later on we will study the way it is distributed and the way it is administered what are distributed are the name servers  servers with gives you the mapping from the domain name system to the ip address    there is an application-layer protocol host  routers  name servers  which sort of all combine and communicate to resolve names  provide this address/name translation   o note  core internet function is implemented as application-layer protocol o complexity at network ? s ? edge ? so that at the network ? s core where the traffic is very high and very heavy this is not present if you had to do the domain name servers at the core routers then it will be of much strain on the routers so they have been put to the edge of the network  refer slide time  12  46-14  29  slide time  12  46-14  29 full resolver  for resolving we use resolvers  and there are full resolvers and stub resolvers  the client for this naming system is called resolver this is transparent to the user and is called by an application to resolve names into real ip-addresses or vice versa when you type a domain name in your browser  the browser is a client application program for http and so its calls the resolver to translate these domain names to corresponding ip addresses the browser will send the http request to the web server using that ip address so it gets it from the resolver  a full resolver is a program distinct from the user program  which forwards all queries to a name server for processing it knows about the name server  responses are cached by the name server for future use  and often by the name server the local full resolver in your host may connect to the local name server if the local names server does not have the resolution  it is going to contact other name servers and finally will get the resolution we will look into the details later  refer slide time  14  30-15  19  slide time  14  30-15  19 in this diagram  the user program gives a user query to the full resolver the full resolver gives this query to the name server this name server has its own database  so it may look up in its own database if it is not there then it may send the request to foreign name servers and finally it will give a response the full resolver also maintains a cache and it will cache this response so that if it gets another request to resolve the same name then it can find from the cache and give the response to the user name server also maintains its own cache  refer slide time  15  20-16  16  slide time  15  20-16  16  a stub resolver is a routine linked with the user program which forwards the queries to a name server for processing responses are cached by the name server but not usually by the resolver there are two differences between a stub resolver and a full resolver one is that  full resolver has a cache but stub resolver usually does not  and secondly  stub resolver has to be linked with the user program where as the full resolver runs by itself  on unix  the stub resolver is implemented by two library routines  gethostbyname   and gethostbyaddr   for converting host names to ip addresses and vice versa  refer slide time  16  17-16  34  slide time  16  17-16  34 stub resolver is a part of the user program which gets linked and this routine sends the query to the local name server and gets the response and passes it on naturally the user program gets it  refer slide time  16  35-20  04  slide time  16  35-20  04 dns organization  is a distributed organization  distributed database o the organization that owns a domain name is responsible for running dns server that can provide the mapping between hostnames within the domain to ip addresses o so some machine run by say an organization like rpi is responsible for everything below within the rpi.edu domain o there is one primary server for a domain  and typically a number of secondary severs containing replicated databases so  it is important to understand how this is organized this is a global system  which means this is very big so any effort to control this centrally would become quite difficult let us say csc.iitkgp.ernet.in is a domain now .in is a domain  which is for whole of india there is one specific organization  in india  which looks after this domain so whatever sub domains are there under this domain  it is the responsibility of that organization to keep track of who all can be given sub domains that is  who all can be given names within these sub domains.in also  any name resolution query coming from anywhere else in the world will direct their query first to this organization who is maintaining the domain .in also there are so many organizations maintaining their own sub domains under the domain .in either that organization will have it in its cache or it will forward the query to the particular domain suppose if it gives sub domain ernet  ernet again gives sub domains to iitkgp and again under iitkgp there may be many sub domains but ernet does not really bother about whatever sub domains are there under iitkgp it only has to know that iitkgp is an organization under ernet which has got a name and a separate domain it is for iitkgp to decide how it is going to break this domain into further sub domains or it may not break at all this way the entire domain administration is decentralized and it is easy  and also these names are some kind of addresses that has been made unique since the names are broken into names which stand for actual organization at any level  naturally any particular organization administering a domain will not have two organizations having the same sub domain name under it this way all the names automatically become distinct which is another good advantage  refer slide time  20  05-20  54  slide time  20  05-20  54 why not centralize dns ?  single point of failure  traffic volume  distant centralized database should not work  maintenance should be a problem  does not scale so new server so its distributed server  no server has all names to ip address mappings local name servers   each isp company has local name server  default name server   host dns query first goes to the local name server authoritative name server   sometimes we may come across something that has been given by authoritative server  for a host stores that hosts ip address  name  can perform name/address translation for that host ? s name  refer slide time  20  55-21  27  slide time  20  55-21  27 there are some root name servers the root name servers are actually still mostly us centric and have some of the biggest name servers so  root name servers are all in usa but of course that depends on what root it is and therefore they could also be distributed  refer slide time  21  28-21  54  slide time  21  28-21  54 nslookup   nslookup is an interactive resolver that allows the user to communicate directly with a dns server  from the os  you can use this nslookup and give a name query so this is actually name/server look up this is why it is called nslookup  nslookup is usually available on unix workstations  refer slide time  21  55-22  12  slide time  21  55-22  12  servers handle request for their domain directly  servers handle request for other domains by contacting remote dns server  s   servers cache external mappings  refer slide time  21  13-23  43  slide time  22  13-23  43 server operation   if a server has no clue about where to find the address for a hostname  it asks the root server  the root server will tell you what name server to contact  a request may get forwarded a few times let us say the iitkgp has a name server a request for a particular domain name translation has come to it it does not know to whom to connect the name server so it can always transfer it to the next higher level  namely  ernet if the ernet also does not know where in .in it is there  then it can contact in in will definitely know all the sub domains under it it has to know because it is administering that domain if it is for some address which is from outside you can send it directly to the root of that particular domain suppose from india you trying to contact something for japan  you can send it the jp root name server and then jp root name server would know which name server to contact dns queries will go back and forth few times and finally the name will be resolved  refer slide time  23  44-24  03  slide time  23  44-24  03 server ? server communication   if a server is asked to provide the mapping for a host outside it ? s domain  and the mapping is not in the server cache   o the server finds a name server for the target domain o the server asks the nameserver to provide the host name to ip translation  to find the right nameserver  once again it can use dns  refer slide time  24  04-25  20  slide time  24  04-25  20 recursion   a request can indicate that recursion is desired  this tells the server to find out the answer  possibly by contacting other servers   if recursion is not requested  the response may be a list of other name servers to contact so there are two versions of this dns server  the recursive server and iterative server if the recursion is requested and that is honored  suppose i am a name server  i will send the request to a name server whom i think may have a clue about how to do this request recursion now  he will make all the other contacts  the next level or may be another level contact as necessary and finally send me the answer so this is the recursive version in the iterative version what happens is that  he will simply give me a list of name servers to whom i can possibly contact directly to find out more then i make some more requests and finally get the name resolved  refer slide time  25  21-25  48  slide time  25  21-25  48 for example  host1 makes a request to the local names server then the local name server may send the request for recursion to another name server so  it will make the necessary request  get the response and then give the response  refer slide time  25  49-26  13  slide time  25  49-26  13 in the iterative case  it knew in one shot but it may not be in one shot when recursion is requested this may go deep down and finally find out and then send the request  refer slide time  26  14-26  37  slide time  26  14-26  37 whereas in the iterated queries  he gives a query and gets some list  he gives it to the next name server and gets some more response then finally he will get it and send it for you and then it will be resolved this is an iterated query  refer slide time  26  38-26  59  slide time  26  38-26  59 dns caching and updating of records   once  any  name server learns mapping  it caches mapping  cache entries timeout  disappear  after some time  update/notify mechanisms under design by ietf  how the cache is to be managed   refer slide time  27  00-27  46  slide time  27  00-27  46 we will not going into all the details  although they are given in the slide these are the so called resource records or rr the rr  resource records  have a format type = a where the name is hostname and value is ip address this is the most common one type = ns where name is domain and value is ip address of authoritative name server for this domain type = cname where name is an alias name for some canonical  the real  name and value is canonical type = mx is for mail server records  so these are the various resource records which are handled by the dns  refer slide time  27  27-28  02  slide time  27  27-28  02 this is the dns message format we have a header followed by some queries  followed by some resource records and some authority records if it is from alternative name server and may be some additional information this is the dns message format  refer slide time  28  03-28  18  slide time  28  03-28  18 we have in the message header  a 16-bit # for identification  16-bit # for query  and reply to query uses the same # and then we have a number of flags  refer slide time  28  19-28  44  slide time  28  19-28  44  qr flag identifying a query  0  or a response  1   op code is a 4-bit field specifying the kind of query  0 for standard query  query  ; 1 for inverse query  query   server status  status   other values are reserved for future use  refer slide time  28  45-29  10  slide time  28  45-29  10  aa  is authoritative answer that means this it is coming from an authoritative name server  tc  to see if the response has been truncated actually if it is truncated  it switches from udp to tcp  rd  recursion desired  ra  recursion available etc  rcode  is return code  refer slide time  29  11-30  19  slide time  29  11-30  19 both udp and tcp are used by name server   tcp for transfers of entire database to secondary servers  udp for lookups the lookups that we discussed about  usually use the udp protocol udp protocol is used as it is a very simple protocol with no extra over head but there is a limit to that udp and in response to udp you will just get one packet which is just 512 bytes  if the response requires more than 512 bytes  then the requester resubmits request using tcp if the message is truncated the flag is set and when the client sees the flag it opens a tcp connection with the corresponding name server and then resubmits the request so that it can get a longer request  refer slide time  30  20-30  46  slide time  30  20-30  46 we have already discussed the administration zones  a zone is a sub tree of the dns tree that is independently managed o second level domains  ernet.in  are usually an independent zone o most sub domains  iitkgp.ernet.in  are also independent independent means that what happens under this sub-domain is their business o eg  most universities have departmental domains that are then independently administered  refer slide time  30  47-32  24  slide time  30  47-32  24  a zone must provide multiple name servers this server records the members in the domain  you typically need a primary name server and one or more secondary name servers  secondary retrieves information from primary using a zone transfer  using a tcp connection the reason why the secondary name server is required is sometimes more than one secondary server is kept and the reason is that it is very vital for everybody suppose if you are administering a domain and you want to be independent then you can create extra sub domains under you where you have to maintain your own name server you can not maintain just one name sever but you have to maintain multiple name servers so that when the primary name server fails the secondary can immediately take over so  from time to time the primary will cache the data and from time to time or the database will be shifted to the secondary one so that they remain more or less in sync therefore as soon as primary goes down the secondary can start acting as a primary and be the authoritative name server for this particular domain there will be requests from other people to you for ip addresses in your domain and you are bound to give that that is the reason you need to have these different name servers and good network connection to handle all these requests  refer slide time  32  25-33  02  slide time  32  25-33  02 there is a reverse query which is sometimes used as a sort of weak protection against spoofing  set q = ptr i.e ptr is the reverse query for lookup so here what is done is that  an ip address is given and the domain name is found out just as we have arp and rarp similarly we have query and reverse query  refer slide time  33  03-33  42  slide time  33  03-33  42 reverse queries are used as a weak mechanism to avoid spoofing this is weak because those machines may have a name but if it connects to the network through a modem and is given a dynamic ip address then sometimes it may not get reflected so sendmail uses an identity message to identify the sender and receiver but this can easily be spoofed  refer slide time  33  43-35  18  slide time  33  43-35  18  some mail servers do not forward mail if you are not in the domain this is for anti-spam spams are mails which are spuriously generated mostly by programs/machines which are automatically generated and sent to millions of people it is estimated that the majority of the mails which go through are actually spam if the mail is not for my domain then i am not going to relay this to other mail servers sometimes you can do that but sometimes you have to relay because it is your responsibility to relay and does not accept mail if it can reverse query your ip address as soon as a mail comes it will find out from which ip address this mail has come from and send a reverse query by reverse query the name looks responsible may be it is coming from some known university etc then accept the mail if you can not reverse query it then maybe it is coming from some spurious source and it does not accept  this is not totally secure because hosts on same physical network can spoof ip headers of domains which are sort of respectable  but anyway this maybe of some use  refer slide time  35  19-35  35  slide time  35  19-35  35 who manages the in-addr arpa space ?  when you get a portion of the ip space you also become responsible for handling the in-addr.arpa queries for that space  this is why queries are in reverse order  refer slide time  35  36-35  57  slide time  35  36-35  57 dynamic dns   dns maps domain names to specific ip addresses o this requires that each domain name is statically assigned  since the zone table is typically stored on disk  this implies that a host using a dynamically assigned ip addresses means you connect to that host  refer slide time  35  58-36  34  slide time  35  58-36  34 this is what dynamic dns is for this is not widely implemented but there is an rfc for this and it uses a secure connection for doing a dynamic dns update you have to sort of update the name server database and anybody can not use this name server and so you have to use a secure connection to update the dns database  refer slide time  36  35-37  58  slide time  36  35-37  58 next  we take up the topic of directories this is similar to dns but more general actually the directories sometimes uses dns many of you have used mails and email clients where you have your own address book from where you can look up the email address of those who have sent you mails one example of a directory service could be some kind of a global address book where we can find the email address of anybody this was the original intention for creating the directory but of course people who produce spam mails have sort of killed this idea so nobody wants his email address to be in a directory which is universally available so that everybody can send junk mails anyway  directory can be used for many other purposes as well  refer slide time  37  59-38  48  slide time  37  59-38  48  what directories are ? o they are object repositories o typically read more than written o have explicit access protocols o support relatively complex queries dns queries are simple but it supports relatively complex queries for example  you can have something like give me the email addresses  assuming that email addresses are still available  of all people who live in delhi whose name contains ram etc you may be looking for somebody so you can have more complex queries than you have in a dns  refer slide time  38  49-39  03  slide time  38  49-39  03 but directories are not meant to be rdbmss  they are just for looking up so  lack notions of tabular views  join operations  stored procedures etc they are not regular rdbms but they are just for this particular service  refer slide time  39  04-39  41  slide time  39  04-39  41 x.500 was originally how directory was envisaged by the telecom industry  the goal was to have global white pages o lookup anyone anywhere o developed by telecom industry o iso standard for osi networks  idea was distributed directory o application uses distributed directory structure o application uses directory user agent to access a directory access point  refer slide time  39  42-39  53  slide time  39  42-39  53 the picture is something like this ; you have a directory user here who uses a directory user agent which in turn connects an access point to the directory  refer slide time  39  54-40  39  slide time  39  54-40  39  how is the name used ? o access resource given the name o build a name to find a resource o information about resource o these are the different uses of names  do only programs look at these names ? sometimes humans also need to use the names for constructing the names recalling names  is resource static ? o sometimes resource may move o change in location may change the name of a particular resource  performance requirements o human scale  refer slide time  40  40-41  12  slide time  40  40-41  12 directory information base which is defined in x.501 is given as a tree structure o root is the entire directory o levels are groups for ex  country  organization  individual  entry structure o unique name build from tree o attributes  type/value pairs o schema enforces type rules  there may be alias entries also  refer slide time  41  13-41  53  slide time  41  13-41  53 directory structure may look something like this you have these different levels  which starting from the top may represent some organizations and then some sub organizations and finally you have the objects now  in an object entry you will have some names and each of these names should have a series of type value pairs there may be more than one particular name ; it may have a number of attribute and each attribute will have a type/value pair this is the general structure of a x.501 tree structure  refer slide time  41  54-42  28  slide time  41  54-42  28  query is to this system defined in x.511 o query is a read  get selected attributes of an entry o compare does an entry match a set of attributes ? o list children of an entry o search  abandon request etc o these are all kinds of queries are possible  modification you can modify these records ? add  remove  modify entry o modify distinguished names etc  refer slide time  42  29-43  14  slide time  42  29-43  14  there is a directory system agent o it may have some local data o can forward request to other system agents o can process requests from user agents and other system agents so  these are like the name server system with dissolvers and also this is the system using directory system agents which can do the query processing it may get the data locally or it may forward the request to other systems  referrals  o if dsa can not handle the request it can make request to other dsa just as you can make iterative and recursive queries in dns o or tell dua to ask other dsa  this is the iterative process  refer slide time  43  15-44  14  slide time  43  15-44  14  directory information can be protected actually they are usually protected  there are two issues  o authentication defined in x.509 o access control defined in x.501  this directory by itself does not give you security so you have to have other components in order to ensure security but a directory can be used for some authentication services  some security purposes  etc directory can very well be used they are actually used that way  standards specify basic access control and individual dsa ? s can define their own access control they can specify to whom they are going to allow access to their local databases  refer slide time  44  15-44  59  slide time  44  15-44  59 replication  this is defined in x.525  single entries can be replicated to multiple dsas just like you have a primary name server and a number of secondary name servers  similarly you can have a directory in a primary or master and then you can have replication  two replication schemes  o cache copies  on demand o shadow copies  agreed in advance from time to time  there is a transfer  copy required to enforce access control o when entry sent  policy must be sent as well  modification is done at the master only  copy can be out of date o how to handle that is defined in x.525  refer slide time  45  00-45  30  slide time  45  00-45  30 there are a number of protocols which are defined in x.519  directory access protocol means the structure of the query and other things would be defined  directory system protocol o request/response between dsas  directory information shadowing protocol o dsa-dsa with shadowing agreement  directory operational binding management protocol there are a number of protocols  refer slide time  45  31-46  07  slide time  45  31-46  07  uses are of course for look-up o attributes  not just distinguished name o context  humans can construct likely names  browsing  yellow pages o aliases also may be given  search restriction/relaxation may be there  groups may be defined that means having a number of members who will be having they are own attributes  authentication information that may be contained in the directory and so on o directory may be used for various purposes  refer slide time  46  08-47  20  slide time  46  08-47  20 we will look at ldap  which is   the lightweight directory access protocol designed by the same people who designed osi x.500 it actually tends to be a little complex  it is heavy and intuits the osi all the seven layers now for the internet purpose which actually uses the tcp/ip stack rather than the seven layer osi stack there was a lightweight directory access protocol which can interoperate at least on one side  that ldap can use that x.500 directory service but this is much simpler than x.500 and ldap is used in many places  this is a lightweight directory access protocol o supports x.500 interface o doesn ? t require the osi protocol this uses the tcp/ip protocol o so this is x.500 for the internet crowd  useful as generic addressing interface  like netscape address book  etc  refer slide time  47  21-47  35  slide time  47  21-47  35  the ldap or lightweight directory access protocol is a networking protocol for querying and modifying directory services running over tcp/ip  an ldap directory usually follows the x.500 model  refer slide time  47  36-48  11  slide time  47  36-48  11  it is a tree of entries  each of which consists of a set named attributes with values  an ldap directory often reflects various political  geographic  and/or organizational boundaries depending on the model chosen when you do that you can also define your security policies based on this directory and based on this boundary  especially authentication service  refer slide time  48  12-48  21  slide time  48  12-48  21  a directory is a tree of directory entries  an entry consists of a set of attributes  an attribute values pair  the attributes are defined in the schema  refer slide time  48  22-49  58  slide time  48  22-49  58 this would be the protocol stack for ldap you have a directory based application  some authorization service or access to some information which may be there for the organization which uses ldap ldap may use tls  transport level security   actually you could use ssl also in future we will give one lecture to security because it has become so important now  in an organizational context  a directory may be an important component of the entire security arrangement security is the complex issue but for ldap we require that we communicate securely in many cases and many ldap implementations support this tls transport level security we can also use ssl or sasl and these uses tcp tcp sits on the ip which sits on the other layer etc so it comes in between the directory based application and the tcp layer this is where it stands in the protocol stack  refer slide time  49  59-50  50  slide time  49  59-50  50 this mentions some of the operations which are in ldap    bind  authenticate and specify ldap protocol version this actually starts the process  start tls  protect the connection with transport layer security to have a more secure connection since you are giving some access to information  you need to put some security feature in that so that is the start tls  search  search for and/or retrieve directory entries if you go through the access controls then you can search for some records  refer slide time  50  51-51  08  slide time  50  51-51  08  compare  test if a named entry contains a given attribute value  you can add a new entry  you can delete an entry  you can modify an entry these are various ldap operations  refer slide time  51  09-51  37  slide time  51  09-51  37  modify dn  move or rename an entry  abandon  abort a previous request  extended operation  generic operation used to define other operations  unbind  close the connection  not the inverse of bind but anyway this is to close the connection  so these are roughly some operations in lightweight directory access protocol  refer slide time  51  38-53  18  slide time  51  38-53  18 we will just touch on this security issue   notion of security for a network protocol is comprised of at least these axes   identity and authentication  o who are you and who says so ? so identify yourself and then it should have some protection against spoofing that somebody is claiming to identity which is false  confidentiality  whatever information is being passed around  other people should not be able to snoop into it so confidentiality is important you might use some kind encryption for this confidentiality purpose  integrity  did anyone muck with this data ? this means  did any one change the data ? if there is a change which has done by some person who is authorized to do that you might want to keep a log or audit trail for such changes otherwise you want to be sure that on the way somebody has not changed this data it may be necessary for some applications to maintain some signature kind of a thing to see that the data has not been changed  authorization  yes  you can do that  but no  you can not do that other thing this means there some organizations in access control user these identity  confidentiality  nativity and authorization kind of accesses are definitely there  refer slide time  53  19-53  44  slide time  53  19-53  44  one needs to separately consider each of the four security axes in the context of anticipated threats  also need to consider security from the perspectives of o the information stored in the directory  and o attributes of the requesters  data security is not equal to access security  refer slide time  53  45-55  06  slide time  53  45-55  06  some typical security features of ldap implementations   simple password based authentication  ssl on a particular port 636  ssl is secure socket layer and tls is transport layer security this is on port 389  there is some access control  there is some configurability there are other things that you can do with the directory especially in the context of an organization therefore because of spams and other issues the idea of actually generating a very global white pages for everything under sun  such a grand idea did not really work out but in the context of specific organization with its own security boundary and its own needs  ldap is a well defined is a protocol which can be used good day the topic for today is congestion control  refer slide time 55  07-56  18  slide time  55  07-56  18 the performance of computer networks on a large extent depends on the kind of congestion present in the network so  actually this is a large topic and we will just touch upon some aspects of them one thing we know by now is that  in general network namely data network or internet in particular  although multimedia and other content are coming in  first of all this is a packet based network and a large data network where we make only best effort of delivering a packet what exactly do you mean by best effort ? most of these best efforts have to do with how we handle the congestion ?  refer slide time 56  19-56  52  slide time  56  19-56  52 what is congestion ? when too many packets are pumped into the system congestions occurs leading into degradation of performance here you can give selective acknowledgement that you have got something in particular but have not got that issue  reno and new reno retransmit at most one lost packet per round-trip time selective acknowledgement  the receiver can acknowledge non continuous blocks of data which means sack selective acknowledgement of 0 to 1023  1024 to 2047 and so on  refer slide time 56  53-57  17  slide time  56  53-57  17  multiple blocks can be sent in a single segment  tcp sack  o enters fast recovery upon three duplicate acks o sender keeps track of sacks and infers if segments are lost sender retransmits the next segment from the list of segments that are deemed to be lost  like fast retransmit  refer slide time 57  18-58  22  slide time  57  18-58  22 many people have tried various kinds of heuristics to improve the performance of tcp there are two competing demands one is that we have to maximize the throughput and if you can maximize the throughput  naturally the overall delay  congestion will be small and at the same time you will get your job done faster but in order to push this maximum throughput we should not get into congestion or absolutely no congestion collapse so we try to guard against that these are the various versions or various flavors of tcp for doing that so  we are going to look at some topics associated with this congestion control and one is traffic engineering this means  can you shape or handle your traffic in a particular way so that congestion is less likely to occur  refer slide time 58  23-58  53  slide time  58  23-58  53 all these build to give quality of service in a network at routers  these may depend on packet classification and packet scheduling at network entrance it may have to do with traffic conditioning at routers or somewhere in the network you may do admission control between hosts and routers you may do signaling therefore these are the different components of qos network computers networks prof  sujoy ghosh indian institute of technology iit kharagpur lecture  5 multiplexing  sharing a medium   refer slide time  00  53  good day today we will talk about multiplexing  refer slide  00  56  1  08  multiplexing is about sharing a medium ; that means different users are sharing the same medium for communication at the same time  refer slide time  1  09  2  13  under the simplest condition  a medium can carry one signal at any moment because if there are two signals over there  they are going to interfere and then the signal will get garbled ; but for multiple signals to share one medium  the medium must somehow be divided  giving each signal a portion of the total bandwidth if you remember  a particular frequency range around one particular frequency is called bandwidth and this bandwidth is the most valuable resource so far as communication is concerned we try to use this bandwidth to facilitate the communication between a number of pairs of senders and receivers that is the idea of multiplexing there are various reasons we want to use multiplexing   refer slide time  2  15  3  20  and the chief one is that transmission service is very expensive ? leased line  packet switching networks  etc for example  laying of lines is in itself fairly expensive and a complex proposition and once you lay a line you like to utilize it to the maximum if you can use that for the maximum amount of communication  multiplexing and compression techniques are the techniques  which we use for this purpose ? it saves a lot of money for the business when you can send a lot of data through the same line  the data capacity of the line increases  it becomes more cost-effective for the company ; most data devices individually require modest amount of data but when there are a number of users  their requirements are aggregated together and the sum total may be of quite a substantial bandwidth  refer slide time  3  21  3  32  the current techniques that can accomplish this include  frequency division multiplexing  wavelength division multiplexing  time division multiplexing  and code division multiplexing we will look at some of these  at least  refer slide time  3  33  4  19  this is the scheme of multiplexing ; you have one multiplexer and then you have n inputs on one side these n inputs have come to the same multiplexer ; they are getting mixed up in some fashion and they are being sent over the same physical link and on the other side  depending on the fashion in which you have put them together  they have separated into different lines these different lines on the right can now go to different recipients so just as on the left we have different senders and we have different receivers  a number of sender ? receiver pairs are utilizing the same physical link in-between  refer slide time  4  20  5  01  the alternative to multiplexing should be direct point-to-point connection ; this has a number of problems the first problem is that you need those lines that we were talking about  you need lines for each device  and you need a large amount of wiring  if they are on different floors another important point is that you need a lot of i/o ports on the computer side  which really is not feasible you may have a few i/o ports  but you can not have hundreds of i/o ports  it ? s really difficult to have hundreds of i/o ports there that is also another bottleneck that we wish to address  refer slide time  5  02  5  22  another approach could be  a somewhat older approach  which is that of a multi-drop line the host polls machines to see who wants to send and then uses the same lines  saves i/o port ; the total communications load is not greater than the data rate of line  refer slide time  5  23  5  42  these are actually the simple approaches using a multiplexer approach  all the devices  their data is multiplexed on one side  sent through one line  and the number of lines in is equal to the number of lines out ; the link carries multiple channels of information  refer slide time  5  43  5  59  the types of multiplexer we have are  fdm  that is  frequency division multiplexing ; tdm  that is  time division multiplexing ; stdm  that is  statistical time division multiplexing we will look at these  refer slide time  6  0  6  26  just quickly before we get into the details of each of these  in time-division multiplexing  each user periodically gets the entire bandwidth that means the entire channel is dedicated to one user but only for a short period of time  for a small burst of time after that it is somebody else ? s time we will look at the details of this later  refer slide time  6  26  6  51  another common approach is the frequency division multiplexing ; here the frequency spectrum is divided among the logical channels here we have only one physical channel  but we want to have a number of logical channels  so the frequency spectrum of the channel is divided  each user has exclusive access to his channel  refer slide time  6  52  8  52  this fdm sends signals in several distinct frequency ranges  one of the oldest uses of frequency division multiplexing is in radio for example  we have this electromagnetic field in our atmosphere  let us say  through which electromagnetic radiation can pass electromagnetic radiation can be of very large range of bandwidth  the whole range of bandwidth is there out of that  the so-called radio frequencies constitute one part of it  a fairly important part of it this whole bandwidth of radio frequencies is divided into small channels and each channel is given to one particular station and on the receiver side  on the radio side  what we do is that we tune our radio  let us say  to one particular frequency  so that it receives signal from that particular station only ; although a number of stations are all transmitting at the same time this is an example of multiplexing another example of multiplexing  the same frequency division multiplexing  we see nowadays in the cable tv the cable tv providers give one cable  one coaxial cable to the premise connected to the tv that one coaxial cable apparently is carrying a number of channels  may be hundreds of channels these days what is done once again is that  all the frequencies  which can travel down this cable  are broken into a number of logical channels and each channel is dedicated to one particular station that is how we carry multiple video channels on a single cable  refer slide time  8  53  10  10  of course i mean point-to-point is out of question imagine the cost of stringing wire for each channel ; you ? ll have a hundred cables coming into your building which is not really possible each signal is modulated on to a different carrier frequency ; carrier frequencies are separated by guard bands this guard band is important because one particular channel  maybe a radio channel or a tv channel  the principle is the same everywhere so  that uses some middle frequency  maybe some range of frequencies the next station maybe a tv station or a radio station ? whatever it is  that can occupy ; first of all that has to be non-overlapping the range of frequencies which is assigned to the second station has to be non-overlapping with the range of frequencies which is given to the first station and not only that  between these two there must be some separation in frequencies otherwise what will happen is these two signals are going to interfere with each other so that is a guard band  refer slide time  10  11  10  17  the bandwidth of the transmission medium exceeds required bandwidth of all signals because of these guard bands which have to come in-between  refer slide time  10  18  11  02  usually for frequency division multiplexing  analog signaling is used to transmit signals broadcast radio and television  cable television and amps cellular phone system use frequency division multiplexing amps is an old cellular phone system that was there in usa nowadays of course  the kind of cellular technology that we have in our country uses more complex multiplexing techniques  maybe i ? ll mention that later on these systems all use frequency division multiplexing this technique is the oldest of the multiplexing techniques  refer slide time  11  03  11  22  assignment of non-overlapping frequency ranges to each user or signal on a medium ? all signals are transmitted at the same time  each using different frequencies a multiplexer accepts inputs and assigns frequencies to each device  refer slide time  11  21  12  07  the multiplexer is attached to a high-speed communications line because all these frequency bands on individual users are going to adapt to a fat range of frequencies the communication line must be able to handle this whole frequency range or in other words  the communication line has to be high speed a corresponding multiplexer or demultiplexer is on the end of the high-speed line and separates the multiplexed signals  because on the other end you have to separate them out since it involves analog signaling  it is more susceptible to noise thus we have seen that the analog signals are more susceptible to noise in digital signals we can sort of clean the noise more easily  refer slide time  12  08  12  52  this is a diagram if you note that for a particular user  suppose user 1  we give channel 1 ; along the time this channel 1 is entirely dedicated to user 1 for all time similarly channel 2  which is at a different frequency ? frequency is on this side and time is on this side ? once again user 2 gets to use this frequency for the whole time this is the simplest kind of scheme  so that for this whole frequency band  frequency is being divided  which is why it is called frequency division multiplexing  refer slide time  12  52  13  13  as was mentioned  the frequency channel is divided into logical channels ; each user hangs on to a particular frequency  the radio spectrum and a radio are examples of the media and the mechanism of extending information from the media  refer slide time  13  13  12  07  this is another picture of the same thing  see channel 1 and then channel 2  channel 3 ? they all send some signals if you plot them across the frequency versus the signal strength  you get a picture like this  so this is the first channel  this is the second channel and this is the third channel in-between this part here is the so-called guard band this frequency is not used by either of them there is some overlapping due to noise and other issues ; we will not get into that ; due to that this is what it looks like  the frequency bands are all separated  refer slide time  14  05  14  47  here is another diagram which shows  let ? s say you have the host and a 300 bps line ; a number of 300 bits per second lines are being multiplexed to 1200 bps line and then there are some guard bands  maybe 300 to 1013 hz is one and then 1433 to 2206 hz is another line ; maybe 2686 to 3400 hz is another line these are the 300 bps sub-channels and you have the guard bands in-between on the other side again you have this multiplexer ? demultiplexer  which takes it to different users  refer slide time  14  48  15  35  one problem with fdm is that it can not utilize the full capacity of the cable it is important that the frequency bands do not overlap so that is why you have to give the guard bands  so the full capacity of the cable is not utilized the other disadvantage ? we will summarize these advantages and disadvantages later on ? is that it is sort of bit more prone to noise because we are dealing with analog signals fdm is usually used to carry analog signals although modulated digital signals can also be sent using this technique  refer slide time  15  35  16  22  we have another type of multiplexing  which is wavelength division multiplexing wavelength division multiplexing is the same as the frequency division multiplexing only thing is that here the operating frequencies are much higher  actually they are in the optical range ; that is why somehow it is given different name like wavelength division multiplexing  you know different wavelengths means different frequencies if you are doing wavelength division it is same as doing frequency division and this is used in optical fibers this is the same as fdm but applied to fibers  refer slide time  16  23  17  08  there ? s a great potential for fibers since the bandwidth is very huge as i mentioned  the operating frequencies are very high  even a slight percentage diviation from the mean operating frequency gives you a very large bandwidth so you can sort of compact or pack a lot of channels at those high frequencies fibers have a large bandwidth capacity and with different energy bands are passed through a diffraction grating prism combined on the long distant link and then split at the destination this is got high reliability as well as high capacity  two very interesting properties  refer slide time  17  08  18  23  so multiplexing and demultiplexing for a wavelength division multiplexing is of course very simple if you take a prism  you know if you send a white light through a prism it breaks up into all the different colours  because the refractive index of the prism varies with the frequency so different frequency can come in  you can make the same light source also to say in this and on the other side you can use a prism to break it up of course i have shown a prism here for simplicity ; usually something like a diffraction grating is used so if you look at the fiber spectrum  if you plot the power versus the frequency so one fiber maybe giving at this frequency  another fiber maybe delivering power at this frequency if you put them together simply then you get this power versus ? or power versus ?  kind of plot that you get  refer slide time  18  24  19  37  wavelength division multiplexing multiplexes multiple data streams onto a single fiber optic line different wavelength lasers called ? s ; traditionally ? is used for denoting a wavelength  some are quite extensively used in this optical communication domain different frequencies are called different ? s and they transmit multiple signals each signal carried on the fiber can be transmitted at a different rate from the other signals this is one very interesting thing of fiber that is  different colours although they may get mixed but finally again they will be separated what rate of data  what protocol etc are they carrying ? the fiber system is really transparent to all that so that is a good thing ? different systems can be put to the same fiber as i mentioned that fiber have a very high capacity so you get to push in a lot of channels into the same fiber  refer slide time  19  39  21  09  dense wavelength division multiplexing also called dwdm they may combine as many as 30  40  50  60 or more channels these days into one fiber and each of these channels has a very high capacity ; so dwdm channel has a very high capacity and it is improving all the time people are finding ways of packing more ? s into the same fiber and it is supposed to be quite scalable into the future ; but of course if you want to pack those wavelengths in a very dense fashion  your equipment becomes somewhat costly a cheaper alternative which has come up recently which are called cwdm so dense wavelength division multiplexing is called dwdm  cheaper version is called coarse wavelength division multiplexing or cwdm in this cwdm the channels are more widely spaced on the spectrum multiplexer  demultiplexer  and all these costs go down and become cheaper alternatives but still you can push in a number of wavelengths into the same fiber now we come to the other very important multiplexing technique called time division multiplexing  refer slide time  21  10  22  10  as a matter of fact this is extensively used in our computer communication or telecommunication time division multiplexing is very extensively used especially on the service provider side ; we will look at these later on sharing of the signal is accomplished in time division multiplexing by dividing the available transmission time on a medium among users ; so time is being divided what is done is that  as i mentioned before  that each user gets a small burst of time in which at that time the entire channel and the entire bandwidth is at his disposal ; but as soon as that short duration of time is over  then it is somebody else ? s turn to send and this maybe in a round-robin fashion after some time it will come back to the original user  so that he can send his next burst of data or voice or whatever it is  refer slide time  22  12  22  40  usually we use digital signaling in time division multiplexing  almost always digital signaling is used almost exclusively time division multiplexing comes in two basic forms  one is synchronous time division multiplexing  the other is statistical or asynchronous time division multiplexing we will look at synchronous time division multiplexing first and because that is the simpler scheme and then you will look at statistical multiplexing  refer slide time  22  41  23  42  so the same multiplexing scheme now looks like this if this is the frequency  the same plot if you remember in the previous diagram when we were doing tdm we were slicing this channel in this fashion we are now slicing it in this fashion ; that means time is divided ; channel 1 channel 2  channel 3  channel 4  channel 5  channel 6 ; they get the entire frequency range for a small burst of time and suppose only 6 channels are being multiplexed  after 6 again it will be the turn of channel 1 so channel 1 sends the first burst of data etc using the entire frequency band during this time period and then during this time period during this time channel 1 is not sending anything so it is quiescent time is getting divided in this fashion  this is why this is called time division multiplexing  refer slide time  23  45  25  23  this is a schematic of a time division multiplexing system like fdm time division multiplexing saves money by allowing more than one telephone call to use a cable at the same time you have terminal 1  terminal 2 and terminal 3 terminal 1 is giving at this particular time then terminal 2 and this terminal 3 and over here on the other side this sequence and the way it goes that is known that has to be known ; so whatever signal comes at one particular slot ; this multiplexer knows that this must be for receiver number 1 and next slot is for receiver number 2 and next slot for receiver number 3 so on the receiver side  it just knows if it is this time slot  it is for a particular user this is a synchronous division multiplexing because this clock and this clock have to be synchronized otherwise  there will be a problem instead of dividing the cable frequency bands  tdm splits cable usage into time slots each channel is given a regular time slot in which to send a pcm signal  refer slide time  25  25  27  41  this is another view of the same time division multiplexing actually in actual practice  we will go into the details of this later on actually this time division multiplexing can be done in a hierarchy of manner we will look at this hierarchy later on if you remember from our digital signals discussion  that our voice  because it is up to say 4 khz is our voice signal  because of nyquist theorem  we require 8 kilo samples ; that means double the rate  that means 8,000 samples/second for capturing voice and for each sample  it has to be converted each sample is an analog value ; so that value has to be converted to a digital signal  an 8 bit digital signal  which is called pcm ? pulse coded modulation that means there are 256 different levels that this is distributing  which is very fine our amplitude of voice if you divide it into 256 parts we are making a very fine distinction ; that gives you 8 bits per sample 8,000 samples/second ; that comes to 64,000 bits per/second this is a very basic rate and this rate has got a name ; we will go to these names later on a number of such channels may be multiplexed together this 64,000 bits/second is a very basic rate a number of such channels may be grouped together to form one particular higher level channel and different higher lever channels may again join together to make a hierarchy of channels  this is what is shown over here  refer slide time  27  41  28  38  these t1 etc  don ? t bother about this figure at this moment because we will look at this later on so t1 is one particular rate at which some of these signals come there are world wide standards actually there are two standards  we will talk about it later on standards of the rate at which these signals come ; they sort of join together and form a stream of t2 stream and different t2 streams  different waves have different names like t1  t2  t3  etc  will form a t3 kind of frame and as you can see that the bandwidth is increasing all the time the t1 rate is 1.544 mb/second  refer slide time  28  38  32  10  time division multiplexing used for digital signals or analog signals carrying digital data  data rate of transmission media exceeds data rate of signals ; so this has to be there otherwise your tdm system will not work because in that small burst of time which is given to a particular user  in that burst of time that user should be able to send whatever digital data it had accumulated during that time  as well as the previous epoch during which it was quiescent ; because at that time it was other people ? s turn it may be a buffer or kind of thing where all these bits are getting accumulated and when it gets its small burst of time  during that burst of time it sends all the bits in that buffer  to make it empty and then it becomes quite again  so it will accumulate the bits again in the buffer and then again when it gets the next burst of time it will send all the bits thus data rate of transmission media has to exceed data rate of signals it uses a frame ; frame means a number of bits and bytes put together to form one particular unit at which to send it over ; one slot for each slice of time what would happen is that a slow device during his slot will send a lower number of bits ; very high-speed device will send a large number of bits  but your slot will come periodically one or more slots of each device is equal to channel and time slots are transmitted whether source has data or not this is one particular problem with time division multiplexing think about this ? that on the receiving side  receiver side is blind ; it does not know this stream of bits which has come is for whom the only way he knows that this is the time slot for receiver i  so he will send those bits to receiver i and so on in a round robin fashion what happens is  suppose the senders are s1  s2 to sn  receivers are also s1  s2 to sn ; and then we have this the si will be sending to ri ; what happens if si has nothing to send at that point of time ? during that time it is not possible for the multiplexer or the demultiplexer  in the normal scheme of things  to send somebody else maybe sj ? s signal during that time although physically it would be possible ; but then on the demultiplexing side it would cause a problem because the demultiplexer would not know whether this bit is for ri or rj that is why even if si has nothing to send  that slot will have to run empty ; you can not utilize it any further this is the weakness of time division multiplexing which we try to sort of address in a different scheme  we will be talking about just now  refer slide time  32  11  32  33  the synchronous time division multiplexing  remember that it is synchronous because the multiplexer and the demultiplexer has to agree about the slot of time ; the original time division multiplexing  the multiplexer accepts input from attached devices in a round robin fashion and transmit t1 and isdn telephone lines are common examples of synchronous time division multiplexing  refer slide time  32  34  33  01  if one device generates data at a faster rate than other devices  then the multiplexer must either sample the incoming data stream from that device more often than it samples the other devices or buffer the faster incoming stream if a device has nothing to transmit the multiplexer must still insert a piece of data from that device into the multiplexed stream  it may be a dummy data  refer slide time  33  02  34  08  before i talk about the other kind of tdm  which is the statistical time division multiplexing  i must mention that there are hybrid multiplexing schemes also that means in the hybrid scheme  what you do is that you take a frequency band ; it is like frequency division multiplexing  so you break up your entire available channels into a number of bands ; but each of the bands instead of in the pure fdm  we are giving it to only one user but this band is allotted to may be a number of users who use tdm on this band this is a combination of fdm and tdm  so such kind of hybrid multiplexing systems are quite widely used in these days and one good example is the cell phone communication that goes on ; that may use hybrid kind of multiplexing systems  refer slide time  34  10  34  21  in hybrid multiplexing system  both fdm and tdm may be combined ; the available channel is broken up into frequency bands ; in each band multiple channels are accommodated through tdm  refer slide time  34  22  36  38  now we talk about the other kind of time division multiplexing  namely  statistical multiplexing this is time division but on demand rather than fixed  so we reschedule link on a per packet basis and packets from different sources are interweaved on the link remember that i mentioned the disadvantage of time division multiplexing is that even if the sender does not have to send anything  that time slot will go empty we can not utilize it because otherwise on the demultiplexer side we will not be able to decipher who it is in the pure time division multiplexing this is to be addressed in statistical time division multiplexing or stdm ; what is done is that the packets are sent on demand ; that means if somebody has to send and the channel is free  it will be sent of course if everybody has to send  then you have to once again do some kind of scheduling in a round robin fashion in a simple vanilla case or you can do more fancy kind of scheduling i am not going into that so this utilizes the channel in a much more efficient manner ; but you have a problem we know what the problem is ? the problem is on the demultiplexer side on the demultiplexer side  one particular time slot being allotted to one particular sender or a receiver  that relationship is no longer there  and if that relationship is no longer there  how do we make out on the other side whether this is meant for whom ? so you have to have that address inside that data stream that means inside the data stream  there must be something which tells the receiver and the demultiplexer that this is meant for that receiver so you have to have the address  at least the destination address in the packet so to say  now i am calling it a packet that what ever the burst of data sent in a particular time slot  refer slide time  36  41  38  20  it allows connection of more nodes to the circuit than the capacity of the circuit how is this possible ? this is because usually our communication is always bursting  for example  when i am talking i may require 4 khz  when i am making a sound ; but then there are periods when i am quiescent that means i ? m not talking at all .so overall if i can utilize that  maybe my effective rate of utilization of the channel will become more than 4 khz ; because one user is using 4 khz and this way in each of the channels  the same thing happens and much more dramatically  in the world of sending and receiving data data traffic is inherently bursting  which means that one computer is communicating with other computer  this will do so in bursts it will want to send a lot of stuff ; suddenly it has something to send  so it will want to send it fast in a burst then for a long time it will be quiet  as there will be nothing because it will go there  maybe get processed over there  maybe some user sees it  sees that data  and things like that so it is quiet for a long time  then again it sends another burst and in-between these bursts there is a lot of time while the burst is there  i am using at a very high speed but then other people can share it  so that is why in some sense it allows connection of more nodes to the circuit than the capacity of the circuit  refer slide time  38  21  39  00  this works on the premise that not all nodes will transmit at full capacity at all times ; must transmit a terminal identification  as i said the destination identification has to be there ; and may require storage because two different sources may want to send at the same time and both of them land up hoping that the channel will be free i am calling it a multiplexer at this point  at the multiplexer end you have to store them and then forward them over the channels  and then the channel becomes available  refer slide time  39  01  39  56  this is a picture of once again getting multiplexed ? they are getting multiplexed as they come this is the queue in-between and you have this buffer over here  this is the memory where the incoming packets are getting stored and they are making a queue so there are a number of packets here and from this queue one by one as they come  it is not necessary that they have to go in a strict round robin fashion ; as they arrive they have are being pumped into this transmission channel on this side  on the demultiplexing side  it will look at some receiver address which is contained within this packet or cell  whatever it is  and then send it to the proper receiver  refer slide time  39  57  40  47  the buffer packets that are contending for the link  the packet queue may be processed first in and out  but as i said this is the most vanilla kind of scheme ; there are other fancy schemes for example you may have a high-priority queue for some of the users who may be paying more ? that queue is processed first before the other queues and all kinds of possibilities are there but of course since you have a buffer  it is theoretically possible and since your capacity of the link can not handle if all the senders decide to send at the same time  which may happen  in which case it will be filling it in the buffer  but the buffer may also overflow  which means that there is a congestion in the network and then some data loss is there  refer slide time  40  48  41  16  to summarize  a statistical multiplexer transmits only the data from active work stations if a work station is not active  no space is wasted on the multiplexed stream ; a statistical multiplexer accepts the incoming data streams and creates a frame containing only the data to be transmitted and also as i said this frame will also contain the some kind of destination address  refer slide time   41  16  45  41  this is an example to identify each piece of data and the address is included so the data of c as well as address of c  data of a as well as address of a ? the address also has to go with the data this of course is under the assumption that all these data packets and these addresses  together all these packet lengths are fixed  which is the case in some systems like atm  etc the size is fixed but the size may vary also  if the size varies then you will have to include the length of a also  that means this is the data of a ; what is the total length of a or maybe the data part  if this part is fixed depending on the scheme then the address to which this is destined all these are put in the form of a frame and then it is sent finally i would like to summarize the advantages and disadvantages of each of the schemes by the way  in the beginning i mentioned something called code division multiplexing  which is a very interesting scheme we will talk about code division multiplexing when we talk about multiple access there are actually two terms ; one is multiplexing and the other is multiple access usually this is how we mean it but distinction is getting blurred these days ; usually when you are multiplexing  the sources are sort of converged to the multiplexer in some sense the sources are converged to the multiplexer in some sense and it goes to the demultiplexer where it diverges there is a specific convergence which is there  that means a number of telephone lines are getting multiplexed ; a number of telephone lines will come to the local telephone exchange there these may be all destined for some other exchange  so all these lines will be multiplexed together so they are happening physically in one place if the problem is this  then once again you have a shared medium but the users are distributed in that case we call it a multiple access system cdma is a multiple access system as well as you can in some sense call it a multiplexing system also as i said this distinction is slowly getting blurred these days ; for example  you are doing some kind of multiplexing when you come to cell phones we are doing some hybrid kind of multiplexing ; that means we have got a combination of fdm and tdm ; i.e  we have some bands of frequencies which are being used by a number of users ; but these users are not at the same place they are carrying some wireless station that means they are carrying their mobile handsets and are at various locations even for the same base station  under the same base station  they are at various locations in that area so to say thus the distinction between multiplexing and multiple access is getting a little blurred these days anyway we will discuss code division multiplexing or multiple access when we talk about other kinds of multiple access as you can guess  there is time division multiple access and then there is frequency division multiple access and then of course this code division multiple access is also there ; so we will discuss it there  refer slide time  45  43  48  20  coming back to the scheme that we discussed  namely  fdm  what are the advantages and good things about each of these schemes ? fdm is of course simple and being simple means that it is cheap and is very popular  and as i mentioned this is the oldest multiplexing technique your radio uses this and lots of other systems use this tdm is specifically for digital signals  so for digital signals tdm is very nice and then you can have a multiplexing hierarchy ; that is another advantage of tdm why it is an advantage ? well the advantage is because of this  at different places we may require different levels of bandwidth and speed just think about this ? suppose we have this telephone network  you may have a small exchange ; the small exchange will naturally have a small number of users and only a few of those users will want to communicate or make an std call or to communicate with some other telephone  which is under some other exchange so the few will have to be multiplexed together at the small exchange and it will be sent to the trunk exchange and from there it may go to another trunk exchange and so on and finally reach at the trunk exchange what is happening is that once again various such connections from different local exchanges are coming and converging to the same trunk exchange when this trunk exchange is communicating with another big trunk exchange  what is happening is that there are a lot of tributaries flowing into it  there are a lot of channels so basically in the same signal  we are doing time division multiplexing that means the rate at which the receiver at this end is sending  that same rate has to be maintained throughout ; but then instead of flowing in small tributaries  it is moved into a very fat channel we require a multiplexing hierarchy so such multiplexing hierarchies are easy to implement using time division multiplexing ; we will see more of this when we talk about synchronous digital hierarchy later on  refer slide time  48  21  50  47  stdm ? s advantages  we are only talking about advantages we will talk about disadvantages later on in statistical time division multiplexing  this has certainly more efficient bandwidth use it is much more efficient because as i mentioned  that specially data usage and usage in general may be very bursty and if it is bursty  then during the quiescent period  ordinary tdm is just wasting the channel whereas stdm is making full use of it so it has more efficient bandwidth use ; that is a good thing about stdm another advantage of stdm is that the frame can contain control information ; since you are putting a frame  may be with the address of the receiver or may be other kinds of control information can be put in the frame and then  the packets can be of varying sizes these are the advantages of stdm ; not all stdm systems will allow this varying sizes ; for example  atm will not allow varying size cells in atm  the packets are called cells  they will have a fixed size but some systems may allow wdm  we are writing it separately because although as i said this is some form of fdm  this works with a very high capacity  is scalable  and this has got low noise sensitivity that is another good thing about the communication in the optical domain suppose you are doing it in a electrical domain through a wire  may be  if there is some kind of electrical noise  somewhere some motor has started or very bad if there is some lightning somewhere nearby  lot of noise will get into it and this electrical wire will catch all this noise whereas an optical fiber is not going to catch any of these noises  it is very immune to noise  which is why it ? s got a very low noise sensitivity  which is very good and very high capacity and you can scale it to still higher capacity using dwdm  refer slide time  50  48  51  20  just a quick look at the disadvantages  fdm  as i mentioned earlier  is susceptible to noise  wasted bandwidth  because of this guard band  etc  and of course one frequency is whatever the small band is being permanently given to one user and if his usage is very bursty  then a lot of bandwidth is wasted then  we have a limited frequency range in tdm we have wasted bandwidth for the same reason  refer slide time  51  21  52  06  stdm takes care of that problem in a tdm but this is very expensive ; traditionally we did not have any other alternative so we used stdm a lot when high speed was necessary especially in the service provider side  we used stdm wdm is somewhat more costly than tdm and fdm but since this is a developing technology  this cost is coming down and that means the wdm cost is coming down but it is still somewhat more costly than tdm and fdm but may be less costly than stdm we have looked at the different multiplexing techniques today ; in the next lecture we will look at one kind of network  which is very widely used for data and all kinds of communication  namely  the telecom network  the telecommunication network because remember that although it is called telecommunication network and it was traditionally for people talking over telephones  for voice  etc  that is the network which carries most of the wide area data traffic today  and that is a very important we will talk about it in the next lecture preview of next lecture computers networks prof  sujoy ghosh indian institute of technology iit kharagpur lecture  6 telecom networks  refer slide time  52  52  today we will talk about telecom networks  means the kind of network that is used by telephones and of course it is by host of other things as we will discuss this telecom network is very important in the sense that first of all  it is one of the earliest network that we had and that is one thing that is quite old and secondly  the telecom network even today is mostly used for a wide area communication comparatively  we have much fewer  i mean entirely or exclusive data networks we will look at the evolution of telecom networks  refer slide time  53  54-55  29  well when alexander graham bell developed the first telephone  it was a couple of telephone instruments connected by wire now if you are trying to connect more than one people that means more than one subscribers are there ; taking this principle forward you will have to connect everybody to everybody else through a wire which of course becomes very unwieldy very soon ; because connecting or stringing a wire between every pair of telephones  that might want to communicate was not a good long term strategy at all as you can see that very soon we ? ll have veritable jungle of wires and of course its costly and it is very difficult to manage at the subscriber end you can not handle so many wires coming into your premise  so better idea was to connect all the telephones to a central switching office there an operator could connect one telephone to another via switchboard that is the next figure  you see that the number of wires have come down as a matter of fact in the figure at the top if you have n subscribers  naturally you have n  n -1  / 2 links which is approximately n2 kind of links whereas in the latter case you have only n links so the number of links as n becomes large  and you know today there are so many telephone subscribers so there is no question of connecting them individually  you have to connect them to a central switching office  refer slide time  55  46-56  59  even then once  again i mentioned this earlier in the lecturer  you must remember that it is not that we have a whole parallel network for data from computers etc all over the globe  it is not there the telecom network has been around for a long time it had a long and very excellent history so that is why even today most of the wide area network traffic still rides on this telecom network originally it might have been a packet then it might be sort of made into some kind of a session for which there is some part of the connection is dedicated and all kinds of technology has come in but even today most of the wide area networks are based on the telecom networks and telecom  that is one side of the story  the other side of the story is that telecom networks the telecom people are actually in the process of routing some of the voice calls and may be some of the other kinds of calls into this packet kind of technology  refer slide time  57  00-57  22  so dsl at subscriber end voice traffic is transmitted as standard analog telephony signals ; data traffic is transmitted over the same line via a dsl modem that transmits the data as high frequency digital broadband signals on the same line if you have dsl modem you can have both your voice as well as data at the same time  unlike very ordinary analog lines  refer slide time  57  23-57  35  so dsl at the central office end  co end  and the signal passes through a splitter as i have shown and a local loop management system the subscriber line access multiplexer is there in this figure  refer slide time  57  36-57  39  we have already seen  refer slide time  57  40-57  43  in this figure  we have dslam and the loop management over there   refer slide time  57  44-57  59  the broadband digital signals are directed to a dslam that terminates and coordinates traffic from multiple local loop lines from the dslam  the traffic is sent to a router and then to the internet and finally we have the loop management system   refer slide time  58  02-58  24  which may be in front of the splitter  or behind the splitter this comes to various functions like giving the connections and testing and all this service kind of testing are done through the local loop management thank you computer networks prof  sujoy ghosh department of computer science and engineering iit  kharagpur lecture # 10  refer start time 00  43  good day so ttoday  we will be speaking about  noise  fiber optic  noise  components  refer slide time  00  53 ? 00  56 min  and fiber optic communication as might of heard tthis lecture as well as the next couple of lectures will concentrate on fiber optic components we have looked at some of the physical  noise  layer components of  noise  fiber optic systems before  so we will quickly review that that so ssome of  noise  the stuff we will be talking about today is going to be common and then  from that point  we will take out take up wdm systems  details of how wavelength division multiplexing is done and how systems are  noise  handled in fiber optic domain tthe fiber optic domain happens to be very crucial because  noise  a lot of  noise  traffic in terms of volume  okmay be as much as forty to fifty percent 40 ? 50 %  actually follows  noise  goes through the fiber as days are going by and as more and more demand for bandwidth  noise  is coming up  fiber optics is becoming more and more important  noisesso we will be talking about fiber optic components today  noise   refer slide time  02  05  02  39 min  sso in fiber optic component  of course  the basic fiber is there ; we have already talked about it  so we will talk little bit more about this then we have light sources and receivers on twotwo ends because we know that in fiber optic  noise  cables  light is the carrier of information then we require these different components like amplifiers  couplers  modulators  multiplexers and switches sso we will look at these components one by one and tthen we will start our discussion on wavelength division multiplexing  noise   refer slide time  02  40 ? 03  34 min  sso optical fiber as was mentioned earlier is very pure and very transparent silica glass is used so aat a moderate dimension  the light is restricted to the fiber because of total internal reflection for ordinary light ; this is a multimode fiber ok mmf mmf is used in lans lans for low speeds or short distances so mmf mmf may be used in lans lans ; that is another kind of fiber bbut the multimode fiber happens to be the cheaper variety and this is used in lan lans  but this is good only for low speed wwhen ii say low speed ii mean comparatively low speed  ok for this say hundred mbps 100 mbps or hundred and fifty five mbps 155 mbps may be a low speed and by short distances may be couple of kilometers at  noise  the maximum  refer slide time  03  34  03  51 min  at a still smaller dimension  that part of the fiber that actually carries the signal ? if you remember our discussion about  the fibers in physical layer  we have shown some diagrams regarding the cross section of a fiber  so at the very core ? is a very thin strand of glass fiber tthis is surrounded by a cladding which is also made of glass ; actually we will not be able to see the actual part of the fiber  which is carrying the signal tthe surrounding is also made of glass and that is again coated or covered etc  by outer protection so if that strand happens to be even smaller  say 8 to 10 nanometer range  tthen it acts like a wave guide and a single mode of operations  refer slide time  04  39  05  10 min  wwe will not go in details of eelectro mmagnetics and wave guide propagation of optics to this fiber  but any ways  the support of the single mode of propagation is called single mode fiber smf is used for higher speed  so all these speeds of 2.5 gb/sec or 10 gb/sec etc  are possible on single mode fiber and it also goes over longer distance ok and nowadays  we have fibers which span across oceans we have fiber from one continent to another  which is really a marvel of engineering and technology  refer slide time  05  31  05  50 min  so these fibers are actually single mode fibers there are a few transmission windows like 1310 and 1550 nm bandwidth etc fifteen fifty nanometer 1550 nm window is preferred for long haul applications because it has less attenuation  wider window  and we can get very easily get good optical amplifiers in this range  refer slide time  05  50  06  30 min  so t,this is the diagram you have seen before  so you will see that at around fifteen fifty nanometer1550 nm range  we have some the  noise  kind of low attenuation  noise  ssimilarly,thirteen ten 1310 nm  noise  nanometeris another window  but this window is quite wide although it may not look very wide in this diagram  in actual practice  this is quite wide so this is the wider window and we get good optical amplifiers we will come back to this point when we discuss optical amplifiers  refer slide time  06  38  07  37 min  why do we require optical amplifiers  because there are losses in fiber,losses in fiber may be due to various reasons  one  of course  the main thing is absorption that is what we showed in the previous diagram ; it loses energy to the atom and absorbs some of the photons so we get lower magnitude or lower strength of the light signal  as we go to longer and longer distances then there is scattering of photons by the medium so there is rayleigh scattering  due to slight changes in the refractive index of glass ; then there is mie scattering due to imperfection of the cylindrical structure  it ? s made to rigorous specification  but it ? s never exact in the engineering world ? it can never be exact so we get all these different types of scattering  absorption  etc  leading to losses in fiber  refer slide time  07  39  07  53 min  apart from these just lowering of signal strength  one problem is that the losses are in nonuniform for different wavelengths ok that means that tthe  noise  loss may be more for one particular frequency and may be less for another particular another frequency the trouble is  when you take a waveform  specially a digital waveform  which is a square waveform and if you analyse it  you will get a lot of spectral component iif you do a fuller transformation on that  you will get the different harmonics or components of that particular wave shape and the and these for that for the perfect square shape to come up  these different harmonics have to be at specific strengths compared to each other ddue to differential losses at different frequencies  what would happen is that their balance would get disturbed what you will actually see is that your pulse shape has changed  refer slide time  08  54 ? 09  23 min  this is known as chromatic dispersion ? chromatic because it depends on the wavelength or frequency  or the color of the light that is why it ? s called chromatic different spectral components of pulse travel at different velocities  noise  tthis is another problem and there is something called group velocity dispersion so wwe get some kind of velocity for all these different components and this leads to some kind of dispersion  noise   refer slide time  09  24 ? 09  46 min  so this is an example of chromatic pulse ? we need not go into the details of this  but this is the input pulse whereas in the output pulse  it has a much more flattened shape because these different components have been attenuated differently as they went along the fiber for compensating these dispersions  nowadays some special types of fibers have come up ; we can not go into details of these ? one is the reduced dispersion fiber by dispersion shifted fibers we mean the natural dispersion is that is sort of acted on nonzero dispersion shifted fibers anyway  the point is that normal smf is there in most of the places  say  more than ninety five percent95 % of the deployed plant dispersion is measured in pico second per nanometer kilometer ; so dispersion is much lower for some of the interesting areas or the window  we get an almost zero dispersion for these fibers so we can get very special fiber these days  which may be utilized for very long haul applications  where dispersion becomes a problem by the way  for short haul applications  when you are travel through a few kilometers  then the dispersion is not much of a problem and we need not bother about dispersion shifted characteristics of the fiber because in ordinary fiber  whatever the dispersion it gives in that small distance  will not matter so much  refer slide time  11  20  11  25 min  we have a bandwidth span product ; that means  how much bandwidth for what kind of distance this is very common in almost all kinds of transmission lines ok  noise  sso a transmission line  which operates at a particular speed quite well for some distance  will not operate that well if you either increase the rate at which you are pumping in the data  increase the frequency  or if you keep the data rate constant and increase the length that would also not work very well sso for any kind of medium  we get the bandwidth distance product  which tends to be more or less sort of constant so aa fiber which is good for at a particular speed for lets 2 kilometers may be just good enough for 1 km when you double the data rate  refer slide time  12  25  13  26 min  for older kind of smf at 1310 nm  we get high speed ? mean these are some typical figures  they are not exact figures ; these are some typical figures to get some ideas sso we can operate at two point five giga 2.5 gbits/sec for six forty kilometers640 kms without amplification  or 10 gb/sec for  let ? s say  100 kms a decent smf can take up to two point five giga bits per second 2.5 gb/sec for four thousand four hundred kilometers 4400 kms,ok which spans from one continent to another or ten giga bits per second 10 gb/sec for five hundred kilometers 500 kms of course  you should multiply these figures for dwdm dwdm we will talk about wdm presently  where it gives you a large number of channels  may be forty 40 channels so you can see that you can realize really tremendous data rate  very very high data rate  using this fiber optic communication and that is the major advantage of fiber tthere are  of course  other advantages like have i mean you are not susceptible to electromagnetic radiations ; that is one good thing because nowadays with so many gadgets all around and so many things moving around  we get all kinds of very noisy electromagnetic ambience ; but  noise  i mean fiber is immune to all that that s that is the good point about fiber  refer slide ime  13  59  4  46 min  next  from fiber  we come to light source that is the led light source is of course of two types  depending on whether we are using multi mode fiber or single mode fiber usually  we would use ordinary light in a multi mode fiber and the source of the ordinary light would be led one good thing about the led led is of course that it is very cheap sso the good thing about multi mode fiber is that it is cheap ; the only thing is that it will not scale up very well with that bandwidth distance product an led led is just a forward biased pn-junction ; what happens is that recombination of injected minority carriers by spontaneous emission produces light and it is a broad spectrum up to gain bandwidth of the medium ; so that is an led  refer slide time  14  47  15  42 min  it is usually of a low power ok power you remember that for power you have to divide it by time although you might get a continuous source of light  it will be comparatively low power like twenty d b m 20 dbm  of low internal modulation so you can modulate it if you internally modulate it you can modulate it at best of with hundreds of mega bits/sec  per second which of course  for some applications  may be more than enough speed but then again  when you are talking about the core of wide area network  then it may not it may be it will is a very low speed so obviously in the core of a wide area network  we will not be using multimode fibers or leds led slicing is led plus a filter iit gives some power loss ; we need not bother about that at the moment  refer slide time  15  43  15  50 min  the other kind of light source  which is very important  is the laser ; ok of course  we use semiconductor lasers here almost always it gives a high i mean much higher power output so in a short duration of time we get quite intense pulses of light that is very good ; it has a high power output ; it has got a sharp spectrum ; that is it is coherent ; that is  it is not at the wide range of spectrum  refer slide time  16  12  16  42 min  so it is sharp spectrum  that is the property of a laser that reduces the chromatic dispersion it can be modulated either internally or externally  so that is also a good point it is good for longer distances and larger bit rates compared to mlm mnf  refer slide time  16  43  17  45 min  mlm we need not bother about mlm we have some special kind of devices  the tunable lasers tunable lasers means a laser  but we can change the color of light over a certain range and as we will see later  the tunable laser may be quite important in some cases we will see what kind of time we require for tuning ; it ? s fairly rapid in the sense that it is in less than milliseconds ? range in the order of milliseconds  we can change the frequency emitted by the lasing system it has a wide and continuous range of over hundred nanometer 100 nm ; has a long lifetime and is stable over lifetime ; and it is easily controllable and manufacturable these are the good points about the tunable lasers  refer slide time  17  46  18  21 min  the methods could be eelectro optical ; changing the refractive index by injecting the current or applying an electromagnetic field sso that is one way ; it could be temperature tuning although it is not much preferred first of all its range is narrow and then it may degrade the lifetime of a laser if you want to do it through temperature ; or mechanical tuning using mems mems this is compact but one problem of this tunable laser is that it is costly ; it is quite costly and that is why this is not very common ; also  it is slightly more complex to manage but in some instances  it gives some advantages we will mention this point later on when we discuss wdm wdm  refer slide time  18  43  19  20 min  then wwe come to receivers ? are of course the light pulse coming will have to be detected by something  whether a pulse has come or whether the pulse has not come  whether it ? s one 1 or a zero 0 sso if an photon comes  it will sort of push up an electron to a conduction band sso that is the standard photo detector  which you must have studied at school so if it is sort of higher than this gap  this energy gap  then we get the electron in the conduction band  which will naturally show up by conducting ; so that is the easiest thing  refer slide time  19  21  21  03 min  i was mentioning that nowadays we have fibers running for thousands of kilometers sso if we have such long haul fibers  what would happen is that naturally  after some distance  what you have to do is that your signal will become weak  so you have to amplify this previously this distance would be something of the order of four five kilometers 4 ? 5kms ok nnowadays twenty five kilometers 5 kms is very common  you can go hundreds  or in special cases  you can go even up to many hundreds of kilometers ; you can go without amplification but whatever it is  after some distance if  because of this loss  absorption  dispersion  etc  you will have to amplify the signal for optical signals traveling long distance through fiber  it needs to be strengthened this may be done through olt olt  which was the older technology in olt  what was done was that  the optical signal was converted back to the electronic domain and then you amplify the signal and then push it back to the optical domain obviously this has quite a number of disadvantages  main disadvantage being cost and the speed ; that means cost is higher and speed is lower that has some advantages also i will mention it later ; this may be done in optical domain the idea was the that  it could be done in optical domain through erbium doped fiber amplifiers there are other kinds of dopers that i will mention ; we will see that  refer slide time  21  04  21  27 min  so this is the scenario ? we have this light propagating and as it propagates with distance  the signal level comes down when it comes down to minimum operating level  at that point  we will have an amplifier that will amplify the signal back ; and then again  after sometime  it will sort of decay and then we again amplify so these are some kind of repeaters  refer slide time  21  28  23  33 min  we come to one point where simple amplification is not always enough ; sometimes we require regeneration these are the so-called 3rs  reamplify  reshape and retime as far as absorption is concerned  if you simply amplify  that means increase the size  the strength of the signal is good enough so the absorption loss or the loss of strength can be handled that way but when you talk about very long distances  due to chromatic dispersion  etc  wave shape will become distorted as we have seen in very long distance  on the other side there will be tremendous amount of errors that may not be acceptable so we have to get a wave into shape now there are some special kinds of fibers ; try to do it in optical domain but more commonly they are deployed today to bring them to electronic domain and then give them the right square shape once again so that is the second r ; and the third r is the timing ; that means how do you keep all the clocks synchronized because  after all  some tdm signals  etc  are traveling ; so you will have to have a very strict control over the time so these reamplify  reshape  and retime  are the 3 r kind of regeneration sometimes we only do with two r 2 rs or simply one r 1 r  which is simply reamplify  which can be done simply with an edfa  that is  the erbium doped fiber amplifiers ; and at certain distances  we simply reamplify this  refer slide time  23  34  24  32 min  if you want to do some reshaping  suppose this is the input shape  which has come this goes through the oe transformation  the optical domain  and we come to the electronic domain we amplify this ; shape this properly ; and then again push it back from the electronic domain to the optical domain so we again get a nicely shaped pulse and the output  which has been strengthened as well as reshaped the problem of this is that  naturally  we can do the reshaping as well as amplification at the same time but one problem that we face in this case is that the cost is high ; and the other problem is that optics inherently can operate at a very high speed but we can get fairly high-speed electronics also but it becomes more and more difficult in the electronic domain as the speed becomes higher and higher and when that happens we would like to do it in optical domain if we could and there are a number of schemes today for handling this in the optical domain for example  we can have some very specially shaped optical waves  whose shape will not change over a distance they are called solitons ; they are sort of done in a way that different spectral components are mixed in such a manner that after dispersion  they cancel out each other similarly there are fibers which give the dispersion in the opposite direction to the standard fiber so that it can be brought back to shape so these are all the atoms to handle this reshaping in the optical domain  but the most widely deployed system as of today is to take it to the electronic domain and do it there  refer slide time  25  51  26  57 min  regenerators are specific bit rate  so that is another problem with the electronic domain it is an opaque unit ; that means it has specific bit rate and modulation format that is used ; whereas optical amplifiers  in optical domain what ever is coming is being amplified so it is transparent to the bit rate  the modulation format  the protocol  etc ; it is transparent to all that whatever is coming  is simply amplifying so that is the good thing about optical amplifiers the system with optical amplifiers can be more easily upgraded to higher bit rate  without replacing the amplifiers if you are going to use the same infrastructure for higher bit rate as service providers often want to do  in that case  if you are taking it to the electronic domain  you have to replace optical amplifiers have large gain bandwidth ; they are also key enablers of dense wavelength division multiplexing  refer slide time  26  58  27  31 min  one of the standard kinds of fiber amplifiers  which is very widely deployed  is the erbium doped fiber amplification ? we have talked about this earlier erbium has a large number of excited states and from some of the excited states  it gives out this 1550 nm light  exactly the wavelength used in the third window a few meters of optical fiber doped with a few parts per million of erbium is pumped with 1480 or 980 nm laser to give amplification  refer slide time  27  32  27  46 min  so edfas amplify all lambdas in the 1550 window simultaneously so key performance parameters include saturation output power  noise figure  gain flatness  pass band  etc  refer slide time  27  47  28  23 min  we have input signal coming through regular fiber and this is the part which is erbium doped and you pump some laser so these are combined using some kind of couplers ; i will be talking about couplers later on because of the pumping laser  the erbium ions become excited and when the incoming signal hits these  they fall back to the ground state may be emitting more photons  so the signal is amplified  refer slide time  28  24  29  11 min  there is another kind of amplifier called raman amplifier  which uses longer lengths of fiber this has other advantages  basically using raman scattering  so we are not going to the details of this once again it has pumping through some kind of pump and signal this pump may be in the same direction as the signal is going or it may be counter pumped in the other direction ; the whole point is that  this pump keeps the atoms excited and  due to raman scattering  so more and more photons come out  so we get an amplified signal finally  refer slide time  29  12  29  45 min  we have other kinds of dopants also  erbium doped for 1550 nm range  praseodymium doped fluoride fiber  pdffa  for 1310 nm  thorium doped for 1350 ? 1450 nm  thulium doped ? well  this is somewhat more academic  because thulium is considered as a rare material ; it is not easily available and even if it is available  it is quite costly anyway this is in the 1450 ? 1530 nm range   refer slide time  29  46  30  03 min  tellerium erbium doped fibers in 1532 ? 1608 nm range raman amplifiers address an extended spectrum using standard single mode fiber that is the good thing about raman amplifier  refer slide time  30  03  30  09 min  so edfas are popular in c-band  raman are proposed for s-band  and gain shifted edfa for l-band etc  refer slide time  30  10  30  32 min  we can have a look at this ? depending on the wavelengths  different kinds of doped and different kinds of fiber amplifiers become is more relevant  like edfa for this range from 1550 etc  tdfa  pdfa  raman amplification for this entire range  etc now we talk about some more components  the first component we talk about is  refer slide time  30  45  31  07 min  some sort of passive device called a coupler optical coupler combines and splits signal wavelengths independent or selective ; that means  the coupler can be wavelength independent as well as wavelength selective ; fabricated using waveguides in integrated optics light couples from one waveguide to a closely placed waveguide because the propagation mode overlaps the two waveguides  refer slide time  31  08  31  40 min  so this is the picture  we have an input waveguide coming in and another input may come ; and there are 2 outputs so what might happen is that it may be used as a coupler ; that means  2 signals joining together  like we wanted to do when we tried to put in a pump in the edfa amplifier or it may be used for splitting the signal coming from one and it is getting split into two directions so this can be used in various ways  refer slide time  31  41  32  3 min  so if a is the coupling ratio  power output 1 is a times power of input 1 whereas power output 2 is 1-a times power of input 1 so you see that together the input power is split into two parts if you want to have a = ?  these are so-called 3-db couplers we put half the power in input 1 and half the power in output 2 if you want to broadcast the same signal to two different destinations  you can use a 3db coupler as i said  light couples from one waveguide to a closely placed waveguide   refer slide time  32  31  32  38 min  iidentical waveguides complete coupling and back periodically sso this is the couple mode theory  refer slide time  32  39  33  06 min  of course we have to follow the conservation of energy constraint so you can not get more ? since this is a more passive device  we can not get more out of it then when you put in actually you get less  so it is possible that electric fields at two outputs have the same magnitude so they are exactly the same  but will be 90 ? out of phase and lossless combining is not possible  so nothing is really 100 % efficient  refer slide time  33  07  33  50 min  passive star is a sort of generalization of this it ? s a broadcast device to more than one recipient it divides the received signal to all output ports at original wavelength ; of course  if you divide the same signal into so many different signals  the received strength of the signal will be proportionally less you have to handle it by either amplification or some other thing  or maybe  weak signal is good enough for your application etc so n ? n passive stars can route n simultaneous connections through  refer slide time  33  51  34  12 min  this is an example of an eight-port splitter whatever signal is coming  it is getting divided into two and again divided into two so we get eight signals over here ; we can actually use some 3-db couplers to form this eight port splitter from y-couplers  refer slide time  34  13  34  35 min  this is another example of an 8 ? 8 star coupler there are 8 lines ; any of these might communicate something which will be broadcast to all the other seven ports so such things are used for broadcasting  refer slide time  34  36  35  26 min  we now come to optical modulation ; that means how we modulate it of course the simple modulation scheme ? since we are talking only about digital systems ? is on/off keying  that means either on or off or 1 or 0 there are two types of modulation techniques  namely  direct modulation versus external modulation in modulation  the extinction ratio of output power for bit = 1 to output power for bit = 0 is very important we want this to be as high as possible some lasers can not be directly modulated ; that is one problem another problem with direct modulation is that you are modulating at the source  modulating at the same place  from where that light is being generated whatever diode or whatever you are using for generating it  we want to modulate through that only so that is the direct modulation  whereas in indirect modulation  what we will do is that there is a continuous source of light and just as the light comes out  we will modulate it we will put it on or off by making it go through something so that is the external modulation  refer slide time  36  00  36  22 min  so the solution is ? naturally since direct modulation has the problem about the chirp  etc ? external modulation for higher speeds  longer distance dispersion  limited regimes  etc we prefer external modulation the light source is continuously operated external modulation turns light signal on or off ; so this is the optical modulation  refer slide time  36  23  36  49 min  they can be integrated in the same package as laser ; the laser source is there and the modulator is external  but they can be packaged electro absorption or ea modulator is one important kind of modulator ; it applies an electric field  shrinks the band gap and photons are absorbed  refer slide time  36  50  37  03 min  so this is the picture  this is the continuous source of this light  which is being modulated  that is  being put on or off depending on whether you want to transmit 1 or 0  refer slide time  37  04  37  52 min  the next set of components are multiplexers  filters  and gratings we will talk a little bit about it if you look at this  these are all wavelength selective devices  multiplexers  filters  and gratings in a wavelength filter suppose ? 1  ? 2  etc so many ? s are coming  but i want only ? 1 out ? 2  ? 3  ? 4  etc  are absorbed ; whereas if you are a multiplexer  i want the different ? s coming in different lines i want all to be mixed together and use the same line that is a wavelength multiplexer  refer slide time  37  53  39  20 min  so the application could be particular wavelength or a particular wave band selection wave bands are nothing but some contiguous  operating wavelengths  which all are side by side in the operating window  whatever be the window you are using ? 1550 or whatever ? you can have a number of ? s  all side by side there is a guard band between each of these operating ? s ? the iqt has specified how much guard band etc  you will have to have you can have large number of ? s  all grouped together in the same window now you can select a band out of that  a bunch of frequencies out of that  instead of selecting only one ; that is wavelength band selection static wavelength cross connects and oadms oadms  optical add drop multiplexers   you have come across this term  optical add drop multiplexers in the context of sonet  but in the optical domain we require optical add drop multiplexers ; we will come to that equalization of gain  that is another application ; filtering of noise ; ideas used in laser operation and dispersion compensation modules etc these are the different applications  refer slide time  39  21  40  20 min  one of the standard wavelength selective components is arrayed waveguide gratings these are curved selection of silica acting as waveguides each waveguide is slightly different in length the incoming signal is split to be slightly different in length is like a running track bend ? in a running track you know that the outer track  in any athletic event  in an 800 m race or something  the outer track is longer than the inner track that is why athletes are given proper handicap  because we want to make all the distances same here deliberately  we want the distances to be different if they are different  they are going to sort of arrive out of phase at the output the incoming signal is split ; every wavelength then travels down each waveguide  refer slide time  40  21  40  34 min  time delayed signals recombine to give each wavelength its own waveguide ; can be reversed to act as a multiplexer rather than a demultiplexer ; usable in optical integrated circuits ; easily combined with other functions  refer slide time  40  35  41  11 min  this is the picture we had seen earlier  if your light is going in this direction  what you are doing is that you are demultiplexing one bunch of frequencies are coming ; we want all these different colors to get separated out so that is the demultiplexing action going on if different wavelengths or different colors of light are coming in the other direction  it ? s just the direct opposite thing  and we will get a multiplexer  so it is an awb acting either as a multiplexer or demultiplexer  depending on how you operate  refer slide time  41  12  43  07 min  s we come to optical switches ; we have seen electrical switches now we will talk little bit about optical switches what is optical switching ? you remember electrical switching ? in electrical switching  there are some one input lines coming in line i and i want to get that signal out through line j so we want to operate the switch through the switch or something  want to connect the ith line and jth line the basic idea was that the signal coming down from ith line has to go out of the jth output line that was the simple switching element it is the same thing here also ; some wavelength is coming through some fiber  that is  one input port we want to get it out of another fiber for the time being  we do not have any wavelength conversion kind of thing  thus the same wavelength has to push it to another fiber so that is my switching at the optical plane redirecting light from one optical fiber to another without electrical conversion so we are always harping on that without electrical conversion  we can operate it at a much higher way and higher speed secondly it may be cheaper also  to operate at high speeds ; it will be cheaper and then if you upgrade eventually  this is going to be transparent this does not depend on the underlying protocol  etc  that is being used at the higher layer these are the other advantages of doing at the optical plane now  the most advanced optical switching technology is mems  that is  tiny movable mirrors  refer slide time  43  08  43  13 min  so this is the crossbar switch 4 ? 4 switch  refer slide time  43  14  44  09 min  we have seen this picture also that is a mems optical cross connect you see that these are all tiny mirrors ; what i can do is that  to follow the red line which is coming  we are using these two mirrors to push it to line number 3 over here ? from line number 1 to line number 3 this way  by just adjusting the angles of the mirrors which we can do through the mems technology  we can have a simple and elegant kind of switch the light goes and bumps off a couple of mirrors and goes out the other fiber whatever signals it is carrying  what protocol it is carrying is immaterial ; similarly  the data rate also is immaterial this is a mems optical cross connect now all this technology sort of enables what is known as the wdm technology  which is a wavelength division multiplexing as i was mentioning when we were discussing multiplexing  wavelength division multiplexing is nothing but frequency division multiplexing ; that means  you want different channels to come at different frequencies it ? s just the opposite of optical domain in wavelength division multiplexing  different wavelengths and different ? s are getting together and light with different wavelengths can very well mix together and go to the other end for example  sunlight has all the frequencies that are mixed up to appear as white light to us ; if you send this through a prism  all the frequencies split up so we will get some kind of a demultiplexing action so you want to use this property for wavelength division multiplexing for achieving very high data rates there are two kinds of wavelength division multiplexing  or wdm  that people talk about mostly in the backbone  people use dwdm dwdm means dense wavelength division multiplexing by dense we mean that we put a lot of channels  lot of ? s side by side  so we get a lot of channels of course  dwdm would not usually be deployed in a lan because dwdm is costly but then  at the backbone  where you are talking about very high speed that cost is effective ; whereas another kind of wavelength division multiplexing is coming into lans  which is called cwdm or coarse wavelength division multiplexing there the wavelengths are not so closely packed ; they are sort of more sparsely placed  which is a good thing because then  the stability of these laser sources  detectors etc  are less of an issue so cdwm tends to be cheaper than dwdm and cwdm is coming into use these days we will start our discussion on wavelength division multiplexing in this lecture and then we will continue in the next lecture with the details of wavelength division multiplexing  refer slide time  46  53  47  07 min  wdm increases the capacity of optical fibers ; different wavelength lasers  each transmit at same time down the same fiber ; multiplexing is combining wavelengths ; demultiplexing is splitting of wavelengths  refer slide time  47  08  48  03 min  usually the number of wavelengths is in the power of 2  4  8  16  64  128  etc  things like 32  64 etc  are big 16  32  64 are deployed ; now people are talking about hundreds of wavelengths  may be even thousands wavelengths are separated by multiples of 0.8 nm guard band  i mentioned this is equivalent to 100 ghz there is 100 ghz separation between two ? s ; that is the minimum separation  which is mandated by the itu standard coarse wdm has widely separated wavelengths so that the components can be little less sophisticated and much more cheaper  refer slide time  48  04  48  25 min  this is a wdm system ; different lasers of different lights coming together to the multiplexer  flowing down the same fiber at the same time  being demultiplexed on the other end the multiplexer  demultiplexer could be an awg or some other  refer slide time  48  26  48  59 min  in point-to-point wdm system  one point is connected to another point through multiple wavelengths wdm is the most cost-effective technology in point-to-point technology  where the distance is about greater than 50 kms in shorter distances  multi fiber is cheaper because in dwdm naturally your end equipment tends to become quite costly if you have some extra strands of fiber  then that may be a cheaper option  refer slide time  49  00  49  48 min  wavelength add drop multiplexer is one thing we require  when we want to add on to a stream of wdm that is going through a fiber  or we want to add on some extra wavelengths on the wave or we want to take just one wavelength out and let the others pass through so that is a wavelength add drop multiplexer needed for routing and wavelength assignment it performs the same functions as the electronic counterpart at the level of wavelengths we had come across its electronic counterparts like adm in sonet ; the same thing happens in the optical domain one problem is that granularity is high  because of inherent capacity of wavelengths ; so even if you take out one single wavelength out of a whole bunch of wavelengths  that one single wavelength can carry a large amount of traffic  let us say  2.5 gbps ? that is a high amount of traffic if there are small amounts of traffic which you want to add or drop  then this is not a very effective technology  refer slide time  50  12  50  36 min  wadm has multiplexers and a set of 2 ? 2 switches  one for each wavelength they are managed electronically ; that means  these switches  etc are programmed electronically to control which incoming length flows through and which is dropped  refer slide time  50  37  51  01 min  so fiber and wavelength cross connects are important components of this wdm  needed in real networks point-to-point connection does not need a passive star  or a passive router or active switch  but in wdm  we may require all these for an entire communication network we have discussed this  refer slide time  51  02  51  51 min  passive router  it can route separately each wavelength  no wavelength conversion ; it allows wavelength reuse  same wavelength can carry multiple connections through the router for example  the same wavelength coming from fiber 1 going through fiber 3 and the same wavelength coming in from fiber 2 and going out through fiber 4 is perfectly possible if enough wavelengths are there  n ? n router  can route n2 simultaneous connections ; some routing issues are there we will discuss the routing issues in the next lecture  refer slide time  51  52  52  17 min  finally  we may have some active switch  which has all the features that a passive router has the difference is that active routing matrix  which has some functionality  has to be powered this is of course an issue when you are talking about a very long haul  refer slide time  52  18  52  20 min  with this we conclude our initial portion of our discussion and in the next lecture we are going to discuss the details of wdm ; that is  how different wavelengths are routed through the network how we can get an entire network output thank you preview of next lecture computer networks prof sujoy ghosh dept of computer science& engineering iit kharagpur lecture 11 routing and wavelength assignment in wdm all optical networks  refer slide time  52  49 min  good day  so iin this lecture  we are going to continue our discussion on wavelength deviation and multiplexing specifically we are going to talk about routing and wavelength assignment  refer slide time  53  09-54  14 min  rrouting and wavelength assignment to what ? well routing and wavelength assignment means that we have some stream of packets or whatever data or whatever communication is going on from one source to one destination now tthese sources and destination  first of all one thing is of course of point to point connection is if there is point to point connection is directly sends to the fiber that is  noise  simple but in general  they will not be directly connected general tthey will go through a network   noise  they go through some intermediate notes to reach the destination sso this for this stream  we have to route this that is one problem and the other thing is that may be they are all the stream right some particular wavelength for the time being llet us assume that it is continued on the same wavelength sso we have to assign one wave length  so we have this problem of routing and wavelength assignment  refer slide time  54  15 54  23 min  in wdm all optical networks ok of course we can do  noise  routing etc  very easily in the electronic domain   noise  that is known  noise  routing in the electronic domain how it is done etc  are we are not discussed is as easier we were discussed it  later on iin the this these series of lectures but routing  i mean we are talking about a simple kinds of routing problem here sso we will talk about routing and wave length assignment  refer slide time  54  43-56  53 min  sso this is an example of light path establishment  suppose you have these a b c d e abcde these are connected so iin the first part  the left half of the figure what we have is the physical connection from aa to bb  there is a connection and bb to dd there is a connection and so on iin this one  noise  ii show some  noise  that means some  noise  rw routing and wavelength assignment has already been done and some of the wavelengths and some of the links have been used sso here only two 2 wavelengths are used  let us say aa to bb  noise  they are not connected say a to c a to c the a to c a to c light path has been established via bb so and aa to bb  there will be a switch which will switch the  noise  and suppose this dashed line is the lambda one lambda 1 sso the lambed lambda1 a one coming through this fiber from a to b a to b that is switched to lambda one lamda 1  noise  using the same wavelength to the outgoing fiber from b to c b to c so wwe have light a paths established between b to c b to c similarly c to d c to d  there is a light path b to d b to d  there is a light path d to e d to e there is a light path e to f e to f there is a light path d to f d to f  there is a light path and so on  using the same lambda one lamda 1 then ii want to connect e to c e to c now ii can not go from e to c e to c after say lambda one lamda 1 has been  noise  assign ii can not go  but from ee by lambda one lamda 1 to anywhere because all the outgoing fibers the lambda ones lamda 1s have been used up this side  for a this side for bb and this side for f f  noise  sorry sso inorder to connect from e to c e to c  ii use the another wavelength which say lambda two lamda 2 which connects me higher dd so and the dd cross connect will connect this particular lambda lamda from this fiber to this fiber so wwe will get a direct  noise  light path from e to c e to c ssimilarly we will get a light path from b to f b to f using lambda two lamda 2a to b a to b using lambda two lamda 2 and this way   noise  they are all connected  refer slide time  56  55-57  40 min  aa burst has a long and variable length payload  if it is long low amortized overhead no fragmentation aa control packet is sent out of band that means using some other lambda lambda lamda control and reserves bandwidth that is lambda lamda data reserves a particular bandwidth along a particular path and configures the switches sso it is like a setting up temporary light path from the source to the destination ok aa burst is sent after an offset time  it arrives at a switch after it has been configured sso no buffering is needed  so our original problem is of not having optical buffer sso buffers in the optical domain that is avoided in this fashion  refer slide time  57  42-58  20 min  sso what will happen is that  this will now moving towards the other end to the next node and  noise  here this will again  noise  do some  noise  do the go through the o to e o two e and then do the  noise  switch  noise  configuration and then again e to o e to o and go to the next half and this delay etc  is calculated in such a fashion that when the burst arrives  what happens is that we when the burst arrives at the intermediate node  the switch fabric is already configured sso you do not have to store it  you simply simply passes through in the optical domain sso that is  refer slide time  58  21-58  44 min  nice so offset of course is now t minus delta t ?  because it spent delta ? amount of time over here sso without any delay  the burst goes through the optical switch fabric  so depending on how many intervening notes are there  you have to have this original tt  so that finally when the tt is exhausted offset is exhausted but you have also reached your  noise  destination computer networks prof.sujoy ghosh department of computer science and engineering iit  kharagpur lecture # 9  refer start time  00  47  good day in this lecture we will discuss about  refer slide time  00  54  01  16  sonet the word sonet stands for synchronous optical network  sonet in the usa  canada  and japan  synchronous digital hierarchy elsewhere for example in india we will be calling sdh so this is a time division multiplexing system that transmits a constant stream of information  refer slide time  01  17  02  10  sdh is actually a successor of pdh few years back we used to have a pdh gear in our telecom infrastructure in the wide area network part that is plesiochronous multiplexing  nearly synchronous   this business of being a nearly synchronous introduces us a lot of problems and complications so  when from this nearly synchronous we went to synchronous  that was a major achievement as well as improvement of services as we will see later on in the pdh multiplexing in which two or more signals are transmitted and nominally in the same digital way and the significant instance occur at nominally the same time this was pdh  refer slide time  02  10  2  34  when sonet was introduced  it had a number of achievements to its credit firstly  it is a standard multiplexing using multiples of 51.84 mbps  that is an sts-1 rate and sts-n ? we will look at this rates this was used as building blocks this is something that is to be understood that why it is that particular rate value is so important the point is when you are multiplexing the original source may come from various sources  and these signals will travel  will get together  will separate out and then mixed with others  etc that is possible only when we have in international multiplexing standard and this international multiplexing standard was first achieved in sonet what happened was previously of course the rate which people used were must less and they had all kinds of differences as technology grew and different sort of countries on different things came together  they came together at a certain rate of transmission and this is a basic building block of sonnet there is a standard multiplexing using multiples of this particular day that in itself was a big achievement  refer slide time  03  50  04  23  secondly  it also first stated the optical signal standard for interconnecting multiple vendor equipment the point was previously of course at lower rates they were all electrical signal standards  sonet has both has electrical signal standard as well as optical signal standard and in this optical signal standard it was possible to bring together multiple vendors to agree on to some particular format  refer slide time  04  23  05  23  and the third achievement in sonet was extensive oam & p capabilities so what are oam & p ? o is for operation ; a is for administration ; and m is for maintenance ; p is for protection maintaining the system  administrating the system  operation of the system etc  are much more flexible in sonet when compared to others what kind of flexibility  etc  that we will see regarding protection also  as a matter of fact it is so strong in sonet  that we will specifically discuss this aspect in a separate lecture when we talk about protection these are very strong points in sonet and that ? s not all  refer slide time  05  23  06  50  the fourth one was multiplexing formats for existing digital signals it ? s not that such a development can take place in vacuum ? that means they had some history and the trouble was that different countries have different kinds of histories it is not feasible for a technology to come and say throw away whatever you have been doing and put this there will never be forklift upgrade ; it is never possible because of cost  practical considerations  and all kinds of things so an evolving technology  in order to be successful  has to bring together previous technologies so that they can merge into this new technology and that was another sonet achievement these existing digital signals ? these ds1  ds2  etc  are different multiplexing standards at the low end by the way there is also ds0 and ds0 rate is our venerable 64 kbps line rate do you remember once again that for voice channels  we require a 64 kbps because of pcm  etc we have already discussed so that is a ds0 rate and these several ds0 get together to form ds1 and so on  and that way  there is a hierarchy of rates  refer slide time  06  50  08  25  then the fifth achievement of sonet was that it supports itu hierarchy  e1  etc so this itu hierarchy was more popular in europe  india  etc and they had rates like e1  e2  e3  etc e1 was something like 2 mbps  and then e2 was 1mbps  and e3 was 34 mbps  whereas the development in usa was on a different track they had a tone rate t1  t2  t3  etc their rates were as above  ds1  ds2  etc what happened was that when sonet got introduced  these two sort of came together and although they are not perfectly identical ? these sonet and sdh ? for most of the part  they are identical ; they interoperate with only very slight modification at the boundaries  which is not very important that is a great thing and that means that the same standard is being adopted worldwide  so that any signal can be transported in any way if there is an infrastructure  we can transport in anyway to another part of world ; there is no problem so bringing together of these  that means bridging the atlantic ocean of these two standards  that was another good achievement of sonet  refer slide time  08  25  08  49  the next is that it accommodates other applications the other applications which were not a part of this kind of hierarchy  like bisdn  that is broadband isdn  also can be accommodated in sonet and that way you see sonet was quite flexible ; and how this flexibility is achieved we will see that later on  refer slide time  08  49  09  32  finally it allows quick recovery from failure  talking about protection  etc so if there is a failure like a line failure or if there is a terminal equipment failure you can deploy a sonet in a particular fashion and sonet can recover from this failure and this retransmission  etc  can take place in a short period of time that is very important when you want to give the so-called career great service  where arbitrary down time is absolutely not acceptable as i said  we will discuss this separately in another lecture  refer slide time  09  32  11  02  some of the broad features of sonet and sdh  it was first standardized by anci/ecsa  sdh by itu ? t so sonet was by this anci/ecsa and sdh by this itu ? t sonet is time division multiplexing  pure we know what time division multiplexing is  and we will see later on how frames  etc are made up it is a pure time division multiplexing system sonet encompasses optical and electrical specifications  so there are optical specifications as well as electrical specifications you know that usually at the user end  quite often things start at the electrical level and the rates are low but as you go more towards the backbone of the network  the rates that are needed at the backbone start becoming higher and higher and finally at the real backbone it has to be very high-speed network  and such high-speed networks are only possible through optical communication and optical networking once again  we will see about optical networking in the next couple of lectures our specification  the sonet specification  spans both the electrical side as well as the optical side  and that is a very good feature of sonet  refer slide time  11  02  11  42  sonet uses octet multiplexing  octet means the same thing as a byte that means 8 bits  so sonet uses octet multiplexing they are multiplexed byte by byte sonet uses extremely precise timing  something like in 30 years  maybe ; sonet has very precise timing and that is why things are synchronous and if things become synchronous  then we derive a lot of advantages out of that and sonet provides support for operation  maintenance  and administration  oam  as we have already mentioned  refer slide time  11  42  14  24  sonet is actually superior to t3 and t4  etc with improvements over the t carriers ; these t3  t4 are still in use but they feed into sonet nowadays but earlier  they were used to feed into this pdh and these t3  t4 have particular rates which existed  and their specification left something to be desired because of this lack of synchronicity  handling the signals from different sources is not easy what could happen is that when things are not synchronous  but just almost synchronous  then to handle this ? almost ? part  you have to do something ; you have to incur some overhead ; and you have to incur some complexity that was the difficulty with pdh ; in sdh or sonet  this is eliminated  and we get better transport performance then  we have the ability to identify sub streams this was another advantage of sonet over pdh  which is that a particular user uses may be using a very small kind of bandwidth ? small in relative sense ? and then  as more and more users  as i said as all these data streams or communications streams come towards the backbone of the network  the pipes tend to get fatter that means  we need faster and faster communication so between say two points in the backbone  there may be a very fast communication going on and then after going to some other hops  this will again diverge sonet has this ability that different streams can get together  travel for some time  and then again diverge so the ability to identify sub streams is very important  and that is also allowed in sonet  which was more difficult in the rdr system and of course international connectivity  as i said that it breached atlantic and that was great it enhanced control and administrative function  that was also very good from the point of view of service providers  refer slide time  14  24  16  00  we have talked about this seven-layer osi protocol ; where does a sonet sdh really fit in ? sonet sdh goes to the bottom of this if you remember  starting from the application layer  we go right up to the physical layer there are several layers in osi model  and there are other models anyway  usually the bottom-most layer is always the physical layer so sonet really fits into the physical layer in some sense so what would happen is that the layer just above the physical is the data link layer  may be  or layer two so after all this encapsulation  etc is over through all these six other layers including the data link layer  sonet takes it over for transporting it from one point to another so sdh is placed at the bottom of the protocol stack in the physical layer along with the fiber any ip traffic even if it is the ip traffic of a packet oriented traffic ? and remember that sonet is a tdm system ? it can sort of travel within a sort of tdm transport as they quite often do so any ip traffic that is destined to be transmitted across a fiber-based sdh network will be framed by a layer two protocol before being ready to take its orders from the sdh equipment  refer slide time  16  00  17  59  these are some of the multiplexing standards ? i have not given all of them i just indicate some of them if you remember as i mentioned ds0 is a 64 kbps channel and 24 of them constitute a t1 line so t1 rate is approximately about 1.5 mbps ; 4 t1 gives t2 and 6 t2 gives t3 and so on similarly 30 ds0 ? this is a european system ? gives e1 line so e1  if you remember  is about say 2 mbps  4 e1 gives e2 ; e3 is a 34 mbps line and then i suddenly jump right up to this thing called oc3 ; this o is for optical so this way  this 155 mbps is 3 of the basic sts 1 rates that i mentioned earlier ; i will come to this later on so these are some of the standards there is a whole hierarchy of standards ; for example  this name sdh is also synchronous digital hierarchy  this is a hierarchy for the sonet  the basic rate is sts 1 that is synchronous transport signal level 1  and the speed is 51.84 mbps this is designed to carry what was ds3 rdr or a combination of ds1 ds1 c  and ds2 etc as i said a combination of different streams can flow through a sonet pipe or sonet infrastructure so that is good and that means ds3 is a fat pipe or ds3 is almost the same as sts-1 so it is a fat pipe through which multiple pipes  say may be ds2 or ds1  etc may travel  refer slide time  18  03  18  25  and this net goes up to sts-n  whereas synchronous transport signal level is n ; so this has a speed of n ? 51.84 mbps designed to carry multiple sts -1 i mentioned that these are byte multiplexed sts-1 means 1 byte from one source and another byte from another source and so on  refer slide time  18  25  19  49  fundamental sdh frame is stm -1 ; sdh if you remember is the other standard  which came from europe and they sort of came together and that is what we are talking about sdh frame is stm -1 synchronous transport module and the sonet version is oc -3  that is  optical container  each providing 155 mbps so when we come to this rate this 155 mbps oc 13  different rates etc and different systems  are culminated here  at this 155 mbps  almost 155 stm 4 provides four times the stm -1 capacity  stm 16 provides a further fourfold increase  which means stm4 may be about 620 mbps  and then  if you go to stm16  which is four times that of about 2.5 giga bit/s  then you have stm 64  which is about 10giga bit/s so all these rates are there ; that means  from this point onwards  these two streams have converged and we are going to higher and higher rates in a sort of universal fashion  which makes things easy across the world  refer slide time  19  50  20  17  it is worth noting that the inter networking between sdh and sonet systems is possible at matched bit rates ; for example stm4 and oc12 ; so they interoperate a slight modification to the overhead is required as they are structured little differently so there will always be a little something ; but anyway that is not very serious so they do interoperate  refer slide time  20  17  20  41  we have seen the sonet electrical hierarchy ; now we look at the sonet optical signal hierarchy  oc-1 is the optical career  level 1 ; it carries sts-1 ; oc 3 carries sts-3 or stm -1 at 155 mbps ; oc-n optical career level n  refer slide time  20  41  22  16  oc  n as i mentioned is an optical carrier  which uses n ? 51.84 mbps  so oc  48 is about 2.4 gbps ; overhead percentage is about 3.45 %  oc signal is sent after scrambling to avoid a long string of 0s and 1s to enable clock recovery this is a small technical point ; that means in order to keep the whole thing synchronized  the sdh units use the transitions which happen when there is a 1 so the point is that if there is no 1 for a very long period in the data stream  then the clock on one side may drift relative to the clock on the other side ; that is always possible so we try to avoid long streams of 0s in this sonet or sdh  and we do that by scrambling the data from various streams  etc  or descrambling them the idea is that even if one of them is sending a long stream of 0s  there will be quite a few 1s from the other streams and then the clock will be maintained an sts -n is synchronous transport signal electronic equivalent of optical carriers  refer slide time  22  16  23  29  oc 3  oc12  oc 24 and oc 48 rates are common in telecom circuits ? if you remember oc 48 is 16 times of oc 3 ; that is  16 times 155 mbps  which is about 10 gbps upto 10 gbps is very common these days actually right now  with dwdm systems  oc 192 rate is already in operation  and oc 768  which is 40 gbps  is being talked about so that was another disadvantage earlier that this digital hierarchy of standard rates did not exist beyond a very small rate ? i mean small in today ? s comparison but now we have an extended and open system where  as technology improves  we can always go for higher and higher rates ; so from oc 3  which is 155 mbps  we can go to maybe oc 192  which is 10 gbps or oc 768  which is 40 gbps that we are talking about now  refer slide time  23  29  24  11  how do you use these high-speed links ? these high-speed links of course have to be on fiber ? we can look at details of fiber later on  but please note that in practical application  an sdh line system will have a multiplexer that takes its inputs from a variety of sources in different layer 2 data formats so here we are talking about these different signals coming in the electronic domain  and they are coming from a variety of sources  may be coming with different layer 2 data formats these are aggregated up to form frames at a line rate of system  for example up to stm 64 for a 10 gbps bit rate system  refer slide time  24  11  25  08  now these frames at 10 gbps can not be pumped anywhere it is very difficult to pump it on a copper so these frames are transmitted out onto optical fiber links there is a possibility of multiple sdh multiplexers to each give out one wavelength of a wdm system as we will see later on  this wdm stands for wave length division multiplexing  which is some form of frequency division multiplexing i mentioned about it when i talked about frequency division multiplexing in fiber optics  we talk about wavelength multiplexing so it is possible that one multiplexer is feeding into one wavelength  another multiplexer is feeding into another wavelength  and all these different wavelengths are traveling together in the fiber  refer slide time  25  08  25  44  at the end of the system  there will be an sdh demultiplexer on the other end  just as we have a multiplexer on one side naturally  you have to have a demultiplexer on the other side that now accesses the individual data streams from the stm 64 frames as required so stm 64 is carrying lots of frames in a very short time ; they are sort of separated out and then fed into slower streams down the line so there may also be an sdh add drop multiplexer with the ability to remove and insert lower bit rate streams from the signal  refer slide time  25  44  26  33  alternatively a digital cross connect may be present with the ability to switch individual vc4s well  this is virtual container four  which is another concept  we will talk about later so between different fiber links there is a digital cross connect ; if you have the digital cross connect in the optical level  the advantage is that you need not go into the electronic domain at all so the advantage of not going into electronic domain is that you are handling a huge  very fat  pipe ; that means  a large number of channels  and you can just switch them from one fiber to another fiber simply in the optical domain without doing any kind of processing ; and that is always an advantage  refer slide time  26  33  27  50  we will talk about some sonet terms now ; for example  envelope this envelope is the payload basically  after all encapsulation  etc  you remember that finally near the bottom we have this layer 2 and this layer 2 protocol will encapsulate it and then hand it over to sonet at the lower level  maybe at the physical level so whatever this layer 2 hands over to sonet is the payload ; the rest of it are kind of system overheads ? payload plus some end system overhead also goes into this payload so these together form what is known as the envelope ; this is a sonet term other bits and bytes which are used for management  that means oam and p portion  goes as the overhead of sonet then there is the concept of concatenation ; that means  unchannelized envelope can carry super rate data payload  for example  atm  etc so  the method of concatenation is different from that of t carrier hierarchy ; we need not bother about it at the moment  refer slide time  27  50  28  23  then there are some nonstandard functional names in sonet  like tm is for terminal multiplexer  also known as line terminating equipment or lte these are ends of point-to-point links adm is for add drop multiplexer ; we have mentioned this dcc is for digital cross connect wideband and broadband ; mn is for matched nodes and d + r means drop and repeat  etc anyway  these are just some terms  refer slide time  28  23  28  40  now let us come to some important concepts in sonet namely  section  line  and path what is a section ? i will just show you figure first and then come back to this  refer slide time  28  40  30  24  please look at this figure  we have some multiplexers so as the figure shows  we have a multiplexer in this side  another is an output that fits to another multiplexer this multiplexer is going in this direction and after some time  the signal becomes weak so we want a repeater ; what is a repeater ? a repeater is something which boosts the signal strength so there is a repeater  then it travels some more distance then there is a repeater again and then it travels some more distance and then on other side we have the corresponding demultiplexer and then it fits into the other de-multiplexer from repeater to repeater  we call it a section so from repeater to multiplexer  this is also a section so multiplexer to repeater  repeater to repeater  these are called sections and then  from multiplexer to multiplexer  we call it a line at the repeater  nothing happens excepting the signal is cleaned up the signal may be boosted or there may be other cleaning operation  synchronizing operation  etc  that may be done at the repeater ; but as such  the signals which are traveling here  the same set of signals are traveling here at the multiplexer  of course  some of the signals may go off in another direction ; some signals may go in some other direction  etc so at the multiplexer  there may be a convergence or divergence  depending on which way the signal is flowing that may happen at the multiplexer  so from multiplexer to multiplexer  we call it a line ; and then from the end user point to end user point  we call it a path  refer slide time  30  30  30  57  look at this once ; the portion from a multiplexer to a repeater is known as a section or it could be a repeater to a repeater also ; the portion from a multiplexer to another multiplexer is a line the portion from source to destination multiplexer is a path ; below path line and section is the photonic sub layer ; that means photonic sub layer is whatever is happening in the optical domain  and we are not discussing that at the moment  refer slide time  30  57  31  14  sections are bounded by repeaters or multiplexers that terminate the line ; lines may carry several tributary signals and are bounded by multiplexers  a path goes end to end between terminating multiplexers  refer slide time  31  15  33  49  each sth frame lasts 125 microseconds as i mentioned  this 125 microseconds time period  time epoch  is sort of sacred in this whole domain because 125 microseconds is what is required for a ds0 channel remember this is a time division multiplexing  which means that if you have a 125 microsecond kind of slot  then some of the ds0 bytes can take these bytes actually if you have to take it as 8 kbps and if it is 8 kbps  inverse of that is 125 microsecond so if you have a 125 microsecond slot  if 1 byte travels in this frame  then that is enough for 1 ds0 channel in sonet we have very very sophisticated and very fast equipment ; that means this is a time division multiplexing system ; within this 125 microseconds  not only 1 byte can go but lot of other bytes can go that means a lot of channels can travel together in this 125 microseconds frame this is the idea so each sth frame lasts 125 microseconds ; how many bytes are going in there depends on whether it is sts -1 or sts -2 or sts ? n  etc so 125 microsecond as i mentioned is 8000 frames/s sts -1 frame has 6480 bits or 810 bytes that means in one  125 microsecond slot or frame  we are putting in 810 bytes theoretically  of course  that means it can carry 810 ds0 or voice signals ; actually it is not 810  it is lesser than that because a number of these bytes are used for different types of overheads we will talk about this we have these 810 bytes  the octets are understood in terms of a table of 9 rows and 90 columns ; so let us look at this figure  refer slide time  33  49  36  16  we have a sonet frame or an sdh frame  which has 9 rows  you can see the 9 rows on this side and then 90 columns  total 90 columns out of these 90 columns  3 columns have been shown in yellow these are sort of used for overhead and these 87 columns are used for payload or for envelope if you remember  the envelope contains the payload as well as little bit of overhead  which we will come to later on this is how after every 90 bytes  we come back to again another 3 bytes of this overhead this is how it is to be understood  the first 3 columns contain transport overhead and toh has 9 rows by 3 columns  that means 27 bytes  which is subdivided into section overhead soh  section overhead   9 bytes  3 rows of 3 columns ; loh  that is  line overhead  which is 18 bytes  that is  6 rows of 3 columns so we have section overhead and we have a line overhead ? remember we have these three concepts like section  line  and path we have not talked about path overhead there is some path overhead and it goes into the envelope ; so there is some path and as far as these things as line and section are concerned  these are the overhead bytes just to clarify why do we require the over bytes ? the point is that the multiplexers or the repeaters have to have some communication between them in the control plain so as to give you this oam capability for that some information needs to be sent or exchanged between the two points ; anywhere there is a section  the section overhead would consider those things which are central to the section about the signal strength and other kind of things ; line overhead maybe would contain something else and similarly path overhead would contain something else but these are required for these oam capabilities that we have in sonet  refer slide time  36  16  36  49  let us look at these overheads separately ; first section overhead  which defines and identifies frames and monitors section errors and communication between section terminating equipment so these are its functions  it identifies frames ; monitors section errors ? if there are errors  it monitors section errors ; and communication between section terminating equipment  maybe two repeaters or a repeater and multiplexer  and so on  refer slide time  36  49  37  29  line overhead locates first octet of spe and monitors line errors and communication between terminating equipment we will come back to this locating of the first octet of spe this is a very interesting feature and we will talk about this separately previously we talking about section errors ; so line errors and communication between terminating equipment  etc  is taken care of by the line overhead apart from that  line overhead contains this pointer  really  which points to the first byte of the spe  refer slide time  37  29  38  36  and then there is a path overhead ; and as i said path overhead is really inside the envelope and we will look at all these later path overhead verifies connection path ; you remember path means from end to end ; that means from the end to end multiplexer is a path whether the connection has been established or not  it monitors path errors  receivers ? status  communication between path termination equipment  and so on this is the poh  we talked about the synchronous payload envelope or spe that i was talking about that is  the other 87 columns hold the spe  synchronous payload envelope   so spe has 9 waves by 87 columns  which are divided into path overhead and payload  which means the path overhead goes along with the envelope that is in the spe  whereas other overheads have separate bytes or separate columns associated with them as shown  refer slide time  38  36  39  52  now this spe does not necessarily start in the column 4  which means that the spe does not necessarily stay within one frame ; these are two very important points in sonet the point is that although you have these 87 columns  actually the data may start getting transmitted at some arbitrary points inside those 87 columns what is the idea ? i mean why do you want to leave something and then only start from the middle ? the point is that if there are some kind of mismatches of late  etc  if everything in the world were absolutely synchronous  all activities and all equipments  etc  then you could have started from the beginning but that is not the case and this is where we absorb this kind of variation and this gives great flexibility to sonet  which was not there earlier and the other interesting thing is that the spe does not necessarily stay within one frame  which means that the spe may start in one frame and then end in another we will just look at a diagram of this ; let us have a diagram of this you see  refer slide time  40  00  40  21  the spe in light green color ; it really starts from somewhere i mean somewhere after leaving some of the rows  it starts here  and the path overhead is somewhere here  and there are two frames here so spe is really spanning both the frames  refer slide time  40  25  40  57  spe is not frame aligned ; it overlaps multiple frames ; avoids buffer management complexity and artificial delays whenever there is something to send  you can just send it in the envelope ; just put that pointer to that yellow edge  so that yellow edge will point to the first byte of the spe it allows direct access to byte synchronous lower level signals  for example  ds1  with just one frame recovery procedure  refer slide time  40  5 7  41  33  these are the advantages of the sonet frames this is one frame coming in may be 125 microseconds ; this is the next frame ; and spe  as i have already shown  can overlap i mean it may start somewhere within the first frame and then continue in the second frame in this fashion and then be over here actually after this  some other envelope may come in over here  refer slide time  41  35  42  34  now of course where is the path overhead ? there are two fields  h1 and h2 in loh ; loh means line overhead  which points to the beginning of the path overhead path overhead beginning floats within the frame ; 9 bytes that is one column may span frame along with the spe ; it is originated and terminated by all path devices ; and this gives you end-to-end support these are the features of path overhead the point is that if you remember the path is end to end  that means it is close to the end users ; just as the end user may start somewhere arbitrarily in-between  a path overhead also goes along with the spe and it starts over there and at loh  we keep a pointer to this path overhead  refer slide time  42  40  44  17  just as some of the equipment that we use in sonet  one of the most important of these is the add drop multiplexer they are important because at certain point in the network  what might happen is that there are some sources which want to send into the network they will sort of go so there is this sonet equipment  which is adm let us say  and sonet stream is flowing let us say like this there may be something that wants to upload and travel along with this thing at the same time  this may be the destination location for some of the other signals which originated elsewhere ; they have to be dropped here so some signals have to be dropped  some signals have to be added so this multiplexer can handle that and that is very important that is why they are called add drop multiplexers this stream is itself of course flowing at a tremendous rate  whatever that rate is so sonet sdh is a synchronous system with the master clock accuracy of 1 in 109  which you will see is highly accurate it shows when you come in some kind of ccm clock somewhere and then there is a protocol for distributing and maintaining this clock over the entire network frames are sent byte by byte and adms can add drop smaller tributaries into the main sonet sdh stream and i have explained how that is done within that frame you can send lot of bytes ; you can take out some of the bytes and add some of the bytes that is how you take out some of the smaller tributaries and add some of the smaller tributaries  refer slide time  44  22  44  58  digital cross connect  which is an optical layer equipment  is also very important it cross connects thousands of streams and software control  so it replaces patch panel ; that is a good thing about the digital cross connect and a software control is coming where the control is coming from the control plane of the switches you can connect the streams from may be one fiber to another ; it handles performance monitoring  pdh sonet streams  and also provides adm functions ; that means add drop multiplexing functions  refer slide time  44  58  45  47  finally we have this concept of grooming in sonet grooming means  we group the traffic in some format so you want to keep this group in one particular way ; it could be that there is a one group of streams for whom you want to give higher priority or you want to give higher quality of service so you have to group them together similarly there may be multiple groups ; so it enables grouping traffic with similar destination  qos  etc  which is a part of grooming it enables multiplexing or extracting streams also ? that is also part of grooming narrow wider broadband and optical cross connects may be used for grooming  refer slide time  45  47  46  40  if you look at this figure  you have this narrow band  this sonet layer and optical layer in the narrow band  we have this ds0 grooming and then in the ds1 grooming  there is a white band and then the broadband ds3 grooming ? so the rates are going up  starting from the 64 kbps  it is going up when you are going up for the sts 48  you are in optical domain ; that means sts 48 is stm 16  so that is a high rate the point is that  at that rate  most probably  you are well in the optical domain then  finally  you can go to all optical domain ; that means wavelength  waveband  and fiber grooming ? there are different levels of grooming  depending on what you want to do  refer slide time  46  42  48  00  lastly we will just talk a little bit about virtual tributaries or containers we have already talked a little bit about it this is the opposite of stm ; actually in some sense this is called sub multiplexing ; that is  different streams coming together to form one very fat or very fast stream this is the other thing ? how do we  sort of  differentiate these sub streams within this  which has to do with sub multiplexing ? sts -1 is divided into 7 virtual tributary groups  sdh uses the term virtual containers or vcs we talked about vcs  we just mentioned what are called vts or virtual tributaries in sonet lingo so we have 7 virtual tributaries  12 columns each  which can be subdivided further you see that there are 12 columns each  with 7 virtual tributary groups ? we have got 84 columns and these 84 columns are out of the 87 you have in sts -1  refer slide time  48  01  50  00  vt groups are byte interleaved to create a basic sonet spe so this vt groups are byte interleaved they may be again extracted from each other vt 1.5 is the most popular  quickly accessed  t1 line within the sts-1 frame so the idea is that you have a t1 line  which is approximately 1.5 mbps line  which is coming out of your small business  and you have a 1.5 mbps line so that is your bandwidth requirement  you want to connect it to a distant location somewhere and you do not want your thing to get mixed up with others at the same time  as a small business you can not have infrastructure of connecting to another location which is wide apart so you will go with this public infrastructure or public switched tele psdn network or whoever is maintaining this communication equipment usually telecom people maintain it in most of the places anyway  they have a sort of fiber going from one place to another  which contains very high-speed links what you want is your t1 line should join them  sort of get transported over the distance and then go and feed into another t1 line at the destination that is what you want you want your t1 line to sort of have a separate sort of existence ? just like in a compartment  we have different passengers passengers have their own individual entity but together they are packed into one compartment and then they travel similarly your t1 line is going to ride onto to this very fast stream and travel to the destination so vt 1.5 gives your t1 line  refer slide time  50  00  51  16  how do you find out about the difference ? how do you separate them in the sp ? the point is  you require one more level of pointer used to access it you can access a t1 with just a 2-pointer operation  first from the loh ? you remember  you go to the sp  just like that similarly  you go to the different tributaries or different containers using just one more level of pointer this flexibility was not there earlier ; so it was very complex to do the same function in ds3 for example  accessing ds0 within ds3 requires full demultiplexing  stacked multiplexing  etc so you require full demultiplexing ; that is not required in sonet the point is that the other streams may go ; you know where in that frame your bytes really are traveling for the stream or for the container or for the tributary that you are interested ; you just extract it  others keep on traveling as they are so you do not demultiplex the whole thing and that gives a great advantage of add drop multiplexing  refer slide time  51  16  52  02  this is just a figure showing that you can have various types of lines  all feeding into the same infrastructure you may have what we have put over here  ds1  which is 1.544 mbps  e1  2.048 mbps  dsic ds2  ds3  atm .48.384  e4  which is 139.264 mbps  atm is about 150 mbps  etc they are sort of traveling ; they are getting in different containers from vt 1.5  different tributaries  that is 1 5236 etc  form a vt group and ride on a higher strength or higher speed stream  refer slide time  52  02  53  55  just as i said  these are sort of identified through a pointer ; so we have this transport overhead we use some bytes for that out of those 87 columns we have so we use some columns of that and then we put a pointer  which gives to the sts payload pointer then there is a vt pointer  virtual tributary pointer  and this much is the vt spe within the overall sts-1 spe  which is the payload even now sonet is the most widely used technology in wide area networking that is existing today of course  as you know  as technology grows  may be we will go out of sonet people are already talking about going out of sonet because one disadvantage of sonet is that its equipment tends to be expensive well  expensive compared to what we think today what is cheap today and what we think is cheap today may sound very expensive tomorrow ; that is how the technology grows so people are talking about direct transport over the optical layer  etc may be we will touch those aspects later on but all that is still in a sort of experimental stage and on the field  actually  sdh or sonet equipment is almost everywhere ; all types of telephone companies are connected through that and major service providers use this as a means of transport thank you  refer slide time  53  58  54  11  good day,so today we will be speaking about fiber optic components  refer slide time  54  11  55  22  and fiber optic communication as might of heard this lecture as well as the next couple of lectures  we will concentrate on fiber optic components we have looked at some of the physical layer components of fiber optic systems before so we will sort of quickly review that  some of the stuff we will be talking about today is going to be common and then from that point we will take out take it up into wdm systems  how wavelength division multiplexing is done and how systems are handled in fiber optic domain  this fiber optic domain happens to be very crucial because a lot of traffic in terms of volume may be as much as forty to fifty percent  actually goes through the fiber as days are going by and as more and more demand for bandwidth is coming up fiber optics is becoming more and more important  we will be talking about fiber optic components today  refer slide time  55  22  55  56  in fiber optic component of course the basic fiber is there we have already talked about it  so we will talk little bit more about this then we have light source and receivers on two end because we know that in fiber optic cables light is the carrier of information then we require these different components like amplifiers  couplers  modulator  multiplexer and switches so we will look up at these components one by one and then we will start our discussion on wavelength division multiplexing  refer slide time  55  56  56  42  the next set of components are multiplexers filters gratings  just talk little bit about it ,if you look at this wavelength  these are all ; wavelength selective  devices multiplexers  filters  these are wavelength selective devices in a wavelength filter and what we want is suppose ? 1  ? 2 etc so many are coming  i want only ? 1 out 2 ? 3 ? 4 etc are absorbed or something where as if you are a multiplexer i want the difference this ? coming in different lines  i want all to be mixed together and use the same line  these are wavelength multiplexer  refer slide time  56  42  58  07  so application could be particular wavelength or a particular wave band selection wave band is nothing but some contiguous operating wavelengths which all are side by side  if you remember that in the operating window what ever be that 1550 what ever may be the window you are using there you can have a number of ? all side by side  there is a guard band between each of these operating ? so where the guard band that is given by the i q t has specified  how much guard band etc you have to have but so you can have large number of ? all group together in the same window aband out of that means a bunch of sequence is out of that you can short select instead of selecting only  that is wavelength band selection static wavelength cross connects and oam is optical add drop multiplexers  you have come across this term optical add drop multiplexers in the context of sonet but optical domain we require optical add drop multiplexers  we will come to that equalization of gain so that is another application filtering of noise ideas used in laser operation and dispersion compensation modules etc  these are the different applications  refer slide time  58  08  58  15  one of the standard wavelength selective component is arrayed waveguide gratings ,we have seen this before ? 