
Dynamic array
 /firstHeading 
 bodyContent 

 tagline 
From Wikipedia, the free encyclopedia
 /tagline 
 subtitle 

 /subtitle 
 jumpto 

					Jump to:					navigation, 					search

 /jumpto 
 bodycontent 




Several values are inserted at the end of a dynamic array using geometric expansion. Grey cells indicate space reserved for expansion. Most insertions are fast (constant time), while some are slow due to the need for reallocation ((n) time, labelled with turtles). The logical size and capacity of the final array are shown.


In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed. It is supplied with standard libraries in many modern mainstream programming languages.
A dynamic array is not the same thing as a dynamically allocated array, which is a fixed-size array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end.[1]




Contents


1 Bounded-size dynamic arrays and capacity
2 Geometric expansion and amortized cost
3 Performance
4 Variants
5 Language support
6 References
7 External links




[edit] Bounded-size dynamic arrays and capacity
The simplest dynamic array is constructed by allocating a fixed-size array and then dividing it into two parts: the first stores the elements of the dynamic array and the second is reserved, or unused. We can then add or remove elements at the end of the dynamic array in constant time by using the reserved space, until this space is completely consumed. The number of elements used by the dynamic array contents is its logical size or size, while the size of the underlying array is called the dynamic array's capacity, which is the maximum possible size without relocating data.
In applications where the logical size is bounded, the fixed-size data structure suffices. This may be short-sighted, when problems with the array filling up turn up later. It is best to put resize code into any array, to respond to new conditions. Then choosing initial capacity is optimization, not getting the program to run. Resizing the underlying array is an expensive task, typically involving copying the entire contents of the array.
[edit] Geometric expansion and amortized cost
To avoid incurring the cost of resizing many times, dynamic arrays resize by a large amount, such as doubling in size, and use the reserved space for future expansion. The operation of adding an element to the end might work as follows:

function insertEnd(dynarray a, element e)
    if (a.size = a.capacity)
        // resize a to twice its current capacity:
        a.capacity  a.capacity * 2  
        // (copy the contents to the new memory location here)
    a[a.size]  e
    a.size  a.size + 1

As n elements are inserted, the capacities form a geometric progression. Expanding the array by any constant proportion ensures that inserting n elements takes O(n) time overall, meaning that each insertion takes amortized constant time. The value of this proportion a leads to a time-space tradeoff: the average time per insertion operation is about a/(a1), while the number of wasted cells is bounded above by (a1)n. The choice of a depends on the library or application: some textbooks use a=2,[2][3] but Java's ArrayList implementation uses a=3/2[1] and the C implementation of Python's list data structure uses a=9/8.[4]
Many dynamic arrays also deallocate some of the underlying storage if its size drops below a certain threshold, such as 30% of the capacity. This threshold must be strictly smaller than 1/a in order to support mixed sequences of insertions and removals with amortized constant cost.
Dynamic arrays are a common example when teaching amortized analysis.[2][3]
[edit] Performance




Linked list
Array
Dynamic
array
Balanced
tree
Random access
list


Indexing
(n)
(1)
(1)
(log n)
(log n)


Insert/delete at beginning
(1)
N/A
(n)
(log n)
(1)


Insert/delete at end
(1)
N/A
(1) amortized
(log n)
(log n) updating


Insert/delete in middle
search time +
(1)[5][6][7]
N/A
(n)
(log n)
(log n) updating


Wasted space (average)
(n)
0
(n)[8]
(n)
(n)



The dynamic array has performance similar to an array, with the addition of new operations to add and remove elements from the end:

Getting or setting the value at a particular index (constant time)
Iterating over the elements in order (linear time, good cache performance)
Inserting or deleting an element in the middle of the array (linear time)
Inserting or deleting an element at the end of the array (constant amortized time)

Dynamic arrays benefit from many of the advantages of arrays, including good locality of reference and data cache utilization, compactness (low memory use), and random access. They usually have only a small fixed additional overhead for storing information about the size and capacity. This makes dynamic arrays an attractive tool for building cache-friendly data structures.
Compared to linked lists, dynamic arrays have faster indexing (constant time versus linear time) and typically faster iteration due to improved locality of reference; however, dynamic arrays require linear time to insert or delete at an arbitrary location, since all following elements must be moved, while linked lists can do this in constant time. This disadvantage is mitigated by the gap buffer and tiered vector variants discussed under Variants below. Also, in a highly fragmented memory region, it may be expensive or impossible to find contiguous space for a large dynamic array, whereas linked lists do not require the whole data structure to be stored contiguously.
A balanced tree can store a list while providing all operations of both dynamic arrays and linked lists reasonably efficiently, but both insertion at the end and iteration over the list are slower than for a dynamic array, in theory and in practice, due to non-contiguous storage and tree traversal/manipulation overhead.
[edit] Variants
Gap buffers are similar to dynamic arrays but allow efficient insertion and deletion operations clustered near the same arbitrary location. Some deque implementations use array deques, which allow amortized constant time insertion/removal at both ends, instead of just one end.
Goodrich[9] presented a dynamic array algorithm called Tiered Vectors that provided O(n1/2) performance for order preserving insertions or deletions from the middle of the array.
Hashed Array Tree (HAT) is a dynamic array algorithm published by Sitarski in 1996.[10] Hashed Array Tree wastes order n1/2 amount of storage space, where n is the number of elements in the array. The algorithm has O(1) amortized performance when appending a series of objects to the end of a Hashed Array Tree.
In a 1999 paper,[8] Brodnik et al. describe a tiered dynamic array data structure, which wastes only n1/2 space for n elements at any point in time, and they prove a lower bound showing that any dynamic array must waste this much space if the operations are to remain amortized constant time. Additionally, they present a variant where growing and shrinking the buffer has not only amortized but worst-case constant time.
Bagwell (2002)[11] presented the VList algorithm, which can be adapted to implement a dynamic array.
[edit] Language support
C++'s std::vector is an implementation of dynamic arrays, as are the ArrayList[12] classes supplied with the Java API and the .NET Framework. The generic List<> class supplied with version 2.0 of the .NET Framework is also implemented with dynamic arrays. Smalltalk's OrderedCollection is a dynamic array with dynamic start and end-index, making the removal of the first element also O(1). Python's list datatype implementation is a dynamic array. Delphi and D implement dynamic arrays at the language's core. Ada's Ada.Containers.Vectors generic package provides dynamic array implementation for a given subtype. Many scripting languages such as Perl and Ruby offer dynamic arrays as a built-in primitive data type. Several cross-platform frameworks provide dynamic array implementations for C: CFArray and CFMutableArray in Core Foundation; GArray and GPtrArray in GLib.
[edit] References

^ a b See, for example, the source code of java.util.ArrayList class from OpenJDK 6.
^ a b Goodrich, Michael T.; Tamassia, Roberto (2002), "1.5.2 Analyzing an Extendable Array Implementation", Algorithm Design: Foundations, Analysis and Internet Examples, Wiley, pp.3941.
^ a b Cormen, Thomas H.; Leiserson, Charles E., Rivest, Ronald L., Stein, Clifford (2001) [1990]. "17.4 Dynamic tables". Introduction to Algorithms (2nd ed.). MIT Press and McGraw-Hill. pp.416424. ISBN0-262-03293-7.
^ List object implementation from python.org, retrieved 2011-09-27.
^ Gerald Kruse. CS 240 Lecture Notes: Linked Lists Plus: Complexity Trade-offs. Juniata College. Spring 2008.
^ Day 1 Keynote - Bjarne Stroustrup: C++11 Style at GoingNative 2012 on channel9.msdn.com from minute 45 or foil 44
^ Number crunching: Why you should never, ever, EVER use linked-list in your code again at kjellkod.wordpress.com
^ a b Brodnik, Andrej; Carlsson, Svante; Sedgewick, Robert; Munro, JI; Demaine, ED (Technical Report CS-99-09), Resizable Arrays in Optimal Time and Space, Department of Computer Science, University of Waterloo, http://www.cs.uwaterloo.ca/research/tr/1999/09/CS-99-09.pdf
^ Goodrich, Michael T.; Kloss II, John G. (1999), "Tiered Vectors: Efficient Dynamic Arrays for Rank-Based Sequences", Workshop on Algorithms and Data Structures, Lecture Notes in Computer Science 1663: 205216, doi:10.1007/3-540-48447-7_21, ISBN978-3-540-66279-2, http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7503
^ Sitarski, Edward (September 1996), Algorithm Alley, "HATs: Hashed array trees", Dr. Dobb's Journal 21 (11), http://www.ddj.com/architect/184409965?pgno=5
^ Bagwell, Phil (2002), Fast Functional Lists, Hash-Lists, Deques and Variable Length Arrays, EPFL, http://citeseer.ist.psu.edu/bagwell02fast.html
^ Javadoc on ArrayList

[edit] External links

NIST Dictionary of Algorithms and Data Structures: Dynamic array
VPOOL - C language implementation of dynamic array.
CollectionSpy  A Java profiler with explicit support for debugging ArrayList- and Vector-related issues.
Open Data Structures - Chapter 2 - Array-Based Lists









v
t
e


Data structures






Types



Collection
Container








Abstract



List
Associative array
Multimap
Set
Multiset
Queue
Double-ended queue
Priority queue
Double-ended priority queue
Stack








Arrays



Dynamic array
Hashed array tree
Sparse array
Circular buffer
Bit array
Hash table








Linked



Linked list
Unrolled linked list
XOR linked list
Skip list
Association list








Trees



B-tree
Binary search tree

self-balancing
AA
AVL
red-black
splay


Heap

binary
binomial
Fibonacci


R-tree

R*
R+
Hilbert


Trie








Graphs



Directed acyclic word graph
Binary decision diagram











List of data structures








 
NewPP limit report
Preprocessor visited node count: 4553/1000000
Preprocessor generated node count: 26046/1500000
Post-expand include size: 40998/2048000 bytes
Template argument size: 11783/2048000 bytes
Highest expansion depth: 16/40
Expensive parser function count: 0/500

 Saved in parser cache with key enwiki:pcache:idhash:1456434-0!*!0!!en!4!* and timestamp 20130120215728 
  /bodycontent 
 printfooter 

				Retrieved from "http://en.wikipedia.org/w/index.php?title=Dynamic_array&oldid=530196043"				
 /printfooter 
 catlinks 
Categories: ArraysHidden categories: Articles with example pseudocode  /catlinks 

 debughtml 
 /debughtml 

 /bodyContent 

 